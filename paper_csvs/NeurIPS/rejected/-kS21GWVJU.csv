Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0016339869281045752,"To estimate item frequencies of data streams with limited space, sketches are widely
1"
ABSTRACT,0.0032679738562091504,"used in real applications, including real-time web analytics, network monitoring,
2"
ABSTRACT,0.004901960784313725,"and self-driving. Sketches can be viewed as a model which maps the identiﬁer of a
3"
ABSTRACT,0.006535947712418301,"stream item to the corresponding frequency domain. Starting from the premise, we
4"
ABSTRACT,0.008169934640522876,"envision a neural data structure, which we term the meta-sketch, to go beyond the
5"
ABSTRACT,0.00980392156862745,"basic structure of conventional sketches. The meta-sketch learns basic sketching
6"
ABSTRACT,0.011437908496732025,"abilities from meta-tasks constituted with synthetic datasets following Zipf distribu-
7"
ABSTRACT,0.013071895424836602,"tions in the pre-training phase, and can be fast adapted to real (skewed) distributions
8"
ABSTRACT,0.014705882352941176,"in the adaption phase. Extensive experiments demonstrate the performance gains
9"
ABSTRACT,0.016339869281045753,"of the meta-sketch and offer insights into our proposals.
10"
INTRODUCTION,0.017973856209150325,"1
Introduction
11"
INTRODUCTION,0.0196078431372549,"Estimating item frequency is a basic topic in data stream processing, which ﬁnds applications in
12"
INTRODUCTION,0.021241830065359478,"the ﬁelds of networking, databases, and machine learning, such as real-time data analyzing [1–4],
13"
INTRODUCTION,0.02287581699346405,"network trafﬁc monitoring [5–7], natural language processing [8] and search ranking [9]. Towards
14"
INTRODUCTION,0.024509803921568627,"inﬁnite data streams, a common class of solutions [10–15] use a compact structure taking sublinear
15"
INTRODUCTION,0.026143790849673203,"space for counting the number of occurrences of each stream item, called the sketch.
16"
INTRODUCTION,0.027777777777777776,"Under the prevalent evidence of skewed distributions in data streams, basic sketches achieve the space
17"
INTRODUCTION,0.029411764705882353,"compactness by hashing and approximately aggregating stream items. Basic sketches, including
18"
INTRODUCTION,0.03104575163398693,"CM-sketch [10], C-sketch [11] and CU-sketch [12], use a 2D array of counters as the core structure.
19"
INTRODUCTION,0.032679738562091505,"To optimize the sketching performance, there arise augmented sketches [13,14], which attach ﬁlters to
20"
INTRODUCTION,0.03431372549019608,"basic sketches, to capture the preliminary patterns of skewed distributions (e.g., high/low-frequency
21"
INTRODUCTION,0.03594771241830065,"items). By separately maintaining the ﬁltered high/low-frequency items, augmented sketches strive
22"
INTRODUCTION,0.03758169934640523,"to eliminate the estimation error incurred by hash collisions between the high- and low-frequency
23"
INTRODUCTION,0.0392156862745098,"items. Further, learned augmented sketches [15] improve the ﬁlters of the augmented sketches by
24"
INTRODUCTION,0.04084967320261438,"memorizing short-term high/low-frequency items via a pre-trained neural network (NN in short)
25"
INTRODUCTION,0.042483660130718956,"classiﬁer. But it is not clear how the pre-trained NN can be adapted to dynamic streaming scenarios,
26"
INTRODUCTION,0.04411764705882353,"where the correspondence between items and frequencies varies. In a nutshell, sketches are structures
27"
INTRODUCTION,0.0457516339869281,"compactly summarizing stream distributions to count item frequencies with limited space budgets.
28"
INTRODUCTION,0.04738562091503268,"From the retrospective analysis of sketches, an observation can be drawn that the evolution of
29"
INTRODUCTION,0.049019607843137254,"sketches conforms with the exploitation of data distributions. It is thus a natural evolution to consider
30"
INTRODUCTION,0.05065359477124183,"a sketch that generally and automatically captures more distribution patterns with limited space
31"
INTRODUCTION,0.05228758169934641,"budgets. In this paper, we envision a novel neural sketch, called the meta-sketch, with techniques
32"
INTRODUCTION,0.05392156862745098,"of meta-learning and memory-augmented neural networks. The meta-sketch learns the sketching
33"
INTRODUCTION,0.05555555555555555,"abilities from automatically generated meta-tasks. Depending on the types of meta-tasks, we study
34"
INTRODUCTION,0.05718954248366013,"two versions of the meta-sketch, called basic and advanced meta-sketches.
35 Store Query"
INTRODUCTION,0.058823529411764705,Figure 1: The Framework of the Meta-sketch
INTRODUCTION,0.06045751633986928,"The basic meta-sketch implements the simulation of basic sketches, through the training process with
36"
INTRODUCTION,0.06209150326797386,"basic meta-tasks following Zipf distributions, which are prevalent in the scenes of real data streams [16–
37"
INTRODUCTION,0.06372549019607843,"20]. The advanced meta-sketch extends the basic version to fast adapt to the speciﬁc runtime of stream
38"
INTRODUCTION,0.06535947712418301,"processing, through the training with adaptive meta-tasks, which are generated by online sampling
39"
INTRODUCTION,0.06699346405228758,"of real data streams. Our work follows a typical setting where the distribution of item frequencies
40"
INTRODUCTION,0.06862745098039216,"follows a skewed distribution, but the correspondence between items and frequencies varies. For
41"
INTRODUCTION,0.07026143790849673,"example, in software-deﬁned networks (SDN), sketches are deployed to programmable switches to
42"
INTRODUCTION,0.0718954248366013,"collect per-ﬂow statistics, where IP packets follow heavy-tailed distributions [15,21]. In distributed
43"
INTRODUCTION,0.07352941176470588,"databases, it gives advances to collect statistics of data shards to optimize data placement and
44"
INTRODUCTION,0.07516339869281045,"query caching, where query phrases follow approximate Zipf distributions [15]. Given that the item
45"
INTRODUCTION,0.07679738562091504,"population follows a speciﬁc distribution, the local distributions, i.e., item-frequency correspondences
46"
INTRODUCTION,0.0784313725490196,"on shards or ﬂows, are different. Instead of retraining learned augmented sketches on each local
47"
INTRODUCTION,0.08006535947712418,"distribution, the advanced-sketch can be quickly adapted to different local distributions once trained.
48"
INTRODUCTION,0.08169934640522876,"As a member of the neural data structure family [15,22–24], the meta-sketch signiﬁcantly differs
49"
INTRODUCTION,0.08333333333333333,"from conventional sketches, in terms of the structure and working mechanism. The meta-sketch
50"
INTRODUCTION,0.08496732026143791,"utilizes NN’s powerful encoding/decoding capabilities to perceive data distributions and express
51"
INTRODUCTION,0.08660130718954248,"and compress explicit or implicit information to retrieve item frequencies with better accuracies.
52"
INTRODUCTION,0.08823529411764706,"Meanwhile, the meta-sketch is differentiable to fully perceive frequency patterns for self-optimization.
53"
INTRODUCTION,0.08986928104575163,"Our contributions are as follows. 1) We propose the meta-sketch, the ﬁrst neural data structure for the
54"
INTRODUCTION,0.0915032679738562,"problem of item frequency estimation, based on meta-learning. 2) The basic meta-sketch acquires
55"
INTRODUCTION,0.09313725490196079,"sketching abilities by learning from synthetic datasets, and outperforms basic sketches in real datasets.
56"
INTRODUCTION,0.09477124183006536,"The advanced meta-sketch automatically encompasses the ability analogous to the auxiliary structures
57"
INTRODUCTION,0.09640522875816994,"deliberately devised in (learned) augmented sketches, yet yielding better accuracies and robustness
58"
INTRODUCTION,0.09803921568627451,"when adapted to dynamic scenes. 3) Through extensive empirical studies on real and synthetic
59"
INTRODUCTION,0.09967320261437909,"datasets, we evaluate our proposed meta-sketches and analyze the mechanism of major modules.
60"
META-SKETCH STRUCTURE,0.10130718954248366,"2
Meta-sketch Structure
61"
PRELIMINARIES,0.10294117647058823,"2.1
Preliminaries
62"
PRELIMINARIES,0.10457516339869281,"We consider a standard data stream scenario [19]. Suppose a data stream SN : {e1, ..., eN} with N
63"
PRELIMINARIES,0.10620915032679738,"items and n distinct items. Each item ei ∈SN takes a value from the item domain X = {x1, ..., xn}
64"
PRELIMINARIES,0.10784313725490197,"where xi ̸= xj. The frequency fi is equal to the number of times that item xi appears in SN.
65"
PRELIMINARIES,0.10947712418300654,"To leverage learning techniques for item frequency estimation, a naïve way is to train a NN model
66"
PRELIMINARIES,0.1111111111111111,"(e.g., MLP/LSTM) that learns/memorizes the mapping relationship between items and frequencies
67"
PRELIMINARIES,0.11274509803921569,"with multiple training iterations, similar to [15,22,24]. However, it violates the typical setting of
68"
PRELIMINARIES,0.11437908496732026,"stream processing where item observations are transient and are therefore handled in one pass [18].
69"
PRELIMINARIES,0.11601307189542484,"More, the costly procedure has to be repeated from the scratch for a new data stream. Inspired by the
70"
PRELIMINARIES,0.11764705882352941,"meta-bloom ﬁlter [23], we consider a case of one-shot learning (ﬁtting for one-pass stream processing)
71"
PRELIMINARIES,0.119281045751634,"by using meta-learning [25,26] and memory-augmented networks [27,28]. Meta-learning employs
72"
PRELIMINARIES,0.12091503267973856,"sampled meta-tasks to learn the ability to solve a class of domain tasks rather than memorizing patterns
73"
PRELIMINARIES,0.12254901960784313,"for a speciﬁc task. The memory-augmented networks incorporate external memories into NN models,
74"
PRELIMINARIES,0.12418300653594772,"signiﬁcantly enhancing the potentials of NN models with more learnable parameters. Meanwhile, it
75"
PRELIMINARIES,0.12581699346405228,"performs efﬁcient and explicit operations (i.e., reading and storing) for external memories, allowing
76"
PRELIMINARIES,0.12745098039215685,"NN models to process information similarly to conventional data structures.
77"
PRELIMINARIES,0.12908496732026145,"The framework of the meta-sketch consists of 4 functional modules, Embedding (FE), Sparse
78"
PRELIMINARIES,0.13071895424836602,"addressing (FSa), Compressed storage matrix (M), and Decoding (Fdec), as shown in Figure 1. Like
79"
PRELIMINARIES,0.1323529411764706,"traditional sketches, the meta-sketch encodes and memorizes online stream items in one pass, and
80"
PRELIMINARIES,0.13398692810457516,"answers queries by decoding corresponding item-frequency information from the structure.
81"
PRELIMINARIES,0.13562091503267973,"Thus, we deﬁne 2 operations, Store and Query. Speciﬁcally, the Store operation ﬁrst passes each
82"
PRELIMINARIES,0.13725490196078433,"incoming stream item to FE for the embedding representation, and then writes the embedding vector
83"
PRELIMINARIES,0.1388888888888889,"into M, according to the address derived by FSa. When estimating the frequency of an item, the
84"
PRELIMINARIES,0.14052287581699346,"Query operation calculates the item’s address in M via FSa, reads the corresponding information
85"
PRELIMINARIES,0.14215686274509803,"vector from M, and decodes the item frequency by Fdec from the retrieved information vector .
86"
MODULES,0.1437908496732026,"2.2
Modules
87"
MODULES,0.1454248366013072,"Embedding. The module FE has two purposes: 1) performing representational transformation for
88"
MODULES,0.14705882352941177,"an incoming item ei and mapping it into a dense embedding vector zi that holds implicit features
89"
MODULES,0.14869281045751634,"about item-frequency distributions and serves as the basis for identifying stream items; 2) decoupling
90"
MODULES,0.1503267973856209,"the embedding vector zi to obtain a reﬁned vector ri, which is used to derive the address for
91"
MODULES,0.15196078431372548,"reading/writing on the compressed storage matrix M.
92"
MODULES,0.15359477124183007,"Accordingly, FE consists of the embedding network gemb and the address network gadd. We assume
93"
MODULES,0.15522875816993464,"that an item ei ∈SN is numerically encoded for the unique identiﬁcation, following the conventions
94"
MODULES,0.1568627450980392,"of stream processing [18, 19]. Thus, we have zi, ri ←FE(ei), where zi ←gemb(ei) and ri ←
95"
MODULES,0.15849673202614378,"gadd(zi). Here, zi ∈Rlz is an embedding vector of length lz, and ri ∈Rlr is a reﬁned vector of
96"
MODULES,0.16013071895424835,"length lr. The vector zi serves multiple intents: 1) it makes a basis for deriving the address of an item
97"
MODULES,0.16176470588235295,"in FSa; 2) it serves as the compressed vector of an item written into M; 3) it works as a partial input
98"
MODULES,0.16339869281045752,"of Fdec for decoding the item frequency; 4) it also plays the role of perceiving/compressing patterns
99"
MODULES,0.1650326797385621,"of a speciﬁc frequency distribution, as discussed in Section 5. In addition, to enhance the addressing
100"
MODULES,0.16666666666666666,"functionality and eliminate other interference factors, we decouple zi to generate a reﬁned vector ri,
101"
MODULES,0.16830065359477125,"instead of using zi directly for the addressing.
102"
MODULES,0.16993464052287582,"Sparse addressing. The module FSa aims to derive the address ai for storing the embedding vector
103"
MODULES,0.1715686274509804,"zi into the storage matrix: ai ←FSa(ri). In terms of functionality, FSa is analogous to the hash
104"
MODULES,0.17320261437908496,"functions of traditional sketches, except that FSa is parameterized and differentiable. Speciﬁcally,
105"
MODULES,0.17483660130718953,"the addressing of the meta-sketch is done via a 3D addressing matrix A of parameters to be learned
106"
MODULES,0.17647058823529413,"and a sparse SoftMax function: ai ←SparseMax(rT
i A), where A ∈Rd1×lr×d2. Then, the batch
107"
MODULES,0.1781045751633987,"matrix multiplication of A and the transpose of ri results in the addressing vector ai ∈Rd1×1×d2.
108"
MODULES,0.17973856209150327,"The setting of d1 and d2 determines the size of address space for storing the embedding vectors.
109"
MODULES,0.18137254901960784,"Typical addressing methods [23, 28] use a 2D matrix (lr × d2) for recording the mapping of an
110"
MODULES,0.1830065359477124,"embedding vector to a slot (d2 is the number of slots). In contrast, we add one more dimension d1
111"
MODULES,0.184640522875817,"to simulate the multi-hash setting of traditional sketches, in view of that a 2D addressing matrix
112"
MODULES,0.18627450980392157,"can reach a differentiable simulation of a hash function [23,24]. Matrix A simulates multiple hash
113"
MODULES,0.18790849673202614,"functions, yielding robust frequency decoding and the rationality of the learning optimization. Note
114"
MODULES,0.1895424836601307,"that each 2D slice A∗of A is stacked from d2-unit vectors bi ∈Rlr by normalizing the parameters
115"
MODULES,0.19117647058823528,"of A at each gradient update of the training process. Normalized A can avoid overﬂowing when
116"
MODULES,0.19281045751633988,"compressing its size by reducing data precisions and enhance the interpretability (see Section 5).
117"
MODULES,0.19444444444444445,"In addition, we utilize sparse SoftMax [29, 30] instead of SoftMax to normalize the address ai.
118"
MODULES,0.19607843137254902,"It brings the following beneﬁts by constraining some bits of ai to zero, which 1) promotes quick
119"
MODULES,0.1977124183006536,"derivation during the back-propagation; 2) reduces the overhead of storage matrix accessing by
120"
MODULES,0.19934640522875818,"skipping the slots of M corresponding to the “0” bits of ai; 3) leads to de-noising with the vector
121"
MODULES,0.20098039215686275,"compression.
122"
MODULES,0.20261437908496732,"Compressed storage matrix. We use a matrix M ∈Rd1×lz×d2 1 to store an embedding vector
123"
MODULES,0.2042483660130719,"zi ∈Rlz in accordance to its address ai ∈Rd1×1×d2. The functionality of M is similar to the 2D
124"
MODULES,0.20588235294117646,"array of counters in traditional sketches, yet yielding better capabilities in the storage compression.
125"
MODULES,0.20751633986928106,"Traditional sketches store item counts. Differently, M stores embedding vectors, which have richer
126"
MODULES,0.20915032679738563,"information compression capabilities, due to the diversity of value changes on different bits.
127"
MODULES,0.2107843137254902,"Decoding. Given a query item xi, the module Fdec, consisting of one NN component gdec, decodes
128"
MODULES,0.21241830065359477,"the information corresponding to xi, in order to obtain the estimated frequency ˆfi. The vector fed
129"
MODULES,0.21405228758169934,"into gdec is the concatenation of vector {M ⊖ai}, vector zi, and the current number of items (i.e., N)
130"
MODULES,0.21568627450980393,"recorded in a counter, ˆfi ←gdec({M ⊖ai}, zi, N). The operator ⊖refers to the reading operation
131"
MODULES,0.2173202614379085,"for the storage matrix. The basic form of ⊖gives the operation as M ⊖ai = MaT
i
2 [27,28]. For
132"
MODULES,0.21895424836601307,"optimization, we consider two optimized forms of ⊖, inspired by the “count-min” mechanism of the
133"
MODULES,0.22058823529411764,"CM-sketch. The ﬁrst one gives the minimum value of each row in MaT
i , aiming to remove the noise
134"
MODULES,0.2222222222222222,"of other items. The second one gives the minimum value of each row in MaT
i ◦1"
MODULES,0.2238562091503268,"zi , a normalized
135"
MODULES,0.22549019607843138,"1In this paper, we control lr : lz ≈1 : 5 to compress A.
2aT
i means transpose operation for dim 1 and d2"
MODULES,0.22712418300653595,"form of MaT
i . Here, ◦denotes the Hadamard product, and zi requires broadcast operations to comply
136"
MODULES,0.22875816993464052,"with its requirements. So, {M ⊖ai} refers to the concatenation of vectors generated by the basic
137"
MODULES,0.23039215686274508,"form and the two optimized forms. Please refer to supplement materials for more details.
138"
OPERATIONS,0.23202614379084968,"2.3
Operations
139"
OPERATIONS,0.23366013071895425,"Operation Store is performed by feeding an incoming item ei to FE and FSa to obtain embedding
140"
OPERATIONS,0.23529411764705882,"vector zi and address ai, and then additively writing zi to M, weighted by ai: M ←M + ziai. Here,
141"
OPERATIONS,0.2369281045751634,"other writing types [23,26–28] can also be employed, but simple additive writing is more efﬁcient
142"
OPERATIONS,0.238562091503268,"and allows to compute gradients in parallel [23]. In addition, additive writing also allows to deﬁne an
143"
OPERATIONS,0.24019607843137256,"optional Delete operation for the meta-sketch (see the supplement materials).
144"
OPERATIONS,0.24183006535947713,"Operation Query estimates the frequency of a given query item xi. First, zi and ai are obtained,
145"
OPERATIONS,0.2434640522875817,"similar to that of operation Store. Then, the vectors {M ⊖ai} are retrieved from M and N can be
146"
OPERATIONS,0.24509803921568626,"easily obtained by a small counter. Finally, {M ⊖ai}, zi and N are jointly fed into gdec to get the
147"
OPERATIONS,0.24673202614379086,"estimated frequency ˆfi of xi as the returned value. The two operations are shown in Algorithm 1.
148"
OPERATIONS,0.24836601307189543,Algorithm 1: Operations
OPERATIONS,0.25,"1 Operation Store(ei, M):
2
zi, ri ←FE(ei) ;
3
ai ←FSa(ri);
4
M ←M + ziai;"
OPERATIONS,0.25163398692810457,"5 Operation Query(xi,M,N):
6
zi, ri ←FE(xi);
7
ai ←FSa(ri);"
OPERATIONS,0.25326797385620914,"8
ˆ
fi ←Fdec({M ⊖ai}, zi, N);"
OPERATIONS,0.2549019607843137,"9
return ˆ
fi;"
OPERATIONS,0.2565359477124183,Algorithm 2: Training Framework
OPERATIONS,0.2581699346405229,"Data: Meta-sketch with all learnable parameters θ, Meta-task sampler R;
1 while i not reach max training steps do
2
Sample a meta-task ti : {si, qi} ∼R and count N;"
OPERATIONS,0.25980392156862747,"3
for e(i)
j
∈si do Store(e(i)
j
, M); end"
OPERATIONS,0.26143790849673204,"4
for x(i)
j
, f (i)
j
∈qi do ˆ
f (i)
j
←Query(x(i)
j
, M,N); L+=LossFun(f (i)
j
, ˆ
f (i)
j
);"
OPERATIONS,0.2630718954248366,"5
Backprop through: dL/dθ and update parameters: θ ←Optimizer(θ, dL/dθ);
6
Normalize A;
7
Clear M;
8 end 149"
META-SKETCH TRAINING,0.2647058823529412,"3
Meta-sketch training
150"
TRAINING FRAMEWORK,0.26633986928104575,"3.1
Training Framework
151"
TRAINING FRAMEWORK,0.2679738562091503,"The meta-sketch employs an efﬁcient one-shot meta-training method [31]. The training process thus
152"
TRAINING FRAMEWORK,0.2696078431372549,"contains two phases, pre-training and adaption phases. In the pre-training phase, the meta-sketch
153"
TRAINING FRAMEWORK,0.27124183006535946,"learns an initial set of module parameters, including gemb, gadd, A, and gdec. The pre-training
154"
TRAINING FRAMEWORK,0.272875816993464,"goes ofﬂine across training units, i.e., basic meta-tasks, to acquire the ability of stream frequency
155"
TRAINING FRAMEWORK,0.27450980392156865,"estimation. Then, in the adaption phase, the pre-trained meta-sketch goes fast across a set of light-
156"
TRAINING FRAMEWORK,0.2761437908496732,"weighted training units, i.e., adaptive meta-tasks, to quickly acquire the task-speciﬁc knowledge, i.e.,
157"
TRAINING FRAMEWORK,0.2777777777777778,"parameters for sketching real data streams at runtime.
158"
TRAINING FRAMEWORK,0.27941176470588236,"The training units, i.e., meta-tasks, are crucial for both phases. The training process of the meta-sketch
159"
TRAINING FRAMEWORK,0.28104575163398693,"on a single meta-task is equivalent to simulating storing and querying an instance of data streams
160"
TRAINING FRAMEWORK,0.2826797385620915,"while computing the estimation error to optimize the learnable parameters. Thus, a meta-task ti
161"
TRAINING FRAMEWORK,0.28431372549019607,"consists of a store set si (also called a support set) and a query set qi. The store set si can be viewed
162"
TRAINING FRAMEWORK,0.28594771241830064,"as an instance of data streams, si : {e(i)
1 , ..., e(i)
Ni}, where Ni is the number of stream items in si. The
163"
TRAINING FRAMEWORK,0.2875816993464052,"query set qi can be represented by a set of items from the stream instance with paired frequencies in
164"
TRAINING FRAMEWORK,0.28921568627450983,"the store set si, formally, qi : {(x(i)
1
: f (i)
1 ), ..., (x(i)
ni : f (i)
ni )}, where ni is the number of distinct items
165"
TRAINING FRAMEWORK,0.2908496732026144,"in si. In this work, we deﬁne two types of meta-tasks, basic (Section 3.2) and adaptive (Section 3.3)
166"
TRAINING FRAMEWORK,0.29248366013071897,"meta-tasks, corresponding to the pre-training and adaption phases, respectively.
167"
TRAINING FRAMEWORK,0.29411764705882354,"The two training phases, that are based on different types of meta-tasks, follow the same training
168"
TRAINING FRAMEWORK,0.2957516339869281,"framework, as shown in Algorithm 2, except for the sampler and initial parameters. To optimize on
169"
TRAINING FRAMEWORK,0.2973856209150327,"reducing both absolute and relative frequency estimation errors3, we devise an adaptive hybrid loss
170"
TRAINING FRAMEWORK,0.29901960784313725,"function [32] for the meta-sketch:
1
2σ2
1 (fi −ˆfi)2 +
1
2σ2
2 |fi −ˆfi|/fi + logσ1σ2, where σ1 and σ2 are
171"
TRAINING FRAMEWORK,0.3006535947712418,"learned parameters, and fi and ˆfi are the true and estimated frequencies of item xi, respectively.
172"
TRAINING FRAMEWORK,0.3022875816993464,3Average Absolute Error: AAE = 1
TRAINING FRAMEWORK,0.30392156862745096,"n
Pn
i=1 |fi −ˆfi|; Average Relative Error: ARE = 1"
TRAINING FRAMEWORK,0.3055555555555556,"n
Pn
i=1
|fi−ˆ
fi|
fi
."
BASIC META-TASK GENERATION,0.30718954248366015,"3.2
Basic Meta-task Generation
173"
BASIC META-TASK GENERATION,0.3088235294117647,"In the pre-training phase, basic meta-tasks should make the meta-sketch to simulate traditional
174"
BASIC META-TASK GENERATION,0.3104575163398693,"sketches and preserve certain generality without relying too much on the patterns of speciﬁc distribu-
175"
BASIC META-TASK GENERATION,0.31209150326797386,"tions (Section 5). Therefore, we generate meta-tasks based on the Zipf distribution, which is found to
176"
BASIC META-TASK GENERATION,0.3137254901960784,"be prevalent in real scenes of data streams [16–20].
177"
BASIC META-TASK GENERATION,0.315359477124183,"A meta-task is essentially a data stream instance with item size n, which can be determined by the
178"
BASIC META-TASK GENERATION,0.31699346405228757,"total number of items N and the relative frequency distribution p. Alternatively, we can generate
179"
BASIC META-TASK GENERATION,0.31862745098039214,"meta-tasks by presupposing different n, ¯f and p, where ¯f is the frequency mean, since N= ¯f×n.
180"
BASIC META-TASK GENERATION,0.3202614379084967,"Thus, basic meta-task generation is based on a sampler R : {I, L, P}, as follows.
181"
BASIC META-TASK GENERATION,0.32189542483660133,"An item pool I is a subset of the item domain X. The cardinality of I is in relevance to the
182"
BASIC META-TASK GENERATION,0.3235294117647059,"identiﬁcation capability of the meta-sketch. If the item domain is known a-priori, it can be directly
183"
BASIC META-TASK GENERATION,0.32516339869281047,"taken as the item pool. Otherwise, in applications where the item domain is only partially known or
184"
BASIC META-TASK GENERATION,0.32679738562091504,"even unknown, the item pool can be constructed by sampling from the historical records. Even in the
185"
BASIC META-TASK GENERATION,0.3284313725490196,"case that the item pool does not completely cover the item domain, the “missing” item can still be
186"
BASIC META-TASK GENERATION,0.3300653594771242,"identiﬁed, due to the homogeneity of the domain-speciﬁc embedding space, given that the number of
187"
BASIC META-TASK GENERATION,0.33169934640522875,"distinct items does not meet the item pool capacity |I|.
188"
BASIC META-TASK GENERATION,0.3333333333333333,"A frequency mean range L is the range for the frequency mean ¯f. One can get the value of ¯f by
189"
BASIC META-TASK GENERATION,0.3349673202614379,"statistics of each sampled stream instance and extract the minimum and maximum ¯fs to build L.
190"
BASIC META-TASK GENERATION,0.3366013071895425,"A distribution pool P consists of many instances generated according to different parameters of
191"
BASIC META-TASK GENERATION,0.3382352941176471,"relative frequency distributions. In this paper, we consider a family of Zipf distributions [33] with
192"
BASIC META-TASK GENERATION,0.33986928104575165,"varied parameter α, as the base for constructing P. α can be selected from a wide range to have a
193"
BASIC META-TASK GENERATION,0.3415032679738562,"good coverage of different distributions.
194"
BASIC META-TASK GENERATION,0.3431372549019608,"Notice that the meta-tasks are for the meta-sketch to learn the sketching ability, instead of spoon-
195"
BASIC META-TASK GENERATION,0.34477124183006536,"feeding the meta-sketch to mechanically memorize the parameters of R. It means that the trained
196"
BASIC META-TASK GENERATION,0.3464052287581699,"meta-sketch has the generalization ability to handle the case not covered in R (see Section 4.2).
197"
BASIC META-TASK GENERATION,0.3480392156862745,"The generation of a meta-task ti can be done based on sampler R, as follows. We ﬁrst randomly
198"
BASIC META-TASK GENERATION,0.34967320261437906,"sample a subset of ni items from I, and a frequency mean ¯fi ∈L. Then, we sample a distribution
199"
BASIC META-TASK GENERATION,0.35130718954248363,"instance pi ∈P and make the ni items’ frequencies conform to pi and ¯fi. For example, the
200"
BASIC META-TASK GENERATION,0.35294117647058826,"frequencies of ni items can be set as ni × ¯fi × pi, where pi ∼Zipf(α) is a random variable. The
201"
BASIC META-TASK GENERATION,0.3545751633986928,"above steps are repeated until the store set si and query set qi are built.
202"
ADAPTIVE META-TASK GENERATION,0.3562091503267974,"3.3
Adaptive Meta-task Generation
203"
ADAPTIVE META-TASK GENERATION,0.35784313725490197,"While processing real data streams, we can get the item set Ir and its distribution pr by online
204"
ADAPTIVE META-TASK GENERATION,0.35947712418300654,"sampling. Ir and pr are then used for generating the set of adaptive meta-tasks. For each adaptive
205"
ADAPTIVE META-TASK GENERATION,0.3611111111111111,"meta-task, an item subset is sampled from Ir, and the relative frequency corresponding to each item
206"
ADAPTIVE META-TASK GENERATION,0.3627450980392157,"is sampled from pr. The process is similar to the generation of basic meta-tasks. The only difference
207"
ADAPTIVE META-TASK GENERATION,0.36437908496732024,"from basic meta-task generation is that, there is no distribution pool anymore, because the real data
208"
ADAPTIVE META-TASK GENERATION,0.3660130718954248,"stream is unique. Also, we intentionally randomize the correspondence between an item and its real
209"
ADAPTIVE META-TASK GENERATION,0.36764705882352944,"relative frequency on the original data records. It is equivalent to constructing meta-tasks where
210"
ADAPTIVE META-TASK GENERATION,0.369281045751634,"the item frequencies dynamically change. For example, the frequency of an item may ﬁrst increase,
211"
ADAPTIVE META-TASK GENERATION,0.3709150326797386,"then suddenly drop [21]. With adaptive meta-tasks, the meta-sketch learns to quickly adapt to the
212"
ADAPTIVE META-TASK GENERATION,0.37254901960784315,"distribution pr, while being ﬂexible against the item frequency change. The detailed algorithms of
213"
ADAPTIVE META-TASK GENERATION,0.3741830065359477,"generating basic/adaptive meta-tasks are shown in supplement materials.
214"
EXPERIMENTS,0.3758169934640523,"4
Experiments
215"
BASIC SETUP,0.37745098039215685,"4.1
Basic Setup
216"
BASIC SETUP,0.3790849673202614,"Dataset. We use two real datasets. Word-query is a streaming record of search queries, where each
217"
BASIC SETUP,0.380718954248366,"query contains multiple words (e.g., “News today”) [15]. IP-trace consists of IP packets, where each
218"
BASIC SETUP,0.38235294117647056,"packet is identiﬁed by a unique source/destination address pair (e.g., 192.168.1.1/12.13.41.4) [21].
219"
BASIC SETUP,0.3839869281045752,"We assume that query phrases and IP addresses are numerically encoded, similar to [15].
220"
BASIC SETUP,0.38562091503267976,Table 1: Results of Basic Meta-sketch (Tr)
BASIC SETUP,0.3872549019607843,"Word-query
IP-trace"
BASIC SETUP,0.3888888888888889,"Method
Metrics
n=5K,
B=9KB"
BASIC SETUP,0.39052287581699346,"n=10K,
B=11KB"
BASIC SETUP,0.39215686274509803,"n=20K,
B=13KB"
BASIC SETUP,0.3937908496732026,"n=40K,
B=15KB"
BASIC SETUP,0.3954248366013072,"n=5K,
B=9KB"
BASIC SETUP,0.39705882352941174,"n=10K,
B=11KB"
BASIC SETUP,0.39869281045751637,"n=20K,
B=13KB"
BASIC SETUP,0.40032679738562094,"n=40K,
B=15KB"
BASIC SETUP,0.4019607843137255,"Basic MS
ARE
12.3
14.74
10.98
13.79
3.00
1.51
2.97
1.13
AAE
31.54
38.54
40.63
53.67
5.57
5.01
6.94
5.56"
BASIC SETUP,0.4035947712418301,"CS
ARE
32.94
57.97
98.01
162.43
6.08
9.94
15.57
24.49
AAE
57.54
101.44
172.44
282.59
10.42
16.82
26.46
41.91"
BASIC SETUP,0.40522875816993464,"CMS
ARE
21.34
48.33
111.82
239.11
8.12
16.07
32.77
65.19
AAE
38.04
84.62
195.61
416.01
13.67
27.39
55.29
110.65
Table 2: Results of Basic Meta-sketch (Ts)
Method
Metrics
n=5K,B=9KB
n=10K,B=11KB
n=20K,B=13KB
n=40K,B=15KB
0.5
1.1
1.5
0.5
1.1
1.5
0.5
1.1
1.5
0.5
1.1
1.5
Basic MS
(Word-query)"
BASIC SETUP,0.4068627450980392,"ARE
0.43
1.05
2.63
0.73
3.25
3.14
0.47
1.67
1.35
0.43
2.58
9.65
AAE
24.7
17.72
8.93
31.24
27.02
9.41
27.29
22.19
9.2
25.04
26.95
19.87
Basic MS
(IP-trace)"
BASIC SETUP,0.4084967320261438,"ARE
0.59
2.27
9.38
0.73
0.86
1.02
0.72
1.73
7.52
0.73
0.79
2.33
AAE
26.45
21.49
14.73
38.33
19.32
7.95
35.48
22.28
15.74
39.57
21.75
14.06"
BASIC SETUP,0.41013071895424835,"CS
ARE
1.98
6.72
10.99
2.7
12.12
16.9
3.73
20.8
27.46
5.17
37.96
43.76
AAE
74.96
47.98
15.89
102.05
75.83
23.8
140.65
118.29
38.7
194.32
198.4
59.96"
BASIC SETUP,0.4117647058823529,"CMS
ARE
4.96
7.52
5.47
9.27
15.85
9.44
17.29
32.7
16.38
32.24
66.35
27.89
AAE
187.52
53.81
8.17
350.08
99.82
13.58
651.63
185.54
22.88
1213.38
347.32
38.18"
BASIC SETUP,0.4133986928104575,"Baseline. We hereby evaluate the basic and advanced meta-sketches. From now on, we use MS to
221"
BASIC SETUP,0.4150326797385621,"represent the term meta-sketch for brevity. We compare basic MS (after the pre-training phase) with
222"
BASIC SETUP,0.4166666666666667,"CM-sketch (CMS) and C-sketch (CS). We compare the advanced MS (after the adaptation phase)
223"
BASIC SETUP,0.41830065359477125,"with learned augmented sketch (LS) and cold ﬁlter (CF), which are two variants of CM/C sketches
224"
BASIC SETUP,0.4199346405228758,"with auxiliary structures. According to the default setting [10,11], the number of hash functions for
225"
BASIC SETUP,0.4215686274509804,"all sketches is 3. We adopt two commonly accepted metrics for evaluating the accuracies of stream
226"
BASIC SETUP,0.42320261437908496,"frequency estimation, AAE and ARE3.
227"
BASIC SETUP,0.42483660130718953,"Parameters. We implement gemb or gadd in MLP with 2-layers of sizes 128 and 48, followed by
228"
BASIC SETUP,0.4264705882352941,"batch normalization, and gdec in an MLP with 3-layers of 256 with residual connections. We use
229"
BASIC SETUP,0.42810457516339867,"the relu function for layer connections. The space budget B is spent on storing M, the same as the
230"
BASIC SETUP,0.4297385620915033,"setting in neural data structures [23]. Other modules, like hashing libraries, are commonly accepted
231"
BASIC SETUP,0.43137254901960786,"as reusable and amortizable resources for multi-deployment of sketches [21,23]. Note that due to
232"
BASIC SETUP,0.43300653594771243,"space limitations, the details and methods of parameter settings of M(A), the ablation experiments
233"
BASIC SETUP,0.434640522875817,"and some parameter discussions are shown in the supporting material.
234"
BASIC META-SKETCH,0.4362745098039216,"4.2
Basic Meta-sketch
235"
BASIC META-SKETCH,0.43790849673202614,"Settings. For each dataset, we train the basic MSs under 4 item pools with {5K, 10K, 20K, 40K}
236"
BASIC META-SKETCH,0.4395424836601307,"different items, respectively. The meta-task sampler are with Zipf distributions. We build the
237"
BASIC META-SKETCH,0.4411764705882353,"distribution pools set with α ∈[0.8, 1.3] and set frequency mean range L = [50, 500]. For basic
238"
BASIC META-SKETCH,0.44281045751633985,"meta-sketch training, the default maximum number of training steps φ is 5 million, the learning rate
239"
BASIC META-SKETCH,0.4444444444444444,"is 0.0001, and the Adam optimizer is used. For evaluation, we consider two types of tasks, Tr and
240"
BASIC META-SKETCH,0.44607843137254904,"Ts. Tr are directly obtained by random sampling on two real data streams with different values of n,
241"
BASIC META-SKETCH,0.4477124183006536,"i.e., the number of distinct items. Note that the frequency distributions of Tr are not necessarily obey
242"
BASIC META-SKETCH,0.4493464052287582,"Zipf distributions. Ts are the synthetic tasks, where the item frequency follows the Zipf distribution
243"
BASIC META-SKETCH,0.45098039215686275,"with α ∈{0.5, 1.1, 1.5}. To evaluate the generability and stability of basic MS, both Ts(0.5) and
244"
BASIC META-SKETCH,0.4526143790849673,"Ts(1.5)’s distributions are not covered by the distribution pool of the meta-task samplers.
245"
BASIC META-SKETCH,0.4542483660130719,"Performance. Table 1 shows the performance of all competitors based on real dataset Tr. It shows
246"
BASIC META-SKETCH,0.45588235294117646,"that the basic MS outperforms traditional basic sketches, i.e., CMS and CS, on all testing cases. For
247"
BASIC META-SKETCH,0.45751633986928103,"example,the results on IP-trace show that, when n=40K and B=15KB, the ARE of basic MS is
248"
BASIC META-SKETCH,0.4591503267973856,"1.13, while AREs of CMS and CS are 65.19 and 24.49, respectively. The advantage of meta-sketch
249"
BASIC META-SKETCH,0.46078431372549017,"is signiﬁcant when testing on Ts with different αs, as shown in Table 2. Note that we use random
250"
BASIC META-SKETCH,0.4624183006535948,"choices to simulate the ideal hash functions for traditional sketches like [15], so that CS and CMS
251"
BASIC META-SKETCH,0.46405228758169936,"have the same result on test tasks with the same α in both datasets.
252"
BASIC META-SKETCH,0.46568627450980393,"We show the trend of ARE w.r.t. the space budget, in Figure 2 (Tr, n=5K, Word-query). Compared to
253"
BASIC META-SKETCH,0.4673202614379085,"the dramatic performance degrading of traditional sketches, basic MS holds stable performance. We
254"
BASIC META-SKETCH,0.46895424836601307,"show that the trend of ARE w.r.t. the number of distinct items in Figure 3 (Tr, B=9KB, Word-query).
255"
BASIC META-SKETCH,0.47058823529411764,"Compared to traditional sketches, the ARE of basic MS increases sub-linearly w.r.t. the value of n.
256"
BASIC META-SKETCH,0.4722222222222222,"Note that AAE has similar results for the above experiments, see the supplement materials.
257"
BASIC META-SKETCH,0.4738562091503268,"Generalization. We test the generality of basic MS to new items that are not in the item pool of
258"
BASIC META-SKETCH,0.47549019607843135,"the meta-task sampler in Figure 4(a). We make the experiments (n=5K, B=9KB, Word-query)
259"
BASIC META-SKETCH,0.477124183006536,"by replacing some items in Tr with new items, and vary the fraction of new items to observe
260"
BASIC META-SKETCH,0.47875816993464054,"the trend of the performance. It shows that the ARE/AAE moderately increases w.r.t. the ratio
261"
K,0.4803921568627451,"5k
9k
13k
17k
Space_budget 0 10 20 30 40 50 60 ARE"
K,0.4820261437908497,"Basic MS
CMS
CS"
K,0.48366013071895425,Figure 2: ARE w.r.t. B
K,0.4852941176470588,1000 2000 3000 4000 5000
K,0.4869281045751634,Item_size 0 5 10 15 20 25 30 ARE
K,0.48856209150326796,"Basic MS
CMS
CS"
K,0.49019607843137253,Figure 3: ARE w.r.t. n
K,0.4918300653594771,0% 20% 40% 60% 80%100%
K,0.4934640522875817,New_item_ratio 4 12 20 28 36 44
K,0.4950980392156863,Metrics
K,0.49673202614379086,"ARE
AAE"
K,0.49836601307189543,"5e+6
5e+5
5e+4
5e+3
5e+2"
K,0.5,True_mean
K,0.5016339869281046,"5e+6
5e+5
5e+4
5e+3
5e+2"
K,0.5032679738562091,Estimate
K,0.5049019607843137,"5e+6
5e+5
5e+4
5e+3
5e+2"
K,0.5065359477124183,True_mean
K,0.5081699346405228,"2
6
10
14
18 ARE"
K,0.5098039215686274,"(a) New Items
(b) New frequency means
Figure 4: Generality of Meta-sketch
Table 3: Results of Advanced Meta-sketch
Method
Metrics
Word-query
IP-trace
n=5K
B=9KB"
K,0.511437908496732,"n=10K,
B=11KB"
K,0.5130718954248366,"n=20K
B=13KB"
K,0.5147058823529411,"n=40K
B=15KB"
K,0.5163398692810458,"n=5K
B=9KB"
K,0.5179738562091504,"n=10K
B=11KB"
K,0.5196078431372549,"n=20K
B=13KB"
K,0.5212418300653595,"n=40K
B=15KB
Advanced
MS"
K,0.5228758169934641,"ARE
3.05
2.83
4.06
5.20
0.87
0.89
1.38
2.29
AAE
21.42
26.11
35.00
43.81
3.77
4.46
5.13
6.55"
K,0.5245098039215687,"CF90
ARE
3.58
14.53
141.70
1127.11
0.85
2.74
4.20
16.71
AAE
21.13
59.18
381.63
2217.28
1.32
3.01
7.71
31.20"
K,0.5261437908496732,"CF70
ARE
7.95
29.02
139.87
541.37
1.51
3.10
8.95
46.79
AAE
29.02
76.58
295.63
970.94
2.57
5.51
16.83
82.84"
K,0.5277777777777778,"CF40
ARE
91.16
138.64
244.24
407.83
12.62
33.50
103.76
155.61
AAE
174.86
252.22
421.85
693.47
24.16
60.79
175.14
279.72"
K,0.5294117647058824,"LCMS(1%)
ARE
20.52
48.69
111.85
266.50
8.34
17.09
35.22
77.79
AAE
37.80
81.93
194.15
451.28
13.72
28.39
59.10
129.86"
K,0.5310457516339869,"LCS(1%)
ARE
25.53
40.84
67.21
104.54
5.20
7.80
11.33
17.12
AAE
44.53
78.17
122.57
180.56
8.78
13.10
18.97
28.38"
K,0.5326797385620915,"of new items. The performance is acceptable considering the fact that the item domain is often
262"
K,0.5343137254901961,"stable in practical applications. We then test the generality of meta-sketches to varied frequency
263"
K,0.5359477124183006,"means that are not in range L of the meta-task sampler, as shown in Figure 4(b). The experiment
264"
K,0.5375816993464052,"(n=5K, B=9KB, Word-query) is done by sampling a series of Ts tasks with frequency means in
265"
K,0.5392156862745098,"{500, 5K, 50K, 500K, 5000K}. It shows that as the mean of the true frequencies increases, the
266"
K,0.5408496732026143,"estimated frequencies of the meta-sketch increase linearly, so that the ARE keeps stable.
267"
ADVANCED META-SKETCH,0.5424836601307189,"4.3
Advanced Meta-sketch
268"
ADVANCED META-SKETCH,0.5441176470588235,"Settings. The generation of adaptive meta-tasks is similar to that of basic meta-tasks (Section 3.2), ex-
269"
ADVANCED META-SKETCH,0.545751633986928,"cept that each item pool reads real frequency distributions for the adaption as described in Section 3.3.
270"
ADVANCED META-SKETCH,0.5473856209150327,"In the adaption phase, the maximum number of training steps is 0.002 ∗φ.
271"
ADVANCED META-SKETCH,0.5490196078431373,"Performance. Table 3 compares the performance of advanced MS with traditional sketches and their
272"
ADVANCED META-SKETCH,0.5506535947712419,"variants, LS and CF, on real dataset Tr. We implement two LSs according to [15], learned CM-sketch
273"
ADVANCED META-SKETCH,0.5522875816993464,"(LCMS) and learned C-sketch (LCS), following the default setting that (top 1%) high-frequency
274"
ADVANCED META-SKETCH,0.553921568627451,"items are separately stored. For CF, we follow the parameter setting in [14], and use CF40, CF70, and
275"
ADVANCED META-SKETCH,0.5555555555555556,"CF90 for setting the ﬁlter percentages to 40%, 70%, and 90% of the total size, respectively. It shows
276"
ADVANCED META-SKETCH,0.5571895424836601,"that the advanced MS achieves a better performance than LSs and CFs. Also, AAE/ARE of advanced
277"
ADVANCED META-SKETCH,0.5588235294117647,"MS increases more moderately w.r.t. the number of distinct items n, compared to its competitors.
278"
ADVANCED META-SKETCH,0.5604575163398693,"Furthermore, we compare the performance of the advanced MS and the LS under dynamic streaming
279"
ADVANCED META-SKETCH,0.5620915032679739,"scenarios, as shown in Figure 5. We select a set of Tr (n=5K,B=9KB,Word-query), and gradually
280"
ADVANCED META-SKETCH,0.5637254901960784,"shufﬂe the correspondence between items and frequencies. Here, the shufﬂe ratio is increased from 0
281"
ADVANCED META-SKETCH,0.565359477124183,"to 100%. It shows that the average ARE of advanced MS only slightly ﬂuctuates between 3.26 and
282"
ADVANCED META-SKETCH,0.5669934640522876,"4.0, and the average AAE is in the range of 21.28 and 21.68. In contrast, AAE of LCS or LCMS starts
283"
ADVANCED META-SKETCH,0.5686274509803921,"above 37, and increase signiﬁcantly w.r.t. the increase of the shufﬂe ratio. Actually, the classiﬁer of
284"
ADVANCED META-SKETCH,0.5702614379084967,"LS tends to incur more errors due to the gradual shift of high- and low-frequency items, resulting in
285"
ADVANCED META-SKETCH,0.5718954248366013,"an increased number of hash collisions, thus deteriorating the estimation accuracy.
286"
ANALYSIS,0.5735294117647058,"5
Analysis
287"
ANALYSIS,0.5751633986928104,"The meta-sketch is trained based on meta-tasks, consisting of various stream distributions. We
288"
ANALYSIS,0.576797385620915,"expected that the meta-sketch can learn the ability to sketch item frequencies. Somehow, it is
289"
ANALYSIS,0.5784313725490197,"unavoidable that the meta-sketch’s ability is limited by patterns of given meta-tasks. Thus, setting
290"
ANALYSIS,0.5800653594771242,"up the two training phases beneﬁts the balance of the trade-offs. In the pre-training phase, we select
291"
ANALYSIS,0.5816993464052288,"the most representative Zipf distribution to form basic meta-tasks, making the basic meta-sketch
292"
ANALYSIS,0.5833333333333334,"adaptable to a wide range of data streams. In the adaptation phase, we sample adaptive meta-tasks
293"
ANALYSIS,0.5849673202614379,"from raw data streams to make the advanced meta-sketch more specialized. Next, we analyze the
294"
ANALYSIS,0.5866013071895425,"0.0
0.2
0.4
0.6
0.8
1.0
Shuffle_ratio 5 15 25 35 45 ARE"
ANALYSIS,0.5882352941176471,"Advanced MS
LCMS
LCS"
ANALYSIS,0.5898692810457516,"0.0
0.2
0.4
0.6
0.8
1.0
Shuffle_ratio 20 30 40 50 60 70 AAE"
ANALYSIS,0.5915032679738562,"Advanced MS
LCMS
LCS"
ANALYSIS,0.5931372549019608,"(a) ARE
(b) AAE"
ANALYSIS,0.5947712418300654,Figure 5: Learned sketch vs. Meta-sketch
ANALYSIS,0.5964052287581699,"0
1
2
3
4
5
Train_step 1e5
0 10 20 30 40 50 60 Norm"
ANALYSIS,0.5980392156862745,"|r|
|z|"
ANALYSIS,0.5996732026143791,"0
1
2
3
4
5
Train_step"
ANALYSIS,0.6013071895424836,"1e5
1
3
5
7
9
11
13
15
17"
ANALYSIS,0.6029411764705882,Sparsity
ANALYSIS,0.6045751633986928,"(a) |r| and |z|
(b) Sparsity of a"
ANALYSIS,0.6062091503267973,Figure 6: |r| and |z| w.r.t. Sparsity of a
ANALYSIS,0.6078431372549019,1000 2000 3000 4000 5000
ANALYSIS,0.6094771241830066,Item_size 5 15 25 35 45 AAE
ANALYSIS,0.6111111111111112,"Advanced MS
K-means MS
Random MS"
ANALYSIS,0.6127450980392157,"Advanced
K-means
Random
Addressing_matrices 0 20 40 60 80 100"
ANALYSIS,0.6143790849673203,Standard_deviation
ANALYSIS,0.6160130718954249,"(a) AAE
(b) Standard deviations"
ANALYSIS,0.6176470588235294,Figure 7: Three addressing matrices
ANALYSIS,0.619281045751634,"0.0
0.5
1.0
1.5
2.0
2.5
Train_step 1e6
8 10 12 14 16 18 20 22"
ANALYSIS,0.6209150326797386,Sparsity
ANALYSIS,0.6225490196078431,"level1
level2
level3
level4"
ANALYSIS,0.6241830065359477,"0.0
0.5
1.0
1.5
2.0
2.5
Train_step 1e6
8 10 12 14 16 18 20 22"
ANALYSIS,0.6258169934640523,Sparsity
ANALYSIS,0.6274509803921569,"level1
level2
level3
level4"
ANALYSIS,0.6290849673202614,"0.0
0.5
1.0
1.5
2.0
2.5
Train_step 1e6
8 10 12 14 16 18 20 22"
ANALYSIS,0.630718954248366,Sparsity
ANALYSIS,0.6323529411764706,"level1
level2
level3
level4"
ANALYSIS,0.6339869281045751,"(a) Zipf
(b) Triangular
(c) Uniform"
ANALYSIS,0.6356209150326797,Figure 8: The sparsity of embedding vectors
ANALYSIS,0.6372549019607843,"working mechanism of the three modules of the meta-sketch as well as their roles in acquiring the
295"
ANALYSIS,0.6388888888888888,"two abilities.
296"
ANALYSIS,0.6405228758169934,"Sparse Addressing Module. We take a 2D slice A∗(size is lr × d2) of the A matrix to analyze
297"
ANALYSIS,0.6421568627450981,"the process of a reﬁned vector r getting addressing a through this module. First, we have a ←
298"
ANALYSIS,0.6437908496732027,"SparseMax(rT A∗) ⇒a ←SparseMax(⟨r · b1, r · b2, ..., r · bd2⟩). Since bi are unit vectors, we
299"
ANALYSIS,0.6454248366013072,"can get a ←SparseMax(|r|c), c=⟨cosθ1, cosθ2, ..., cosθd2⟩, where θi is the angle between r and
300"
ANALYSIS,0.6470588235294118,bi. We continue to transform the form to get addressing a ←Sparsegen(c; u; |r|−1
ANALYSIS,0.6486928104575164,"|r| ) [30], where u
301"
ANALYSIS,0.6503267973856209,"is a component-wise transformation function applied on c. in this paper, we set u(c)=c.
302"
ANALYSIS,0.6519607843137255,"Based on the principle of Sparsegen [30], |r| mainly affects the sparsity (i.e., the proportion of
303"
ANALYSIS,0.6535947712418301,"non-zero bits in the vector) of a during training process, while c determines the positions and values
304"
ANALYSIS,0.6552287581699346,"of non-sparse bits. The Figure 6 shows a strong correlation between the average |r| and the sparsity
305"
ANALYSIS,0.6568627450980392,"of a during training from scratch (n=5K, B=9KB, Word-query, Basic MS). Since the embedding
306"
ANALYSIS,0.6584967320261438,"vector z does not directly participate in the addressing process, the average |z| remains stable. Further,
307"
ANALYSIS,0.6601307189542484,"we observe that the sparsity of a will eventually converge to around 1, which means that each item
308"
ANALYSIS,0.6617647058823529,"is generally stored in a slot corresponding to the reﬁned vector r and the unit vector in A∗with the
309"
ANALYSIS,0.6633986928104575,"maximum cosine similarity.
310"
ANALYSIS,0.6650326797385621,"Therefore, the role of A∗is to map reﬁned vectors to the addressing vectors. The d2 unit vectors in
311"
ANALYSIS,0.6666666666666666,"A∗are the reference standard for mapping, which is equivalent to the mutually exclusive d2 -divisions
312"
ANALYSIS,0.6683006535947712,"of the reﬁned vector space. Follow this point, we construct two matrices K∗and R∗of the same size
313"
ANALYSIS,0.6699346405228758,"as A∗. Among them, the d2 unit vectors in K∗come from the cluster centers of the sampled reﬁned
314"
ANALYSIS,0.6715686274509803,"vectors. To achieve mutually exclusive division, we perform Kmeans clustering with K = d2 and
315"
ANALYSIS,0.673202614379085,"Cosine similarity criterion. Then, we normalize the resulting d2 cluster centers and stack them as K∗.
316"
ANALYSIS,0.6748366013071896,"In contrast, the unit vectors in R∗are entirely randomly generated.
317"
ANALYSIS,0.6764705882352942,"Figure 7 (a) shows the results of replacing A∗on the trained meta-sketch with K∗and R∗. The
318"
ANALYSIS,0.6781045751633987,"meta-sketch with R∗shows the worst performance, but the performance of the meta-sketch with K∗
319"
ANALYSIS,0.6797385620915033,"is close to the original A∗. Furthermore, We count the number of items mapped in every slot of A∗,
320"
ANALYSIS,0.6813725490196079,"K∗, R∗and show their standard deviation in Figure 7 (b). The standard deviation of R∗is much
321"
ANALYSIS,0.6830065359477124,"higher than A∗and K∗, and a better meta-sketch tends to store items more evenly in each slot. Thus,
322"
ANALYSIS,0.684640522875817,"The addressing module simulates the traditional sketch mechanism. Its principal function is to store
323"
ANALYSIS,0.6862745098039216,"the embedding vectors of items as evenly as possible in multiple memory slots, and an item is written
324"
ANALYSIS,0.6879084967320261,"to only one slot.
325"
ANALYSIS,0.6895424836601307,"Embedding Module. The major source of conﬂicts in the meta-sketch is the stacking of different
326"
ANALYSIS,0.6911764705882353,"embedding vectors in a single slot. Thus, the sparsity of the embedding vector becomes an important
327"
ANALYSIS,0.6928104575163399,"indicator to determine the degree of conﬂicts. Figure 8 shows the relation between the sparsity of
328"
ANALYSIS,0.6944444444444444,"embedding vectors and the stream distributions (n=5K, B=9KB, Word-query, advanced MS). We
329"
ANALYSIS,0.696078431372549,"select the meta-tasks under Zipf, Triangular, and Uniform distributions with different skewness levels
330"
ANALYSIS,0.6977124183006536,"(the deﬁnition of skewness and corresponding distribution parameters are shown in the supplement
331"
ANALYSIS,0.6993464052287581,"materials). The results show that the sparsity of the embedding vector is positively proportional to
332"
ANALYSIS,0.7009803921568627,1000 2000 3000 4000 5000
ANALYSIS,0.7026143790849673,Item_size
ANALYSIS,0.704248366013072,"8
12
16
20
24
28
32
36 AAE"
ANALYSIS,0.7058823529411765,"Advanced MS
MS(No frozen gdec)"
ANALYSIS,0.7075163398692811,MS(Frozen gdec)
ANALYSIS,0.7091503267973857,"5e+6
5e+5
5e+4
5e+3
5e+2"
ANALYSIS,0.7107843137254902,True_mean 1 2 3 4 5 6 ARE
ANALYSIS,0.7124183006535948,"Advanced MS
MS(No frozen gdec)"
ANALYSIS,0.7140522875816994,MS(Frozen gdec)
ANALYSIS,0.7156862745098039,"(a) Item size
(b) Frequency mean"
ANALYSIS,0.7173202614379085,Figure 9: Generality w.r.t. Decoding module
ANALYSIS,0.7189542483660131,"0
10
20
30
40
Unstable_memory_slot 0.00 0.25 0.50 0.75 1.00"
ANALYSIS,0.7205882352941176,"0
10
20
30
40
Stable_memory_slot 0.00 0.25 0.50 0.75 1.00"
ANALYSIS,0.7222222222222222,"0
20
40
60
80
100
Sort_of_frequency 8.0 8.5 9.0 9.5 10.0 10.5"
ANALYSIS,0.7238562091503268,Sparsity
ANALYSIS,0.7254901960784313,"Unstable
Stable"
ANALYSIS,0.7271241830065359,"(a) Multiple slots
(b) A single slot"
ANALYSIS,0.7287581699346405,Figure 10: Unstable case vs. Stable case
ANALYSIS,0.7303921568627451,"the skewness of a distribution. Therefore, we speculate that the meta-sketch memorizes the pattern
333"
ANALYSIS,0.7320261437908496,"information of the distribution being adapted by self-tuning the sparsity of embedding vectors.
334"
ANALYSIS,0.7336601307189542,"Decoding Module. The decoding module, as the deepest NNs in the meta-sketch, integrates various
335"
ANALYSIS,0.7352941176470589,"information to predict the item frequency and achieves generalization ability. To verify this, we adapt
336"
ANALYSIS,0.7369281045751634,"the advanced MS (n=5K, B=9KB, Word-query) to a special adaptive meta-task. The meta-task
337"
ANALYSIS,0.738562091503268,"was sampled from the real data stream but with a ﬁxed item size (5000) and frequency mean (250).
338"
ANALYSIS,0.7401960784313726,"Meanwhile, we do not change the correspondence between items and frequencies. Such meta-task
339"
ANALYSIS,0.7418300653594772,"forces the meta-sketch to pay more attention to the ﬁxed patterns and thus limit its generalization.
340"
ANALYSIS,0.7434640522875817,"Thus, we train the advanced MS with (or without) freezing the decoding module parameters based
341"
ANALYSIS,0.7450980392156863,"on the above meta-task. Figure 9 (a) shows the performance changes of the three models (advanced
342"
ANALYSIS,0.7467320261437909,"MS as baseline) on the evaluation tasks (Tr) of different item sizes. Without the frozen decoding
343"
ANALYSIS,0.7483660130718954,"module, the meta-sketch loses generalization ability at extended item sizes other than 5000. On the
344"
ANALYSIS,0.75,"contrary, the meta-sketch with the frozen decoding module still retains the generalization ability and
345"
ANALYSIS,0.7516339869281046,"further utilizes the data stream pattern compared to the advanced MS, achieving the best performance.
346"
ANALYSIS,0.7532679738562091,"Similarly, as shown in Figure 9 (b), the meta-sketch without the frozen decoding module also loses a
347"
ANALYSIS,0.7549019607843137,"certain generalization ability in terms of frequency mean.
348"
ANALYSIS,0.7565359477124183,"Actually, the above meta-task (termed as the stable case) can be viewed as a special case of an ordinary
349"
ANALYSIS,0.7581699346405228,"adaptive meta-task (termed as the unstable case). As a matter of fact, augmented sketches utilize
350"
ANALYSIS,0.7598039215686274,"frequency patterns similar to the stable case. For example, the learned augmented sketch memorizes
351"
ANALYSIS,0.761437908496732,"(relatively) stable correspondence between items and frequencies, for ﬁltering high-frequency items.
352"
ANALYSIS,0.7630718954248366,"To understand the meta-sketch’s self-optimizing mechanism from the unstable case to the stable case,
353"
ANALYSIS,0.7647058823529411,"we analyze the storage of high/low-frequency items between multiple slots and a single slot in the
354"
ANALYSIS,0.7663398692810458,"memory. In Figure 10 (a), we show density heat-maps of low-frequency (below the top 20% high
355"
ANALYSIS,0.7679738562091504,"frequencies) items, stored by meta-sketches of stable and unstable cases on a 2D slice (d1=2) of the
356"
ANALYSIS,0.7696078431372549,"storage matrix M, where the x-axis is the index of slots. The two heat-maps show that the meta-sketch
357"
ANALYSIS,0.7712418300653595,"under the stable case can store the low-frequency items concentratedly in some slots to avoid the
358"
ANALYSIS,0.7728758169934641,"conﬂicts with high-frequency items. Interestingly, the meta-sketch does not intentionally do this like
359"
ANALYSIS,0.7745098039215687,"augmented sketches. Instead, it is achieved by self-optimization during the training. Furthermore,
360"
ANALYSIS,0.7761437908496732,"Figure 10 (b) shows the relation between the sparsity of the embedding vector of items stored in a
361"
ANALYSIS,0.7777777777777778,"single slot and the frequency order, where the x-axis represents the frequencies in the ascending order.
362"
ANALYSIS,0.7794117647058824,"We speculate that the meta-sketch autonomously adjusts the sparsity of the embedding vector within
363"
ANALYSIS,0.7810457516339869,"a single slot in the stable case, so that the high/low-frequency items are automatically separated.
364"
CONCLUSION,0.7826797385620915,"6
Conclusion
365"
CONCLUSION,0.7843137254901961,"In this paper, we propose a neural data structure, called the meta-sketch, for estimating item fre-
366"
CONCLUSION,0.7859477124183006,"quencies in data streams. Unlike traditional sketches, the meta-sketch utilizes meta-learning and
367"
CONCLUSION,0.7875816993464052,"memory-augmented neural networks. The meta-sketch is pre-trained with Zipf distributions and can
368"
CONCLUSION,0.7892156862745098,"be fast adapted to speciﬁc runtime streams. We study a series of techniques for constructing the
369"
CONCLUSION,0.7908496732026143,"meta-sketch. We also devise the generation of basic and adaptive meta-tasks corresponding to the
370"
CONCLUSION,0.7924836601307189,"pre-training and adaption phases, respectively. Extensive empirical studies on real datasets are done
371"
CONCLUSION,0.7941176470588235,"to evaluate our proposals. In the future, it is interesting to extend our proposal to other sketching
372"
CONCLUSION,0.795751633986928,"tasks that are supported by traditional sketches.
373"
REFERENCES,0.7973856209150327,"References
374"
REFERENCES,0.7990196078431373,"[1] Tobias Weller. Compromised account detection based on clickstream data. In WWW, pages
375"
REFERENCES,0.8006535947712419,"819–823, 2018.
376"
REFERENCES,0.8022875816993464,"[2] Yunyue Zhu and Dennis E. Shasha. Statstream: Statistical monitoring of thousands of data
377"
REFERENCES,0.803921568627451,"streams in real time. In VLDB, pages 358–369, 2002.
378"
REFERENCES,0.8055555555555556,"[3] Ramine Tinati, Xin Wang, Ian C. Brown, Thanassis Tiropanis, and Wendy Hall. A streaming
379"
REFERENCES,0.8071895424836601,"real-time web observatory architecture for monitoring the health of social machines. In WWW,
380"
REFERENCES,0.8088235294117647,"pages 1149–1154, 2015.
381"
REFERENCES,0.8104575163398693,"[4] Mohammad Tanvir Irfan and Tucker Gordon. The power of context in networks: Ideal point
382"
REFERENCES,0.8120915032679739,"models with social interactions. In IJCAI, pages 6176–6180, 2019.
383"
REFERENCES,0.8137254901960784,"[5] Qun Huang, Patrick P. C. Lee, and Yungang Bao. Sketchlearn: relieving user burdens in
384"
REFERENCES,0.815359477124183,"approximate measurement with automated statistical inference. In SIGCOMM, pages 576–590,
385"
REFERENCES,0.8169934640522876,"2018.
386"
REFERENCES,0.8186274509803921,"[6] Samuel Madden and Michael J. Franklin. Fjording the stream: An architecture for queries over
387"
REFERENCES,0.8202614379084967,"streaming sensor data. In ICDE, pages 555–566, 2002.
388"
REFERENCES,0.8218954248366013,"[7] Lu Wang, Ge Luo, Ke Yi, and Graham Cormode. Quantiles over data streams: an experimental
389"
REFERENCES,0.8235294117647058,"study. In SIGMOD, 2013.
390"
REFERENCES,0.8251633986928104,"[8] Amit Goyal, Hal Daumé III, and Graham Cormode. Sketch algorithms for estimating point
391"
REFERENCES,0.826797385620915,"queries in NLP. In EMNLP-CoNLL 2012, July 12-14, 2012, Jeju Island, Korea, pages 1093–
392"
REFERENCES,0.8284313725490197,"1103. ACL, 2012.
393"
REFERENCES,0.8300653594771242,"[9] Fabon Dzogang, Thomas Lansdall-Welfare, Saatviga Sudhahar, and Nello Cristianini. Scalable
394"
REFERENCES,0.8316993464052288,"preference learning from data streams. In WWW 2015, Florence, Italy, May 18-22, 2015 -
395"
REFERENCES,0.8333333333333334,"Companion Volume, pages 885–890. ACM, 2015.
396"
REFERENCES,0.8349673202614379,"[10] Graham Cormode and S. Muthukrishnan. An improved data stream summary: the count-min
397"
REFERENCES,0.8366013071895425,"sketch and its applications. J. Algorithms, 55(1):58–75, 2005.
398"
REFERENCES,0.8382352941176471,"[11] Moses Charikar, Kevin C. Chen, and Martin Farach-Colton. Finding frequent items in data
399"
REFERENCES,0.8398692810457516,"streams. In ICALP, pages 693–703, 2002.
400"
REFERENCES,0.8415032679738562,"[12] Cristian Estan and George Varghese. New directions in trafﬁc measurement and accounting. In
401"
REFERENCES,0.8431372549019608,"SIGCOMM, pages 323–336, 2002.
402"
REFERENCES,0.8447712418300654,"[13] Pratanu Roy, Arijit Khan, and Gustavo Alonso. Augmented sketch: Faster and more accurate
403"
REFERENCES,0.8464052287581699,"stream processing. In SIGMOD, pages 1449–1463, 2016.
404"
REFERENCES,0.8480392156862745,"[14] Yang Zhou, Tong Yang, Jie Jiang, Bin Cui, Minlan Yu, Xiaoming Li, and Steve Uhlig. Cold
405"
REFERENCES,0.8496732026143791,"ﬁlter: A meta-framework for faster and more accurate stream processing. In SIGMOD, pages
406"
REFERENCES,0.8513071895424836,"741–756, 2018.
407"
REFERENCES,0.8529411764705882,"[15] Chen-Yu Hsu, Piotr Indyk, Dina Katabi, and Ali Vakilian. Learning-based frequency estimation
408"
REFERENCES,0.8545751633986928,"algorithms. In ICLR, 2019.
409"
REFERENCES,0.8562091503267973,"[16] Taiwo Kolajo, Olawande J. Daramola, and Ayodele Ariyo Adebiyi. Big data stream analysis: a
410"
REFERENCES,0.8578431372549019,"systematic literature review. J. Big Data, 6:47, 2019.
411"
REFERENCES,0.8594771241830066,"[17] Xue-Qiang Zeng and Guo-Zheng Li. Incremental partial least squares analysis of big streaming
412"
REFERENCES,0.8611111111111112,"data. Pattern Recognition, 47(11):3726–3735, 2014.
413"
REFERENCES,0.8627450980392157,"[18] Brian Babcock, Shivnath Babu, Mayur Datar, Rajeev Motwani, and Jennifer Widom. Models
414"
REFERENCES,0.8643790849673203,"and issues in data stream systems. In PODS, pages 1–16, 2002.
415"
REFERENCES,0.8660130718954249,"[19] Graham Cormode, Minos N. Garofalakis, Peter J. Haas, and Chris Jermaine. Synopses for
416"
REFERENCES,0.8676470588235294,"massive data: Samples, histograms, wavelets, sketches. Found. Trends Databases, 4(1-3):1–294,
417"
REFERENCES,0.869281045751634,"2012.
418"
REFERENCES,0.8709150326797386,"[20] M. S. B. PhridviRaja and C. V. GuruRao. Data mining : past present and future - a typical
419"
REFERENCES,0.8725490196078431,"survey on data streams. CoRR, abs/1605.01429, 2016.
420"
REFERENCES,0.8741830065359477,"[21] Lu Tang, Qun Huang, and Patrick P. C. Lee. Mv-sketch: A fast and compact invertible sketch
421"
REFERENCES,0.8758169934640523,"for heavy ﬂow detection in network data streams. In INFOCOM, pages 2026–2034. IEEE, 2019.
422"
REFERENCES,0.8774509803921569,"[22] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned
423"
REFERENCES,0.8790849673202614,"index structures. In SIGMOD, pages 489–504, 2018.
424"
REFERENCES,0.880718954248366,"[23] Jack Rae, Sergey Bartunov, and Timothy Lillicrap. Meta-learning neural bloom ﬁlters. In ICML,
425"
REFERENCES,0.8823529411764706,"pages 5271–5280. PMLR, 2019.
426"
REFERENCES,0.8839869281045751,"[24] Michael Mitzenmacher. A model for learned bloom ﬁlters and related structures. arXiv preprint
427"
REFERENCES,0.8856209150326797,"arXiv:1802.00884, 2018.
428"
REFERENCES,0.8872549019607843,"[25] Timothy M. Hospedales, Antreas Antoniou, Paul Micaelli, and Amos J. Storkey. Meta-learning
429"
REFERENCES,0.8888888888888888,"in neural networks: A survey. CoRR, abs/2004.05439, 2020.
430"
REFERENCES,0.8905228758169934,"[26] Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap.
431"
REFERENCES,0.8921568627450981,"Meta-learning with memory-augmented neural networks. In ICML, pages 1842–1850. PMLR,
432"
REFERENCES,0.8937908496732027,"2016.
433"
REFERENCES,0.8954248366013072,"[27] Alex Graves, Greg Wayne, and Ivo Danihelka.
Neural turing machines.
arXiv preprint
434"
REFERENCES,0.8970588235294118,"arXiv:1410.5401, 2014.
435"
REFERENCES,0.8986928104575164,"[28] Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-
436"
REFERENCES,0.9003267973856209,"Barwi´nska, Sergio Gómez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou,
437"
REFERENCES,0.9019607843137255,"et al. Hybrid computing using a neural network with dynamic external memory. Nature,
438"
REFERENCES,0.9035947712418301,"538(7626):471–476, 2016.
439"
REFERENCES,0.9052287581699346,"[29] Andre Martins and Ramon Astudillo. From softmax to sparsemax: A sparse model of attention
440"
REFERENCES,0.9068627450980392,"and multi-label classiﬁcation. In ICML, pages 1614–1623. PMLR, 2016.
441"
REFERENCES,0.9084967320261438,"[30] Anirban Laha, Saneem Ahmed Chemmengath, Priyanka Agrawal, Mitesh Khapra, Karthik
442"
REFERENCES,0.9101307189542484,"Sankaranarayanan, and Harish G Ramaswamy. On controllable sparse alternatives to softmax.
443"
REFERENCES,0.9117647058823529,"NIPS, 31, 2018.
444"
REFERENCES,0.9133986928104575,"[31] Oriol Vinyals, Charles Blundell, Tim Lillicrap, Koray Kavukcuoglu, and Daan Wierstra. Match-
445"
REFERENCES,0.9150326797385621,"ing networks for one shot learning. In Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg,
446"
REFERENCES,0.9166666666666666,"Isabelle Guyon, and Roman Garnett, editors, NIPS, pages 3630–3638, 2016.
447"
REFERENCES,0.9183006535947712,"[32] Alex Kendall, Yarin Gal, and Roberto Cipolla. Multi-task learning using uncertainty to weigh
448"
REFERENCES,0.9199346405228758,"losses for scene geometry and semantics. In CVPR, pages 7482–7491, 2018.
449"
REFERENCES,0.9215686274509803,"[33] Lada A. Adamic. Zipf, power-laws, and pareto- a ranking tutorial.
450"
CHECKLIST,0.923202614379085,"7
Checklist
451"
CHECKLIST,0.9248366013071896,"1. For all authors...
452"
CHECKLIST,0.9264705882352942,"(a) Do the main claims made in the abstract and introduction accurately reﬂect the paper’s
453"
CHECKLIST,0.9281045751633987,"contributions and scope? [Yes]
454"
CHECKLIST,0.9297385620915033,"(b) Did you describe the limitations of your work? [Yes] Compared with traditional data
455"
CHECKLIST,0.9313725490196079,"structures,neural data structures are usually relative weak in term of time latency. In
456"
CHECKLIST,0.9330065359477124,"future research, We need to study and reduce time cost of meta-sketches’ operation or
457"
CHECKLIST,0.934640522875817,"disign a framework to get a huge throughput utilizing parallel algebraic operations as a
458"
CHECKLIST,0.9362745098039216,"remedy.
459"
CHECKLIST,0.9379084967320261,"(c) Did you discuss any potential negative societal impacts of your work? [N/A] There is
460"
CHECKLIST,0.9395424836601307,"no negative societal impacts of my work, since it is foundational research.
461"
CHECKLIST,0.9411764705882353,"(d) Have you read the ethics review guidelines and ensured that your paper conforms to
462"
CHECKLIST,0.9428104575163399,"them? [Yes]
463"
CHECKLIST,0.9444444444444444,"2. If you are including theoretical results...
464"
CHECKLIST,0.946078431372549,"(a) Did you state the full set of assumptions of all theoretical results? [N/A]
465"
CHECKLIST,0.9477124183006536,"(b) Did you include complete proofs of all theoretical results? [N/A]
466"
CHECKLIST,0.9493464052287581,"3. If you ran experiments...
467"
CHECKLIST,0.9509803921568627,"(a) Did you include the code, data, and instructions needed to reproduce the main experi-
468"
CHECKLIST,0.9526143790849673,"mental results (either in the supplemental material or as a URL)? [Yes]
469"
CHECKLIST,0.954248366013072,"(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they
470"
CHECKLIST,0.9558823529411765,"were chosen)? [Yes] We give the details of the implementation as much as possible,but
471"
CHECKLIST,0.9575163398692811,"some of them will put into appendix.
472"
CHECKLIST,0.9591503267973857,"(c) Did you report error bars (e.g., with respect to the random seed after running exper-
473"
CHECKLIST,0.9607843137254902,"iments multiple times)? [Yes] We visualize the difference in line graphs by drawing
474"
CHECKLIST,0.9624183006535948,"shadows, which includes various of comparative experiments with all type of meta-
475"
CHECKLIST,0.9640522875816994,"sketches. But due to the huge amount of data ,error bars of table are not included. See
476"
CHECKLIST,0.9656862745098039,"section 4 and 5.
477"
CHECKLIST,0.9673202614379085,"(d) Did you include the total amount of compute and the type of resources used (e.g.,
478"
CHECKLIST,0.9689542483660131,"type of GPUs, internal cluster, or cloud provider)? [Yes] All of our experiments are
479"
CHECKLIST,0.9705882352941176,"implemented in python and run at a NVIDIA DGX workstation with CPU E5-2698
480"
CHECKLIST,0.9722222222222222,"(2.20GHz, 20 cores), and 4 NVIDIA V100 GPUs (5120 CUDA cores and 16GB GPU
481"
CHECKLIST,0.9738562091503268,"memory on each GPU).
482"
CHECKLIST,0.9754901960784313,"4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
483"
CHECKLIST,0.9771241830065359,"(a) If your work uses existing assets, did you cite the creators? [Yes]
484"
CHECKLIST,0.9787581699346405,"(b) Did you mention the license of the assets? [N/A]
485"
CHECKLIST,0.9803921568627451,"(c) Did you include any new assets either in the supplemental material or as a URL? [N/A]
486 487"
CHECKLIST,0.9820261437908496,"(d) Did you discuss whether and how consent was obtained from people whose data you’re
488"
CHECKLIST,0.9836601307189542,"using/curating? [N/A]
489"
CHECKLIST,0.9852941176470589,"(e) Did you discuss whether the data you are using/curating contains personally identiﬁable
490"
CHECKLIST,0.9869281045751634,"information or offensive content? [N/A]
491"
CHECKLIST,0.988562091503268,"5. If you used crowdsourcing or conducted research with human subjects...
492"
CHECKLIST,0.9901960784313726,"(a) Did you include the full text of instructions given to participants and screenshots, if
493"
CHECKLIST,0.9918300653594772,"applicable? [N/A]
494"
CHECKLIST,0.9934640522875817,"(b) Did you describe any potential participant risks, with links to Institutional Review
495"
CHECKLIST,0.9950980392156863,"Board (IRB) approvals, if applicable? [N/A]
496"
CHECKLIST,0.9967320261437909,"(c) Did you include the estimated hourly wage paid to participants and the total amount
497"
CHECKLIST,0.9983660130718954,"spent on participant compensation? [N/A]
498"
