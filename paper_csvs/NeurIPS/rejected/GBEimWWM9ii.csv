Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.001736111111111111,"Recent state-of-the-art anomaly detection algorithms mainly adopt generative mod-
1"
ABSTRACT,0.003472222222222222,"els or approaches based on deep one-class classification. These approaches have
2"
ABSTRACT,0.005208333333333333,"hyperparameters to balance the adversarial framework of the generative adversarial
3"
ABSTRACT,0.006944444444444444,"network and to determine the decision boundary of the classifier. Both methods
4"
ABSTRACT,0.008680555555555556,"show good performance, but their performance suffers from hyperparameter sen-
5"
ABSTRACT,0.010416666666666666,"sitivity. A new category of anomaly detection methods has been proposed that
6"
ABSTRACT,0.012152777777777778,"utilizes prior knowledge about abnormal data or pretrained features, but it is more
7"
ABSTRACT,0.013888888888888888,"generic not to use such side information. In this study, we propose “Multi-Level
8"
ABSTRACT,0.015625,"Masking and Restoration with Refinement (MMRR)”, an unsupervised-learning-
9"
ABSTRACT,0.017361111111111112,"based anomaly detection method based on a generative model that overcomes
10"
ABSTRACT,0.019097222222222224,"hyperparameter sensitivity and the need for side information. MMRR learns the
11"
ABSTRACT,0.020833333333333332,"salient features of normal data distributions through restoration from restricted
12"
ABSTRACT,0.022569444444444444,"information via masking, resulting in a better restoration of in-distribution data than
13"
ABSTRACT,0.024305555555555556,"out-of-distribution data. To overcome hyperparameter sensitivity, we ensemble
14"
ABSTRACT,0.026041666666666668,"restoration results from information restricted to predefined multiple levels instead
15"
ABSTRACT,0.027777777777777776,"of finding a single optimal restriction level, and propose a novel mask generation
16"
ABSTRACT,0.029513888888888888,"and refinement method to achieve hyperparameter robustness. Extensive exper-
17"
ABSTRACT,0.03125,"imental evaluation on common benchmarks (i.e., MNIST, FMNIST, CIFAR10,
18"
ABSTRACT,0.03298611111111111,"MVTecAD) demonstrates the efficacy of the MMRR.
19"
INTRODUCTION,0.034722222222222224,"1
Introduction
20"
INTRODUCTION,0.036458333333333336,"Anomaly detection tackles the problem of detecting abnormal data with a distribution that is signifi-
21"
INTRODUCTION,0.03819444444444445,"cantly different from normal data. It is an important task that enables machine learning algorithms
22"
INTRODUCTION,0.03993055555555555,"to cope with unexpected distribution in real-word tasks such as self-driving or medical imaging.
23"
INTRODUCTION,0.041666666666666664,"Anomaly detection problems are formulated assuming the unavailability of abnormal data during the
24"
INTRODUCTION,0.043402777777777776,"training process; therefore, anomaly detection models cannot be trained for the original purpose of
25"
INTRODUCTION,0.04513888888888889,"anomaly detection. With same context, it is impossible to validate in advance whether a proposed
26"
INTRODUCTION,0.046875,"model performs anomaly detection well during the training process. This means that even if the
27"
INTRODUCTION,0.04861111111111111,"anomaly detection ability of the model is significantly affected by the hyperparameter values, it is
28"
INTRODUCTION,0.050347222222222224,"impossible to find the optimal hyperparameter value through validation. Therefore, a method with a
29"
INTRODUCTION,0.052083333333333336,"robust anomaly detection performance is necessary that does not include hyperparameters that have a
30"
INTRODUCTION,0.05381944444444445,"significant influence on anomaly detection performance.
31"
INTRODUCTION,0.05555555555555555,"Three deep-learning-based leading strategies have been proposed to solve anomaly detection. The
32"
INTRODUCTION,0.057291666666666664,"first is using methods based on generative model which perform anomaly detection based on the
33"
INTRODUCTION,0.059027777777777776,"efficiency of the proposed generative models in restoring data. Early generative-model-based methods
34"
INTRODUCTION,0.06076388888888889,"failed in the anomaly detection task owing to the good generalization capability of the autoencoder
35"
INTRODUCTION,0.0625,"[37, 2]. Furthermore, to solve this problem, many studies [39, 36, 1, 8, 30, 31] inspired by generative
36"
INTRODUCTION,0.0642361111111111,"adversarial networks (GANs) [15] have attempted to create autoencoders that can only restore normal
37"
INTRODUCTION,0.06597222222222222,"data by limiting the generalization capability using an adversarial concept. The second leading
38"
INTRODUCTION,0.06770833333333333,"strategy is using deep one class classification methods [20, 35, 16, 21], which try to find the smallest
39"
INTRODUCTION,0.06944444444444445,"hypersphere surrounding only normal data in unsupervised manner. However, generative model-based
40"
INTRODUCTION,0.07118055555555555,"methods that try to restore only normal data well and deep one class classification methods that
41"
INTRODUCTION,0.07291666666666667,"try to find hypersphere surrounding only normal data have hyperparameters that have a significant
42"
INTRODUCTION,0.07465277777777778,"impact on anomaly detection performance. We define hyperparameter sensitivity problem as having
43"
INTRODUCTION,0.0763888888888889,"hyperparameters that significantly affect performance even in the nature of the anomaly detection
44"
INTRODUCTION,0.078125,"field where abnormal data is not available.
45"
INTRODUCTION,0.0798611111111111,"The third leading strategy is using side-information-based methods, which utilize prior knowledge
46"
INTRODUCTION,0.08159722222222222,"about the difference between normal data and abnormal data [17, 13, 12, 18, 3, 41, 45, 25, 47] or
47"
INTRODUCTION,0.08333333333333333,"utilize features [4, 28, 38, 5, 33] obtained from pretrained networks. Side-information based methods
48"
INTRODUCTION,0.08506944444444445,"have shown good performance on many benchmark datasets, but it is not common to know side
49"
INTRODUCTION,0.08680555555555555,"informations that can help distinguish normal data from abnormal data. In addition, these methods
50"
INTRODUCTION,0.08854166666666667,"suffer from massive performace degradation in a setting where used side information is not applied
51"
INTRODUCTION,0.09027777777777778,"well.
52"
INTRODUCTION,0.0920138888888889,"In this paper, we propose a novel method, Multi-Level Masking and Restoration with Refinement
53"
INTRODUCTION,0.09375,"(MMRR) that does not use side information, is based on a generative model, and avoids the hyperpa-
54"
INTRODUCTION,0.0954861111111111,"rameter sensitivity problem. The motivation behind our proposed method is that a network trained
55"
INTRODUCTION,0.09722222222222222,"to restore normal data from limited information about normal data will learn the salient features of
56"
INTRODUCTION,0.09895833333333333,"normal data. So that restoration from limited information succeeds for normal data and fails for
57"
INTRODUCTION,0.10069444444444445,"abnormal data, which makes it possible to perform anomaly detection in terms of restoration. To this
58"
INTRODUCTION,0.10243055555555555,"end, our method consists of the following two key components. First, masking, which is a process
59"
INTRODUCTION,0.10416666666666667,"that uses a mask to obtain restricted information by restricting the remaining information except for
60"
INTRODUCTION,0.10590277777777778,"the parts essential for restoration. Second, restoration, which is the process of restoring original data
61"
INTRODUCTION,0.1076388888888889,"by using only the restricted information obtained through masking.
62"
INTRODUCTION,0.109375,"For MMRR to perform anomaly detection, it is necessary to find the optimal masking level that
63"
INTRODUCTION,0.1111111111111111,"causes normal data to be restored successfully and restoration of abnormal data to fail: masking level
64"
INTRODUCTION,0.11284722222222222,"is the degree to which the mask limits information. However, to avoid the hyperparameter sensitivity
65"
INTRODUCTION,0.11458333333333333,"problem caused by the absence of abnormal data during training, we detected anomalies through
66"
INTRODUCTION,0.11631944444444445,"ensembles at multiple masking levels rather than finding a single optimal masking level. Our novel
67"
INTRODUCTION,0.11805555555555555,"mask generation method made it possible to ensemble at multiple masking levels by enabling the
68"
INTRODUCTION,0.11979166666666667,"manual control of the masking level of the mask, which eliminated the need for adversarial loss. In
69"
INTRODUCTION,0.12152777777777778,"addition, our mask generation method made the mask learnable such that the mask most helpful for
70"
INTRODUCTION,0.1232638888888889,"restoration at the corresponding masking level was generated, which led to better anomaly detection
71"
INTRODUCTION,0.125,"performance.
72"
INTRODUCTION,0.1267361111111111,"However, our masking method compares the degree of restoration at the same masking level without
73"
INTRODUCTION,0.1284722222222222,"considering the complexity of each data. Therefore, masking and restoration alone often restores
74"
INTRODUCTION,0.13020833333333334,"simple abnormal data better compared with complex normal data, in which case anomaly detection
75"
INTRODUCTION,0.13194444444444445,"fails. To solve this problem, we propose an additional refinement process that eliminates the difference
76"
INTRODUCTION,0.13368055555555555,"in restoration caused by the difference in data complexity. Our contributions are as follows:
77"
INTRODUCTION,0.13541666666666666,"• Hyperparameter robustness and Prior knowledge-free. We resolve the hyperparameter sensi-
78"
INTRODUCTION,0.1371527777777778,"tivity problem that previous studies had overlooked with the proposed Multi-Level Masking and
79"
INTRODUCTION,0.1388888888888889,"Restoration. Also, we have empirically shown through experiments that Multi-Level Masking is
80"
INTRODUCTION,0.140625,"robust to hyperparameters. Furthermore, our method doesn’t need any prior knowledge.
81"
INTRODUCTION,0.1423611111111111,"• Experiments on benchmark datasets. Unlike existing studies, MMRR does not strive to obtain
82"
INTRODUCTION,0.1440972222222222,"optimal anomaly detection by solving the hyperparameter sensitivity problem. Nevertheless,
83"
INTRODUCTION,0.14583333333333334,"we introduced Refinement Network considering the intrinsic complexity of data, and obtained
84"
INTRODUCTION,0.14756944444444445,"comparable performance to SOTA approaches.
85"
RELATED WORKS,0.14930555555555555,"2
Related Works
86"
RELATED WORKS,0.15104166666666666,"Classical methods proposed to solve anomaly detection include PCA [19], OC-SVM [40], SVDD
87"
RELATED WORKS,0.1527777777777778,"[42], iForest [26], and KDE [7]. Most of them perform anomaly detection using hand-crafted simple
88"
RELATED WORKS,0.1545138888888889,"functions. However, advancements in deep learning have made it easier to obtain richer and more
89"
RELATED WORKS,0.15625,"complex features of data, and thus many deep-learning-based anomaly detection studies have been
90"
RELATED WORKS,0.1579861111111111,"conducted. The following three strategies are widely used deep-learning-based anomaly detection
91"
RELATED WORKS,0.1597222222222222,"tequniques.
92"
RELATED WORKS,0.16145833333333334,"Generative-model-based methods.
Methods based on generative model begin with the assumption
93"
RELATED WORKS,0.16319444444444445,"that the generative model trained only with normal data will fail to restore abnormal data. However,
94"
RELATED WORKS,0.16493055555555555,"Sakurada and Yairi [37] and An and Cho [2] have demonstrated that a, simple autoencoder and
95"
RELATED WORKS,0.16666666666666666,"variational autoencoder sufficiently restore abnormal data, thereby leading to the failure of anomaly
96"
RELATED WORKS,0.1684027777777778,"detection. Therefore, various autoencoders for anomaly detection have been proposed that perform
97"
RELATED WORKS,0.1701388888888889,"certain tasks, such as denoising [36] and inpainting [48]. Also, there are studies that [8, 23] used
98"
RELATED WORKS,0.171875,"backpropagation to measure the distance from the manifold of the data. Many generative-model-based
99"
RELATED WORKS,0.1736111111111111,"methods are inspired by GAN and adversarial training. Some previous studies assumed networks that
100"
RELATED WORKS,0.1753472222222222,"learned normal distribution through adversarial training would not be able to restore abnormal data
101"
RELATED WORKS,0.17708333333333334,"or classify them as fake data [39, 1]. Some studies have highlighted that autoencoders have good
102"
RELATED WORKS,0.17881944444444445,"generalization capabilities and tried to design autoencoders that have limited resotraion capability by
103"
RELATED WORKS,0.18055555555555555,"limiting the latent space through adversarial loss [30, 31], or by prototyping the latent space [14, 20].
104"
RELATED WORKS,0.18229166666666666,"However, most generative-model-based methods suffer from the hyperparameter sensitivity problem
105"
RELATED WORKS,0.1840277777777778,"because they have to find the optimal point that balances adversarial losses and other losses to obtain
106"
RELATED WORKS,0.1857638888888889,"the best anomaly detection performance, which is impossible because of the absence of abnormal
107"
RELATED WORKS,0.1875,"data.
108"
RELATED WORKS,0.1892361111111111,"Deep one-class classification methods.
Since anomaly detection cannot use abnormal data for
109"
RELATED WORKS,0.1909722222222222,"training, it is difficult to design a classifier that distinguishes between normal data and abnormal data.
110"
RELATED WORKS,0.19270833333333334,"Ruff et al. [35] proposed a deep learning solution called SVDD [42] that seeks to find the smallest
111"
RELATED WORKS,0.19444444444444445,"hypersphere surrounding normal data. They used various constraints to prevent representation
112"
RELATED WORKS,0.19618055555555555,"collapse due to the absence of abnormal data during the training process. Hu et al. [21] proposed
113"
RELATED WORKS,0.19791666666666666,"a constraint called holistic regularization to prevent representation collapse. Some studies have
114"
RELATED WORKS,0.1996527777777778,"artificially generated abnormal data for training one-class classifiers. Goyal et al. [16] obtained,
115"
RELATED WORKS,0.2013888888888889,"artificial abnormal data through adversarial search, and Pourreza et al. [32] utilized data generated
116"
RELATED WORKS,0.203125,"from immature generator as abnormal data. Methods based on deep one class classification suffer
117"
RELATED WORKS,0.2048611111111111,"from the hyperparameter sensitivity problem as there are variables that significantly influence the
118"
RELATED WORKS,0.2065972222222222,"performance of anomaly detection, such as the radius variable in Goyal et al. [16].
119"
RELATED WORKS,0.20833333333333334,"Side-information-based methods.
Self-supervised methods utilize prior knowledge of the dif-
120"
RELATED WORKS,0.21006944444444445,"ferences between normal and abnormal data. For example, some studies [13, 18, 3, 41] focused on
121"
RELATED WORKS,0.21180555555555555,"differences in terms of geometry. Golan and El-Yaniv [13] assumed that a network can learn the
122"
RELATED WORKS,0.21354166666666666,"geometric features of normal data through a learning process that predicts the geometric transsforma-
123"
RELATED WORKS,0.2152777777777778,"tions applied to normal data. They expected the that a trained transform classifier will fail to predict
124"
RELATED WORKS,0.2170138888888889,"abnormal data with different geometric characteristics compared with normal data. Based on this
125"
RELATED WORKS,0.21875,"study, a method to restore transformed data [11] and methods that combined geometric concept with
126"
RELATED WORKS,0.2204861111111111,"constructive learning [6] were proposed [3, 41]. Other self-supervised methods augment normal
127"
RELATED WORKS,0.2222222222222222,"data to create synthetic abnormal data and use them to train networks that can detect locally defect
128"
RELATED WORKS,0.22395833333333334,"areas [45, 25, 47]. However, as mentioned in Goyal et al. [16], these methods rely heavily on prior
129"
RELATED WORKS,0.22569444444444445,"knowledge. Some studies have attempted to perform anomaly detection using features obtained from
130"
RELATED WORKS,0.22743055555555555,"pre-trained networks using external data. [4, 28, 38, 5, 33, 9]
131"
MULTI-LEVEL MASKING AND RESTORATION WITH REFINEMENT,0.22916666666666666,"3
Multi-Level Masking and Restoration with Refinement
132"
MULTI-LEVEL MASKING AND RESTORATION WITH REFINEMENT,0.2309027777777778,"The overall framework of the proposed method is shown in Fig. 3. In this section, we provide a
133"
MULTI-LEVEL MASKING AND RESTORATION WITH REFINEMENT,0.2326388888888889,"detailed description of our method called Multi-Level Masking and Restoration with Refinement
134"
MULTI-LEVEL MASKING AND RESTORATION WITH REFINEMENT,0.234375,"(MMRR). We describe the Multi-Level Masking and Restoration procedures that restrict the informa-
135"
MULTI-LEVEL MASKING AND RESTORATION WITH REFINEMENT,0.2361111111111111,"tion in a given input, and finally the Refinement that further improves the restored image.
136"
MULTI-LEVEL MASKING,0.2378472222222222,"3.1
Multi-Level Masking
137"
MULTI-LEVEL MASKING,0.23958333333333334,"Masking is a process that restricts embedding e ∈Rd, which is generated through embedding
138"
MULTI-LEVEL MASKING,0.24131944444444445,"network(fE : Rd →Rd) as e = tanh(fE(x)), by using mask m. The masking process is
139"
MULTI-LEVEL MASKING,0.24305555555555555,"˜e = e ⊙m + ϵ ⊙(1 −m),
(1)"
MULTI-LEVEL MASKING,0.24479166666666666,"Figure 1: Overall framework of MMRR. Given data x, the embedding network fE generates
embedding e. The embedding thus generated is limited through a mask m with a masking level
µm generated through the masking network fM, and using only such restricted embedding, the
restoration network fres performs the restoration of the original data x. Finally, the refinement
network fref complements the part not restored where restoration has inevitably failed due to the
intrinsic complexity, which allows MMRR to perform anomaly detection only with the intended
difference caused by masking and restoration."
MULTI-LEVEL MASKING,0.2465277777777778,"where ⊙is the Hadamard product, and ϵ is noise sampled from uniform random noise ϵ ∼U(−1, 1)d.
140"
MULTI-LEVEL MASKING,0.2482638888888889,"The output of the masking process, ˜e, is called restricted embedding.
141"
MULTI-LEVEL MASKING,0.25,"We masked e instead of directly masking x because the training process using only normal data will
142"
MULTI-LEVEL MASKING,0.2517361111111111,"make fE generate e, which helps in restoration. Thus, using e will enable our proposed masking
143"
MULTI-LEVEL MASKING,0.2534722222222222,"and restoration method to have a better discrimination ability. Noise ϵ is used because, without ϵ,
144"
MULTI-LEVEL MASKING,0.2552083333333333,"irrespective how small m is, trivial solution that can easily restore data is generated because e is
145"
MULTI-LEVEL MASKING,0.2569444444444444,"learnable. For the same reason, tanh was used to create e to prevent a trivial solution that makes
146"
MULTI-LEVEL MASKING,0.2586805555555556,"restoration easier by making the value of e significantly different from the noise value.
147"
MULTI-LEVEL MASKING,0.2604166666666667,"We can easily infer from Eq. 1 that if the value of m become smaller, the portion of embedding e in
148"
MULTI-LEVEL MASKING,0.2621527777777778,"˜e decreases and becomes noisy, and restoration becomes harder. For example, if all elements of m
149"
MULTI-LEVEL MASKING,0.2638888888888889,"are 0, ˜e will resemble uniform noise U(−1, 1)d, and restoration will be impossible. Therefore, we
150"
MULTI-LEVEL MASKING,0.265625,"consider that the average value of m can represent the difficulty of restoration from ˜e and define it as
151"
MULTI-LEVEL MASKING,0.2673611111111111,a masking level µm = 1
MULTI-LEVEL MASKING,0.2690972222222222,"d
Pd
i=1 mi, where mi refers to i-th element of m and µm ∈[0, 1].
152"
MULTI-LEVEL MASKING,0.2708333333333333,"The restricted embedding ˜e ∈Rd should meet two conditions for masking and restoration to detect
153"
MULTI-LEVEL MASKING,0.2725694444444444,"anomalies: normal data should be successfullt restore and abnormal data should not be restored. To
154"
MULTI-LEVEL MASKING,0.2743055555555556,"accomplish the goal, we need to find m with a µm that can best differentiate normal and abnormal data
155"
MULTI-LEVEL MASKING,0.2760416666666667,"in terms of restoration. However, we cannot find an optimal masking level µm that best distinguishes
156"
MULTI-LEVEL MASKING,0.2777777777777778,"abnormal data from normal data. This is because abnormal data cannot be used in the training process
157"
MULTI-LEVEL MASKING,0.2795138888888889,"owingto the nature of the field of anomaly detection.
158"
MULTI-LEVEL MASKING,0.28125,"Therefore, we decided to ensemble the ability to distinguish at multiple masking levels µm, which are
159"
MULTI-LEVEL MASKING,0.2829861111111111,"uniformly distributed between 0 and 1. For example, if we use L levels of masking for the ensemble,
160"
MULTI-LEVEL MASKING,0.2847222222222222,"µm ∈{0,
1
L−1,
2
L−1, ..., 1} will be used.
161"
MULTI-LEVEL MASKING,0.2864583333333333,"Our novel mask generation method made it possible to manually adjust the µm of m for multilevel
162"
MULTI-LEVEL MASKING,0.2881944444444444,"ensemble. Furthermore, the novel mask generation made m learnable such that it is generated in a
163"
MULTI-LEVEL MASKING,0.2899305555555556,"direction that is most useful for restoration from the corresponding µm, which improves the ability to
164"
MULTI-LEVEL MASKING,0.2916666666666667,"distinguish between normal data and abnormal data.
165"
MULTI-LEVEL MASKING,0.2934027777777778,"Mask generation method.
We propose a novel mask generation method that can generate a mask
166"
MULTI-LEVEL MASKING,0.2951388888888889,"m with masking level µm by m = σ(fM(x) + b), where fM : Rd →Rd is the masking network.
167"
MULTI-LEVEL MASKING,0.296875,"The goal of our mask generation method is to find the appropriate bias b ∈R that makes the average
168"
MULTI-LEVEL MASKING,0.2986111111111111,value of the mask to a predefined µm as follows: 1
MULTI-LEVEL MASKING,0.3003472222222222,"d
Pd
i=1 σ(fM(x)i + b) = µm, where µm is on
169"
MULTI-LEVEL MASKING,0.3020833333333333,"interval [0, 1] because m ∈[0, 1]d. As sigmoid σ is a monotonically increasing function, we can use
170"
MULTI-LEVEL MASKING,0.3038194444444444,"the root-finding method (in our case, the bisection method) to find bias b that satisfies the condition,
171"
MULTI-LEVEL MASKING,0.3055555555555556,"which allows us to successfully generate mask m with masking level µm. While the root finding
172"
MULTI-LEVEL MASKING,0.3072916666666667,"method is non-differential, the gradient to the output of fM was obtained under the assumption that
173"
MULTI-LEVEL MASKING,0.3090277777777778,"the bias satisfying the condition was well found, which is as follows:
174"
MULTI-LEVEL MASKING,0.3107638888888889,"∂L
∂fM(x)i
=
X ∀j"
MULTI-LEVEL MASKING,0.3125,"∂L
∂mj
mj(1 −mj)

δ(i, j) −
mi(1 −mi)
P"
MULTI-LEVEL MASKING,0.3142361111111111,∀k mk(1 −mk)
MULTI-LEVEL MASKING,0.3159722222222222,"
,
δ(i, j) =
1,
if i = j
0,
otherwise . (2)"
RESTORATION,0.3177083333333333,"3.2
Restoration
175"
RESTORATION,0.3194444444444444,"Restoration refers to the process in which restricted embedding ˜e is restored to original data x via the
176"
RESTORATION,0.3211805555555556,"restoration network(fres: Rd →Rd), where the restoration output is ˆx = tanh(fres(˜e)). Owing to
177"
RESTORATION,0.3229166666666667,"the mask generation method, not only fres but also fE and fM can be trained with only the simple
178"
RESTORATION,0.3246527777777778,"restoration loss, which is formulated as:
179"
RESTORATION,0.3263888888888889,"Lres = 1 d d
X"
RESTORATION,0.328125,"i=1
(xi −ˆxi)2
(3)"
RESTORATION,0.3298611111111111,"fres, which is trained using a training dataset consisting of only normal data, learns how to restore
180"
RESTORATION,0.3315972222222222,"normal data from ˜e. In such a training process, fres will learn salient features for normal distribution
181"
RESTORATION,0.3333333333333333,"p+. The features for normal distribution p+ obtained in this way will allow fres to restore normal
182"
RESTORATION,0.3350694444444444,"data efficiently even when the masking level µm is small.
183"
RESTORATION,0.3368055555555556,"While fres has been able to successfully restore normal data as mentioned above, this way of
184"
RESTORATION,0.3385416666666667,"restoration will fail for abnormal data. The reason is, fres has no choice but to generate an output that
185"
RESTORATION,0.3402777777777778,"resembles normal data because fres will also apply learned features for p+ even when restoration is
186"
RESTORATION,0.3420138888888889,"performed from ˜e of abnormal data. This failure to restore abnormal data will allow the masking and
187"
RESTORATION,0.34375,"restoration method to detect anomalies through the restoration loss.
188"
REFINEMENT,0.3454861111111111,"3.3
Refinement
189"
REFINEMENT,0.3472222222222222,"Our masking and restoration method resolves the hyperparameter sensitivity problem by ensembling
190"
REFINEMENT,0.3489583333333333,"the anomaly detection performance at multiple masking levels µm ∈{0,
1
L−1,
2
L−1, ..., 1}. However,
191"
REFINEMENT,0.3506944444444444,"comparing the degree of restoration at the same µm without considering the characteristics of the
192"
REFINEMENT,0.3524305555555556,"data causes another problem. This is because the degree of restoration is intrinsically different even if
193"
REFINEMENT,0.3541666666666667,"it is restored from the same µm because different x have different complexities.
194"
REFINEMENT,0.3559027777777778,"Let us assume that the restoration loss obtained from masking and restoration is composed of two
195"
REFINEMENT,0.3576388888888889,"losses. The first loss is caused by the inevitable restoration failure due to the intrinsic complexity of
196"
REFINEMENT,0.359375,"x, which is denoted as intrinsic loss. The second loss occurs when abnormal data are restored like
197"
REFINEMENT,0.3611111111111111,"normal data owing to masking and restoration, which is denoted as abnormality loss. We originally
198"
REFINEMENT,0.3628472222222222,"intended to perform anomaly detection based on this abnormality loss.
199"
REFINEMENT,0.3645833333333333,"This problem occurs when the abnormal sample is relatively simple compared with the normal sample.
200"
REFINEMENT,0.3663194444444444,"In this case, the sum of the intrinsic loss and the abnormality loss of the abnormal sample can be
201"
REFINEMENT,0.3680555555555556,"smaller than the intrinsic loss of the normal sample, which leads to the anomaly detection failure of
202"
REFINEMENT,0.3697916666666667,"the masking and restoration method.
203"
REFINEMENT,0.3715277777777778,"To address this problem, the refinement method aims to eliminate the intrinsic loss that inevitably
204"
REFINEMENT,0.3732638888888889,"occurs due to intrinsic complexity difference so that anomaly detection can be performed only with
205"
REFINEMENT,0.375,"the abnormality loss caused by masking and restoration process. For this, the refinement network
206"
REFINEMENT,0.3767361111111111,"fref : Rd × Rd × Rd × Rd →Rd predicts x −d that have not yet been restored at a particular µm as
207"
REFINEMENT,0.3784722222222222,"follows: r = fref(x, e, m, ϵ). fref is trained with refinement loss formulated as:
208"
REFINEMENT,0.3802083333333333,"Lref = 1 d d
X"
REFINEMENT,0.3819444444444444,"i=1
(xi −(ˆxi + ri))2
(4)"
TRAINING AND EVALUATION,0.3836805555555556,"3.4
Training and Evaluation
209"
TRAINING AND EVALUATION,0.3854166666666667,"Training.
Our method consists of a two-step training process. The first phase is a training process
210"
TRAINING AND EVALUATION,0.3871527777777778,"for masking and restoration. During this phase, the masking level µm is uniformly sampled, where
211"
TRAINING AND EVALUATION,0.3888888888888889,"µm ∼U(0, 1). The embedding network fE, masking network fM, restoration network fres are trained
212"
TRAINING AND EVALUATION,0.390625,"only with restoration loss. Furthermore, we selected the model with the smallest restoration loss for
213"
TRAINING AND EVALUATION,0.3923611111111111,"the validation data. The second phase is a training process for refinement. To this end, networks that
214"
TRAINING AND EVALUATION,0.3940972222222222,"have been trained in the first phase are used with fixed weights. µm is sampled from U(0, 1) as in
215"
TRAINING AND EVALUATION,0.3958333333333333,"first phase. The refinement network fref is trained with only the refinement loss. Furthermore, we
216"
TRAINING AND EVALUATION,0.3975694444444444,"selected the model with the smallest refinement loss for the validation data.
217"
TRAINING AND EVALUATION,0.3993055555555556,"Evaluation.
For evaluation, we must first determine the number of µm required. If we decide to
218"
TRAINING AND EVALUATION,0.4010416666666667,"use L masking levels, we must use {0,
1
L−1,
2
L−1, ..., 1} masking levels that are distributed evenly at
219"
TRAINING AND EVALUATION,0.4027777777777778,"1/(L−1) intervals for evaluation. Finally, we perform anomaly detection by summing the refinement
220"
TRAINING AND EVALUATION,0.4045138888888889,"loss at all masking levels for ensemble.
221"
EXPERIMENT,0.40625,"4
Experiment
222"
EXPERIMENTAL SETTINGS,0.4079861111111111,"4.1
Experimental Settings
223"
EXPERIMENTAL SETTINGS,0.4097222222222222,"To validate the proposed anomaly detection method, MMRR using multi-class datasets (MNIST [24],
224"
EXPERIMENTAL SETTINGS,0.4114583333333333,"FMNIST [44], CIFAR10 [22]), which is not designated for anomaly detection, we used the one-vs-all
225"
EXPERIMENTAL SETTINGS,0.4131944444444444,"strategy. The one-vs-all strategy selects one normal class 1 ≤c ≤C among C different classes.
226"
EXPERIMENTAL SETTINGS,0.4149305555555556,"For training, we only used the training set belonging to class c. For testing, the normality score
227"
EXPERIMENTAL SETTINGS,0.4166666666666667,"was calculated for all the data in the test set, the extent to which normal data and abnormal data are
228"
EXPERIMENTAL SETTINGS,0.4184027777777778,"distinguished in terms of the normality score was measured using the area under receiver operating
229"
EXPERIMENTAL SETTINGS,0.4201388888888889,"curve (AUROC). This process was repeated for all classes C to evaluate the anomaly detection model.
230"
EXPERIMENTAL SETTINGS,0.421875,"On the other hand, in the case of the MVTecAD dataset, for each class c, the train dataset consisting
231"
EXPERIMENTAL SETTINGS,0.4236111111111111,"of only normal data and the test dataset mixed with abnormal data are already prepared. Therefore,
232"
EXPERIMENTAL SETTINGS,0.4253472222222222,"we trained using only the train data as a given material, and used the test dataset in the test process.
233"
EXPERIMENTAL SETTINGS,0.4270833333333333,"Implementation details.
All proposed networks were implemented using the U-Net[34] based on
234"
EXPERIMENTAL SETTINGS,0.4288194444444444,"the wide residual[46] blocks proposed for wide residual networks. We used group normalization for
235"
EXPERIMENTAL SETTINGS,0.4305555555555556,"all blocks. For 32x32 datasets, we used four feature map resolutions(32x32 to 4x4). For 256x256
236"
EXPERIMENTAL SETTINGS,0.4322916666666667,"datasets, we used five feature map resolutions(256x256 to 16x16). We used two wide residual blocks
237"
EXPERIMENTAL SETTINGS,0.4340277777777778,"that consisted of convolutions with 128 output channels for each feature map resolution. RAdam[27]
238"
EXPERIMENTAL SETTINGS,0.4357638888888889,"was used as the optimizer with a learning rate of 0.0001. Batch size was set as 64 and 4 for the 32x32
239"
EXPERIMENTAL SETTINGS,0.4375,"and 256x256 datasets, respectively. The learning was decayed by a factor 0.5 if the validation loss
240"
EXPERIMENTAL SETTINGS,0.4392361111111111,"did not decrease for 500 epochs. We split the normal training set into training and validation sets
241"
EXPERIMENTAL SETTINGS,0.4409722222222222,"using a 95:5 ratio, and used the validation set to select the model with smallest validation loss.
242"
DATASETS AND RESULTS,0.4427083333333333,"4.2
Datasets and Results
243"
DATASETS AND RESULTS,0.4444444444444444,"Baseline Methods.
For anomaly detection in multi-class datasets, we compared MMRR with
244"
DATASETS AND RESULTS,0.4461805555555556,"classical approaches such as: OC-SVM [40], and KDE [29]; generative-model-based approaches such
245"
DATASETS AND RESULTS,0.4479166666666667,"as: AnoGAN [39], OCGAN [30], γ −V AEg [10] and CAVGAu [43]; deep one-class classification
246"
DATASETS AND RESULTS,0.4496527777777778,"approaches such as: DSVDD [35], and DROCC [16]. For anomaly detection on MVTecAD dataset,
247"
DATASETS AND RESULTS,0.4513888888888889,"we compared our MMRR with vanilla autoencoder AE, AE with skip connectins AE+skip, variational
248"
DATASETS AND RESULTS,0.453125,"autoencoder VAE, Ganomaly[1], MemAE [14], CAVGAu, and DAAD [20].
249"
DATASETS AND RESULTS,0.4548611111111111,"• MNIST includes a training set of 60,000 examples, and a test set of 10,000 examples. The data are
250"
DATASETS AND RESULTS,0.4565972222222222,"28x28 handwritten digits(0-9). For simplicity they were resized to 32x32. It was used for training
251"
DATASETS AND RESULTS,0.4583333333333333,"without any augmentations except resizing. Our MMRR model achieved averaged AUROC of
252"
DATASETS AND RESULTS,0.4600694444444444,"0.967, which is slightly lower compared to SOTA methods. The reason our model has slightly poor
253"
DATASETS AND RESULTS,0.4618055555555556,"performance on the MNIST dataset is that the data have a very easy distribution, so reconstruction
254"
DATASETS AND RESULTS,0.4635416666666667,"occurs well enough even at a very low masking level µm. For example, in Figure 3, we can see that
255"
DATASETS AND RESULTS,0.4652777777777778,"the digit 0 is restored well enough even if µm is 0.01. As such, if there is already a sample that can
256"
DATASETS AND RESULTS,0.4670138888888889,"be restored well in the masking and restoration stage of very low µm, it can be seen that refinement
257"
DATASETS AND RESULTS,0.46875,"has a limit in solving this problem.
258"
DATASETS AND RESULTS,0.4704861111111111,"• FMNIST consists of a training set of 60,000 examples, and test set of 10,000 examples, full of 10
259"
DATASETS AND RESULTS,0.4722222222222222,"different types of fashion items. For simplicity they were resized to 32x32. It was used for training
260"
DATASETS AND RESULTS,0.4739583333333333,"without any augmentations except resizing. MMRR greatly beats the existing SOTA performance
261"
DATASETS AND RESULTS,0.4756944444444444,"of 0.885 AUROC of CAVGA.
262"
DATASETS AND RESULTS,0.4774305555555556,"• CIFAR10 consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are
263"
DATASETS AND RESULTS,0.4791666666666667,"50000 training and 10000 test images. The dataset was used for training without any augmentations.
264"
DATASETS AND RESULTS,0.4809027777777778,"As shown in Table 5, our method achieved an average AUROC performance of 0.737 on the
265"
DATASETS AND RESULTS,0.4826388888888889,"CIFAR10 dataset, which is comparable to that of other SOTA methods: 0.742 for DROCC and
266"
DATASETS AND RESULTS,0.484375,"0.737 for CAVGA. Moreover, the performance obtained by our method is meaningful because it is
267"
DATASETS AND RESULTS,0.4861111111111111,"obtained without experiencing hyperparameter sensitivity problem unlike other SOTA methods.
268"
DATASETS AND RESULTS,0.4878472222222222,"• MVTecAD is a dataset for benchmarking anomaly detection methods with a focus on industrial
269"
DATASETS AND RESULTS,0.4895833333333333,"inspection. It contains over 5000 high-resolution images divided into 15 different object and
270"
DATASETS AND RESULTS,0.4913194444444444,"texture categories. Each category comprises a set of defect-free training images and a test set
271"
DATASETS AND RESULTS,0.4930555555555556,"of images with a variety of defects as well as images without defects. We resized all the data
272"
DATASETS AND RESULTS,0.4947916666666667,"to 256x256. We performed two tasks on the MVTecAD dataset, image-level anomaly detection
273"
DATASETS AND RESULTS,0.4965277777777778,"and pixel-level anomaly localization. Experimental results on MVTecAD dataset can be seen in
274"
DATASETS AND RESULTS,0.4982638888888889,"Table 7. MMRR achieved average 0.865 AUROC for pixel-level anomaly detection and 0.844
275"
DATASETS AND RESULTS,0.5,"AUROC for image-level anomaly detection, which is close to SOTA methods. We found that
276"
DATASETS AND RESULTS,0.5017361111111112,"among the test defect-free data in the screw class, there were samples with a different distribution
277"
DATASETS AND RESULTS,0.5034722222222222,"in terms of brightness compared to the train defect-free data. Therefore, we trained MMRR by
278"
DATASETS AND RESULTS,0.5052083333333334,"applying brightness augmentation to the train data, and a result of 0.95 AUROC was obtained in the
279"
DATASETS AND RESULTS,0.5069444444444444,"image-wise anomaly detection. However, we did not report the performance because we assumed
280"
DATASETS AND RESULTS,0.5086805555555556,"that we do not know the distribution of the test data.
281"
DATASETS AND RESULTS,0.5104166666666666,"1   
2   
4   
8   
16  
32  
64  
128 256 512 1024
0.55 0.6 0.65 0.7 0.75 0.8 0.85 AUROC"
DATASETS AND RESULTS,0.5121527777777778,"Airplanes
Cars
Birds
Cats
Deer"
DATASETS AND RESULTS,0.5138888888888888,"Dogs
Frogs
Horses
Ships
Trucks"
DATASETS AND RESULTS,0.515625,"Figure 2: Illustration of AUROC with re-
spects to the number of Masking-Level (µm)
used for MMRR on CIFAR10 dataset."
DATASETS AND RESULTS,0.5173611111111112,"Hyperparameter sensitivity.
As we mentioned earlier,
282"
DATASETS AND RESULTS,0.5190972222222222,"most of the generative model based methods and deep-one
283"
DATASETS AND RESULTS,0.5208333333333334,"class classification based methods have hyperparameter
284"
DATASETS AND RESULTS,0.5225694444444444,"sensitivity problem. For example, DROCC [16] showed
285"
DATASETS AND RESULTS,0.5243055555555556,"how sensitively the performance changes according to the
286"
DATASETS AND RESULTS,0.5260416666666666,"radius value, which is a hyperparameter that they used to
287"
DATASETS AND RESULTS,0.5277777777777778,"obtain negative samples. Anomaly detection performace
288"
DATASETS AND RESULTS,0.5295138888888888,"of DROCC in CIFAR10 dataset fluctuates between 0.7-0.8
289"
DATASETS AND RESULTS,0.53125,"for airplane, 0.5-0.7 for deer, and 0.7-0.8 for trucks in
290"
DATASETS AND RESULTS,0.5329861111111112,"terms of AUROC depending on the radius value. There-
291"
DATASETS AND RESULTS,0.5347222222222222,"fore, they carefully searched for the radius value to obtain
292"
DATASETS AND RESULTS,0.5364583333333334,"optimal anomaly detection performance. In addition to
293"
DATASETS AND RESULTS,0.5381944444444444,"this, Akçay et al. [1] showed that the performance of their
294"
DATASETS AND RESULTS,0.5399305555555556,"proposed model is sensitively changed according to the
295"
DATASETS AND RESULTS,0.5416666666666666,"values of three hyperparameters that balance their losses
296"
DATASETS AND RESULTS,0.5434027777777778,"in the CIFAR10 dataset. Also, Hou et al. [20] showed that
297"
DATASETS AND RESULTS,0.5451388888888888,"the anomaly detection performance in MVTecAD dataset fluctuates between 0.716-0.821 based on
298"
DATASETS AND RESULTS,0.546875,"the value of division rate(rh&rw) that determines the size of the query.
299"
DATASETS AND RESULTS,0.5486111111111112,"However, MMRR uses only one loss for each training phase. And we provide a clear criterion for
300"
DATASETS AND RESULTS,0.5503472222222222,"model design: selecting the model with the lowest loss on validation data. Furthermore, we show
301"
DATASETS AND RESULTS,0.5520833333333334,"how the performance of MMRR changes according to the only hyperparameter that significantly
302"
DATASETS AND RESULTS,0.5538194444444444,"affects our performance in the Fig. 2. From Fig. 2, It can be seen that the performance of anomaly
303"
DATASETS AND RESULTS,0.5555555555555556,"detection improves as the number of masking levels used for evaluation increases.
304"
DATASETS AND RESULTS,0.5572916666666666,"GEOM
MMRR w/o ref.
MMRR"
DATASETS AND RESULTS,0.5590277777777778,"w/o aug.
0.86
0.676
0.737
w/ aug.
0.691
0.682
0.7"
DATASETS AND RESULTS,0.5607638888888888,"Table 1: Comparing AUROC against GEOM[13] on
CIFAR10 dataset with training data augmentations
(rotation ±30◦and flips)."
DATASETS AND RESULTS,0.5625,"Prior knowledge.
It has been shown in Goyal
305"
DATASETS AND RESULTS,0.5642361111111112,"et al. [16] that the side-information based meth-
306"
DATASETS AND RESULTS,0.5659722222222222,"ods mentioned in Section 2 relies heavily on the
307"
DATASETS AND RESULTS,0.5677083333333334,"prior knowledge they used. To prove this, they
308"
DATASETS AND RESULTS,0.5694444444444444,"applied flips and small rotations of angle ±30◦
309"
DATASETS AND RESULTS,0.5711805555555556,"to CIFAR10 data during training. As can be seen
310"
DATASETS AND RESULTS,0.5729166666666666,"in Table 1 there was a large decline in the perfor-
311"
DATASETS AND RESULTS,0.5746527777777778,"mance(0.86 to 0.691) of the Golan and El-Yaniv
312"
DATASETS AND RESULTS,0.5763888888888888,"[13] that used prior knowledge. On the other hand, MMRR w/o refine showed rather good perfor-
313"
DATASETS AND RESULTS,0.578125,"mance (0.676 to 0.682), and MMRR showed 0.037 lower performance (0.737 to 0.7).
314"
ABLATION STUDY,0.5798611111111112,"4.3
Ablation Study
315"
ABLATION STUDY,0.5815972222222222,"MNIST
OC-SVM
KDE
AnoGAN
DSVDD
OC-GAN
CAVGA
MMRR w/o ref.
MMRR
0
0.988
0.885
0.966
0.98
0.998
0.994
0.9857
0.9941
1
0.999
0.996
0.992
0.997
0.999
0.997
0.999
0.9982
2
0.902
0.71
0.85
0.917
0.942
0.989
0.8981
0.94
3
0.95
0.693
0.887
0.919
0.963
0.983
0.9246
0.955
4
0.955
0.844
0.894
0.949
0.975
0.977
0.9309
0.9352
5
0.968
0.776
0.883
0.885
0.98
0.968
0.9173
0.971
6
0.978
0.861
0.947
0.983
0.991
0.988
0.9765
0.989
7
0.965
0.884
0.935
0.946
0.981
0.986
0.9539
0.966
8
0.853
0.669
0.849
0.939
0.939
0.988
0.906
0.945
9
0.955
0.825
0.924
0.965
0.981
0.991
0.9511
0.98"
ABLATION STUDY,0.5833333333333334,Table 5: Image-level AUROC for one-vs-all anomaly detection on MNIST.
ABLATION STUDY,0.5850694444444444,"w/o ref.
w/ ref."
ABLATION STUDY,0.5868055555555556,"w/o emb. e
0.642
0.6449
w/ emb. e
0.676
0.737"
ABLATION STUDY,0.5885416666666666,"Table 2: AUROC performance of
MMRR w/o and w/ embedding net-
work on CIFAR10."
ABLATION STUDY,0.5902777777777778,"Embedding.
To prove the effectiveness of using embedding e,
316"
ABLATION STUDY,0.5920138888888888,"we directly masked the data x. As can be seen from the table, we
317"
ABLATION STUDY,0.59375,"got an average AUROC of 0.6449 in the CIFAR10 dataset when e
318"
ABLATION STUDY,0.5954861111111112,"was not used. And 0.6449 AUROC is far lower than 0.737 AUROC,
319"
ABLATION STUDY,0.5972222222222222,"which is the performance obtained when e is used. Through these
320"
ABLATION STUDY,0.5989583333333334,"results, it can be seen that fE learned a salient features for normal
321"
ABLATION STUDY,0.6006944444444444,"data in the training process of generating e, which is most helpful
322"
ABLATION STUDY,0.6024305555555556,"for restoration even though it is restricted by masking. And the
323"
ABLATION STUDY,0.6041666666666666,"embedding e generated from fE can be seen to have a positive effect on the anomaly detection
324"
ABLATION STUDY,0.6059027777777778,"performance by widening the restoration gap between normal data and abnormal data.
325"
ABLATION STUDY,0.6076388888888888,"(a) From left to right, data, constant mask,
bernoulli mask, our mask"
ABLATION STUDY,0.609375,"Constant
Bernoulli
Ours"
ABLATION STUDY,0.6111111111111112,"w/o ref.
0.619
0.612
0.676"
ABLATION STUDY,0.6128472222222222,"w/ ref.
0.674
0.648
0.737"
ABLATION STUDY,0.6145833333333334,"Table 3: AUROC according to mask genera-
tion method on CIFAR10"
ABLATION STUDY,0.6163194444444444,"Mask generation method.
We proved the effective-
326"
ABLATION STUDY,0.6180555555555556,"ness of our learnable mask by comparing it with other
327"
ABLATION STUDY,0.6197916666666666,"simple masks which are unable to learn. The first mask
328"
ABLATION STUDY,0.6215277777777778,"is a mask in which all elements have the same constant
329"
ABLATION STUDY,0.6232638888888888,"value µm, and we will call it a constant mask. The
330"
ABLATION STUDY,0.625,"second mask to be compared is a mask generated by
331"
ABLATION STUDY,0.6267361111111112,"bernoulli sampling with a probability of µm. When we
332"
ABLATION STUDY,0.6284722222222222,"used the constant mask, we got an AUROC performance
333"
ABLATION STUDY,0.6302083333333334,"of 0.667, and when we used the bernoulli mask, we got
334"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6319444444444444,"0.6478. These are lower performances when compared
335"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6336805555555556,"to 0.737 obtained by our mask generation method. From
336"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6354166666666666,"the experimental results, it can be seen that the use of
337"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6371527777777778,"a our multi-level mask that can learn to leave informa-
338"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6388888888888888,"tion which is most helpful for restoration at a specific
339"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.640625,"masking level during the masking process also helps anomaly detection.
340"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6423611111111112,"MNIST
FMNIST
CIFAR10
MVTecAD"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6440972222222222,"w/o ref.
0.944
0.928
0.676
0.825 / 0.861
w/ ref.
0.967
0.93
0.737
0.840 / 0.865"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6458333333333334,"Table 4: AUROC w/o and w/ refinement module on MNIST,
FMNIST, CIFAR10, and MVTecAD. Image-wise / Pixel-wise
AUROC performance was reported on MVTecAD."
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6475694444444444,"Refinement.
As can be seen from
341"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6493055555555556,"the Table 4, there is a big difference
342"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6510416666666666,"between MMRR with refinement and
343"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6527777777777778,"MMRR without refinement. In the case
344"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6545138888888888,"of MNIST dataset, average auroc im-
345"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.65625,"proved by 0.033 from 0.944 to 0.967.
346"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6579861111111112,"And for CIFAR10 dataset, average au-
347"
THESE ARE LOWER PERFORMANCES WHEN COMPARED,0.6597222222222222,"roc improved by 0.067 from 0.68 to
348"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6614583333333334,"0.747. Experimental results show another interesting phenomenon besides performance improve-
349"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6631944444444444,"ment. For example, data that has already had good anomaly detection performance in MMRR w/o
350"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6649305555555556,"refinement, such as data beloning to airplane, deer, ship classes, does not improve significantly when
351"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6666666666666666,"refinement is applied as can be seen in Table 5. However, the data that performed poorly in the
352"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6684027777777778,"MMRR w/o refinement, such as data belonging to automobile, truck, showed a remarkably large
353"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6701388888888888,"performance improvement. These results show that the intrinsic complexity difference between
354"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.671875,"classes is well resolved through the refinement as intended. However, as MVTecAD dataset is the
355"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6736111111111112,"data proposed to detect local defect areas, the difference in intrinsic complexity between normal
356"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6753472222222222,"data and abnormal data is not large. Therefore, as can be seen from the Table 4, the performance
357"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6770833333333334,"improvement due to refinement was insignificant.
358"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6788194444444444,"CIFAR10
OC-SVM
KDE
AnoGAN
DSVDD
OC-GAN
γ-VAE
CAVGA
DROCC
MMRR w/o ref
MMRR
Airplane
0.63
0.658
0.671
0.617
0.757
0.702
0.653
0.817
0.7778
0.7965
Automobile
0.44
0.52
0.547
0.659
0.531
0.663
0.784
0.767
0.6065
0.7377
Bird
0.649
0.657
0.529
0.508
0.64
0.68
0.761
0.667
0.6926
0.7024
Cat
0.487
0.497
0.545
0.591
0.62
0.713
0.747
0.671
0.6076
0.6595
Deer
0.735
0.727
0.651
0.609
0.723
0.77
0.775
0.736
0.7638
0.7817
Dog
0.5
0.496
0.603
0.657
0.62
0.689
0.552
0.744
0.6143
0.6739
Frog
0.725
0.758
0.585
0.677
0.723
0.805
0.813
0.744
0.6966
0.7641
Horse
0.533
0.564
0.625
0.673
0.575
0.588
0.745
0.714
0.626
0.7037
Ship
0.649
0.68
0.758
0.759
0.82
0.813
0.801
0.800
0.7878
0.8181
Truck
0.508
0.54
0.665
0.731
0.554
0.744
0.741
0.762
0.6229
0.7325"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6805555555555556,Table 6: Image-level AUROC for one-vs-all anomaly detection on CIFAR10.
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6822916666666666,Method Class
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6840277777777778,"carpet
grid
leather
tile
wood
bottle
cable
capsule
hazelnut
metalnut
pill
screw
toothbrush
transistor
zipper"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6857638888888888,Pixel-level
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6875,"AE
0.539
0.96
0.751
0.476
0.63
0.909
0.732
0.786
0.976
0.88
0.885
0.979
0.971
0.906
0.68
VAE
0.58
0.888
0.834
0.465
0.695
0.902
0.828
0.862
0.977
0.881
0.888
0.958
0.971
0.894
0.814
γ −VAEg
0.727
0.979
0.897
0.581
0.809
0.931
0.88
0.917
0.988
0.914
0.935
0.972
0.983
0.931
0.871"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6892361111111112,"MMRR w/o ref.
0.6733
0.8529
0.8599
0.7851
0.7911
0.8878
0.9117
0.898
0.8555
0.8648
0.9335
0.9074
0.9506
0.8865
0.8526
MMRR
0.6561
0.8477
0.8405
0.7916
0.7858
0.889
0.8841
0.9179
0.9414
0.8197
0.9209
0.8924
0.9486
0.9038
0.8779"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6909722222222222,Image-level
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6927083333333334,"Ganomaly
0.699
0.708
0.842
0.794
0.834
0.892
0.757
0.732
0.785
0.7
0.743
0.746
0.653
0.792
0.745
AE
0.411
0.841
0.615
0.696
0.961
0.955
0.688
0.819
0.884
0.565
0.882
0.956
0.977
0.776
0.878
MemAE
0.454
0.946
0.611
0.63
0.967
0.954
0.694
0.831
0.891
0.537
0.883
0.992
0.972
0.793
0.871
AE+skip
0.385
0.879
0.57
0.986
0.977
0.713
0.579
0.747
0.828
0.336
0.853
1
0.742
0.749
0.696
DAAD
0.671
0.975
0.628
0.825
0.957
0.975
0.72
0.866
0.893
0.552
0.898
1
0.989
0.814
0.906
DAAD+
0.866
0.957
0.862
0.882
0.982
0.976
0.844
0.767
0.921
0.758
0.9
0.987
0.992
0.876
0.859"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6944444444444444,"MMRR w/o ref.
0.4166
0.981
0.8005
0.9015
0.9842
0.9458
0.8277
0.738
0.9157
0.7085
0.8862
0.5288
0.9816
0.8897
0.8629
MMRR
0.496
0.9908
0.7993
0.7652
0.9316
0.9595
0.8639
0.7535
0.9107
0.8162
0.8775
0.66
0.9798
0.9162
0.8703"
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6961805555555556,Table 7: Pixel-level and Image-level anomaly detection on MVTecAD dataset.
EXPERIMENTAL RESULTS SHOW ANOTHER INTERESTING PHENOMENON BESIDES PERFORMANCE IMPROVE-,0.6979166666666666,Figure 3: Qualitative results for normal and abnormal samples.
CONCLUSION,0.6996527777777778,"5
Conclusion
359"
CONCLUSION,0.7013888888888888,"We proposed Multi-Level Masking and Restoration with Refinement (MMRR), which started from the
360"
CONCLUSION,0.703125,"motivation to perform anomaly detection through a series of processes of information limitation and
361"
CONCLUSION,0.7048611111111112,"restoration. The most noteworthy point of this study is that it presented the hyperparameter sensitivity
362"
CONCLUSION,0.7065972222222222,"problem for the first time, a problem that had been overlooked in existing anomaly detection studies.
363"
CONCLUSION,0.7083333333333334,"MMRR solved the hyperparameter sensitivity problem through ensemble at multiple masking levels
364"
CONCLUSION,0.7100694444444444,"with novel mask generation method. To empirically demonstrate the robustness to hyperparameter
365"
CONCLUSION,0.7118055555555556,"and prior knowledge-free properties of MMRR, we compared the performance as varying the number
366"
CONCLUSION,0.7135416666666666,"of masking level and augmentations. Additionally, we solved the problem of not considering the
367"
CONCLUSION,0.7152777777777778,"intrinsic complexity of data owing to the novel mask generation method through the refinement
368"
CONCLUSION,0.7170138888888888,"module, and achieved comparable performance on MNIST, FMNIST, CIFAR10, and MVTecAD
369"
CONCLUSION,0.71875,"datasets. However, since we have to forward several times for ensemble in multi-level masking, it
370"
CONCLUSION,0.7204861111111112,"has the disadvantage of being computationally expensive. We will go further here and try to find a
371"
CONCLUSION,0.7222222222222222,"lightweight anomaly detection method without suffering from hyperparameter sensitivity problems.
372"
REFERENCES,0.7239583333333334,"References
373"
REFERENCES,0.7256944444444444,"[1] S. Akçay, A. Atapour-Abarghouei, and T. P. Breckon. Skip-ganomaly: Skip connected and adversarially
374"
REFERENCES,0.7274305555555556,"trained encoder-decoder anomaly detection. In 2019 International Joint Conference on Neural Networks
375"
REFERENCES,0.7291666666666666,"(IJCNN), pages 1–8. IEEE, 2019.
376"
REFERENCES,0.7309027777777778,"[2] J. An and S. Cho. Variational autoencoder based anomaly detection using reconstruction probability.
377"
REFERENCES,0.7326388888888888,"Special Lecture on IE, 2(1):1–18, 2015.
378"
REFERENCES,0.734375,"[3] L. Bergman and Y. Hoshen. Classification-based anomaly detection for general data. In International
379"
REFERENCES,0.7361111111111112,"Conference on Learning Representations, 2019.
380"
REFERENCES,0.7378472222222222,"[4] L. Bergman, N. Cohen, and Y. Hoshen. Deep nearest neighbor anomaly detection. arXiv preprint
381"
REFERENCES,0.7395833333333334,"arXiv:2002.10445, 2020.
382"
REFERENCES,0.7413194444444444,"[5] P. Bergmann, M. Fauser, D. Sattlegger, and C. Steger. Uninformed students: Student-teacher anomaly
383"
REFERENCES,0.7430555555555556,"detection with discriminative latent embeddings. In Proceedings of the IEEE/CVF Conference on Computer
384"
REFERENCES,0.7447916666666666,"Vision and Pattern Recognition, pages 4183–4192, 2020.
385"
REFERENCES,0.7465277777777778,"[6] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton. A simple framework for contrastive learning of visual
386"
REFERENCES,0.7482638888888888,"representations. In International conference on machine learning, pages 1597–1607. PMLR, 2020.
387"
REFERENCES,0.75,"[7] R. A. Davis, K.-S. Lii, and D. N. Politis. Remarks on some nonparametric estimates of a density function.
388"
REFERENCES,0.7517361111111112,"In Selected Works of Murray Rosenblatt, pages 95–100. Springer, 2011.
389"
REFERENCES,0.7534722222222222,"[8] L. Deecke, R. Vandermeulen, L. Ruff, S. Mandt, and M. Kloft. Image anomaly detection with generative
390"
REFERENCES,0.7552083333333334,"adversarial networks. In Joint european conference on machine learning and knowledge discovery in
391"
REFERENCES,0.7569444444444444,"databases, pages 3–17. Springer, 2018.
392"
REFERENCES,0.7586805555555556,"[9] T. Defard, A. Setkov, A. Loesch, and R. Audigier. Padim: a patch distribution modeling framework for
393"
REFERENCES,0.7604166666666666,"anomaly detection and localization. In International Conference on Pattern Recognition, pages 475–489.
394"
REFERENCES,0.7621527777777778,"Springer, 2021.
395"
REFERENCES,0.7638888888888888,"[10] D. Dehaene, O. Frigo, S. Combrexelle, and P. Eline. Iterative energy-based projection on a normal data
396"
REFERENCES,0.765625,"manifold for anomaly localization. CoRR, abs/2002.03734, 2020. URL https://arxiv.org/abs/2002.
397"
REFERENCES,0.7673611111111112,"03734.
398"
REFERENCES,0.7690972222222222,"[11] Y. Fei, C. Huang, C. Jinkun, M. Li, Y. Zhang, and C. Lu. Attribute restoration framework for anomaly
399"
REFERENCES,0.7708333333333334,"detection. IEEE Transactions on Multimedia, 2020.
400"
REFERENCES,0.7725694444444444,"[12] S. Gidaris, P. Singh, and N. Komodakis. Unsupervised representation learning by predicting image
401"
REFERENCES,0.7743055555555556,"rotations. arXiv preprint arXiv:1803.07728, 2018.
402"
REFERENCES,0.7760416666666666,"[13] I. Golan and R. El-Yaniv. Deep anomaly detection using geometric transformations. Advances in neural
403"
REFERENCES,0.7777777777777778,"information processing systems, 31, 2018.
404"
REFERENCES,0.7795138888888888,"[14] D. Gong, L. Liu, V. Le, B. Saha, M. R. Mansour, S. Venkatesh, and A. v. d. Hengel. Memorizing
405"
REFERENCES,0.78125,"normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection.
406"
REFERENCES,0.7829861111111112,"In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1705–1714, 2019.
407"
REFERENCES,0.7847222222222222,"[15] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio.
408"
REFERENCES,0.7864583333333334,"Generative adversarial nets. Advances in neural information processing systems, 27, 2014.
409"
REFERENCES,0.7881944444444444,"[16] S. Goyal, A. Raghunathan, M. Jain, H. V. Simhadri, and P. Jain. Drocc: Deep robust one-class classification.
410"
REFERENCES,0.7899305555555556,"In International Conference on Machine Learning, pages 3711–3721. PMLR, 2020.
411"
REFERENCES,0.7916666666666666,"[17] D. Hendrycks, M. Mazeika, and T. Dietterich.
Deep anomaly detection with outlier exposure.
In
412"
REFERENCES,0.7934027777777778,"International Conference on Learning Representations, 2018.
413"
REFERENCES,0.7951388888888888,"[18] D. Hendrycks, M. Mazeika, S. Kadavath, and D. Song. Using self-supervised learning can improve model
414"
REFERENCES,0.796875,"robustness and uncertainty. Advances in Neural Information Processing Systems, 32, 2019.
415"
REFERENCES,0.7986111111111112,"[19] H. Hoffmann. Kernel pca for novelty detection. Pattern recognition, 40(3):863–874, 2007.
416"
REFERENCES,0.8003472222222222,"[20] J. Hou, Y. Zhang, Q. Zhong, D. Xie, S. Pu, and H. Zhou. Divide-and-assemble: Learning block-wise
417"
REFERENCES,0.8020833333333334,"memory for unsupervised anomaly detection. In Proceedings of the IEEE/CVF International Conference
418"
REFERENCES,0.8038194444444444,"on Computer Vision, pages 8791–8800, 2021.
419"
REFERENCES,0.8055555555555556,"[21] W. Hu, M. Wang, Q. Qin, J. Ma, and B. Liu. Hrn: A holistic approach to one class learning. Advances in
420"
REFERENCES,0.8072916666666666,"Neural Information Processing Systems, 33:19111–19124, 2020.
421"
REFERENCES,0.8090277777777778,"[22] A. Krizhevsky, G. Hinton, et al. Learning multiple layers of features from tiny images. 2009.
422"
REFERENCES,0.8107638888888888,"[23] G. Kwon, M. Prabhushankar, D. Temel, and G. AlRegib. Backpropagated gradient representations for
423"
REFERENCES,0.8125,"anomaly detection. In European Conference on Computer Vision, pages 206–226. Springer, 2020.
424"
REFERENCES,0.8142361111111112,"[24] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition.
425"
REFERENCES,0.8159722222222222,"Proceedings of the IEEE, 86(11):2278–2324, 1998.
426"
REFERENCES,0.8177083333333334,"[25] C.-L. Li, K. Sohn, J. Yoon, and T. Pfister. Cutpaste: Self-supervised learning for anomaly detection and
427"
REFERENCES,0.8194444444444444,"localization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
428"
REFERENCES,0.8211805555555556,"pages 9664–9674, 2021.
429"
REFERENCES,0.8229166666666666,"[26] F. T. Liu, K. M. Ting, and Z.-H. Zhou. Isolation forest. In 2008 eighth ieee international conference on
430"
REFERENCES,0.8246527777777778,"data mining, pages 413–422. IEEE, 2008.
431"
REFERENCES,0.8263888888888888,"[27] L. Liu, H. Jiang, P. He, W. Chen, X. Liu, J. Gao, and J. Han. On the variance of the adaptive learning rate
432"
REFERENCES,0.828125,"and beyond. CoRR, abs/1908.03265, 2019. URL http://arxiv.org/abs/1908.03265.
433"
REFERENCES,0.8298611111111112,"[28] P. Liznerski, L. Ruff, R. A. Vandermeulen, B. J. Franks, M. Kloft, and K.-R. Müller. Explainable deep
434"
REFERENCES,0.8315972222222222,"one-class classification. arXiv preprint arXiv:2007.01760, 2020.
435"
REFERENCES,0.8333333333333334,"[29] E. Parzen. On estimation of a probability density function and mode. The annals of mathematical statistics,
436"
REFERENCES,0.8350694444444444,"33(3):1065–1076, 1962.
437"
REFERENCES,0.8368055555555556,"[30] P. Perera, R. Nallapati, and B. Xiang. Ocgan: One-class novelty detection using gans with constrained
438"
REFERENCES,0.8385416666666666,"latent representations. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
439"
REFERENCES,0.8402777777777778,"Recognition, pages 2898–2906, 2019.
440"
REFERENCES,0.8420138888888888,"[31] S. Pidhorskyi, R. Almohsen, and G. Doretto. Generative probabilistic novelty detection with adversarial
441"
REFERENCES,0.84375,"autoencoders. Advances in neural information processing systems, 31, 2018.
442"
REFERENCES,0.8454861111111112,"[32] M. Pourreza, B. Mohammadi, M. Khaki, S. Bouindour, H. Snoussi, and M. Sabokrou. G2d: generate to
443"
REFERENCES,0.8472222222222222,"detect anomaly. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision,
444"
REFERENCES,0.8489583333333334,"pages 2003–2012, 2021.
445"
REFERENCES,0.8506944444444444,"[33] T. Reiss, N. Cohen, L. Bergman, and Y. Hoshen. Panda: Adapting pretrained features for anomaly
446"
REFERENCES,0.8524305555555556,"detection and segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
447"
REFERENCES,0.8541666666666666,"Recognition, pages 2806–2814, 2021.
448"
REFERENCES,0.8559027777777778,"[34] O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical image segmentation.
449"
REFERENCES,0.8576388888888888,"CoRR, abs/1505.04597, 2015. URL http://arxiv.org/abs/1505.04597.
450"
REFERENCES,0.859375,"[35] L. Ruff, R. Vandermeulen, N. Goernitz, L. Deecke, S. A. Siddiqui, A. Binder, E. Müller, and M. Kloft.
451"
REFERENCES,0.8611111111111112,"Deep one-class classification. In International conference on machine learning, pages 4393–4402. PMLR,
452"
REFERENCES,0.8628472222222222,"2018.
453"
REFERENCES,0.8645833333333334,"[36] M. Sabokrou, M. Khalooei, M. Fathy, and E. Adeli. Adversarially learned one-class classifier for novelty
454"
REFERENCES,0.8663194444444444,"detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages
455"
REFERENCES,0.8680555555555556,"3379–3388, 2018.
456"
REFERENCES,0.8697916666666666,"[37] M. Sakurada and T. Yairi. Anomaly detection using autoencoders with nonlinear dimensionality reduction.
457"
REFERENCES,0.8715277777777778,"In Proceedings of the MLSDA 2014 2nd workshop on machine learning for sensory data analysis, pages
458"
REFERENCES,0.8732638888888888,"4–11, 2014.
459"
REFERENCES,0.875,"[38] M. Salehi, N. Sadjadi, S. Baselizadeh, M. H. Rohban, and H. R. Rabiee. Multiresolution knowledge
460"
REFERENCES,0.8767361111111112,"distillation for anomaly detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and
461"
REFERENCES,0.8784722222222222,"Pattern Recognition, pages 14902–14912, 2021.
462"
REFERENCES,0.8802083333333334,"[39] T. Schlegl, P. Seeböck, S. M. Waldstein, U. Schmidt-Erfurth, and G. Langs. Unsupervised anomaly
463"
REFERENCES,0.8819444444444444,"detection with generative adversarial networks to guide marker discovery. In International conference on
464"
REFERENCES,0.8836805555555556,"information processing in medical imaging, pages 146–157. Springer, 2017.
465"
REFERENCES,0.8854166666666666,"[40] B. Schölkopf, J. C. Platt, J. Shawe-Taylor, A. J. Smola, and R. C. Williamson. Estimating the support of a
466"
REFERENCES,0.8871527777777778,"high-dimensional distribution. Neural computation, 13(7):1443–1471, 2001.
467"
REFERENCES,0.8888888888888888,"[41] J. Tack, S. Mo, J. Jeong, and J. Shin. Csi: Novelty detection via contrastive learning on distributionally
468"
REFERENCES,0.890625,"shifted instances. Advances in neural information processing systems, 33:11839–11852, 2020.
469"
REFERENCES,0.8923611111111112,"[42] D. M. Tax and R. P. Duin. Support vector data description. Machine learning, 54(1):45–66, 2004.
470"
REFERENCES,0.8940972222222222,"[43] S. Venkataramanan, K.-C. Peng, R. V. Singh, and A. Mahalanobis. Attention guided anomaly localization
471"
REFERENCES,0.8958333333333334,"in images. In European Conference on Computer Vision, pages 485–503. Springer, 2020.
472"
REFERENCES,0.8975694444444444,"[44] H. Xiao, K. Rasul, and R. Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine
473"
REFERENCES,0.8993055555555556,"learning algorithms. arXiv preprint arXiv:1708.07747, 2017.
474"
REFERENCES,0.9010416666666666,"[45] J. Yi and S. Yoon. Patch svdd: Patch-level svdd for anomaly detection and segmentation. In Proceedings
475"
REFERENCES,0.9027777777777778,"of the Asian Conference on Computer Vision, 2020.
476"
REFERENCES,0.9045138888888888,"[46] S. Zagoruyko and N. Komodakis. Wide residual networks. arXiv preprint arXiv:1605.07146, 2016.
477"
REFERENCES,0.90625,"[47] V. Zavrtanik, M. Kristan, and D. Skoˇcaj. Draem-a discriminatively trained reconstruction embedding for
478"
REFERENCES,0.9079861111111112,"surface anomaly detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision,
479"
REFERENCES,0.9097222222222222,"pages 8330–8339, 2021.
480"
REFERENCES,0.9114583333333334,"[48] V. Zavrtanik, M. Kristan, and D. Skoˇcaj. Reconstruction by inpainting for visual anomaly detection.
481"
REFERENCES,0.9131944444444444,"Pattern Recognition, 112:107706, 2021.
482"
REFERENCES,0.9149305555555556,"Checklist
483"
REFERENCES,0.9166666666666666,"The checklist follows the references. Please read the checklist guidelines carefully for information on
484"
REFERENCES,0.9184027777777778,"how to answer these questions. For each question, change the default [TODO] to [Yes] , [No] , or
485"
REFERENCES,0.9201388888888888,"[N/A] . You are strongly encouraged to include a justification to your answer, either by referencing
486"
REFERENCES,0.921875,"the appropriate section of your paper or providing a brief inline description. For example:
487"
REFERENCES,0.9236111111111112,"• Did you include the license to the code and datasets? [Yes] See Section ??.
488"
REFERENCES,0.9253472222222222,"• Did you include the license to the code and datasets? [No] The code and the data are proprietary.
489"
REFERENCES,0.9270833333333334,"• Did you include the license to the code and datasets? [N/A]
490"
REFERENCES,0.9288194444444444,"Please do not modify the questions and only use the provided macros for your answers. Note that the
491"
REFERENCES,0.9305555555555556,"Checklist section does not count towards the page limit. In your paper, please delete this instructions
492"
REFERENCES,0.9322916666666666,"block and only keep the Checklist section heading above along with the questions/answers below.
493"
REFERENCES,0.9340277777777778,"1. For all authors...
494"
REFERENCES,0.9357638888888888,"(a) Do the main claims made in the abstract and introduction accurately reflect the paper’s
495"
REFERENCES,0.9375,"contributions and scope? [Yes] The contributions of our work are thoroughly are
496"
REFERENCES,0.9392361111111112,"included in both abstract and introduction.
497"
REFERENCES,0.9409722222222222,"(b) Did you describe the limitations of your work? [Yes] The limitations of our work are
498"
REFERENCES,0.9427083333333334,"mentioned in Section 5.
499"
REFERENCES,0.9444444444444444,"(c) Did you discuss any potential negative societal impacts of your work? [N/A]
500"
REFERENCES,0.9461805555555556,"(d) Have you read the ethics review guidelines and ensured that your paper conforms to
501"
REFERENCES,0.9479166666666666,"them? [Yes]
502"
REFERENCES,0.9496527777777778,"2. If you are including theoretical results...
503"
REFERENCES,0.9513888888888888,"(a) Did you state the full set of assumptions of all theoretical results? [N/A]
504"
REFERENCES,0.953125,"(b) Did you include complete proofs of all theoretical results? [N/A]
505"
REFERENCES,0.9548611111111112,"3. If you ran experiments...
506"
REFERENCES,0.9565972222222222,"(a) Did you include the code, data, and instructions needed to reproduce the main experi-
507"
REFERENCES,0.9583333333333334,"mental results (either in the supplemental material or as a URL)? [Yes] We include all
508"
REFERENCES,0.9600694444444444,"the information required to reproduce our experimental results in Section 4.
509"
REFERENCES,0.9618055555555556,"(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they
510"
REFERENCES,0.9635416666666666,"were chosen)? [Yes] All the training details are mentioned in Section 4.
511"
REFERENCES,0.9652777777777778,"(c) Did you report error bars (e.g., with respect to the random seed after running experi-
512"
REFERENCES,0.9670138888888888,"ments multiple times)? [Yes] We reported error bars in the tables in Section 4.
513"
REFERENCES,0.96875,"(d) Did you include the total amount of compute and the type of resources used (e.g., type
514"
REFERENCES,0.9704861111111112,"of GPUs, internal cluster, or cloud provider)? [Yes] They are reported in Appendix.
515"
REFERENCES,0.9722222222222222,"4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
516"
REFERENCES,0.9739583333333334,"(a) If your work uses existing assets, did you cite the creators? [Yes] We cited all the
517"
REFERENCES,0.9756944444444444,"creators for the assets we use throughout our paper.
518"
REFERENCES,0.9774305555555556,"(b) Did you mention the license of the assets? [N/A]
519"
REFERENCES,0.9791666666666666,"(c) Did you include any new assets either in the supplemental material or as a URL? [No]
520"
REFERENCES,0.9809027777777778,"(d) Did you discuss whether and how consent was obtained from people whose data you’re
521"
REFERENCES,0.9826388888888888,"using/curating? [Yes] We use the data widely used in the field related to our work.
522"
REFERENCES,0.984375,"(e) Did you discuss whether the data you are using/curating contains personally identifiable
523"
REFERENCES,0.9861111111111112,"information or offensive content? [N/A]
524"
REFERENCES,0.9878472222222222,"5. If you used crowdsourcing or conducted research with human subjects...
525"
REFERENCES,0.9895833333333334,"(a) Did you include the full text of instructions given to participants and screenshots, if
526"
REFERENCES,0.9913194444444444,"applicable? [N/A]
527"
REFERENCES,0.9930555555555556,"(b) Did you describe any potential participant risks, with links to Institutional Review
528"
REFERENCES,0.9947916666666666,"Board (IRB) approvals, if applicable? [N/A]
529"
REFERENCES,0.9965277777777778,"(c) Did you include the estimated hourly wage paid to participants and the total amount
530"
REFERENCES,0.9982638888888888,"spent on participant compensation? [N/A]
531"
