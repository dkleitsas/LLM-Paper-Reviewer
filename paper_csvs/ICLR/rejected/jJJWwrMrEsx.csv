Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0028169014084507044,"With the expanding role of neural networks, the need for formal veriﬁcation of their behav-
ior, interpretability and human post-processing has become critical in many applications.
In 2018, it has been shown that Binary Neural Networks (BNNs) have an equivalent repre-
sentation in boolean logic and can be formally analyzed using logical reasoning tools such
as SAT or MaxSAT solvers. This formulation is powerful as it allows us to address a vast
range of questions: existential, probabilistic, explanation generation, etc. However, to date,
only BNNs can be transformed into a SAT formula and their strong binary constraints limit
their natural accuracy. Moreover, the corresponding SAT conversion method intrinsically
leads to formulas with a large number of variables and clauses, impeding interpretability
as well as formal veriﬁcation scalability. In this work, we introduce Truth Table Deep
Convolutional Neural Networks (TT-DCNNs), a new family of SAT-encodable models
featuring real-valued weights and real intermediate values as well as a highly interpretable
conversion method. The TT-DCNN architecture enables for the ﬁrst time all the logical
classiﬁcation rules to be extracted from a performant neural network which can be then
easily interpreted by anyone familiar with the domain. Therefore, this allows integrating
human knowledge in post-processing as well as enumerating all possible inputs/outputs
prior to deployment in production. We believe our new architecture paves the way between
eXplainability AI (XAI) and formal veriﬁcation. First, we experimentally show that TT-
DCNNs offer a better tradeoff between natural accuracy and formal veriﬁcation than BNNs.
Then, in the robustness veriﬁcation setting, we demonstrate that TT-DCNNs outperform
the veriﬁable accuracy of BNNs with a comparable computation time. Finally, we also
drastically decrease the number of clauses and variables, enabling the usage of general SAT
solvers and exact model counting solvers. Our developed real-valued network has general
applications and we believe that its demonstrated robustness constitutes a suitable response
to the rising demand for functional formal veriﬁcation."
INTRODUCTION,0.005633802816901409,"1
INTRODUCTION"
INTRODUCTION,0.008450704225352112,"Deep Neural Network (DNN) systems offer exceptional performance in a variety of difﬁcult domains
(Goodfellow et al., 2016) and today these results far outstrip our ability to secure and analyze those DNNs.
As DNNs are becoming widely integrated in a variety of applications, several concerns have emerged: lack
of robustness emphasized by a lack of explainability, difﬁculty of integrating human knowledge in post-
processing and impossibility to formally verify their behavior due to their large complexity. Under these
circumstances and especially when these systems are deployed in applications where safety and security
are issues, the formal veriﬁcation of DNN systems and the ﬁeld of eXplainable AI (XAI) are under intense
research efforts. For example, Tesla has recently ﬁled a patent on the DNNs’ portability on a platform"
INTRODUCTION,0.011267605633802818,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.014084507042253521,"incorporating a component dedicated to formal veriﬁcation (Driscoll, 2020). Also, the European Union’s
general data protection regulation includes a provision on the explainability of AIs (Regulation, 2016)."
INTRODUCTION,0.016901408450704224,"DNNs formal veriﬁcation methods are mainly based either on Satisﬁability Modulo Theory (SMT) (Katz
et al., 2017) or Mixed-Integer Programming (MIP) (Xiao et al., 2018) which are not yet scalable to real-valued
DNNs. Some recent publications (Jia & Rinard (2020);Narodytska et al. (2019b); Narodytska et al. (2018))
approach the problem of complete veriﬁcation from the well-known boolean SATisﬁability (SAT) (Biere
et al., 2009) point of view where Binary Neural Networks (BNNs, Hubara et al. (2016)) are ﬁrst converted
into SAT formulas and then formally veriﬁed using SAT or MaxSAT solvers. This pipeline is computationally
efﬁcient (Jia & Rinard, 2020), enables security veriﬁcations (Baluta et al., 2019) and more generally can
answer a vast range of question such as how many adversarial attacks exist for a given DNN, image and noise
level (Narodytska et al., 2019a). Besides, this approach is faster than SMT or MIP robustness veriﬁcation
method (Jia & Rinard, 2020). However, to date, only BNNs can be transformed into a SAT formula and their
strong binary constraints limit their natural accuracy. Moreover, the corresponding SAT conversion method
intrinsically leads to formulas with a large number of variables and clauses, impeding interpretability as well
as formal veriﬁcation scalability. Finally, only few studies (Ignatiev et al. (2019a) ; Ignatiev et al. (2019b))
investigated the relationship between formal DNNs’ veriﬁcation and XAI."
INTRODUCTION,0.01971830985915493,"Our contributions.
In this work, we offer three main contributions. (1) First, we deﬁne a new family of
real-valued Deep Convolutional Neural Networks (DCNN) that can be encoded into SAT formulas: Truth
Table Deep Convolutional Neural Network (TT-DCNN). Our TT-DCNN leverages its model formulation
in the form of a truth table to allow weights and certain intermediate values to be real. To the best of our
knowledge, this is the ﬁrst method to encode a real-valued DCNN into SAT. For the ﬁrst time, we can extract
all the logic classiﬁcation rules from a subfamily of DCNNs which allows a bridge between XAI and formal
veriﬁcation, while achieving sufﬁcient natural accuracy for practical use. Indeed, the nature of the SAT
conversion between TT-DCNN and BNN is intrinsically different: our method relies upon giving one SAT
expression per 2D-CNN ﬁlter instead of one SAT expression per neuron. This global interpretability method
is in sharp contrast with the previous limited BNNs and local DNNs explainability. (2) TT-DCNNs offer
two main valuable conversion properties over BNNs. (2-a: Post-tuning) The ﬁrst one allows us to integrate
human knowledge in the post-processing: we can now interpret the model inference with simple concepts,
which enables to manually modify the 2D-CNN ﬁlter activation towards a desired goal. For example, we
decided to focus on reducing overﬁtting and, to this end, we characterize TT-DCNN logic rules resulting from
overﬁtting and propose a ﬁltering approach, which increases the veriﬁable accuracy without decreasing the
natural accuracy (cf. Appendix A.1). (2-b: Tractability) The second property is the possibility to compute
all possible model inputs/outputs prior to deployment in production. In an adversarial setting, we can assess
whether the input noise will propagate to the output. We can therefore disregard ﬁlters with no impact on the
output. This leads to a lower number of clauses and variables in the SAT formulas compared to BNNs which
allows using generic SAT solvers and exact model counting solvers. (3) We apply our model to complete
robustness veriﬁcation (cf. Appendix A.1). TT-DCNNs offer a good tradeoff between the state-of-the-art
of BNN/SAT method (Jia & Rinard, 2020) and of real-valued DNN/MILP complete robustness veriﬁcation
methods (Xiao et al. (2018); Tjeng et al. (2017)). This is expected as our network is both real-weighted
and SAT-convertible. Our TT-DCNN model improves the veriﬁable accuracy by more than 2.5% for high
noise MNIST and by 0.5% for the high noise of CIFAR10 when compared to BNN/SAT method while
decreasing the veriﬁcation time by a factor of 9 for MNIST and 150 for CIFAR10 high noise when compared
to DNN/MILP methods. Finally, our SAT formulas are 5 and 9 times more compact in term of number of
clauses for high noise MNIST and CIFAR10 respectively compared to the BNN/SAT method."
INTRODUCTION,0.022535211267605635,"Outline.
Section 2 introduces the notations and the related work. Section 3 presents our new TT-DCNN
model and its two main properties. Section 4 details the complete robustness veriﬁcation set-up and reports
the evaluation results. Finally, we conclude this work in Section 5."
INTRODUCTION,0.02535211267605634,Under review as a conference paper at ICLR 2022
BACKGROUND & RELATED WORK,0.028169014084507043,"2
BACKGROUND & RELATED WORK"
BACKGROUND & RELATED WORK,0.030985915492957747,"Boolean SATisﬁability (SAT).
The boolean SATisﬁability problem (SAT) (Biere et al., 2009) is the problem
of deciding whether there exists a variable assignment to satisfy a given boolean expression Φ. We can
consider a boolean expression in a Conjunctive Normal Form (CNF) or in a Disjunctive Normal Form (DNF).
They are both deﬁned over a set of boolean variables (x1, · · · , xn). A literal li is deﬁned as a variable xi or
its complement xi. A CNF is a conjunction of a set of clauses: Φ = (c1 ∧· · · ∧cm), where each clause cj is a
disjunction of some literals cj = lj1∨· · ·∨ljr. A DNF is a disjunction of a set of clauses: Φ = (c1∨· · ·∨cm),
where each clause cj is a conjunction of some literals cj = lj1 ∧· · · ∧ljr. A pseudo-boolean constraint is a"
BACKGROUND & RELATED WORK,0.03380281690140845,"constraint of the form:
N
P"
BACKGROUND & RELATED WORK,0.036619718309859155,"p=1
aplp ◦b, where ap ∈Z, b ∈Z and ◦∈{≤, =, ≥}, which can be mapped to a SAT"
BACKGROUND & RELATED WORK,0.03943661971830986,"formula (Roussel & Manquinho, 2009). However, the output SAT formula contains a tremendous number
of clauses and literals compared to the number of variables in the pseudo-boolean constraint making it very
hard to understand (cf. example in Appendix A.2). A boolean function has the form {0, 1}n →{0, 1} and its
corresponding truth table gives outputs for all possible inputs combinations."
BACKGROUND & RELATED WORK,0.04225352112676056,"Two-dimensional Convolutional Neural Networks (2D-CNNs).
We consider the 2D-CNN as a function
Φf, which, for a given ﬁlter f, takes n = k2c inputs at position (i, j) with k the kernel size and c the number
of input channels. The outputs can be written y(i,j)
f
= Φf(x(i,j)
1
, · · · , x(i,j)
n
). Note that in the binary case, a
truth table between inputs and outputs for 2n entries can be easily set up (if n is not too large). If we now
consider a multi-layers network with s convolution layers : a similar truth table can be constructed, except
now the kernel size k needs to be replaced by a patch function P(s) (also referred to as the size of a receptive
ﬁeld in the literature). We have P(1) = k and P(s + 1) = P(s) if and only if the kernel size of the layer is 1.
We denote by P(s, i, j), the receptive ﬁeld after the sth layer at position (i, j). We denote the vector obtained
after the ﬂatten operation and before the ﬁnal classiﬁer layer as the vector of features V . If there are a total of
L layers in the DNN, each element of V is a non-linear function over a patch (P(L), P(L)) on the input."
BACKGROUND & RELATED WORK,0.04507042253521127,"SAT encoding of neural networks.
The sole published method converting a DNN into a SAT formula is
limited to BNNs (Narodytska et al. (2018); Cheng et al. (2018)) and involves recomposing a block formed
of a 2D-CNN layer, a batch normalization layer and a step function into an inequality in order to apply the
pseudo-boolean constraint (Roussel & Manquinho, 2009). This approach has been further reﬁned using a
different training method and a speciﬁc SAT solver resulting in a signiﬁcantly reduced veriﬁcation resolution
time (Jia & Rinard, 2020). Although the proposed inequality rewriting is elegant, the corresponding SAT
formula contains a tremendous number of clauses and literals compared to the number of variables in
the pseudo-boolean constraint (cf. example Appendix A.2). This prevents both the interpretability and
the tractability of those SAT/BNNs formulas. Hence, our goal is to ﬁnd a real-valued DCNN with good
performance and coincidentally convertible to SAT with fully interpretive inference."
BACKGROUND & RELATED WORK,0.04788732394366197,"Interpretability by global rule extraction.
Machine learning interpretability analysis fall into four main
categories: either local (input dependant) or global methods, either exact or non-exact methods. The most
famous techniques for local non-exact interpretability are LIME and the ANCHOR explainers (Ribeiro et al.
(2016); Ribeiro et al. (2018)). PI-explanations (Shih et al., 2018) and SHAP (Lundberg & Lee, 2017) are
also popular techniques for local exact method and global non-exact method respectively. The only scalable
method for global exact interpretability was proposed in (Granmo et al., 2019). Our work aims to extend the
studies of the latter strategy with the use of truth tables in order to obtain the equivalent conjectures. Using
truth tables in machine learning has been documented for hardware optimisation (Soga & Nakahara (2020),
Wang et al. (2019)) and recently in an attempt for global non-exact interpretation of BNNs (Burkhardt et al.,
2021). Our work is pioneer in the use of truth table to create a new architecture enabling the extraction of all
the global exact logic rules as well as the increase of model robustness for formal veriﬁcation."
BACKGROUND & RELATED WORK,0.05070422535211268,Under review as a conference paper at ICLR 2022
BACKGROUND & RELATED WORK,0.05352112676056338,"3
TRUTH TABLE DEEP CONVOLUTION NEURAL NETWORK (TT-DCNN)"
BACKGROUND & RELATED WORK,0.056338028169014086,"In an attempt to address the currently identiﬁed drawbacks of the low interpretability and the high encoding
complexity of the SAT formulas of the BNN’s transformation process, we designed a new DNN architecture.
Our TT-DCNN model is developed ﬁrst as a DCNN with real-valued weights and some intermediate real
values encodable into SAT. Secondly, TT-DCNN is interpretable: each feature can be understood as an
indicator function. In fact, the feature associated to the ﬁlter f is equal to 1 if there exists a mask M in the set
of masks Sf that matches the input patch, 0 otherwise (we will deﬁne later what are a mask, a set of masks
and the matching operator). We emphasize that our formulation is a new paradigm: there is no longer any
need for the DNNs in production. Since the knowledge of the TT-DCNN is reduced to the set Sf for all ﬁlters,
we no longer need the model after the training. To the best of our knowledge, this is the ﬁrst time that the
exact knowledge of a real-valued DCNN is formally extracted. Finally, we will show that this formulation
gives the user two major degrees of freedom: post-tuning and tractability."
BACKGROUND & RELATED WORK,0.059154929577464786,"Brieﬂy, our model considers an image with three channels and ﬂoating-point inputs, while being composed of
only one block of 2D-CNN as deﬁned in Section 3.2. In order to convert the image into binary inputs, we
incorporate a preprocessing layer before this block. Finally, we include a ﬁnal linear layer after the 2D-CNN
block to perform classiﬁcation. For clarity sake, we will present our new TT-DCNN model in a stepwise
fashion with increasing complexity using illustrative examples and a companion video 1. We will initially
analyse a 2D-CNN layer with a single ﬁlter (Section 3.1). Next, we will deﬁne a block of our TT-DCNN
architecture (Section 3.2). Finally, Sections 3.3 and 3.4 present the whole architecture of the TT-DCNN and
its main properties, respectively."
BACKGROUND & RELATED WORK,0.061971830985915494,"3.1
SAT ENCODING OF A ONE-LAYER 2D-CNN"
BACKGROUND & RELATED WORK,0.0647887323943662,"For this ﬁrst building block, we consider as input a binary image with one channel and as a model a trained
DCNN with only one layer. We ﬁrst start to encode one ﬁlter."
BACKGROUND & RELATED WORK,0.0676056338028169,"One ﬁlter.
The main idea is to ﬁx the number of possible outputs of the 2D-CNN by ﬁxing the number of
its possible inputs, which will allow to test all possible combinations. Following the notations introduced in
Section 2, we have as output y(i,j)
binary,f, for the ﬁlter f:"
BACKGROUND & RELATED WORK,0.07042253521126761,"y(i,j)
binary,f = Bin(y(i,j)
f
) = Bin(Φf(x(i,j)
1
, · · · , x(i,j)
n
))
(1)"
BACKGROUND & RELATED WORK,0.07323943661971831,"with Bin being the Heaviside step function, deﬁned as Bin(x) = 1"
BACKGROUND & RELATED WORK,0.07605633802816901,2 + sgn(x)
BACKGROUND & RELATED WORK,0.07887323943661972,"2
. If xj ∈{0, 1}, we can
establish the truth table of the 2D-CNN’s ﬁlter f by trying all the possible inputs, for a total of 2n operations.
In this paper, we will limit ourselves to n ≤9. Hence, in 29 = 512 operations, we can trivially generate our
truth table. Then, we can convert the truth table into a simpliﬁed SAT formula and by doing so we can rewrite
Equation 1 as:"
BACKGROUND & RELATED WORK,0.08169014084507042,"y(i,j)
binary,f = SATDNF
f
(x(i,j)
1
, · · · , x(i,j)
n
) = SATCNF
f
(x(i,j)
1
, · · · , x(i,j)
n
)"
BACKGROUND & RELATED WORK,0.08450704225352113,"with SATDNF
f
(resp. SATCNF
f
) being the formal expression of the ﬁlter in the DNF form (resp. CNF form).
It is noteworthy that unlike previous works, our approach is not limited to binary weights but allows for
arbitrary weights within the 2D-CNN."
BACKGROUND & RELATED WORK,0.08732394366197183,"Example.
We consider a 2D-CNN with one ﬁlter and a kernel size of 2, with the weights: W1 =

10
−1
3
−5"
BACKGROUND & RELATED WORK,0.09014084507042254,"
.
As c = 1, we have X
=

x0
x1
x2
x3"
BACKGROUND & RELATED WORK,0.09295774647887324,"
and the sixteen possible entries are:

0
0
0
0 
,"
BACKGROUND & RELATED WORK,0.09577464788732394,1Link video: https://youtu.be/loGlpVcy0AI
BACKGROUND & RELATED WORK,0.09859154929577464,Under review as a conference paper at ICLR 2022
BACKGROUND & RELATED WORK,0.10140845070422536,"
0
0
0
1"
BACKGROUND & RELATED WORK,0.10422535211267606,"
,

0
0
1
0"
BACKGROUND & RELATED WORK,0.10704225352112676,"
,

0
0
1
1"
BACKGROUND & RELATED WORK,0.10985915492957747,"
, · · · ,

1
1
0
1"
BACKGROUND & RELATED WORK,0.11267605633802817,"
,

1
1
1
1"
BACKGROUND & RELATED WORK,0.11549295774647887,"
. For each input, we calculate the corresponding output:"
BACKGROUND & RELATED WORK,0.11830985915492957,"y = [0, −5, 3, −2, −1, −5, 3, −2, 10, 5, 13, 8, 9, 4, 12, 7]. After binarization with the Heaviside step func-
tion, we have ybinary = [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]. Therefore, after simpliﬁcation, we have
SATDNF
1
= (x2 ∧x3) ∨x0 and SATCNF
1
= (x2 ∨x0) ∧(x3 ∨x0)."
BACKGROUND & RELATED WORK,0.12112676056338029,"Multiple ﬁlters.
For multiple ﬁlters, the above described method is simply repeated for each individual
ﬁlter, thus yielding one expression per ﬁlter."
BACKGROUND & RELATED WORK,0.12394366197183099,"Multiple channels.
As convolutional networks generally take several channels as input (3 for RGB images
or more for intermediate 2D-CNNs) the number of input variables can therefore greatly increase. A 2D-CNN
that takes 32 input channels with a kernel size of 2 yields an input of size 128, well above our limit set at
n = 9. To overcome this, we gather the channels by groups (Dumoulin & Visin, 2016). Grouped convolutions
divide the input channels into g groups, then apply separate convolutions within each group; this effectively
decreases the number of inputs to each individual ﬁlter by a factor of g. We have in that case n = k2c/g.
Thus, in the above example, by using 16 groups, the number of inputs to our truth tables becomes 32"
BACKGROUND & RELATED WORK,0.1267605633802817,16 ×22 = 8.
BACKGROUND & RELATED WORK,0.1295774647887324,"Limits.
At this point of the model development and despite the real-valued weights, we observe sub-optimal
performances due to the group parameters. When we add an extension layer, as detailed in the next subsection,
to increase the learning capacity of the DCNN without augmenting the size of the patches seen by the DCNN
(Sandler et al., 2018), we experience an improvement of about 5% of natural accuracy. Please refer to Table 8
of Appendix A.9.2 for detailed results."
BACKGROUND & RELATED WORK,0.1323943661971831,"3.2
SAT ENCODING OF A TWO-LAYERS 2D-CNN: ONE BLOCK OF TT-DCNN"
BACKGROUND & RELATED WORK,0.1352112676056338,"Ampliﬁcation layer.
In the previous subsection, we pointed out that only the 2D-CNN input size matters
when establishing the 2D-CNN SAT expression. Therefore, we can add a second layer as long as we do
not increase the patch size. This can be simply achieved by adding a layer with kernel size 1. Note that the
intermediate values from the ﬁrst layer do not need to be binary anymore. From a practical standpoint, using
eight ﬁlters in layer one and one ﬁlter in layer two, drastically improves the learning capacity of the TT-DCNN
and therefore the natural accuracy as well. This observation is consistent with other published studies (Sandler
et al., 2018). A block is therefore composed of two 2D-CNN layers with a so-called ampliﬁcation parameter
which corresponds to the ratio between the number of ﬁlters of the ﬁrst layer and the number of ﬁlters of the
second layer (value often set at 8). Each layer is followed by a batch normalisation and a non-linear activation
function: ReLU for the ﬁrst layer and Heaviside step function for the second one."
THE TT-DCNN ARCHITECTURE,0.13802816901408452,"3.3
THE TT-DCNN ARCHITECTURE"
THE TT-DCNN ARCHITECTURE,0.14084507042253522,"Having deﬁned one block of 2D-CNN in the previous section, we may now examine how this block is
integrated into the TT-DCNN. The overall architecture is presented in Appendix A.3.1"
THE TT-DCNN ARCHITECTURE,0.14366197183098592,"Preprocessing layer.
DCNNs inputs are usually ﬂoating points. However, encoding ﬂoating points in SAT
typically implies high complexity. In order to simplify the veriﬁcation process and improve the network
robustness, we applied a three steps ﬁrst-layer or pre-processing procedure: (i) Quantitation of inputs (Jia
& Rinard, 2020); (ii) Batch normalization (Narodytska et al., 2019b); and (iii) Step Function. Details are
presented in Appendix A.3.2."
THE TT-DCNN ARCHITECTURE,0.14647887323943662,"Final layer.
TT-DCNN uses a single linear layer as a classiﬁer block. It is straightforward to grasp, even for
non-experts and it can be easily encoded into SAT using pseudo-boolean constraint as detailed in Section 2"
THE TT-DCNN ARCHITECTURE,0.14929577464788732,Under review as a conference paper at ICLR 2022
THE TT-DCNN ARCHITECTURE,0.15211267605633802,"as long as the weights are integers numbers. As shown in (Jia & Rinard, 2020), we also incorporate batch
normalization after the last layer for improving test accuracy. Please refer to Appendix A.3.3 for more details."
INTERPRETATION OF OUR TT-DCNN MODEL AND TWO IMPORTANT PROPERTIES,0.15492957746478872,"3.4
INTERPRETATION OF OUR TT-DCNN MODEL AND TWO IMPORTANT PROPERTIES"
INTERPRETATION OF OUR TT-DCNN MODEL AND TWO IMPORTANT PROPERTIES,0.15774647887323945,"Interpretation.
To illustrate the ease of interpretability of our conversion method, we now offer an in-
terpretation of the SAT formula of the ﬁlter with weight matrix W1 deﬁned in the example of Section 3.1:
SATDNF
1
= (x3 ∧x2) ∨x0. First of all, we can observe that the expression is now independent of the value of
x1. Then, because the formula is a DNF, we observe that there are two conditions to activate the feature. We"
INTERPRETATION OF OUR TT-DCNN MODEL AND TWO IMPORTANT PROPERTIES,0.16056338028169015,"can deﬁne the set of masks S1 = {M1, M2} with M1 =

N
N
1
0"
INTERPRETATION OF OUR TT-DCNN MODEL AND TWO IMPORTANT PROPERTIES,0.16338028169014085,"
and M2 =

1
N
N
N"
INTERPRETATION OF OUR TT-DCNN MODEL AND TWO IMPORTANT PROPERTIES,0.16619718309859155,"
, corresponding to"
INTERPRETATION OF OUR TT-DCNN MODEL AND TWO IMPORTANT PROPERTIES,0.16901408450704225,"the clause x2 ∧x3 and x0 respectively, with N denoting Null. We can observe that if one of the two masks
""matches"" the patch of the image, the feature corresponding to the patch position (i, j) will be activated.
By ""matching"", an operation denoted as ≡, we consider that the Null position does not matter (i.e. it can
be either a 0 or a 1) and that only the 0 and 1 positions should exactly match the 0 and 1 positions of the
transformed binary input in order to activate the feature. A formal deﬁnition of the operator ≡is given in
Appendix A.4. The features for ﬁlter 1 are therefore indicator functions in the case of our model."
INTERPRETATION OF OUR TT-DCNN MODEL AND TWO IMPORTANT PROPERTIES,0.17183098591549295,"More generally, from the SATDNF
f
expression we can establish Sf, the set of masks for ﬁlter f. Then, the
value V at position (i, j), for ﬁlter f is:"
INTERPRETATION OF OUR TT-DCNN MODEL AND TWO IMPORTANT PROPERTIES,0.17464788732394365,"V (f, i, j) =
1
if ∃M ∈Sf such that P(L, i, j) ≡M
0
otherwise"
INTERPRETATION OF OUR TT-DCNN MODEL AND TWO IMPORTANT PROPERTIES,0.17746478873239438,"In our example with f = 1, the feature V (1, i, j) would be activated if P(L, i, j) ≡M1 or P(L, i, j) ≡M2.
As V is the feature vector before the last classiﬁcation layer, the result for each class becomes a weighted
sum of these indicator functions. For a particular class, these features add up in a weighted way. This means
that these sets either participate in favor of the class (positive weight) or against (negative weight) or are
independent (weight equals zero). The knowledge of the TT-DCNN therefore resides in Sf. The existence and
the analysis of Sf creates a strong link between XAI and formal veriﬁcation. To the best of our knowledge,
this is the ﬁrst time that all these masks are formulated and extracted for real-valued DCNNs. The fact that all
the masks can be exhaustively given leads to two main properties of TT-DCNN: post-tuning and tractability."
INTERPRETATION OF OUR TT-DCNN MODEL AND TWO IMPORTANT PROPERTIES,0.18028169014084508,"Two important properties: post-tuning and tractability.
After the training, we can modify the set of
learned masks Sf for a speciﬁc purpose. We will see in the next section how we can build a heuristic to
characterize overﬁtting masks, how we can remove them and therefore increase the overall robustness of our
model by hand. Another particularity of this architecture is that we can calculate all the possible inputs/outputs
of the 2D-CNN block. The Section 4 describes the application of the latter feature to drastically decrease the
SAT complexity and therefore enabling the use of a general SAT-solver and an exact model counting solver."
EXPERIMENTS,0.18309859154929578,"3.5
EXPERIMENTS"
EXPERIMENTS,0.18591549295774648,"Results.
Our aim is to provide a fully interpretable SAT-convertible model with high natural accuracy.
Table 6 compares the performance of a given real-valued DCNN with its corresponding TT-DCNN and BNN
(cf. results and architectures in Appendix A.9.1). As expected, this TT-DCNN gives better natural accuracy
than BNN (+1.37% for MNIST, +0.57% for CIFAR10) but inferior than the original DCNN (-0.14% for
MNIST, -12.05% for CIFAR10). By increasing the truth table dimension n to 27, the gap with the BNN
performances increases: +1.49% for MNIST, +4.05% for CIFAR10. Those results show that our network
achieves sufﬁcient accuracy for practical use. A summary comparison between BNN, DCNN and TT-DCNN
is given in Table 7."
EXPERIMENTS,0.18873239436619718,Under review as a conference paper at ICLR 2022
EXPERIMENTS,0.19154929577464788,"Limits and further works.
Our results look promising for further scaling up, by adding a block layer or/and
increasing the truth table dimension (for n ≥10). We could also attempt using a probability function instead
of an indicator function in order to increase interpretability. We could also propose more interpretable sets Sf.
For instance, before using the MNIST dataset, we could force training ﬁlters with relevant geometrical shapes
(arc of circle, circle, line etc.). Ideally, it should be possible to give theoretical masks according to the dataset
or to the problem."
EXPERIMENTS,0.19436619718309858,"Conclusion.
We have described the TT-DCNN architecture, its encoding and main properties. We then
compared our model in the exact veriﬁcation ﬁeld as done previously (Narodytska et al. (2018); Narodytska
et al. (2019b); Jia & Rinard (2020)). We will show that the TT-DCNN post-tuning and tractability properties
are not just theoretical. The ﬁrst feature addresses the question of how to inject human feedback into a model.
The second leads to SAT formulas that can be solved by classic SAT solvers and exact model counting. In
doing so, we improve the previous state-of-the-art of SAT complete neural network robustness veriﬁcation for
high and low noise levels."
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.19718309859154928,"4
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2,"We previously described the TT-DCNN architecture, its encoding and main properties. We have established
that our model gives the user the freedom to modify the set of fully explicit masks Sf for all ﬁlters f and to
pre-compute all possible outputs of the TT-DCNN before proceeding to production. In this section, we show
how to use the ﬁrst property to address a very general problem: adding domain knowledge into a trained
TT-DCNN. Namely, we wish to reduce the model overﬁtting part in order to increase the veriﬁable accuracy
without modifying the natural accuracy. To do so, we ﬁrst propose a characterization of the masks responsible
for the overﬁtting of the TT-DCNN followed by a very simple suppression process. Finally, we will see how
the tractability property decreases the ﬁnal layer encoding size. We validate our approach by testing several
performance metrics of our model in comparison with other speciﬁc state-of-the art models."
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2028169014084507,"4.1
POST-TUNING: CHARACTERIZING AND FILTERING OVERFITTING MASKS"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2056338028169014,"General.
One may envision the set Sf as a bag full of masks. Upon training, this set is ﬁxed such that it can
be considered as the TT-DCNN knowledge. Since we have made these masks explicit (see Section 3.4), we
may then modify them for a speciﬁc purpose. Drawing on the example of Section 3.4, we can consider that"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2084507042253521,"the mask M2 =

1
N
N
N"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2112676056338028,"
is too general and decide to remove it from the set S1. By doing so, we modify the"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2140845070422535,activation of ﬁlter 1 by integrating human knowledge in post-tuning.
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.21690140845070421,"Characterizing overﬁtting masks.
A mask is considered as an overﬁtting mask if the ratio of the number
of Null values over the total number of variables in the mask is below a certain threshold (cf Appendix A.6).
Indeed, the less Null values in the mask, the more constraints on the input image there are, which hinders
the model to generalize properly. The extreme case of the zero ratio means that the ﬁlter is only active if the
patch exactly overlaps the mask. Therefore, by changing only one bit, we can deactivate that mask."
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.21971830985915494,"Deleting overﬁtting masks.
First, we remove the overﬁtting tagged masks deﬁned above with a given
Null ratio. Then, among the remaining masks, we tag as additional overﬁtting masks those having the
minimum Null ratio in the formula. Finally, we apply a random Bernoulli process to partially delete tagged
masks. This technique increases the veriﬁable accuracy of the TT-DCNN models trained on CIFAR10: from
22.79% to 23.08%, without affecting the natural accuracy: from 31.18% to 31.13%. The results are shown in
Table 1."
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.22253521126760564,Under review as a conference paper at ICLR 2022
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.22535211267605634,"4.2
TRACTABILITY: ENCODING THE ADVERSARIAL SETUP INTO SAT"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.22816901408450704,"General.
Another feature of the TT-DCNN’s architecture is that one can calculate all the possible in-
puts/outputs of the 2D-CNN block before using the model in production."
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.23098591549295774,"Encoding pixel noise.
Let us consider some noise (e.g. norm-bounded by l∞) added to the input image
prior binarization. After the preprocessing layer, a binarized pixel may either remain unchanged by the
perturbation and so ﬁxed as 0 or 1, or it may ﬂip (from 0 to 1 or from 1 to 0) and hence we consider them
""unknown"", further denoted as U. Let us see how this unknown binarized pixel can be integrated in the
example of Section 3.4. As there are 4 entries, there are 34 = 81 input possibilities for the block level in"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.23380281690140844,"an adversial/production setting due to noise:

0
0
0
0"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.23661971830985915,"
,

0
0
0
1"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.23943661971830985,"
,

0
0
0
U"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.24225352112676057,"
, · · · ,

U
U
U
U"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.24507042253521127,"
. More generally, as"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.24788732394366197,"the maximum number of variables for the SAT entry was set to n = 9 in this paper, there are therefore a
maximum of 39 = 19683 input possibilities for our TT-DCNN . Those unknown binarized pixels are therefore
the ﬁrst literals of our SAT equation: they are the gateway to noise propagation."
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2507042253521127,"Noise propagation at the block level.
In order to encode noise propagation through blocks, we encode in
SAT the input/output relationship y(i,j)
f
= SATCNF
f
(x(i,j)
1
, · · · , x(i,j)
n
) for all (i, j) and f. For example, for"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2535211267605634,"the ﬁlter 1 SATDNF
1
= (x2 ∧x3) ∨x0, the entry

0
1
0
U"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2563380281690141,"
gives x3 = U as output. The latter result depends"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2591549295774648,"on U, whereas the input

0
U
0
0"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2619718309859155,"
gives 0 (whatever U is). Hence, there are two noticeable cases: either"
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2647887323943662,"U propagates through the block (case 1), either it does not (case 2). This example of pre-calculation of
inputs/outputs illustrates the superior feature of our model allowing to know precisely how the noise will
propagate. This comes in sharp contrast with the currently available BNN model where one has to consider
that the noise propagates through the layers in both cases."
APPLICATION TO COMPLETE ROBUSTNESS VERIFICATION,0.2676056338028169,"Encoding the attack at the ﬁnal layer level.
Ultimately, for the ﬁnal layer, we encode ri,j = yi −yj > 0
as a reiﬁed cardinality constraint which denotes whether the score of class i is higher than the score of class
j. Being able to distinguish between known and unknown elements of the feature V of the image allows
us to reduce signiﬁcantly the size of the SAT formulas when compared to current state-of-the-art models.
Looking at MNIST high noise for instance, our SAT equation yields on average 4K clauses and 1K variables
(Table 1). This is a substantial improvement over previously published works where (Jia & Rinard, 2020) has
21K clauses and 48K variables and where (Narodytska et al., 2019b) reported at least 20K clauses and 8K
variables. Similar trends were observed with CIFAR10 noise (Table 1). The drastic reduction in the size of
SAT formulas renders our model truly amenable to formal veriﬁcation. Indeed, our SAT veriﬁcation step is
much more tractable for general SAT solvers and exact model counting solvers."
EXPERIMENTS,0.2704225352112676,"4.3
EXPERIMENTS"
EXPERIMENTS,0.27323943661971833,"Untargeted attack.
Table 1 presents gathered results for natural accuracy, veriﬁable accuracy for l∞-norm
bounded input perturbations, veriﬁcation time and the average number of clauses and variables in the SAT
formulas on MNIST and CIFAR10. We compare our work with the state-of-the-art of exact veriﬁcation for
BNNs (Jia & Rinard, 2020) and for real-valued networks (Xiao et al. (2018); Tjeng et al. (2017)). We present
model architectures details and experimental settings in Appendix A.3.1 and A.6. Table 1 shows that our
model after ﬁltering masks considered to be overﬁtting is more robust. Moreover, our veriﬁable accuracy is
always superior to that of the BNN and even superior to that of the real value based model in the CIFAR10
high noise case. We also show that, with a general SAT solver (here MiniCard (Lifﬁton & Maglalang, 2012)),
we reach a resolution time competitive with BNNs and much lower than the real-valued model. The latter"
EXPERIMENTS,0.27605633802816903,Under review as a conference paper at ICLR 2022
EXPERIMENTS,0.27887323943661974,"results, as proposed in (Jia & Rinard, 2020) is mainly due the fact that it is hard to formally verify ﬂoating
point errors. Thus, we reached our goals: we developed a new a model that is both highly interpretable and
competitive with the state-of-the-art. Extended comparison are given in Appendix A.7."
EXPERIMENTS,0.28169014084507044,"Table 1:
Comparison of TT-DCNN with and without ﬁltering with state-of-the-art regarding complete
adversarial robustness veriﬁcation for high noise bounded by l∞(results are reported as in the original
articles)."
EXPERIMENTS,0.28450704225352114,"Dataset and
Noise Level
Complete Veriﬁcation Method
Accuracy
Mean time
(s)
Timeout
#cls/#vars"
EXPERIMENTS,0.28732394366197184,"Veriﬁable
Natural MNIST"
EXPERIMENTS,0.29014084507042254,ϵtest = 0.1
EXPERIMENTS,0.29295774647887324,"SAT-based
TT-DCNN (Ours)
94.24%
97.77%
0.2885
0
1K/0.4K
TT-DCNN + Filtering (Ours)
94.26%
97.70%
0.3724
0
1K/0.4K"
EXPERIMENTS,0.29577464788732394,"Jia & Rinard (2020)
91.68%
97.46%
0.1115
0
21K/48K"
EXPERIMENTS,0.29859154929577464,"Real-value-based
Xiao et al. (2018)
94.33%
98.68%
5.47
0.05%
-
Tjeng et al. (2017)
95.62%
98.11%
3.52
0
- MNIST"
EXPERIMENTS,0.30140845070422534,ϵtest = 0.3
EXPERIMENTS,0.30422535211267604,"SAT-based
TT-DCNN (Ours)
79.93%
96.79 %
0.4135
0
4K/1K
TT-DCNN + Filtering (Ours)
80.36%
96.73 %
0.5722
0
4K/1K"
EXPERIMENTS,0.30704225352112674,"Jia & Rinard (2020)
77.59%
96.36%
0.1179
0
21K/48K"
EXPERIMENTS,0.30985915492957744,"Real-value-based
Xiao et al. (2018)
80.68%
97.33%
7.12
1.02%
-
Tjeng et al. (2017)
74.21%
86.60%
5.13
0
-"
EXPERIMENTS,0.3126760563380282,CIFAR10
EXPERIMENTS,0.3154929577464789,ϵtest = 2/255
EXPERIMENTS,0.3183098591549296,"SAT-based
TT-DCNN (Ours)
32.72%
40.67%
0.1988
0
0.7K/0.3K
TT-DCNN + Filtering (Ours)
33.04 %
40.62%
0.7782
0
0.7K/0.2K"
EXPERIMENTS,0.3211267605633803,"Jia & Rinard (2020)
32.18%
37.75%
0.0236
0
33K/70K"
EXPERIMENTS,0.323943661971831,"Real-value-based
Xiao et al. (2018)
45.93%
61.12%
66.08
1.86%
-"
EXPERIMENTS,0.3267605633802817,CIFAR10
EXPERIMENTS,0.3295774647887324,ϵtest = 8/255
EXPERIMENTS,0.3323943661971831,"SAT-based
TT-DCNN (Ours)
22.79%
31.18%
0.1635
0
1K/0.4K
TT-DCNN + Filtering (Ours)
23.08%
31.13%
0.3887
0
1K/0.4K"
EXPERIMENTS,0.3352112676056338,"Jia & Rinard (2020)
22.55%
35.00%
0.1781
0
9K/13K"
EXPERIMENTS,0.3380281690140845,"Real-value-based
Xiao et al. (2018)
20.27%
40.45%
60.67
2.47%
-"
EXPERIMENTS,0.3408450704225352,"Likelihood of adversarial examples.
The objective of this experiment is to demonstrate that our approach,
thanks to its tractability property, allows for the ﬁrst time the use of exact model counting techniques for low
and high noise likelihood estimation. As in (Narodytska et al., 2019b) work, we deﬁne the probability that a
perturbation is an adversarial example as the number of input perturbations that leads to an attack divided by
the total number of input perturbations. For example, for CIFAR10 high noise, the probability of running into
an attack is 16.4%, while for low noise it is 10.0%. Complementary results are given in Appendix A.8."
EXPERIMENTS,0.3436619718309859,"Limits and further works.
As it is the case with all complete verﬁcation methods, the main limitation of
TT-DCNN appears with high noise where observed veriﬁable and natural accuracies diverge siginiﬁcantly
and are very far from the computer vision state-of-the art. Further work is required to address this issue.
One direction would be to develop a pipeline with exact model counting in order to estimate the prediction
distribution of our model at a given noise level."
CONCLUSION,0.3464788732394366,"5
CONCLUSION"
CONCLUSION,0.3492957746478873,"We presented a novel architecture of SAT encodable real-valued DCNN based on truth tables. This enables a
global and exact interpretability as well as post-processing the model. It exhibits competitive performance
given low and high noise with state-of-the-art complete veriﬁcation methods on MNIST and CIFAR10. In
a world where DNNs and DCNNs will be widely embedded, the importance of completly verifying the
robustness of neural networks to input perturbations is growing. We believe that the TT-DCNN demonstrated
robustness constitutes a suitable response to the rising demand for functional formal veriﬁcation."
CONCLUSION,0.352112676056338,Under review as a conference paper at ICLR 2022
REPRODUCIBILITY,0.35492957746478876,"6
REPRODUCIBILITY"
REPRODUCIBILITY,0.35774647887323946,The project code reproducibility for can be found at this URL address2
REFERENCES,0.36056338028169016,REFERENCES
REFERENCES,0.36338028169014086,"Ignasi Abío, Robert Nieuwenhuis, Albert Oliveras, and Enric Rodríguez-Carbonell. Bdds for pseudo-boolean
constraints–revisited. In International Conference on Theory and Applications of Satisﬁability Testing, pp.
61–75. Springer, 2011."
REFERENCES,0.36619718309859156,"Teodora Baluta, Shiqi Shen, Shweta Shinde, Kuldeep S Meel, and Prateek Saxena. Quantitative veriﬁcation
of neural networks and its security applications. In Proceedings of the 2019 ACM SIGSAC Conference on
Computer and Communications Security, pp. 1249–1264, 2019."
REFERENCES,0.36901408450704226,"Armin Biere, Marijn Heule, and Hans van Maaren. Handbook of satisﬁability, volume 185. IOS press, 2009."
REFERENCES,0.37183098591549296,"Sophie Burkhardt, Jannis Brugger, Nicolas Wagner, Zahra Ahmadi, Kristian Kersting, and Stefan Kramer.
Rule extraction from binary neural networks with convolutional rules for model validation. Frontiers in
Artiﬁcial Intelligence, 4:90, 2021."
REFERENCES,0.37464788732394366,"Chih-Hong Cheng, Georg Nührenberg, Chung-Hao Huang, and Harald Ruess. Veriﬁcation of binarized neural
networks via inter-neuron factoring. In Working Conference on Veriﬁed Software: Theories, Tools, and
Experiments, pp. 279–290. Springer, 2018."
REFERENCES,0.37746478873239436,"Michael Driscoll. System and method for adapting a neural network model on a hardware platform, July 2
2020. US Patent App. 16/728,884."
REFERENCES,0.38028169014084506,"Vincent Dumoulin and Francesco Visin. A guide to convolution arithmetic for deep learning. arXiv preprint
arXiv:1603.07285, 2016."
REFERENCES,0.38309859154929576,"Niklas Eén and Niklas Sörensson. Translating pseudo-boolean constraints into sat. Journal on Satisﬁability,
Boolean Modeling and Computation, 2(1-4):1–26, 2006."
REFERENCES,0.38591549295774646,"Richard Evans, Matko Bošnjak, Lars Buesing, Kevin Ellis, David Pfau, Pushmeet Kohli, and Marek Sergot.
Making sense of raw input. Artiﬁcial Intelligence, 299:103521, 2021."
REFERENCES,0.38873239436619716,"Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http://www.
deeplearningbook.org."
REFERENCES,0.39154929577464787,"Ole-Christoffer Granmo, Sondre Glimsdal, Lei Jiao, Morten Goodwin, Christian W Omlin, and Geir Thore
Berge. The convolutional tsetlin machine. arXiv preprint arXiv:1905.09688, 2019."
REFERENCES,0.39436619718309857,"Steffen Hölldobler, Norbert Manthey, and Peter Steinke. A compact encoding of pseudo-boolean constraints
into sat. In Annual Conference on Artiﬁcial Intelligence, pp. 107–118. Springer, 2012."
REFERENCES,0.3971830985915493,"Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. Binarized neural
networks. In Proceedings of the 30th international conference on neural information processing systems,
pp. 4114–4122. Citeseer, 2016."
REFERENCES,0.4,"Alexey Ignatiev, Antonio Morgado, and Joao Marques-Silva. PySAT: A Python toolkit for prototyping
with SAT oracles. In SAT, pp. 428–437, 2018. doi: 10.1007/978-3-319-94144-8_26. URL https:
//doi.org/10.1007/978-3-319-94144-8_26."
REFERENCES,0.4028169014084507,2https://github.com/iclr2022anonymous/Truth-Table-Deep-Convolutional-Neural-Network
REFERENCES,0.4056338028169014,Under review as a conference paper at ICLR 2022
REFERENCES,0.4084507042253521,"Alexey Ignatiev, Nina Narodytska, and Joao Marques-Silva. Abduction-based explanations for machine
learning models. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 33, pp.
1511–1519, 2019a."
REFERENCES,0.4112676056338028,"Alexey Ignatiev, Nina Narodytska, and Joao Marques-Silva. On relating explanations and adversarial
examples. Advances in Neural Information Processing Systems, 32:15883–15893, 2019b."
REFERENCES,0.4140845070422535,"Kai Jia and Martin Rinard.
Efﬁcient exact veriﬁcation of binarized neural networks.
arXiv preprint
arXiv:2005.03597, 2020."
REFERENCES,0.4169014084507042,"Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer. Reluplex: An efﬁcient smt
solver for verifying deep neural networks. In International Conference on Computer Aided Veriﬁcation, pp.
97–117. Springer, 2017."
REFERENCES,0.4197183098591549,"Diederik P Kingma and Jimmy Ba.
Adam: A method for stochastic optimization.
arXiv preprint
arXiv:1412.6980, 2014."
REFERENCES,0.4225352112676056,"Mark H Lifﬁton and Jordyn C Maglalang. A cardinality solver: More expressive constraints for free. In
International Conference on Theory and Applications of Satisﬁability Testing, pp. 485–486. Springer, 2012."
REFERENCES,0.4253521126760563,"Scott M Lundberg and Su-In Lee. A uniﬁed approach to interpreting model predictions. In Proceedings of
the 31st international conference on neural information processing systems, pp. 4768–4777, 2017."
REFERENCES,0.428169014084507,"Norbert Manthey, Tobias Philipp, and Peter Steinke. A more compact translation of pseudo-boolean constraints
into cnf such that generalized arc consistency is maintained. In Joint German/Austrian Conference on
Artiﬁcial Intelligence (Künstliche Intelligenz), pp. 123–134. Springer, 2014."
REFERENCES,0.4309859154929577,"Nina Narodytska, Shiva Kasiviswanathan, Leonid Ryzhyk, Mooly Sagiv, and Toby Walsh. Verifying properties
of binarized deep neural networks. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence,
volume 32, 2018."
REFERENCES,0.43380281690140843,"Nina Narodytska, Aditya Shrotri, Kuldeep S Meel, Alexey Ignatiev, and Joao Marques-Silva. Assessing
heuristic machine learning explanations with model counting. In International Conference on Theory and
Applications of Satisﬁability Testing, pp. 267–278. Springer, 2019a."
REFERENCES,0.43661971830985913,"Nina Narodytska, Hongce Zhang, Aarti Gupta, and Toby Walsh. In search for a sat-friendly binarized neural
network architecture. In International Conference on Learning Representations, 2019b."
REFERENCES,0.4394366197183099,"Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep
learning library. Advances in neural information processing systems, 32:8026–8037, 2019."
REFERENCES,0.4422535211267606,"General Data Protection Regulation. Regulation eu 2016/679 of the european parliament and of the council
of 27 april 2016. Ofﬁcial Journal of the European Union. Available at: http://ec. europa. eu/justice/data-
protection/reform/ﬁles/regulation_oj_en. pdf (accessed 20 September 2017), 2016."
REFERENCES,0.4450704225352113,"Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. "" why should i trust you?"" explaining the
predictions of any classiﬁer. In Proceedings of the 22nd ACM SIGKDD international conference on
knowledge discovery and data mining, pp. 1135–1144, 2016."
REFERENCES,0.447887323943662,"Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. Anchors: High-precision model-agnostic explana-
tions. In Proceedings of the AAAI conference on artiﬁcial intelligence, volume 32, 2018."
REFERENCES,0.4507042253521127,"Olivier Roussel and Vasco Manquinho. Pseudo-boolean and cardinality constraints. In Handbook of
satisﬁability, pp. 695–733. IOS Press, 2009."
REFERENCES,0.4535211267605634,Under review as a conference paper at ICLR 2022
REFERENCES,0.4563380281690141,"Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. Mobilenetv2:
Inverted residuals and linear bottlenecks. In Proceedings of the IEEE conference on computer vision and
pattern recognition, pp. 4510–4520, 2018."
REFERENCES,0.4591549295774648,"Shubham Sharma, Subhajit Roy, Mate Soos, and Kuldeep S Meel. Ganak: A scalable probabilistic exact
model counter. In IJCAI, volume 19, pp. 1169–1176, 2019."
REFERENCES,0.4619718309859155,"Andy Shih, Arthur Choi, and Adnan Darwiche. A symbolic approach to explaining bayesian network
classiﬁers. arXiv preprint arXiv:1805.03364, 2018."
REFERENCES,0.4647887323943662,"Naoto Soga and Hiroki Nakahara. Design method for an lut network-based cnn with a sparse local convolution.
In 2020 International Conference on Field-Programmable Technology (ICFPT), pp. 294–295. IEEE, 2020."
REFERENCES,0.4676056338028169,"Vincent Tjeng, Kai Xiao, and Russ Tedrake. Evaluating robustness of neural networks with mixed integer
programming. arXiv preprint arXiv:1711.07356, 2017."
REFERENCES,0.4704225352112676,"Seinosuke Toda. Pp is as hard as the polynomial-time hierarchy. SIAM Journal on Computing, 20(5):865–877,
1991."
REFERENCES,0.4732394366197183,"Erwei Wang, James J Davis, Peter YK Cheung, and George A Constantinides. Lutnet: Rethinking inference
in fpga soft logic. In 2019 IEEE 27th Annual International Symposium on Field-Programmable Custom
Computing Machines (FCCM), pp. 26–34. IEEE, 2019."
REFERENCES,0.476056338028169,"Kai Y Xiao, Vincent Tjeng, Nur Muhammad Shaﬁullah, and Aleksander Madry. Training for faster adversarial
robustness veriﬁcation via inducing relu stability. arXiv preprint arXiv:1809.03008, 2018."
REFERENCES,0.4788732394366197,"A
APPENDIX"
REFERENCES,0.48169014084507045,"A.1
COMPLETE VERIFICATION & ROBUSTNESS."
REFERENCES,0.48450704225352115,"Property veriﬁcation of SAT-convertible DNNs has been presented in (Narodytska et al., 2018) as follows:
given a precondition prec on the inputs x, a property prop on the outputs o and a SAT relations given by a
DNN between inputs/outputs denoted as DNN(x, o), we check whether the following statement is valid:
prec(x) ∧DNN(x, o) =⇒prop(o). In order to seek a counterexample to this property, we look for a
satisfying assignment of prec(x) ∧DNN(x, o) ∧prop(o). An application example of property veriﬁcation
is to check for the existence of adversarial perturbation in a trained DNN. In this case, prec deﬁnes an ϵ-ball
of valid perturbations and prop states that the classiﬁcation should not change under small perturbations.
Therefore, we distinguish the traditional ""natural accuracy"" from the ""veriﬁed accuracy"" the later measuring
the fraction of the predictions which remains correct for all adversarial attacks within the perturbation
constraints."
REFERENCES,0.48732394366197185,"A.2
EXAMPLES OF PSEUDO-BOOLEAN CONSTRAINT ENCODING."
REFERENCES,0.49014084507042255,"The ﬁrst row of Table 2 presents one inequality example containing 3 natural variables (x1, x2, x3). The
corresponding output SAT encoding are given for 5 different published methods: (Abío et al. (2011),
Hölldobler et al. (2012) , Eén & Sörensson (2006), Manthey et al. (2014))."
REFERENCES,0.49295774647887325,"We can see that we systematically end-up with many literals and clauses in the SAT equation. This add
complexity to solve the problem. Moreover, there is no straightforward relationship between the SAT formula
literals li and the inequality variables xi, or between the coefﬁcient of the inequality and the clauses."
REFERENCES,0.49577464788732395,Under review as a conference paper at ICLR 2022
REFERENCES,0.49859154929577465,Table 2: Examples of inequality conversion into SAT formulas according to different methodologies
REFERENCES,0.5014084507042254,"Inequality to convert into SAT Formulas
x1 −2x2 + 3x3 ≤3"
REFERENCES,0.504225352112676,"Encoding 1 - Abío et al. (2011)
(l4) ∧(l1 ∨l2 ∨l5) ∧(l5 ∨l3 ∨l6) ∧(l6)"
REFERENCES,0.5070422535211268,Encoding 2 - Hölldobler et al. (2012)
REFERENCES,0.5098591549295775,"(l4 ∨l9) ∧(l5 ∨l10) ∧(l6 ∨l11)
∧(l7 ∨l12) ∧(l8 ∨l13) ∧(l9 ∨l14) ∧(l10 ∨l15) ∧(l11 ∨l16)
∧(l12 ∨l17) ∧(l13 ∨l18)∧
(l3 ∨l4) ∧(l3 ∨l5) ∧(l3 ∨l6)∧
(l2 ∨l9) ∧(l2 ∨l10) ∧(l1 ∨14) ∧(l4 ∨l2 ∨l11)∧
(l5 ∨l2 ∨l12) ∧(l6 ∨l2 ∨l13) ∧(l9 ∨l1 ∨l15)∧
(l10 ∨l1 ∨l16) ∧(l11 ∨l1 ∨l17) ∧(l12 ∨l1 ∨l18) ∧(l7)∧
(l8) ∧(l7 ∨l2) ∧(l13 ∨l1)"
REFERENCES,0.5126760563380282,"Encoding 3 - Eén & Sörensson (2006)
(l5 ∨l3 ∨l2) ∧(l7 ∨l3 ∨l1) ∧(l8 ∨l3) ∧(l8 ∨l2) ∧(l6 ∨l8 ∨l7) ∧(l4 ∨l6 ∨l5) ∧(l4)"
REFERENCES,0.5154929577464789,Encoding 4 - Eén & Sörensson (2006)
REFERENCES,0.5183098591549296,"(l3 ∨l1 ∨l4) ∧(l3 ∨l1 ∨l4) ∧(l3 ∨l1 ∨l4) ∧(l3 ∨l1 ∨l4) ∧(l3 ∨l5)∧
(l1 ∨l5) ∧(l3 ∨l1 ∨l5) ∧(l3 ∨l2 ∨l5 ∨l6) ∧(l3 ∨l2 ∨l5 ∨l6)∧
(l3 ∨l2 ∨l5 ∨l6) ∧(l3 ∨l2 ∨l5 ∨l6) ∧(l3 ∨l2 ∨l5 ∨l6)
∧(l3 ∨l2 ∨l5 ∨l6) ∧(l3 ∨l2 ∨l5 ∨l6) ∧(l3 ∨l2 ∨l5 ∨l6) ∧(l2 ∨l5 ∨l7) ∧(l3 ∨l5 ∨l7) ∧(l3 ∨l2 ∨l7)
∧(l2 ∨l5 ∨l7) ∧(l3 ∨l5 ∨l7) ∧(l3 ∨l2 ∨l7) ∧(l7 ∨l6 ∨l3)∧
(l7 ∨l6 ∨l2) ∧(l7 ∨l6 ∨l5) ∧(l7 ∨l6 ∨l3) ∧(l7 ∨l6 ∨l2) ∧(l7 ∨l6 ∨l5) ∧(l7 ∨l6)"
REFERENCES,0.5211267605633803,"Encoding 5 - Manthey et al. (2014)
(l4) ∧(l3 ∨l5) ∧(l1 ∨l5) ∧(l3 ∨l1 ∨l6) ∧(l3 ∨l7) ∧(l2 ∨l7) ∧(l3 ∨l2 ∨l8) ∧(l7 ∨l9)∧
(l8 ∨l10) ∧(l6 ∨l9) ∧(l7 ∨l6 ∨l10) ∧(l8 ∨l6 ∨l11) ∧(l11)"
REFERENCES,0.523943661971831,"A.3
MODEL DESCRIPTION"
REFERENCES,0.5267605633802817,"A.3.1
OVERALL ARCHITECTURE"
REFERENCES,0.5295774647887324,"In this study, we considered the two architectures shown in Table 3. All the paddings are set to 0."
REFERENCES,0.532394366197183,"Table 3: Different studied model architectures details.
Dataset
Name
Layers
Number of Block
Size ﬁlters
Kernels
Groups
Strides
Features
Parameters
FLOP
Patch Size"
REFERENCES,0.5352112676056338,"MNIST
Model Small
4
2
60-48-384-48
3-1-2-1
1-1-24-24
3-1-2-1
768
15488
0.63 m
(6,6)
Model Big
4
2
60-48-384-48
3-1-3-1
1-1-48-48
2-1-2-1
2352
32530
1.77 m
(7,7)"
REFERENCES,0.5380281690140845,"CIFAR 10
Model Small
4
2
60-48-384-48
3-1-2-1
3-3-24-24
3-1-2-1
1200
17890
0.89 m
(6,6)
Model Big
4
2
60-48-384-48
3-1-3-1
3-3-48-48
2-1-2-1
2352
32530
1.87 m
(7,7)"
REFERENCES,0.5408450704225352,"A.3.2
FIRST LAYER"
REFERENCES,0.543661971830986,"Like in (Jia & Rinard, 2020), before applying the batch normalisation and the step function, we quantize the
inputs as xq = ⌊x"
REFERENCES,0.5464788732394367,"q ⌋· s where x is the real-valued input, xq is the quantized input to be fed into the TT-DCNN
and s is the quantization step size which can be set to s = 1/255 to emulate 8-bit ﬁxed-point values, or 2ϵ for
adversarial training with a l∞disturbance limit of ϵ."
REFERENCES,0.5492957746478874,"A.3.3
LAST LAYER"
REFERENCES,0.5521126760563381,"Last layer.
The last linear layer is composed of a linear layer and a batch normalisation. The weights of the
linear layer can be natural instead of binary but this leads to a large increase in the size of the SAT formulas."
REFERENCES,0.5549295774647888,"Natural features.
We may also increase the amount of information held by the vector of features
V by accepting natural values.
Coming back to our previous example, we can see the output y =
[0, −5, 3, −2, 1, −4, 4, −1, 10, 5, 13, 8, 11, 6, 14, 9] as y = −5 × [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] +
3 × [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] + · · · + 9 × [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]. Therefore,
each of these coefﬁcients can have an associated SAT expression of its own."
REFERENCES,0.5577464788732395,Under review as a conference paper at ICLR 2022
REFERENCES,0.5605633802816902,"For the sake of natural accuracy performance, as in (Evans et al., 2021), it is advisable to encode features and
weights on 8 bits. Results for features and weights encoded on 8 bits are given in Appendix A.9. However,
the results in this paper are given for binary features and weights."
REFERENCES,0.5633802816901409,"As we trained the TT-DCNN with a ﬁnal linear layer then a batch normalisation, we encoded the last layer for
the label i as follow: yi ="
REFERENCES,0.5661971830985916,"|V |
X"
REFERENCES,0.5690140845070423,"k=1
wk,iVk + bi and"
REFERENCES,0.571830985915493,"yBN
i
= BatchNorm(yi) = γ ·
yi −E(yi)
p"
REFERENCES,0.5746478873239437,"V ar[yi] + ϵ
+ β"
REFERENCES,0.5774647887323944,"yBN
i
= BatchNorm(yi) =
P|V |
k=1 γwk,iVk + γbi −E(yi)
p"
REFERENCES,0.5802816901408451,"V ar[x] + ϵ
+ β"
REFERENCES,0.5830985915492958,with ϵ = 1e −5 and · denotes element-wise multiplication.
REFERENCES,0.5859154929577465,"yBN
i
="
REFERENCES,0.5887323943661972,"|V |
X"
REFERENCES,0.5915492957746479,"k=1
˜wk,iVk + ˜bi with"
REFERENCES,0.5943661971830986,"˜wk,i = ⌊
γwk,i
p"
REFERENCES,0.5971830985915493,"V ar[yi] + ϵ
⌋"
REFERENCES,0.6,"˜bi =
γbi −E(yi)
p"
REFERENCES,0.6028169014084507,"V ar[yi] + ϵ
+ β"
REFERENCES,0.6056338028169014,"To facilitate the SAT conversion, we also restrict the variance statistics and the scale parameter γ in Batch-
Norm() of the last layer to be scalars computed on the whole feature map rather than per-channel statistics.
Before rounding, we multiply ˜wk,i and ˜bi by 100 in order to keep some details contained in the ﬂoating points."
REFERENCES,0.6084507042253521,"A.4
OPERATOR"
REFERENCES,0.6112676056338028,We note as · the operator standing for the product term by term between two matrices. A mask (for example
REFERENCES,0.6140845070422535,"M1 =

N
N
1
0"
REFERENCES,0.6169014084507042,"
) can be decomposed into two masks: M (0) and M (1). M (0) is 0 where M takes the value"
REFERENCES,0.6197183098591549,"Null, 1 everywhere else (ie as M (0)
1
=

0
0
1
1"
REFERENCES,0.6225352112676056,"
). M (1) is 1 where M takes the value 1, 0 everywhere else"
REFERENCES,0.6253521126760564,"(ie as M (1)
1
=

0
0
1
0 
)."
REFERENCES,0.6281690140845071,"Now let us note I the input matrices of the 2D-CNN and ˜
M the matrix given by ˜
M = I · M (0). Then, we say
that M matches I if and only if: ∀(i, j) ˜
M[i, j] = M (1)[i, j]."
REFERENCES,0.6309859154929578,Under review as a conference paper at ICLR 2022
REFERENCES,0.6338028169014085,"A.5
DETAILS OF TT-DCNN ENCODING"
REFERENCES,0.6366197183098592,"A.5.1
FIRST LAYER"
REFERENCES,0.6394366197183099,"Published as in Narodytska et al. (2019b), we note xq the quantiﬁed pixel variable, and xb the bit variable
after the ﬁrst preprocessing layer, we have xb = sign( α"
REFERENCES,0.6422535211267606,"σ (xq −µ) + γ) = sign(xinter)with α, σ, µ, γ
the characteristic of the ﬁrst batch normalisation. We consider two extreme values of the expression that
is an input of sign w.r.t. ϵ. We have (for α > 0) two extreme point: xmax
inter = α"
REFERENCES,0.6450704225352113,"σ (xq + ϵ −µ) + γ) and
xmin
inter = α"
REFERENCES,0.647887323943662,σ (xq −ϵ −µ) + γ)
REFERENCES,0.6507042253521127,"If xmin
inter ≥0 then we know that xb = 1. If xmax
inter < 0 then we know that xb = 0. Otherwise, xb ∈{0, 1},
therefore it’s a literal for the SAT encoding. We can consider the reverse transformation. If xb = 0 (i.e. for
xb = 1) is a solution of a problem produced by the SAT solver then we can map back to xattack = x −ϵ (i.e.
for xattack = x + ϵ)."
REFERENCES,0.6535211267605634,"A.5.2
LAST LAYER"
REFERENCES,0.6563380281690141,"Let V be the feature vector before the last linear layer, and U the set of indices of V that are unknown due to
noise propagation and K those that are known. We have, for the class attack a higher than class target t:"
REFERENCES,0.6591549295774648,"|V |
X"
REFERENCES,0.6619718309859155,"k=1
wk,aVk >"
REFERENCES,0.6647887323943662,"|V |
X"
REFERENCES,0.6676056338028169,"l=1
wl,tVl"
REFERENCES,0.6704225352112676,We can divide the set [1 · · · n] into U and K X
REFERENCES,0.6732394366197183,"k∈K
wk,aVk +
X"
REFERENCES,0.676056338028169,"k∈U
wk,aVk >
X"
REFERENCES,0.6788732394366197,"l∈K
wl,tVk +
X"
REFERENCES,0.6816901408450704,"l∈U
wl,tVl"
REFERENCES,0.6845070422535211,We group together the set known and X
REFERENCES,0.6873239436619718,"k∈U
(wk,t −wk,a)Vk <
X"
REFERENCES,0.6901408450704225,"l∈K
(wl,a −wl,t)Vl"
REFERENCES,0.6929577464788732,We note c = P
REFERENCES,0.6957746478873239,"l∈K(wl,a −wl,t)Vl, then c is a integer number. We have X"
REFERENCES,0.6985915492957746,"k∈U
(wk,t −wk,a)Vk ≤c −1"
REFERENCES,0.7014084507042253,"We note G = GCD(abs(wk,t −wk,a)∀k ∈U), then we have: X k∈U"
REFERENCES,0.704225352112676,"(wk,t −wk,a)"
REFERENCES,0.7070422535211267,"G
Vk ≤c −1 G"
REFERENCES,0.7098591549295775,As c−1
REFERENCES,0.7126760563380282,"G need to be an integer, we have: X k∈U"
REFERENCES,0.7154929577464789,"(wk,t −wk,a)"
REFERENCES,0.7183098591549296,"G
Vk ≤⌊c −1 G
⌋"
REFERENCES,0.7211267605633803,Under review as a conference paper at ICLR 2022
REFERENCES,0.723943661971831,"This inequality is encoded with the project (Ignatiev et al., 2018)."
REFERENCES,0.7267605633802817,"A.6
EXPERIMENTAL DETAILS"
REFERENCES,0.7295774647887324,"Experimental environment.
The project was implemented with Python and the library PyTorch (Paszke
et al., 2019). The project code can be found at this URL address3. Our work station is constituted of a GPU
Nvidia GeForce GTX 970 with 4043 MiB memory and four Intel core i5-4460 processors clocked at 3.20
GHz."
REFERENCES,0.7323943661971831,"Training method.
We build our training method on the top of Jia & Rinard (2020) project and we refer to
their notations for this section. We train the networks using the Adam optimizer (Kingma & Ba, 2014) for
90 epochs with a minibatch size of 128. The mean and variance statistics of batch normalization layers are
recomputed on the whole training set after training ﬁnishes."
REFERENCES,0.7352112676056338,"Learning rate is 0.0005. We use PGD with adaptive gradient cancelling to train robust networks, where the
perturbation bound ϵ is increased linearly from 0 to the desired value in the ﬁrst 50 epochs and the number of
PGD iteration steps grows linearly from 0 to 10 in the ﬁrst 23 epochs."
REFERENCES,0.7380281690140845,"The parameter α in adaptive gradient cancelling is chosen to maximize the PGD attack success rate evaluated
on 40 minibatches of training data sampled at the ﬁrst epoch. Candidate values of α are between 0.6 to
3.0 with a step of 0.4. Note that α is a global parameter shared by all neurons. We do not use any data
augmentation techniques for training. Due to limited computing resource and signiﬁcant differences between
the settings we considered, data in this paper are reported based on one evaluation run."
REFERENCES,0.7408450704225352,"Weight initialization.
Weights for the ﬁnal connected layers are initialized from a Gaussian distribution
with standard deviation 0.01, and the mask weights in BinMask are enforced to be positive by taking the
absolute value during initialization."
REFERENCES,0.7436619718309859,"Other hyperparameters.
The input quantization step s is set to be 0.61 = 0.3 × 2 + 0.01 for training on
the MNIST dataset, and 0.064 ≈16.3/255 for CIFAR10, which are chosen to be slightly greater than twice
the largest perturbation bound we consider for each dataset. Except for CIFAR10 for wich we double the
trainig noise, the training noise level is equal to the testing noise level. The CBD loss is applied on MNIST
high noise only and ν is set to be 5e −4, 0 otherwise. We apply a weight decay of 1e −7 on the binarized
mask weight of BinMask. We use the encoding proposed in (Abío et al., 2011). In Table 1, we use model Big
except for the high noise model with CIFAR10. For the post tunning parameters, we use a proportion ratio of
0.1 and a probability p = 0.05 for MNIST low noise, we double it for high noise and a proportion ratio of
0.05 and a probability p = 0.01 for CIFAR10 low noise and we double it for high noise."
REFERENCES,0.7464788732394366,"A.7
COMPARISON WITH SAT METHOD FOR EXACT SAME ARCHITECTURE AND EXACT SAME
TRAINING CONDITIONS"
REFERENCES,0.7492957746478873,"As the architectures in (Jia & Rinard, 2020) are different from ours, we reproduce the results for BNN with
our exact same architecture and the exact same training conditions. We also add an experiment with their
model architecture and our training condition for CIFAR10 high noise as we trained it for a noise of 16/255.
Results can be found in Table 4. We can observe that our model always outperforms the BNN model in term
of veriﬁable accuracy."
REFERENCES,0.752112676056338,3https://github.com/iclr2022anonymous/Truth-Table-Deep-Convolutional-Neural-Network
REFERENCES,0.7549295774647887,Under review as a conference paper at ICLR 2022
REFERENCES,0.7577464788732394,Table 4: Performance of studied models as BNN for equitable comparaison
REFERENCES,0.7605633802816901,"Dataset and
Noise Level
Model & Training condition
Accuracy
Mean time
(s)
Timeout
#cls/#vars"
REFERENCES,0.7633802816901408,"Veriﬁable
Natural"
REFERENCES,0.7661971830985915,"MNIST
0.3
Model Big as BNN
49.53%
93.62%
0.010
0
23K/33K"
REFERENCES,0.7690140845070422,"CIFAR10
2/255
Model Big as BNN
28.43%
37.66%
0.008
0
32K/46K"
REFERENCES,0.7718309859154929,"CIFAR10
8/255"
REFERENCES,0.7746478873239436,"Model Small as BNN
20.21%
29.38%
0.005
0
15K/22K"
REFERENCES,0.7774647887323943,"Architecture proposed in Jia & Rinard (2020)
as BNN with our training noise conditions
19.86%
31.95%
0.002
0
31K/64K"
REFERENCES,0.780281690140845,"A.8
MODEL COUNTING"
REFERENCES,0.7830985915492957,"Exact model counting.
Given a CNF formula Φ, the problem of model counting is to calculate the
corresponding number of satisfying assignments #Φ. This problem is complete for the complexity class
#P (Toda, 1991). A number of tools for exact model counting have been developed and for this study we
are using the recent Ganak model counter (Sharma et al., 2019). An application example of model counting
is to establish how many adversarial attacks exist for a trained DNN. In this case, prec deﬁnes an ϵ-ball of
valid perturbations and prop states that the classiﬁcation should change under small perturbations. And the
problem is given to a model counting solver (instead of a SAT solver) in the form of CNF."
REFERENCES,0.7859154929577464,"Exact model counting set up.
We encode as condition the input noise and the noise propagation as before.
We change the ﬁnal inequality: by encoding such that the class i is greater than all others. Then, we start
the MaxSAT solver on this formula: it gives us how many entries lead to an output if class i. We also add a
scenario: we randomly ﬁxed 50% of the ﬁrst layer literals to a random value (0 or 1). This leads to a partial
distribution of prediction instead of an exact distribution prediction. We reports P(adv), the probability to get
an adversarial, the number of timout of the exact model counting and ﬁnaly, the accuracy given by the argmax
of the distribution as prediction. The same is given in the noise scenario. We tested the ﬁrst 1K samples of
the dataset for model with and without ﬁltering"
REFERENCES,0.7887323943661971,"Results.
We performed the experiments for MNIST only. Results can be found in Table 5. First, we observe
that, for the Small model, the number of solved samples is very high: almost 100% except in 3 cases: when
the ﬁnal linear is not binary (Ter) and when the training noise is not in line with with the testing noise. This
contrasts with the results in Narodytska et al. (2019b) where there is only a single conﬁguration with 100% of
the instances solved with an approximated model counting. In the case of Small model, the probability to get
an adversarial is pretty high. The latter surprisingly increases with the ﬁltering and with the robust training.
On the contrary, for the Big model, the probability to get an adversarial is pretty low and the number of time
out increases. However, in the noise setting, the number of timeout drastically decreases, but the probability
to get an adversarial also increases. We also highlight the very high accuracy if we return the argmax of the
output distribution as prediction. We think these observations can lead to interesting further works."
REFERENCES,0.7915492957746478,"A.9
ABLATION STUDY"
REFERENCES,0.7943661971830986,"A.9.1
NATURAL ACCURACY"
REFERENCES,0.7971830985915493,"We compare the BNNs, TT-DCNN models and the standard real-valued models. We use the two-block Big
model, without the ampliﬁcation blocks for BNN and real-valued model. TT-DCNN has a ﬁnal layer with"
REFERENCES,0.8,Under review as a conference paper at ICLR 2022
REFERENCES,0.8028169014084507,Table 5: Results of TT-DCNN in the likelihood adversarial examples set-up for MNIST
REFERENCES,0.8056338028169014,"Model
Noise train
Noise test
Loss type
Ampliﬁcation
Final Linear
P(adv)
Accuracy
- P(adv)
Timeout
- P(adv)
P(adv)
with 50% noise"
REFERENCES,0.8084507042253521,"Accuracy
- P(adv)
with 50% noise"
REFERENCES,0.8112676056338028,"Timeout -
P(adv)
with 50% noise"
REFERENCES,0.8140845070422535,"Normal
Filtered
Normal
Filtered
Normal
Filtered
Normal
Filtered
Normal
Filtered
Normal
Filtered Small"
REFERENCES,0.8169014084507042,"0
0.3
0
Small
Bin
0.0119
-
716
-
101
-
0.05
-
875
-
0
-
0.3
0
Normal
Bin
0.00084
0.00162
526
549
432
388
0.0135
0.012
898
862
13
6"
REFERENCES,0.819718309859155,"0.1
0.1
0
Normal
Bin
0.2135
0.2194
936
932
0
0
0.3787
0.3559
938
930
0
0"
REFERENCES,0.8225352112676056,"0.3
0.3
0
Normal
Bin
0.09265
0.1068
900
883
1
1
0.2849
0.28267
899
884
0
0
0.3
3
Normal
Bin
0.1003
0.1085
901
863
0
0
0.3019
0.289
903
865
0
0 0.4"
REFERENCES,0.8253521126760563,"0.3
0
Small
Bin
0.4045
-
837
-
0
-
0.467
-
832
-
0
-
0.3
0
Normal
Bin
0.2099
-
877
-
0
-
0.3439
-
853
-
0
-
0.3
1
Normal
Bin
0.1643
-
880
-
0
-
0.3038
-
883
-
0
-
0.3
3
Normal
Bin
0.1914
0.2060
886
877
0
0
0.36322
0.3412
899
898
0
0
0.3
0
Normal
Ter
0.0
-
641
-
354
-
0
-
795
-
195
- Big"
REFERENCES,0.828169014084507,"0
0.3
0
Normal
Bin
0.0
-
111
-
888
-
-
-
-
-
-
-"
REFERENCES,0.8309859154929577,"0.1
0.1
0
Normal
Bin
0.022
0.039
973
970
13
17
0.03
0.05
979
978
0
1"
REFERENCES,0.8338028169014085,"0.3
0.3
0
Normal
Bin
2E-10
2E-10
802
815
184
174
-
-
-
-
-
-
0.3
3
Normal
Bin
3E-06
2E-06
802
805
196
195
0.014
0.017
936
942
31
31"
REFERENCES,0.8366197183098592,"0.4
0.3
0
Normal
Bin
0.0053
-
864
-
108
-
-
-
-
-
-
-
0.3
1
Normal
Bin
0.00464
-
862
-
125
-
-
-
-
-
-
-
0.3
3
Normal
Bin
0.005
0.009
867
864
105
94
0.012
0.0377
936
923
8
4"
REFERENCES,0.8394366197183099,"integer values. We stopped the training at 45 epochs for all three models to prevent overﬁtting. We also
compare TT-DCNN for two values of truth table size n: 9 and 27. The results are given in Table 6. We
observe that for MNIST and CIFAR10, TT-DCNN outperforms BNN and is inferior to the real-valued model.
We also observe that as n increases, TT-DCNN tends to the real-valued model performances. We use n = 27
as it seems reasonable to compute 227 operations to get the SAT formula of a ﬁlter."
REFERENCES,0.8422535211267606,"Table 6: Comparison of natural accuracy between TT-DCNN, BNN and DCNN."
REFERENCES,0.8450704225352113,"Binary based model
BNN
Real based model
DCNN
TT-DCNN Our
(n = 9)
TT-DCNN Our
(n = 27)"
REFERENCES,0.847887323943662,"Natural Accuracy on MNIST
96.98%
98.49%
98.35%
98.47%
Natural Accuracy on CIFAR10
53.53%
66.16%
54.11%
58.08%"
REFERENCES,0.8507042253521127,"Table 7: Comparison of model architectures between TT-DCNN, BNN and DCNN."
REFERENCES,0.8535211267605634,"BNN
DCNN
TT-DCNN"
REFERENCES,0.856338028169014,"Type weigths
Binary
Floating
Floating
Type Intermediate values
Binary
Floating
Mixed Floating - Binary
Group CNN
Not Grouped
Not Grouped
Grouped"
REFERENCES,0.8591549295774648,"Final linear classiﬁcation
MLP
(Multi-Layer-Perceptron)
MLP
(Multi-Layer-Perceptron)
Linear"
REFERENCES,0.8619718309859155,"A.9.2
STUDY ON INFLUENCE OF AMPLIFICATION LAYER"
REFERENCES,0.8647887323943662,"We tested three models: a model without ampliﬁcation (one block is one layer), a model with minimal
ampliﬁcation (one block is two layers - with ampliﬁcation factor 1) and a model with standard ampliﬁcation
(model presented in Appendix A.3.1). Results are presented in Table 8. We respect the training conditions
proposed in Appendix A.6."
REFERENCES,0.8676056338028169,We can observe that the ampliﬁcation layer is always proﬁtable for the natural accuracy.
REFERENCES,0.8704225352112676,Under review as a conference paper at ICLR 2022
REFERENCES,0.8732394366197183,"Table 8:
Comparison of the natural accuracy of TT-DCNN for three different types of ampliﬁcation
conﬁguration, for CIFAR10 and MNIST, in the case of training with noise and without noise."
REFERENCES,0.8760563380281691,"Dataset
Noise Training
Ampliﬁcation
Accuracy"
REFERENCES,0.8788732394366198,"Model Small
Model Big MNIST"
NO,0.8816901408450705,"0
No
89.71%
95.28%
Small
91.66%
95.79%
Normal
94.60%
97.53%"
NO,0.8845070422535212,"0.4
No
82.63%
92.42%
Small
85.67%
94.19%
Normal
87.59%
95.77%"
NO,0.8873239436619719,CIFAR10
NO,0.8901408450704226,"0
No
40.53%
44.33%
Small
42.51%
47.12%
Normal
44.05%
50.27%"
NO,0.8929577464788733,"16/255
No
22.40%
28.05%
Small
27.86%
37.29%
Normal
32.19%
47.12%"
NO,0.895774647887324,"A.9.3
OTHERS"
NO,0.8985915492957747,"For the study, we tested the ﬁrst 1K samples of the dataset for model small and big with and without ﬁltering.
We reported the natural accuracy, the veriﬁed accuracy, the total time to compute, the number of clauses and
variables. We don’t report the number of timeout as they are all 0. The results were computed on an other
computer than those of Table 1. We took the measures for different:"
NO,0.9014084507042254,"• Size of the model. We use the two models presented above.
• Dataset. We use MNIST and CIFAR10"
NO,0.9042253521126761,• Training noise level.
NO,0.9070422535211268,• Testing noise level.
NO,0.9098591549295775,• Loss coefﬁcient as introduced in Jia & Rinard (2020).
NO,0.9126760563380282,• Ampliﬁcation Layer. Two ampliﬁcations possibles described in Appendix A.9.2
NO,0.9154929577464789,• Final Layer. Two possibilities: with binary (Bin) or ternary (Ter) weigths.
NO,0.9183098591549296,"First, we saw that MNIST and CIFAR10 can be scaled to our two models for low and high noise. Then, we
observe that the loss coefﬁcient has little impact on the performances. We can highlight that the training noise
level has an important impact on the veriﬁcation accuracy and the time computation.We can observe that most
of the time the ﬁltering leads to a better veriﬁable accuracy and sometimes to a better natural accuracy."
NO,0.9211267605633803,Under review as a conference paper at ICLR 2022
NO,0.923943661971831,Table 9: Results of TT-DCNN in the untargeted attack set-up for CIFAR10
NO,0.9267605633802817,"Model
Noise train
Noise test
Loss type
Ampliﬁcation
Final Linear
Natural Accuracy
Veriﬁable Accuracy
Mean time
(s)
#cls/#vars"
NO,0.9295774647887324,"Normal
Filtered
Normal
Filtered
Normal
Filtered
Normal
Filtered Small"
NO,0.9323943661971831,"0
8/255
0
Small
Bin
448
-
20
-
0.254
-
9722/1610
-
0
Normal
Bin
456
-
18
-
0.266
-
10859/1555
-"
NO,0.9352112676056338,"2/255
2/255
0
Normal
Bin
460
456
328
330 (light)
0.105
0.208
661/258
639/250
463
299 (strong)
0.200
584/233
3
Normal
Bin
463
446
300
288
01:45
03:25
696/273
675/269
2.2/255
0
Normal
Bin
458
431
305
316
0.106
0.217
730/279
676/257"
NO,0.9380281690140845,"8/255
8/255"
"SMALL
BIN",0.9408450704225352,"0
Small
Bin
348
248
190
185
0.090
0.239
1349/395
1273/390"
"NORMAL
BIN",0.9436619718309859,"0
Normal
Bin
357
357
196
229 (light)
0.109
0.208
2269/509
2246/508
356
231 (Strong)
0.213
2176/507
1
Normal
Bin
368
347
173
186
0.110
0.223
1890/494
1519/464
3
Normal
Bin
358
299
178
192
0.113
0.200
2337/557
2031/538"
"NORMAL
BIN",0.9464788732394366,"16/255
8/255"
"SMALL
BIN",0.9492957746478873,"0
Small
Bin
232
-
135
-
0.061
-
1148/368
-
0
Normal
Bin
329
-
219
-
0.092
-
1342/425
-
1
Normal
Bin
344
-
194
-
0.095
-
1339/413
-
3
Normal
Bin
334
334
194
193
0.093
0.206
1473/461
1273/428
0
Normal
Ter
390
-
139
-
0.104
-
3119/1302
-
16.7/255
0
Normal
Bin
347
332
201
244
0.998
0.199
1379/451
1300/440 Big"
"SMALL
BIN",0.952112676056338,"0
8/255
0
Small
Bin
506
-
15
-
0.703
-
26183/3545
-
0
Normal
Bin
539
-
10
-
0.640
-
23777/3874
-
2/255
2/255
0
Normal
Bin
458
-
290
-
0.158
-
1327/452
-
8/255
8/255
0
Normal
Bin
380
-
153
-
0.172
-
4099/730
-"
"SMALL
BIN",0.9549295774647887,"16/255
8/255"
"SMALL
BIN",0.9577464788732394,"0
Small
Bin
294
-
226
-
0.193
-
3595/813
-
0
Normal
Bin
366
-
214
-
0.205
-
4666/941
-
0
Normal
Ter
389
-
88
-
0.512
-
22757/9828
-
1
Normal
Bin
348
-
212
-
0.175
-
3625/912
-
3
Normal
Bin
327
-
108
-
0.174
-
4661/957
-"
"SMALL
BIN",0.9605633802816902,Table 10: Results of TT-DCNN in the untargeted attack set-up for MNIST
"SMALL
BIN",0.9633802816901409,"Model
Noise train
Noise test
Loss type
Ampliﬁcation
Final Linear
Natural Accuracy
Veriﬁable Accuracy
Mean time
(s)
Timeout
#cls/#vars"
"SMALL
BIN",0.9661971830985916,"Normal
Filtered
Normal
Filtered
Normal
Filtered
Normal
Filtered
Normal
Filtered Small"
"SMALL
BIN",0.9690140845070423,"0
0.3
0
Small
Bin
909
-
226
-
0.183
-
0
-
2771 / 795
-
0
Normal
Bin
936
908
169
161
0.239
0.268
0
0
3209/871
2974/838"
"SMALL
BIN",0.971830985915493,"0.1
0.1
0
Normal
Bin
943
937
848
665
0.073
0.128
0
0
456/199
442/195"
"SMALL
BIN",0.9746478873239437,"0.3
0.3
0
Normal
Bin
906
902
674
648
0.139
0.207
0
0
1406/501
1370/498
3
Normal
Bin
912
866
665
637
0.147
0.217
0
0
665 1403
1332 493"
"SMALL
BIN",0.9774647887323944,"0.4
0.3"
"SMALL
BIN",0.9802816901408451,"0
Small
Bin
819
-
670
-
0.114
-
0
-
977/397
-
0
Normal
Bin
859
-
676
-
0.127
-
0
-
1091/425
-
1
Normal
Bin
889
-
651
-
0.146
-
0
-
1239/467
-
3
Normal
Bin
886
881
677
680
0.117
0.245
0
0
1059 421
1041 419
0
Normal
Ter
930
-
641
-
0.324
-
0
-
4016/1887
- Big"
"SMALL
BIN",0.9830985915492958,"0
0.3
0
Normal
Bin
974
-
111
-
0.716
-
0
-
9879/2637
-"
"SMALL
BIN",0.9859154929577465,"0.1
0.1
0
Normal
Bin
976
978
944
947 (low)
0.302
0.494
0
0
1146 461
1137 459
977
946 (low)
0.491
0
1138/459"
"SMALL
BIN",0.9887323943661972,"0.3
0.3
0
Normal
Bin
957
953
771
776
0.463
0.634
0
0
4047/1250
3834/1206"
"NORMAL
BIN",0.9915492957746479,"3
Normal
Bin
965
964
774
778 (high)
0.485
0.634
0
0
3923 1240
3863/1231
959
773 (high)
0.696
0
3820 1223"
"NORMAL
BIN",0.9943661971830986,"0.4
0.3"
"NORMAL
BIN",0.9971830985915493,"0
Normal
Bin
951
-
790
-
0.423
-
0
-
3163/1039
-
1
Normal
Bin
957
-
808
-
0.446
-
0
-
-
3
Normal
Bin
954
931
808
781
0.436
0.590
0
0
3117 1062
2816 980
0
Normal
Ter
974
-
723
-
10,44
-
0
-
-"
