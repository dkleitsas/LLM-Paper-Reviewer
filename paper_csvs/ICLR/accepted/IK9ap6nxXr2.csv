Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0013986013986013986,"We propose an interacting contour stochastic gradient Langevin dynamics (IC-
SGLD) sampler, an embarrassingly parallel multiple-chain contour stochastic
gradient Langevin dynamics (CSGLD) sampler with efÔ¨Åcient interactions. We
show that ICSGLD can be theoretically more efÔ¨Åcient than a single-chain CSGLD
with an equivalent computational budget. We also present a novel random-Ô¨Åeld
function, which facilitates the estimation of self-adapting parameters in big data and
obtains free mode explorations. Empirically, we compare the proposed algorithm
with popular benchmark methods for posterior sampling. The numerical results
show a great potential of ICSGLD for large-scale uncertainty estimation tasks."
INTRODUCTION,0.002797202797202797,"1
INTRODUCTION"
INTRODUCTION,0.004195804195804196,"Stochastic gradient Langevin dynamics (SGLD) (Welling & Teh, 2011) has achieved great successes
in simulations of high-dimensional systems for big data problems. It, however, yields only a fast
mixing rate when the energy landscape is simple, e.g., local energy wells are shallow and not well
separated. To improve its convergence for the problems with complex energy landscapes, various
strategies have been proposed, such as momentum augmentation (Chen et al., 2014; Ding et al., 2014),
Hessian approximation (Ahn et al., 2012; Li et al., 2016), high-order numerical schemes (Chen et al.,
2015; Li et al., 2019b), and cyclical learning rates (Izmailov et al., 2018; Maddox et al., 2019; Zhang
et al., 2020b). In spite of their asymptotic properties in Bayesian inference (Vollmer et al., 2016)
and non-convex optimization (Zhang et al., 2017), it is still difÔ¨Åcult to achieve compelling empirical
results for pathologically complex deep neural networks (DNNs)."
INTRODUCTION,0.005594405594405594,"To simulate from distributions with complex energy landscapes, e.g., those with a multitude of modes
well separated by high energy barriers, an emerging trend is to run multiple chains, where interactions
between different chains can potentially accelerate the convergence of the simulation. For example,
Song et al. (2014) and Futami et al. (2020) showed theoretical advantages of appropriate interactions
in ensemble/population simulations. Other multiple chain methods include particle-based nonlinear
Markov (Vlasov) processes (Liu & Wang, 2016; Zhang et al., 2020a) and replica exchange methods
(also known as parallel tempering) (Deng et al., 2021a). However, the particle-based methods
result in an expensive kernel matrix computation given a large number of particles (Liu & Wang,
2016); similarly, na¬®ƒ±vely extending replica exchange methods to population chains leads to a long
waiting time to swap between non-neighboring chains (Syed et al., 2021). Therefore, how to conduct
interactions between different chains, while maintaining the scalability of the algorithm, is the key to
the success of the parallel stochastic gradient MCMC algorithms."
INTRODUCTION,0.006993006993006993,"In this paper, we propose an interacting contour stochastic gradient Langevin dynamics (ICSGLD)
sampler, a pleasingly parallel extension of contour stochastic gradient Langevin dynamics (CSGLD)
(Deng et al., 2020b) with efÔ¨Åcient interactions. The proposed algorithm requires minimal communi-
cation cost in that each chain shares with others the marginal energy likelihood estimate only. As a
result, the interacting mechanism improves the convergence of the simulation, while the minimal
communication mode between different chains enables the proposed algorithm to be naturally adapted
to distributed computing with little overhead. For the single-chain CSGLD algorithm, despite its
theoretical advantages as shown in Deng et al. (2020b), estimation of the marginal energy likelihood
remains challenging for big data problems with a wide energy range, jeopardizing the empirical
performance of the class of importance sampling methods (Gordon et al., 1993; Doucet et al., 2001;"
INTRODUCTION,0.008391608391608392,Published as a conference paper at ICLR 2022
INTRODUCTION,0.009790209790209791,"Wang & Landau, 2001; Liang et al., 2007; Andrieu et al., 2010; Deng et al., 2020b) in big data
applications. To resolve this issue, we resort to a novel interacting random-Ô¨Åeld function based
on multiple chains for an ideal variance reduction and a more robust estimation. As such, we can
greatly facilitate the estimation of the marginal energy likelihood so as to accelerate the simulations
of notoriously complex distributions. To summarize, the algorithm has three main contributions:"
INTRODUCTION,0.011188811188811189,"‚Ä¢ We propose a scalable interacting importance sampling method for big data problems with the min-
imal communication cost. A novel random-Ô¨Åeld function is derived to tackle the incompatibility
issue of the class of importance sampling methods in big data problems."
INTRODUCTION,0.012587412587412588,"‚Ä¢ Theoretically, we study the local stability of a non-linear mean-Ô¨Åeld system and justify regularity
properties of the solution of Poisson‚Äôs equation. We also prove the asymptotic normality for the
stochastic approximation process in mini-batch settings and show that ICSGLD is asymptotically
more efÔ¨Åcient than the single-chain CSGLD with an equivalent computational budget."
INTRODUCTION,0.013986013986013986,"‚Ä¢ Our proposed algorithm achieves appealing mode explorations using a Ô¨Åxed learning rate on the
MNIST dataset and obtains remarkable performance in large-scale uncertainty estimation tasks."
PRELIMINARIES,0.015384615384615385,"2
PRELIMINARIES"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.016783216783216783,"2.1
STOCHASTIC GRADIENT LANGEVIN DYNAMICS"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.01818181818181818,"A standard sampling algorithm for big data problems is SGLD (Welling & Teh, 2011), which is a
numerical scheme of a stochastic differential equation in mini-batch settings:"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.019580419580419582,"xk+1 = xk ‚àíœµk
N"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.02097902097902098,"n ‚àáx eU(xk) +
‚àö"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.022377622377622378,"2œÑœµkwk,
(1)"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.023776223776223775,"where xk ‚ààX ‚ààRd, œµk is the learning rate at iteration k, N denotes the number of total data points,
œÑ is the temperature, and wk is a standard Gaussian vector of dimension d. In particular, N"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.025174825174825177,"n ‚àáx eU(x)
is an unbiased stochastic gradient estimator based on a mini-batch data B of size n and N"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.026573426573426574,"n eU(x) is the
unbiased energy estimator for the exact energy function U(x). Under mild conditions on U, xk+1 is
known to converge weakly to a unique invariant distribution œÄ(x) ‚àùe‚àíU(x)"
STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.027972027972027972,"œÑ
as œµk ‚Üí0."
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.02937062937062937,"2.2
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.03076923076923077,"Despite its theoretical guarantees, SGLD can converge exponentially slow when U(x) is non-convex
and exhibits high energy barriers. To remedy this issue, CSGLD (Deng et al., 2020b) exploits the Ô¨Çat
histogram idea and proposes to simulate from a Ô¨Çattened density with much lower energy barriers"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.032167832167832165,"œñŒ®Œ∏(x) ‚àùœÄ(x)/Œ®Œ∂
Œ∏(U(x)),
(2)"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.033566433566433566,"where Œ∂ is a hyperparameter, Œ®Œ∏(u) = Pm
i=1"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.03496503496503497,"
Œ∏(i ‚àí1)e(log Œ∏(i)‚àílog Œ∏(i‚àí1))
u‚àíui‚àí1"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.03636363636363636,"‚àÜu

1ui‚àí1<u‚â§ui."
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.03776223776223776,"In particular, {ui}m
i=0 determines the partition {Xi}m
i=1 of X such that Xi = {x : ui‚àí1 < U(x) ‚â§
ui}, where ‚àí‚àû= u0 < u1 < ¬∑ ¬∑ ¬∑ < um‚àí1 < um = ‚àû. For practical purposes, we assume
ui+1 ‚àíui = ‚àÜu for i = 1, ¬∑ ¬∑ ¬∑ , m ‚àí2. In addition, Œ∏ = (Œ∏(1), Œ∏(2), . . . , Œ∏(m)) is the self-adapting"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.039160839160839164,"parameter in the space Œò =

(Œ∏(1), ¬∑ ¬∑ ¬∑ , Œ∏(m))
0 < Œ∏(1), ¬∑ ¬∑ ¬∑ , Œ∏(m) < 1& Pm
i=1 Œ∏(i) = 1

."
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.04055944055944056,"Ideally, setting Œ∂ = 1 and Œ∏(i) = Œ∏‚àû(i), where Œ∏‚àû(i) =
R"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.04195804195804196,"Xi œÄ(x)dx for i ‚àà{1, 2, ¬∑ ¬∑ ¬∑ , m}, enables
CSGLD to achieve a ‚Äúrandom walk‚Äù in the space of energy and to penalize the over-visited partition
(Wang & Landau, 2001; Liang et al., 2007; Fort et al., 2011; 2015). However, the optimal values of
Œ∏‚àûis unknown a priori. To tackle this issue, CSGLD proposes the following procedure to adaptively
estimate Œ∏ via stochastic approximation (SA) (Robbins & Monro, 1951; Benveniste et al., 1990):"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.043356643356643354,(1) Sample xk+1 = xk + œµk N
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.044755244755244755,"n ‚àáx eUŒ®Œ∏k (xk) + ‚àö2œÑœµkwk,"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.046153846153846156,"(2) Optimize Œ∏k+1 = Œ∏k + œâk+1 eH(Œ∏k, xk+1),"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.04755244755244755,Published as a conference paper at ICLR 2022
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.04895104895104895,"Algorithm 1 Interacting contour stochastic gradient Langevin dynamics algorithm (ICSGLD).
{Xi}m
i=1 is pre-deÔ¨Åned partition and Œ∂ is a hyperparameter. The update rule in distributed-memory
settings and discussions of hyperparameters is detailed in section B.1.1 in the supplementary material."
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.05034965034965035,"[1.] (Data subsampling) Draw a mini-batch data Bk from D, and compute stochastic gradients
‚àáx eU(x(p)
k ) and energies eU(x(p)
k ) for each x(p), where p ‚àà{1, 2, ¬∑ ¬∑ ¬∑ , P}, |Bk| = n, and |D| = N.
[2.] (Parallel simulation) Sample x
N P
k+1 := (x(1)
k+1, x(2)
k+1, ¬∑ ¬∑ ¬∑ , x(P )
k+1)‚ä§based on SGLD and Œ∏k"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.05174825174825175,"x
N P
k+1 = x
N P
k
+ œµk
N"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.05314685314685315,"n ‚àáx eUŒ®Œ∏k (x
N P
k
) +
‚àö"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.05454545454545454,"2œÑœµkw
N P
k
,
(4)"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.055944055944055944,"where œµk is the learning rate, œÑ is the temperature, w
N P
k
denotes P independent standard
Gaussian vectors, ‚àáx eUŒ®Œ∏(x
N P ) = (‚àáx eUŒ®Œ∏(x(1)), ‚àáx eUŒ®Œ∏(x(2)), ¬∑ ¬∑ ¬∑ , ‚àáx eUŒ®Œ∏(x(P )))‚ä§, and"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.057342657342657345,"‚àáx eUŒ®Œ∏(x) =
h
1 + Œ∂œÑ"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.05874125874125874,"‚àÜu
 
log Œ∏(JeU(x)) ‚àílog Œ∏((JeU(x) ‚àí1) ‚à®1)
i
‚àáx eU(x) for any x ‚ààX."
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.06013986013986014,"[3.] (Stochastic approximation) Update the self-adapting parameter Œ∏(i) for i ‚àà{1, 2, ¬∑ ¬∑ ¬∑ , m}"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.06153846153846154,"Œ∏k+1(i) = Œ∏k(i) + œâk+1
1
P P
X"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.06293706293706294,"p=1
Œ∏k(JeU(x(p)
k+1))

1i=J e
U(x(p)
k+1) ‚àíŒ∏k(i)

,
(5)"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.06433566433566433,where 1A is an indicator function that takes value 1 if the event A appears and equals 0 otherwise.
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.06573426573426573,"where ‚àáx eUŒ®Œ∏(¬∑) is a stochastic gradient function of œñŒ®Œ∏(¬∑) to be detailed in Algorithm 1. eH(Œ∏, x) :=

eH1(Œ∏, x), ¬∑ ¬∑ ¬∑ , eHm(Œ∏, x)

is random-Ô¨Åeld function where each entry follows"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.06713286713286713,"eHi(Œ∏, x) = Œ∏Œ∂(JeU(x))

1i=J e
U(x) ‚àíŒ∏(i)

, where JeU(x) = m
X"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.06853146853146853,"i=1
i1ui‚àí1< N"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.06993006993006994,"n eU(x)‚â§ui.
(3)"
CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.07132867132867132,"Theoretically, CSGLD converges to a sampling-optimization equilibrium in the sense that Œ∏k ap-
proaches to a Ô¨Åxed point Œ∏‚àûand the samples are drawn from the Ô¨Çattened density œñŒ®Œ∏‚àû(x).
Notably, the mean-Ô¨Åeld system is globally stable with a unique stable equilibrium point in a small
neighborhood of Œ∏‚àû. Moreover, such an appealing property holds even when U(x) is non-convex."
INTERACTING CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.07272727272727272,"3
INTERACTING CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS"
INTERACTING CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS,0.07412587412587412,"The major goal of interacting CSGLD (ICSGLD) is to improve the efÔ¨Åciency of CSGLD. In particular,
the self-adapting parameter Œ∏ is crucial for ensuring the sampler to escape from the local traps and
traverse the whole energy landscape, and how to reduce the variability of Œ∏k‚Äôs is the key to the success
of such a dynamic importance sampling algorithm. To this end, we propose an efÔ¨Åcient variance
reduction scheme via interacting parallel systems to improve the accuracy of Œ∏k‚Äôs."
INTERACTIONS IN PARALLELISM,0.07552447552447553,"3.1
INTERACTIONS IN PARALLELISM"
INTERACTIONS IN PARALLELISM,0.07692307692307693,Now we Ô¨Årst consider a na¬®ƒ±ve parallel sampling scheme with P chains as follows
INTERACTIONS IN PARALLELISM,0.07832167832167833,"x
N P
k+1 = x
N P
k
+ œµk
N"
INTERACTIONS IN PARALLELISM,0.07972027972027972,"n ‚àáx eUŒ®Œ∏k (x
N P
k
) +
‚àö"
INTERACTIONS IN PARALLELISM,0.08111888111888112,"2œÑœµkw
N P
k
,"
INTERACTIONS IN PARALLELISM,0.08251748251748252,"where x
N P = (x(1), x(2), ¬∑ ¬∑ ¬∑ , x(P ))‚ä§, w
N P
k
denotes P independent standard Gaussian vectors,
and eUŒ®Œ∏(x
N P ) = (eUŒ®Œ∏(x(1)), eUŒ®Œ∏(x(2)), ¬∑ ¬∑ ¬∑ , eUŒ®Œ∏(x(P )))‚ä§."
INTERACTIONS IN PARALLELISM,0.08391608391608392,Stochastic approximation aims to Ô¨Ånd the solution Œ∏ of the mean-Ô¨Åeld system h(Œ∏) such that
INTERACTIONS IN PARALLELISM,0.08531468531468532,"h(Œ∏) =
Z"
INTERACTIONS IN PARALLELISM,0.08671328671328671,"X
e
H(Œ∏, x)œñŒ∏(dx) = 0,"
INTERACTIONS IN PARALLELISM,0.08811188811188811,"where œñŒ∏ is the invariant measure simulated via SGLD that approximates œñŒ®Œ∏ in (2) and eH(Œ∏, x)
is the novel random-Ô¨Åeld function to be deÔ¨Åned later in (8). Since h(Œ∏) is observable only up
to large random perturbations (in the form of eH(Œ∏, x)), the optimization of Œ∏ based on isolated"
INTERACTIONS IN PARALLELISM,0.08951048951048951,Published as a conference paper at ICLR 2022
INTERACTIONS IN PARALLELISM,0.09090909090909091,"random-Ô¨Åeld functions may not be efÔ¨Åcient enough. However, due to the conditional independence
of x(1), x(2), ¬∑ ¬∑ ¬∑ , x(P ) in parallel sampling, it is very natural to consider a Monte Carlo average"
INTERACTIONS IN PARALLELISM,0.09230769230769231,"h(Œ∏) = 1 P P
X p=1 Z"
INTERACTIONS IN PARALLELISM,0.0937062937062937,"X
e
H(Œ∏, x(p))œñŒ∏(dx(p)) = 0.
(6)"
INTERACTIONS IN PARALLELISM,0.0951048951048951,"Namely, we are considering the following stochastic approximation scheme"
INTERACTIONS IN PARALLELISM,0.0965034965034965,"Œ∏k+1 = Œ∏k + œâk+1f
H(Œ∏k, x
N P
k+1 ),
(7)"
INTERACTIONS IN PARALLELISM,0.0979020979020979,"where f
H(Œ∏k, x
N P
k+1 ) is an interacting random-Ô¨Åeld function f
H(Œ∏k, x
N P
k+1 ) = 1"
INTERACTIONS IN PARALLELISM,0.0993006993006993,"P
PP
p=1 eH(Œ∏k, x(p)
k+1).
Note that the Monte Carlo average is very effective to reduce the variance of the interacting random-
Ô¨Åeld function f
H(Œ∏, x
N P ) based on the conditionally independent random Ô¨Åeld functions. Moreover,
each chain shares with others only a very short message during each iteration. Therefore, the
interacting parallel system is well suited for distributed computing, where the implementations
and communication costs are further detailed in section B.1.2 in the supplementary material. By
contrast, each chain of the non-interacting parallel CSGLD algorithm deals with the parameter Œ∏ and
a large-variance random-Ô¨Åeld function eH(Œ∏, x) individually, leading to coarse estimates in the end."
INTERACTIONS IN PARALLELISM,0.1006993006993007,"Formally, for the population/ensemble interaction scheme (7), we deÔ¨Åne a novel random-Ô¨Åeld function
eH(Œ∏, x) = ( eH1(Œ∏, x), eH2(Œ∏, x), ¬∑ ¬∑ ¬∑ , eHm(Œ∏, x)), where each component satisÔ¨Åes"
INTERACTIONS IN PARALLELISM,0.1020979020979021,"eHi(Œ∏, x) = Œ∏(JeU(x))

1i=J e
U(x) ‚àíŒ∏(i)

.
(8)"
INTERACTIONS IN PARALLELISM,0.1034965034965035,"As shown in Lemma 1, the corresponding mean-Ô¨Åeld function proposes to converge to a different
Ô¨Åxed point Œ∏‚ãÜ, s.t."
INTERACTIONS IN PARALLELISM,0.1048951048951049,"Œ∏‚ãÜ(i) ‚àù
Z"
INTERACTIONS IN PARALLELISM,0.1062937062937063,"Xi
e‚àíU(x)"
INTERACTIONS IN PARALLELISM,0.1076923076923077,"œÑ
dx
 1 Œ∂
‚àùŒ∏"
INTERACTIONS IN PARALLELISM,0.10909090909090909,"1
Œ∂
‚àû(i).
(9)"
INTERACTIONS IN PARALLELISM,0.11048951048951049,"A large data set often renders the task of estimating Œ∏‚àûnumerically challenging. By contrast, we
resort to a different solution by estimating Œ∏‚ãÜinstead based on a large value of Œ∂. The proposed
algorithm is summarized in Algorithm 1. For more study on the scalablity of the new scheme, we
leave the discussion in section B.1.3."
RELATED WORKS,0.11188811188811189,"3.2
RELATED WORKS"
RELATED WORKS,0.11328671328671329,"Replica exchange SGLD (Deng et al., 2020a; 2021a) has successfully extended the traditional
replica exchange (Swendsen & Wang, 1986; Geyer, 1991; Earl & Deem, 2005) to big data problems.
However, it works with two chains only and has a low swapping rate. As shown in Figure 1(a), a
na¬®ƒ±ve extension of multi-chain replica exchange SGLD yields low communication efÔ¨Åciency. Despite
some recipe in the literature (Katzgraber et al., 2008; Bittner et al., 2008; Syed et al., 2021), how to
conduct multi-chain replica exchange with low-frequency swaps is still an open question."
RELATED WORKS,0.11468531468531469,"(a) Replica Exchange (parallel tempering)
(b) Interacting contour SGLD (ICSGLD)"
RELATED WORKS,0.11608391608391608,"Figure 1: A comparison of communication costs between replica exchange (RE) and ICSGLD. We
see RE takes many iterations to swap with all the other chains; by contrast, ICSGLD possesses a
pleasingly parallel mechanism where the only cost comes from sharing a light message."
RELATED WORKS,0.11748251748251748,"Stein variational gradient descent (SVGD) (Liu & Wang, 2016) is a popular approximate inference
method to drive a set of particles for posterior approximation. In particular, repulsive forces are
proposed to prevent particles to collapse together into neighboring regions, which resembles our
strategy of penalizing over-visited partition. However, SVGD tends to underestimate the uncertainty
given a limited number of particles. Moreover, the quadratic cost in kernel matrix computation further
raises the scalability concerns as more particles are proposed."
RELATED WORKS,0.11888111888111888,Published as a conference paper at ICLR 2022
RELATED WORKS,0.12027972027972028,"Admittedly, ICSGLD is not the Ô¨Årst interacting importance sampling algorithm. For example, a
population stochastic approximation Monte Carlo (pop-SAMC) algorithm has been proposed in Song
et al. (2014), and an interacting particle Markov chain Monte Carlo (IPMCMC) algorithm has been
proposed in Rainforth et al. (2016). A key difference between our algorithm and others is that our
algorithm is mainly devised for big data problems. The IPMCMC and pop-SAMC are gradient-free
samplers, which are hard to be adapted to high-dimensional big data problems."
RELATED WORKS,0.12167832167832168,"Other parallel SGLD methods (Ahn et al., 2014; Chen et al., 2016) aim to reduce the computational
cost of gradient estimations in distributed computing, which, however, does not consider interactions
for accelerating the convergence. Li et al. (2019a) proposed asynchronous protocols to reduce
communication costs when the master aggregates model parameters from all workers. Instead, we
don‚Äôt communicate the parameter x ‚ààRd but only share Œ∏ ‚ààRm and the indices, where m ‚â™d."
RELATED WORKS,0.12307692307692308,"Our work also highly resembles the well-known Federated Averaging (FedAvg) algorithm (Li et al.,
2020; Deng et al., 2021b), except that the stochastic gradient eU(x) is replaced with the random Ô¨Åeld
function eH(Œ∏, x) and we only share the low-dimensional latent vector Œ∏. Since privacy concerns
and communication cost are not major bottlenecks of our problem, we leave the study of taking the
Monte Carlo average in Eq.(6) every K > 1 iterations for future works."
CONVERGENCE PROPERTIES,0.12447552447552447,"4
CONVERGENCE PROPERTIES"
CONVERGENCE PROPERTIES,0.1258741258741259,"To study theoretical properties of ICSGLD, we Ô¨Årst show a local stability property that is well-suited
to big data problems, and then we present the asymptotic normality for the stochastic approxi-
mation process in mini-batch settings, which eventually yields the desired result that ICSGLD is
asymptotically more efÔ¨Åcient than a single-chain CSGLD with an equivalent computational cost."
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.12727272727272726,"4.1
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.12867132867132866,"The Ô¨Årst obstacle for the theoretical study is to approximate the components of Œ∏‚àûcorresponding to
the high energy region. To get around this issue, the random Ô¨Åeld function eH(Œ∏, x) in (8) is adopted"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.13006993006993006,to estimate a different target Œ∏‚ãÜ‚àùŒ∏
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.13146853146853146,"1
Œ∂‚àû. As detailed in Lemma 3 in the supplementary material, the
mean-Ô¨Åeld equation is now formulated as follows"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.13286713286713286,"hi(Œ∏) ‚àùŒ∏Œ∂
‚ãÜ(i) ‚àí(Œ∏(i)CŒ∏)Œ∂ + perturbations,
(10)"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.13426573426573427,"where CŒ∏ =

e
ZŒ∂,Œ∏
e
ZŒ∂
Œ∂,Œ∏‚ãÜ  1"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.13566433566433567,"Œ∂
and eZŒ∂,Œ∏ = Pm
k=1 R"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.13706293706293707,Xk œÄ(x)dx
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.13846153846153847,Œ∏Œ∂‚àí1(k) . We see that (10) may not be linearly stable
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.13986013986013987,"as in Deng et al. (2020b). Although the solution of the mean-Ô¨Åeld system h(Œ∏) = 0 is still unique,
there may exist unstable invariant subspaces, leading us to consider the local properties. For a proper
initialization of Œ∏, which can be achieved by pre-training the model long enough time through SGLD,
the mean value theorem implies a linear property in a local region
hi(Œ∏) ‚àùŒ∏‚ãÜ(i) ‚àíŒ∏(i) + perturbations.
Combining the perturbation theory (Vanden-Eijnden, 2001), we present the following stability result:"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.14125874125874127,"Lemma 1 (Local stability, informal version of Lemma 3) Assume Assumptions A1-A4 (given in
the supplementary material) hold. For any properly initialized Œ∏, we have ‚ü®h(Œ∏), Œ∏ ‚àíbŒ∏‚ãÜ‚ü©‚â§"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.14265734265734265,"‚àíœÜ‚à•Œ∏ ‚àíbŒ∏‚ãÜ‚à•2, where bŒ∏‚ãÜ= Œ∏‚ãÜ+ O
 
supx Var(Œæn(x)) + œµ + 1"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.14405594405594405,"m

, Œ∏‚ãÜ‚àùŒ∏"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.14545454545454545,"1
Œ∂‚àû, œÜ > 0, œµ denotes a
learning rate, and Œæn(x) denotes the noise in the stochastic energy estimator of batch size n and
Var(¬∑) denotes the variance."
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.14685314685314685,"By justifying the drift conditions of the adaptive transition kernel and relevant smoothness properties,
we can prove the existence and regularity properties of the solution of the Poisson‚Äôs equation in
Lemma 6 in the supplementary material. In what follows, we can control the Ô¨Çuctuations in stochastic
approximation and eventually yields the L2 convergence."
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.14825174825174825,"Lemma 2 (L2 convergence rate, informal version of Lemma 7) Given standard Assumptions A1-
A5. Œ∏k converges to bŒ∏‚ãÜ, where bŒ∏‚ãÜ= Œ∏‚ãÜ+ O
 
supx Var(Œæn(x)) + œµ + 1"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.14965034965034965,"m

, such that"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.15104895104895105,"E
h
‚à•Œ∏k ‚àíbŒ∏‚ãÜ‚à•2i
= O (œâk) ."
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.15244755244755245,Published as a conference paper at ICLR 2022
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.15384615384615385,"The result differs from Theorem 1 of Deng et al. (2020b) in that the biased Ô¨Åxed point bŒ∏‚ãÜinstead of
Œ∏‚ãÜis treated as the equilibrium of the continuous system, which provides us a user-friendly proof.
Similar techniques have been adopted by Durmus & ¬¥Eric Moulines (2017); Xu et al. (2018). Although"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.15524475524475526,"the global stability (Deng et al., 2020b) may be sacriÔ¨Åced when Œ∂ Ã∏= 1 based on Eq.(8), Œ∏‚ãÜ‚àùŒ∏"
LOCAL STABILITY FOR NON-LINEAR MEAN-FIELD SYSTEMS IN BIG DATA,0.15664335664335666,"1
Œ∂‚àûis
much easier to estimate numerically for any i that yields 0 < Œ∏‚àû(i) ‚â™1 based on a large Œ∂ > 1."
ASYMPTOTIC NORMALITY,0.15804195804195803,"4.2
ASYMPTOTIC NORMALITY"
ASYMPTOTIC NORMALITY,0.15944055944055943,"To study the asymptotic behavior of œâ
‚àí1"
K,0.16083916083916083,"2
k
(Œ∏k ‚àíbŒ∏‚ãÜ), where bŒ∏‚ãÜis the equilibrium point s.t. bŒ∏‚ãÜ=
Œ∏‚ãÜ+O
 
Var(Œæn(x)) + œµ + 1"
K,0.16223776223776223,"m

, we consider a Ô¨Åxed step size œâ in the SA step for ease of explanation.
Let ¬ØŒ∏t denote the solution of the mean-Ô¨Åeld system in continuous time (¬ØŒ∏0 = Œ∏0), and rewrite the
single-chain SA step (7) as follows"
K,0.16363636363636364,"Œ∏k+1 ‚àí¬ØŒ∏(k+1)œâ = Œ∏k ‚àí¬ØŒ∏kœâ + œâ
 
H(Œ∏k, xk+1) ‚àíH(¬ØŒ∏kœâ, xk+1)
"
K,0.16503496503496504,"+ œâ
 
H(¬ØŒ∏kœâ, xk+1) ‚àíh(¬ØŒ∏kœâ)

‚àí
 ¬ØŒ∏(k+1)œâ ‚àí¬ØŒ∏kœâ ‚àíœâh(¬ØŒ∏kœâ)

."
K,0.16643356643356644,"Further, we set eŒ∏kœâ := œâ‚àí1"
K,0.16783216783216784,"2 (Œ∏k ‚àí¬ØŒ∏kœâ). Then the stochastic approximation differs from the mean
Ô¨Åeld system in that"
K,0.16923076923076924,"eŒ∏(k+1)œâ = œâ
1
2 k
X i=0"
K,0.17062937062937064," 
H(Œ∏i, xi+1) ‚àíH(¬ØŒ∏iœâ, xi+1)
"
K,0.17202797202797201,"|
{z
}
I: perturbations"
K,0.17342657342657342,"+œâ
1
2 k
X i=0"
K,0.17482517482517482," 
H(¬ØŒ∏iœâ, xi+1) ‚àíh(¬ØŒ∏iœâ)
"
K,0.17622377622377622,"|
{z
}
II: martingale Mi"
K,0.17762237762237762,"‚àíœâ
1
2 ¬∑ remainder"
K,0.17902097902097902,"‚âàœâ
1
2 k
X"
K,0.18041958041958042,"i=0
hŒ∏(Œ∏iœâ) (Œ∏i ‚àí¬ØŒ∏iœâ)
|
{z
}"
K,0.18181818181818182,"‚âàœâ
1
2 eŒ∏iœâ"
K,0.18321678321678322,"+œâ
1
2 k
X"
K,0.18461538461538463,"i=0
Mi ‚âà
Z (k+1)œâ"
K,0.18601398601398603,"0
hŒ∏(¬ØŒ∏s)eŒ∏sds +
Z (k+1)œâ"
R,0.1874125874125874,"0
R
1
2 (¬ØŒ∏s)dWs,"
R,0.1888111888111888,"where hŒ∏(Œ∏) :=
d
dŒ∏h(Œ∏) is a matrix, W ‚ààRm is a standard Brownian motion, the last term follows
from a certain central limit theorem (Benveniste et al., 1990) and R denotes the covariance matrix of
the random-Ô¨Åeld function s.t. R(Œ∏) := P‚àû
k=‚àí‚àûCovŒ∏(H(Œ∏, xk), H(Œ∏, x0))."
R,0.1902097902097902,We expect the weak convergence of Uk to the stationary distribution of a diffusion
R,0.1916083916083916,"dUt = hŒ∏(Œ∏t)Utdt + R1/2(Œ∏t)dWt,
(11)"
R,0.193006993006993,"where Ut = œâ‚àí1/2
t
(Œ∏t ‚àíbŒ∏‚ãÜ). Given that Œ∏t converges to bŒ∏‚ãÜsufÔ¨Åciently fast and the local linearity of
hŒ∏, the diffusion (11) resembles the Ornstein‚ÄìUhlenbeck process and yields the following solution"
R,0.1944055944055944,"Ut ‚âàe‚àíthŒ∏(bŒ∏‚ãÜ)U0 +
Z t"
R,0.1958041958041958,"0
e‚àí(t‚àís)hŒ∏(bŒ∏‚ãÜ) ‚ó¶R(bŒ∏‚ãÜ)dWs."
R,0.1972027972027972,"Then we have the following theorem, whose formal proof is given in section C.3."
R,0.1986013986013986,"Theorem 1 (Asymptotic Normality) Assume Assumptions A1-A5 (given in the supplementary ma-
terial) hold. We have the following weak convergence"
R,0.2,"œâ‚àí1/2
k
(Œ∏k ‚àíbŒ∏‚ãÜ) ‚áíN(0, Œ£), where Œ£ =
Z ‚àû"
R,0.2013986013986014,"0
ethŒ∏‚ãÜ‚ó¶R ‚ó¶eth‚ä§
Œ∏‚ãÜdt, hŒ∏‚ãÜ= hŒ∏(bŒ∏‚ãÜ)."
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT,0.20279720279720279,"4.3
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT"
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT,0.2041958041958042,"For clarity, we Ô¨Årst denote an estimate of Œ∏ based on ICSGLD with P interacting parallel chains by
Œ∏P
k and denote the estimate based on a single-long-chain CSGLD by Œ∏kP ."
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT,0.2055944055944056,"Note that Theorem 1 holds for any step size œâk = O(k‚àíŒ±), where Œ± ‚àà(0.5, 1]. If we simply run a
single-chain CSGLD algorithm with P times of iterations, by Theorem 1,"
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT,0.206993006993007,"œâ‚àí1/2
kP
(Œ∏kP ‚àíbŒ∏‚ãÜ) ‚áíN(0, Œ£)."
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT,0.2083916083916084,"As to ICSGLD, since the covariance Œ£ relies on R, which depends on the covariance of the
martingale {Mi}i‚â•1, the conditional independence of x(1), x(2), ¬∑ ¬∑ ¬∑ , x(P ) naturally results in an
efÔ¨Åcient variance reduction such that"
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT,0.2097902097902098,Published as a conference paper at ICLR 2022
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT,0.2111888111888112,"Corollary 1 (Asymptotic Normality for ICSGLD) Assume the same assumptions. For ICSGLD
with P interacting chains, we have the following weak convergence"
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT,0.2125874125874126,"œâ‚àí1/2
k
(Œ∏P
k ‚àíbŒ∏‚ãÜ) ‚áíN(0, Œ£/P)."
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT,0.213986013986014,"That is, under a similar computational budget, we have ‚à•Var(Œ∏kP ‚àíbŒ∏‚ãÜ)‚à•F"
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT,0.2153846153846154,"‚à•Var(Œ∏P
k ‚àíbŒ∏‚àó)‚à•F =
wkP
wk/P ‚âàP 1‚àíŒ±."
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT,0.21678321678321677,"Corollary 2 (EfÔ¨Åciency) Given a decreasing step size œâk = O(k‚àíŒ±), where 0.5 < Œ± < 1, ICSGLD
is asymptotically more efÔ¨Åcient than the single-chain CSGLD with an equivalent training cost."
INTERACTING PARALLEL CHAINS ARE MORE EFFICIENT,0.21818181818181817,"In practice, slowly decreasing step sizes are often preferred in stochastic algorithms for a better
non-asymptotic performance (Benveniste et al., 1990)."
EXPERIMENTS,0.21958041958041957,"5
EXPERIMENTS"
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION,0.22097902097902097,"5.1
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION"
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION,0.22237762237762237,"This section shows how the novel random-Ô¨Åeld function (8) facilitates the exploration of multiple
modes on the MNIST dataset¬ß, while the standard methods, such as stochastic gradient descent (SGD)
and SGLD, only get stuck in few local modes. To simplify the experiments, we choose a large batch
size of 2500 and only pick the Ô¨Årst Ô¨Åve classes, namely digits from 0 to 4. The learning rate is Ô¨Åxed
to 1e-6 and the temperature is set to 0.1 ‚Ä†. We see from Figure 2(a) that both SGD and SGLD lead to
fast decreasing losses. By contrast, ICSGLD yields Ô¨Çuctuating losses that traverse freely between
high energy and low energy regions. As the particles stick in local regions, the penalty of re-visiting
these zones keeps increasing until a negative learning rate is injected to encourage explorations."
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION,0.22377622377622378,"(a) Training Loss
(b) SGD
(c) SGLD
(d) ICSGLD 0 20 40"
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION,0.22517482517482518,"0
100
200
300
400
500
Epochs"
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION,0.22657342657342658,Losses (in thousands)
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION,0.22797202797202798,"ICSGLD
SGLD
SGD 10 7 4 1 2"
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION,0.22937062937062938,"4
1
2
5 100 1000 10000"
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION,0.23076923076923078,Trajectory 10 7 4 1 5 1 3 7
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION,0.23216783216783216,"Trajectory 0 10 20 30
15 5 5"
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION,0.23356643356643356,Trajectory
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION,0.23496503496503496,Figure 2: Visualization of mode exploration on a MNIST example based on different algorithms.
LANDSCAPE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION,0.23636363636363636,"We conducted a singular value decomposition (SVD) based on the Ô¨Årst two coordinates to visualize
the trajectories: We Ô¨Årst choose a domain that includes all the coordinates, then we recover the
parameter based on the grid point and truncated values in other dimensions, and Ô¨Ånally we Ô¨Åne-tune
the parameters and present the approximate losses of the trajectories in Figure 2(b-d). We see SGD
trajectories get stuck in a local region; SGLD exploits a larger region but is still quite limited in
the exploration; ICSGLD, instead, Ô¨Årst converges to a local region and then escapes it once it over-
visits this region. This shows the strength of ICSGLD in the simulations of complex multi-modal
distributions. More experimental details are presented in section D.1 of the supplementary material."
SIMULATIONS OF MULTI-MODAL DISTRIBUTIONS,0.23776223776223776,"5.2
SIMULATIONS OF MULTI-MODAL DISTRIBUTIONS"
SIMULATIONS OF MULTI-MODAL DISTRIBUTIONS,0.23916083916083916,"This section shows the acceleration effect of ICSGLD via a group of simulation experiments for
a multi-modal distribution. The baselines include popular Monte Carlo methods such as CSGLD,
SGLD, cyclical SGLD (cycSGLD), replica exchange SGLD (reSGLD), and the particle-based SVGD."
SIMULATIONS OF MULTI-MODAL DISTRIBUTIONS,0.24055944055944056,"The target multi-modal density is presented in Figure 3(a). Figure 3(b-g) displays the empirical
performance of all the testing methods: the vanilla SGLD with 5 parallel chains (√óP5) undoubtedly"
SIMULATIONS OF MULTI-MODAL DISTRIBUTIONS,0.24195804195804196,"¬ßThe random-Ô¨Åeld function (Deng et al., 2020b) requires an extra perturbation term as discussed in section
D4 in the supplementary material (Deng et al., 2020b); therefore it is not practically appealing in big data.
‚Ä†Data augmentation implicitly leads to a more concentrated posterior (Wenzel et al., 2020; Aitchison, 2021)."
SIMULATIONS OF MULTI-MODAL DISTRIBUTIONS,0.24335664335664337,Published as a conference paper at ICLR 2022
SIMULATIONS OF MULTI-MODAL DISTRIBUTIONS,0.24475524475524477,"performs the worst in this example and fails to quantify the weights of each mode correctly; the
single-chain cycSGLD with 5 times of iterations (√óT5) improves the performance but is still not
accurate enough; reSGLD (√óP5) and SVGD (√óP5) have good performances, while the latter is
quite costly in computations; ICSGLD (√óP5) does not only traverse freely over the rugged energy
landscape, but also yields the most accurate approximation to the ground truth distribution. By
contrast, CSGLD (√óT5) performs worse than ICSGLD and overestimates the weights on the left side.
For the detailed setups, the study of convergence speed, and runtime analysis, we refer interested
readers to section D.2 in the supplementary material."
SIMULATIONS OF MULTI-MODAL DISTRIBUTIONS,0.24615384615384617,"(a) Truth
(b) SGLD
(c) cycSGLD
(d) SVGD
(e) reSGLD
(f) CSGLD
(g) ICSGLD
Figure 3: Empirical behavior on a simulation dataset. Figure 3(c) and 3(f) show the simulation based
on a single chain with 5 times of iterations (√óT5) and the others run 5 parallel chains (√óP5)."
DEEP CONTEXTUAL BANDITS ON MUSHROOM TASKS,0.24755244755244754,"5.3
DEEP CONTEXTUAL BANDITS ON MUSHROOM TASKS"
DEEP CONTEXTUAL BANDITS ON MUSHROOM TASKS,0.24895104895104894,"This section evaluates ICSGLD on the contextual bandit problem based on the UCI Mushroom
data set as in Riquelme et al. (2018). The mushrooms are assumed to arrive sequentially and the
agent needs to take an action at each time step based on past feedbacks. Our goal is to minimize
the cumulative regret that measures the difference between the cumulative reward obtained by the
proposed policy and optimal policy. We evaluate Thompson Sampling (TS) based on a variety of
approximate inference methods for posterior sampling. We choose one œµ-greedy policy (EpsGreedy)
based on the RMSProp optimizer with a decaying learning rate (Riquelme et al., 2018) as a baseline.
Two variational methods, namely stochastic gradient descent with a constant learning rate (ConstSGD)
(Mandt et al., 2017) and Monte Carlo Dropout (Dropout) (Gal & Ghahramani, 2016) are compared
to approximate the posterior distribution. For the sampling algorithms, we include preconditioned
SGLD (pSGLD) (Li et al., 2016), preconditioned CSGLD (pCSGLD) (Deng et al., 2020b), and
preconditioned ICSGLD (pICSGLD). Note that all the algorithms run 4 parallel chains with average
outputs (√óP4) except that pCSGLD runs a single-chain with 4 times of computational budget (√óT4).
For more details, we refer readers to section D.3 in the supplementary material."
DEEP CONTEXTUAL BANDITS ON MUSHROOM TASKS,0.25034965034965034,"Figure 4 shows that EpsGreedy √óP4 tends to explore too much for a long horizon as expected;
ConstSGD√óP4 and Dropout√óP4 perform poorly in the beginning but eventually outperform Eps-
Greedy √óP4 due to the inclusion of uncertainty for exploration, whereas the uncertainty seems to
be inadequate due to the nature of variational inference. By contrast, pSGLD√óP4 signiÔ¨Åcantly 6000 7000 8000 9000"
DEEP CONTEXTUAL BANDITS ON MUSHROOM TASKS,0.2517482517482518,"0
500
1000
1500
2000
Steps"
DEEP CONTEXTUAL BANDITS ON MUSHROOM TASKS,0.25314685314685315,Cumulative Regret
DEEP CONTEXTUAL BANDITS ON MUSHROOM TASKS,0.2545454545454545,"EpsGreedy xP4
ConstSGD xP4
Dropout xP4
pCSGLD xT4
pSGLD xP4
pICSGLD xP4"
DEEP CONTEXTUAL BANDITS ON MUSHROOM TASKS,0.25594405594405595,"Figure 4: Cumulative regret
on the mushroom task."
DEEP CONTEXTUAL BANDITS ON MUSHROOM TASKS,0.2573426573426573,"outperforms the variational methods by considering preconditioners
within an exact sampling framework (SGLD). As a unique algo-
rithm that runs in a single-chain manner, pCSGLD√óT4 leads to
the worst performance due to the inefÔ¨Åciency in learning the self-
adapting parameters, fortunately, pCSGLD√óT4 slightly outperform
pSGLD√óP4 in the later phase with the help of the well-estimated
self-adapting parameters. Nevertheless, pICSGLD√óP4 propose to
optimize the shared self-adapting parameters at the same time, which
in turn greatly contributes to the simulation of the posterior. As a
result, pICSGLD√óP4 consistently shows the lowest regret exclud-
ing the very early period. This shows the great superiority of the
interaction mechanism in learning the self-adapting parameters for
accelerating the simulations."
UNCERTAINTY ESTIMATION,0.25874125874125875,"5.4
UNCERTAINTY ESTIMATION"
UNCERTAINTY ESTIMATION,0.2601398601398601,"This section evaluates the qualify of our algorithm in uncertainty quantiÔ¨Åcation. For model architec-
tures, we use residual networks (ResNet) (He et al., 2016) and a wide ResNet (WRN) (Zagoruyko
& Komodakis, 2016); we choose 20, 32, and 56-layer ResNets (denoted by ResNet20, et al.) and a
WRN-16-8 network, a 16-layer WRN that is 8 times wider than ResNet16. We train the models on"
UNCERTAINTY ESTIMATION,0.26153846153846155,Published as a conference paper at ICLR 2022
UNCERTAINTY ESTIMATION,0.2629370629370629,"CIFAR100, and report the test accuracy (ACC) and test negative log-likelihood (NLL) based on 5
trials with standard error. For the out-of-distribution prediction performance, we test the well-trained
models in Brier scores (Brier) * on the Street View House Numbers dataset (SVHN)."
UNCERTAINTY ESTIMATION,0.26433566433566436,"Due to the wide adoption of momentum stochastic gradient descent (M-SGD), we use stochastic
gradient Hamiltonian Monte Carlo (SGHMC) (Chen et al., 2014) as the baseline sampling algorithm
and denote the interacting contour SGHMC by ICSHMC. In addition, we include several high
performing baselines, such as SGHMC with cyclical learning rates (cycSGHMC) (Zhang et al.,
2020b), SWAG based on cyclic learning rates of 10 cycles (cycSWAG) (Maddox et al., 2019) and
variance-reduced replica exchange SGHMC (reSGHMC) (Deng et al., 2021a). For a fair comparison,
ICSGLD also conducts variance reduction on the energy function to alleviate the bias. Moreover, a
large Œ∂ = 3 √ó 106 is selected, which only induces mild gradient multipliers ranging from ‚àí1 to 2 to
penalize over-visited partitions. We don‚Äôt include SVGD (Liu & Wang, 2016) and SPOS (Zhang et al.,
2020a) for scalability reasons. A batch size of 256 is selected. We run 4 parallel processes (√óP4)
with 500 epochs for M-SGD, reSGHMC and ICSGHMC and run cycSGHMC and cycSWAG 2000
epochs (√óT4) based on a single process with 10 cycles. Refer to section D.4 of the supplementary
material for the detailed settings."
UNCERTAINTY ESTIMATION,0.26573426573426573,TABLE 1: UNCERTAINTY ESTIMATIONS ON CIFAR100 AND SVHN.
UNCERTAINTY ESTIMATION,0.26713286713286716,"MODEL
ResNet20
ResNet32
ACC (%)
NLL
Brier (‚Ä∞)
ACC (%)
NLL
Brier (‚Ä∞)
cycSGHMC√óT4
75.41¬±0.10
8437¬±30
2.91¬±0.13
77.93¬±0.17
7658¬±19
3.29¬±0.13
cycSWAG√óT4
75.46¬±0.11
8419¬±26
2.78¬±0.12
77.91¬±0.15
7656¬±22
3.19¬±0.14
M-SGD√óP4
76.01¬±0.12
8175¬±25
2.58¬±0.08
78.41¬±0.12
7501¬±23
2.77¬±0.15
reSGHMC√óP4
76.15¬±0.16
8196¬±27
2.73¬±0.10
78.57¬±0.07
7454¬±15
3.04¬±0.09
ICSGHMC√óP4
76.34¬±0.15
8076¬±31
2.54¬±0.14
78.72¬±0.16
7406¬±29
2.76¬±0.15"
UNCERTAINTY ESTIMATION,0.26853146853146853,"MODEL
ResNet56
WRN-16-8
ACC (%)
NLL
Brier (‚Ä∞)
ACC (%)
NLL
Brier (‚Ä∞)
cycSGHMC√óT4
81.23¬±0.19
6770¬±59
3.18¬±0.08
82.98¬±0.03
6384¬±11
2.17¬±0.05
cycSWAG√óT4
81.14¬±0.11
6744¬±55
3.06¬±0.09
83.05¬±0.04
6359¬±14
2.04¬±0.07
M-SGD√óP4
81.03¬±0.14
6847¬±22
2.86¬±0.08
82.57¬±0.07
6821¬±21
1.77¬±0.06
reSGHMC√óP4
81.11¬±0.16
6915¬±40
2.92¬±0.12
82.72¬±0.08
6452¬±19
1.92¬±0.04
ICSGHMC√óP4
81.51¬±0.18
6630¬±38
2.88¬±0.09
83.12¬±0.10
6338¬±36
1.83¬±0.06"
UNCERTAINTY ESTIMATION,0.2699300699300699,"Table 1 shows that the vanilla ensemble results via M-SGD√óP4 surprisingly outperform
cycSGHMC√óT4 and cycSWAG√óT4 on medium models, such as ResNet20 and ResNet32, and
show very good performance on the out-of-distribution samples in Brier scores. We suspect that
the parallel implementation (√óP4) provides isolated initializations with less correlated samples; by
contrast, cycSGHMC√óT4 and cycSWAG√óT4 explore the energy landscape contiguously, implying a
risk to stay near the original region. reSGHMC√óP4 shows a remarkable performance overall, but
demonstrates a large variance occasionally; this indicates the insufÔ¨Åciency of the swaps when multiple
processes are included. When it comes to testing WRN-16-8, cycSWAG√óT4 shows a marvelous
result and a large improvement compared to the other baselines. We conjecture that cycSWAG is
more independent of hyperparameter tuning, thus leading to better performance in larger models.
We don‚Äôt report CSGHMC√óP4 since it becomes quite unstable during the training of ResNet56 and
WRN-16-8 models and causes mediocre results. As to ICSGHMC√óP4, it consistently performs
remarkable in both ACC and NLL and performs comparable to M-SGD√óP4 in Brier scores."
UNCERTAINTY ESTIMATION,0.27132867132867133,Code is available at github.com/WayneDW/Interacting-Contour-Stochastic-Gradient-Langevin-Dynamics.
CONCLUSION,0.2727272727272727,"6
CONCLUSION"
CONCLUSION,0.27412587412587414,"We have proposed the ICSGLD as an efÔ¨Åcient algorithm for sampling from distributions with a
complex energy landscape, and shown theoretically that ICSGLD is indeed more efÔ¨Åcient than
the single-chain CSGLD for a slowly decreasing step size. To our best knowledge, this is the
Ô¨Årst interacting importance sampling algorithm that adapts to big data problems without scalability
concerns. ICSGLD has been compared with numerous state-of-the-art baselines for various tasks,
whose remarkable results indicate its promising future in big data applications."
CONCLUSION,0.2755244755244755,*The Brier score measures the mean squared error between the predictive and actual probabilities.
CONCLUSION,0.27692307692307694,Published as a conference paper at ICLR 2022
CONCLUSION,0.2783216783216783,ACKNOWLEDGMENT
CONCLUSION,0.27972027972027974,"Liang‚Äôs research was supported in part by the grants DMS-2015498, R01-GM117597 and R01-
GM126089. Lin acknowledges the support from NSF (DMS-1555072, DMS-2053746, and DMS-
2134209), BNL Subcontract 382247, and DE-SC0021142."
REFERENCES,0.2811188811188811,REFERENCES
REFERENCES,0.28251748251748254,"Sungjin Ahn, Anoop Korattikara, and Max Welling. Bayesian Posterior Sampling via Stochastic
Gradient Fisher Scoring. In Proc. of the International Conference on Machine Learning (ICML),
2012."
REFERENCES,0.2839160839160839,"Sungjin Ahn, Babak Shahbaba, and Max Welling. Distributed Stochastic Gradient MCMC. In Proc.
of the International Conference on Machine Learning (ICML), 2014."
REFERENCES,0.2853146853146853,"Laurence Aitchison. A Statistical Theory of Cold Posteriors in Deep Neural Networks. In Proc. of
the International Conference on Learning Representation (ICLR), 2021."
REFERENCES,0.2867132867132867,"C. Andrieu, E. Moulines, and P. Priouret. Stability of Stochastic Approximation under VeriÔ¨Åable
Conditions. SIAM J. Control Optim., 44(1):283‚Äì312, 2005."
REFERENCES,0.2881118881118881,"Christophe Andrieu, Arnaud Doucet, and Roman Holenstein. Particle Markov Chain Monte Carlo
Methods. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 72(3), 2010."
REFERENCES,0.2895104895104895,"Albert Benveniste, Michael M¬¥etivier, and Pierre Priouret. Adaptive Algorithms and Stochastic
Approximations. Berlin: Springer, 1990."
REFERENCES,0.2909090909090909,"Elmar Bittner, Andreas Nussbaumer, and Wolfhard Janke. Make Life Simple: Unleash the Full Power
of the Parallel Tempering Algorithm. Physical Review Letters, 101:130603‚Äì130603, 2008."
REFERENCES,0.2923076923076923,"Changyou Chen, Nan Ding, and Lawrence Carin. On the Convergence of Stochastic Gradient MCMC
Algorithms with High-order Integrators. In Advances in Neural Information Processing Systems
(NeurIPS), pp. 2278‚Äì2286, 2015."
REFERENCES,0.2937062937062937,"Changyou Chen, Nan Ding, Chunyuan Li, Yizhe Zhang, and Lawrence Carin. Stochastic Gradient
MCMC with Stale Gradients. In Advances in Neural Information Processing Systems (NeurIPS),
2016."
REFERENCES,0.2951048951048951,"Tianqi Chen, Emily B. Fox, and Carlos Guestrin. Stochastic Gradient Hamiltonian Monte Carlo. In
Proc. of the International Conference on Machine Learning (ICML), 2014."
REFERENCES,0.2965034965034965,"Wei Deng, Qi Feng, Liyao Gao, Faming Liang, and Guang Lin. Non-Convex Learning via Replica
Exchange Stochastic Gradient MCMC. In Proc. of the International Conference on Machine
Learning (ICML), 2020a."
REFERENCES,0.29790209790209793,"Wei Deng, Guang Lin, and Faming Liang. A Contour Stochastic Gradient Langevin Dynamics
Algorithm for Simulations of Multi-modal Distributions. In Advances in Neural Information
Processing Systems (NeurIPS), 2020b."
REFERENCES,0.2993006993006993,"Wei Deng, Qi Feng, Georgios Karagiannis, Guang Lin, and Faming Liang. Accelerating Conver-
gence of Replica Exchange Stochastic Gradient MCMC via Variance Reduction. In Proc. of the
International Conference on Learning Representation (ICLR), 2021a."
REFERENCES,0.3006993006993007,"Wei Deng, Yi-An Ma, Zhao Song, Qian Zhang, and Guang Lin. On Convergence of Federated
Averaging Langevin Dynamics. arXiv:2112.05120v1, 2021b."
REFERENCES,0.3020979020979021,"Nan Ding, Youhan Fang, Ryan Babbush, Changyou Chen, Robert D. Skeel, and Hartmut Neven.
Bayesian Sampling using Stochastic Gradient Thermostats. In Advances in Neural Information
Processing Systems (NeurIPS), pp. 3203‚Äì3211, 2014."
REFERENCES,0.3034965034965035,"Arnaud Doucet, Nando de Freitas, and Neil Gordon. Sequential Monte Carlo Methods in Practice.
Springer Science & Business Media, 2001."
REFERENCES,0.3048951048951049,Published as a conference paper at ICLR 2022
REFERENCES,0.3062937062937063,"Alain Durmus and ¬¥Eric Moulines.
Non-asymptotic Convergence Analysis for the Unadjusted
Langevin Algorithm. Annals of Applied Probability, 27:1551‚Äì1587, 2017."
REFERENCES,0.3076923076923077,"David J. Earl and Michael W. Deem. Parallel Tempering: Theory, Applications, and New Perspectives.
Phys. Chem. Chem. Phys., 7:3910‚Äì3916, 2005."
REFERENCES,0.3090909090909091,"Murat A Erdogdu, Lester Mackey, and Ohad Shamir. Global Non-convex Optimization with Dis-
cretized Diffusions. In Advances in Neural Information Processing Systems (NeurIPS), 2018."
REFERENCES,0.3104895104895105,"G. Fort, E. Moulines, and P. Priouret. Convergence of Adaptive and Interacting Markov Chain Monte
Carlo Algorithms. Annals of Statistics, 39:3262‚Äì3289, 2011."
REFERENCES,0.3118881118881119,"G. Fort, B. Jourdain, E. Kuhn, T. Leli`evre, and G. Stoltz. Convergence of the Wang-Landau Algorithm.
Math. Comput., 84(295):2297‚Äì2327, 2015."
REFERENCES,0.3132867132867133,"Futoshi Futami, Issei Sato, and Masashi Sugiyama. Accelerating the Diffusion-based Ensemble
Sampling by Non-reversible Dynamics. In Proc. of the International Conference on Machine
Learning (ICML), 2020."
REFERENCES,0.3146853146853147,"Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian Approximation: Representing Model
Uncertainty in Deep Learning. In Proc. of the International Conference on Machine Learning
(ICML), 2016."
REFERENCES,0.31608391608391606,"Charles J. Geyer. Markov Chain Monte Carlo Maximum Likelihood. Computing Science and
Statistics: Proceedings of the 23rd Symposium on the Interfac, pp. 156‚Äì163, 1991."
REFERENCES,0.3174825174825175,"Neil J Gordon, David J Salmond, and Adrian FM Smith. Novel Approach to Nonlinear/Non-Gaussian
Bayesian State Estimation. IEE Proceedings F (Radar and Signal Processing), 140(2), 1993."
REFERENCES,0.31888111888111886,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image
Recognition. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016."
REFERENCES,0.3202797202797203,"Pavel Izmailov, Dmitry Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gordon Wilson.
Averaging Weights Leads to Wider Optima and Better Generalization. In Proc. of the Conference
on Uncertainty in ArtiÔ¨Åcial Intelligence (UAI), 2018."
REFERENCES,0.32167832167832167,"K. Jarrett, K. Kavukcuoglu, M. Ranzato, and Y. LeCun. What is the Best Multi-stage Architecture
for Object Recognition? In Proc. of the International Conference on Computer Vision (ICCV), pp.
2146‚Äì2153, September 2009."
REFERENCES,0.3230769230769231,"Helmut G Katzgraber, Simon Trebst, David A Huse, and Matthias Troyer. Feedback-Optimized
Parallel Tempering Monte Carlo. Journal of Statistical Mechanics: Theory and Experiment, pp. p.
P03018, 2008."
REFERENCES,0.32447552447552447,"Chunyuan Li, Changyou Chen, David Carlson, and Lawrence Carin. Preconditioned Stochastic
Gradient Langevin Dynamics for Deep Neural Networks. In Proc. of the National Conference on
ArtiÔ¨Åcial Intelligence (AAAI), pp. 1788‚Äì1794, 2016."
REFERENCES,0.3258741258741259,"Chunyuan Li, Changyou Chen, Yunchen Pu, Ricardo Henao, and Lawrence Carin. Communication-
EfÔ¨Åcient Stochastic Gradient MCMC for Neural Networks. In Proc. of the National Conference on
ArtiÔ¨Åcial Intelligence (AAAI), 2019a."
REFERENCES,0.32727272727272727,"Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the Convergence of
FedAvg on Non-IID Data. In Proc. of the International Conference on Learning Representation
(ICLR), 2020."
REFERENCES,0.32867132867132864,"Xuechen Li, Denny Wu, Lester Mackey, and Murat A. Erdogdu. Stochastic Runge-Kutta Accelerates
Langevin Monte Carlo and Beyond. In Advances in Neural Information Processing Systems
(NeurIPS), pp. 7746‚Äì7758, 2019b."
REFERENCES,0.3300699300699301,"Faming Liang, Chuanhai Liu, and Raymond J. Carroll. Stochastic Approximation in Monte Carlo
Computation. Journal of the American Statistical Association, 102:305‚Äì320, 2007."
REFERENCES,0.33146853146853145,"Qiang Liu and Dilin Wang. Stein Variational Gradient Descent: A General Purpose Bayesian
Inference Algorithm. In Advances in Neural Information Processing Systems (NeurIPS), 2016."
REFERENCES,0.3328671328671329,Published as a conference paper at ICLR 2022
REFERENCES,0.33426573426573425,"Wesley Maddox, Timur Garipov, Pavel Izmailov, Dmitry Vetrov, and Andrew Gordon Wilson. A
Simple Baseline for Bayesian Uncertainty in Deep Learning. In Advances in Neural Information
Processing Systems (NeurIPS), 2019."
REFERENCES,0.3356643356643357,"Stephan Mandt, Matthew D. Hoffman, and David M. Blei. Stochastic Gradient Descent as Approxi-
mate Bayesian Inference. Journal of Machine Learning Research, 18:1‚Äì35, 2017."
REFERENCES,0.33706293706293705,"J.C. Mattingly, A.M. Stuartb, and D.J. Highamc. Ergodicity for SDEs and Approximations: Locally
Lipschitz Vector Fields and Degenerate Noise. Stochastic Processes and their Applications, 101:
185‚Äì232, 2002."
REFERENCES,0.3384615384615385,"Jonathan C. Mattingly, Andrew M. Stuart, and M.V. Tretyakov. Convergence of Numerical Time-
Averaging and Stationary Measures via Poisson Equations. SIAM Journal on Numerical Analysis,
48:552‚Äì577, 2010."
REFERENCES,0.33986013986013985,"Mariane Pelletier. Weak Convergence Rates for Stochastic Approximation with Application to
Multiple Targets and Simulated Annealing. Annals of Applied Probability, 8:10‚Äì44, 1998."
REFERENCES,0.3412587412587413,"Maxim Raginsky, Alexander Rakhlin, and Matus Telgarsky. Non-convex Learning via Stochastic
Gradient Langevin Dynamics: a Nonasymptotic Analysis. In Proc. of Conference on Learning
Theory (COLT), June 2017."
REFERENCES,0.34265734265734266,"Tom Rainforth, Christian A. Naesseth, Fredrik Lindsten, Brooks Paige, Jan-Willem van de Meent,
Arnaud Doucet, and Frank Wood. Interacting Particle Markov Chain Monte Carlo. In Proc. of the
International Conference on Machine Learning (ICML), 2016."
REFERENCES,0.34405594405594403,"Carlos Riquelme, George Tucker, and Jasper Snoek. Deep Bayesian Bandits Showdown. In Proc. of
the International Conference on Learning Representation (ICLR), 2018."
REFERENCES,0.34545454545454546,"Herbert Robbins and Sutton Monro. A Stochastic Approximation Method. Annals of Mathematical
Statistics, 22:400‚Äì407, 1951."
REFERENCES,0.34685314685314683,"Gareth O. Roberts and Richard L. Tweedie. Exponential Convergence of Langevin Distributions and
Their Discrete Approximations. Bernoulli, 2(4):341‚Äì363, 1996."
REFERENCES,0.34825174825174826,"Issei Sato and Hiroshi Nakagawa. Approximation Analysis of Stochastic Gradient Langevin Dynamics
by Using Fokker-Planck Equation and Ito Process. In Proc. of the International Conference on
Machine Learning (ICML), 2014."
REFERENCES,0.34965034965034963,"Qifan Song, Mingqi Wu, and Faming Liang. Weak Convergence Rates of Population versus Single-
Chain Stochastic Approximation MCMC Algorithms. Advances in Applied Probability, 46:
1059‚Äì1083, 2014."
REFERENCES,0.35104895104895106,"Robert H. Swendsen and Jian-Sheng Wang. Replica Monte Carlo Simulation of Spin-Glasses.
Physical Review Letters, 57:2607‚Äì2609, 1986."
REFERENCES,0.35244755244755244,"Saifuddin Syed, Alexandre Bouchard-CÀÜot¬¥e, George Deligiannidis, and Arnaud Doucet.
Non-
Reversible Parallel Tempering: a Scalable Highly Parallel MCMC scheme. Journal of Royal
Statistical Society, Series B, 2021."
REFERENCES,0.35384615384615387,"Yee Whye Teh, Alexandre Thi¬¥ery, and Sebastian Vollmer. Consistency and Fluctuations for Stochastic
Gradient Langevin Dynamics. Journal of Machine Learning Research, 17:1‚Äì33, 2016."
REFERENCES,0.35524475524475524,"Eric Vanden-Eijnden. Introduction to Regular Perturbation Theory. Slides, 2001. URL https:
//cims.nyu.edu/Àúeve2/reg_pert.pdf."
REFERENCES,0.35664335664335667,"Sebastian J. Vollmer, Konstantinos C. Zygalakis, and Yee Whye Teh. Exploration of the (Non-)
Asymptotic Bias and Variance of Stochastic Gradient Langevin Dynamics. Journal of Machine
Learning Research, 17(159):1‚Äì48, 2016."
REFERENCES,0.35804195804195804,"Fugao Wang and David P. Landau. EfÔ¨Åcient, Multiple-range Random Walk Algorithm to Calculate
the Density of States. Physical Review Letters, 86:2050‚Äì3, 2001."
REFERENCES,0.3594405594405594,"T. Weinhart, A. Singh, and A.R. Thornton. Perturbation Theory & Stability Analysis. Slides, 2010."
REFERENCES,0.36083916083916084,Published as a conference paper at ICLR 2022
REFERENCES,0.3622377622377622,"Max Welling and Yee Whye Teh. Bayesian Learning via Stochastic Gradient Langevin Dynamics. In
Proc. of the International Conference on Machine Learning (ICML), pp. 681‚Äì688, 2011."
REFERENCES,0.36363636363636365,"Florian Wenzel, Kevin Roth, Bastiaan S. Veeling, Jakub ¬¥Swiatkowski, Linh Tran, Stephan Mandt,
Jasper Snoek, Tim Salimans, Rodolphe Jenatton, and Sebastian Nowozin. How Good is the Bayes
Posterior in Deep Neural Networks Really? In Proc. of the International Conference on Machine
Learning (ICML), 2020."
REFERENCES,0.365034965034965,"Pan Xu, Jinghui Chen, Difan Zou, and Quanquan Gu. Global Convergence of Langevin Dynamics
Based Algorithms for Nonconvex Optimization. In Advances in Neural Information Processing
Systems (NeurIPS), 2018."
REFERENCES,0.36643356643356645,"Sergey Zagoruyko and Nikos Komodakis. Wide Residual Networks. In Proceedings of the British
Machine Vision Conference (BMVC), pp. 87.1‚Äì87.12, September 2016."
REFERENCES,0.3678321678321678,"Jianyi Zhang, Ruiyi Zhang, Lawrence Carin, and Changyou Chen. Stochastic Particle-Optimization
Sampling and the Non-Asymptotic Convergence Theory. In Proceedings of the International
Workshop on ArtiÔ¨Åcial Intelligence and Statistics, 2020a."
REFERENCES,0.36923076923076925,"Ruqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Chen, and Andrew Gordon Wilson. Cyclical
Stochastic Gradient MCMC for Bayesian Deep Learning. In Proc. of the International Conference
on Learning Representation (ICLR), 2020b."
REFERENCES,0.3706293706293706,"Yuchen Zhang, Percy Liang, and Moses Charikar. A Hitting Time Analysis of Stochastic Gradient
Langevin Dynamics. In Proc. of Conference on Learning Theory (COLT), pp. 1980‚Äì2022, 2017."
REFERENCES,0.37202797202797205,"Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi Yang. Random Erasing Data Augmen-
tation. ArXiv e-prints, 2017."
REFERENCES,0.3734265734265734,Published as a conference paper at ICLR 2022
REFERENCES,0.3748251748251748,"We summarize the supplementary material as follows: Section A provides the preliminary knowledge
for stochastic approximation; Section B shows a local stability condition that adapts to high losses;
Section C proves the main asymptotic normality for the stochastic approximation process, which
naturally yields the conclusion that interacting contour stochastic gradient Langevin dynamics
(ICSGLD) is more efÔ¨Åcient than the analogous single chain based on slowly decreasing step sizes;
Section D details the experimental settings."
REFERENCES,0.37622377622377623,"A
PRELIMINARIES"
REFERENCES,0.3776223776223776,"A.1
STOCHASTIC APPROXIMATION"
REFERENCES,0.37902097902097903,"Given a random-Ô¨Åeld function eH(Œ∏, x), the stochastic approximation algorithm (Benveniste et al.,
1990) proposes to solve the mean-Ô¨Åeld equation h(Œ∏) = 0 in the analysis of adaptive algorithms"
REFERENCES,0.3804195804195804,"h(Œ∏) =
Z"
REFERENCES,0.38181818181818183,"X
eH(Œ∏, x)œñŒ∏(dx) = 0,"
REFERENCES,0.3832167832167832,"where x ‚ààX ‚äÇRd, Œ∏ ‚ààŒò ‚äÇRm, œñŒ∏(x) is a distribution that depends on the self-adapting
parameter Œ∏. Given the transition kernel Œ†Œ∏(x, A) for any Borel subset A ‚äÇX, the algorithm can be
written as follows"
REFERENCES,0.38461538461538464,"(1) Simulate xk+1 ‚àºŒ†Œ∏k(xk, ¬∑), which yields the invariant distribution œñŒ∏k(¬∑),"
REFERENCES,0.386013986013986,"(2) Optimize Œ∏k+1 = Œ∏k + œâk+1 eH(Œ∏k, xk+1)."
REFERENCES,0.38741258741258744,"Compared with the standard Robbins‚ÄìMonro algorithm (Robbins & Monro, 1951), the algorithm
proposes to simulate x from a transition kernel Œ†Œ∏(¬∑, ¬∑) instead of the distribution œñŒ∏(¬∑) directly. In
other words, , eH(Œ∏k, xk+1) ‚àíh(Œ∏k) is not a Martingale but rather a Markov state-dependent noise."
REFERENCES,0.3888111888111888,"A.2
POISSON‚ÄôS EQUATION"
REFERENCES,0.3902097902097902,"In the stochastic approximation algorithm, the sequence of {(xk, Œ∏k)}‚àû
k=1 on the product space
X √ó Œò is generated, which is an inhomogeneous Markov chain and requires the tool of the Poisson‚Äôs
equation to study the convergence"
REFERENCES,0.3916083916083916,"¬µŒ∏(x) ‚àíŒ†Œ∏¬µŒ∏(x) = eH(Œ∏, x) ‚àíh(Œ∏),"
REFERENCES,0.393006993006993,"where ¬µŒ∏(¬∑) is a function on X. The solution ¬µŒ∏(x) to the Poisson‚Äôs equation exists and is formulated
in the following form when the above series converges:"
REFERENCES,0.3944055944055944,"¬µŒ∏(x) :=
X"
REFERENCES,0.3958041958041958,"k‚â•0
Œ†k
Œ∏( eH(Œ∏, x) ‚àíh(Œ∏)),"
REFERENCES,0.3972027972027972,"where Œ†k
Œ∏( eH(Œ∏, x) ‚àíh(Œ∏)) =
RRR
( eH(Œ∏, y) ‚àíh(Œ∏))Œ†k
Œ∏(x, dy). To ensure such a convergence,
Benveniste et al. (1990) made the following regularity conditions on the solution ¬µŒ∏(¬∑) of the
Poisson‚Äôs equation:"
REFERENCES,0.3986013986013986,"There exist a Lyapunov function V : X ‚Üí[1, ‚àû) and a positive constant C > 0 such that ‚àÄŒ∏, Œ∏‚Ä≤ ‚ààŒò,
we have"
REFERENCES,0.4,"‚à•Œ†Œ∏¬µŒ∏(x)‚à•‚â§CV (x),
‚à•Œ†Œ∏¬µŒ∏(x) ‚àíŒ†Œ∏‚Ä≤¬µŒ∏‚Ä≤(x)‚à•‚â§C‚à•Œ∏ ‚àíŒ∏‚Ä≤‚à•V (x),
E[V (x)] ‚â§‚àû,
(12)"
REFERENCES,0.4013986013986014,"where a common choice for the Lyapunov function is to set V (x) = 1 + ‚à•x‚à•2 (Teh et al., 2016;
Vollmer et al., 2016)."
REFERENCES,0.4027972027972028,"A.3
GAUSSIAN DIFFUSIONS"
REFERENCES,0.4041958041958042,Consider a stochastic linear differential equation
REFERENCES,0.40559440559440557,"dUt = hŒ∏(Œ∏t)Utdt + R1/2(Œ∏t)dWt,
(13)"
REFERENCES,0.406993006993007,"where
U
is
a
m-dimensional
random
vector,
hŒ∏
:=
d
dŒ∏h(Œ∏),
R(Œ∏)
:=
P‚àû
k=‚àí‚àûCovŒ∏(H(Œ∏, xk), H(Œ∏, x0)) is a positive deÔ¨Ånite matrix that depends on Œ∏(¬∑), W ‚ààRm"
REFERENCES,0.4083916083916084,Published as a conference paper at ICLR 2022
REFERENCES,0.4097902097902098,"is a standard Brownian motion. Given a large enough t such that Œ∏t converges to a Ô¨Åxed point bŒ∏‚ãÜ
sufÔ¨Åciently fast, we may write the diffusion associated with Eq.(13) as follow"
REFERENCES,0.4111888111888112,"Ut ‚âàe‚àíthŒ∏(bŒ∏‚ãÜ)U0 +
Z t"
REFERENCES,0.4125874125874126,"0
e‚àí(t‚àís)hŒ∏(bŒ∏‚ãÜ) ‚ó¶R(bŒ∏‚ãÜ)dWs,
(14)"
REFERENCES,0.413986013986014,"Suppose that the matrix hŒ∏(bŒ∏‚ãÜ) is negative deÔ¨Ånite, then Ut converges in distribution to a Gaussian
variable"
REFERENCES,0.4153846153846154,E[Ut] = e‚àíthŒ∏(bŒ∏‚ãÜ)U0
REFERENCES,0.4167832167832168,"Var(Ut) =
Z t"
REFERENCES,0.41818181818181815,"0
ethŒ∏(bŒ∏‚ãÜ) ‚ó¶R ‚ó¶ethŒ∏(bŒ∏‚ãÜ)du."
REFERENCES,0.4195804195804196,"The main goal of this supplementary Ô¨Åle is to study the Gaussian approximation of the process
œâ‚àí1/2
k
(Œ∏k ‚àíbŒ∏‚ãÜ) to the solution Eq.(14) for a proper step size œâk. Thereafter, the advantage of
interacting mechanisms can be naturally derived."
REFERENCES,0.42097902097902096,"B
STABILITY AND CONVERGENCE ANALYSIS"
REFERENCES,0.4223776223776224,"As required by the algorithm, we update P contour stochastic gradient Langevin dynamics (CSGLD)
simultaneously. For the notations, we denote the particle of the p-th chain at iteration k by x(p)
k
‚ààX ‚äÇ"
REFERENCES,0.42377622377622376,"Rd and the joint state of the P parallel particles at iteration k by x
N P
k
:=

x(1)
k , x(2)
k , ¬∑ ¬∑ ¬∑ , x(P )
k
‚ä§
‚àà"
REFERENCES,0.4251748251748252,"X
N P ‚äÇRdP . We also denote the learning rate and step size at iteration k by œµk and œâk, respectively.
We denote by N(0, IdP ) a standard dP-dimensional Gaussian vector and denote by Œ∂ a positive
hyperparameter."
REFERENCES,0.42657342657342656,"B.1
ICSGLD ALGORITHM"
REFERENCES,0.427972027972028,"First, we introduce the interacting contour stochastic gradient Langevin dynamics (ICSGLD) with P
parallel chains:"
REFERENCES,0.42937062937062936,"(1) Simulate x
N P
k+1 = x
N P
k
‚àíœµk‚àáx eL(x
N P
k
, Œ∏k) + N(0, 2œµkœÑIdP ),
(S1)"
REFERENCES,0.4307692307692308,"(2) Optimize Œ∏k+1 = Œ∏k + œâk+1f
H(Œ∏k, x
N P
k+1 ),
(S2)"
REFERENCES,0.43216783216783217,"where ‚àáx eL(x
N P , Œ∏) :=

‚àáxeL(x(1), Œ∏), ‚àáxeL(x(2), Œ∏), ¬∑ ¬∑ ¬∑ , ‚àáxeL(x(P ), Œ∏)
‚ä§
, ‚àáxeL(x, Œ∏) is the
stochastic adaptive gradient given by"
REFERENCES,0.43356643356643354,"‚àáxeL(x, Œ∏) = N n"
REFERENCES,0.43496503496503497,"
1 + Œ∂œÑ"
REFERENCES,0.43636363636363634,"‚àÜu
 
log Œ∏(JeU(x)) ‚àílog Œ∏((JeU(x) ‚àí1) ‚à®1)
"
REFERENCES,0.43776223776223777,"|
{z
}
gradient multiplier"
REFERENCES,0.43916083916083914,"‚àáx eU(x).
(15)"
REFERENCES,0.4405594405594406,"In particular, the interacting random-Ô¨Åeld function is written as"
REFERENCES,0.44195804195804195,"f
H(Œ∏k, x
N P
k+1 ) = 1 P P
X"
REFERENCES,0.4433566433566434,"p=1
eH(Œ∏k, x(p)
k+1),
(16)"
REFERENCES,0.44475524475524475,"where each random-Ô¨Åeld function eH(Œ∏, x) = ( eH1(Œ∏, x), . . . , eHm(Œ∏, x)) follows"
REFERENCES,0.4461538461538462,"eHi(Œ∏, x) = Œ∏(JeU(x))

1i=J e
U(x) ‚àíŒ∏(i)

,
i = 1, 2, . . . , m.
(17)"
REFERENCES,0.44755244755244755,"Here JeU(x) denotes the index i ‚àà{1, 2, 3, ¬∑ ¬∑ ¬∑ , m} such that ui‚àí1 < N"
REFERENCES,0.4489510489510489,"n eU(x) ‚â§ui for a set of
energy partitions {ui}m
i=0 and eU(x) = P"
REFERENCES,0.45034965034965035,"i‚ààB Ui(x) where Ui denotes the negative log of a posterior
based on a single data point i and B denotes a mini-batch of data of size n. Note that the stochastic"
REFERENCES,0.45174825174825173,Published as a conference paper at ICLR 2022
REFERENCES,0.45314685314685316,"energy estimator eU(x) results in a biased estimation for the partition index JeU(x) due to a non-linear
transformation. To avoid such a bias asymptotically with respect to the learning rate œµk, we may
consider a variance-reduced energy estimator eUVR(x) following Deng et al. (2021a) N"
REFERENCES,0.45454545454545453,"n
eUVR(x) = N n X i‚ààBk"
REFERENCES,0.45594405594405596,"
Ui(x) ‚àíUi

xq‚åäk"
REFERENCES,0.45734265734265733,"q ‚åã

+ N
X"
REFERENCES,0.45874125874125876,"i=1
Ui

xq‚åäk"
REFERENCES,0.46013986013986014,"q ‚åã

,
(18)"
REFERENCES,0.46153846153846156,where the control variate xq‚åäk
REFERENCES,0.46293706293706294,q ‚åãis updated every q iterations.
REFERENCES,0.4643356643356643,"Compared with the na¬®ƒ±ve parallelism of CSGLD, a key feature of the ICSGLD algorithm lies in
the joint estimation of the interacting random-Ô¨Åeld function f
H(Œ∏, x
N P ) in Eq.(16) for the same
mean-Ô¨Åeld function h(Œ∏)."
REFERENCES,0.46573426573426574,"B.1.1
DISCUSSIONS ON THE HYPERPARAMETERS"
REFERENCES,0.4671328671328671,"The most important hyperparameter is Œ∂. A Ô¨Åne-tuned Œ∂ usually leads to a small or even slightly
negative learning rate in low energy regions to avoid local-trap problems. Theoretically, Œ∂ affects the
L2 convergence rate hidden in the big-O notation in Lemma 3."
REFERENCES,0.46853146853146854,"The other hyperparameters can be easily tuned. For example, the ResNet models yields the full loss
ranging from 10,000 to 60,000 after warm-ups, we thus partition the sample space according to the
energy into 200 subregions equally without tuning; since the optimization of SA is nearly convex,
tuning {œâk} is much easier than tuning {œµk} for non-convex learning."
REFERENCES,0.4699300699300699,"B.1.2
DISCUSSIONS ON DISTRIBUTED COMPUTING AND COMMUNICATION COST"
REFERENCES,0.47132867132867134,"In shared-memory settings, the implementation is trivial and the details are omitted."
REFERENCES,0.4727272727272727,In distributed-memory settings: Œ∏k+1 is updated by the central node as follows:
REFERENCES,0.47412587412587415,"‚Ä¢ The p-th worker conducts the sampling step (S1) and sends the indices JeU(x(p)
k+1)‚Äôs to the central node;"
REFERENCES,0.4755244755244755,‚Ä¢ The central node aggregates the indices from all worker and updates Œ∏k based on (S2);
REFERENCES,0.47692307692307695,‚Ä¢ The central node sends Œ∏k+1 back to each worker.
REFERENCES,0.4783216783216783,"We emphasize that we don‚Äôt communicate the model parameters x ‚ààRd, but rather share the self-
adapting parameter Œ∏ ‚ààRm, where m ‚â™d. For example, WRN-16-8 has 11 M parameters (40 MB),
while Œ∏ can be set to dimension 200 of size 4 KB; hence, the communication cost is not a big issue.
Moreover, the theoretical advantage still holds if the communication frequency is slightly reduced."
REFERENCES,0.4797202797202797,"B.1.3
SCALABILITY TO BIG DATA"
REFERENCES,0.4811188811188811,Recall that the adaptive sampler follows that
REFERENCES,0.4825174825174825,"xk+1 = xk ‚àíœµk+1
N n"
REFERENCES,0.48391608391608393,"
1 + Œ∂œÑ log Œ∏k(J e
U(xk)) ‚àílog Œ∏k((J e
U(xk) ‚àí1) ‚à®1)
‚àÜu "
REFERENCES,0.4853146853146853,"|
{z
}
gradient multiplier"
REFERENCES,0.48671328671328673,"‚àáx eU(xk) +
p"
REFERENCES,0.4881118881118881,"2œÑœµk+1wk+1,"
REFERENCES,0.48951048951048953,"The key to the success of (I)CSGLD is to generate sufÔ¨Åciently strong bouncy moves (negative gradient
multiplier) to escape local traps. To this end, Œ∂ can be tuned to generate proper bouncy moves."
REFERENCES,0.4909090909090909,Take the CIFAR100 experiments for example:
REFERENCES,0.49230769230769234,"‚Ä¢ the self-adjusting mechanism fails if the gradient multiplier uniformly ‚Äúequals‚Äù to 1 and a too
small value of Œ∂ = 1 could lead to this issue;"
REFERENCES,0.4937062937062937,"‚Ä¢ the self-adjusting mechanism works only if we choose a large enough Œ∂ such as 3e6 to generate
(desired) negative gradient multiplier in over-visited regions."
REFERENCES,0.4951048951048951,Published as a conference paper at ICLR 2022
REFERENCES,0.4965034965034965,"However, when we set Œ∂ =3e6, the original stochastic approximation (SA) update proposed in (Deng
et al., 2020b) follows that"
REFERENCES,0.4979020979020979,Œ∏k+1(i) = Œ∏k(i) + œâk+1 Œ∏Œ∂
REFERENCES,0.4993006993006993,"k(JeU(xk+1))
|
{z
}
essentially 0 for Œ∂‚â´1"
REFERENCES,0.5006993006993007,"
1i=J e
U(xk+1) ‚àíŒ∏k(i)

."
REFERENCES,0.5020979020979021,"Since Œ∏(i) < 1 for any i ‚àà{1, ¬∑ ¬∑ ¬∑ , m}, Œ∏(i)Œ∂ is essentially 0 for such a large Œ∂, which means that
the original SA fails to optimize when Œ∂ is large. Therefore, the limited choices of Œ∂ inevitably
limits the scalability to big data problems. Our newly proposed SA scheme"
REFERENCES,0.5034965034965035,"Œ∏k+1(i) = Œ∏k(i) + œâk+1 Œ∏k(JeU(xk+1))
|
{z
}
independent of Œ∂"
REFERENCES,0.5048951048951049,"
1i=J e
U(xk+1) ‚àíŒ∏k(i)
"
REFERENCES,0.5062937062937063,"is more independent of Œ∂ and proposes to converge to a much smoother equilibrium Œ∏1/Œ∂
‚àûinstead
of Œ∏‚àû, where Œ∏‚àû(i) =
R"
REFERENCES,0.5076923076923077,"œái œÄ(x)dx ‚àù
R"
REFERENCES,0.509090909090909,œái e‚àíU(x)
REFERENCES,0.5104895104895105,"œÑ dx is the energy PDF. As such, despite the linear"
REFERENCES,0.5118881118881119,"stability is sacriÔ¨Åced, the resulting algorithm is more scalable. For example, estimating e‚àí10,000√ó 1"
REFERENCES,0.5132867132867133,"Œ∂ is
numerically much easier than e‚àí10,000 for a large Œ∂ such as 10, 000, where 10, 000 can be induced
by the high losses in training deep neural networks in big data."
REFERENCES,0.5146853146853146,"B.2
ASSUMPTIONS"
REFERENCES,0.5160839160839161,"A long-standing problem for stochastic approximation is the difÔ¨Åculty in establishing the stability
property and a practical remedy for this problem is to study Œò on a Ô¨Åxed compact set."
REFERENCES,0.5174825174825175,"Assumption A1 (Compactness) The space Œò is compact and infŒò Œ∏(i) > 0 for any i ‚àà
{1, 2, . . . , m}."
REFERENCES,0.5188811188811189,"For weaker assumptions, we refer readers to Theorem 3.2 (Fort et al., 2015), where a recurrence prop-
erty can be proved for the Metropolis-based Wang-Landau algorithm, which eventually established
that the estimates return to a desired compact set often enough."
REFERENCES,0.5202797202797202,"Next, we lay out the smoothness assumption, which is standard in the convergence analysis of SGLD,
see e.g. Mattingly et al. (2010), Raginsky et al. (2017) and Xu et al. (2018)."
REFERENCES,0.5216783216783217,"Assumption A2 (Smoothness) U(x) is M-smooth when there exists a positive constant M that
satisÔ¨Åes ‚àÄx, x‚Ä≤ ‚ààX,"
REFERENCES,0.5230769230769231,"‚à•‚àáxU(x) ‚àí‚àáxU(x‚Ä≤)‚à•‚â§M‚à•x ‚àíx‚Ä≤‚à•.
(19)"
REFERENCES,0.5244755244755245,"In addition, we assume the dissipativity condition to ensure that the geometric ergodicity of the
dynamical system holds. This assumption is also crucial for verifying the solution properties of
the solution of Poisson‚Äôs equation. Similar assumptions have been made in Mattingly et al. (2010);
Raginsky et al. (2017) and Xu et al. (2018)."
REFERENCES,0.5258741258741259,"Assumption A3 (Dissipativity) There exist constants Àúm > 0 and Àúb ‚â•0 that satisÔ¨Åes ‚àÄx ‚ààX and
any Œ∏ ‚ààŒò,
‚ü®‚àáxL(x, Œ∏), x‚ü©‚â§Àúb ‚àíÀúm‚à•x‚à•2.
(20)"
REFERENCES,0.5272727272727272,"To further establish a bounded second moment on x ‚ààX with respect to a proper Lyapunov function
V (x), we impose the following conditions on the gradient noise:"
REFERENCES,0.5286713286713287,"Assumption A4 (Gradient noise) The stochastic gradient based on mini-batch settings is an unbi-
ased estimator such that
E[‚àáx eU(xk) ‚àí‚àáxU(xk)] = 0;
furthermore, for some positive constants M and B, we have"
REFERENCES,0.5300699300699301,"E[‚à•‚àáx eU(xk) ‚àí‚àáxU(xk)‚à•2] ‚â§M 2‚à•x‚à•2 + B2,"
REFERENCES,0.5314685314685315,where E[¬∑] acts on the distribution of the noise in the stochastic gradient ‚àáx eU(xk).
REFERENCES,0.5328671328671328,Published as a conference paper at ICLR 2022
REFERENCES,0.5342657342657343,"B.3
LOCAL STABILITY VIA THE SCALABLE RANDOM-FIELD FUNCTION"
REFERENCES,0.5356643356643357,"Now, we are ready to present our Ô¨Årst result. Lemma 3 establishes a local stability condition for the
non-linear mean-Ô¨Åeld system of ICSGLD, which implies a potential convergence of Œ∏k to a unique
Ô¨Åxed point that adapts to a wide energy range under mild assumptions."
REFERENCES,0.5370629370629371,"Lemma 3 (Local stability, restatement of Lemma 1) Assume Assumptions A1-A4 hold. Given any
small enough learning rate œµ, a large enough m and batch size n, and any Œ∏ ‚ààeŒò, where eŒò is a small
neighborhood of Œ∏‚ãÜthat contains bŒ∏‚ãÜ, we have ‚ü®h(Œ∏), Œ∏‚àíbŒ∏‚ãÜ‚ü©‚â§‚àíœÜ‚à•Œ∏‚àíbŒ∏‚ãÜ‚à•2, where bŒ∏‚ãÜ= Œ∏‚ãÜ+O(Œµ),"
REFERENCES,0.5384615384615384,"Œµ = O
 
supx Var(Œæn(x)) + œµ + 1"
REFERENCES,0.5398601398601398,"m

and Œ∏‚ãÜ= R"
REFERENCES,0.5412587412587413,"X1 œÄ(x)dx
 1 Œ∂"
REFERENCES,0.5426573426573427,"Pm
k=1
R"
REFERENCES,0.544055944055944,"Xk œÄ(x)dx
 1"
REFERENCES,0.5454545454545454,"Œ∂ , . . . ,
(
R"
REFERENCES,0.5468531468531469,"Xm œÄ(x)dx)
1
Œ∂"
REFERENCES,0.5482517482517483,"Pm
k=1
R"
REFERENCES,0.5496503496503496,"Xk œÄ(x)dx
 1 Œ∂ ! ,"
REFERENCES,0.551048951048951,"œÜ = infŒ∏ mini bZ‚àí1
Œ∂,Œ∏(i)
 
1 ‚àíO(Œµ)

> 0, bZŒ∂,Œ∏(i) is deÔ¨Åned below Eq.(28), and Œæn(x) denotes the noise"
REFERENCES,0.5524475524475524,in the energy estimator eU(x) of batch size n and Var(¬∑) denotes the variance.
REFERENCES,0.5538461538461539,"Proof
The random-Ô¨Åeld function eHi(Œ∏, x) = Œ∏(JeU(x))

1i=J e
U(x) ‚àíŒ∏(i)

based on the stochastic"
REFERENCES,0.5552447552447553,"energy estimator eU(x) yields a biased estimator of Hi(Œ∏, x) = Œ∏(J(x))
 
1i=J(x) ‚àíŒ∏(i)

for any
i ‚àà{1, 2, . . . , m} based on the exact energy partition function J(¬∑). By Lemma.4, we know that the
bias caused by the stochastic energy is of order O(Var(Œæn(x)))."
REFERENCES,0.5566433566433566,Now we compute the mean-Ô¨Åeld function h(Œ∏) based on the measure œñŒ∏(x) simulated from SGLD:
REFERENCES,0.558041958041958,"hi(Œ∏) =
Z"
REFERENCES,0.5594405594405595,"X
e
Hi(Œ∏, x)œñŒ∏(x)dx =
Z"
REFERENCES,0.5608391608391609,"X
Hi(Œ∏, x)œñŒ∏(x)dx + O (Var(Œæn(x))) =
Z"
REFERENCES,0.5622377622377622,"X
Hi(Œ∏, x) Ô£´"
REFERENCES,0.5636363636363636,"Ô£¨
Ô£¨
Ô£≠œñeŒ®Œ∏(x)
|
{z
}
I1"
REFERENCES,0.5650349650349651,"‚àíœñeŒ®Œ∏(x) + œñŒ®Œ∏(x)
|
{z
}
I2:piece-wise approximation"
REFERENCES,0.5664335664335665,"‚àíœñŒ®Œ∏(x) + œñŒ∏(x)
|
{z
}
I3:numerical discretization Ô£∂"
REFERENCES,0.5678321678321678,"Ô£∑
Ô£∑
Ô£∏dx + O (Var(Œæn(x))) , (21)"
REFERENCES,0.5692307692307692,"where œñŒ∏ is the invariant measure simulated via SGLD that approximates œñŒ®Œ∏(x). œñŒ®Œ∏(x) and
œñeŒ®Œ∏(x) are two invariant measures that follow œñŒ®Œ∏(x) ‚àù
œÄ(x)
Œ®Œ∂
Œ∏(U(x)) and œñeŒ®Œ∏(x) ‚àù
œÄ(x)
eŒ®Œ∂
Œ∏(U(x));"
REFERENCES,0.5706293706293706,"Œ®Œ∏(u) and eŒ®Œ∏(u) are piecewise continuous and constant functions, respectively"
REFERENCES,0.5720279720279721,"Œ®Œ∏(u) = m
X k=1"
REFERENCES,0.5734265734265734,"
Œ∏(k ‚àí1)e(log Œ∏(k)‚àílog Œ∏(k‚àí1))
u‚àíuk‚àí1"
REFERENCES,0.5748251748251748,"‚àÜu

1uk‚àí1<u‚â§uk;
eŒ®Œ∏(u) = m
X"
REFERENCES,0.5762237762237762,"k=1
Œ∏(k)1uk‚àí1<u‚â§uk. (22)"
REFERENCES,0.5776223776223777,"(i) For the Ô¨Årst term I1, we have Z"
REFERENCES,0.579020979020979,"X
Hi(Œ∏, x)œñeŒ®Œ∏(x)dx =
1
eZŒ∂+1,Œ∏ Z"
REFERENCES,0.5804195804195804,"X
Œ∏(J(x))
 
1i=J(x) ‚àíŒ∏(i)

œÄ(x)
Œ∏Œ∂(J(x))dx"
REFERENCES,0.5818181818181818,"=
1
eZŒ∂+1,Œ∏ m
X k=1 Z"
REFERENCES,0.5832167832167832,"Xk
(1i=k ‚àíŒ∏(i))
œÄ(x)
Œ∏Œ∂‚àí1(k)dx"
REFERENCES,0.5846153846153846,"=
1
eZŒ∂+1,Œ∏ "" m
X k=1 Z Xk"
REFERENCES,0.586013986013986,"œÄ(x)
Œ∏Œ∂‚àí1(k)1k=idx ‚àíŒ∏(i) m
X k=1 Z Xk"
REFERENCES,0.5874125874125874,"œÄ(x)
Œ∏Œ∂‚àí1(k)dx #"
REFERENCES,0.5888111888111888,"=
1
eZŒ∂+1,Œ∏ ""R"
REFERENCES,0.5902097902097903,Xi œÄ(x)dx
REFERENCES,0.5916083916083916,"Œ∏Œ∂‚àí1(i)
‚àíŒ∏(i) eZŒ∂,Œ∏ # , (23)"
REFERENCES,0.593006993006993,"where eZŒ∂+1,Œ∏ = Pm
k=1 R"
REFERENCES,0.5944055944055944,Xk œÄ(x)dx
REFERENCES,0.5958041958041959,"Œ∏Œ∂(k)
denotes the normalizing constant of œñeŒ®Œ∏(x)."
REFERENCES,0.5972027972027972,Published as a conference paper at ICLR 2022
REFERENCES,0.5986013986013986,The solution Œ∏‚ãÜthat solves R
REFERENCES,0.6,Xk œÄ(x)dx
REFERENCES,0.6013986013986014,"Œ∏Œ∂‚àí1(k)
‚àíŒ∏(k) eZŒ∂,Œ∏ = 0 for any k ‚àà{1, 2, ¬∑ ¬∑ ¬∑ , m} satisÔ¨Åes Œ∏‚ãÜ(k) =
 R"
REFERENCES,0.6027972027972028,Xk œÄ(x)dx
REFERENCES,0.6041958041958042,"e
ZŒ∂,Œ∏‚ãÜ  1"
REFERENCES,0.6055944055944056,"Œ∂
. Combining the deÔ¨Ånition of eZŒ∂,Œ∏‚ãÜ= Pm
k=1 R"
REFERENCES,0.606993006993007,Xk œÄ(x)dx
REFERENCES,0.6083916083916084,"Œ∏Œ∂‚àí1
‚ãÜ
(k) , we have"
REFERENCES,0.6097902097902098,"eZŒ∂,Œ∏‚ãÜ= m
X k=1 R"
REFERENCES,0.6111888111888112,Xk œÄ(x)dx
REFERENCES,0.6125874125874126,"Œ∏Œ∂‚àí1
‚ãÜ
(k)
= m
X k=1 R"
REFERENCES,0.6139860139860139,"Xk œÄ(x)dx
 R"
REFERENCES,0.6153846153846154,Xk œÄ(x)dx
REFERENCES,0.6167832167832168,"e
ZŒ∂,Œ∏‚ãÜ  Œ∂‚àí1 Œ∂ = eZ Œ∂‚àí1"
REFERENCES,0.6181818181818182,"Œ∂
Œ∂,Œ∏‚ãÜ m
X k=1 R"
REFERENCES,0.6195804195804195,"Xk œÄ(x)dx
R"
REFERENCES,0.620979020979021,"Xk œÄ(x)dx
 Œ∂‚àí1"
REFERENCES,0.6223776223776224,"Œ∂
= eZ Œ∂‚àí1"
REFERENCES,0.6237762237762238,"Œ∂
Œ∂,Œ∏‚ãÜ m
X k=1 Z"
REFERENCES,0.6251748251748251,"Xk
œÄ(x)dx
 1 Œ∂
,"
REFERENCES,0.6265734265734266,"which leads to eZŒ∂,Œ∏‚ãÜ=
Pm
k=1
R"
REFERENCES,0.627972027972028,"Xk œÄ(x)dx
 1"
REFERENCES,0.6293706293706294,"Œ∂ Œ∂
. In other words, the mean-Ô¨Åeld system without"
REFERENCES,0.6307692307692307,perturbations yields a unique solution Œ∏‚ãÜ(i) = R
REFERENCES,0.6321678321678321,"Xi œÄ(x)dx
 1 Œ∂"
REFERENCES,0.6335664335664336,"Pm
k=1
R"
REFERENCES,0.634965034965035,"Xk œÄ(x)dx
 1"
REFERENCES,0.6363636363636364,"Œ∂ for any i ‚àà{1, 2, ¬∑ ¬∑ ¬∑ , m}."
REFERENCES,0.6377622377622377,"(ii) For the second term I2, we have
Z"
REFERENCES,0.6391608391608392,"X
Hi(Œ∏, x)(‚àíœñeŒ®Œ∏(x) + œñŒ®Œ∏(x))dx = O
 1 m"
REFERENCES,0.6405594405594406,"
,
(24)"
REFERENCES,0.641958041958042,"where the result follows from the boundedness of H(Œ∏, x) in (A1) and Lemma B4 (Deng et al.,
2020b)."
REFERENCES,0.6433566433566433,"(iii) For the last term I3, following Theorem 6 of Sato & Nakagawa (2014), we have for any Ô¨Åxed Œ∏,
Z"
REFERENCES,0.6447552447552447,"X
Hi(Œ∏, x) (‚àíœñŒ®Œ∏(x) + œñŒ∏(x)) dx = O(œµ).
(25)"
REFERENCES,0.6461538461538462,"Plugging Eq.(23), Eq.(24) and Eq.(25) into Eq.(21), we have"
REFERENCES,0.6475524475524476,"hi(Œ∏) = eZ‚àí1
Œ∂+1,Œ∏ """
REFERENCES,0.6489510489510489,ŒµÀúŒ≤i(Œ∏) + R
REFERENCES,0.6503496503496503,Xi œÄ(x)dx
REFERENCES,0.6517482517482518,"Œ∏Œ∂‚àí1(i)
‚àíŒ∏(i) eZŒ∂,Œ∏ #"
REFERENCES,0.6531468531468532,"= eZ‚àí1
Œ∂+1,Œ∏
eZŒ∂,Œ∏‚ãÜ
Œ∏Œ∂‚àí1(i) """
REFERENCES,0.6545454545454545,ŒµÀúŒ≤i(Œ∏)Œ∏Œ∂‚àí1(i)
REFERENCES,0.6559440559440559,"eZŒ∂,Œ∏‚ãÜ
+ R"
REFERENCES,0.6573426573426573,Xi œÄ(x)dx
REFERENCES,0.6587412587412588,"eZŒ∂,Œ∏‚ãÜ
‚àíŒ∏Œ∂(i)
eZŒ∂,Œ∏
eZŒ∂,Œ∏‚ãÜ #"
REFERENCES,0.6601398601398601,"= eZ‚àí1
Œ∂+1,Œ∏
eZŒ∂,Œ∏‚ãÜ
Œ∏Œ∂‚àí1(i) """
REFERENCES,0.6615384615384615,ŒµÀúŒ≤i(Œ∏)Œ∏Œ∂‚àí1(i)
REFERENCES,0.6629370629370629,"eZŒ∂,Œ∏‚ãÜ
+ Œ∏Œ∂
‚ãÜ(i) ‚àí(Œ∏(i)CŒ∏)Œ∂
# , (26)"
REFERENCES,0.6643356643356644,"where ÀúŒ≤i(Œ∏) is a bounded term such that eZ‚àí1
Œ∂+1,Œ∏ŒµÀúŒ≤i(Œ∏) = O
 
Var(Œæn(x)) + œµ + 1"
REFERENCES,0.6657342657342658,"m

, Œµ ="
REFERENCES,0.6671328671328671,"O
 
supx Var(Œæn(x)) + œµ + 1"
REFERENCES,0.6685314685314685,"m

and CŒ∏ =
 e
ZŒ∂,Œ∏
e
ZŒ∂,Œ∏‚ãÜ  1"
REFERENCES,0.66993006993007,"Œ∂ . By the deÔ¨Ånition of eZŒ∂,Œ∏ = Pm
k=1 R"
REFERENCES,0.6713286713286714,Xk œÄ(x)dx
REFERENCES,0.6727272727272727,"Œ∏Œ∂‚àí1(k) ,
when Œ∂ = 1, CŒ∏ ‚â°1 for any Œ∏ ‚ààŒò, which suggests that the stability condition doesn‚Äôt
rely on the initialization of Œ∏; however, when Œ∂ Ã∏= 1, CŒ∏ Ã∏= 1 when Œ∏ Ã∏= Œ∏‚ãÜ, we see that
hi(Œ∏) ‚àùŒ∏‚ãÜ(i)Œ∂ ‚àí(Œ∏(i)CŒ∏)Œ∂ + perturbations is a non-linear mean-Ô¨Åeld system and requires a
proper initialization of Œ∏ ‚ààeŒò."
REFERENCES,0.6741258741258741,"For any Œ∏ ‚àà
eŒò ‚äÇŒò being close enough to Œ∏‚ãÜ, there exists a Lipschitz constant LeŒ∏ =
supi‚â§m,Œ∏‚ààe
Œò
|CŒ∏‚ãÜ‚àíCŒ∏|
|Œ∏‚ãÜ(i)‚àíŒ∏(i)| < ‚àû.
By CŒ∏‚ãÜ= 1, Œ∏(i) ‚â§1, and mean value theorem for some
eŒ∏(i) ‚àà[Œ∏(i), Œ∏‚ãÜ(i)], we have"
REFERENCES,0.6755244755244755,"|Œ∏Œ∂
‚ãÜ(i) ‚àí(Œ∏(i)CŒ∏)Œ∂ | = Œ∂(eŒ∏(i)CeŒ∏)Œ∂‚àí1|Œ∏‚ãÜ(i) ‚àíŒ∏(i)CŒ∏|"
REFERENCES,0.676923076923077,= Œ∂(eŒ∏(i)CeŒ∏)Œ∂‚àí1|Œ∏‚ãÜ(i) ‚àíŒ∏(i) + Œ∏(i)CŒ∏‚ãÜ‚àíŒ∏(i)CŒ∏|
REFERENCES,0.6783216783216783,‚â§Œ∂(eŒ∏(i)CeŒ∏)Œ∂‚àí1|Œ∏‚ãÜ(i) ‚àíŒ∏(i)| + Œ∏(i)|CŒ∏‚ãÜ‚àíCŒ∏|
REFERENCES,0.6797202797202797,"‚â§Œ∂(eŒ∏(i)CeŒ∏)Œ∂‚àí1(1 + LeŒ∏)|Œ∏‚ãÜ(i) ‚àíŒ∏(i)|,
(27)"
REFERENCES,0.6811188811188811,Published as a conference paper at ICLR 2022
REFERENCES,0.6825174825174826,"Combining Eq.(26) and Eq.(27), we have"
REFERENCES,0.6839160839160839,"hi(Œ∏) = eZ‚àí1
Œ∂+1,Œ∏
eZŒ∂,Œ∏‚ãÜ
Œ∏Œ∂‚àí1(i) """
REFERENCES,0.6853146853146853,ŒµÀúŒ≤i(Œ∏)Œ∏Œ∂‚àí1(i)
REFERENCES,0.6867132867132867,"eZŒ∂,Œ∏‚ãÜ
+ Œ∏Œ∂
‚ãÜ(i) ‚àí(Œ∏(i)CŒ∏)Œ∂
#"
REFERENCES,0.6881118881118881,"= bZ‚àí1
Œ∂,Œ∏(i) [ŒµŒ≤i(Œ∏) + Œ∏‚ãÜ(i) ‚àíŒ∏(i)] , (28)"
REFERENCES,0.6895104895104895,"where bZ‚àí1
Œ∂,Œ∏(i) =
e
Z‚àí1
Œ∂+1,Œ∏ e
ZŒ∂,Œ∏‚ãÜ
Œ∂(eŒ∏(i)C e
Œ∏)Œ∂‚àí1(1+L e
Œ∏)Œ∏Œ∂‚àí1(i); Œ≤i(Œ∏) is some bounded term such that Œ≤i(Œ∏) ‚â§"
REFERENCES,0.6909090909090909,"ÀúŒ≤i(Œ∏)Œ∏Œ∂‚àí1(i)
Œ∂(eŒ∏(i)C e
Œ∏)Œ∂‚àí1(1+L e
Œ∏) e
ZŒ∂,Œ∏‚ãÜ; CeŒ∏ =

e
ZŒ∂, e
Œ∏
e
ZŒ∂,Œ∏‚ãÜ  1"
REFERENCES,0.6923076923076923,"Œ∂
; LeŒ∏ = supi‚â§m,Œ∏‚ààe
Œò
|CŒ∏‚ãÜ‚àíCŒ∏|
|Œ∏‚ãÜ(i)‚àíŒ∏(i)| < ‚àû."
REFERENCES,0.6937062937062937,"Next, we apply the perturbation theory to solve the ODE system with small disturbances (Weinhart
et al., 2010) and obtain the equilibrium bŒ∏‚ãÜ,"
REFERENCES,0.6951048951048951,"where ŒµŒ≤(bŒ∏‚ãÜ) + Œ∏‚ãÜ‚àíbŒ∏‚ãÜ= 0, to the mean-Ô¨Åeld equation hi(Œ∏) such that"
REFERENCES,0.6965034965034965,"hi(Œ∏) = bZ‚àí1
Œ∂,Œ∏(i) [ŒµŒ≤i(Œ∏) + Œ∏‚ãÜ(i) ‚àíŒ∏(i)]"
REFERENCES,0.6979020979020979,"= bZ‚àí1
Œ∂,Œ∏(i)
h
ŒµŒ≤i(Œ∏) ‚àíŒµŒ≤i(bŒ∏‚ãÜ) + ŒµŒ≤i(bŒ∏‚ãÜ) + Œ∏‚ãÜ(i) ‚àíŒ∏(i)
i"
REFERENCES,0.6993006993006993,"= bZ‚àí1
Œ∂,Œ∏(i)
h
O(Œµ)(Œ∏(i) ‚àíbŒ∏‚ãÜ(i)) + bŒ∏‚ãÜ(i) ‚àíŒ∏(i)
i"
REFERENCES,0.7006993006993008,"= bZ‚àí1
Œ∂,Œ∏(i)
 
1 ‚àíO(Œµ)
 
bŒ∏‚ãÜ(i) ‚àíŒ∏(i)

, (29)"
REFERENCES,0.7020979020979021,"where a smoothness condition clearly holds for the Œ≤(¬∑) function ‚Ä†. Given a positive deÔ¨Ånite
Lyapunov function V(Œ∏) = 1"
REFERENCES,0.7034965034965035,"2‚à•bŒ∏‚ãÜ‚àíŒ∏‚à•2, the mean-Ô¨Åeld system h(Œ∏) = bZ‚àí1
Œ∂,Œ∏(i)(ŒµŒ≤(Œ∏) + Œ∏‚ãÜ‚àíŒ∏) =
bZ‚àí1
Œ∂,Œ∏(i)(1 ‚àíO(Œµ))(bŒ∏‚ãÜ‚àíŒ∏) for i ‚àà{1, 2, ¬∑ ¬∑ ¬∑ , m} enjoys the following property"
REFERENCES,0.7048951048951049,"‚ü®h(Œ∏), ‚àáV(Œ∏)‚ü©= ‚ü®h(Œ∏), Œ∏ ‚àíbŒ∏‚ãÜ‚ü©"
REFERENCES,0.7062937062937062,"‚â§‚àímin
i
bZ‚àí1
Œ∂,Œ∏(i)
 
1 ‚àíO(Œµ)

‚à•Œ∏ ‚àíbŒ∏‚ãÜ‚à•2"
REFERENCES,0.7076923076923077,"‚â§‚àíœÜ‚à•Œ∏ ‚àíbŒ∏‚ãÜ‚à•2,"
REFERENCES,0.7090909090909091,"where œÜ = infŒ∏ mini bZ‚àí1
Œ∂,Œ∏(i)
 
1 ‚àíO(Œµ)

> 0 given the compactness assumption A1 and a small
enough Œµ = O
 
supx Var(Œæn(x)) + œµ + 1 m

."
REFERENCES,0.7104895104895105,"Remark 1 The newly proposed random-Ô¨Åeld function Eq.(17) may sacriÔ¨Åce the global stability
by including an approximately linear mean-Ô¨Åeld system Eq.(28) instead of a linear stable system
(see formula (15) in Deng et al. (2020b)). The advantage, however, is that such a mechanism
facilitates the estimation of Œ∏‚ãÜ. We emphasize that the original energy probability in each partition
 R"
REFERENCES,0.7118881118881119,"Xk œÄ(x)dx
	m
k=1 (Deng et al., 2020b) may be very difÔ¨Åcult to estimate for big data problems. By"
REFERENCES,0.7132867132867133,"contrast, the estimation of
  R"
REFERENCES,0.7146853146853147,"Xk œÄ(x)dx
 1"
REFERENCES,0.7160839160839161,"Œ∂ 	m
k=1 becomes much easier given a proper Œ∂ > 0."
REFERENCES,0.7174825174825175,Technical lemmas
REFERENCES,0.7188811188811188,"Lemma 4 The stochastic energy estimator eU(x) leads to a controllable bias in the random-Ô¨Åeld
function.
|E[ eHi(Œ∏, x)] ‚àíHi(Œ∏, x)| = O (Var(Œæn(x))) ,
where the expectation E[¬∑] is taken with respect to the random noise in the stochastic energy estimator
of eU(¬∑)."
REFERENCES,0.7202797202797203,"Proof
Denote the noise in the stochastic energy estimator by Œæ(x), such that eU(¬∑) = U(¬∑) +"
REFERENCES,0.7216783216783217,"Œæ(¬∑). Recall that eHi(Œ∏, x) = Œ∏(JeU(x))

1i=J e
U(x) ‚àíŒ∏(i)

and JeU(x) ‚àà{1, 2, ¬∑ ¬∑ ¬∑ , m} satisÔ¨Åes"
REFERENCES,0.7230769230769231,"‚Ä†A small change of Œ∏ won‚Äôt signiÔ¨Åcantly affect the perturbations caused by Eq.(24), Eq.(25) and Var(Œæn(¬∑))."
REFERENCES,0.7244755244755244,Published as a conference paper at ICLR 2022
REFERENCES,0.7258741258741259,"uJ e
U(x)‚àí1 < N"
REFERENCES,0.7272727272727273,"n eU(x) ‚â§uJ e
U(x) for a set of energy partitions {ui}m
i=0. We can interpret eHi(Œ∏, x) as a
non-linear transformation Œ¶ that maps eU(x) to (0, 1). Similarly, Hi(Œ∏, x) maps U(x) to (0, 1). In
what follows, the bias of random-Ô¨Åeld function is upper bounded as follows"
REFERENCES,0.7286713286713287,"|E[ eHi(Œ∏, x)] ‚àíHi(Œ∏, x)| ="
REFERENCES,0.73006993006993,"Z
Œ¶(U(x) + Œæ(x)) ‚àíŒ¶(U(x))d¬µ(Œæ(x)) ="
REFERENCES,0.7314685314685314,"Z
Œæ(x)Œ¶‚Ä≤(U(x)) + Œæ(x)2"
REFERENCES,0.7328671328671329,"2
Œ¶‚Ä≤‚Ä≤(u)d¬µ(Œæ(x)) ‚â§"
REFERENCES,0.7342657342657343,"Z
Œæn(x)Œ¶‚Ä≤(U(x))d¬µ(Œæn(x))
 +

Œ¶‚Ä≤‚Ä≤(u) 2"
REFERENCES,0.7356643356643356,"Z
Œæn(x)2d¬µ(Œæn(x))"
REFERENCES,0.737062937062937,"‚â§O (Var(Œæn(x))) ,"
REFERENCES,0.7384615384615385,"where ¬µ(Œæ(x)) is the probability measure associated with Œæ(x); the second equality follows from
Taylor expansion for some energy u and the third equality follows because the stochastic energy
estimator is unbiased; Œ¶‚Ä≤(U(x)) = O( Œ∏(J(x))‚àíŒ∏(J(x)‚àí1)"
REFERENCES,0.7398601398601399,"‚àÜu
) is clearly bounded due to the deÔ¨Ånition of
Œ∏; a similar conclusion also applies to Œ¶‚Ä≤‚Ä≤(¬∑). The last inequality easily follows by applying Cauchy
Schwarz inequality."
REFERENCES,0.7412587412587412,"B.4
CONVERGENCE OF THE SELF-ADAPTING PARAMETERS"
REFERENCES,0.7426573426573426,"The following is a restatement of Lemma 3.2 of Raginsky et al. (2017), which holds for any Œ∏ in the
compact space Œò."
REFERENCES,0.7440559440559441,"Lemma 5 (Uniform L2 bounds) Assume Assumptions A1, A3 and A4 hold. We have a bounded
second moment supk‚â•1 E[‚à•xk‚à•2] < ‚àûgiven a small enough learning rate."
REFERENCES,0.7454545454545455,"The following lemma justiÔ¨Åes the regularity properties of Poisson‚Äôs equation, which is crucial in
controlling the perturbations through the stochastic approximation process. The Ô¨Årst version was
proposed in Lemma B2 of Deng et al. (2020b). Now we give a more detailed proof by utilizing a
Lyapunov function V (x) = 1 + x2 and Lemma 5."
REFERENCES,0.7468531468531469,"Lemma 6 (Solution of Poisson‚Äôs equation) Assume that Assumptions A1-A4 hold. There is a solu-
tion ¬µŒ∏(¬∑) on X to the Poisson‚Äôs equation"
REFERENCES,0.7482517482517482,"¬µŒ∏(x) ‚àíŒ†Œ∏¬µŒ∏(x) = eH(Œ∏, x) ‚àíh(Œ∏).
(30)"
REFERENCES,0.7496503496503496,"Furthermore, there exists a constant C such that for all Œ∏, Œ∏‚Ä≤ ‚ààŒò"
REFERENCES,0.7510489510489511,"E[‚à•Œ†Œ∏¬µŒ∏(x)‚à•] ‚â§C,"
REFERENCES,0.7524475524475525,"E[‚à•Œ†Œ∏¬µŒ∏(x) ‚àíŒ†Œ∏‚Ä≤¬µŒ∏‚Ä≤(x)‚à•] ‚â§C‚à•Œ∏ ‚àíŒ∏‚Ä≤‚à•.
(31)"
REFERENCES,0.7538461538461538,"Proof
The existence and the regularity property of Poisson‚Äôs equation can be used to control the
perturbations. The key of the proof lies in verifying drift conditions proposed in Section 6 of Andrieu
et al. (2005)."
REFERENCES,0.7552447552447552,"(DRI) By the smoothness assumption A2, we have that U(x) is continuously differentiable almost
everywhere. By the dissipative assumption A3 and Theorem 2.1 (Roberts & Tweedie, 1996), we
can show that the discrete dynamics system is irreducible and aperiodic. Now consider a Lyapunov
function V = 1 + ‚à•x‚à•2 and any compact subset K ‚äÇŒò, the drift conditions are veriÔ¨Åed as follows:"
REFERENCES,0.7566433566433567,"(DRI1) Given small enough learning rates {œµk}k‚â•1, the smoothness assumption A2, and the dissipa-
tive assumption A3, applying Corollary 7.5 (Mattingly et al., 2002) yields the minorization condition
for the CSGLD algorithm, i.e. there exists Œ∑ > 0, a measure ŒΩ, and a set C such that ŒΩ(C) = 1.
Moreover, we have
PŒ∏‚ààK(x, A) ‚â•Œ∑ŒΩ(A)
‚àÄA ‚ààX, x ‚ààC.
(I)"
REFERENCES,0.7580419580419581,"where PŒ∏(x, y) :=
1
2‚àö"
REFERENCES,0.7594405594405594,"(4œÄœµ)d/2 E

e‚àí‚à•y‚àíx+œµ‚àáx e
L(x,Œ∏)‚à•2"
REFERENCES,0.7608391608391608,"4œµ
|x

denotes the transition kernel based on CS-"
REFERENCES,0.7622377622377622,"GLD with the parameter Œ∏ ‚ààK and a learning rate œµ, in addition, the expectation is taken over the"
REFERENCES,0.7636363636363637,Published as a conference paper at ICLR 2022
REFERENCES,0.765034965034965,"adaptive gradient ‚àáxeL(x, Œ∏) in Eq.(15). Using Assumption A1-A4, we can prove the uniform L2
upper bound by following Lemma 3.2 (Raginsky et al., 2017). Further, by Theorem 7.2 (Mattingly
et al., 2002), there exist ÀúŒ± ‚àà(0, 1) and ÀúŒ≤ ‚â•0 such that"
REFERENCES,0.7664335664335664,"PŒ∏‚ààKV (x) ‚â§ÀúŒ±V (x) + ÀúŒ≤.
(II)"
REFERENCES,0.7678321678321678,"Consider a Lyapunov function V = 1 + ‚à•x‚à•2 and a constant Œ∫ = ÀúŒ± + ÀúŒ≤, it yields that"
REFERENCES,0.7692307692307693,"PŒ∏‚ààKV (x) ‚â§Œ∫V (x).
(III)"
REFERENCES,0.7706293706293706,"Now we have veriÔ¨Åed the Ô¨Årst condition (DRI1) by checking conditions (I),(II), and (III),"
REFERENCES,0.772027972027972,"(DRI2) In what follows, we check the boundedness and Lipshitz conditions on the random-Ô¨Åeld
function eH(Œ∏, x), where each subcomponent is deÔ¨Åend as eHi(Œ∏, x) = Œ∏(JeU(x))

1i=J e
U(x) ‚àíŒ∏(i)

."
REFERENCES,0.7734265734265734,"Recall that V = 1 + ‚à•x‚à•2, the compactness assumption A1 directly leads to"
REFERENCES,0.7748251748251749,"sup
Œ∏‚ààK‚äÇ[0,1]m ‚à•H(Œ∏, x)‚à•‚â§mV (x).
(IV)"
REFERENCES,0.7762237762237763,"For any Œ∏1, Œ∏2 ‚ààK and a Ô¨Åxed x ‚ààX, it sufÔ¨Åces for us to solely verify the i-th index, which is the
index that maximizes |Œ∏1(i) ‚àíŒ∏2(i)|, then"
REFERENCES,0.7776223776223776,"| eHi(Œ∏1, x) ‚àíeHi(Œ∏2, x)| = Œ∏1(JeU(x))

1i=J e
U(x) ‚àíŒ∏1(i)

‚àíŒ∏2(JeU(x))

1i=J e
U(x) ‚àíŒ∏2(i)
"
REFERENCES,0.779020979020979,‚â§|Œ∏1(JeU(x)) ‚àíŒ∏2(JeU(x))| + |Œ∏1(JeU(x))Œ∏1(i) ‚àíŒ∏2(JeU(x))Œ∏2(i)|
REFERENCES,0.7804195804195804,"‚â§max
j"
REFERENCES,0.7818181818181819,"
|Œ∏1(j) ‚àíŒ∏2(j)| + Œ∏1(j)|Œ∏1(i) ‚àíŒ∏2(i)| + |Œ∏1(j) ‚àíŒ∏2(j)|Œ∏2(i)
"
REFERENCES,0.7832167832167832,"‚â§3|Œ∏1(i) ‚àíŒ∏2(i)|,"
REFERENCES,0.7846153846153846,"where the last inequality holds since Œ∏(i) ‚àà(0, 1] for any i ‚â§m."
REFERENCES,0.786013986013986,"(DRI3) We proceed to verify the smoothness of the transitional kernel PŒ∏(x, y) with respect to Œ∏.
For any Œ∏1, Œ∏2 ‚ààK and Ô¨Åxed x and y, we have"
REFERENCES,0.7874125874125875,"|PŒ∏1(x, y) ‚àíPŒ∏2(x, y)| =
1"
P,0.7888111888111888,"2
p"
P,0.7902097902097902,"(4œÄœµ)d/2 E

e‚àí‚à•y‚àíx+œµ‚àáx e
L(x,Œ∏1)‚à•2"
P,0.7916083916083916,"4œµ
|x

‚àí
1"
P,0.793006993006993,"2
p"
P,0.7944055944055944,"(4œÄœµ)d/2 E

e‚àí‚à•y‚àíx+œµ‚àáx e
L(x,Œ∏2)‚à•2"
P,0.7958041958041958,"4œµ
|x
"
P,0.7972027972027972,"‚â≤|‚à•y ‚àíx + œµ‚àáxeL(x, Œ∏1)‚à•2 ‚àí‚à•y ‚àíx + œµ‚àáxeL(x, Œ∏2)‚à•2|"
P,0.7986013986013986,"‚â≤‚à•‚àáxeL(x, Œ∏1) ‚àí‚àáxeL(x, Œ∏2)‚à•
‚â≤‚à•Œ∏1 ‚àíŒ∏2‚à•,"
P,0.8,"where the Ô¨Årst inequality (up to a Ô¨Ånite constant) follows by ‚à•ex ‚àíey‚à•‚â≤‚à•x ‚àíy‚à•for any x, y in a
compact space; the last inequality follows by the deÔ¨Ånition of the adaptive gradient in Eq.(15) and
‚à•log(x) ‚àílog(y)‚à•‚â≤‚à•x ‚àíy‚à•by the compactness assumption A1."
P,0.8013986013986014,"For f : X ‚ÜíRd, deÔ¨Åne the norm ‚à•f‚à•V = supx‚ààX
|f(x)|"
P,0.8027972027972028,"V (x) . Following the same technique proposed
in Liang et al. (2007) (page 319), we can verify the last drift condition"
P,0.8041958041958042,"‚à•PŒ∏1f ‚àíPŒ∏2f‚à•V ‚â§C‚à•f‚à•V ‚à•Œ∏1 ‚àíŒ∏2‚à•, ‚àÄf ‚ààLV := {f : X ‚ÜíRd, ‚à•f‚à•V < ‚àû}.
(VI)"
P,0.8055944055944056,"Having conditions (I), (II), ¬∑ ¬∑ ¬∑ and (VI) veriÔ¨Åed, we are now able to prove the drift conditions
proposed in Section 6 of Andrieu et al. (2005)."
P,0.806993006993007,"Before we present the L2 convergence of Œ∏k, we make some extra assumptions on the step size."
P,0.8083916083916084,"Assumption A5 (Learning rate and step size) The learning rate {œµk}k‚ààN is a positive non-
increasing sequence of real numbers satisfying the conditions"
P,0.8097902097902098,"lim
k œµk = 0, ‚àû
X"
P,0.8111888111888111,"k=1
œµk = ‚àû."
P,0.8125874125874126,Published as a conference paper at ICLR 2022
P,0.813986013986014,The step size {œâk}k‚ààN is a positive non-increasing sequence of real numbers such that
P,0.8153846153846154,"lim
k‚Üí‚àûœâk = 0, ‚àû
X"
P,0.8167832167832167,"k=1
œâk = +‚àû, ‚àû
X"
P,0.8181818181818182,"k=1
œâ2
k < +‚àû.
(32)"
P,0.8195804195804196,"A practical strategy is to set œâk := O(k‚àíŒ±) to satisfy the above conditions for any Œ± ‚àà(0.5, 1]."
P,0.820979020979021,"The following is an application of Theorem 24 (page 246) (Benveniste et al., 1990) given stability
conditions (Lemma 3)."
P,0.8223776223776224,"Lemma 7 (L2 convergence rate, restatement of Lemma 2) Assume Assumptions A1-A5 hold.
For any Œ∏0 ‚ààeŒò ‚äÇŒò, a large m, small learning rates {œµk}‚àû
k=1, and step sizes {œâk}‚àû
k=1, {Œ∏k}‚àû
k=0
converges to bŒ∏‚ãÜ, where bŒ∏‚ãÜ= Œ∏‚ãÜ+ O
 
supx Var(Œæn(x)) + supk‚â•k0 œµk + 1"
P,0.8237762237762237,"m

for some k0, such that"
P,0.8251748251748252,"E
h
‚à•Œ∏k ‚àíbŒ∏‚ãÜ‚à•2i
= O (œâk) ."
P,0.8265734265734266,"The theoretical novelty is that we treat the biased bŒ∏‚ãÜas the equilibrium of the continuous system
instead of analyzing how far we are away from Œ∏‚ãÜin all aspects as in Theorem 1 (Deng et al., 2020b).
This enables us to directly apply Theorem 24 (page 246). Nevertheless, it can be interpreted as a
special case of Theorem 1 (Deng et al., 2020b) except that there are no perturbation terms and the
equilibrium is bŒ∏‚ãÜinstead of Œ∏‚ãÜ."
P,0.827972027972028,"C
GAUSSIAN APPROXIMATION"
P,0.8293706293706293,"C.1
PRELIMINARY: SUFFICIENT CONDITIONS FOR WEAK CONVERGENCE"
P,0.8307692307692308,"To formally prove the asymptotic normality of the stochastic approximation process œâ‚àí1/2
k
(Œ∏k ‚àíbŒ∏‚ãÜ),
we Ô¨Årst lay out a preliminary result (Theorem 1 of Pelletier (1998)) that provides sufÔ¨Åcient conditions
to guarantee the weak convergence."
P,0.8321678321678322,"Lemma 8 (SufÔ¨Åcient Conditions) Consider a stochastic algorithm as follows
Œ∏k+1 = Œ∏k + œâk+1h(Œ∏k) + œâk+1eŒΩk+1 + œâk+1ek+1,
where eŒΩk+1 denotes a perturbation and ek+1 is a random noise. Given three conditions (C1), (C2),
and (C3) deÔ¨Åned below, we have the desired weak convergence result œâ‚àí1"
P,0.8335664335664336,"2 (Œ∏k ‚àíbŒ∏‚ãÜ) ‚áíN(0, Œ£),
(33)"
P,0.8349650349650349,"where Œ£ =
R ‚àû
0
ethŒ∏‚ãÜ‚ó¶R ‚ó¶eth‚ä§
Œ∏‚ãÜdt, R denotes the limiting covariance of the martingale
limk‚Üí‚àûE[ek+1e‚ä§
k+1|Fk] and Fk is the œÉ-algebra of the events up to iteration k, hŒ∏‚ãÜ= hŒ∏(bŒ∏‚ãÜ)+bŒæI,
bŒæ = limk‚Üí‚àû
œâ0.5
k
‚àíœâ0.5
k+1
œâ1.5
k
. ‚Ä†"
P,0.8363636363636363,"(C1) There exists an equilibrium point bŒ∏‚ãÜand a stable matrix hŒ∏‚ãÜ:= hŒ∏(bŒ∏‚ãÜ) ‚ààRm√óm such that for
any Œ∏ ‚àà{Œ∏ : ‚à•Œ∏ ‚àíbŒ∏‚ãÜ‚à•‚â§f
M} for some f
M > 0, the mean-Ô¨Åeld function h : Rm ‚ÜíRm satisÔ¨Åes"
P,0.8377622377622378,h(bŒ∏‚ãÜ) = 0
P,0.8391608391608392,"‚à•h(Œ∏) ‚àíhŒ∏‚ãÜ(Œ∏ ‚àíbŒ∏‚ãÜ)‚à•‚â≤‚à•Œ∏ ‚àíbŒ∏‚ãÜ‚à•2,"
P,0.8405594405594405,"(C2) The step size œâk decays with an order Œ± ‚àà(0, 1] such that œâk = O(k‚àíŒ±)."
P,0.8419580419580419,"(C3) Assumptions on the disturbances . There exists constants f
M > 0 and eŒ± > 2 such that
E [ek+1|Fk] 1{‚à•Œ∏‚àíbŒ∏‚ãÜ‚à•‚â§f
M} = 0,
(I1)"
P,0.8433566433566434,"sup
k
E
h
‚à•ek+1‚à•eŒ±|Fk
i
1{‚à•Œ∏‚àíbŒ∏‚ãÜ‚à•‚â§f
M} < ‚àû,
(I2)"
P,0.8447552447552448,"E

œâ‚àí1
k ‚à•eŒΩk+1‚à•2
1{‚à•Œ∏‚àíbŒ∏‚ãÜ‚à•‚â§f
M} ‚Üí0,
(II)"
P,0.8461538461538461,"E

ek+1e‚ä§
k+1|Fk

1{‚à•Œ∏‚àíbŒ∏‚ãÜ‚à•‚â§f
M} ‚ÜíR.
(III)"
P,0.8475524475524475,"‚Ä†For example, bŒæ = 0 if œâk = O(k‚àíŒ±), where Œ± ‚àà(0.5, 1] and bŒæ = k0"
P,0.848951048951049,2 if œâk = k0 k .
P,0.8503496503496504,Published as a conference paper at ICLR 2022
P,0.8517482517482518,"Remark 2 By the deÔ¨Ånition of the mean-Ô¨Åeld function h(Œ∏) in Eq.(26), it is easy to verify the
condition C1. Moreover, Assumption A5 also fulÔ¨Ålls the condition C2. Then, the proof hinges on the
veriÔ¨Åcation of the condition C3."
P,0.8531468531468531,"C.2
PRELIMINARY: CONVERGENCE OF THE COVARIANCE ESTIMATORS"
P,0.8545454545454545,"In particular, to verify the condition E

ek+1e‚ä§
k+1|Fk

1{‚à•Œ∏‚àíbŒ∏‚ãÜ‚à•‚â§f
M} ‚ÜíR, , we study the con-
vergence of the empirical sample mean E[f(xk)] for a test function f to the posterior expectation
¬Øf =
R"
P,0.855944055944056,"X f(x)œñbŒ∏‚ãÜ(x)(dx). Poisson‚Äôs equation is often used to characterize the Ô¨Çuctuation between
f(x) and ¬Øf:
Lg(x) = f(x) ‚àí¬Øf,
(34)"
P,0.8573426573426574,"where L refers to an inÔ¨Ånitesimal generator and g(x) denotes the solution of the Poisson‚Äôs equation.
Similar to the proof of Lemma 6, the existence of the solution of the Poisson‚Äôs equation has been
established in (Mattingly et al., 2002; Vollmer et al., 2016). Moreover, the perturbations of E[f(xk)]‚àí
¬Øf are properly bounded given regularity properties for g(x), where the 0-th, 1st, and 2nd order of the
regularity properties has been established in Erdogdu et al. (2018)."
P,0.8587412587412587,"The following result helps us to identify the convergence of the covariance estimators, which is
adapted from Theorem 5 (Chen et al., 2015) with decreasing learning rates {œµk}k‚â•1. The gradient
biases from Theorem 2 (Chen et al., 2015) are also included to handle the adaptive biases."
P,0.8601398601398601,"Lemma 9 (Convergence of the Covariance Estimators) Suppose Assumptions A1-A5 hold. For
any Œ∏0 ‚ààeŒò ‚äÇŒò, a large m, small learning rates {œµk}‚àû
k=1, step sizes {œâk}‚àû
k=1 and any bounded
function f, we have
E [f(xk)] ‚àí
Z"
P,0.8615384615384616,"X
f(x)œñbŒ∏‚ãÜ(x)dx
 ‚Üí0,"
P,0.862937062937063,"where œñbŒ∏‚ãÜ(x) is the invariant measure simulated via SGLD that approximates œñeŒ®Œ∏‚ãÜ(x) ‚àù
œÄ(x)
Œ∏Œ∂
‚ãÜ(J(x))."
P,0.8643356643356643,"Proof
We study the single-chain CSGLD and reformulate the adaptive algorithm as follows:"
P,0.8657342657342657,"xk+1 = xk ‚àíœµk‚àáxeL(xk, Œ∏k) + N(0, 2œµkœÑI)"
P,0.8671328671328671,"= xk ‚àíœµk

‚àáxeL(xk, bŒ∏‚ãÜ) + Œ•(xk, Œ∏k)

+ N(0, 2œµkœÑI),"
P,0.8685314685314686,"where ‚àáxeL(x, Œ∏) = N"
P,0.8699300699300699,"n
h
1 + Œ∂œÑ"
P,0.8713286713286713,"‚àÜu (log Œ∏(J(x)) ‚àílog Œ∏((J(x) ‚àí1) ‚à®1))
i
‚àáx eU(x) ‚Ä°, ‚àáxeL(x, Œ∏) is"
P,0.8727272727272727,"deÔ¨Åned in Section B.1 and the bias term is given by Œ•(xk, Œ∏k) = ‚àáxeL(xk, Œ∏k) ‚àí‚àáxeL(xk, bŒ∏‚ãÜ)."
P,0.8741258741258742,"Then, by Jensen‚Äôs inequality and Lemma 7, we have"
P,0.8755244755244755,"‚à•E[Œ•(xk, Œ∏k)]‚à•‚â§E[‚à•‚àáxeL(xk, Œ∏k) ‚àí‚àáxeL(xk, bŒ∏‚ãÜ)‚à•]"
P,0.8769230769230769,"‚â≤E[‚à•Œ∏k ‚àíbŒ∏‚ãÜ‚à•] ‚â§
q"
P,0.8783216783216783,"E[‚à•Œ∏k ‚àíbŒ∏‚ãÜ‚à•2] ‚â§O (‚àöœâk) .
(35)"
P,0.8797202797202798,"Combining Eq.(35) and Theorem 5 (Chen et al., 2015), we have"
P,0.8811188811188811,"E [f(xk)] ‚àí
Z"
P,0.8825174825174825,"X
f(x)œñbŒ∏‚ãÜ(x)dx
 = O"
PK,0.8839160839160839,"1
Pk
i œµi
+
Pk
i=1 œâi‚à•E[Œ•(xi, Œ∏i)]‚à•"
PK,0.8853146853146853,"Pk
i œâi
+
Pk
i œµ2
i
Pk
i œµi !"
PK,0.8867132867132868,"‚Üí0, as k ‚Üí‚àû,"
PK,0.8881118881118881,"where the last argument directly follows from the conditions on learning rates and step sizes in
Assumption A5."
PK,0.8895104895104895,"‚Ä°J(x) = Pm
i=1 i1ui‚àí1<U(x)‚â§ui, where the exact energy function U(x) is selected."
PK,0.8909090909090909,Published as a conference paper at ICLR 2022
PK,0.8923076923076924,"C.3
PROOF OF THEOREM 1"
PK,0.8937062937062937,Recall that the stochastic approximation based on a single process follows from
PK,0.8951048951048951,"Œ∏k+1
= Œ∏k + œâk+1H(Œ∏k, xk+1)
= Œ∏k + œâk+1h(Œ∏k) + œâk+1 (¬µŒ∏k(xk+1) ‚àíŒ†Œ∏k¬µŒ∏k(xk+1))
= Œ∏k + œâk+1h(Œ∏k)"
PK,0.8965034965034965,+ œâk+1
PK,0.8979020979020979,"
Œ†Œ∏k+1¬µŒ∏k+1(xk+1) ‚àíŒ†Œ∏k¬µŒ∏k(xk+1) + œâk+2 ‚àíœâk+1"
PK,0.8993006993006993,"œâk+1
Œ†Œ∏k+1¬µŒ∏k+1(xk+1)
"
PK,0.9006993006993007,"|
{z
}
ŒΩk+1"
PK,0.9020979020979021,+ œâk+1
PK,0.9034965034965035,"
1
œâk+1"
PK,0.9048951048951049,"
œâk+1Œ†Œ∏k¬µŒ∏k(xk) ‚àíœâk+2Œ†Œ∏k+1¬µŒ∏k+1(xk+1)
"
PK,0.9062937062937063,"|
{z
}
œÇk+1"
PK,0.9076923076923077,"+ ¬µŒ∏k(xk+1) ‚àíŒ†Œ∏k¬µŒ∏k(xk)
|
{z
}
ek+1 "
PK,0.9090909090909091,"= Œ∏k + œâk+1h(Œ∏k) + œâk+1 (ŒΩk+1 + œÇk+1)
|
{z
}
perturbation"
PK,0.9104895104895104,"+œâk+1 ek+1
|{z}
martingale , (36)"
PK,0.9118881118881119,where the second equality holds from the solution of Poisson‚Äôs equation in Eq.(30).
PK,0.9132867132867133,"We denote ¬®Œ∏k = Œ∏k + œâk+1Œ†Œ∏k¬µŒ∏k(xk). Adding œâk+2Œ†Œ∏k+1¬µŒ∏k+1(xk+1) on both sides of Eq.(36),
we have
¬®Œ∏k+1"
PK,0.9146853146853147,= ¬®Œ∏k + œâk+1h(Œ∏k) + œâk+1 (ŒΩk+1 + ek+1 + œÇk+1) + œâk+2Œ†Œ∏k+1¬µŒ∏k+1(xk+1) ‚àíœâk+1Œ†Œ∏k¬µŒ∏k(xk)
PK,0.916083916083916,= ¬®Œ∏k + œâk+1h(Œ∏k) + œâk+1 (ŒΩk+1 + ek+1)
PK,0.9174825174825175,"= ¬®Œ∏k + œâk+1h(¬®Œ∏k) + œâk+1 (ÀúŒΩk+1 + ek+1) ,
(37)"
PK,0.9188811188811189,"where ÀúŒΩk+1 = ŒΩk+1 + h(Œ∏k) ‚àíh(¬®Œ∏k). Next, we proceed to verify the conditions in C3."
PK,0.9202797202797203,"(I) By the martingale difference property of {ek} and the compactness assumption A1, we know that
for any eŒ± > 2
E[ek+1|Fk] = 0,
sup
k‚â•0
E[‚à•ek+1‚à•eŒ±|Fk] < ‚àû.
(I)"
PK,0.9216783216783216,"(II) By the deÔ¨Ånition of h(Œ∏k) in Eq.(26), we can easily check that h(Œ∏k) is Lipschitz continuous
in a neighborhood of bŒ∏‚ãÜ. Combining Eq.(31), we have ‚à•h(Œ∏k) ‚àíh(¬®Œ∏k)‚à•= O(‚à•Œ∏k ‚àí¬®Œ∏k‚à•) =
O(‚à•œâk+1Œ†Œ∏k¬µŒ∏k(xk)‚à•) = O(œâk+1). Then E[‚à•ŒΩk+1‚à•] ‚â§C‚à•Œ∏k ‚àí¬®Œ∏k‚à•+ O(œâk+2) = O(œâk+1) by
the step size condition Eq.(32). In what follows, we can verify"
PK,0.9230769230769231,"E
‚à•ÀúŒΩk+1‚à•2 œâk"
PK,0.9244755244755245,"
‚â§2E
‚à•ŒΩk+1‚à•2 œâk"
PK,0.9258741258741259,"
+ 2E"
PK,0.9272727272727272,"""
‚à•h(Œ∏k) ‚àíh(¬®Œ∏k)‚à•2 œâk #"
PK,0.9286713286713286,"= O(œâk) ‚Üí0.
(II)"
PK,0.9300699300699301,"(III) For the martingale difference noise ek+1 = ¬µŒ∏k(xk+1) ‚àíŒ†Œ∏k¬µŒ∏k(xk) with mean 0, we have"
PK,0.9314685314685315,"E[ek+1e‚ä§
k+1|Fk] = E[¬µŒ∏k(xk+1)¬µŒ∏k(xk+1)‚ä§|Fk] ‚àíŒ†Œ∏k¬µŒ∏k(xk)Œ†Œ∏k¬µŒ∏k(xk)‚ä§."
PK,0.9328671328671329,"We denote E[ek+1e‚ä§
k+1|Fk] by a function f(xk). Applying Lemma 9, we have"
PK,0.9342657342657342,"E[ek+1e‚ä§
k+1|Fk] = E[f(xk)] ‚Üí
Z
f(x)œñbŒ∏‚ãÜdx = lim
k‚Üí‚àûE[ek+1e‚ä§
k+1|Fk] := R,
(III)"
PK,0.9356643356643357,"where R := R(bŒ∏‚ãÜ) and R(Œ∏) is also equivalent to P‚àû
k=‚àí‚àûCovŒ∏(H(Œ∏, xk), H(Œ∏, x0))."
PK,0.9370629370629371,"Having the conditions C1, C2 and C3 veriÔ¨Åed, we apply Lemma 8 and have the following weak
convergence for ¬®Œ∏k"
PK,0.9384615384615385,"œâ‚àí1/2
k
(¬®Œ∏k ‚àíbŒ∏‚ãÜ) ‚áíN(0, Œ£),"
PK,0.9398601398601398,Published as a conference paper at ICLR 2022
PK,0.9412587412587412,"where Œ£ =
R ‚àû
0
ethŒ∏‚ãÜ‚ó¶R ‚ó¶eth‚ä§
Œ∏‚ãÜdt and hŒ∏‚ãÜ= hŒ∏(bŒ∏‚ãÜ) + bŒæI, bŒæ = limk‚Üí‚àû
œâ0.5
k
‚àíœâ0.5
k+1
œâ1.5
k
."
PK,0.9426573426573427,"Considering the deÔ¨Ånition that ¬®Œ∏k = Œ∏k + œâk+1Œ†Œ∏k¬µŒ∏k(xk) and E[‚à•Œ†Œ∏k¬µŒ∏k(xk)‚à•] is uniformly
bounded by Eq.(31), we have"
PK,0.9440559440559441,"œâ1/2
k
Œ†Œ∏k¬µŒ∏k(xk) ‚Üí0
in probability."
PK,0.9454545454545454,"By Slutsky‚Äôs theorem, we eventually have the desired result"
PK,0.9468531468531468,"œâ‚àí1/2
k
(Œ∏k ‚àíbŒ∏‚ãÜ) ‚áíN(0, Œ£)."
PK,0.9482517482517483,"where the step size œâk decays with an order Œ± ‚àà(0.5, 1] such that œâk = O(k‚àíŒ±)."
PK,0.9496503496503497,Published as a conference paper at ICLR 2022
PK,0.951048951048951,"D
MORE ON EXPERIMENTS"
PK,0.9524475524475524,"D.1
MODE EXPLORATION ON MNIST VIA THE SCALABLE RANDOM-FIELD FUNCTION"
PK,0.9538461538461539,"For the network structure, we follow Jarrett et al. (2009) and choose a standard convolutional neural
network (CNN). Such a CNN has two convolutional (conv) layers and two fully-connected (FC) layers.
The two conv layers has 32 and 64 feature maps, respectively. The FC layers both have 50 hidden
nodes and the network has 5 outputs. A large batch size of 2500 is selected to reduce the gradient noise
and reduce the stochastic approximation bias. We Ô¨Åx Œ∂ = 3e4 and weight decay 25. For simplicity,
we choose 100,000 partitions and ‚àÜu = 10. The step size follows œâk = min{0.01,
1
k0.6+100}."
PK,0.9552447552447553,"D.2
SIMULATIONS OF MULTI-MODAL DISTRIBUTIONS"
PK,0.9566433566433566,"The
target
density
function
is
given
by
œÄ(x)
‚àù
exp(‚àíU(x)),
where
x
=
(x1, x2)
and
U(x)
follows
U(x)
=
0.2(x2
1 + x2
2) ‚àí2(cos(2œÄx1) + cos(2œÄx2))."
PK,0.958041958041958,Figure 5: Target density.
PK,0.9594405594405594,"We also include a regularization term L(x) = I(x2
1+x2
2)>20 √ó
((x2
1 + x2
2) ‚àí20). This design leads to a highly multi-modal
distribution with 25 isolated modes. Figure 5 shows the con-
tour and the 3-D plot of the target density. The ICSGLD
and baseline algorithms are applied to this example. For IC-
SGLD, we set œµk = 3e‚àí3, œÑ = 1, Œ∂ = 0.75 and total number
of iterations= 8e4. Besides, we partition the sample space
into 100 subregions with bandwidth ‚àÜu = 0.125 and set
œâk = min(3e‚àí3,
1
k0.6+100)."
PK,0.9608391608391609,"For comparison, we run the baseline algorithms under similar
settings. For CSGLD, we run a single process 5 times of the
time budget and all the settings are the same as those used by ICSGLD. For reSGLD, we run Ô¨Åve
parallel chains with learning rates 0.001, 0.002, ¬∑ ¬∑ ¬∑ , 0.005 and temperatures 1, 2, ¬∑ ¬∑ ¬∑ , 5, respectively.
We estimate the correction every 100 iterations. We Ô¨Åx the initial correction 30 and choose the same
step size for the stochastic approximation as in ICSGLD. For SGLD, we run Ô¨Åve chains in parallel
with the learning rate 3e‚àí3 and a temperature of 1. For cycSGLD, we run a single-chain with 5
times of the time budget. We set the initial learning rate as 1e‚àí2 and choose 10 cycles. For the
particle-based SVGD, we run Ô¨Åve chains in parallel. For each chain, we initialize 100 particles as
being drawn from a uniform distribution over a rectangle. The learning rate is set to 3e‚àí3."
PK,0.9622377622377623,"Figure 6: Estimation KL divergence versus time steps for ICSGLD and baseline methods. We repeat
experiments 20 times."
PK,0.9636363636363636,"To compare the convergence rates in terms of running steps and time between ICSGLD and other
algorithms, we repeat each algorithm 20 times and calculate the mean and standard error over 20
trials. Note that we run all the algorithms based on 5 parallel chains (√óP5) except that cycSGLD
and CSGLD are run in a single-chain with 5 times of time budget (√óT5) and the steps and running"
PK,0.965034965034965,Published as a conference paper at ICLR 2022
PK,0.9664335664335665,"time are also scaled accordingly. Figure 6 shows that the vanilla SGLD√óP5 converges the slowest
among the Ô¨Åve algorithms due to the lack of mechanism to escape local traps; cycSGLD√óT5 slightly
alleviates that problem by adopting cyclical learning rates; reSGLD√óP5 greatly accelerates the
computations by utilizing high-temperature chains for exploration and low-temperature chains for
exploitation, but the large correction term inevitably slows down the convergence; ICSGLD√óP5
converges faster than all the others and the noisy energy estimators only induce a bias for the latent
variables and don‚Äôt affect the convergence rate signiÔ¨Åcantly."
PK,0.9678321678321679,"For the particle-based SVGD method, since more particles require expensive computations while
fewer particles lead to a crude approximation. Therefore, we don‚Äôt show the convergence of SVGD
and only compare the Monte Carlo methods."
PK,0.9692307692307692,"D.3
DEEP CONTEXTUAL BANDITS ON MUSHROOM TASKS"
PK,0.9706293706293706,"For the UCI Mushroom data set, each mushroom is either edible or poisonous. Eating an edible
mushroom yields a reward of 5, but eating a poisonous mushroom has a 50% chance to result in a
reward of -35 and a reward of 5 otherwise. Eating nothing results in 0 reward. All the agents use the
same architecture. In particular, we Ô¨Åt a two-layer neural network with 100 neurons each and ReLU
activation functions. The input of the network is a feature vector with dimension 22 (context) and
there are 2 outputs, representing the predicted reward for eating or not eating a mushroom. The mean
squared loss is adopted for training the models. We initialize 1024 data points and keep a data buffer
of size 4096 as the training proceeds. The size of the mini-batch data is set to 512. To adapt to online
scenarios, we train models after every 20 new observations."
PK,0.972027972027972,"We choose one œµ-greedy policy (EpsGreedy) based on the RMSProp optimizer with a decaying learn-
ing rate (Riquelme et al., 2018) as a baseline. Two variational methods, namely stochastic gradient
descent with a constant learning rate (ConstSGD) (Mandt et al., 2017) and Monte Carlo Dropout
(Dropout) (Gal & Ghahramani, 2016) are compared to approximate the posterior distribution. For the
sampling algorithms, we include preconditioned SGLD (pSGLD) (Li et al., 2016), preconditioned
CSGLD (pCSGLD) (Deng et al., 2020b), and preconditioned ICSGLD (pICSGLD). Note that all the
algorithms run 4 parallel chains with average outputs (√óP4) except that pCSGLD runs a single-chain
with 4 times of computational budget (√óT4). In particular for the two contour algorithms, we set
Œ∂ = 20 and choose a constant step size for the stochastic approximation to Ô¨Åt for the time-varying
posterior distributions. For more details on the experimental setups, we refer readers to section D in
the supplementary material."
PK,0.9734265734265735,"We report the experimental setups for each algorithm. Similar to Table 2 of Riquelme et al. (2018),
the inclusion of advanced techniques may change the optimal settings of the hyperparameters.
Nevertheless, we try to report the best setups for each individual algorithm. We train each algorithm
2000 steps. We initialize 1024 mushrooms and keep a data buffer of size 4096 as the training proceeds.
For each step, we are given 20 random mushrooms and train the model 16 iterations every step for
the parallel algorithms (√óP4); we train pCSGLD√óT4 64 iterations every step."
PK,0.9748251748251748,"EpsGreedy decays the learning rate by a factor of 0.999 every step; by contrast, all the others choose
a Ô¨Åxed learning rate. RMSprop adopts a regularizer of 0.001 and a learning rate of 0.01 to learn the
preconditioners. Dropout proposes a 50% dropout rate and each subprocess simulates 5 models for
predictions. For the two importance sampling (IS) algorithms, we partition the energy space into
m = 100 subregions and set the energy depth ‚àÜu as 10. We Ô¨Åx the hyperrameter Œ∂ = 20. The step
sizes for pICSGLD√óP4 and pCSGLD√óT4 are chosen as 0.03 and 0.006, respectively. A proper
regularizer is adopted for the low importance weights. See Table 2 for details."
PK,0.9762237762237762,TABLE 2: DETAILS OF THE EXPERIMENTAL SETUPS.
PK,0.9776223776223776,"ALGORITHM
LEARNING RATE
Temperature
RMSprop
IS
Train
Dropout
œµ-Greedy
EPSGREEDY√óP4
5e-7 (0.999)
0
YES
NO
16
NO
0.3%
CONSTSGD√óP4
1e-6
0
NO
NO
16
NO
NO
DROPOUT√óP4
1e-6
0
NO
NO
16
YES (50%)
NO
PCSGLD√óT4
5e-8
0.3
YES
YES
64
NO
NO
PSGLD√óP4
3e-7
0.3
YES
NO
16
NO
NO
PICSGLD√óP4
3e-7
0.3
YES
YES
16
NO
NO"
PK,0.9790209790209791,Published as a conference paper at ICLR 2022
PK,0.9804195804195804,"D.4
UNCERTAINTY ESTIMATION"
PK,0.9818181818181818,"All the algorithms, excluding M-SGD√óP4, choose a temperature of 0.0003 ‚Ä†. We run the parallel
algorithms 500 epochs (√óP4) and run the single-chain algorithms 2000 epochs (√óT4). The initial
learning rate is 2e-6 (Bayesian settings), which corresponds to the standard 0.1 for averaged data
likelihood."
PK,0.9832167832167832,"We train cycSGHMC√óT4 and MultiSWAG√óT4 based on the cosine learning rates with 10 cycles.
The learning rate in the last 15% of each cycle is Ô¨Åxed at a constant value. MultiSWAG simulates 10
random models at the end of each cycle. M-SGD√óP4 follows the same cosine learning rate strategy
with one cycle."
PK,0.9846153846153847,"reSGHMC√óP4 proposes swaps between neighboring chains and requires a Ô¨Åxed correction of 4000
for ResNet20, 32, and 56 and a correction of 1000 for WRN-16-8. The learning rate is annealed at
250 and 375 epochs with a factor of 0.2. ICSGHMC√óP4 also applies the same learning rate. We
choose m = 200 and ‚àÜu = 200 for ResNet20, 32, and 56 and ‚àÜu = 60 for WRN-16-8. Proper
regularizations may be applied to the importance weights and gradient multipliers for training deep
neural networks."
PK,0.986013986013986,"Variance reduction (Deng et al., 2021a) only applies to reSGHMC√óP4 and ICSGHMC√óP4 because
they are the only two algorithms that require accurate estimations of the energy. We only update
control variates every 2 epochs in the last 100 epochs, which maintain a reasonable training time and a
higher reduction of variance due to a small learning rate. Other algorithms yield a worse performance
when variance reduction is applied to the gradients."
PK,0.9874125874125874,"D.5
EMPIRICAL VALIDATION OF REDUCED VARIANCE"
PK,0.9888111888111888,"To compare the Œ∏‚Äôs learned from ICSGLD and CSGLD, we try to simulate from a Gaussian mixture
distribution 0.4N(‚àí6, 1) + 0.6N(4, 1), where N(u, v) denotes a Gaussian distribution with mean u
and standard deviation v. We Ô¨Åx Œ∂ = 0.9 and ‚àÜu = 1. We run ICSGLD with 1,000,000 iterations 0.0 0.2 0.4 0.6"
PK,0.9902097902097902,"2.5
5.0
7.5
10.0
Energy"
PK,0.9916083916083916,PDF in Energy (density of states)
PK,0.993006993006993,"ICSGLD xP10
CSGLD xT10
Œ∏*"
PK,0.9944055944055944,Figure 7: ICSGLD v.s. CSGLD.
PK,0.9958041958041958,"based on 10 interacting parallel chains and run CSGLD with
10,000,000 iterations using a single chain. We refer to them
as ICSGLD√óP10 and CSGLD√óT10, respectively. The rest
of the settings follows from the experimental setup in section
4.1 (Deng et al., 2020a)."
PK,0.9972027972027973,"To measure the variance of the estimates, we repeated the
experiments 10 times and present the mean and two stan-
dard deviations for both CSGLD√óT10 and ICSGLD√óP10
in Figure 7. The results indicate that both estimates of Œ∏Œ∂
(by CSGLD and ICSGLD) converge to the equilibrium that
approximates the ground truth of the density of states. No-
tably, ICSGLD√óP10 yields a signiÔ¨Åcantly smaller variance
than CSGLD√óT10, but with the same computational budget.
This shows the clear advantage of ICSGLD (many interact-
ing short runs) over CSGLD (a single long run) in tackling
the large variance issue for importance sampling."
PK,0.9986013986013986,"‚Ä†We use various data augmentation techniques, such as random Ô¨Çipping, cropping, and random erasing
(Zhong et al., 2017). This leads to a much more concentrated posterior and requires a very low temperature."
