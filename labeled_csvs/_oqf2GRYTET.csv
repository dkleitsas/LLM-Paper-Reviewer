Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.008264462809917356,"We generalize the concept of skew spectrum of a graph, a group-theoretical
permutation-invariant feature mapping. The skew spectrum considers adjacency
matrices as functions over Sn and leverages Fourier transform and group-theoretical
tools to extract features that are invariant under the group action. The main short-
coming of the previous result is that the skew spectrum only works for unlabeled
graphs. The reason is that these graphs can be represented using matrices whose
main diagonal contains zeros, meaning that there is only one set of elements that
can permute among themselves (i.e., one orbit). However, the representations of
more complex graphs (e.g., labeled graphs, multigraphs, or hypergraphs) have
different sets of elements that can consistently permute on different orbits. In this
work, we generalize the skew spectrum to the multiple orbits case. Our multi-
orbits skew spectrum produces features invariant to such permutations and possibly
informative of non-consistent ones. We show this method can improve the per-
formances of models that learn on graphs by providing comparisons with single
orbit representations and eigenvalues. Moreover, the theory is general enough to
handle invariance under the action of any ﬁnite group on multiple orbits and has
applications beyond the graph domain."
INTRODUCTION,0.01652892561983471,"1
Introduction"
INTRODUCTION,0.024793388429752067,"In the past decade, machine learning on datasets representing data as tensors became an active area
of research. This trend is fueled by important applications in anomaly detection, medical imaging,
genomics, and many others [1–3]. We generalize the skew spectrum, a graph invariant proposed
in [4], to a new tensor invariant. In the context of graphs, for which we frame this manuscript,
our generalization extends the applicability of this feature extraction method to more complex data
structures, such as labelled graphs, multigraphs, and hypergraphs."
INTRODUCTION,0.03305785123966942,"The skew spectrum of a graph is a permutation invariant mapping from the adjacency matrix A ∈
Rn×n of a weighted, directed, unlabeled graph G to a new feature space. A graph is unweighted when
the entries of A are just elements of {0, 1}, undirected when AT = A, and unlabeled when Aii = 0
for i ∈[n]. This mapping interprets the graph as a function on the symmetric group f : Sn 7→R,
where n is the number of nodes in the graph. The function f is deﬁned as f(σ) = Aσ(n),σ(n−1), for"
INTRODUCTION,0.04132231404958678,The Multi-Orbits Skew Spectrum: Boosting Permutation-Invariant Data Representations
INTRODUCTION,0.049586776859504134,"σ ∈Sn, here σ ∈Sn is permutation of the set [n] and σ(n) is the image of n under the permutation
σ. For more precise deﬁnitions on graph theory we refer the reader to Appendix A. Leveraging
techniques from non-commutative harmonic analysis it is possible to see that the skew spectrum
of a function f is related to the Fourier transform of the triple correlation of f [5]. An entry of the
skew spectrum is a matrix, denoted as Sf(σ, ρ), which is a function of a permutation σ ∈Sn, and an
irreducible representation ρ. We recall that a representation of Sn is a map ρ from the group Sn to
a subgroup of the orthogonal group on a real, ﬁnite-dimensional vector space. The representation
ρ is irreducible if it cannot be decomposed into direct sum of other representations. The intuition
here is that Sf(σ, ρ) is a polynomial of third order in the adjacency matrix such that this polynomial
is invariant with respect to joint permutations of rows and columns of the adjacency matrix. While
the skew spectrum might be a complete invariant in some cases [6], this is not true for many many
applications of the skew spectrum to permutation-invariant representations (i.e., two non-isomorphic
graphs could be mapped to the same feature vector)."
INTRODUCTION,0.05785123966942149,"The reduced skew spectrum [4, Deﬁnition 2] is a lightweight version of the skew spectrum, which
is deﬁned by reducing the size of the matrices of Sf(σ, ρ). The motivation for using the reduced
skew spectrum is threefold: While the computation of the skew spectrum has a complexity of O(n6),
the reduced skew spectrum has a computational complexity of O(n3) only (here n is the number of
the nodes of the graph); the output size of the reduced skew spectrum is independent of n and skew
spectrum contains many entries which are trivially zero, the reduced skew spectrum eliminates almost
all such entries. The (reduced) skew spectrum can only be applied to datasets with a single orbit; this
limitation is particularly important when dealing with tensor datasets. In this work, we extend the
skew spectrum to the multi-orbits setting. We show how we can inherit good computational properties
of the reduced skew spectrum also for the multiple orbit setting. While the main contribution of
this work is theoretical, we corroborate our analysis with some prototypical experiments on real and
synthetic datasets. We conclude that the multiple-orbits skew spectrum can enhance the representation
of datasets where keeping a consistency between permutation on different orbits is important."
IMPLEMENTATION/METHODS,0.06611570247933884,"2
The multi-orbits skew spectrum"
IMPLEMENTATION/METHODS,0.0743801652892562,"The main idea in generalizing the skew spectrum to multiple orbits is two-fold: we replace the
function f : Sn 7→R by a vector-valued function f : Sn 7→Rk, where k is the number of orbits, and
we replace products of functions by tensor products. For simplicity, we will describe the computation
for the case of two orbits for a function generated by the adjacency matrix A ∈Rn×n of a graph G.
Note, however, that all of our formulas are valid for any ﬁnite number of orbits. The interested reader
can refer to Appendix A for the representing more complex graphs as functions."
IMPLEMENTATION/METHODS,0.08264462809917356,"A labeled graph is one for which the adjacency matrix has some non-zero entries on the diagonal.
For a given labeled graph G, the adjacency matrix A is unique only up to arbitrary permutations of
the same indexes of both rows and columns. If we can obtain the adjacency matrix of a graph G by
applying a permutation σ ∈Sn to the indexes of the adjacency matrix of another graph ˜G, then we
say the graphs are isomorphic. It is fairly easy to see that the adjacency matrix of a labeled graph has
two orbits: the main diagonal, and the off-diagonal. For σ ∈Sn, let f : Sn 7→R2 be deﬁned as"
IMPLEMENTATION/METHODS,0.09090909090909091,"f(σ) =

Aσ(n),σ(n)
Aσ(n),σ(n−1)"
IMPLEMENTATION/METHODS,0.09917355371900827,"
.
(1)"
IMPLEMENTATION/METHODS,0.10743801652892562,We deﬁne an entry of the multi-orbits skew spectrum as
IMPLEMENTATION/METHODS,0.11570247933884298,"Sf(σ, ρ) =
1
(n!)2
X"
IMPLEMENTATION/METHODS,0.12396694214876033,˜σ1∈Sn X
IMPLEMENTATION/METHODS,0.1322314049586777,"˜σ2∈Sn
f(˜σ1) ⊗f(˜σ1σ) ⊗f(˜σ2) ⊗

ρ(˜σ1)†ρ(˜σ2)

,
(2)"
IMPLEMENTATION/METHODS,0.14049586776859505,"where † denotes the usual complex conjugate transpose. From this formula, one can notice that
the skew spectrum entries are invariant to permutations of the indices of the adjacency matrix, see
Appendix B for a formal proof and some intuition on the invariance."
IMPLEMENTATION/METHODS,0.1487603305785124,"Naively computing one skew spectrum entry from Eq. 2 would require O((n!)2) steps, which soon
becomes computationally infeasible even for small graphs. However, we can signiﬁcantly speed
up the calculation using insights from group theory. Up to improvements of constant factors, our
computational speedups coincide with the ones presented in Kondor and Borgwardt [4] and so the
computational cost is O(n6) (we are considering k = 2 as a constant). The key insight on the"
IMPLEMENTATION/METHODS,0.15702479338842976,The Multi-Orbits Skew Spectrum: Boosting Permutation-Invariant Data Representations
IMPLEMENTATION/METHODS,0.1652892561983471,"computational optimization that we adapt from the single-orbit case is the following. Denoting ˆf the
Fourier transform of f and writing"
IMPLEMENTATION/METHODS,0.17355371900826447,ˆf(ρ) = 1 n! X
IMPLEMENTATION/METHODS,0.18181818181818182,"˜σ∈Sn
f(˜σ) ⊗ρ(˜σ)
and
ˆrf(σ, ρ) = 1 n! X"
IMPLEMENTATION/METHODS,0.19008264462809918,"˜σ∈Sn
f(˜σ) ⊗f(˜σσ) ⊗ρ(˜σ)
(3)"
IMPLEMENTATION/METHODS,0.19834710743801653,"we get that Eq. 2 can be rewritten as Sf(σ, ρ) = ˆr†
f(σ, ρ) ⊙ˆf(ρ), where ⊙denotes tensor product of
functions and matrix product of representations. This signiﬁcantly speeds up the calculation since
the calculation of ˆf can be reduced to sum only over n(n −1) elements (as a property of f) and the
calculation of ˆrf can be reduced in a similar way, via Clausen-FFT type of arguments [5, 7]."
IMPLEMENTATION/METHODS,0.2066115702479339,"At the same time, Kondor and Borgwardt [4] show that the skew spectrum needs to be computed for
only 7 group entries and 4 irreducible representations, ﬁxing the overall computation of the skew
spectrum to O(n6). It is possible to prove that we actually need only 6 group elements. Indeed, 2 of
the 7 are inverses of each other and computing the skew spectra for both of them does not introduce
extra information. Moreover, we have empirical evidence that one of the 4 irreducible representation
only produces 0 matrices for undirected graphs and can therefore be discarded in such case."
IMPLEMENTATION/METHODS,0.21487603305785125,"While the computational complexity is polynomial in the size of the graph, there are still two problems:
O(n6) starts to be infeasible for medium-sized graphs and the number of computed features scales
with the number of nodes. Both of these problems are solved by using the reduced skew spectrum [4].
The main idea is that the Fourier transform ˆf consists of matrices that have variable number of rows
but ﬁxed number of columns, so the variable size of skew spectrum comes only from ˆrf. We thus
compute the reduced skew spectrum by limiting the number of rows of ˆrf, producing matrices of
ﬁxed size for all n, with a computational complexity of O(n3). In the general case, with k orbits, the
computational complexity of the reduced skew spectrum becomes O(k2n3 + k3n2). For a symmetric
adjacency matrix of a graph with n nodes, the single-orbit reduced skew spectrum consists of 36
numbers, while the two-orbits reduced skew spectrum consists of 288 numbers. In general, for k
orbits, the reduced multi-orbits skew spectrum consists of 36k3 numbers."
IMPLEMENTATION/METHODS,0.2231404958677686,"Generalization to multigraphs and hypergraphs.
We present the generalization of our method to
multigraphs. Different types of edges can be seen as several adjacency matrices and we can treat those
as additional orbits. Consider a multigraph with two types of edges. Let A be the adjacency matrix
corresponding to the ﬁrst type of edges and let B be adjacency matrix corresponding to the second
type of edges (note that the diagonals of both A and B coincide since the labels of the nodes are always
the same). We can then construct the function fAB(σ) = (Aσ(n),σ(n), Aσ(n),σ(n−1), Bσ(n),σ(n−1))⊺
and use the skew spectrum (or reduced skew spectrum) of fAB."
IMPLEMENTATION/METHODS,0.23140495867768596,"We can always represent a hypergraph as a multigraph where each edge type is an edge, but we also
propose an alternative encoding. Consider ﬁrst hyperedges that connect exactly 3 nodes. We can
then represent these hyperedges via n × n × n adjacency tensor A such that Aabc, a ̸= b ̸= c ̸= a, is
the weight of the hyperedge connecting the nodes labeled by a, b, and c. We can then use similar
methods to construct the corresponding function f and compute its skew spectrum. We can use similar
approach for hypergraphs with hyperedges connecting at most k nodes by considering adjacency
tensors Aa1...ak. With this alternative representation, and still considering the amount of orbits as a
constant, the computational complexity of the skew spectrum and the reduced skew spectrum will
increase. This is because for a standard graph the computational speedup heavily relies on the fact
that the function f is Sn−2 symmetric, but, for example, for hypergraph with hyperedges connecting
at most 3 nodes the resulting function will be only Sn−3 symmetric. Thus, for example, one would
need to sum at least n(n −1)(n −2) elements in order to compute ˆf(ρ)."
RESULTS/EXPERIMENTS,0.2396694214876033,"3
Numerical Experiments"
RESULTS/EXPERIMENTS,0.24793388429752067,"We implemented the code for both the single-orbit skew spectrum and the multi-orbits skew spectrum.
In this section, we report some prototypical experiments using their reduced versions on labeled
graphs. The experiments aim to show the enhanced representation power of the multi-orbits skew
spectrum against its predecessor. Comparison with other state-of-the-art graph invariants is out
of the scope of this manuscript and is left for future work. We discuss some extra experiments in
Appendix C."
RESULTS/EXPERIMENTS,0.256198347107438,The Multi-Orbits Skew Spectrum: Boosting Permutation-Invariant Data Representations
RESULTS/EXPERIMENTS,0.2644628099173554,"3.1
Graph classiﬁcation on a synthetic dataset"
RESULTS/EXPERIMENTS,0.2727272727272727,"The dataset contains undirected, unweighted, and labeled graphs. The node labels assume all the
values between 0 and n −1, with n the number of nodes. The labels are encoded along the main
diagonal of the graphs’ adjacency matrices. The dataset consists of four families of graphs, namely
15A, 15B, 6A, and 6B (Fig. 1 illustrates one graph representative per family). Each family contains
1000 isomorphic graphs, meaning that, inside a family, all the graphs are equal up to permutations that
are simultaneously edge-preserving and label-preserving. The graphs in 15A and 15B are equivalent
up to edge-preserving permutations but are not isomorphic if we also consider the labels permutations,
and so are the graphs in 6A and 6B. The task is to classify the four families of graphs correctly. 0
1 2 3 4
5 6 7 8 9 10 11 12 13 14"
RESULTS/EXPERIMENTS,0.2809917355371901,"(a) 15A. 0 5 9 11 8 3 1
7 10 12
2 13 4 6 14"
RESULTS/EXPERIMENTS,0.2892561983471074,"(b) 15B. 0 1
2 3 4 5"
RESULTS/EXPERIMENTS,0.2975206611570248,"(c) 6A. 2 5 3 1 4
0"
RESULTS/EXPERIMENTS,0.30578512396694213,(d) 6B.
RESULTS/EXPERIMENTS,0.3140495867768595,Figure 1: Synthetic dataset’s graph families representatives.
RESULTS/EXPERIMENTS,0.32231404958677684,"We have processed this dataset twice, producing two different representations. The ﬁrst one consists
of a concatenation of the outputs of the single-orbit skew spectrum computed separately on the
off-diagonal and on the main diagonal elements of the adjacency matrix (i.e., each skew spectrum
uses one row of Eq. 1 as a function). The second one consists of the output of the two-orbits skew
spectrum (computed using Eq. 1). We trained a random forest (60 estimators, no max depth) on the
two representations, holding out a balanced 20% of the dataset for testing purposes. The classiﬁer
achieves an accuracy of 0.5 on the single-orbit representation and of 1 on the 2-orbits one, meeting
our expectations. This is because the concatenation of single-orbit skew spectra cannot distinguish
the couples 15A-15B and 6A-6B, whose labels and edges are linked by different permutations."
RESULTS/EXPERIMENTS,0.3305785123966942,"3.2
Atomization energy regression on QM7"
RESULTS/EXPERIMENTS,0.33884297520661155,"The dataset is composed of a list of 23 × 23 matrices representing the Coulomb matrices of 7165
molecules composed of up to 23 atoms, from which up to 7 are considered heavy atoms [8, 9]. The
Coulomb matrix C ∈R23×23 is deﬁned as Cii = 1"
RESULTS/EXPERIMENTS,0.34710743801652894,"2Z2.4
i
and Cij =
ZiZj
|Ri−Rj|, where Zi is the nuclear
charge of the i-th atom of the molecule, and Ri is its position. The learning task associated with this
dataset is to predict the atomization energies of the molecules (kcal/mol), which are reals in the range
[−2000, −800] renormalized in [−1, 1]. We compute the reduced single-orbit skew spectrum on the
off-diagonal elements and the multiple-orbits skew spectrum and use them for regression, holding
out 20% of the dataset for the test set. Table 1 summarizes the results."
RESULTS/EXPERIMENTS,0.35537190082644626,"Table 1: Regression on qm7 with different features. We tested the following machine learning
models: Extreme Gradient Boosting (Xgboost), Gradient Boosting Regressor (GBR), Elastic Net
(EN), Linear Regression (Linear) using the default parameters of sk-learn[10]. Linear regression
cannot ﬁt the dataset for the eigenvectors of the Coulomb matrix. The error is measured as Mean
Absolute Error."
RESULTS/EXPERIMENTS,0.36363636363636365,"Representation
Xgboost
GBR
EN
Linear"
RESULTS/EXPERIMENTS,0.371900826446281,"Single-orbit
29.15
36.55
114.68
61.15
2-orbits
18.28
27.12
58.60
49.45
C’s eigs
38.04
37.92
47.83
-
Laplacian’s eigs
23.52
26.93
47.62
47.80"
RESULTS/EXPERIMENTS,0.38016528925619836,The Multi-Orbits Skew Spectrum: Boosting Permutation-Invariant Data Representations
CONCLUSION/DISCUSSION,0.3884297520661157,"4
Conclusions"
CONCLUSION/DISCUSSION,0.39669421487603307,"This work presents a generalization of the skew spectrum to multiple orbits. Thanks to our implemen-
tation, we can test the performances of the multi-orbits skew spectrum on classiﬁcation and regression
tasks. The performances obtained in these prototypical experiments highlight the limitations of
the single-orbit skew spectrum and the advantages of the proposed solution. For the classiﬁcation
experiment, we have a clear separation between the performances of a simple learner on 1-orbit and
2-orbits skew spectra of labeled graphs. For regression, the 2-orbits skew spectrum can improve the
mean absolute error compared to the single orbit case of all the machine learning models studied. We
leave for future work the study of problems on tensor datasets where the multi-orbits skew spectrum
can outperform state-of-the-art machine learning models."
CONCLUSION/DISCUSSION,0.4049586776859504,Acknowledgements
CONCLUSION/DISCUSSION,0.4132231404958678,"We would like to thank Ramakrishna Kakarala for providing us with a soft copy of his thesis. We
thank the Quantum Open Source Foundation, through which we ﬁrst met. Furthermore, we thank
Petar Veliˇckovi´c and Vijay Prakash Dwivedi for the kind feedback and useful discussions. AB would
like to thank professors Stefano Zanero, Ferruccio Resta and Donatella Sciuto for their support,
and Patrick Rebentrost for hosting him at CQT at the time of writing. MP acknowledges support
from the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation, project numbers
447948357 and 440958198), the Sino-German Center for Research Promotion (Project M-0294),
the ERC (Consolidator Grant 683107/TempoQ), the German Ministry of Education and Research
(Project QuKuK, BMBF Grant No. 16KIS1618K) and from the Alexander von Humboldt Foundation.
Research at CQT is funded by the National Research Foundation, the Prime Minister’s Ofﬁce, and the
Ministry of Education, Singapore under the Research Centres of Excellence programme’s research
grant R-710-000-012-135. We also acknowledge funding from the Quantum Engineering Programme
(QEP 2.0) under grant NRF2021-QEP2-02-P05."
REFERENCES,0.4214876033057851,References
REFERENCES,0.4297520661157025,"[1] Yh Taguchi and Turki Turki. Novel feature selection method via kernel tensor decomposition
for improved multi-omics data analysis. BMC medical genomics, 15(1):1–12, 2022. 1
[2] Hadi Fanaee-T and João Gama. Tensor-based anomaly detection: An interdisciplinary survey.
Knowledge-Based Systems, 98:130–147, 2016.
[3] Derek K Jones, Lewis D Grifﬁn, Daniel C Alexander, Marco Catani, Mark A Horsﬁeld, Robert
Howard, and Steve CR Williams. Spatial normalization and averaging of diffusion tensor mri
data sets. Neuroimage, 17(2):592–617, 2002. 1
[4] Risi Kondor and Karsten M Borgwardt. The skew spectrum of graphs. In Proceedings of the
25th international conference on Machine learning, pages 496–503, 2008. 1, 2, 3
[5] Risi Kondor. The skew spectrum of functions on ﬁnite groups and their homogeneous spaces.
arXiv preprint arXiv:0712.4259, 2007. 2, 3
[6] Ramakrishna Kakarala. Triple correlation on groups. University of California, Irvine, 1992. 2
[7] Michael Clausen. Fast generalized fourier transforms. Theoretical Computer Science, 67(1):
55–63, 1989. 3
[8] M. Rupp, A. Tkatchenko, K.-R. Müller, and O. A. von Lilienfeld. Fast and accurate modeling
of molecular atomization energies with machine learning. Physical Review Letters, 108:058301,
2012. 4
[9] L. C. Blum and J.-L. Reymond. 970 million druglike small molecules for virtual screening in
the chemical universe database GDB-13. J. Am. Chem. Soc., 131:8732, 2009. 4
[10] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel,
P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher,
M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine
Learning Research, 12:2825–2830, 2011. 4"
OTHER,0.4380165289256198,The Multi-Orbits Skew Spectrum: Boosting Permutation-Invariant Data Representations
OTHER,0.4462809917355372,"A
Representing graph data using functions"
OTHER,0.45454545454545453,"In this section we describe some cathegories of graphs and how we can represent them using functions
of the form f : Sn 7→Rk. Rather than being an exhaustive list, this section should give the reader an
idea of how to construct functions for more complex data structures."
OTHER,0.4628099173553719,"The simplest class of graphs that we can represent are directed, weighted graphs with n nodes. Such
graphs can be represented using an adjacency matrix A ∈Rn×n with entries equal to 0 on the main
diagonal. In this case, we can build a function f : Sn 7→R, as
f(σ) = Aσ(n),σ(n−1),
(4)"
OTHER,0.47107438016528924,"where σ(i) denotes the image of n under the permutation σ. The function takes a permutation as
input and outputs a matrix element, using the image of n and n −1 under this permutation (it only
iterates over the non-diagonal elements of A). This is the function of the original skew spectrum.
Plugging this function in our multi-orbits skew spectrum formulation will give the same result as the
single-orbit skew spectrum."
OTHER,0.4793388429752066,"Generalizing to some more complex graph structures, we consider graphs whose nodes can be
associated with one attribute.
Deﬁnition 1 (Labeled graph). Labeled graphs are graphs whose nodes have one attribute that can
be encoded as a real number."
OTHER,0.48760330578512395,"We can represent such graphs using the same adjacency matrix A ∈Rn×n, and we could encode the
attribute of the node i in the diagonal entry Aii. In this case, we want to be sure that a permutation
will consistently move both the edges and the node labels. Those live in two different orbits, that
need to permute accordingly. In this case, we can construct the graph function f : Sn 7→R2 as"
OTHER,0.49586776859504134,"f(σ) =

Aσ(n),σ(n−1)
Aσ(n),σ(n)"
OTHER,0.5041322314049587,"
.
(5)"
OTHER,0.512396694214876,"Here the order of the elements in the output vector in R2 does not matter, as long as the choice is
consistent during the computation. Given a permutation σ, this function returns a vector containing
an element on the off-diagonal and an element on the diagonal of A."
OTHER,0.5206611570247934,"A more general class of graphs are graphs with node attributes.
Deﬁnition 2 (Graph with node attributes). A graph with node attributes is a graph whose nodes are
associated to a vector of attributes, represented by real numbers."
OTHER,0.5289256198347108,"Say that each node can contain at most k′ distinct attributes. Then, we can represent the graph using
an adjacency matrix A ∈Rn×n with zeroes on the main diagonal and a set of k′ vectors xi ∈Rn
for i ∈{0, . . . , n −1}. Each vector xi represents an attribute and contains n entries, one per node.
In this case, off-diagonal elements of A can permute among themselves, entries in the same xi can
permute among themselves, but they have to do so consistently, forming k = k′ + 1 orbits. We
represent the jth entry of xi as xi,j and it represents the value of the attribute i for the node j. We
can construct the relative graph function f : Sn 7→Rk′+1 as"
OTHER,0.5371900826446281,f(σ) = 
OTHER,0.5454545454545454,"


"
OTHER,0.5537190082644629,"Aσ(n),σ(n−1)
x1,σ(n)
x2,σ(n)
· · ·
xk′,σ(n) "
OTHER,0.5619834710743802,"


.
(6)"
OTHER,0.5702479338842975,"Even in this case, the matrix outputs one element per orbit."
OTHER,0.5785123966942148,"Going on with more complex data structures, we can show how to represent multigraphs.
Deﬁnition 3 (Multigraph). Multigraphs are graphs where an edge can connect the multiple nodes."
OTHER,0.5867768595041323,"Say that we have k different layers of edges, each layer having its own meaning. Then, we can
represent the graph using a tensor adjacency matrix A ∈Rk×n×n, where Ak,i,j represents the value
of the edge in layer k between nodes i and j. The k layers form k distinct orbits where permutations
need to occur consistently. We can construct the graph function f : Sn 7→Rk as"
OTHER,0.5950413223140496,"f(σ) =  
"
OTHER,0.6033057851239669,"A0,σ(n),σ(n−1)
A1,σ(n),σ(n−1)
· · ·
Ak−1,σ(n),σ(n−1) "
OTHER,0.6115702479338843,"
.
(7)"
OTHER,0.6198347107438017,The Multi-Orbits Skew Spectrum: Boosting Permutation-Invariant Data Representations
OTHER,0.628099173553719,"Whenever we wanted to consider multigraphs with node attributes, we could increment the number
of orbits and build bigger functions."
OTHER,0.6363636363636364,"About hypegraphs, we refer the reader to the intuition in the main text. We recall that the computation
easily starts to become unpractical for hypergraphs having edges connecting more than a handful of
nodes (say 6). This is because the formulation for hypergraphs introduces a dependency on m in the
runtime (rather than k), which is provably at least factorial m!."
OTHER,0.6446280991735537,"B
Invariance of the multi-orbits skew spectrum"
OTHER,0.6528925619834711,"Theorem 4. Let f1(σ) : Sn 7→Rk be a function that maps an element of the permutation group to
a vector of real numbers. Let f2(σ) : Sn 7→Rk be a function that is equivalent to f1 up to input
permutation, such that f2(σ) = f1(σ′σ) for a ﬁxed σ′ ∈Sn. Then, the multi-orbits skew spectra of
f2 and f1 are equal."
OTHER,0.6611570247933884,"Proof. Consider a function f1(σ) : Sn 7→Rk. Now consider a second function f2(σ) = f1(σ′σ),
which is equivalent to f1 up to a permutation σ′ ∈Sn of its input. We can show that each single
entry of the skew spectrum for f2 is equal to the entry for f1, using the fact that ρ†(g)ρ(g) = I and
that P"
OTHER,0.6694214876033058,g∈G f(g′g) = P
OTHER,0.6776859504132231,"ˆg∈G f(ˆg) for any group G, any ﬁxed element g′ ∈G, and any function f
deﬁned over the group. We have"
OTHER,0.6859504132231405,"Sf2(σ, ρ) =
1
(n!)2
X"
OTHER,0.6942148760330579,˜σ1∈Sn X
OTHER,0.7024793388429752,"˜σ2∈Sn
f2(˜σ1) ⊗f2(˜σ1σ) ⊗f2(˜σ2) ⊗

ρ(˜σ1)†ρ(˜σ2)
"
OTHER,0.7107438016528925,"=
1
(n!)2
X"
OTHER,0.71900826446281,˜σ1∈Sn X
OTHER,0.7272727272727273,"˜σ2∈Sn
f1(σ′˜σ1) ⊗f1(σ′˜σ1σ) ⊗f1(σ′˜σ2) ⊗

ρ(˜σ1)†ρ(˜σ2)
"
OTHER,0.7355371900826446,"=
1
(n!)2
X"
OTHER,0.743801652892562,ˆσ1∈Sn X
OTHER,0.7520661157024794,"ˆσ2∈Sn
f1(ˆσ1) ⊗f1(ˆσ1σ) ⊗f1(ˆσ2) ⊗

ρ(σ′−1ˆσ1)†ρ(σ′−1ˆσ2)
"
OTHER,0.7603305785123967,"=
1
(n!)2
X"
OTHER,0.768595041322314,ˆσ1∈Sn X
OTHER,0.7768595041322314,"ˆσ2∈Sn
f1(ˆσ1) ⊗f1(ˆσ1σ) ⊗f1(ˆσ2) ⊗

ρ(ˆσ1)†ρ(σ′−1)†ρ(σ′−1)ρ(ˆσ2)
"
OTHER,0.7851239669421488,"=
1
(n!)2
X"
OTHER,0.7933884297520661,ˆσ1∈Sn X
OTHER,0.8016528925619835,"ˆσ2∈Sn
f1(ˆσ1) ⊗f1(ˆσ1σ) ⊗f1(ˆσ2) ⊗

ρ(ˆσ1)†ρ(ˆσ2)
"
OTHER,0.8099173553719008,"= Sf1(σ, ρ)"
OTHER,0.8181818181818182,where we relabeled ˆσ1 = σ′˜σ1 and ˆσ2 = σ′˜σ2.
OTHER,0.8264462809917356,"The key intuition here is that the functions of two isomorphic graphs are equal up to a translation by
the permutation σ that links their respective adjacency matrices: let fG be the function corresponding
to the original graph and let fG be the function given by the permuted adjacency matrix, then
fG(σ) = fG(σσ). Summing over all the elements of Sn neutralizes this translation."
OTHER,0.8347107438016529,"C
Extra experiments"
OTHER,0.8429752066115702,"C.1
Synthetic dataset - weighted and directed"
OTHER,0.8512396694214877,"We repeated the same experiment of Section 3.1, with directed, weighted, and labeled graphs. Figure 2
reports the representatives of the four new families. Each edge has a weight in the interval (0, 2]."
OTHER,0.859504132231405,"Even in this case, the concatenation of the single orbit skew spectra allow the random forest to achieve
an accuracy of 0.5, while the 2-orbit skew spectra allow for an accuracy of 1."
OTHER,0.8677685950413223,"C.2
Eigenvalue collisions"
OTHER,0.8760330578512396,"If we consider labeled graphs, then the eigenvalues or singular values, will be a valid invariant
for them. Indeed a permutation matrix would only rotate the adjacency matrix, without changing
the eigenvalues. However, it is easy to ﬁnd examples of non-isomorphic labeled graphs where the
eigenvalue invariant will collide. A valid example is the given by the graphs in Fig. 3."
OTHER,0.8842975206611571,"The Multi-Orbits Skew Spectrum: Boosting Permutation-Invariant Data Representations 0 1 2 3 4 5 6
7 8
9 10
11 12 13 14"
OTHER,0.8925619834710744,"(a) 15A. 9 5
13 11 14 6 1 12
0 10
7 4 2 3 8"
OTHER,0.9008264462809917,(b) 15B. 0 1 2 3 4 5
OTHER,0.9090909090909091,"(c) 6A. 1 0 5 2 3
4"
OTHER,0.9173553719008265,(d) 6B.
OTHER,0.9256198347107438,"Figure 2: Synthetic dataset’s graph families representatives. Graphs are directed and each edge has a
weight in (0, 2]. 2
1 2 1"
OTHER,0.9338842975206612,"(a) Graph 1. 1
2 2 1"
OTHER,0.9421487603305785,(b) Graph 2.
OTHER,0.9504132231404959,"Figure 3: Example of two graphs with the same eigenvalues/singular values, but with distinct
(reduced) skew spectra."
OTHER,0.9586776859504132,"In the graph of Fig. 3a, we have that the node with label 1 goes to the one labeled 2 with a weight
of 1. However, in the graph of Fig. 3b, the cost of moving from 1 to 2 is 2 and the two graphs are
non-isomorphic. The two adjacency matrices of the graphs in Fig. 3 are"
OTHER,0.9669421487603306,"A1 =

1
1
2
2"
OTHER,0.9752066115702479,"
A2 =

2
1
2
1"
OTHER,0.9834710743801653,"
.
(8)"
OTHER,0.9917355371900827,"It is easy to verify that Eigs(A1) = {3, 0} and Eigs(A2) = {3, 0}. Similarly, SingVals(A1) =
SingVals(A2) = {3.16227766, 0}. However, the reduced skew spectra of the two graphs are
different, meaning that the skew spectrum manages to distinguish the two cases."
