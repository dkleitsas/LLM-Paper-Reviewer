Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0023148148148148147,"Many datasets in scientific and engineering applications are comprised of objects
1"
ABSTRACT,0.004629629629629629,"which have specific geometric structure. A common example is data inhabiting a
2"
ABSTRACT,0.006944444444444444,"representation of SO(3) scalars, vectors, and tensors. One way to exploit prior
3"
ABSTRACT,0.009259259259259259,"knowledge of the structured data is to enforce SO(3)-equivariance. While general
4"
ABSTRACT,0.011574074074074073,"methods for handling arbitrary SO(3) representations exist, they can be compu-
5"
ABSTRACT,0.013888888888888888,"tationally intensive and complicated to implement. We show that by judicious
6"
ABSTRACT,0.016203703703703703,"symmetry breaking, we can efficiently increase the expressiveness of a network
7"
ABSTRACT,0.018518518518518517,"operating on these representations. We demonstrate the method on an important
8"
ABSTRACT,0.020833333333333332,"classification problem from High Energy Physics known as b-tagging. In this
9"
ABSTRACT,0.023148148148148147,"task, we find that our method achieves a 2.7× improvement in rejection score over
10"
ABSTRACT,0.02546296296296296,"standard methods.
11"
INTRODUCTION,0.027777777777777776,"1
Introduction
12"
INTRODUCTION,0.03009259259259259,"In many Machine Learning (ML) applications, at least some of the data of interest have specific
13"
INTRODUCTION,0.032407407407407406,"geometric structure. For example, position measurements from LiDAR imaging, the configuration of
14"
INTRODUCTION,0.034722222222222224,"atoms in molecular potentials, and measurements of particle momenta are all cases where the data are
15"
INTRODUCTION,0.037037037037037035,"naturally represented as spatial 3-vectors. However, classical Neural Network (NN) architectures are
16"
INTRODUCTION,0.03935185185185185,"not well suited to this sort of data; for instance, the standard Multi Level Perceptron would require
17"
INTRODUCTION,0.041666666666666664,"that all information, spatial or otherwise, must be collapsed into a flat list of features as input to the
18"
INTRODUCTION,0.04398148148148148,"network. In this case, the spatial nature of the data, while not lost, is not communicated a priori nor
19"
INTRODUCTION,0.046296296296296294,"enforced post hoc.
20"
INTRODUCTION,0.04861111111111111,"More recently, developments in the field of Representation Learning have shown that equivariant
21"
INTRODUCTION,0.05092592592592592,"NNs are a natural way to accommodate structured data, and in many cases lead to substantially
22"
INTRODUCTION,0.05324074074074074,"improved algorithms. Very informally, a function (such as a NN) is called equivariant if the output
23"
INTRODUCTION,0.05555555555555555,"transforms similarly to the input.
24"
INTRODUCTION,0.05787037037037037,"Convolutional Neural Networks (CNNs) are the prototypical example of this. CNNs exploit the fact
25"
INTRODUCTION,0.06018518518518518,"that image data can be most naturally represented as data on a discrete 2-dimensional grid. This data
26"
INTRODUCTION,0.0625,"structure is associated with the representation of the group of discrete translations. The standard
27"
INTRODUCTION,0.06481481481481481,"CNN layer takes advantage of this by operating on input grid (pixel) data with discrete translation
28"
INTRODUCTION,0.06712962962962964,"operations, and returning outputs on a similar grid structure. Because the output of each layer has the
29"
INTRODUCTION,0.06944444444444445,"same representational structure as the input, it is straightforward to build very deep representations
30"
INTRODUCTION,0.07175925925925926,"without destroying the prior spatial structure of the data, simply by stacking CNN layers. The result,
31"
INTRODUCTION,0.07407407407407407,"of course, is that CNNs have completely revolutionized the field of computer vision.
32"
INTRODUCTION,0.0763888888888889,"We specifically consider the case of continuous scalar and 3-dimensional vector point data, as may
33"
INTRODUCTION,0.0787037037037037,"be encountered in many point-cloud datasets. For these data, the natural group associated with their
34"
INTRODUCTION,0.08101851851851852,"representation is SO(3), the set of 3D rotations. Therefore, one strategy to incorporate this structure
35"
INTRODUCTION,0.08333333333333333,"into a neural architecture is to enforce equivariance w.r.t. SO(3), and several such architectures
36"
INTRODUCTION,0.08564814814814815,"have been proposed [1, 2, 3]. In general, these approaches achieve equivariance either by defining
37"
INTRODUCTION,0.08796296296296297,"a spherical convolutional operation [3, 1], or by constraining the network’s operations to maintain
38"
INTRODUCTION,0.09027777777777778,"strict representational structure [2, 4].
39"
INTRODUCTION,0.09259259259259259,"Our method follows the latter approach, but in a much simpler way. Rather than concerning
40"
INTRODUCTION,0.09490740740740741,"ourselves with arbitrary (2ℓ+ 1)-dimensional representations, we consider only a few physically
41"
INTRODUCTION,0.09722222222222222,"relevant representations: scalars, vectors, and order-2 tensors. For these three representations, it
42"
INTRODUCTION,0.09953703703703703,"is straightforward to enumerate the options for linear neuron layers. We also want our network
43"
INTRODUCTION,0.10185185185185185,"to be able to exchange information between different representations. The Clebsh-Gordon theory
44"
INTRODUCTION,0.10416666666666667,"prescribed in other methods provides the most general method for projecting arbitrary tensor products
45"
INTRODUCTION,0.10648148148148148,"between representations back into irreducible representations, However, once again we take a similar
46"
INTRODUCTION,0.1087962962962963,"approach, and instead introduce a simple Tensor Bilinear Layer, a subset of the CG space that consists
47"
INTRODUCTION,0.1111111111111111,"of commonly known and physically intuitive operations, such as the vector dot product and cross
48"
INTRODUCTION,0.11342592592592593,"product.
49"
INTRODUCTION,0.11574074074074074,"Importantly, we propose a novel method that allows us to relax equivariance requirements when an
50"
INTRODUCTION,0.11805555555555555,"axial symmetry is present, by allowing the global SO(3) symmetry to be locally broken down to
51"
INTRODUCTION,0.12037037037037036,"SO(2). These looser conditions allow us to design of models that enforce only the instantaneously
52"
INTRODUCTION,0.12268518518518519,"relevant equivariance, and allows the network to learn more expressive functions at each layer. We
53"
INTRODUCTION,0.125,"show that this kind of equivariant neuron is generally only possible with the introduction of order-2
54"
INTRODUCTION,0.12731481481481483,"tensor representations, but we provide an efficient implementation for vector-valued networks that
55"
INTRODUCTION,0.12962962962962962,"constructs only the minimal tensors required.
56"
INTRODUCTION,0.13194444444444445,"To illustrate a real-world application to data with an axial symmetry, we introduce a common
57"
INTRODUCTION,0.13425925925925927,"problem from the field of High Energy Physics (HEP), described in Sec. 2. In Sec. 3, we describe
58"
INTRODUCTION,0.13657407407407407,"the modular elements of our method, from which a wide variety of neural architectures may be
59"
INTRODUCTION,0.1388888888888889,"composed. In Sec. 4, we describe a specific architecture based on Deep Sets [5] which will serve as a
60"
INTRODUCTION,0.1412037037037037,"baseline model, and we illustrate how to adapt this architecture using our approach. In Sec. 5, we
61"
INTRODUCTION,0.14351851851851852,"describe the simulated data used for training and evaluation, and describe the results of a progressive
62"
INTRODUCTION,0.14583333333333334,"implementation of the modules developed herein. Finally, we offer concluding remarks in Sec. 6.
63"
RELATED WORK,0.14814814814814814,"1.1
Related Work
64"
RELATED WORK,0.15046296296296297,"From the field of High Energy Physics, there has been much work in applying various DL approaches
65"
RELATED WORK,0.1527777777777778,"to jet tagging [6, 7, 8, 9] in general and b-tagging in particular [10, 11]. The present work seeks to
66"
RELATED WORK,0.1550925925925926,"build on this effort by offering novel neural architectures that can be adapted into next-generation
67"
RELATED WORK,0.1574074074074074,"applications.
68"
RELATED WORK,0.1597222222222222,"From the field of Machine Learning, there have been numerous prior works on SO(3) equivariant
69"
RELATED WORK,0.16203703703703703,"models [1, 2, 3, 4]. In general, these approaches depend on Clebsh-Gordon (CG) decomposition
70"
RELATED WORK,0.16435185185185186,"and/or sampling from spherical harmonics. While our approach is more similar to the CG method, it
71"
RELATED WORK,0.16666666666666666,"is simpler and more relevant for the task at hand. Moreover, we innovate on the the space of allowed
72"
RELATED WORK,0.16898148148148148,"equivariant operations by relaxing the global SO(3) symmetry which is relevant for our particular
73"
RELATED WORK,0.1712962962962963,"application.
74"
NOVEL DEVELOPMENTS,0.1736111111111111,"1.2
Novel Developments
75"
NOVEL DEVELOPMENTS,0.17592592592592593,"The main innovation of this paper is to expand the set of linear equivariant maps in the special case
76"
NOVEL DEVELOPMENTS,0.17824074074074073,"where there is a “special” direction in space, which may change from sample to sample. In this
77"
NOVEL DEVELOPMENTS,0.18055555555555555,"case, it is possible to maintain global SO(3) equivariance, while breaking the per-layer equivariance
78"
NOVEL DEVELOPMENTS,0.18287037037037038,"condition down to a locally-defined SO(2) symmetry, which is parameterized by the special direction.
79"
NOVEL DEVELOPMENTS,0.18518518518518517,"We also innovate by introducing a simpler method of forming SO(3)-equivariant nonlinearities, by
80"
NOVEL DEVELOPMENTS,0.1875,"simply introducing familiar bilinear operations on spatial representations such as scalars, vectors, and
81"
NOVEL DEVELOPMENTS,0.18981481481481483,"tensors. In addition to the nonlinearity provided by the bilinear operations, we also introduce simple
82"
NOVEL DEVELOPMENTS,0.19212962962962962,"nonlinear activation functions on the vector and tensor representations, which we find helps stabilize
83"
NOVEL DEVELOPMENTS,0.19444444444444445,"training and improve performance.
84"
NOVEL DEVELOPMENTS,0.19675925925925927,"Lastly, from the physics perspective, we propose a significant departure from standard practice, by
85"
NOVEL DEVELOPMENTS,0.19907407407407407,"stipulating that our b-tagging should be provided with raw 3-dimension position and momentum
86"
NOVEL DEVELOPMENTS,0.2013888888888889,"information, as this is the only way to ensure that SO(3)/SO(2) equivariance is exploited.
87"
NOVEL DEVELOPMENTS,0.2037037037037037,"While we demonstrate our methods using a specifc architecture based on Deep Sets [5], we expect
88"
NOVEL DEVELOPMENTS,0.20601851851851852,"these innovations can be useful in many other applications. Given the modularity and strictly defined
89"
NOVEL DEVELOPMENTS,0.20833333333333334,"input and output representations of each layer, these elements could be used to augment other neural
90"
NOVEL DEVELOPMENTS,0.21064814814814814,"architectures such as convolutional, graph, and transformers as well.
91"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.21296296296296297,"2
B-jet Identification at LHC Experiments
92"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2152777777777778,"In HEP experiments, such as ATLAS [12] and CMS [13] at CERN, b-jets are a crucial signal for
93"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2175925925925926,"studying rare phenomena and precision physics at the smallest scales of nature. A jet is a collimated
94"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2199074074074074,"spray of hadronic particles originating from energetic quarks or gluons produced in high energy
95"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2222222222222222,"particle collisions. A b-jet is a jet which specifically originates from a b-quark; when these quarks
96"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.22453703703703703,"hadronize, they form metastable B-mesons which travel some distance from the collision origin
97"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.22685185185185186,"before decaying, emitting particles from a secondary, displaced vertex.
98"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.22916666666666666,"Charged particles originating from these vertices are measured with tracking detectors and are often
99"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.23148148148148148,"referred to as tracks. Due to the displacement of the secondary vertex, when track trajectories
100"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2337962962962963,"originating from B-meson decays are extrapolated backwards, they are generally not incident to the
101"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2361111111111111,"origin. Therefore, we instead measure the distance to the point of closest approach; this is often
102"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.23842592592592593,"referred to as the track impact parameter, which is a 3-vector quantity that we denote with a.
103"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.24074074074074073,"In most applications, only the transverse and longitudinal components, d0 and z0, of this impact
104"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.24305555555555555,"parameter are examined [14]. The magnitude of these projections is the most distinctive feature that
105"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.24537037037037038,"indicates whether a particular jet originated from a b-quark.
106"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.24768518518518517,"The inspiration for this work was the observation that the physical processes which govern how
107"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.25,"particles within a jet are produced and propagated are largely invariant with respect to rotations about
108"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2523148148148148,"the jet axis, denoted ˆj. This is the unit vector in the direction of the aggregate jet’s momentum vector.
109"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.25462962962962965,"On the other hand the standard b-tagging observables d0 and z0 have no well-defined transformation
110"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2569444444444444,"rule under rotations, i.e. they are not part of a covariant representation.
111"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.25925925925925924,"Previous works [8] have demonstrated that networks which exploit this natural SO(2) symmetry
112"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.26157407407407407,"can greatly improve performance, but these methods all essentially rely on reducing the problem to
113"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2638888888888889,"vectors in a 2-dimensional plane. In order to obtain an equivariant representation in the case of b-jets,
114"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2662037037037037,"we must consider the full 3-dimensional structure of the impact parameter, which transforms as a
115"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.26851851851851855,"vector under general rotations a
R→Ra. In addition to the 3-dimensional impact parameter a, we also
116"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2708333333333333,"have information about the track’s momentum p and various scalar quantities such as the particle’s
117"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.27314814814814814,"charge, energy, and a limited identification of the particle type.
118"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.27546296296296297,"In the next section, we will describe modular neural elements that can solve this problem, by allowing
119"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2777777777777778,"a network to admit a global SO(3) symmetry which preserves the scalar and vector representations,
120"
B-JET IDENTIFICATION AT LHC EXPERIMENTS,0.2800925925925926,"while also breaking SO(3) down to the more physically appropriate SO(2) whenever possible.
121"
NETWORK ELEMENTS,0.2824074074074074,"3
Network Elements
122"
NETWORK ELEMENTS,0.2847222222222222,"Our proposed method depends on three modular elements, described in detail in the following
123"
NETWORK ELEMENTS,0.28703703703703703,"subsections. The overall strategy begins by mirroring what has proved to work for NNs in general:
124"
NETWORK ELEMENTS,0.28935185185185186,"we interleave simple linear (or affine) layers with nonlinear activation functions, in order to learn
125"
NETWORK ELEMENTS,0.2916666666666667,"powerful models. For an equivariant network, we first need to identify a set of linear equivariant
126"
NETWORK ELEMENTS,0.29398148148148145,"maps suitable for the symmetry at hand. In our case, we come up with two sets of such maps: a
127"
NETWORK ELEMENTS,0.2962962962962963,"global SO(3)-equivariant affine layer, and a locally SO(2)ˆj-equivariant linear layer.
128"
NETWORK ELEMENTS,0.2986111111111111,"Since we also require our network to mix between its scalar, vector, and tensor representations, we
129"
NETWORK ELEMENTS,0.30092592592592593,"introduce an equivariant bilinear layer. Lastly, we define SO(3) equivariant nonlinear activations for
130"
NETWORK ELEMENTS,0.30324074074074076,"each output representation.
131"
NETWORK ELEMENTS,0.3055555555555556,"In Sec. 4, we demonstrate how to combine these elements into a complete neural architecture. This
132"
NETWORK ELEMENTS,0.30787037037037035,"architecture is based on the Deep Sets [5] architecture suitable for variable-length, permutation-
133"
NETWORK ELEMENTS,0.3101851851851852,"invariant data.
134"
NETWORK ELEMENTS,0.3125,"3.1
SO(2)ˆj-equivariant Linear Layers
135"
NETWORK ELEMENTS,0.3148148148148148,"A well-known way to ensure equivariance w.r.t. any group is to broadcast the neural action across the
136"
NETWORK ELEMENTS,0.31712962962962965,"representational indices of the data [15, 16]. That is, the neural weight matrix simply forms linear
137"
NETWORK ELEMENTS,0.3194444444444444,"combinations of the features in their representation space. In general, it is helpful to add a bias term,
138"
NETWORK ELEMENTS,0.32175925925925924,"but care must be taken to select one that preserves equivariance.
139"
NETWORK ELEMENTS,0.32407407407407407,"The simplest example of this is for a collection of F scalar input features, {si}, mapping to a
140"
NETWORK ELEMENTS,0.3263888888888889,"collection of K output features. The scalar has no representational indices, so this simply amounts to
141"
NETWORK ELEMENTS,0.3287037037037037,"the standard affine1 network layer
142"
NETWORK ELEMENTS,0.33101851851851855,"yi = Wijsj + bi
(1)"
NETWORK ELEMENTS,0.3333333333333333,"where the learnable parameters Wij and bi are the neural weights and bias terms, respectively. In the
143"
NETWORK ELEMENTS,0.33564814814814814,"vector case, we may generalize to
144"
NETWORK ELEMENTS,0.33796296296296297,"yi = Wijvj ; bi = 0 .
(2)"
NETWORK ELEMENTS,0.3402777777777778,"Note that the equivariance condition for vector-valued functions f(Rv) = Rf(v) implies that
145"
NETWORK ELEMENTS,0.3425925925925926,"Rb = b for arbitrary rotation R; hence, the bias vector must be zero. Finally, the analogous case for
146"
NETWORK ELEMENTS,0.3449074074074074,"order-2 tensors is:
147"
NETWORK ELEMENTS,0.3472222222222222,"Yi = WijTj + Bi ; Bi = biI ,
(3)"
NETWORK ELEMENTS,0.34953703703703703,"where again we have learnable scalar parameters bi. In this case, the equivariance condition is
148"
NETWORK ELEMENTS,0.35185185185185186,"f(RTRT ) = Rf(T)RT , which implies that RBRT = B, i.e. B must commute with arbitrary R.
149"
NETWORK ELEMENTS,0.3541666666666667,"Therefore, B must be proportional to the identity tensor I.
150"
NETWORK ELEMENTS,0.35648148148148145,"The above neurons are purely isotropic in SO(3). However, as discussed in Sec. 1, for our problem
151"
NETWORK ELEMENTS,0.3587962962962963,"we have prior knowledge that the distribution is symmetric about a specific axis. At worst, having
152"
NETWORK ELEMENTS,0.3611111111111111,"only isotropic operations can over-regularize the network by imposing too much structure, and at best
153"
NETWORK ELEMENTS,0.36342592592592593,"it might be harder for the network to spontaneously learn about the axial symmetry. We therefore
154"
NETWORK ELEMENTS,0.36574074074074076,"consider the most general linear map is equivariant w.r.t. the axial symmetry. Since this is a lesser
155"
NETWORK ELEMENTS,0.3680555555555556,"degree of symmetry, the network should have greater freedom in choosing linear maps.
156"
VECTOR CASE,0.37037037037037035,"3.1.1
Vector Case
157"
VECTOR CASE,0.3726851851851852,"Let ˆj be a unit vector (in our application, the jet’s momenutm axis) which is instantaneously fixed per
158"
VECTOR CASE,0.375,"batch input. The rotations about this axis define a proper subgroup Sˆj ⊂SO(3) where we identify
159"
VECTOR CASE,0.3773148148148148,"Sˆj ∼= SO(2). We therefore refer to this subgroup as SO(2)ˆj ⊂SO(3); the distinction being that
160"
VECTOR CASE,0.37962962962962965,"SO(2)ˆj fixes a representation on R3 which depends on ˆj.
161"
VECTOR CASE,0.3819444444444444,"The set of all linear SO(2)ˆj-equivariant maps is exactly the set of matrices A which commute with
162"
VECTOR CASE,0.38425925925925924,"arbitrary Rˆj ∈SO(2)ˆj, which are of the form
163"
VECTOR CASE,0.38657407407407407,"A = (aˆjˆj
T + b(I −ˆjˆj
T ))R′
ˆj(ϕ) ,
(4)"
VECTOR CASE,0.3888888888888889,"for arbitrary learnable parameters ¯θ = (a, b, ϕ). The first two terms represent anisotropic scaling
164"
VECTOR CASE,0.3912037037037037,"in the directions parallel and perpendicular to ˆj, respectively. The third term represents any other
165"
VECTOR CASE,0.39351851851851855,"arbitrary rotation about the ˆj axis, parameterized by a single angle ϕ.
166"
VECTOR CASE,0.3958333333333333,"Because A commutes with all Rˆj ∈SO(2)ˆj, the linear layer defined by
167"
VECTOR CASE,0.39814814814814814,"yi = A¯θijvj
(5)"
VECTOR CASE,0.40046296296296297,"is SO(2)ˆj-equivariant, for arbitrary parameters ¯θij. The isotropic linear neuron of Eq. 1 corresponds
168"
VECTOR CASE,0.4027777777777778,"to the special case aij = bij, ϕij = 0.
169"
TENSOR CASE,0.4050925925925926,"3.1.2
Tensor Case
170"
TENSOR CASE,0.4074074074074074,"In order for a tensor-valued linear map L to be equivariant, we require that L(RˆjTRT
ˆj ) = Rˆj(LT)RT
ˆj .
171"
TENSOR CASE,0.4097222222222222,"Note that in the case of full SO(3) equivariance, the only option is for L to be proportional to the
172"
TENSOR CASE,0.41203703703703703,1Also referred to as a Dense or Linear layer.
TENSOR CASE,0.41435185185185186,Figure 1: A schematic diagram of the bilinear layer with mixing between different representations.
TENSOR CASE,0.4166666666666667,"identity. Without loss of generality, we may assume the order-4 tensor L can be written as a sum
173"
TENSOR CASE,0.41898148148148145,"of terms A ⊗B for some order-2 tensors A, B. The tensor product acts on an order-2 tensor T as
174"
TENSOR CASE,0.4212962962962963,"(A ⊗B)T := ATBT . Taking L to be of this form (up to linear combinations), the equivariance
175"
TENSOR CASE,0.4236111111111111,"condition reads A(RˆjTRT
ˆj )BT = Rˆj(ATBT )RT
ˆj . This is satisfied when both A and B commute
176"
TENSOR CASE,0.42592592592592593,"with Rˆj; we have already identified the set of such matrices in Eq. 4. Therefore, we define the action
177"
TENSOR CASE,0.42824074074074076,"of the tensor-valued SO(2)ˆj linear layer by:
178"
TENSOR CASE,0.4305555555555556,"Yi = A¯θijTjAT
¯φij + biI ,
(6)"
TENSOR CASE,0.43287037037037035,"where the parameters (¯θij, ¯φij) are the neural connections and we also allow for an affine bias term
179"
TENSOR CASE,0.4351851851851852,"parameterized by bi, which is proportional to the identity tensor and hence also equivariant.
180"
TENSOR BILINEAR OPERATIONS,0.4375,"3.2
Tensor Bilinear Operations
181"
TENSOR BILINEAR OPERATIONS,0.4398148148148148,"So far we have provided two means for working with data in the SO(3) scalar, vector, and order-2
182"
TENSOR BILINEAR OPERATIONS,0.44212962962962965,"tensor representations. However, we also desire a means for allowing information between the
183"
TENSOR BILINEAR OPERATIONS,0.4444444444444444,"different representations to be combined and mixed.
184"
TENSOR BILINEAR OPERATIONS,0.44675925925925924,"The most general approach to this is addressed by Clebsh-Gordon theory [2, 4]. But we adopt a
185"
TENSOR BILINEAR OPERATIONS,0.44907407407407407,"simpler approach, wherein we take advantage of the familiar representations of our data and employ
186"
TENSOR BILINEAR OPERATIONS,0.4513888888888889,"common bilinear operations such as dot products and cross products for vectors2. This allows
187"
TENSOR BILINEAR OPERATIONS,0.4537037037037037,"the network to create a mixing between different representations. The operations considered are
188"
TENSOR BILINEAR OPERATIONS,0.45601851851851855,"enumerated schematically in Fig. 1. In order to form these terms, the bilinear layer requires that the
189"
TENSOR BILINEAR OPERATIONS,0.4583333333333333,"scalar, vector, and tensor inputs (s, v, T) all have the same size, 2F, in their feature dimension, and
190"
TENSOR BILINEAR OPERATIONS,0.46064814814814814,"that the size is a multiple of two. We then split the features into groups of two: sa = {si}i=1..F ,
191"
TENSOR BILINEAR OPERATIONS,0.46296296296296297,"sb = {si}i=F +1..2F , and define similarly va,b and Ta,b.
192"
TENSOR BILINEAR OPERATIONS,0.4652777777777778,"After effecting all of the options from Fig. 1, the layer returns scalar, vector, and tensor outputs with
193"
TENSOR BILINEAR OPERATIONS,0.4675925925925926,"3F features each.
194"
TENSOR BILINEAR OPERATIONS,0.4699074074074074,"3.3
SO(3)-equivariant Nonlinear Activations
195"
TENSOR BILINEAR OPERATIONS,0.4722222222222222,"For the scalar features, any function is automatically equivariant. Therefore, for these features we use
196"
TENSOR BILINEAR OPERATIONS,0.47453703703703703,"the well-known ReLU[17] activation function, although any alternative nonlinearity would also work.
197"
TENSOR BILINEAR OPERATIONS,0.47685185185185186,"In the vector and tensor cases, care must be taken to ensure equivariance. For the vector case, we
198"
TENSOR BILINEAR OPERATIONS,0.4791666666666667,"state a simple theorem[18]:
199"
TENSOR BILINEAR OPERATIONS,0.48148148148148145,"Theorem 3.1 For any vector-valued function f : R3 →R3 which satisfies f(Rx) = Rf(x) for all
200"
TENSOR BILINEAR OPERATIONS,0.4837962962962963,"R ∈SO(3), there exists a scalar function ˜f such that
201"
TENSOR BILINEAR OPERATIONS,0.4861111111111111,"f(x) = ˜f(|x|)ˆx ,"
TENSOR BILINEAR OPERATIONS,0.48842592592592593,"where ˆx = x/|x| when |x| > 0 and ˆx = 0 otherwise.
202"
TENSOR BILINEAR OPERATIONS,0.49074074074074076,"2Of course, these operations can be expressed in terms of the CG basis, but may not span the entire space of
irreducible representations guaranteed by Schur’s lemma."
TENSOR BILINEAR OPERATIONS,0.4930555555555556,"In other words, we may chose an arbitrary, nonlinear function ˜f which acts only on the vector magni-
203"
TENSOR BILINEAR OPERATIONS,0.49537037037037035,"tude, and the layer must leave the direction of the input unchanged. This leaves many possibilities;
204"
TENSOR BILINEAR OPERATIONS,0.4976851851851852,"after some experimentation, we found the following activation, which we call Vector ReLU (VReLU),
205"
TENSOR BILINEAR OPERATIONS,0.5,"works well:
206"
TENSOR BILINEAR OPERATIONS,0.5023148148148148,"VReLU(v) :=
 v
|v| < 1
v/|v|
else
.
(7)"
TENSOR BILINEAR OPERATIONS,0.5046296296296297,"The VReLU activation is analogous to the standard rectified linear unit, except that the transition
207"
TENSOR BILINEAR OPERATIONS,0.5069444444444444,"from linear to constant happens at a fixed positive magnitude rather than zero. We found that in
208"
TENSOR BILINEAR OPERATIONS,0.5092592592592593,"particular, the saturating aspect of VReLU greatly helps to stabilize training, as otherwise the vector
209"
TENSOR BILINEAR OPERATIONS,0.5115740740740741,"features tend to coherently grow in magnitude, leading to exploding gradients.
210"
TENSOR BILINEAR OPERATIONS,0.5138888888888888,"For the order-2 tensor case, we note here that the tensor analog to Theorem 3.1 is much more
211"
TENSOR BILINEAR OPERATIONS,0.5162037037037037,"nuanced[18], and in general depends on three principal invariants I1, I2, I3. For simplicity, we define
212"
TENSOR BILINEAR OPERATIONS,0.5185185185185185,"the Tensor ReLU (TReLU) completely analogously to the vector case, and leave a more complete
213"
TENSOR BILINEAR OPERATIONS,0.5208333333333334,"analysis of tensor nonlinearities to future work:
214"
TENSOR BILINEAR OPERATIONS,0.5231481481481481,"TReLU(T) :=
T
||T||F < 1
T/||T||F
else
.
(8)"
BENCHMARK ARCHITECTURES,0.5254629629629629,"4
Benchmark Architectures
215"
BENCHMARK ARCHITECTURES,0.5277777777777778,"We now have defined the four modular elements which provide the appropriate equivariant operations.
216"
BENCHMARK ARCHITECTURES,0.5300925925925926,"In order to evaluate the practical effects of these modules, we define a benchmark architecture that is
217"
BENCHMARK ARCHITECTURES,0.5324074074074074,"based on the Deep Sets architecture[5], also referred to as a Particle Flow Network (PFN) [19] in
218"
BENCHMARK ARCHITECTURES,0.5347222222222222,"the field of HEP. The PFN is a commonly-used architecture for this sort of problem in real-world
219"
BENCHMARK ARCHITECTURES,0.5370370370370371,"applications such as at the ATLAS experiment[14].
220"
BENCHMARK ARCHITECTURES,0.5393518518518519,"We will first define the standard PFN architecture, which will serve as our baseline in experiments.
221"
BENCHMARK ARCHITECTURES,0.5416666666666666,"Then, we describe a modified version at the module level using the analogous equivariant operations
222"
BENCHMARK ARCHITECTURES,0.5439814814814815,"in place of the standard neural network layers.
223"
PARTICLE FLOW NETWORK,0.5462962962962963,"4.1
Particle Flow Network
224"
PARTICLE FLOW NETWORK,0.5486111111111112,"The basic structure of the PFN [19] is based on the Deep Sets [5] architecture, and will serve as our
225"
PARTICLE FLOW NETWORK,0.5509259259259259,"baseline. It is of the form:
226"
PARTICLE FLOW NETWORK,0.5532407407407407,"PFN({pk}) = F P
X"
PARTICLE FLOW NETWORK,0.5555555555555556,"k=1
Φ(pk) ! .
(9)"
PARTICLE FLOW NETWORK,0.5578703703703703,"where Φ : RF →RL and F : RL →Y are arbitrary continuous functions parameterized by neural
227"
PARTICLE FLOW NETWORK,0.5601851851851852,"networks. L is the dimension of the latent embedding space in which the particles are aggregated and
228"
PARTICLE FLOW NETWORK,0.5625,"P is the number of particles in an observed jet. Y represents the relevant output space for the task at
229"
PARTICLE FLOW NETWORK,0.5648148148148148,"hand; since our task is classification, we consider Y = [0, 1].
230"
PARTICLE FLOW NETWORK,0.5671296296296297,"The input features {pk} represent the observed track particles within the jet. These features include:
231"
PARTICLE FLOW NETWORK,0.5694444444444444,"• The jet 3-momentum in detector coordinates, (p(J)
T , η(J), ϕ(J))
232"
PARTICLE FLOW NETWORK,0.5717592592592593,"• The 3-momentum of each particle track in relative detector coordinates, (pk
T , ∆ηk, ∆ϕk)
233"
PARTICLE FLOW NETWORK,0.5740740740740741,"• The track impact parameters of each particle (dk
0, zk
0)
234"
PARTICLE FLOW NETWORK,0.5763888888888888,"• The particle’s charge q and particle type {electron, muon, hadron}
235"
PARTICLE FLOW NETWORK,0.5787037037037037,"For each jet, we allow up to P = 30 particle tracks; inputs with fewer than 30 particles are padded
236"
PARTICLE FLOW NETWORK,0.5810185185185185,"with zeros. We also repeat the jet 3-momentum over the particle axis and concatenate with the rest
237"
PARTICLE FLOW NETWORK,0.5833333333333334,"of the per-particle features. The discrete particle type feature is embedded into 3 dimensions. After
238"
PARTICLE FLOW NETWORK,0.5856481481481481,"concatenating all features, the input to the PFN is of shape (∗, P, F) where F = 12 is the feature
239"
PARTICLE FLOW NETWORK,0.5879629629629629,"dimension.
240"
PARTICLE FLOW NETWORK,0.5902777777777778,"The subnetworks Φ and F are simple fully-connected neural networks. Φ consists of two hidden
241"
PARTICLE FLOW NETWORK,0.5925925925925926,"layers with 128 units each, and ReLU activation. The output layer of Φ has L units and no activation
242"
PARTICLE FLOW NETWORK,0.5949074074074074,"applied. The F network consists of three hidden layers with 128 units each and ReLU activations.
243"
PARTICLE FLOW NETWORK,0.5972222222222222,"The final output layer has two units with no activation, in order to train with a categorical cross
244"
PARTICLE FLOW NETWORK,0.5995370370370371,"entropy objective.
245"
VECTOR AND TENSOR PFN,0.6018518518518519,"4.2
Vector and Tensor PFN
246"
VECTOR AND TENSOR PFN,0.6041666666666666,"We now adapt the basic PFN architecture and promote it to what we term a Vector PFN (VPFN)
247"
VECTOR AND TENSOR PFN,0.6064814814814815,"or Tensor PFN (TPFN), according to the highest representation included. The overall architecture
248"
VECTOR AND TENSOR PFN,0.6087962962962963,"is of the same form as Eq. 9; we will simply modify the detailed implementation of the Φ and F
249"
VECTOR AND TENSOR PFN,0.6111111111111112,"sub-networks.
250"
VECTOR AND TENSOR PFN,0.6134259259259259,"The first change is that the input features now belong strictly to one of the three SO(3) representations:
251"
VECTOR AND TENSOR PFN,0.6157407407407407,"scalar, vector, or order-2 tensor:
252"
VECTOR AND TENSOR PFN,0.6180555555555556,"TPFN({(s, v, T)k}) = F P
X"
VECTOR AND TENSOR PFN,0.6203703703703703,"k=1
Φ(sk, vk, Tk) ! (10)"
VECTOR AND TENSOR PFN,0.6226851851851852,"In general, the number of features in any of the representation channels are independent. The features
253"
VECTOR AND TENSOR PFN,0.625,"for the TPFN experiments include:
254"
VECTOR AND TENSOR PFN,0.6273148148148148,"• The jet 3-momentum in Cartesian coordinates (p(J)
x , p(J)
y , p(J)
z
)
255"
VECTOR AND TENSOR PFN,0.6296296296296297,"• The 3-momentum of each particle track pk
256"
VECTOR AND TENSOR PFN,0.6319444444444444,"• The 3-position of the track’s point of closest approach to the origin ak
257"
VECTOR AND TENSOR PFN,0.6342592592592593,"• The charge and particle type of each track, as described in Sec. 4.1
258"
VECTOR AND TENSOR PFN,0.6365740740740741,"As before, we replicate the jet momentum across the particle index, and we embed the particle type
259"
VECTOR AND TENSOR PFN,0.6388888888888888,"into 3 dimensions, resulting in Fs = 4 scalar and Fv = 3 vector features. Since there are no observed
260"
VECTOR AND TENSOR PFN,0.6412037037037037,"tensor features for particle tracks, we synthesize an initial set of features to act as a starting point for
261"
VECTOR AND TENSOR PFN,0.6435185185185185,"the tensor operations. This is done by taking the outer product between all combinations of the three
262"
VECTOR AND TENSOR PFN,0.6458333333333334,"available vector features, resulting in Ft = 9 features.
263"
VECTOR AND TENSOR PFN,0.6481481481481481,"We now have Φ : RFs×3Fv×9Ft →RL×3L×9L, where Fs, Fv, Ft are the number of scalar, vector,
264"
VECTOR AND TENSOR PFN,0.6504629629629629,"and tensor inputs, respectively. A single layer of Φ is formed as shown in Fig. 2, by combining
265"
VECTOR AND TENSOR PFN,0.6527777777777778,"in sequence the Affine, SO(2)ˆj-Linear, Bilinear, and Nonlinear modules described in Sec. 3. The
266"
VECTOR AND TENSOR PFN,0.6550925925925926,"network consists of two hidden and one output layer. Each hidden Affine layer of the Φ network
267"
VECTOR AND TENSOR PFN,0.6574074074074074,"contains 2F = 128 features per representation, which results in 3F = 192 features after the Bilinear
268"
VECTOR AND TENSOR PFN,0.6597222222222222,"layer. The output of the Φ sub-network had L features, and there is no Bilinear or Nonlinear layers
269"
VECTOR AND TENSOR PFN,0.6620370370370371,"applied.
270"
VECTOR AND TENSOR PFN,0.6643518518518519,"The F network is built similarly to the Φ network, except that it has three hidden tensor layers. In
271"
VECTOR AND TENSOR PFN,0.6666666666666666,"lieu of an output layer, after the hidden tensor layers, the F network computes the square magnitude
272"
VECTOR AND TENSOR PFN,0.6689814814814815,"of each vector and tensor feature, in order to create a final set of 3 × 3F scalar invariant features. The
273"
VECTOR AND TENSOR PFN,0.6712962962962963,"scalar features are concatenated, passed through two more hidden layers with 128 units each and
274"
VECTOR AND TENSOR PFN,0.6736111111111112,"ReLU activations, and finally to an output layer with two units and no activation.
275"
EXPERIMENTS,0.6759259259259259,"5
Experiments
276"
EXPERIMENTS,0.6782407407407407,"To train b-tagging algorithms, we must use Monte Carlo simulations of particle collision events,
277"
EXPERIMENTS,0.6805555555555556,"as this is the only way to get sufficiently accurate ground truth labels. The optimization of these
278"
EXPERIMENTS,0.6828703703703703,"algorithms is commonly studied by experiments such as ATLAS and CMS, which use highly
279"
EXPERIMENTS,0.6851851851851852,"detailed proprietary detector simulation software, and only limited amounts data are available for use
280"
EXPERIMENTS,0.6875,"outside of the collaborations. [20] There are also some community-generated datasets available for
281"
EXPERIMENTS,0.6898148148148148,"benchmarking [7], however none of these publicly-available datasets contain the key information that
282"
EXPERIMENTS,0.6921296296296297,"our method leverages for its unique equivariant approach. Specifically, our model requires the full
283"
EXPERIMENTS,0.6944444444444444,"3-dimensional displacement vector of each track’s impact parameter, whereas the existing datasets
284"
EXPERIMENTS,0.6967592592592593,"only retain the transverse and longitudinal projections d0 and z0. Therefore, we have created a new
285"
EXPERIMENTS,0.6990740740740741,"dataset for b-jet tagging benchmarks, to be made publicly available. The data is generated using
286"
EXPERIMENTS,0.7013888888888888,"standard Monte Carlo tools from the HEP community.
287"
EXPERIMENTS,0.7037037037037037,"We begin by generating inclusive QCD and t¯t events for background and signal, respectively, using
288"
EXPERIMENTS,0.7060185185185185,"PYTHIA8[21]. PYTHIA handles sampling the matrix element of the hard processes at √s = 13TeV ,
289"
EXPERIMENTS,0.7083333333333334,Tensor Bilinears
EXPERIMENTS,0.7106481481481481,"TReLU
ReLU"
EXPERIMENTS,0.7129629629629629,SO(3) Affine
EXPERIMENTS,0.7152777777777778,SO(2) Linear VReLU
EXPERIMENTS,0.7175925925925926,Tensor Bilinears
EXPERIMENTS,0.7199074074074074,SO(3) Affine
EXPERIMENTS,0.7222222222222222,SO(2) Linear F
EXPERIMENTS,0.7245370370370371,Tensor Bilinears
EXPERIMENTS,0.7268518518518519,"TReLU
ReLU"
EXPERIMENTS,0.7291666666666666,SO(3) Affine
EXPERIMENTS,0.7314814814814815,SO(2) Linear VReLU
EXPERIMENTS,0.7337962962962963,NN Layer(s)
EXPERIMENTS,0.7361111111111112,Covariant Inputs
EXPERIMENTS,0.7384259259259259,Invariant Output
EXPERIMENTS,0.7407407407407407,Figure 2: A schematic diagram of the DeepSets-adapated Tensor PFN.
EXPERIMENTS,0.7430555555555556,"the parton shower, and hadronization. The hadron-level particles are then passed DELPHES[22], a
290"
EXPERIMENTS,0.7453703703703703,"fast parametric detector simulator which is configured to emulate the CMS[13] detector at the LHC.
291"
EXPERIMENTS,0.7476851851851852,"After detector simulation, jets are formed from reconstructed EFlow objects using the anti-kT [23, 24]
292"
EXPERIMENTS,0.75,"clustering algorithm with radius parameter R = 0.5. Only jets with pT > 90GeV are considered. For
293"
EXPERIMENTS,0.7523148148148148,"the signal sample, we additionally only consider jets which are truth-matched to a B-meson. Finally,
294"
EXPERIMENTS,0.7546296296296297,"the highest-pT jet is selected and the track and momentum features are saved to file.
295"
EXPERIMENTS,0.7569444444444444,"The training dataset consists of a balanced mixture of signal and background with a total of 1M jets.
296"
EXPERIMENTS,0.7592592592592593,"The validation and test datasets contain 100k signal jets each. Due to the high degree of background
297"
EXPERIMENTS,0.7615740740740741,"rejection observed, we must generate a substantially larger sample of background events for accurate
298"
EXPERIMENTS,0.7638888888888888,"test metrics, so the validation and test datasets contain 300k background jets each.
299"
RESULTS,0.7662037037037037,"5.1
Results
300"
RESULTS,0.7685185185185185,"To quantify the performance of our model, we consider the following metrics in our experiments.
301"
RESULTS,0.7708333333333334,"First, the loss function used in the training is sparse categorical cross entropy, which is also used
302"
RESULTS,0.7731481481481481,"in the validation dataset. We also consider the area under the ROC curve (AUC) as an overall
303"
RESULTS,0.7754629629629629,"measure of the performance in signal efficiency and background rejection. We also consider the
304"
RESULTS,0.7777777777777778,"background rejection at fixed efficiency points of 70% and 85%, labeled by R70 and R85, respectively.
305"
RESULTS,0.7800925925925926,"Background rejection is defined as the reciprocal of the false positive rate at the specified true positive
306"
RESULTS,0.7824074074074074,"rate.
307"
RESULTS,0.7847222222222222,"A summary of a variety of experiments is given in Table 1. The numbers in the table represent the
308"
RESULTS,0.7870370370370371,"median test score over 10 training runs, where the test score is always recorded at the epoch with the
309"
RESULTS,0.7893518518518519,"lowest validation loss. The quoted uncertainties for the rejections are the inter-quartile range.
310"
DISCUSSION,0.7916666666666666,"5.2
Discussion
311"
DISCUSSION,0.7939814814814815,"Table 1 shows that the family of models with only vector representations can indeed improve over
312"
DISCUSSION,0.7962962962962963,"the baseline, provided that we include at least the bilinear layer allowing the vector and scalar
313"
DISCUSSION,0.7986111111111112,"representations to mix. Moreover we find that adding the the SO(2) linear operations gives the vector
314"
DISCUSSION,0.8009259259259259,"network access to a minimal set of order-2 tensors, Rˆj, ˆjˆj
T , and I to enable it to exploit the axial
315"
DISCUSSION,0.8032407407407407,"symmetry of the data.
316"
DISCUSSION,0.8055555555555556,"Table 1: Test metrics for training experiments on progressive model architectures. R70 and R85
indicate the test rejection at 70% and 85% signal efficiency, respectively. The percentage relative
improvement in these metrics is also shown. Values shown are the median result over at least 10
training runs, per model type; errors quoted on rejection figures are the inter-quartile range.
Model
R70
Impr.(R70)
R85
Impr.(R85)
Baseline (PFN)
436 ± 15
–
112 ± 3
–
Vector PFN
1047 ± 85
140%
235 ± 12
110%
Tensor PFN
1176 ± 103
170%
259 ± 23
130%"
DISCUSSION,0.8078703703703703,"In the case of the tensor family of models, there is a less substantial improvement when adding the
317"
DISCUSSION,0.8101851851851852,"SO(2) linear layer. We expect that this is because the network with only bilinear operations is, at least
318"
DISCUSSION,0.8125,"in theory, able to learn the relevant operations on its own. Nonetheless, there is some improvement
319"
DISCUSSION,0.8148148148148148,"when adding this layer, so it would be reasonable to include both unless computational constraints
320"
DISCUSSION,0.8171296296296297,"are a concern.
321"
DISCUSSION,0.8194444444444444,"Finally, we note that neither family of models performs even as well as the baseline, when no bilinear
322"
DISCUSSION,0.8217592592592593,"operations are allowed. This clearly demonstrates the effectiveness of a network which can mix
323"
DISCUSSION,0.8240740740740741,"SO(3) representations.
324"
CONCLUSION,0.8263888888888888,"6
Conclusion
325"
CONCLUSION,0.8287037037037037,"In this work, we have introduced four modules of neural network architecture that allow for the
326"
CONCLUSION,0.8310185185185185,"preservation of SO(3) symmetry. The Tensor Particle Flow Network (TPFN) shows promising results
327"
CONCLUSION,0.8333333333333334,"in our dataset, yielding up to 2.7× improvement in background rejection, compared to the simple
328"
CONCLUSION,0.8356481481481481,"Particle Flow baseline model. We emphasize that the overall architecture of the PFN and TPFN are
329"
CONCLUSION,0.8379629629629629,"nearly identical; the improvement is entirely due to a drop-in replacement of standard neural layers
330"
CONCLUSION,0.8402777777777778,"with our covariant and bilinear layers. We also note that in our approach, the TPFN outputs a scalar
331"
CONCLUSION,0.8425925925925926,"which is rotationally invariant. However, it is also possible to obtain a covariant output by simply
332"
CONCLUSION,0.8449074074074074,"not apply the scalar pooling operations. This could be useful for many other applications, such as
333"
CONCLUSION,0.8472222222222222,"regression tasks, where covariant predictions are desired.
334"
CONCLUSION,0.8495370370370371,"Moreover, we show that second-order tensor representations are required in order to exploit a locally-
335"
CONCLUSION,0.8518518518518519,"restricted class of equivariance with respect to the axial rotations SO(2)ˆj. When computational
336"
CONCLUSION,0.8541666666666666,"constraints are a concern, it is possible to recover most of the performance of the Bilinear Tensor
337"
CONCLUSION,0.8564814814814815,"Network, by restricting it to a faster Bilinear Vector Network with the appropriate SO(2) equivariant
338"
CONCLUSION,0.8587962962962963,"linear layer.
339"
CONCLUSION,0.8611111111111112,"While the example application demonstrated here is of particular interest to the field of HEP, we
340"
CONCLUSION,0.8634259259259259,"expect our method can have great impact in other ares where vector-valued point cloud data is used.
341"
CONCLUSION,0.8657407407407407,"Finally, we note that while we demonstrated the modular elements of the TBN on a simple Deep Sets
342"
CONCLUSION,0.8680555555555556,"/ PFN type network, it should also be possible to use these modules for creating equivariant Graph
343"
CONCLUSION,0.8703703703703703,"and attention based networks.
344"
REFERENCES,0.8726851851851852,"References
345"
REFERENCES,0.875,"[1] Nathaniel Thomas, Tess E. Smidt, Steven M. Kearnes, Lusann Yang, Li Li, Kai Kohlhoff, and
346"
REFERENCES,0.8773148148148148,"Patrick F. Riley. Tensor field networks: Rotation- and translation-equivariant neural networks
347"
REFERENCES,0.8796296296296297,"for 3d point clouds. ArXiv, abs/1802.08219, 2018.
348"
REFERENCES,0.8819444444444444,"[2] Risi Kondor, Zhen Lin, and Shubhendu Trivedi. Clebsch-gordan nets: a fully fourier space
349"
REFERENCES,0.8842592592592593,"spherical convolutional neural network. In Neural Information Processing Systems, 2018.
350"
REFERENCES,0.8865740740740741,"[3] Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, and Taco Cohen. 3d steerable
351"
REFERENCES,0.8888888888888888,"cnns: Learning rotationally equivariant features in volumetric data. In Neural Information
352"
REFERENCES,0.8912037037037037,"Processing Systems, 2018.
353"
REFERENCES,0.8935185185185185,"[4] Brandon M. Anderson, Truong Son Hy, and Risi Kondor. Cormorant: Covariant molecular
354"
REFERENCES,0.8958333333333334,"neural networks. In Neural Information Processing Systems, 2019.
355"
REFERENCES,0.8981481481481481,"[5] Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabás Póczos, Ruslan Salakhutdinov,
356"
REFERENCES,0.9004629629629629,"and Alex Smola. Deep sets. ArXiv, abs/1703.06114, 2017.
357"
REFERENCES,0.9027777777777778,"[6] Anja Butter et al. The Machine Learning landscape of top taggers. SciPost Phys., 7:014, 2019.
358"
REFERENCES,0.9050925925925926,"[7] Huilin Qu, Congqiao Li, and Sitian Qian. Particle Transformer for Jet Tagging. 2 2022.
359"
REFERENCES,0.9074074074074074,"[8] Chase Shimmin. Particle Convolution for High Energy Physics. 7 2021.
360"
REFERENCES,0.9097222222222222,"[9] Chase Shimmin, Peter Sadowski, Pierre Baldi, Edison Weik, Daniel Whiteson, Edward Goul,
361"
REFERENCES,0.9120370370370371,"and Andreas Søgaard. Decorrelated Jet Substructure Tagging using Adversarial Neural Networks.
362"
REFERENCES,0.9143518518518519,"Phys. Rev. D, 96(7):074034, 2017.
363"
REFERENCES,0.9166666666666666,"[10] Daniel Guest, Julian Collado, Pierre Baldi, Shih-Chieh Hsu, Gregor Urban, and Daniel Whiteson.
364"
REFERENCES,0.9189814814814815,"Jet Flavor Classification in High-Energy Physics with Deep Neural Networks. Phys. Rev. D,
365"
REFERENCES,0.9212962962962963,"94(11):112002, 2016.
366"
REFERENCES,0.9236111111111112,"[11] Graph Neural Network Jet Flavour Tagging with the ATLAS Detector.
Technical
367"
REFERENCES,0.9259259259259259,"report, CERN, Geneva, 2022.
All figures including auxiliary figures are available
368"
REFERENCES,0.9282407407407407,"at https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PUBNOTES/ATL-PHYS-PUB-2022-
369"
REFERENCES,0.9305555555555556,"027.
370"
REFERENCES,0.9328703703703703,"[12] G. Aad et al. The ATLAS Experiment at the CERN Large Hadron Collider. JINST, 3:S08003,
371"
REFERENCES,0.9351851851851852,"2008.
372"
REFERENCES,0.9375,"[13] S. Chatrchyan et al. The CMS Experiment at the CERN LHC. JINST, 3:S08004, 2008.
373"
REFERENCES,0.9398148148148148,"[14] Georges Aad et al. Configuration and performance of the ATLAS b-jet triggers in Run 2. Eur.
374"
REFERENCES,0.9421296296296297,"Phys. J. C, 81(12):1087, 2021.
375"
REFERENCES,0.9444444444444444,"[15] Jeffrey Wood and John Shawe-Taylor. Representation theory and invariant neural networks.
376"
REFERENCES,0.9467592592592593,"Discret. Appl. Math., 69:33–60, 1996.
377"
REFERENCES,0.9490740740740741,"[16] Marc Finzi, Max Welling, and Andrew Gordon Wilson. A practical method for constructing
378"
REFERENCES,0.9513888888888888,"equivariant multilayer perceptrons for arbitrary matrix groups. ArXiv, abs/2104.09459, 2021.
379"
REFERENCES,0.9537037037037037,"[17] Vinod Nair and Geoffrey E. Hinton.
Rectified linear units improve restricted boltzmann
380"
REFERENCES,0.9560185185185185,"machines. In International Conference on Machine Learning, 2010.
381"
REFERENCES,0.9583333333333334,"[18] C. S. Jog. Introduction to Tensors, volume 1, page 1–136. Cambridge University Press, 3
382"
REFERENCES,0.9606481481481481,"edition, 2015.
383"
REFERENCES,0.9629629629629629,"[19] Patrick T. Komiske, Eric M. Metodiev, and Jesse Thaler. Energy flow networks: deep sets for
384"
REFERENCES,0.9652777777777778,"particle jets. Journal of High Energy Physics, 2019(1), jan 2019.
385"
REFERENCES,0.9675925925925926,"[20] Kimmo Kallonen. Sample with jet properties for jet-flavor and other jet-related ml studies,
386"
REFERENCES,0.9699074074074074,"2019.
387"
REFERENCES,0.9722222222222222,"[21] Christian Bierlich, Smita Chakraborty, Nishita Desai, Leif Gellersen, Ilkka J. Helenius, Philip
388"
REFERENCES,0.9745370370370371,"Ilten, Leif Lonnblad, Stephen Mrenna, Stefan Prestel, Christian T. Preuss, Torbjorn Sjostrand,
389"
REFERENCES,0.9768518518518519,"Peter Skands, Marius Utheim, and Rob Verheyen. A comprehensive guide to the physics and
390"
REFERENCES,0.9791666666666666,"usage of pythia 8.3. SciPost Physics Codebases, 2022.
391"
REFERENCES,0.9814814814814815,"[22] J. de Favereau, C. Delaere, Pavel Evgen’evich Demin, Andrea Giammanco, Vincent Lemaître,
392"
REFERENCES,0.9837962962962963,"Alexandre Mertens, Michele Selvaggi, and The Delphes 3 collaboration. Delphes 3: A modular
393"
REFERENCES,0.9861111111111112,"framework for fast-simulation of generic collider experiments. Journal of Physics: Conference
394"
REFERENCES,0.9884259259259259,"Series, 523:012033, 2013.
395"
REFERENCES,0.9907407407407407,"[23] Matteo Cacciari, Gavin P. Salam, and Gregory Soyez. FastJet User Manual. Eur. Phys. J. C,
396"
REFERENCES,0.9930555555555556,"72:1896, 2012.
397"
REFERENCES,0.9953703703703703,"[24] Matteo Cacciari and Gavin P. Salam. Dispelling the N 3 myth for the kt jet-finder. Phys. Lett.
398"
REFERENCES,0.9976851851851852,"B, 641:57–61, 2006.
399"
