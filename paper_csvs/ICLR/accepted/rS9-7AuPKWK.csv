Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.001088139281828074,"Generalization is one of the fundamental issues in machine learning. However,
traditional techniques like uniform convergence may be unable to explain gener-
alization under overparameterization (Nagarajan & Kolter, 2019). As alternative
approaches, techniques based on stability analyze the training dynamics and derive
algorithm-dependent generalization bounds. Unfortunately, the stability-based
bounds are still far from explaining the surprising generalization in deep learning
since neural networks usually suffer from unsatisfactory stability. This paper pro-
poses a novel decomposition framework to improve the stability-based bounds via
a more fine-grained analysis of the signal and noise, inspired by the observation
that neural networks converge relatively slowly when fitting noise (which indicates
better stability). Concretely, we decompose the excess risk dynamics and apply the
stability-based bound only on the noise component. The decomposition framework
performs well in both linear regimes (overparameterized linear regression) and
non-linear regimes (diagonal matrix recovery). Experiments on neural networks
verify the utility of the decomposition framework."
INTRODUCTION,0.002176278563656148,"1
INTRODUCTION"
INTRODUCTION,0.003264417845484222,"Generalization is one of the essential mysteries uncovered in modern machine learning (Neyshabur
et al., 2014; Zhang et al., 2016; Kawaguchi et al., 2017), measuring how the trained model performs
on unseen data. One of the most popular approaches to generalization is uniform convergence (Mohri
et al., 2018), which takes the supremum over parameter space to decouple the dependency between
the training set and the trained model. However, Nagarajan & Kolter (2019) pointed out that uniform
convergence itself might not be powerful enough to explain generalization, because the uniform
bound can still be vacuous under overparameterized linear regimes."
INTRODUCTION,0.004352557127312296,"One alternative solution beyond uniform convergence is to analyze the generalization dynamics,
which measures the generalization gap during the training dynamics. Stability-based bound is among
the most popular techniques in generalization dynamics analysis (Lei & Ying, 2020), which is derived
from algorithmic stability (Bousquet & Elisseeff, 2002). Fortunately, one can derive non-vacuous
bounds under general convex regimes using stability frameworks (Hardt et al., 2016). However,
stability is still far from explaining the remarkable generalization abilities of neural networks, mainly
due to two obstructions. Firstly, stability-based bound depends heavily on the gradient norm in
non-convex regimes (Li et al., 2019), which is typically large at the beginning phase in training neural
networks. Secondly, stability-based bound usually does not work well under general non-convex
regimes (Hardt et al., 2016; Charles & Papailiopoulos, 2018; Zhou et al., 2018b) but neural networks
are usually highly non-convex."
INTRODUCTION,0.00544069640914037,"The aforementioned two obstructions mainly stem from the coarse-grained analysis of the signal and
noise. As Zhang et al. (2016) argued, neural networks converge fast when fitting signal but converge"
INTRODUCTION,0.006528835690968444,∗Equal contribution.
INTRODUCTION,0.007616974972796518,Published as a conference paper at ICLR 2022
INTRODUCTION,0.008705114254624592,"̂θv
̂θ"
INTRODUCTION,0.009793253536452665,"θ(0) = θ(0) v
≈0 loss"
INTRODUCTION,0.01088139281828074,parameter (a)
INTRODUCTION,0.011969532100108813,parameter loss
INTRODUCTION,0.013057671381936888,parameter loss (b)
INTRODUCTION,0.014145810663764961,"Figure 1: (a) The gradient norm of standard training (training over noisy data) is larger than that
of variance training (training over pure noise) at initialization θ(0) = θ(0)
v
≈0. We denote the
minimizers of the training loss by ˆθ, ˆθv, respectively (where the y-axis is the training loss). (b) The
whole training loss landscape is highly non-convex while the trajectory of the variance training lies
in a convex region due to the slow convergence. We defer the details to Appendix B."
INTRODUCTION,0.015233949945593036,"relatively slowly when fitting noise1, indicating that the training dynamics over signal and noise
are significantly different. Consequently, on the one hand, the fast convergence of signal-related
training contributes to a large gradient norm at the beginning phase (see Figure 1a), resulting in
poor stability. On the other hand, the training on signal forces the trained parameter away from the
initialization, making the whole training path highly non-convex (see Figure 1b). The above two
phenomena inspire us to decompose the training dynamics into noise and signal components and only
apply the stability-based analysis over the noise component. To demonstrate that such decomposition
generally holds in practice, we conduct several experiments of neural networks on both synthetic and
real-world datasets (see Figure 2 for more details)."
INTRODUCTION,0.01632208922742111,"Based on the above discussion, we improve the stability-based analysis by proposing a decomposition
framework on excess risk dynamics2, where we handle the noise and signal components separately
via a bias-variance decomposition. In detail, we decompose the excess risk into variance excess
risk (VER) and bias excess risk (BER), where VER measures how the model fits noise and BER
measures how the model fits signal. Under the decomposition, we apply the stability-based techniques
to VER and apply uniform convergence to BER inspired by Negrea et al. (2020). The decomposition
framework accords with the theoretical and experimental evidence surprisingly well, providing that it
outperforms stability-based bounds in both linear (overparameterized linear regression) and non-linear
(diagonal matrix recovery) regimes."
INTRODUCTION,0.017410228509249184,We summarize our contributions as follows:
INTRODUCTION,0.018498367791077257,"• We propose a new framework aiming at improving the traditional stability-based bounds,
which is a novel approach to generalization dynamics analysis focusing on decomposing
the excess risk dynamics into variance component and bias component. Starting from the
overparameterized linear regression regimes, we show how to deploy the decomposition
framework in practice, and the proposed framework outperforms the stability-based bounds.
• We theoretically analyze the excess risk decomposition beyond linear regimes. As a case
study, we derive a generalization bound under diagonal matrix recovery regimes. To our
best knowledge, this is the first work to analyze the generalization performance of diagonal
matrix recovery.
• We conduct several experiments on both synthetic datasets and real-world datasets (MINIST,
CIFAR-10) to validate the utility of the decomposition framework, indicating that the
framework provides interesting insights for the generalization community."
INTRODUCTION,0.01958650707290533,"1In this paper, we refer the signal to the clean data without the output noise, and the noise to the output noise.
See Section 2 for the formal definitions.
2We decompose the excess risk, which is closely related to generalization, purely due to technical reasons.
The excess risk dynamics tracks the excess risk during the training process."
INTRODUCTION,0.020674646354733407,Published as a conference paper at ICLR 2022
INTRODUCTION,0.02176278563656148,"(a)
(b)"
INTRODUCTION,0.022850924918389554,"Figure 2: Experiments of neural networks on synthetic (linear ground truth, 3-layer NN, SGD) and
real-world (MNIST, 3-layer CNN, Adam) datasets. The trend of excess risk dynamics (blue) meets its
bias component (BER) at the beginning phase and meets its variance component (VER) afterwards,
indicating that ER can indeed be decomposed into VER and BER. See Appendix A for more details."
RELATED WORK,0.023939064200217627,"1.1
RELATED WORK"
RELATED WORK,0.025027203482045703,"Stability-based Generalization. The stability-based researches can be roughly split into two
branches. One branch is about how algorithmic stability leads to generalization (Feldman & Vondrak,
2018; 2019; Bousquet et al., 2020). Another branch focus on how to calculate the stability parameter
for specific problems, e.g., Hardt et al. (2016) prove a generalization bound scales linearly with
time in convex regimes. Furthermore, researchers try to apply stability techniques into more general
settings, e.g., non-smooth loss (Lei & Ying, 2020; Bassily et al., 2020), noisy gradient descent in
non-convex regimes (Mou et al., 2018; Li et al., 2019) and stochastic gradient descent in non-convex
regimes (Zhou et al., 2018b; Charles & Papailiopoulos, 2018; Zhang et al., 2021). In this paper, we
mainly focus on applying the decomposition framework to improve the stability-based bound."
RELATED WORK,0.026115342763873776,"Uniform Convergence is widely used in generalization analysis. For bounded losses, the gener-
alization gap is tightly bounded by its Rademacher Complexity (Koltchinskii & Panchenko, 2000;
Koltchinskii, 2001; Koltchinskii et al., 2006). Furthermore, we reach faster rates under realizable
assumption (Srebro et al., 2010). A line of work focuses on uniform convergence under neural
network regimes, which is usually related to the parameter norm (Bartlett et al., 2017; Wei & Ma,
2019). However, as Nagarajan & Kolter (2019) pointed out, uniform convergence may be unable to
explain generalization. Therefore, more techniques are explored to go beyond uniform convergence."
RELATED WORK,0.02720348204570185,"Other Approaches to Generalization. There are some other approaches to generalization, including
PAC-Bayes (Neyshabur et al., 2017a; Dziugaite & Roy, 2017; Neyshabur et al., 2017b; Dziugaite &
Roy, 2018; Zhou et al., 2018a; Yang et al., 2019), information-based bound (Russo & Zou, 2016;
Xu & Raginsky, 2017; Banerjee & Montúfar, 2021; Haghifam et al., 2020; Steinke & Zakynthinou,
2020), and compression-based bound (Arora et al., 2018; Allen-Zhu et al., 2018; Arora et al., 2019)."
RELATED WORK,0.028291621327529923,"Bias-Variance Decomposition. Bias-variance decomposition plays an important role in statistical
analysis (Lehmann & Casella, 2006; Casella & Berger, 2021; Geman et al., 1992). Generally, high
bias indicates that the model has poor predicting ability on average and high variance indicates that the
model performs unstably. Bias-variance decomposition is widely used in machine learning analysis,
e.g., adversarial training (Yu et al., 2021), double descent (Adlam & Pennington, 2020), uncertainty
(Hu et al., 2020). Additionally, (Nakkiran et al., 2020) propose a decomposition framework from an
online perspective relating the different optimization speeds on empirical and population loss. Oymak
et al. (2019) applied bias-variance decomposition on the Jacobian of neural networks to explain their
different performances on clean and noisy data. This paper considers a slightly different bias-variance
decomposition following the analysis of SGD (Dieuleveut et al., 2016; Jain et al., 2018; Zou et al.,
2021), focusing on the decomposition of the noisy output."
RELATED WORK,0.029379760609358,Published as a conference paper at ICLR 2022
RELATED WORK,0.030467899891186073,"Matrix Recovery. Earlier methods for solving matrix recovery problems rely on the convex relaxation
techniques for minimum norm solutions (Recht et al., 2010; Chandrasekaran et al., 2011). Recently,
a branch of works focuses on the matrix factorization techniques with simple local search methods. It
has been shown that there is no spurious local minima in the exact regime (Ge et al., 2016; 2017;
Zhang et al., 2019). In the overparameterized regimes, it was first conjectured by Gunasekar et al.
(2018) and then answered by Li et al. (2018) that gradient descent methods converge to the low-rank
solution efficiently. Later, Zhuo et al. (2021) extends the conclusion to the noisy settings."
PRELIMINARY,0.031556039173014146,"2
PRELIMINARY"
PRELIMINARY,0.03264417845484222,"In this section, we introduce necessary definitions, assumptions, and formally introduce previous
techniques in dealing with generalization."
PRELIMINARY,0.03373231773667029,"Data distribution. Let x ∈X ⊂Rp be the input and y ∈Y ⊂R be the output, where x, y are
generated from a joint distribution (x, y) ∼P. Define Px, Py, and Py|x as the corresponding
marginal and conditional distributions, respectively. Given n training samples D ≜{xi, yi}i∈[n]
generated from distribution P, we denote its empirical distribution by Pn. To simplify the notations,
we define X ∈Rn×p as the design matrix and Y ∈Rn as the response vector."
PRELIMINARY,0.03482045701849837,"Excess Risk. Given the loss function ℓ(θ; x, y) with parameter θ and sample (x, y), we de-
fine the population loss as L(θ; P) ≜E(x,y)∼P [ℓ(θ; x, y)] and its corresponding training loss
as L(θ; Pn) ≜1 n
P"
PRELIMINARY,0.035908596300326445,"i ℓ(θ; xi, yi). Let At denote the optimization algorithm which takes the dataset
D as an input and returns the trained parameter ˆθ(t) at time t, namely, At(D) = ˆθ(t). During
the analysis, we focus on the excess risk dynamics EL(ˆθ(t); P), which measures how the trained
parameter ˆθ(t) performs on the population loss:"
PRELIMINARY,0.036996735582154515,"EL(ˆθ(t); P) ≜L(ˆθ(t); P) −min
θ L(θ; P)."
PRELIMINARY,0.03808487486398259,"Although the minimizer may not be unique, we define L(θ∗; P) ≜minθ L(θ; P) where θ∗denotes
arbitrarily one of the minimizers. Additionally, bounding the generalization gap L(ˆθ(t); P) −
L(ˆθ(t); Pn) suffices to bound the excess risk under Empirical Risk Minimization (ERM) framework
by Equation equation 1. Therefore, we mainly discuss the excess risk following Bartlett et al. (2020)."
PRELIMINARY,0.03917301414581066,"EL(ˆθ(t); P)=
h
L(ˆθ(t); P)−L(ˆθ(t); Pn)
i"
PRELIMINARY,0.04026115342763874,"|
{z
}
generalization gap"
PRELIMINARY,0.041349292709466814,"+
h
L(ˆθ(t); Pn)−L(θ∗; Pn)
i"
PRELIMINARY,0.042437431991294884,"|
{z
}
≤0 under ERM"
PRELIMINARY,0.04352557127312296,"+
h
L(θ∗; Pn)−L(θ∗; P)
i"
PRELIMINARY,0.04461371055495103,"|
{z
}
≈0 by concentration inequalities . (1)"
PRELIMINARY,0.04570184983677911,"VER and BER. As discussed in Section 1, we aim to decompose the excess risk into the variance
excess risk (VER) and the bias excess risk (BER) defined in Definition 1. The decomposition focuses
on the noisy output regimes and we split the output y into the signal component E[y|x] and the noise
component y −E[y|x]. Informally, VER measures how the model performs on pure noise, and BER
measures how the model performs on clean data."
PRELIMINARY,0.046789989118607184,"Definition 1 (VER and BER) Given (x, y) ∼P, let (x, E[y|x]) ∼Pb denote the signal distri-
bution and (x, y −E[y|x]) ∼Pv denote the noise distribution. The variance excess risk (VER)
Ev
L(θ; P) and bias excess risk (BER) Eb
L(θ; P) are defined as:"
PRELIMINARY,0.04787812840043525,"Ev
L(θ; P) ≜EL(θ; Pv),
Eb
L(θ; P) ≜EL(θ; Pb)."
PRELIMINARY,0.04896626768226333,"To better illustrate VER and BER, we consider three surrogate training dynamics: Standard Training,
Variance Training, and Bias Training, corresponding to ER, VER, and BER, respectively.
Standard Training: Training process over the noisy data (X, Y ) from the initialization θ(0). We
denote the trained parameter at time t by ˆθ(t).
Variance Training: Training process over the pure noise (X, Y −E[Y |X]) from the initialization"
PRELIMINARY,0.05005440696409141,"θ(0)
v . We denote the trained parameter at time t by ˆθ(t)
v .
Bias Training: Training process over the clean data (X, E[Y |X]) from the initialization θ(0)
b . We"
PRELIMINARY,0.051142546245919476,Published as a conference paper at ICLR 2022
PRELIMINARY,0.05223068552774755,"denote the trained parameter at time t by ˆθ(t)
b .
When the context is clear, although the trained parameters ˆθ(t), ˆθ(t)
v , ˆθ(t)
b
are related to the corre-
sponding initialization and the algorithms, we omit the dependency. Besides, we denote θ∗, θ∗
v and
θ∗
b the optimal parameters which minimize the corresponding population loss L(θ; P), L(θ; Pv),
and L(θ; Pb), respectively."
PRELIMINARY,0.05331882480957562,"Techniques in generalization. We next introduce two techniques in generalization analysis includ-
ing stability-based techniques in Proposition 1 and uniform convergence in Proposition 2. These
techniques will be revisited in Section 3."
PRELIMINARY,0.0544069640914037,"Proposition 1 (Stability Bound from Feldman & Vondrak (2019)) Assume that algorithm At is
ϵ-uniformly-stable at time t, meaning that for any two dataset D and D′ with only one different data
point, we have
sup
(x,y)
EA [ℓ(At(D); x, y) −ℓ(At(D′); x, y)] ≤ϵ."
PRELIMINARY,0.055495103373231776,Then the following inequality holds3 with probability at least 1 −δ:
PRELIMINARY,0.056583242655059846,|L (At(D); P) −L (At(D); Pn)| = O 
PRELIMINARY,0.05767138193688792,ϵ log(n) log(n/δ) + r
PRELIMINARY,0.058759521218716,log(1/δ) n ! .
PRELIMINARY,0.05984766050054407,"Proposition 2 (Uniform Convergence from Wainwright (2019)) Uniform convergence decouples
the dependency between the trained parameter and the training set by taking supremum over a
parameter space that is independent of training data, namely"
PRELIMINARY,0.060935799782372145,"L(At(D); P) −L(At(D); Pn) ≤sup
θ∈B
[L(θ; P) −L(θ; Pn)] ."
PRELIMINARY,0.062023939064200215,where B is independent of dataset D and At(D) ∈B for any time t.
PRELIMINARY,0.06311207834602829,"3
WARM-UP: DECOMPOSITION UNDER LINEAR REGIMES"
PRELIMINARY,0.06420021762785637,"In this section, we consider the overparameterized linear regression with linear assumptions, where
the sample size is less than the data dimension, namely, n < p. We will show how the decomposition
framework works and the improvements compared to traditional stability-based bounds. Before diving
into the details, we emphasize the importance of studying overparameterized linear regression. As
the arguably simplest models, we expect a framework can at least work under such regimes. Besides,
recent works (e.g., Jacot et al. (2018)) show that neural networks converge to overparametrized
linear models (with respect to the parameters) as the width goes to infinity under some regularity
conditions. Therefore, studying overparameterized linear regression provides enormous intuition to
neural networks."
PRELIMINARY,0.06528835690968444,"Settings. When the context is clear, we reuse the notations in Section 2. Without loss of generality,
we assume that E[x] = 0. Besides, we assume a linear ground truth y = x⊤θ∗+ ϵ where
E[ϵ|x] = 0. Let Σx ≜E[xx⊤] denote the covariance matrix. Given ℓ2 loss ℓ(θ; x, y) = (y−x⊤θ)2,
we apply gradient descent (GD) with constant step size λ and initialization θ(0) = 0, namely,
ˆθ(t+1) = ˆθ(t) + λ n
P"
PRELIMINARY,0.06637649619151251,"i xi(yi −x⊤
i ˆθ(t)). We provide the main results of overparameterized linear
regression in Theorem 1 and then introduce how to apply the decomposition framework."
PRELIMINARY,0.06746463547334058,"Theorem 1 (Linear Regression Regimes) Under the overparameterized linear regression settings,
assume that w =
θ∗,⊤x
√"
PRELIMINARY,0.06855277475516866,"θ∗,⊤Σxθ∗is σ2
w-subgaussian. If ∥x∥≤1, |ϵ| ≤V , supt∈[T ] ∥ˆθ(t)
v ∥≤B are all"
PRELIMINARY,0.06964091403699674,"bounded, the following inequality holds with probability at least 1 −δ:"
PRELIMINARY,0.07072905331882481,EL(ˆθ(T ); P) = ˜O 
PRELIMINARY,0.07181719260065289,"max
n
1, θ∗,⊤Σxθ∗σ2
w, [V + B]2o r"
PRELIMINARY,0.07290533188248095,log(4/δ)
PRELIMINARY,0.07399347116430903,"n
+ ∥θ∗∥2"
PRELIMINARY,0.0750816104461371,"λT
+ Tλ[V + B]2 n ! ,"
PRELIMINARY,0.07616974972796518,where the probability is taken over the randomness of training data.
PRELIMINARY,0.07725788900979326,"3In the rest of the paper, we use O or ≲to omit the constant dependency and use ˜O to omit the log dependency
of n. For example, we write 2/n = O(1/n) or 2/n ≲1/n, log(n)/n = ˜O(1/n), and log2(n)/n = ˜O(1/n)."
PRELIMINARY,0.07834602829162132,Published as a conference paper at ICLR 2022
PRELIMINARY,0.0794341675734494,"By setting T = θ(√n) in Theorem 1, the upper bound is approximately ˜O( 1
√n), indicating that
the estimator at time T is consistent4. Below we show the comparison with some existing bounds,
including benign overfitting bound and traditional stability-based bound5."
PRELIMINARY,0.08052230685527748,"Comparison with benign overfitting. The bound in Bartlett et al. (2020) mainly focus on the min-
norm solution (as T →∞, the parameter trained in GD converges to the min-norm solution). Instead,
the bound in Theorem 1 does not require the min-norm solution assumption."
PRELIMINARY,0.08161044613710555,Comparison with stability-based bound. The stability-based bound (without applying the decompo-
PRELIMINARY,0.08269858541893363,"sition framework) is ˜O

max{1, [V + B′]2}
q"
PRELIMINARY,0.08378672470076169,log(2/δ)
N,0.08487486398258977,"2n
+ T λ"
N,0.08596300326441784,"n [V + B′]2

, where B′ = supt ∥ˆθ(t)∥"
N,0.08705114254624592,"denotes the bound of the trained parameter in standard training. As a comparison, the notation B in
Theorem 1 denotes the bound of the trained parameter in variance training. One major difference
between B and B′ is that: B is independent of ∥θ∗∥while B′ is closely related to ∥θ∗∥. Therefore,
with a large time T, the bound in Theorem 1 outperforms the stability-based bound when ∥θ∗∥
is large compared to V (namely, large signal-to-noise ratio)6. We refer to Appendix F.1 for more
discussion."
N,0.088139281828074,"Proof Sketch. We defer the proof details to Appendix C due to space limitations. Firstly, we provide
Lemma 1 to show that the excess risk can be decomposed into VER and BER."
N,0.08922742110990206,"Lemma 1 Under the overparameterized linear regression settings with initialization θ(0) = θ(0)
b
=
θ(0)
v
= 0, for any time T, the following decomposition inequality holds:"
N,0.09031556039173014,"EL(ˆθ(T ); P) ≤2Ev
L(ˆθ(T )
v
; P) + 2Eb
L(ˆθ(T )
b
; P)."
N,0.09140369967355821,"We next bound VER and BER separately in Lemma 2 and Lemma 3. When applying the stability-
based bound on VER, we first convert VER into a generalization gap (see Equation 1) and then bound
three terms individually."
N,0.09249183895538629,"Lemma 2 Under the overparameterized linear regression settings, assume that ∥x∥≤1, |ϵ| ≤V ,
supt ∥ˆθ(t)
v ∥≤B are all bounded. Consider the gradient descent algorithm with constant stepsize λ,
with probability at least 1 −δ:"
N,0.09357997823721437,"Ev
L

ˆθ(T )
v
; P

= O Tλ"
N,0.09466811751904244,"n [V + B]2 log(n) log(2n/δ) + max
n
1, [V + B]2o r"
N,0.0957562568008705,log(2/δ)
N,0.09684439608269858,"2n ! .
(2)"
N,0.09793253536452666,"In Lemma 3, we apply uniform convergence to bound BER. Although we can bound it by directly
calculating the excess risk, we still apply uniform convergence, because exact calculating is limited to
a specific problem while uniform convergence is much more general. To link the uniform convergence
and excess risk, we split the excess risk into two pieces inspired by Negrea et al. (2020). For the first
piece, which stands for the generalization gap, we bound it by uniform convergence. For the second
piece, which stands for the (surrogate) training loss, we derive a bound decreasing with time T."
N,0.09902067464635474,"Lemma 3 Under the overparameterized linear regression settings, assume that w =
θ∗,⊤x
√"
N,0.10010881392818281,"θ∗,⊤Σxθ∗is"
N,0.10119695321001088,"σ2
w-subgaussian, then with probability at least 1 −δ:"
N,0.10228509249183895,"Eb
L(ˆθ(T )
b
; P) = O"
N,0.10337323177366703,"θ∗,⊤Σxθ∗"
N,0.1044613710554951,"√n
σ2
w s"
N,0.10554951033732318,"log
2 δ"
N,0.10663764961915125,"
+
1
λ[2T + 1]∥θ∗∥2
! .
(3)"
N,0.10772578890097932,"Although we do not present it explicitly, the results in Lemma 3 are derived under uniform convergence
frameworks. Combining Lemma 1, Lemma 2 and Lemma 3 leads to Theorem 1.
□"
N,0.1088139281828074,"4Consistency means the upper bound converges to zero as the number of training samples goes to infinity.
5We remark that the assumptions in Theorem 1 can be relaxed. Firstly, assuming x is subGaussian suffices to
show that w is subGaussian. Secondly, assuming ϵ is subGaussian suffices to bound |ϵ| ≤V with a log(n) cost.
6A large time t can guarantee that the dominating term in Theorem 1 is T λ"
N,0.10990206746463548,"n [V + B′]2. We remark that with
a large signal-to-noise ratio, we have T λ"
N,0.11099020674646355,n [V + B′]2 ≥T λ
N,0.11207834602829161,n [V + B]2 ).
N,0.11316648531011969,Published as a conference paper at ICLR 2022
DECOMPOSITION UNDER GENERAL REGIMES,0.11425462459194777,"4
DECOMPOSITION UNDER GENERAL REGIMES"
DECOMPOSITION UNDER GENERAL REGIMES,0.11534276387377584,"This section mainly discusses how to decompose the excess risk into variance component (VER)
and bias component (BER) beyond linear regimes. Due to a fine-grained analysis on the signal and
noise, the decomposition framework improves the stability-based bounds under the general regimes.
We emphasize that the methods derived in this section are nevertheless the only way to reach the
decomposition goal and we leave more explorations for future work. To simplify the discussion, we
assume the minimizer θ∗of the excess risk exists and is unique. Before diving into the main theorem,
it is necessary to introduce the definition of local sharpness for the excess risk function, measuring
the smoothness of the excess risk function around the minimizer θ∗."
DECOMPOSITION UNDER GENERAL REGIMES,0.11643090315560392,"Definition 2 (Local Sharpness) For a given excess risk function EL(θ; P) with EL(θ∗; P) = 0, we
define s > 0 as the local sharpness factor when the following equation holds7:"
DECOMPOSITION UNDER GENERAL REGIMES,0.117519042437432,"0 <
lim
θ:∥θ−θ∗∥→0
EL(θ; P)
∥θ −θ∗∥s < ∞."
DECOMPOSITION UNDER GENERAL REGIMES,0.11860718171926006,"Assumption 1 (Uniform Bound) Assume that for excess risk function EL(θ; P) with local sharp-
ness s, given Px, for any Py|x and θ, the uniform bounds 0 < mu(Px) ≤Mu(Px) exist:"
DECOMPOSITION UNDER GENERAL REGIMES,0.11969532100108814,mu(Px) ≤EL(θ; P)
DECOMPOSITION UNDER GENERAL REGIMES,0.12078346028291621,∥θ −θ∗∥s ≤Mu(Px).
DECOMPOSITION UNDER GENERAL REGIMES,0.12187159956474429,"When the context is clear, we omit the dependency of Px and denote the bounds by mu and Mu."
DECOMPOSITION UNDER GENERAL REGIMES,0.12295973884657237,"Roughly speaking, the uniform bounds act as the maximal and minimal eigenvalues of the excess risk
function EL(θ; P). For example, under the overparameterized linear regression regimes (Section 3),
the uniform bounds are the maximum and minimum eigenvalues of the covariance matrix Σx."
DECOMPOSITION UNDER GENERAL REGIMES,0.12404787812840043,"Assumption 2 (Dynamics Decomposition Condition, DDC) We assume the trained parameters
ˆθ(T ) are (a, C, C′)-bounded at time T, namely:"
DECOMPOSITION UNDER GENERAL REGIMES,0.1251360174102285,"∥ˆθ(T ) −θ∗∥≤a(∥ˆθ(T )
v
−θ∗
v∥+ ∥ˆθ(T )
b
−θ∗
b∥) + C
√"
DECOMPOSITION UNDER GENERAL REGIMES,0.12622415669205658,"T
+ C′"
DECOMPOSITION UNDER GENERAL REGIMES,0.12731229597388466,"√n,
(4)"
DECOMPOSITION UNDER GENERAL REGIMES,0.12840043525571274,"where n denotes the size of training samples, T denotes the training time, and θ∗, θ∗
v and θ∗
b denote
the minimizers of the corresponding population loss L(θ; P), L(θ; Pv), and L(θ; Pb), respectively."
DECOMPOSITION UNDER GENERAL REGIMES,0.1294885745375408,"We emphasize that although we use
C
√"
DECOMPOSITION UNDER GENERAL REGIMES,0.1305767138193689,T + C′
DECOMPOSITION UNDER GENERAL REGIMES,0.13166485310119697,"√n in Assumption 2, it can be replaced with any o(1)
term which converges to zero when T, n go to infinity. Empirically, several experiments demonstrate
the generality of DDC and its variety (see Figure 3). From the theoretical perspective, we derive
that overparameterized linear regression is (1, 0, 0)-bounded in DDC, and diagonal matrix recovery
regimes satisfy DDC (see Section 4.1). We next show how to transfer DDC to the Decomposition
Theorem in Theorem 2."
DECOMPOSITION UNDER GENERAL REGIMES,0.13275299238302501,"Theorem 2 (Decomposition Theorem) Assume that the excess risk has a unique minimizer with
local sharpness factor s. Under Assumption 1 and Assumption 2, the following decomposition
inequality holds:"
DECOMPOSITION UNDER GENERAL REGIMES,0.1338411316648531,EL(ˆθ(T ); P) ≤[4a]s Mu mu
DECOMPOSITION UNDER GENERAL REGIMES,0.13492927094668117,"h
Ev
L(ˆθ(T )
v
; P) + Eb
L(ˆθ(T )
b
; P)
i
+ Mu"
DECOMPOSITION UNDER GENERAL REGIMES,0.13601741022850924," 4C
√ T"
DECOMPOSITION UNDER GENERAL REGIMES,0.13710554951033732,"s
+ Mu 4C′ √n"
DECOMPOSITION UNDER GENERAL REGIMES,0.1381936887921654,"s
.
(5)"
DECOMPOSITION UNDER GENERAL REGIMES,0.13928182807399347,"We defer the proofs to Appendix D due to limited space. In Theorem 2, Assumption 1 and As-
sumption 2 focus on the population loss and the training dynamics individually. We remark that our
proposed generalization bound is algorithm-dependent due to parameters (a, C, C′) in DDC."
DECOMPOSITION UNDER GENERAL REGIMES,0.14036996735582155,"By Theorem 2, we successfully decompose the excess risk dynamics into VER and BER. The
remaining question is how to bound VER and BER individually. As we will derive in Section 4.1
via a case study on diagonal matrix recovery, we bound VER by stability techniques and BER by
uniform convergence."
DECOMPOSITION UNDER GENERAL REGIMES,0.14145810663764963,7Here ∥· ∥refers to the ℓ2-norm.
DECOMPOSITION UNDER GENERAL REGIMES,0.1425462459194777,Published as a conference paper at ICLR 2022
DECOMPOSITION UNDER GENERAL REGIMES,0.14363438520130578,"(a) linear regression, n = 300
(b) matrix recovery, n = 200
(c) neural network, n = 500"
DECOMPOSITION UNDER GENERAL REGIMES,0.14472252448313383,"(d) linear regression, n = 800
(e) matrix recovery, n = 600
(f) neural network, n = 1500"
DECOMPOSITION UNDER GENERAL REGIMES,0.1458106637649619,"Figure 3: DDC holds in overparameterized linear regression, general matrix recovery, and neural networks.
For linear regression and neural networks, we set a = 1, C = C′ = 0 in DDC. For matrix recovery problems,
we set a = 1, C = 0, C′ = 8.5 in DDC. The upper bound (the right hand side in DDC, red line) is over the
standard norm (the left hand side in DDC, orange line), indicating that DDC holds in general. We defer the
experimental details to Appendix B."
DIAGONAL MATRIX RECOVERY,0.14689880304678998,"4.1
DIAGONAL MATRIX RECOVERY"
DIAGONAL MATRIX RECOVERY,0.14798694232861806,"From the previous discussion, we now conclude the basic procedure when applying the decomposition
framework under Theorem 2. Generally, there are three questions to be answered in a specific problem:
(a) Does the problem satisfy DDC? (b) How to bound VER using stability? (c) How to bound BER
using uniform convergence? To better illustrate how to solve the three questions individually, we
provide a case study on diagonal matrix recovery, a special and simplified case of a general low-rank
matrix recovery problem but still retains the key properties. The diagonal matrix recovery regime and
its variants are studied as a prototypical problem in Gissin et al. (2019); HaoChen et al. (2021)."
DIAGONAL MATRIX RECOVERY,0.14907508161044614,"Settings. Let X⋆= Diag{σ⋆
1, · · · , σ⋆
r, 0, · · · , 0} ∈Rd×d denote a rank-r (low rank) diagonal
matrix, where σ⋆
1 ≥· · · ≥σ⋆
r > 0. We define A ∈Rd×d as the measurement matrix which is
diagonal and y ∈Rd as the measurement vector. Assume the ground truth yi = Aiσ⋆
i + εi where
yi, Ai denotes their corresponding i-th element, ϵi denotes the noise, and σ⋆
i = 0 if r < i ≤d. Our
goal is to recover X⋆from dataset D = {A(i), y(i)}i∈[n] with n training samples."
DIAGONAL MATRIX RECOVERY,0.1501632208922742,"In the training process, we use the diagonal matrix U = Diag{u1, · · · , ud} to predict X⋆via
ˆX = UU ⊤. Given the loss function8 Ln(U) = 1"
DIAGONAL MATRIX RECOVERY,0.1512513601741023,"n
Pn
j=1
y(j) −A(j) ⊙UU ⊤2, we train the model
with Gradient Flow9 ˙Ut = −∇Ln(Ut). During the analysis, we assume that Ai is O(1)-uniformly
bounded with unit variance, and εi is ν2-subGaussian with uniform bounds |ε(j)
i | ≤V . We emphasize
that the training procedure of diagonal matrix recovery is fundamentally different from linear regimes
since Ln(U) is non-convex with respect to U."
DIAGONAL MATRIX RECOVERY,0.15233949945593037,"Theorem 3 (Decomposition Theorem in Diagonal Matrix Recovery) In the diagonal matrix re-
covery settings, if we set the initialization U0 = αI where α > 0 is the initialization scale, then for"
DIAGONAL MATRIX RECOVERY,0.15342763873775844,"8We use ⊙to represent the Hadamard product.
9We use gradient flow instead of gradient descent mainly due to technical simplicity."
DIAGONAL MATRIX RECOVERY,0.15451577801958652,Published as a conference paper at ICLR 2022
DIAGONAL MATRIX RECOVERY,0.15560391730141457,"any 0 < t < ∞, with probability at least 1 −δ, we have:"
DIAGONAL MATRIX RECOVERY,0.15669205658324264,"EL(Ut; P) ≲

∥X⋆∥2
F + dV 2 + dα4 r"
DIAGONAL MATRIX RECOVERY,0.15778019586507072,"log (d/δ) n
+ r
X j=1"
DIAGONAL MATRIX RECOVERY,0.1588683351468988,"σ4
j
σ2
j + α4eΩ(σjt) + α2d t"
DIAGONAL MATRIX RECOVERY,0.15995647442872687,+ dV 2(t + 1)
DIAGONAL MATRIX RECOVERY,0.16104461371055495,"n
log(n) log
2dn δ"
DIAGONAL MATRIX RECOVERY,0.16213275299238303,"
+ dα2 + log2
 1 α2"
DIAGONAL MATRIX RECOVERY,0.1632208922742111," rν2 log (r/δ) n
. (6)"
DIAGONAL MATRIX RECOVERY,0.16430903155603918,"By setting α = Θ

(d2n)−1"
DIAGONAL MATRIX RECOVERY,0.16539717083786726,"4

and t = Θ (log (dnσr) /σr) in Theorem 3, the upper bound is"
DIAGONAL MATRIX RECOVERY,0.16648531011969533,"approximately ˜O

dV 2+∥X⋆∥2
F
√n

, indicating that the estimator at time t is consistent."
DIAGONAL MATRIX RECOVERY,0.16757344940152338,Comparison with stability-based bound. The stability-based bound (without applying the decomposi-
DIAGONAL MATRIX RECOVERY,0.16866158868335146,"tion framework) is ˜O

dV 2+∥X⋆∥2
F
√n
+ (dV 2+∥X⋆∥⋆)(t+1)"
DIAGONAL MATRIX RECOVERY,0.16974972796517954,"n

. As a comparison, the bound in Theorem 3
outperforms the stability-based bound in the sense that we deduce the coefficient of the blowing-up
term t+1"
DIAGONAL MATRIX RECOVERY,0.1708378672470076,"n from dV 2 + ∥X⋆∥⋆to dV 2, which is a significant improvement with a large signal-to-noise
ratio under large time t. Besides, the bound in Theorem 3 captures the bias-variance tradeoff, meaning
that the excess risk curve falls first and then rises."
DIAGONAL MATRIX RECOVERY,0.1719260065288357,"Proof Sketch. We defer the proof details to Appendix E due to space limitations. Similar to Section 3,
the proof of Theorem 3 consists of the following three lemmas, corresponding to the DDC, BER, and
VER terms separately. We first prove that diagonal matrix recovery regimes satisfy DDCin Lemma 4."
DIAGONAL MATRIX RECOVERY,0.17301414581066377,"Lemma 4 Under the assumptions in Theorem 3, for any 0 ≤t < ∞, with probability at least 1 −δ,
we have"
DIAGONAL MATRIX RECOVERY,0.17410228509249184,"UtU ⊤
t −X⋆
F ≤
U b
t U b,⊤
t
−X⋆
F +
U v
t U v,⊤
t

F + O "
DIAGONAL MATRIX RECOVERY,0.17519042437431992,"log
 1 α2  r"
DIAGONAL MATRIX RECOVERY,0.176278563656148,rν2 log (r/δ) n ! . (7)
DIAGONAL MATRIX RECOVERY,0.17736670293797607,"Different from the overparameterized linear regression regimes, Lemma 4 suffers from a O

1
√n
"
DIAGONAL MATRIX RECOVERY,0.17845484221980412,"factor due to the non-linearity. This phenomenon can be verified empirically in Figure 3b and
Figure 3e. We next apply stability techniques and uniform convergence to tackle VER and BER in
Lemma 5 and Lemma 6, respectively."
DIAGONAL MATRIX RECOVERY,0.1795429815016322,"Lemma 5 For VER, under the assumptions in Theorem 3, with probability at least 1 −δ, we have"
DIAGONAL MATRIX RECOVERY,0.18063112078346028,"Ev
L(Ut; P) ≲dV 2(t + 1)"
DIAGONAL MATRIX RECOVERY,0.18171926006528835,"n
log(n) log
2dn δ"
DIAGONAL MATRIX RECOVERY,0.18280739934711643,"
+ dα2 + dV 2
r"
DIAGONAL MATRIX RECOVERY,0.1838955386289445,log (2d/δ)
DIAGONAL MATRIX RECOVERY,0.18498367791077258,"n
.
(8)"
DIAGONAL MATRIX RECOVERY,0.18607181719260066,"Lemma 6 For BER, under the assumptions in Theorem 3, with probability at least 1 −δ, we have"
DIAGONAL MATRIX RECOVERY,0.18715995647442873,"Eb
L(Ut; P) ≲

∥X⋆∥2
F + dα4 r"
DIAGONAL MATRIX RECOVERY,0.1882480957562568,"log (d/δ) n
+ r
X j=1"
DIAGONAL MATRIX RECOVERY,0.1893362350380849,"σ4
j
σ2
j + α4eΩ(σjt) + α2d"
DIAGONAL MATRIX RECOVERY,0.19042437431991294,"t .
(9)"
DIAGONAL MATRIX RECOVERY,0.191512513601741,"Combining the above lemmas leads to Theorem 3.
□"
DIAGONAL MATRIX RECOVERY,0.1926006528835691,"Remark: Directly applying Theorem 2 under overparameterized linear regression regimes costs a
loss on condition number. The cost comes from the DDC condition where we transform the function
space (excess risk function) to the parameter space (the distance between the trained parameter and
the minimizer). We emphasize that the field of decomposition framework is indeed much larger than
Theorem 2, and there are other different approaches beyond Theorem 2. For example, informally, by
introducing a pre-conditioner matrix A, changing DDC from the form ∥ˆθ −θ⋆∥to ∥Aˆθ −Aθ⋆∥and
setting A = Σ1/2
x
, one can avoid the cost of the condition number. We leave the technical discussion
for future work."
DIAGONAL MATRIX RECOVERY,0.19368879216539717,Published as a conference paper at ICLR 2022
DIAGONAL MATRIX RECOVERY,0.19477693144722524,ACKNOWLEDGMENTS
DIAGONAL MATRIX RECOVERY,0.19586507072905332,"This work has been partially supported by National Key R&D Program of China (2019AAA0105200)
and 2030 innovation megaprojects of china (programme on new generation artificial intelligence)
Grant No.2021AAA0150000. The authors would like to thank Ruiqi Gao for his insightful sugges-
tions. We also thank Tianle Cai, Haowei He, Kaixuan Huang, and, Jingzhao Zhang for their helpful
discussions."
REFERENCES,0.1969532100108814,REFERENCES
REFERENCES,0.19804134929270947,"Ben Adlam and Jeffrey Pennington. Understanding double descent requires a fine-grained bias-
variance decomposition. arXiv preprint arXiv:2011.03321, 2020."
REFERENCES,0.19912948857453755,"Zeyuan Allen-Zhu, Yuanzhi Li, and Yingyu Liang. Learning and generalization in overparameterized
neural networks, going beyond two layers. arXiv preprint arXiv:1811.04918, 2018."
REFERENCES,0.20021762785636563,"Sanjeev Arora, Rong Ge, Behnam Neyshabur, and Yi Zhang. Stronger generalization bounds for deep
nets via a compression approach. In International Conference on Machine Learning, pp. 254–263.
PMLR, 2018."
REFERENCES,0.20130576713819368,"Sanjeev Arora, Simon Du, Wei Hu, Zhiyuan Li, and Ruosong Wang. Fine-grained analysis of
optimization and generalization for overparameterized two-layer neural networks. In International
Conference on Machine Learning, pp. 322–332. PMLR, 2019."
REFERENCES,0.20239390642002175,"Pradeep Kr. Banerjee and Guido Montúfar. Information complexity and generalization bounds, 2021."
REFERENCES,0.20348204570184983,"Peter Bartlett, Dylan J Foster, and Matus Telgarsky. Spectrally-normalized margin bounds for neural
networks. arXiv preprint arXiv:1706.08498, 2017."
REFERENCES,0.2045701849836779,"Peter L Bartlett, Philip M Long, Gábor Lugosi, and Alexander Tsigler. Benign overfitting in linear
regression. Proceedings of the National Academy of Sciences, 117(48):30063–30070, 2020."
REFERENCES,0.20565832426550598,"Raef Bassily, Vitaly Feldman, Cristóbal Guzmán, and Kunal Talwar. Stability of stochastic gradient
descent on nonsmooth convex losses. arXiv preprint arXiv:2006.06914, 2020."
REFERENCES,0.20674646354733406,"Olivier Bousquet and André Elisseeff. Stability and generalization. The Journal of Machine Learning
Research, 2:499–526, 2002."
REFERENCES,0.20783460282916214,"Olivier Bousquet, Yegor Klochkov, and Nikita Zhivotovskiy. Sharper bounds for uniformly stable
algorithms. In Conference on Learning Theory, pp. 610–626. PMLR, 2020."
REFERENCES,0.2089227421109902,"George Casella and Roger L Berger. Statistical inference. Cengage Learning, 2021."
REFERENCES,0.2100108813928183,"Venkat Chandrasekaran, Sujay Sanghavi, Pablo A Parrilo, and Alan S Willsky. Rank-sparsity
incoherence for matrix decomposition. SIAM Journal on Optimization, 21(2):572–596, 2011."
REFERENCES,0.21109902067464636,"Zachary Charles and Dimitris Papailiopoulos. Stability and generalization of learning algorithms
that converge to global optima. In International Conference on Machine Learning, pp. 745–754.
PMLR, 2018."
REFERENCES,0.21218715995647444,"Aymeric Dieuleveut, Francis Bach, et al. Nonparametric stochastic approximation with large step-
sizes. Annals of Statistics, 44(4):1363–1399, 2016."
REFERENCES,0.2132752992383025,"Gintare Karolina Dziugaite and Daniel Roy. Entropy-sgd optimizes the prior of a pac-bayes bound:
Generalization properties of entropy-sgd and data-dependent priors. In International Conference
on Machine Learning, pp. 1377–1386. PMLR, 2018."
REFERENCES,0.21436343852013057,"Gintare Karolina Dziugaite and Daniel M Roy. Computing nonvacuous generalization bounds for
deep (stochastic) neural networks with many more parameters than training data. arXiv preprint
arXiv:1703.11008, 2017."
REFERENCES,0.21545157780195864,"Vitaly Feldman and Jan Vondrak. Generalization bounds for uniformly stable algorithms. arXiv
preprint arXiv:1812.09859, 2018."
REFERENCES,0.21653971708378672,Published as a conference paper at ICLR 2022
REFERENCES,0.2176278563656148,"Vitaly Feldman and Jan Vondrak. High probability generalization bounds for uniformly stable
algorithms with nearly optimal rate. In Conference on Learning Theory, pp. 1270–1279. PMLR,
2019."
REFERENCES,0.21871599564744287,"Rong Ge, Jason D Lee, and Tengyu Ma. Matrix completion has no spurious local minimum. arXiv
preprint arXiv:1605.07272, 2016."
REFERENCES,0.21980413492927095,"Rong Ge, Chi Jin, and Yi Zheng. No spurious local minima in nonconvex low rank problems: A
unified geometric analysis. In International Conference on Machine Learning, pp. 1233–1242.
PMLR, 2017."
REFERENCES,0.22089227421109903,"Stuart Geman, Elie Bienenstock, and René Doursat. Neural networks and the bias/variance dilemma.
Neural computation, 4(1):1–58, 1992."
REFERENCES,0.2219804134929271,"Daniel Gissin, Shai Shalev-Shwartz, and Amit Daniely. The implicit bias of depth: How incremental
learning drives generalization. arXiv preprint arXiv:1909.12051, 2019."
REFERENCES,0.22306855277475518,"Suriya Gunasekar, Blake Woodworth, Srinadh Bhojanapalli, Behnam Neyshabur, and Nathan Srebro.
Implicit regularization in matrix factorization. In 2018 Information Theory and Applications
Workshop (ITA), pp. 1–10. IEEE, 2018."
REFERENCES,0.22415669205658323,"Mahdi Haghifam, Jeffrey Negrea, Ashish Khisti, Daniel M Roy, and Gintare Karolina Dziugaite.
Sharpened generalization bounds based on conditional mutual information and an application to
noisy, iterative algorithms. arXiv preprint arXiv:2004.12983, 2020."
REFERENCES,0.2252448313384113,"Jeff Z HaoChen, Colin Wei, Jason Lee, and Tengyu Ma. Shape matters: Understanding the implicit
bias of the noise covariance. In Conference on Learning Theory, pp. 2315–2357. PMLR, 2021."
REFERENCES,0.22633297062023938,"Moritz Hardt, Ben Recht, and Yoram Singer. Train faster, generalize better: Stability of stochastic
gradient descent. In International Conference on Machine Learning, pp. 1225–1234. PMLR, 2016."
REFERENCES,0.22742110990206746,"Shi Hu, Nicola Pezzotti, Dimitrios Mavroeidis, and Max Welling. Simple and accurate uncertainty
quantification from bias-variance decomposition. arXiv preprint arXiv:2002.05582, 2020."
REFERENCES,0.22850924918389554,"Arthur Jacot, Franck Gabriel, and Clément Hongler. Neural tangent kernel: Convergence and
generalization in neural networks. arXiv preprint arXiv:1806.07572, 2018."
REFERENCES,0.2295973884657236,"Prateek Jain, Sham Kakade, Rahul Kidambi, Praneeth Netrapalli, and Aaron Sidford. Parallelizing
stochastic gradient descent for least squares regression: mini-batching, averaging, and model
misspecification. Journal of Machine Learning Research, 18, 2018."
REFERENCES,0.2306855277475517,"Kenji Kawaguchi, Leslie Pack Kaelbling, and Yoshua Bengio. Generalization in deep learning. arXiv
preprint arXiv:1710.05468, 2017."
REFERENCES,0.23177366702937977,"Vladimir Koltchinskii. Rademacher penalties and structural risk minimization. IEEE Transactions
on Information Theory, 47(5):1902–1914, 2001."
REFERENCES,0.23286180631120784,"Vladimir Koltchinskii and Dmitriy Panchenko. Rademacher processes and bounding the risk of
function learning. In High dimensional probability II, pp. 443–457. Springer, 2000."
REFERENCES,0.23394994559303592,"Vladimir Koltchinskii et al. Local rademacher complexities and oracle inequalities in risk minimiza-
tion. Annals of Statistics, 34(6):2593–2656, 2006."
REFERENCES,0.235038084874864,"Erich L Lehmann and George Casella. Theory of point estimation. Springer Science & Business
Media, 2006."
REFERENCES,0.23612622415669204,"Yunwen Lei and Yiming Ying. Fine-grained analysis of stability and generalization for stochastic
gradient descent. In International Conference on Machine Learning, pp. 5809–5819. PMLR, 2020."
REFERENCES,0.23721436343852012,"Jian Li, Xuanyuan Luo, and Mingda Qiao. On generalization error bounds of noisy gradient methods
for non-convex learning. arXiv preprint arXiv:1902.00621, 2019."
REFERENCES,0.2383025027203482,"Yuanzhi Li, Tengyu Ma, and Hongyang Zhang. Algorithmic regularization in over-parameterized
matrix sensing and neural networks with quadratic activations. In Conference On Learning Theory,
pp. 2–47. PMLR, 2018."
REFERENCES,0.23939064200217627,Published as a conference paper at ICLR 2022
REFERENCES,0.24047878128400435,"Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of machine learning. MIT
press, 2018."
REFERENCES,0.24156692056583243,"Wenlong Mou, Liwei Wang, Xiyu Zhai, and Kai Zheng. Generalization bounds of sgld for non-convex
learning: Two theoretical viewpoints. In Conference on Learning Theory, pp. 605–638. PMLR,
2018."
REFERENCES,0.2426550598476605,"Vaishnavh Nagarajan and J Zico Kolter. Uniform convergence may be unable to explain generalization
in deep learning. arXiv preprint arXiv:1902.04742, 2019."
REFERENCES,0.24374319912948858,"Preetum Nakkiran, Behnam Neyshabur, and Hanie Sedghi. The deep bootstrap: Good online learners
are good offline generalizers. arXiv e-prints, pp. arXiv–2010, 2020."
REFERENCES,0.24483133841131666,"Jeffrey Negrea, Gintare Karolina Dziugaite, and Daniel Roy. In defense of uniform convergence:
Generalization via derandomization with an application to interpolating predictors. In International
Conference on Machine Learning, pp. 7263–7272. PMLR, 2020."
REFERENCES,0.24591947769314473,"Behnam Neyshabur, Ryota Tomioka, and Nathan Srebro. In search of the real inductive bias: On the
role of implicit regularization in deep learning. arXiv preprint arXiv:1412.6614, 2014."
REFERENCES,0.2470076169749728,"Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nathan Srebro. Exploring general-
ization in deep learning. arXiv preprint arXiv:1706.08947, 2017a."
REFERENCES,0.24809575625680086,"Behnam Neyshabur, Srinadh Bhojanapalli, and Nathan Srebro. A pac-bayesian approach to spectrally-
normalized margin bounds for neural networks. arXiv preprint arXiv:1707.09564, 2017b."
REFERENCES,0.24918389553862894,"Samet Oymak, Zalan Fabian, Mingchen Li, and Mahdi Soltanolkotabi. Generalization guaran-
tees for neural networks via harnessing the low-rank structure of the jacobian. arXiv preprint
arXiv:1906.05392, 2019."
REFERENCES,0.250272034820457,"Benjamin Recht, Maryam Fazel, and Pablo A Parrilo. Guaranteed minimum-rank solutions of linear
matrix equations via nuclear norm minimization. SIAM review, 52(3):471–501, 2010."
REFERENCES,0.2513601741022851,"Daniel Russo and James Zou. Controlling bias in adaptive data analysis using information theory. In
Artificial Intelligence and Statistics, pp. 1232–1240. PMLR, 2016."
REFERENCES,0.25244831338411317,"Nathan Srebro, Karthik Sridharan, and Ambuj Tewari. Optimistic rates for learning with a smooth
loss. arXiv preprint arXiv:1009.3896, 2010."
REFERENCES,0.2535364526659412,"Thomas Steinke and Lydia Zakynthinou. Reasoning about generalization via conditional mutual
information. In Conference on Learning Theory, pp. 3437–3452. PMLR, 2020."
REFERENCES,0.2546245919477693,"Martin J Wainwright. High-dimensional statistics: A non-asymptotic viewpoint, volume 48. Cam-
bridge University Press, 2019."
REFERENCES,0.25571273122959737,"Colin Wei and Tengyu Ma. Improved sample complexities for deep networks and robust classification
via an all-layer margin. arXiv preprint arXiv:1910.04284, 2019."
REFERENCES,0.25680087051142547,"Aolin Xu and Maxim Raginsky. Information-theoretic analysis of generalization capability of learning
algorithms. arXiv preprint arXiv:1705.07809, 2017."
REFERENCES,0.2578890097932535,"Jun Yang, Shengyang Sun, and Daniel M Roy. Fast-rate pac-bayes generalization bounds via shifted
rademacher processes. In NeurIPS, pp. 10802–10812, 2019."
REFERENCES,0.2589771490750816,"Yaodong Yu, Zitong Yang, Edgar Dobriban, Jacob Steinhardt, and Yi Ma. Understanding generaliza-
tion in adversarial training via the bias-variance decomposition. arXiv preprint arXiv:2103.09947,
2021."
REFERENCES,0.2600652883569097,"Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530, 2016."
REFERENCES,0.2611534276387378,"Richard Y Zhang, Somayeh Sojoudi, and Javad Lavaei. Sharp restricted isometry bounds for the
inexistence of spurious local minima in nonconvex matrix recovery. Journal of Machine Learning
Research, 20(114):1–34, 2019."
REFERENCES,0.2622415669205658,Published as a conference paper at ICLR 2022
REFERENCES,0.26332970620239393,"Yikai Zhang, Wenjia Zhang, Sammy Bald, Vamsi Pingali, Chao Chen, and Mayank Goswami.
Stability of sgd: Tightness analysis and improved bounds. arXiv preprint arXiv:2102.05274, 2021."
REFERENCES,0.264417845484222,"Wenda Zhou, Victor Veitch, Morgane Austern, Ryan P Adams, and Peter Orbanz. Non-vacuous
generalization bounds at the imagenet scale: a pac-bayesian compression approach. arXiv preprint
arXiv:1804.05862, 2018a."
REFERENCES,0.26550598476605003,"Yi Zhou, Yingbin Liang, and Huishuai Zhang. Generalization error bounds with probabilistic
guarantee for sgd in nonconvex optimization. arXiv preprint arXiv:1802.06903, 2018b."
REFERENCES,0.26659412404787813,"Jiacheng Zhuo, Jeongyeol Kwon, Nhat Ho, and Constantine Caramanis. On the computational and
statistical complexity of over-parameterized matrix sensing. arXiv preprint arXiv:2102.02756,
2021."
REFERENCES,0.2676822633297062,"Difan Zou, Jingfeng Wu, Vladimir Braverman, Quanquan Gu, and Sham M Kakade. Benign
overfitting of constant-stepsize sgd for linear regression. arXiv preprint arXiv:2103.12692, 2021."
REFERENCES,0.2687704026115343,Published as a conference paper at ICLR 2022
REFERENCES,0.26985854189336234,Supplementary Materials
REFERENCES,0.27094668117519044,"In this section, we first provide additional numerical experiment in Section A and figure illustration in
Section B. We then give all the omitted proofs of lemmas and theorems in Section C, Section D, and
Section E. We finally provide some further discussions, including why we apply stability on VER,
the motivation behind DDC and a relaxed version of DDC."
REFERENCES,0.2720348204570185,"A
NUMERICAL EXPERIMENT"
REFERENCES,0.2731229597388466,"In this section we provide additional numerical experiments on neural network to verify that our
theory is satisfied for general neural network architectures and optimization algorithms."
REFERENCES,0.27421109902067464,"(a) Depth, L = 2
(b) Depth, L = 3
(c) Depth, L = 4"
REFERENCES,0.27529923830250275,"(d) Width, m = 64
(e) Width, m = 256
(f) Width, m = 512"
REFERENCES,0.2763873775843308,"(g) SGD
(h) Adam
(i) Rprop"
REFERENCES,0.27747551686615884,Figure 4: Numerical results in Section A.1.
REFERENCES,0.27856365614798695,"A.1
SYNTHETIC EXPERIMENT"
REFERENCES,0.279651795429815,"In this section, our goal is to recover a sparse linear function f ⋆(x) = ⟨θ⋆, x⟩(x ∈R30) with fully
connected ReLU network. For each setting, we run 5 independent trials and report their average
performances (the solid line) and the corresponding standard deviations (the error bar)."
REFERENCES,0.2807399347116431,"Effects of depth:
We first explore the effect of depth and width for the excess risk decomposition
property. In this experiment, we fix the width of each layer to be 64, and use SGD as the optimizer
with Gaussian initialization (N(0, σ2) where σ = 1×10−3) and stepsize η = 1×10−2. For the dash
line, we plot a(BER + VER) to verify the performance of our risk decomposition framework. Here a
can be regarded as a measure of the success of our theory. Ideally a should be a small constant so that"
REFERENCES,0.28182807399347115,Published as a conference paper at ICLR 2022
REFERENCES,0.28291621327529926,"our bound is non-vacuous. Specific to this experiment, for Figure 4a, 4b, 4c, we set a = 1.3, 2.0, 2.3,
respectively. Overall, these results are well-predicted by our theory. Moreover, it is remarkable to
notice that this constant becomes large once increasing the depth. This mainly contributes to the fact
that deeper neural network has higher non-linearity."
REFERENCES,0.2840043525571273,"Effects of width:
In this experiment, we explore the effect of width for 2-layer ReLU network with
SGD optimizer (the initialization and the stepsize are the same as above). For Figure 4d, 4e, 4e,
we set a = 1.3, 1.0, 1.0, respectively. As can be seen, the wider the neural network, the better our
risk decomposition works. We comment that this behavior also comes to the level of non-linearity. It
is now well-known that when the width tends to infinity, the neural network converges to a linear
function (e.g. (Jacot et al., 2018))."
REFERENCES,0.2850924918389554,"Effects of optimizer:
In this experiment, we try three different optimizers: SGD (the same
hyperparameters as before), Adam (stepsize η = 0.002, (β1, β2) = (0.9, 0.999), ϵ = 1e −08, no
weight decay), Rprop (learning rate η = 5 × 10−4, (η1, η2) = (0.5, 1.2), stepsizes (1 × 10−6, 50)).
For Figure 4g, 4h, 4i, we set a = 1.3, 1.2, 1.1. It can be seen that our risk decomposition framework
is robust to different optimization algorithms, demonstrating its generality and potential to extend to
general optimization problems."
REFERENCES,0.28618063112078346,"A.2
CIFAR-10"
REFERENCES,0.28726877040261156,"In this section we deliver additional experiment in CIFAR-10 dataset. In this experiment, we use
ResNet-18 and choose Adam as the optimizer. We regard that optimizing over the original dataset
as the bias training (in the sense that all the label is noiseless, referring to the bias part). As for the
variance training, we set the ground truth to be the uniform logit v = [0.1, · · · , 0.1]⊤(here we use
one-hot coding and choose the categorical cross entropy loss). As for the labels in the training dataset,
we generate it uniformly from {e1, · · · , e10}, where ei is the standard basis in R10. Under such data
generating model, its Bayes risk is provided by −10 × 0.1 × log(0.1) ≈2.3026 for categorical cross
entropy loss. For the standard training, we generate the training label as follows: y = (1−p)y⋆+pej.
Here p ∈[0, 1] is the corruption probability, y⋆is the true label and j is uniformly sampled from
{1, · · · , 10}. In this experiment, we set the corruption probability to be 0.4. The numerical result is
provided in Figure 5 . Different from the performance on MINIST, here the variance training actually
converges to the ground truth. We conjecture that this is due to the structure of ResNet, resulting to
some kind of implicit regularization towards the training process.10"
REFERENCES,0.2883569096844396,"B
FIGURE ILLUSTRATION"
REFERENCES,0.28944504896626766,"B.1
FIGURE 1A"
REFERENCES,0.29053318824809576,"Figure 1a conveys an important message that variance training has a much smaller gradient norm at the
beginning compared to standard training. This mainly comes from the difference in their landscapes.
Since there is no signal term in the variance learning, we can regard the landscape corresponding
to the variance training as just a translation transformation of the original landscape (Figure 1a, the
blue line is just a translation transformation of the green line). Based on this difference, they pursue
different optima. We denote ˆθv, ˆθ the empirical loss minimizer, respectively. Due to concentration,
we have ˆθv ≈0, and ˆθ ≈θ⋆. Note that we use a near-zero initialization θ(0) = θ(0)
v
≈0, we
immediately have that θ(0)
v
≈ˆθv, indicating that the gradient norm is small. On the other hand, since
θ(0) is far away from the optimum, its initial gradient norm can be very large."
REFERENCES,0.2916213275299238,"To better illustrate this principle, we use linear regression to provide a simple example. For the
standard training, the empirical loss is Ln(θ; P) = 1"
REFERENCES,0.2927094668117519,"n
Pn
i=1 (⟨θ, Xi⟩−⟨θ⋆, Xi⟩−εi)2. Hence, we"
REFERENCES,0.29379760609357997,"10We do observe that for certain learning rate regimes, the algorithm will overfit the training dataset for
variance training, leading to a large VER (∼10)."
REFERENCES,0.29488574537540807,Published as a conference paper at ICLR 2022
REFERENCES,0.2959738846572361,Figure 5: Three excess risk dynamics for CIFAR-10. have
REFERENCES,0.2970620239390642,"∇Ln(θ(0); P) = 2 n n
X i=1"
REFERENCES,0.2981501632208923,"D
θ(0), Xi
E
−⟨θ⋆, Xi⟩−εi

Xi = −2 n n
X"
REFERENCES,0.2992383025027203,"i=1
(⟨θ⋆, Xi⟩+ εi) Xi ≈−2θ⋆, (10)"
REFERENCES,0.3003264417845484,"if we assume Xi ∼N (0, Id×d). On the other hand, for the variance training, the empirical loss is
Ln(θ; Pv) = 1"
REFERENCES,0.3014145810663765,"n
Pn
i=1 (⟨θ, Xi⟩−εi)2. Therefore, we have"
REFERENCES,0.3025027203482046,"∇Ln(θ(0)
b ; Pv) = 2 n n
X i=1"
REFERENCES,0.30359085963003263,"D
θ(0)
b , Xi
E
−εi

Xi = −2 n n
X"
REFERENCES,0.30467899891186073,"i=1
εiXi ≈0.
(11)"
REFERENCES,0.3057671381936888,"In conclusion, we have
∇Ln(θ(0); P)
 ≈2 ∥θ⋆∥,
∇Ln(θ(0)
v ; Pv)
 ≈0.
(12)"
REFERENCES,0.3068552774755169,"Obviously, there is a huge initial gradient norm gap between standard and variance training, showing
that our bound is significantly better than the direct stability-based bound under such regimes."
REFERENCES,0.30794341675734493,"B.2
FIGURE 1B"
REFERENCES,0.30903155603917304,"Figure 1b provides an example showing that the trajectory experienced by the variance training is
likely to stay a convex region, though the global landscape can be highly non-smooth and non-convex.
The reason is similar to that of Figure 1a. Since θ(0)
v
≈ˆθv, the gradient norm is small and the training
dynamics may stay close to the optimum, which lies on a smooth and convex region. On the contrary,
the standard training needs to cross potentially many bad local minimum or saddle points, suffering
from large cumulative gradient norms."
REFERENCES,0.3101196953210011,"B.3
FIGURE 2"
REFERENCES,0.31120783460282914,"The setting of Figure 2 is similar to that of Section A. For MINIST dataset, we use three layer
convoluted neural network with Adam optimizer."
REFERENCES,0.31229597388465724,Published as a conference paper at ICLR 2022
REFERENCES,0.3133841131664853,"B.4
FIGURE 3"
REFERENCES,0.3144722524483134,"Figure 3 provides the numerical verification of Dynamics Decomposition Condition, and our upper
bounds for both linear regression and matrix recovery problems 11."
REFERENCES,0.31556039173014144,"Linear Regression
We set the dimension d = 500, the sample sizes are n = 300, 800, respectively.
Samples x1 · · · , xn are i.i.d. from standard Gaussian distribution N (0, Id×d), and the output
yi = ⟨xi, θ⋆⟩+εi where εi ∼N(0, σ2) and σ = 2. We set the initialization θ(0) = θ(0)
b
= θ(0)
v
= 0
and the learning rate λ = 0.01."
REFERENCES,0.31664853101196955,"Matrix Recovery
We set the dimension d = 20, rank r = 3, the ground truth X⋆= V ΣV ⊤, where
Σ = Diag{5, 3, 1, 0, · · · , 0} and V is an orthonormal matrix. The numbers of the measurement
matrices are 200, 600, respectively. The measurement matrices A1, · · · , An are i.i.d. standard
Gaussian matrices. The corresponding measurement yi = ⟨Ai, X⋆⟩+εi, where εi ∼N(0, 1). In this
numerical experiment, we use the initialization U(0) = Ub(0) = Uv(0) = αId×d where α = 0.01.
We solve this problem via gradient descent with constant stepsize η = 0.1."
REFERENCES,0.3177366702937976,"For the upper bound, it is calculated via upper bound =
Xb
t −X⋆
F + ∥Xv
t ∥F + 8.5
√n, where the
last term is corresponding to the additional term in Lemma 4."
REFERENCES,0.3188248095756257,"Neural Network
We the dimension d = 30, the ground truth function is f ⋆(x) = ⟨θ⋆, x⟩where
θ⋆is sparse and ∥θ⋆∥= Θ(1). The covariate x is generated from Gaussian distribution. The label
for bias training is exactly yi = f ⋆(xi). For the variance trainng, its label is generated from an
additional Gaussian distribution εi ∼N(0, σ2) where σ = 1.5. For the standard training, its label is"
REFERENCES,0.31991294885745375,"yi = f ⋆(xi)+εi. For the upper bound, it is calculated via upper bound =
fθb
t −f ⋆
P +
fθv
t

P."
REFERENCES,0.32100108813928185,"Here ∥·∥P is defined to be the L2(P) norm, i.e., ∥g∥2
P = Ex∼P

f(x)2
. For these settings, we
choose SGD (with stepsize η = 1 × 10−3) as the optimizer where the initialization is randomly
generated from a Gaussian distribution."
REFERENCES,0.3220892274211099,"C
PROOF FOR OVERPARAMETERIZED LINEAR REGRESSION"
REFERENCES,0.32317736670293795,"C.1
PROOF OF THEOREM 1"
REFERENCES,0.32426550598476606,"In this section, we prove Theorem 1 stated as follows:"
REFERENCES,0.3253536452665941,"Theorem 1 (Linear Regression Regimes) Under the overparameterized linear regression settings,
assume that w =
θ∗,⊤x
√"
REFERENCES,0.3264417845484222,"θ∗,⊤Σxθ∗is σ2
w-subgaussian. If ∥x∥≤1, |ϵ| ≤V , supt∈[T ] ∥ˆθ(t)
v ∥≤B are all"
REFERENCES,0.32752992383025026,"bounded, the following inequality holds with probability at least 1 −δ:"
REFERENCES,0.32861806311207836,EL(ˆθ(T ); P) = ˜O 
REFERENCES,0.3297062023939064,"max
n
1, θ∗,⊤Σxθ∗σ2
w, [V + B]2o r"
REFERENCES,0.3307943416757345,log(4/δ)
REFERENCES,0.33188248095756256,"n
+ ∥θ∗∥2"
REFERENCES,0.33297062023939067,"λT
+ Tλ[V + B]2 n ! ,"
REFERENCES,0.3340587595212187,where the probability is taken over the randomness of training data.
REFERENCES,0.33514689880304677,Proof:
REFERENCES,0.33623503808487487,"11Here, we extend the diagonal matrix recovery problem to the general matrix recovery problem."
REFERENCES,0.3373231773667029,Published as a conference paper at ICLR 2022
REFERENCES,0.338411316648531,"We first calculate the population loss under linear regression regime, namely, for any time t:"
REFERENCES,0.3394994559303591,"L(ˆθ(t); P) = Ex,y
h
y −x⊤ˆθ(t)i2"
REFERENCES,0.3405875952121872,"(a)
= E
h
x⊤θ∗+ ϵ −x⊤ˆθ(t)i2"
REFERENCES,0.3416757344940152,"= E
h
x⊤θ∗−x⊤ˆθ(t)i2
−2E
h
ϵx⊤ˆθ(t)i
+ Eϵ2"
REFERENCES,0.34276387377584333,"=
h
θ∗−ˆθ(t)i⊤
Σx
h
θ∗−ˆθ(t)i
−2ExEϵ
h
ϵx⊤ˆθ(t)|x
i
+ Eϵ2"
REFERENCES,0.3438520130576714,"=
h
θ∗−ˆθ(t)i⊤
Σx
h
θ∗−ˆθ(t)i
−2Ex
h
x⊤ˆθ(t)Eϵ [ϵ|x]
i
+ Eϵ2"
REFERENCES,0.34494015233949943,"(b)
=
h
θ∗−ˆθ(t)i⊤
Σx
h
θ∗−ˆθ(t)i
+ Eϵ2,"
REFERENCES,0.34602829162132753,where (a) we use the condition that y = x⊤θ∗+ ϵ and (b) we use the assumption that E[ϵ|x] = 0.
REFERENCES,0.3471164309031556,"Therefore, the excess risk can be written as"
REFERENCES,0.3482045701849837,"E(ˆθ(t)) =
h
θ∗−ˆθ(t)i⊤
Σx
h
θ∗−ˆθ(t)i
."
REFERENCES,0.34929270946681173,"Now plugging the Lemma 1, Lemma 2, Lemma 3, into Theorem 2, we derive that with probability at
least 1 −δ:"
REFERENCES,0.35038084874863984,"EL(ˆθ(T ); P) ≲Ev
L(ˆθ(T )
v
; P) + Eb
L(ˆθ(T )
b
; P)"
REFERENCES,0.3514689880304679,"≲θ∗,⊤Σxθ∗"
REFERENCES,0.352557127312296,"√n
σ2
w s"
REFERENCES,0.35364526659412404,"log
4 δ"
REFERENCES,0.35473340587595215,"
+
1
λ [2T + 1]∥θ∗∥2 + Tλ"
REFERENCES,0.3558215451577802,"n [V + B]2 log(n) log(2n/δ) + max
n
1, [V + B]2o r"
REFERENCES,0.35690968443960824,log(4/δ)
N,0.35799782372143635,"2n
. = ˜O "
N,0.3590859630032644,"max
n
1, θ∗,⊤Σxθ∗σ2
w, [V + B]2o r"
N,0.3601741022850925,log(4/δ)
N,0.36126224156692055,"n
+ ∥θ∗∥2"
N,0.36235038084874865,"λT
+ Tλ [V + B]2 n ! ,"
N,0.3634385201305767,"which completes the proof.
□"
N,0.3645266594124048,"C.2
PROOF OF LEMMA 1"
N,0.36561479869423286,We first recall Lemma 1 as follows:
N,0.36670293797606096,"Lemma 1 Under the overparameterized linear regression settings with initialization θ(0) = θ(0)
b
=
θ(0)
v
= 0, for any time T, the following decomposition inequality holds:"
N,0.367791077257889,"EL(ˆθ(T ); P) ≤2Ev
L(ˆθ(T )
v
; P) + 2Eb
L(ˆθ(T )
b
; P)."
N,0.36887921653971706,"Proof: Firstly, when we use gradient descent, we have that:"
N,0.36996735582154516,ˆθ(t+1) = ˆθ(t) + λ n X
N,0.3710554951033732,"i
xi[yi −x⊤
i ˆθ(t)],"
N,0.3721436343852013,"ˆθ(t+1)
v
= ˆθ(t)
v
+ λ n X"
N,0.37323177366702937,"i
xi[ϵi −x⊤
i ˆθ(t)
v )],"
N,0.37431991294885747,"ˆθ(t+1)
b
= ˆθ(t)
b
+ λ n X"
N,0.3754080522306855,"i
xi[x⊤
i θ∗−x⊤
i ˆθ(t)
b ]."
N,0.3764961915125136,"We next prove the conclusion by induction. Since we choose θ(0) = θ(0)
v
= θ(0)
b
= 0, the conclusion
holds at the initialization
θ(0) = θ(0)
v
+ θ(0)
b ."
N,0.37758433079434167,Published as a conference paper at ICLR 2022
N,0.3786724700761698,"Now assume that ˆθ(t) = ˆθ(t)
v
+ ˆθ(t)
b
holds at time t, we have"
N,0.3797606093579978,ˆθ(t+1) = ˆθ(t) + λ n X
N,0.3808487486398259,"i
xi[yi −x⊤
i ˆθ(t)]"
N,0.381936887921654,"= ˆθ(t)
v
+ ˆθ(t)
b
+ λ n X"
N,0.383025027203482,"i
xi
h
ϵi + x⊤
i θ∗−x⊤
i

ˆθ(t)
v
+ ˆθ(t)
b
i ="
N,0.38411316648531013,"""
ˆθ(t)
v
+ λ n X"
N,0.3852013057671382,"i
xi[ϵi −x⊤
i ˆθ(t)
v ] # +"
N,0.3862894450489663,"""
ˆθ(t)
b
+ λ n X"
N,0.38737758433079433,"i
xi[x⊤
i θ∗−x⊤
i ˆθ(t)
b ] #"
N,0.38846572361262244,"= ˆθ(t+1)
v
+ ˆθ(t+1)
b
."
N,0.3895538628944505,"In summary, we have: ˆθ(t) = ˆθ(t)
v
+ ˆθ(t)
b
holds for any time t. Besides, we easily calculate that
θ∗= θ∗
v + θ∗
b since θ∗= θ∗
b = θ∗and θ∗
v = 0."
N,0.3906420021762786,"Therefore, we have ˆθ(t) −θ⋆= ˆθ(t)
v −θ⋆
v + ˆθ(t)
b −θ⋆
b holds for any t. By Cauchy–Schwarz inequality,
we derive that for a specific time T:"
N,0.39173014145810664,EL(ˆθ(T ); P)
N,0.3928182807399347,"=
h
θ∗−ˆθ(T )i⊤
Σx
h
θ∗−ˆθ(T )i"
N,0.3939064200217628,"=
θ∗−ˆθ(T )
2 Σx"
N,0.39499455930359084,"=
θ∗
v −ˆθ(T )
v
+ θ∗
b −ˆθ(T )
b

2"
N,0.39608269858541895,"Σx
(a)
≤2
θ∗
v −ˆθ(T )
v

2"
N,0.397170837867247,"Σx + 2
θ∗
b −ˆθ(T )
b

2"
N,0.3982589771490751,"Σx
≤2Ev
L(ˆθ(T )
v
; P) + 2Eb
L(ˆθ(T )
b
; P)."
N,0.39934711643090315,"where we denote the norm ∥u∥2
A = u⊤Au. □"
N,0.40043525571273125,"C.3
PROOF OF LEMMA 2"
N,0.4015233949945593,"Lemma 2 Under the overparameterized linear regression settings, assume that ∥x∥≤1, |ϵ| ≤V ,
supt ∥ˆθ(t)
v ∥≤B are all bounded. Consider the gradient descent algorithm with constant stepsize λ,
with probability at least 1 −δ:"
N,0.40261153427638735,"Ev
L

ˆθ(T )
v
; P

= O Tλ"
N,0.40369967355821545,"n [V + B]2 log(n) log(2n/δ) + max
n
1, [V + B]2o r"
N,0.4047878128400435,log(2/δ)
N,0.4058759521218716,"2n ! .
(2)"
N,0.40696409140369966,"Proof: When the context is clear, we omit v in this section and denote the trained parameter by ˆθ(t).
For any time t, we first split the excess risk into three components following Equation 1."
N,0.40805223068552776,"EL(ˆθ(t); Pv) =
h
L(ˆθ(t); Pv) −L(ˆθ(t); Pn
v )
i"
N,0.4091403699673558,"|
{z
}
(I)"
N,0.4102285092491839,"+
h
L(ˆθ(t); Pn
v ) −L(θ∗; Pn
v )
i"
N,0.41131664853101196,"|
{z
}
(II)"
N,0.41240478781284007,"+ [L(θ∗; Pn
v ) −L(θ∗; Pv)]
|
{z
}
(III) . (13)"
N,0.4134929270946681,Part (I). We bound the first component in Equation 13 using stability.
N,0.41458106637649617,"Fact A: the loss ℓ(θ; x, y) is 2 [V + B]-Lipschitz."
N,0.41566920565832427,"∥∇θℓ(θ; x, y)∥= 2∥x(ϵ −x⊤θ)∥≤2 [V + B] ."
N,0.4167573449401523,Fact B: the stability of the parameter is 2λt
N,0.4178454842219804,"n [V + B]. Denote the parameter trained on dataset S and
the parameter trained on dataset S′ as ˆθ(t)
S and ˆθ(t)
S′ , respectively. We will show that, when S and S′"
N,0.41893362350380847,Published as a conference paper at ICLR 2022
N,0.4200217627856366,"have only one different sample (e.g., WLOG S = {x1, x2, · · · , xn} and S′ = {x′
1, x2, · · · , xn}),
ˆθ(t)
S is close to ˆθ(t)
S′ ."
N,0.4211099020674646,"ˆθ(t+1)
S
−ˆθ(t+1)
S′ ≤"
N,0.42219804134929273,"
I −λ"
N,0.4232861806311208,"nX⊤X

ˆθ(t)
S + λ"
N,0.4243743199129489,"nX⊤Y −

I −λ"
N,0.42546245919477693,"nX′,⊤X′

ˆθ(t)
S′ −λ"
N,0.426550598476605,"nX′,⊤Y ′ ≤"
N,0.4276387377584331,"
I −λ"
N,0.42872687704026113,"nX⊤X
 h
ˆθ(t)
S −ˆθ(t)
S′
i
∥+ ∥
λ"
N,0.42981501632208924,"nX′,⊤X′ −λ"
N,0.4309031556039173,"nX⊤X

ˆθ(t)
S′ ∥+ λ"
N,0.4319912948857454,"n∥X⊤Y −X′,⊤Y ′"
N,0.43307943416757344,"≤

h
ˆθ(t)
S −ˆθ(t)
S′
i + λ n"
N,0.43416757344940154,"h
x1x⊤
1 −x′
1x⊤,′
1
i
ˆθ(t)
S′
 + λ n"
N,0.4352557127312296,"x⊤
1 ϵ1 −x′,⊤
1 ϵ′
1"
N,0.4363438520130577,"≤

h
ˆθ(t)
S −ˆθ(t)
S′
i + 2λ"
N,0.43743199129488575,n [V + B] .
N,0.4385201305767138,Summation over time t provides the following result:
N,0.4396082698585419,"∥ˆθ(t)
S −ˆθ(t)
S′ ∥≤2tλ"
N,0.44069640914036995,n [V + B] .
N,0.44178454842219805,"Therefore, the total stability with respect to the ℓ2-loss is"
N,0.4428726877040261,"|ℓ(ˆθ(t)
S ) −ℓ(ˆθ(t)
S′ )| ≤4tλ"
N,0.4439608269858542,n [V + B]2 .
N,0.44504896626768226,"By Proposition 1, we have that"
N,0.44613710554951036,"L(ˆθ(t); Pv) −L(ˆθ(t); Pn
v ) ≲tλ"
N,0.4472252448313384,n [V + B]2 log(n) log(2n/δ) + r
N,0.44831338411316646,"log(1/δ) n
."
N,0.44940152339499456,Part II. We next show that the second component in Equation 13 is less than zero based on Lemma 7.
N,0.4504896626768226,"L(θ(t); Pn
v ) −L(θ∗; Pn
v ) = 1 n"
N,0.4515778019586507,"h
∥ϵ −Xθ(t)∥2 −∥ϵ∥2i = 1 nϵ⊤
"" −2X """
N,0.45266594124047876,"I −

I −λ"
N,0.45375408052230687,"nX⊤X
t#"
N,0.4548422198041349,"X† + X†,⊤
"""
N,0.455930359085963,"I −

I −λ"
N,0.45701849836779107,"nX⊤X
t# X⊤X """
N,0.4581066376496192,"I −

I −λ"
N,0.4591947769314472,"nX⊤X
t# X†
# ϵ."
N,0.4602829162132753,The i-th eigenvalue of the matrix [−2X[I −[I −λ
N,0.4613710554951034,"nX⊤X]t]X† +X†,⊤[I −[I −λ"
N,0.4624591947769314,"nX⊤X]t]X⊤X[I −
[I −λ"
N,0.46354733405875953,nX⊤X]t]X†] can be calculated as follows
N,0.4646354733405876,"−2

1 −(1 −λσi)t
+

1 −(1 −λσi)t2 = (1 −λσi)2t −1 ≤0,"
N,0.4657236126224157,where σi refers to the i-th eigenvalue of the matrix 1
N,0.46681175190424373,"nX⊤X. Therefore, we have"
N,0.46789989118607184,"L(θ(t); Pn
v ) −L(θ∗; Pn
v ) ≤0."
N,0.4689880304678999,Part III. We bound the third component in Equation 13 using concentration.
N,0.470076169749728,"Note that |ℓ2(θ; x, y)| = |(y −x⊤θ)2| ≤[V + B]2, so we can use Hoeffding’s inequality,"
N,0.47116430903155604,"P [|L(θ∗; Pn
v ) −L(θ∗; Pv)| ≥u] ≤2 exp

−
2nu2"
N,0.4722524483133841,"(B + V )4 
."
N,0.4733405875952122,By setting u = [V + B]2 q
N,0.47442872687704024,log(2/δ)
N,0.47551686615886835,"2n
, then with probability at least 1 −δ, we have"
N,0.4766050054406964,"|L(θ∗; Pn
v ) −L(θ∗; Pv)| ≤[V + B]2
r"
N,0.4776931447225245,log(2/δ)
N,0.47878128400435255,"2n
."
N,0.47986942328618065,Published as a conference paper at ICLR 2022
N,0.4809575625680087,"Combining Part (I), (II), and (III) together, at time T, we have:"
N,0.4820457018498368,EL(ˆθ(T ); Pv) ≲Tλ
N,0.48313384113166485,n [V + B]2 log(n) log(2n/δ) + r
N,0.4842219804134929,log(1/δ)
N,0.485310119695321,"n
+ [V + B]2
r"
N,0.48639825897714906,log(2/δ)
N,0.48748639825897716,2n ≲Tλ
N,0.4885745375408052,"n [V + B]2 log(n) log(2n/δ) + max{1, [V + B]2} r"
N,0.4896626768226333,log(2/δ)
N,0.49075081610446136,"2n
. □"
N,0.49183895538628947,"C.4
PROOF OF LEMMA 3"
N,0.4929270946681175,"Lemma 3 Under the overparameterized linear regression settings, assume that w =
θ∗,⊤x
√"
N,0.4940152339499456,"θ∗,⊤Σxθ∗is"
N,0.49510337323177367,"σ2
w-subgaussian, then with probability at least 1 −δ:"
N,0.4961915125136017,"Eb
L(ˆθ(T )
b
; P) = O"
N,0.4972796517954298,"θ∗,⊤Σxθ∗"
N,0.49836779107725787,"√n
σ2
w s"
N,0.499455930359086,"log
2 δ"
N,0.500544069640914,"
+
1
λ[2T + 1]∥θ∗∥2
! .
(3)"
N,0.5016322089227421,"Proof: Since we use the noiseless data (x, E(y|x)) and E(y|x) = x⊤θ∗, by Lemma 7 we have"
N,0.5027203482045702,"θ(t)
b
= """
N,0.5038084874863983,"I −

I −λ"
N,0.5048966267682263,"nX⊤X
t#"
N,0.5059847660500544,"X†Xθ∗= θ∗
"""
N,0.5070729053318824,"I −

I −λ"
N,0.5081610446137106,"nX⊤X
t# θ∗,"
N,0.5092491838955386,"where we use the fact that
h
I −

I −λ"
N,0.5103373231773667,"nX⊤X
ti
X†X = I −

I −λ"
N,0.5114254624591947,"nX⊤X
t."
N,0.5125136017410229,"Therefore, BER can be expressed as:"
N,0.5136017410228509,"EL(θ; Pn
b ) =
h
θ∗−θ(t)
b
i⊤
Σx
h
θ∗−θ(t)
b
i"
N,0.514689880304679,"= θ∗,⊤

I −λ"
N,0.515778019586507,"nX⊤X
t
Σx"
N,0.5168661588683352,"
I −λ"
N,0.5179542981501633,"nX⊤X
t
θ∗"
N,0.5190424374319913,"= θ∗,⊤

I −λ"
N,0.5201305767138193,"nX⊤X
t 
Σx −1"
N,0.5212187159956474,"nX⊤X
 
I −λ"
N,0.5223068552774756,"nX⊤X
t
θ∗"
N,0.5233949945593036,"+ θ∗,⊤

I −λ"
N,0.5244831338411317,"nX⊤X
t  1"
N,0.5255712731229597,"nX⊤X
 
I −λ"
N,0.5266594124047879,"nX⊤X
t
θ∗."
N,0.5277475516866159,"We split the excess risk into two parts. Intuitively, it is just like the decomposition in Equation 1. The
first part is similar to the generalization gap to use uniform convergence to bound it. Note that here
we require that λ < supX0
1
∥1"
N,0.528835690968444,"n X0⊤X0∥. Hence, we have"
N,0.529923830250272,Published as a conference paper at ICLR 2022
N,0.5310119695321001,"θ∗,⊤

I −λ"
N,0.5321001088139282,"nX⊤X
t 
Σx −1"
N,0.5331882480957563,"nX⊤X
 
I −λ"
N,0.5342763873775843,"nX⊤X
t
θ∗ ≤"
N,0.5353645266594124,"sup
X0
θ∗,⊤

I −λ"
N,0.5364526659412405,"nX0
⊤X0"
N,0.5375408052230686,"t 
Σx −1"
N,0.5386289445048966,"nX⊤X
 
I −λ"
N,0.5397170837867247,"nX0
⊤X0 t
θ∗ ="
N,0.5408052230685527,"sup
X0
tr "
N,0.5418933623503809,"θ∗,⊤

I −λ"
N,0.5429815016322089,"nX0
⊤X0"
N,0.544069640914037,"t 
Σx −1"
N,0.545157780195865,"nX⊤X
 
I −λ"
N,0.5462459194776932,"nX0
⊤X0"
N,0.5473340587595212,"t
θ∗
! ="
N,0.5484221980413493,"sup
X0
tr"
N,0.5495103373231773,"
I −λ"
N,0.5505984766050055,"nX0
⊤X0"
N,0.5516866158868335,"t 
Σx −1"
N,0.5527747551686616,"nX⊤X
 
I −λ"
N,0.5538628944504896,"nX0
⊤X0"
N,0.5549510337323177,"t
θ∗θ∗,⊤
! ="
N,0.5560391730141458,"sup
X0 "
N,0.5571273122959739,"
I −λ"
N,0.558215451577802,"nX0
⊤X0"
N,0.55930359085963,"t 
Σx −1"
N,0.5603917301414582,"nX⊤X
 
I −λ"
N,0.5614798694232862,"nX0
⊤X0"
N,0.5625680087051143,"t
θ∗θ∗,⊤  ≤"
N,0.5636561479869423,"sup
X0 "
N,0.5647442872687704,"
I −λ"
N,0.5658324265505985,"nX0
⊤X0 t "
N,0.5669205658324266,"
Σx −1"
N,0.5680087051142546,"nX⊤X
 
I −λ"
N,0.5690968443960827,"nX0
⊤X0"
N,0.5701849836779108,"t
θ∗θ∗,⊤  ≤"
N,0.5712731229597389,"sup
X0 "
N,0.5723612622415669,"
Σx −1"
N,0.573449401523395,"nX⊤X
 
I −λ"
N,0.5745375408052231,"nX0
⊤X0"
N,0.5756256800870512,"t
θ∗θ∗,⊤  ="
N,0.5767138193688792,"sup
X0
tr "
N,0.5778019586507073,"θ∗,⊤

Σx −1"
N,0.5788900979325353,"nX⊤X
 
I −λ"
N,0.5799782372143635,"nX0
⊤X0"
N,0.5810663764961915,"t
θ∗
!"
N,0.5821545157780196,"≤
sup
X0
tr

θ∗,⊤

Σx −1"
N,0.5832426550598476,"nX⊤X

θ∗
"
N,0.5843307943416758,"=
θ∗,⊤

Σx −1"
N,0.5854189336235038,"nX⊤X

θ∗
 ,"
N,0.5865070729053319,"where we apply Lemma 8 repeatedly since rank

θ∗,⊤θ∗A

= 1 where A stands for arbitrary matrix."
N,0.5875952121871599,"We highlight the difference between X0 and X. The notation X represents the contribution of the
training set to the training error. The notation X0 represents the contribution of the training set to the
training estimator ˆθ. The uniform convergence is taken over the estimator θ. Therefore, we take sup
operator on X0."
N,0.588683351468988,"We next bound θ∗,⊤
Σx −1"
N,0.5897714907508161,"nX⊤X

θ∗. Assume that w = θ∗,⊤x/
p"
N,0.5908596300326442,"θ∗,⊤Σxθ∗is SubGaussian
with subGaussian norm σw. Obviously, E [w] = 0, E

w2
= 1. Therefore, we have that: w2 −1 is
sub-Exponential distributions with sub-Exponential norm
w2 −1

ψ1 ≤σ2
w."
N,0.5919477693144722,"While ϵ/

θ⊤Σxθ

< σ2
w, we have the following tail bound"
N,0.5930359085963003,"P

|θ∗,⊤

Σx −1"
N,0.5941240478781284,"nX⊤X

θ∗| ≥ϵ

= P  | 1 n n
X i=1"
N,0.5952121871599565,"
(x⊤
i θ)2 −θ⊤Σxθ

| ≥ϵ ! = P  | 1 n n
X i=1"
N,0.5963003264417845,"
w2
i −1

| ≥ϵ/

θ⊤Σxθ

!"
N,0.5973884657236126,"≤2 exp "" −c"
N,0.5984766050054406,"
ϵ/

θ⊤Σxθ
2 nσ4w # ,"
N,0.5995647442872688,where c is a universal constant.
N,0.6006528835690969,"Therefore, by setting ϵ =

θ⊤Σxθ
 σ2
w log[2/δ]
√c√n
with probability at least 1 −δ, we have"
N,0.6017410228509249,"θ∗,⊤

Σx −1"
N,0.602829162132753,"nX⊤X

θ∗
 ≤

θ⊤Σxθ
 σ2
w
p"
N,0.6039173014145811,"log [2/δ]
√c√n
."
N,0.6050054406964092,Published as a conference paper at ICLR 2022
N,0.6060935799782372,"With abuse to use c as a constant, we have with probability at least ≥1 −δ
θ∗,⊤

Σx −1"
N,0.6071817192600653,"nX⊤X

θ∗
 ≤c

θ⊤Σxθ
 σ2
w
p"
N,0.6082698585418934,"log(2/δ)
√n
."
N,0.6093579978237215,"For the second part, which is closely related to the empirical loss of θ(t)
b , We will show
that: for a general case, the empirical loss converges with rate O(1/t).
Denote the eigen-
values of
1
nX⊤X as σ1, · · · , σn, 0, · · · , 0.
Then the corresponding eigenvalues of matrix

I −λ"
N,0.6104461371055495,"nX⊤X
t  1"
N,0.6115342763873776,"nX⊤X
 
I −λ"
N,0.6126224156692056,"nX⊤X
t are (1 −λσi)2tσi. Therefore, we have:"
N,0.6137105549510338,"θ∗,⊤

I −λ"
N,0.6147986942328618,"nX⊤X
t  1"
N,0.6158868335146899,"nX⊤X
 
I −λ"
N,0.6169749727965179,"nX⊤X
t
θ∗"
N,0.6180631120783461,"≤∥θ∗∥2 max
i (1 −λσi)2tσi"
N,0.6191512513601741,"≤
1
λ(2t + 1) ∥θ∗∥2 ."
N,0.6202393906420022,"The maximum is attained while σi =
1
λ(2t+1)."
N,0.6213275299238302,"Combining these terms leads to the conclusion.
□"
N,0.6224156692056583,"C.5
AUXILIARY LEMMAS"
N,0.6235038084874864,Lemma 7 The dynamics of ˆθ(t) using GD is:
N,0.6245919477693145,"ˆθ(t) =

I −λ"
N,0.6256800870511425,"nX⊤X
t h
θ(0) −X†Y
i
+ X†Y."
N,0.6267682263329706,where X† represents the pseudo inverse of matrix X.
N,0.6278563656147987,"Proof: The proof is based on induction. We notice that when t = 0, the equation directly follows.
Assume when t = t, the equation holds. Then at time t + 1, we have"
N,0.6289445048966268,ˆθ(t+1) = ˆθ(t) + λ
N,0.6300326441784548,nX⊤(Y −X ˆθ(t))
N,0.6311207834602829,"=

1 −λ"
N,0.6322089227421109,"nX⊤X
 ""
I −λ"
N,0.6332970620239391,"nX⊤X
t h
θ(0) −X†Y
i
+ X†Y # + λ nX⊤Y"
N,0.6343852013057671,"=

I −λ"
N,0.6354733405875952,"nX⊤X
t+1 h
θ(0) −X†Y
i
+

1 −λ"
N,0.6365614798694232,"nX⊤X

X†Y + λ nX⊤Y"
N,0.6376496191512514,"=

I −λ"
N,0.6387377584330794,"nX⊤X
t+1 h
θ(0) −X†Y
i
+ X†Y,"
N,0.6398258977149075,where we use the fact that X⊤XX† = X⊤. □
N,0.6409140369967355,"Lemma 8 For rank-1 matrix A, we have that ∥A∥= |tr [A]|."
N,0.6420021762785637,"D
PROOF OF THEOREM 2"
N,0.6430903155603918,"In this section, we provide the proof of Theorem 2. We first recall the formal statement of Theorem 2."
N,0.6441784548422198,"Theorem 2 (Decomposition Theorem) Assume that the excess risk has a unique minimizer with
local sharpness factor s. Under Assumption 1 and Assumption 2, the following decomposition
inequality holds:"
N,0.6452665941240479,EL(ˆθ(T ); P) ≤[4a]s Mu mu
N,0.6463547334058759,"h
Ev
L(ˆθ(T )
v
; P) + Eb
L(ˆθ(T )
b
; P)
i
+ Mu"
N,0.6474428726877041," 4C
√ T"
N,0.6485310119695321,"s
+ Mu 4C′ √n"
N,0.6496191512513602,"s
.
(5)"
N,0.6507072905331882,Published as a conference paper at ICLR 2022
N,0.6517954298150164,"Proof: Under Assumption 1 (upper bound), we have:"
N,0.6528835690968444,EL(ˆθ(t); P) = EL(ˆθ(t); P)
N,0.6539717083786725,∥ˆθ(t) −ˆθ∗∥s ∥ˆθ(t) −ˆθ∗∥s
N,0.6550598476605005,"≤
h
M 1/s
u
∥ˆθ(t) −ˆθ∗∥
is
."
N,0.6561479869423286,"Combining Assumption 2 (DDC) and the lower bound in Assumption 1, we have"
N,0.6572361262241567,∥ˆθ(t) −ˆθ∗∥
N,0.6583242655059848,"≤a∥ˆθ(t)
b
−ˆθ∗
b∥+ a∥ˆθ(t)
v
−ˆθ∗
v∥+ C
√"
N,0.6594124047878128,t + C′ √n ≤[ 1
N,0.6605005440696409,"mu
]1/saE1/s
L (ˆθ(t)
b ; Pb) + [ 1"
N,0.661588683351469,"mu
]1/saE1/s
L (ˆθ(t)
v ; Pv) + C
√"
N,0.6626768226332971,"t + C′ √n,"
N,0.6637649619151251,"where we remark that Assumption 1 holds uniformly on distribution Py|x and θ. Therefore, we have
that"
N,0.6648531011969532,EL(ˆθ(t); P) ≤
N,0.6659412404787813,"""
Mu
mu"
N,0.6670293797606094,"1/s
aE1/s
L (ˆθ(t)
b ; Pb) + Mu mu"
N,0.6681175190424374,"1/s
aE1/s
L (ˆθ(t)
v ; Pv) + C
√"
N,0.6692056583242655,t + C′ √n #s
N,0.6702937976060935,"≤4s
Mu"
N,0.6713819368879217,"mu
asEL(ˆθ(t)
b ; Pb) + Mu"
N,0.6724700761697497,"mu
asEL(ˆθ(t)
v ; Pv) +

M 1/s
u
C
√ t"
N,0.6735582154515778,"s
+

M 1/s
u
C′
√n s"
N,0.6746463547334058,≤[4a]s Mu mu
N,0.675734494015234,"h
EL(ˆθ(t)
b ; Pb) + EL(ˆθ(t)
v ; Pv)
i
+ Mu 4C
√ t"
N,0.676822633297062,"s
+ Mu 4C′ √n s
."
N,0.6779107725788901,"where we use the fact that (a + b + c + d)p ≤max{(4a)p, (4b)p, (4c)p, (4d)p} ≤(4a)p + (4b)p +
(4c)p + (4d)p when a, b, c, d, p > 0. □"
N,0.6789989118607181,"E
PROOF FOR DIAGONAL MATRIX RECOVERY"
N,0.6800870511425462,"In this section, we prove Theorem 3 via proving the proceeding three lemmas separately."
N,0.6811751904243744,"E.1
PROOF OF THEOREM 3"
N,0.6822633297062024,"Theorem 3 (Decomposition Theorem in Diagonal Matrix Recovery) In the diagonal matrix re-
covery settings, if we set the initialization U0 = αI where α > 0 is the initialization scale, then for
any 0 < t < ∞, with probability at least 1 −δ, we have:"
N,0.6833514689880305,"EL(Ut; P) ≲

∥X⋆∥2
F + dV 2 + dα4 r"
N,0.6844396082698585,"log (d/δ) n
+ r
X j=1"
N,0.6855277475516867,"σ4
j
σ2
j + α4eΩ(σjt) + α2d t"
N,0.6866158868335147,+ dV 2(t + 1)
N,0.6877040261153428,"n
log(n) log
2dn δ"
N,0.6887921653971708,"
+ dα2 + log2
 1 α2"
N,0.6898803046789989," rν2 log (r/δ) n
. (6)"
N,0.690968443960827,"Note that although we do optimization based on U, we consider its square X = UU ⊤as the parameter
since we require the solution is unique during the analysis. Note that we do not change the update
rule (where GD is still taken on U). One can directly check that under Diagonal Matrix Recovery
regimes, s = 2 and Mu = mu = 1. Therefore, combining Lemma 4, Lemma 5 and Lemma 6 leads
to Theorem 3."
N,0.6920565832426551,"E.2
PROOF OF LEMMA 4"
N,0.6931447225244831,"Lemma 4 Under the assumptions in Theorem 3, for any 0 ≤t < ∞, with probability at least 1 −δ,
we have
UtU ⊤
t −X⋆
F ≤
U b
t U b,⊤
t
−X⋆
F +
U v
t U v,⊤
t

F + O "
N,0.6942328618063112,"log
 1 α2  r"
N,0.6953210010881393,rν2 log (r/δ) n ! . (7)
N,0.6964091403699674,Published as a conference paper at ICLR 2022
N,0.6974972796517954,"Proof: Since all the measurement matrices A(1), · · · , A(n) are diagonal, we can analyze the dynamic
of each singular value separately."
N,0.6985854189336235,"For a given singular value σ, assume ai ∼N(0, 1), εi ∼subG(ν2). Then we define σ1 =
1
n
Pn
i=1 a2
i σ, and σ2 =
1
n
Pn
i=1 aiεi, denote σ = σ1 + σ2, and ξ =
1
n
Pn
i=1 a2
i . Denote u2(t),
u2
b(t), u2
v(t) the dynamics of standard training, bias training, and variance training, respectively. Then
our goal is to show that |σ −u2(t)| ≤|σ −u2
b(t)| + u2
v(t) + small term holds with high probability."
N,0.6996735582154516,"Before diving into the details, we first give the dynamics of u2(t), u2
b(t), u2
v(t). If σ > 0, we have"
N,0.7007616974972797,"u2(t) =
σα2e2σt"
N,0.7018498367791077,σ −ξα2 + ξα2e2σt .
N,0.7029379760609358,"u2
b(t) =
σ1α2e2σ1t"
N,0.7040261153427638,σ1 −ξα2 + ξα2e2σ1t .
N,0.705114254624592,"Furthermore, if σ2 > 0, we have"
N,0.70620239390642,"u2
v(t) =
σ2α2e2σ2t"
N,0.7072905331882481,σ2 −ξα2 + ξα2e2σ2t .
N,0.7083786724700761,"Otherwise, if σ2 < 0 we have"
N,0.7094668117519043,"u2
v(t) =
|σ2| α2"
N,0.7105549510337323,(|σ2| + ξα2) e2|σ2|t −ξα2 .
N,0.7116430903155604,"If σ⋆= 0, we have"
N,0.7127312295973884,"u2
b(t) =
α2"
N,0.7138193688792165,ξα2t + 1.
N,0.7149075081610446,"Now we turn to the proof of Lemma 4. If σ = 0, then σ = σ2, which implies u2(t) = u2
v(t),
indicating that the conclusion holds."
N,0.7159956474428727,"Hence, we only consider the case that σ ≥σr > 0. By triangle inequality, it suffices to show
u2(t) −u2
b(t)
 = O (|σ2|) ."
N,0.7170837867247007,"Without loss of generality, we assume σ > σ1 > 0. Note that"
N,0.7181719260065288,"u2(t) −u2
b(t)
 =

σα2e2σt"
N,0.719260065288357,"σ + ξα2e2σt −
σ1α2e2σ1t"
N,0.720348204570185,σ1 + ξα2e2σ1t
N,0.721436343852013,+ O(|σ2|)
N,0.7225244831338411,"=
α2σσ1
 
e2σt −e2σ1t"
N,0.7236126224156693,(σ + ξα2e2σt) (σ1 + ξα2e2σ1t) + O(|σ2|).
N,0.7247007616974973,"Via integration-by-parts formula, we have"
N,0.7257889009793254,"e2σt −e2σ1t = 2σ2e2σt
Z t"
N,0.7268770402611534,"0
e−2σ2sds ≤2σ2te2σt."
N,0.7279651795429815,"Therefore, it suffices to show that"
N,0.7290533188248096,σσ1α2te2σt
N,0.7301414581066377,(σ + ξα2e2σt) (σ1 + ξα2e2σ1t) = ˜O(1).
N,0.7312295973884657,"We prove that there exists a universal constant C, such that"
N,0.7323177366702938,σσ1α2te2σt
N,0.7334058759521219,"(σ + ξα2e2σt) (σ1 + ξα2e2σ1t) ≤C,"
N,0.73449401523395,which is equivalent to show
N,0.735582154515778,"ϕ(t) = C
 
σ + ξα2e2σt  
σ1 + ξα2e2σ1t
−σσ1α2te2σt ≥0,
∀0 ≤t < ∞."
N,0.7366702937976061,"Note that ϕ(0) = C
 
σ + ξα2  
σ1 + ξα2
≥0, and its gradient is"
N,0.7377584330794341,"ϕ′(t) = 2Cξ2α4(σ + σ1)e2(σ+σ1)t + 2Cσσ1ξα2  
e2σt + e2σ1t
−σσ1α2e2σt −2σ2σα2te2σt."
N,0.7388465723612623,Published as a conference paper at ICLR 2022
N,0.7399347116430903,"By concentration of Chi-square distribution, we have ξ ≥1 −
q"
N,0.7410228509249184,log(1/δ)
N,0.7421109902067464,"n
= Ω(1) with probability at
least 1 −δ, providing that n ≳log
  1"
N,0.7431991294885746,"δ

. It suffices to show that ϕ′(t) ≥0, which is equivalent to"
N,0.7442872687704026,ψ(t) = Cα2e2σ1t + Cσ1 −σσ1t ≥0.
N,0.7453754080522307,It attains its minimum σ
N,0.7464635473340587,2 + Cσ1 −σ
LOG,0.7475516866158868,"2 log
 
1
2Cα2

at the point t = log
 
1
2Cα2

/2σ1. Therefore, it
suffices to set C = log
  1"
LOG,0.7486398258977149,"α2

."
LOG,0.749727965179543,"Overall, we have
u2(t) −u2
b(t)
 = O

log 1"
LOG,0.750816104461371,"α2 |σ2|

if σ⋆> 0;
u2(t) −u2
b(t)
 ≤u2
v(t)
if σ⋆= 0.
Hence, with proper choice of probability, we have with probability at least 1 −δ, the following holds"
LOG,0.7519042437431991,"∥Xt −X⋆∥F ≤
Xb
t −X⋆
F + ∥Xv
t ∥F + O "
LOG,0.7529923830250272,"log
 1 α2  r"
LOG,0.7540805223068553,rσ2 log (r/δ) n ! .
LOG,0.7551686615886833,"To summarize, the case is

a = 1, C = 0, C′ = O

log
  1"
LOG,0.7562568008705114,"α2
 p"
LOG,0.7573449401523396,"rσ2 log (r/δ)

-bounded (See
DDC). □"
LOG,0.7584330794341676,"E.3
PROOF OF LEMMA 5"
LOG,0.7595212187159956,"Lemma 5 For VER, under the assumptions in Theorem 3, with probability at least 1 −δ, we have"
LOG,0.7606093579978237,"Ev
L(Ut; P) ≲dV 2(t + 1)"
LOG,0.7616974972796517,"n
log(n) log
2dn δ"
LOG,0.7627856365614799,"
+ dα2 + dV 2
r"
LOG,0.763873775843308,log (2d/δ)
LOG,0.764961915125136,"n
.
(8)"
LOG,0.766050054406964,Proof:
LOG,0.7671381936887922,"Similar to the proof in overparameterized linear regression regimes, we first split the excess risk in
three componenets:
EL(Ut; Pv) = L
 
u2(t)

−Ln
 
u2(t)
"
LOG,0.7682263329706203,"|
{z
}
(I)"
LOG,0.7693144722524483,"+ Ln
 
u2(t)

−Ln (0)
|
{z
}
(I)"
LOG,0.7704026115342764,"+ Ln (0) −L (0)
|
{z
}
(III)"
LOG,0.7714907508161044,".
(14)"
LOG,0.7725788900979326,Part (I). We bound the first component in Equation 13 using stability. We define σ2 = 1
LOG,0.7736670293797606,"n
Pn
i=1 aiεi,
σ′
2 = 1"
LOG,0.7747551686615887,"n
Pn−1
i=1 aiεi + a′
nε′
n. Similarly, we define ξ = 1"
LOG,0.7758433079434167,"n
Pn
i=1 a2
i , and ξ′ = 1"
LOG,0.7769314472252449,"n
Pn−1
i=1 a2
i + a′2
n ."
LOG,0.7780195865070729,"In the first case, we assume both σ2, σ′
2 > 0, so that their difference can be bounded"
LOG,0.779107725788901,"|u2
v(t) −u′2
v (t)| ≲"
LOG,0.780195865070729,"α2σ2σ′
2

e2σ2t −e2σ′
2t + α4 ξ′σ2e2σ2t −ξσ′
2e2σ′
2t + α4(σ2ξ′ −σ′
2ξ)e2(σ2+σ′
2)t"
LOG,0.7812840043525572,"(σ2 −ξα2 + ξα2e2σ2t)
 
σ′
2 −ξ′α2 + ξ′α2e2σ′
2t
."
LOG,0.7823721436343852,"WLOG, we assume σ2 > σ′
2. Then, similar to the proof in Lemma 4, we have
α2σ2σ′
2

e2σ2t −e2σ′
2t"
LOG,0.7834602829162133,"(σ2 −ξα2 + ξα2e2σ2t)
 
σ′
2 −ξ′α2 + ξ′α2e2σ′
2t = O (|σ2 −σ′
2|t) ."
LOG,0.7845484221980413,"The second term is dominated by the first term. Hence, we only need to handle the third term. Note
that"
LOG,0.7856365614798694,"|σ2ξ′ −σ′
2ξ| = |σ2 (ξ′ −ξ) + ξ(σ2 −σ′
2)| ≤|σ2| n"
LOG,0.7867247007616975,"a2
n −a,2
n
 +

ξ
n (anεn −a′
nε′
n)
 ,"
LOG,0.7878128400435256,"we have
α4(σ2ξ′ −σ′
2ξ)e2(σ2+σ′
2)t"
LOG,0.7889009793253536,"(σ2 −ξα2 + ξα2e2σ2t)
 
σ′
2 −ξ′α2 + ξ′α2e2σ′
2t ≤|σ2ξ′ −σ′
2ξ|
ξξ′ ≲|σ2| n"
LOG,0.7899891186071817,"a2
n −a,2
n
 +

ξ
n (anεn −a′
nε′
n)
 ."
LOG,0.7910772578890098,Published as a conference paper at ICLR 2022
LOG,0.7921653971708379,"Combined the above three parts, we finally have"
LOG,0.7932535364526659,"|u2
v(t) −u′2
v (t)| = O
V (t + 1) n 
."
LOG,0.794341675734494,"In the second case, we assume both σ2, σ′
2 < 0. Since both of them would decrease to 0, we have
|u2
b(t) −u′2
b (t)| ≤α2 where α = O(
1
n1/4 )."
LOG,0.795429815016322,"In the last case, without loss of generality, we assume σ2 < 0 < σ′
2. Since u2
v(t) decreases to 0, and
u′2
v(t) increases to σ′
2, we have |u2
b(t) −u′2
b(t)| ≤σ′
2 ≤|σ′
2 −σ2|."
LOG,0.7965179542981502,"Overall, we have"
LOG,0.7976060935799782,"|u2
v(t) −u′2
v (t)| = O
V (t + 1) n 
."
LOG,0.7986942328618063,"Besides, since the loss is O(V )-Lipschitz:"
LOG,0.7997823721436343,"∥∇u2ℓ(u)∥= 2
 
au2 −ε

a ≲V."
LOG,0.8008705114254625,"where u2 is bounded upper bounded by O(V ) during the training analysis due to a small initialization.
Then the total stability is"
LOG,0.8019586507072906,"|ℓ(u2
v(t)) −ℓ(u′2
v (t))| ≤V 2(t + 1) n
."
LOG,0.8030467899891186,"Summation over the dimension d, the whole loss ℓd(u2
v(t)) has stability"
LOG,0.8041349292709467,"|ℓd(U 2
v (t)) −ℓd(U ′2
v (t))| ≤dV 2(t + 1) n
."
LOG,0.8052230685527747,"By Proposition 1, we have that"
LOG,0.8063112078346029,"L(ˆθ(t)
v ; P) −L(ˆθ(t)
v ; Pn) ≲dV 2(t + 1)"
LOG,0.8073993471164309,"n
log(n) log(2dn/δ) + p"
LOG,0.808487486398259,"log(1/δ)
√n
."
LOG,0.809575625680087,"Part (II). We next calculate the second term. Take the explicit formula into the equation, we have"
LOG,0.8106637649619152,"Ln
 
u2(t)

−Ln (0) = 1 n n
X i=1"
LOG,0.8117519042437432," 
a2
i u4
v(t) −2aiεiu2
v(t)

."
LOG,0.8128400435255713,If σ2 = 1
LOG,0.8139281828073993,"n
Pn
i=1 aiεi > 0, we have"
N,0.8150163220892275,"1
n n
X i=1"
N,0.8161044613710555," 
a2
i u4
v(t) −2aiεiu2
v(t)

= −(σ2 −ξα2)σ2
2α2e2σ2t"
N,0.8171926006528836,(σ2 −ξα2 + ξα2e2σ2t)2 ≤0.
N,0.8182807399347116,"If σ2 < 0, we have"
N,0.8193688792165397,"1
n n
X i=1"
N,0.8204570184983678," 
a2
i u4
v(t) −2aiεiu2
v(t)

= ξ
σ2
2α4
 
(|σ2| + ξα2)e2|σ2|t −ξα22 +
2|σ2|2α2"
N,0.8215451577801959,(|σ2| + ξα2)e2|σ2|t −ξα2
N,0.8226332970620239,"≤ξα4 + 2|σ2|α2 ≲α2
r ν2 n ."
N,0.823721436343852,"In conclusion, we have Ln
 
u2(t)

−Ln (0) ≲α2
q ν2 n ."
N,0.8248095756256801,"Part (III). For the third term, we just need one single concentration inequality. Note that for the
variance training, the loss function is of the order O
 
V 2
. Hence, via the Hoeffding inequality, with
probability at least 1 −δ, we have"
N,0.8258977149075082,Ln (0) −L (0) ≲V r
N,0.8269858541893362,"log(1/δ) n
."
N,0.8280739934711643,Combining the three terms leads to Lemma 5. □
N,0.8291621327529923,Published as a conference paper at ICLR 2022
N,0.8302502720348205,"E.4
PROOF OF LEMMA 6"
N,0.8313384113166485,"Lemma 6 For BER, under the assumptions in Theorem 3, with probability at least 1 −δ, we have"
N,0.8324265505984766,"Eb
L(Ut; P) ≲

∥X⋆∥2
F + dα4 r"
N,0.8335146898803046,"log (d/δ) n
+ r
X j=1"
N,0.8346028291621328,"σ4
j
σ2
j + α4eΩ(σjt) + α2d"
N,0.8356909684439608,"t .
(9)"
N,0.8367791077257889,Proof:
N,0.8378672470076169,"Similar to linear regression, we decompose the excess risk into two parts:"
N,0.8389553862894451,"E
h
a2  
u2
b(t) −σ
2i
= E "" a2 −1 n n
X"
N,0.8400435255712732,"i=1
a2
i"
N,0.8411316648531012,"#
 
u2
b(t) −σ
2 + 1 n n
X"
N,0.8422198041349293,"i=1
a2
i
 
u2
b(t) −σ
2 ."
N,0.8433079434167573,"We use the uniform convergence to bound the first term. Assume that σ > 0, we have"
N,0.8443960826985855,"σ −u2
b(t) = σ −
σ1α2e2σ1t"
N,0.8454842219804135,σ1 −ξα2 + ξα2e2σ1t
N,0.8465723612622416,= σσ1 −ξα2σ + α2e2σ1t (ξσ −σ)
N,0.8476605005440696,σ1 −ξα2 + ξα2e2σ1t
N,0.8487486398258978,"=
σσ1 −ξα2σ
σ1 −ξα2 + ξα2e2σ1t"
N,0.8498367791077258,"=
σ2 −α2σ
σ −α2 + α2e2ξσt"
N,0.8509249183895539,≤σ(1 −α2) ≤σ.
N,0.8520130576713819,"Now assume σ = 0, we have"
N,0.85310119695321,"u2
b(t) =
α2"
N,0.8541893362350381,ξα2t + 1 ≤α2.
N,0.8552774755168662,"The second term refers to the training loss, if σ > 0, we have"
N,0.8563656147986942,"1
n n
X"
N,0.8574537540805223,"i=1
a2
i
 
u2
b(t) −σ
2 = ξ"
N,0.8585418933623504," 
σ2 −α2σ
2"
N,0.8596300326441785,"(σ −α2 + α2e2ξσt)2 ≲
σ4"
N,0.8607181719260065,σ2 + α4eΩ(σt) .
N,0.8618063112078346,"If σ = 0, we have"
N,0.8628944504896626,"1
n n
X"
N,0.8639825897714908,"i=1
a2
i
 
u2
b(t) −σ
2 = ξ
α4"
N,0.8650707290533188,"(ξα2t + 1)2 ≲
α4"
N,0.8661588683351469,1 + α4t2 .
N,0.8672470076169749,"Finally, by assigning probability properly, we have"
N,0.8683351468988031,"EL(Ut; Pb) ≲

∥X⋆∥2
F + dα4 r"
N,0.8694232861806311,"log (d/δ) n
+ r
X j=1"
N,0.8705114254624592,"σ4
j
σ2
j + α4eΩ(σjt) + α2d t . □"
N,0.8715995647442872,"F
ADDITIONAL DISCUSSION"
N,0.8726877040261154,"In this section, we discuss more the details in the main text. We first show a case where our bound
outperforms previous stability-based bound under linear regimes. We then validate the rationality
of applying stability-based bound by showing that the generalization gap (under variance regime)
increases with time. We next provide some motivation behind Dynamics Decomposition Condition
by showing that it indeed holds as the beginning of the training phase. We finally introduce a related
version of Dynamics Decomposition Condition which does not require the information about θ∗, θ∗
v,
and θ∗."
N,0.8737758433079434,Published as a conference paper at ICLR 2022
N,0.8748639825897715,"F.1
COMPARISON TO PREVIOUS STABILITY-BASED BOUNDS UNDER LINEAR REGIMES"
N,0.8759521218715995,"One of the shortcomings of the stability-based bound is its failure with a large time T. Our decompo-
sition framework can aid in reducing the failure at a large time T. For example, when considering a
large time T = n3/4 with λ = 1, the newly-proposed decomposition bound is"
N,0.8770402611534276,O(n−1/4[V + B]2).
N,0.8781284004352558,"As a comparison, the original stability-based bound is"
N,0.8792165397170838,O(n−1/4[V + B′]2).
N,0.8803046789989118,We next show that B < B′ holds with a large signal-to-noise ratio.
N,0.8813928182807399,We write the above formula as
N,0.8824809575625681,"∥ˆθ(t)
v ∥= B < B′ = ∥ˆθ(t)∥."
N,0.8835690968443961,"From the formulation of the trained parameter, we have ˆθ(t)
v
= [I −[I −λ"
N,0.8846572361262242,"nX⊤X]t]X†ϵ and
ˆθ(t) = [I −[I −λ"
N,0.8857453754080522,nX⊤X]t]X†Y = [I −[I −λ
N,0.8868335146898803,"nX⊤X]t]θ∗+ ˆθ(t)
v . Therefore, it suffices to show that
∥[I −[I −λ"
N,0.8879216539717084,"nX⊤X]t]θ∗∥> 2∥ˆθ(t)
v ∥."
N,0.8890097932535365,"Note that the first part is only related to signal θ∗and the second part is related to noise ϵ (by applying
concentration, the second part is closely related to the noise level). Therefore, informally, with a large
signal-to-noise ratio, the last equation ∥[I −[I −λ"
N,0.8900979325353645,"nX⊤X]t]θ∗∥> 2∥ˆθ(t)
v ∥holds. To summary, it
holds that B < B′ and our bound outperforms the original stability-based bounds."
N,0.8911860718171926,"F.2
THE GENERALIZATION GAP UNDER VARIANCE INCREASES WITH TIME"
N,0.8922742110990207,"In this part, we will prove that the (variance regime) generalization gap indeed increases with time,
which validates that applying stability-based bound (which also increases with time) is rational."
N,0.8933623503808488,We provide the following Lemma 9 which validates the above statement.
N,0.8944504896626768,"Lemma 9 Let ∆v(t) = L(ˆθ(t)
v ; P) −L(ˆθ(t)
v ; Pn) be the generalization gap under variance regime.
Assume that Σx = I. Then under linear regression settings as in Section 3, we have"
N,0.8955386289445049,"∂
∂t∆v(t) ≥0."
N,0.8966267682263329,Proof: Note that the population loss is calculated as follows by Equation C.1
N,0.8977149075081611,"L(ˆθ(t)
v ; P) =
h
ˆθ(t)
v
i⊤
Σx
h
ˆθ(t)
v
i
+ Eϵ2."
N,0.8988030467899891,And the training loss is calculated as follows:
N,0.8998911860718172,"L(ˆθ(t)
v ; Pn) = 1"
N,0.9009793253536452,"n∥E −X ˆθ(t)
v ∥2 = 1"
N,0.9020674646354734,"n∥X ˆθ(t)
v ∥2 −2"
N,0.9031556039173014,"nE⊤h
X ˆθ(t)
v
i
+ 1 n∥E∥2"
N,0.9042437431991295,"=
h
ˆθ(t)
v
i⊤ 1"
N,0.9053318824809575,"nX⊤X
 h
ˆθ(t)
v
i
−2"
N,0.9064200217627857,"nE⊤X ˆθ(t)
v
+ 1 n∥E∥2 ."
N,0.9075081610446137,"Note that by Lemma 7, we have"
N,0.9085963003264418,"ˆθ(t)
v
= """
N,0.9096844396082698,"I −

I −λ"
N,0.9107725788900979,"nX⊤X
t#

X†E

."
N,0.911860718171926,Published as a conference paper at ICLR 2022
N,0.9129488574537541,"Therefore, we have:"
N,0.9140369967355821,"∆v(t) = L(ˆθ(t)
v ; P) −L(ˆθ(t)
v ; Pn)"
N,0.9151251360174102,"=
h
ˆθ(t)
v
i⊤
Σx
h
ˆθ(t)
v
i
+ Eϵ2 −
h
ˆθ(t)
v
i⊤ 1"
N,0.9162132752992383,"nX⊤X
 h
ˆθ(t)
v
i
+ 2"
N,0.9173014145810664,"nE⊤X ˆθ(t)
v
−1 n∥E∥2"
N,0.9183895538628944,"=
h
ˆθ(t)
v
i⊤
Σx −1"
N,0.9194776931447225,"nX⊤X
 h
ˆθ(t)
v
i
+ 2"
N,0.9205658324265505,"nE⊤X ˆθ(t)
v
+ Eϵ2 −1 n∥E∥2"
N,0.9216539717083787,"= E⊤
X†⊤
"""
N,0.9227421109902068,"I −

I −λ"
N,0.9238302502720348,"nX⊤X
t# 
Σx −1"
N,0.9249183895538629,"nX⊤X
 """
N,0.926006528835691,"I −

I −λ"
N,0.9270946681175191,"nX⊤X
t#

X†E
 + 2 nE⊤X """
N,0.9281828073993471,"I −

I −λ"
N,0.9292709466811752,"nX⊤X
t#

X†E

+ Eϵ2 −1"
N,0.9303590859630033,n∥E∥2.
N,0.9314472252448314,"By omitting the terms in ∆v(t) that is uncorrelated to t, we have (denote as ¯∆v(t)):"
N,0.9325353645266594,"¯∆v(t) = E⊤
X†⊤
I −λ"
N,0.9336235038084875,"nX⊤X
t 
Σx −1"
N,0.9347116430903155,"nX⊤X
 
I −λ"
N,0.9357997823721437,"nX⊤X
t 
X†E
"
N,0.9368879216539717,"−2E⊤
X†⊤
Σx −1"
N,0.9379760609357998,"nX⊤X
 
I −λ"
N,0.9390642002176278,"nX⊤X
t 
X†E
 −2"
N,0.940152339499456,"nE⊤X

I −λ"
N,0.941240478781284,"nX⊤X
t 
X†E
"
N,0.9423286180631121,"= E⊤
X†⊤
I −λ"
N,0.9434167573449401,"nX⊤X
t 
Σx −1"
N,0.9445048966267682,"nX⊤X
 
I −λ"
N,0.9455930359085963,"nX⊤X
t 
X†E
"
N,0.9466811751904244,"−2E⊤
X†⊤[Σx]

I −λ"
N,0.9477693144722524,"nX⊤X
t 
X†E
"
N,0.9488574537540805,"= E⊤
X†⊤
""
I −λ"
N,0.9499455930359086,"nX⊤X
t 
Σx −1"
N,0.9510337323177367,"nX⊤X

−2Σx"
N,0.9521218715995647,"# 
I −λ"
N,0.9532100108813928,"nX⊤X
t 
X†E

."
N,0.9542981501632208,"where we use the fact that

X†⊤X⊤X = X."
N,0.955386289445049,We next focus on the matrix
N,0.956474428726877,"Ma ≜

X†⊤
""
I −λ"
N,0.9575625680087051,"nX⊤X
t 
I −1"
N,0.9586507072905331,"nX⊤X

−2I"
N,0.9597388465723613,"# 
I −λ"
N,0.9608269858541894,"nX⊤X
t
X†,"
N,0.9619151251360174,where we plug in Σx = I by assumption. Denote the SVD of 1
N,0.9630032644178455,"nX⊤X as U ⊤ΣU where the i-th
eigenvalue is σi. Then when σi = 0, the i −th eigenvalue of Ma is also equal to zero (due to the
persudo inverse X†). When σi > 0, the i −th eigenvalue of Ma can be derived as"
N,0.9640914036996736,"σi(t; Ma) = [(1 −λσi)t(1 −σi) −2] (1 −λσi)t σi
."
N,0.9651795429815017,Its derivation is then
N,0.9662676822633297,"∂
∂tσi(t; Ma) = 2(1 −λσi)t log(1 −λσi) σi"
N,0.9673558215451578,"
(1 −σi)(1 −λσi)t −1

≥0,
(15)"
N,0.9684439608269858,"since log(1 −λσi) ≤0 and (1 −σi)(1 −λσi)t −1 ≤0. Therefore, the derivation of each eigenvalue
is larger than zero."
N,0.969532100108814,"We rewrite ¯∆v(t) = z⊤ΣMaz⊤where z⊤= UE is a vector independent of time t and ΣMa is the
diagonal matrix with diagonal σi(Ma). As a result, we have"
N,0.970620239390642,"∂
∂t
¯∆v(t) = z⊤( ∂"
N,0.9717083786724701,"∂tΣMa)z⊤≥0,"
N,0.9727965179542981,since ∂
N,0.9738846572361263,∂tΣMa ⪰0 according to Equation 15.
N,0.9749727965179543,Published as a conference paper at ICLR 2022
N,0.9760609357997824,"Note that ¯∆v(t) and ∆v(t) only differ with a term independent of time, we have"
N,0.9771490750816104,"∂
∂t∆v(t) = ∂"
N,0.9782372143634385,"∂t
¯∆v(t) ≥0. □"
N,0.9793253536452666,"F.3
MOTIVATION BEHIND DYNAMICS DECOMPOSITION CONDITION"
N,0.9804134929270947,"For a dataset S = {(Xi, yi)}n
i=1, where yi = fθ⋆(Xi) + εi, and θ⋆∈θ. We choose the ℓ2-loss
to solve this problem L(θ) =
1
2n
Pn
i=1 (fθ(Xi) −yi)2. Then we can show that the Dynamics
Decomposition Condition holds at the beginning phase if we initialize θ(0)
v
= 0, and assume
f0(X) = 0, ∀X ∈supp{P}. For sufficient small t > 0, the dynamics are well approximated by"
N,0.9815016322089227,"ˆθ(t) = θ(0) −1 n n
X"
N,0.9825897714907508,"i=1
(fθ(0)(Xi) −yi) ∇fθ(0)(Xi)t;"
N,0.9836779107725789,"ˆθ(t)
b
= θ(0)
b
−1 n n
X i=1"
N,0.984766050054407,"
fθ(0)
b (Xi) −fθ⋆(Xi)

∇fθ(0)
b (Xi)t;"
N,0.985854189336235,"ˆθ(t)
v
= θ(0)
v
−1 n n
X i=1"
N,0.9869423286180631,"
fθ(0)
v (Xi) −εi

∇fθ(0)
v (Xi)t. (16)"
N,0.9880304678998912,"Suppose θ(0) = θ(0)
b , then based on Taylor expansion, we have the approximation"
N,0.9891186071817193,"ˆθ(t) ≈ˆθ(t)
b
+ ˆθ(t)
v
+ 1 n n
X"
N,0.9902067464635473,"i=1
εi∇2fθ(0)(Xi)

θ(0)
v
−θ(0)
t ≈ˆθ(t)
b
+ ˆθ(t)
v .
(17)"
N,0.9912948857453754,"Therefore, the Dynamics Decomposition Condition holds at least at the beginning phase. Moreover,
we discuss in the main text that for a branch of learning tasks, such as linear regression and matrix
recovery, these Dynamics Decomposition Condition uniformly holds for arbitrary 0 ≤t < ∞."
N,0.9923830250272034,"F.4
RELAXED VERSION OF DDC"
N,0.9934711643090316,"One may notice that there exist θ∗, θ∗
v, θ∗
b in DDC (See Assumption 2), which is the optimal solution
to the corresponding population loss. They are sometimes unavailable in practice and even have no
explicit solution. For more convenient analysis, we propose a relaxed version of DDC in Lemma 10."
N,0.9945593035908596,"Lemma 10 (Relaxed DDC) Let the loss be ℓ2 loss where ℓ(y, ˆy) = (y −ˆy)2. We assume the
predicting model ˆy = f ˆθ(x) is unique with respect to ˆθ (when θi ̸= θj, fθi ̸= fθj). Besides, assume
fθ=0(x) = 0 for all x. For the ground truth, we assume an additive noise, namely, y = fθ∗(x) + ϵ
where ϵ is independent of x. Then the following Equation 18 suffices to prove (max{a, 1}, C, C′)-
boundedness for DDC (See Assumption 2)."
N,0.9956474428726877,"∥ˆθ(t) −ˆθ(t)
b ∥≤a∥ˆθ(t)
v ∥+ C
√"
N,0.9967355821545157,t + C′
N,0.9978237214363439,"√n.
(18)"
N,0.998911860718172,"Based on Lemma 10, one can verify DDC without knowing the optimal solution parameter θ∗, θ∗
v, θ∗
b.
Besides, since we usually have the iteration equation (the relationship between ˆθ(t+1) and ˆθ(t)) given
an algorithm, it is possible to verify DDC based on the iteration forms. Note that we may not directly
verify the condition in practice based on the relaxed DDC if we do not have the explicit split on signal
E[y|x] and noise y −E[y|x]."
