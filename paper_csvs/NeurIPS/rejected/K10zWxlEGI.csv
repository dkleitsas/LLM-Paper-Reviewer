Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0016420361247947454,"The advent of large-scale neural recordings has enabled new approaches that
1"
ABSTRACT,0.003284072249589491,"aim to discover the computational mechanisms of neural circuits by understand-
2"
ABSTRACT,0.0049261083743842365,"ing the rules that govern how their state evolves over time. While these neural
3"
ABSTRACT,0.006568144499178982,"dynamics cannot be directly measured, they can typically be approximated by
4"
ABSTRACT,0.008210180623973728,"low-dimensional models in a latent space. How these models represent the map-
5"
ABSTRACT,0.009852216748768473,"ping from latent space to neural space can affect the interpretability of the latent
6"
ABSTRACT,0.011494252873563218,"representation. Typical choices for this mapping (e.g., linear layer or MLP) lack the
7"
ABSTRACT,0.013136288998357963,"property of injectivity, meaning that changes in latent state may have no effect on
8"
ABSTRACT,0.014778325123152709,"neural activity. During training, non-injective readouts incentivize the invention of
9"
ABSTRACT,0.016420361247947456,"dynamics that misrepresent the underlying system and the computation it performs.
10"
ABSTRACT,0.0180623973727422,"Combining our injective Flow readout with prior work on interpretable latent dy-
11"
ABSTRACT,0.019704433497536946,"namics models, we created the Ordinary Differential equations autoencoder with
12"
ABSTRACT,0.021346469622331693,"Injective Nonlinear readout (ODIN), which learns to capture latent dynamical
13"
ABSTRACT,0.022988505747126436,"systems that are nonlinearly embedded into observed neural firing rates via an
14"
ABSTRACT,0.024630541871921183,"approximately injective nonlinear mapping. We show that ODIN can recover non-
15"
ABSTRACT,0.026272577996715927,"linearly embedded systems from simulated neural activity, even when the nature of
16"
ABSTRACT,0.027914614121510674,"the system and embedding are unknown. Additionally, we show that ODIN enables
17"
ABSTRACT,0.029556650246305417,"the unsupervised recovery of underlying dynamical features (e.g., fixed-points) and
18"
ABSTRACT,0.031198686371100164,"embedding geometry. When applied to biological neural recordings, ODIN can
19"
ABSTRACT,0.03284072249589491,"reconstruct neural activity with comparable accuracy to previous state-of-the-art
20"
ABSTRACT,0.034482758620689655,"methods while using substantially fewer latent dimensions. Overall, ODIN’s accu-
21"
ABSTRACT,0.0361247947454844,"racy in recovering ground-truth latent features and ability to accurately reconstruct
22"
ABSTRACT,0.03776683087027915,"neural activity with low dimensionality make it a promising method for distilling
23"
ABSTRACT,0.03940886699507389,"interpretable dynamics that can help explain neural computation.
24"
INTRODUCTION,0.041050903119868636,"1
Introduction
25"
INTRODUCTION,0.042692939244663386,"Recent evidence has shown that when artificial recurrent neural networks are trained to perform
26"
INTRODUCTION,0.04433497536945813,"tasks, the rules that govern how the internal activity evolves over time (i.e., the network dynamics)
27"
INTRODUCTION,0.04597701149425287,"can provide insight into how the network performs the underlying computation [1–4]. Given the
28"
INTRODUCTION,0.047619047619047616,"conceptual similarities between artificial neural networks and biological neural circuits, it may be
29"
INTRODUCTION,0.04926108374384237,"possible to apply these same dynamical analyses to brain activity to gain insight into how neural
30"
INTRODUCTION,0.05090311986863711,"circuits perform complex sensory, cognitive, and motor processes [5–7]. However, unlike in artificial
31"
INTRODUCTION,0.052545155993431854,"networks, we cannot easily interrogate the dynamics of biological neural circuits and must instead
32"
INTRODUCTION,0.054187192118226604,"estimate them from observed neural activity.
33"
INTRODUCTION,0.05582922824302135,"Fortunately, advances in recording technology have dramatically increased the number of neurons
34"
INTRODUCTION,0.05747126436781609,"that can be simultaneously recorded, providing ample data for novel population-level analyses of
35"
INTRODUCTION,0.059113300492610835,"neural activity [8–10]. In these datasets, the activity of hundreds or thousands of neurons can often
36"
INTRODUCTION,0.060755336617405585,"be captured by relatively low-dimensional subspaces [11], orders-of-magnitude smaller than the total
37"
INTRODUCTION,0.06239737274220033,"number of neurons. Neural activity in these latent spaces seems to evolve according to consistent sets
38"
INTRODUCTION,0.06403940886699508,"of rules (i.e., latent dynamics) [12, 6]. Assuming no external inputs, these rules can be expressed
39"
INTRODUCTION,0.06568144499178982,"mathematically as:
40"
INTRODUCTION,0.06732348111658457,"zt+1 = zt + f(zt)
(1)
yt = exp g(zt)
(2)
xt ∼Poisson(yt)
(3)"
INTRODUCTION,0.06896551724137931,"where zt ∈RD represents the latent state at time t, f(·) : RD →RD is the vector field governing the
41"
INTRODUCTION,0.07060755336617405,"dynamical system, yt ∈RN denotes the firing rates of the N neurons, g(·) : RD →RN maps latent
42"
INTRODUCTION,0.0722495894909688,"activity into log-firing rates, and xt ∈RN denotes the observed spike counts at time t, assuming the
43"
INTRODUCTION,0.07389162561576355,"spiking activity follows a Poisson distribution with time-varying rates given at each moment t by yt.
44"
INTRODUCTION,0.0755336617405583,"Unfortunately, any latent system can be equivalently described by many combinations of dynamics f
45"
INTRODUCTION,0.07717569786535304,"and embeddings g, which makes the search for a unique latent system futile. However, versions of a
46"
INTRODUCTION,0.07881773399014778,"latent system’s dynamics f and embedding g that are less complex and use fewer latent dimensions
47"
INTRODUCTION,0.08045977011494253,"can be much easier to interpret than alternative representations that are more complex and/or higher-
48"
INTRODUCTION,0.08210180623973727,"dimensional. Models of latent dynamics that can discover simple and low-dimensional representations
49"
INTRODUCTION,0.08374384236453201,"will make it easier to link latent dynamics to neural computation.
50"
INTRODUCTION,0.08538587848932677,"A popular approach to estimate neural dynamics [13–15] is to use neural population dynamics models
51"
INTRODUCTION,0.08702791461412152,"(NPDMs), which model neural activity as a latent dynamical system embedded into neural activity.
52"
INTRODUCTION,0.08866995073891626,"We refer to the components of an NPDM that learn the dynamics and embedding as the generator ˆf
53"
INTRODUCTION,0.090311986863711,"and the readout ˆg, respectively. When modeling neural activity, the generator and readout are jointly
54"
INTRODUCTION,0.09195402298850575,"trained to infer firing rates ˆy that maximize the likelihood of the observed neural activity x.
55"
INTRODUCTION,0.09359605911330049,"Using NPDMs to estimate underlying dynamics and embedding implicitly assumes that good recon-
56"
INTRODUCTION,0.09523809523809523,"struction performance (i.e., ˆx ≈x) implies interpretable estimates of the underlying system (i.e.,
57"
INTRODUCTION,0.09688013136288999,"ˆz ≈z, ˆf ≈f, ˆg ≈g). However, recent work has shown that when the state dimensionality of
58"
INTRODUCTION,0.09852216748768473,"the generator ˆD is larger than a system’s latent dimensionality D, high reconstruction performance
59"
INTRODUCTION,0.10016420361247948,"may actually correspond to estimates of the latent system that are overly complex or misleading
60"
INTRODUCTION,0.10180623973727422,"and therefore harder to interpret [15]. Thus at present, reconstruction performance is seemingly an
61"
INTRODUCTION,0.10344827586206896,"unreliable indicator for the interpretability of the learned dynamics.
62"
INTRODUCTION,0.10509031198686371,"This vulnerability to learning overly complex latent features might come from the fact that, in general,
63"
INTRODUCTION,0.10673234811165845,"changes in the latent state are not obligated to have an effect on predicted neural activity. Thus,
64"
INTRODUCTION,0.10837438423645321,"NPDMs can be rewarded for inventing latent activity that boosts reconstruction performance, even if
65"
INTRODUCTION,0.11001642036124795,"that latent activity has no direct correspondence to the neural activity. A potential solution is to make
66"
INTRODUCTION,0.1116584564860427,"the readout ˆg injective, which obligates all latent activity to affect neural reconstruction. This would
67"
INTRODUCTION,0.11330049261083744,"penalize any latent activity that is not reflected in the observed neural activity and puts pressure on
68"
INTRODUCTION,0.11494252873563218,"the generator ˆf and readout ˆg to learn a more interpretable (i.e., simpler and lower dimensional)
69"
INTRODUCTION,0.11658456486042693,"representation of the underlying system.
70"
INTRODUCTION,0.11822660098522167,"In addition, most previously used readouts ˆg were not expressive enough to model diverse mappings
71"
INTRODUCTION,0.11986863711001643,"from latent space to neural space, assuming the embedding g to be a relatively simple (often linear)
72"
INTRODUCTION,0.12151067323481117,"transformation (though there are exceptions [16–18]). Capturing nonlinear embeddings is important
73"
INTRODUCTION,0.12315270935960591,"because neural activity often lives on a lower-dimensional manifold that is nonlinearly embedded
74"
INTRODUCTION,0.12479474548440066,"into the higher-dimensional neural space [7]. Therefore, assumptions of linearity are likely to prevent
75"
INTRODUCTION,0.12643678160919541,"NPDMs from capturing dynamics in their simplest and lowest-dimensional form, making them less
76"
INTRODUCTION,0.12807881773399016,"interpretable than the latent features learned by NPDMs that can approximate these nonlinearities.
77"
INTRODUCTION,0.1297208538587849,"To address these challenges, we propose a novel architecture called the Ordinary Differential equa-
78"
INTRODUCTION,0.13136288998357964,"tion autoencoder with Injective Nonlinear readout (ODIN), which implements ˆf using a Neural
79"
INTRODUCTION,0.1330049261083744,"ODE (NODE [19]) and ˆg using a network inspired by invertible ResNets [20–22, 19, 23]. ODIN
80"
INTRODUCTION,0.13464696223316913,"approximates an injective nonlinear mapping between latent states and neural activity, obligating all
81"
INTRODUCTION,0.13628899835796388,"latent state variance to appear in the predicted neural activity and penalizing the model for inventing
82"
INTRODUCTION,0.13793103448275862,"excessively complex or high-dimensional dynamics. On synthetic data, ODIN learns representations
83"
INTRODUCTION,0.13957307060755336,"of the latent system that are more interpretable, with simpler and lower-dimensional latent activity and
84"
INTRODUCTION,0.1412151067323481,"dynamical features (e.g., fixed-points) than alternative readouts. ODIN’s interpretability is also more
85"
INTRODUCTION,0.14285714285714285,"robust to overestimates of latent dimensionality and can recover the nonlinear embedding of synthetic
86"
INTRODUCTION,0.1444991789819376,"data that evolves on a simulated manifold. When applied to neural activity from a monkey performing
87"
INTRODUCTION,0.14614121510673234,"a reaching task with obstacles, ODIN reconstructs neural activity comparably to state-of-the-art
88"
INTRODUCTION,0.1477832512315271,"recurrent neural network (RNN)-based models while requiring far fewer latent state dimensions.
89"
INTRODUCTION,0.14942528735632185,"In summary, ODIN estimates interpretable latent features from synthetic data and can reconstruct
90"
INTRODUCTION,0.1510673234811166,"biological neural recordings with high accuracy, making it a promising tool for understanding how
91"
INTRODUCTION,0.15270935960591134,"the brain performs computation.
92"
RELATED WORK,0.15435139573070608,"2
Related Work
93"
RELATED WORK,0.15599343185550082,"Many previous models have attempted to understand neural activity through the lens of neural
94"
RELATED WORK,0.15763546798029557,"dynamics. Early efforts limited model complexity by constraining both ˆf and ˆg to be linear [24–26].
95"
RELATED WORK,0.1592775041050903,"While these models were relatively straightforward to analyze, they often failed to adequately explain
96"
RELATED WORK,0.16091954022988506,"neural activity patterns [27].
97"
RELATED WORK,0.1625615763546798,"Other approaches increased the expressiveness of the modeled dynamics ˆf. RNNs can learn to
98"
RELATED WORK,0.16420361247947454,"approximate complex nonlinear dynamics, and have been shown to substantially outperform linear
99"
RELATED WORK,0.16584564860426929,"dynamics models in reconstructing neural activity [27]. Unfortunately, RNNs implicitly couple the
100"
RELATED WORK,0.16748768472906403,"capacity of the model to the latent state dimensionality, meaning their ability to model complex
101"
RELATED WORK,0.16912972085385877,"dynamics relies on having a high-dimensional latent state. In contrast, NODEs can model arbitrarily
102"
RELATED WORK,0.17077175697865354,"complex dynamics of embedded dynamical systems at the dimensionality of the system [19, 15].
103"
RELATED WORK,0.1724137931034483,"On synthetic data, NODEs have been shown to recover dynamics more accurately than RNN-
104"
RELATED WORK,0.17405582922824303,"based methods [28, 15]. In contrast to our approach, previous NODE-based models used a linear
105"
RELATED WORK,0.17569786535303777,"readout ˆg that lacks injectivity. This can make the accuracy of estimated latent activity vulnerable
106"
RELATED WORK,0.17733990147783252,"to overestimates of the latent dimensionality (i.e., when ˆD > D) and/or fail to capture potential
107"
RELATED WORK,0.17898193760262726,"nonlinearities in the embedding g.
108"
RELATED WORK,0.180623973727422,"Early efforts to allow greater flexibility in ˆg preserved linearity in ˆf, using feed-forward neural
109"
RELATED WORK,0.18226600985221675,"networks to nonlinearly embed linear dynamical systems in high-dimensional neural firing rates
110"
RELATED WORK,0.1839080459770115,"[16]. More recently, models have used Gaussian Processes to approximate nonlinear mappings
111"
RELATED WORK,0.18555008210180624,"from latent state to neural firing with tuning curves [17]. Other models have combined nonlinear
112"
RELATED WORK,0.18719211822660098,"dynamics models and nonlinear embeddings for applications in behavioral tracking [29] and neural
113"
RELATED WORK,0.18883415435139572,"reconstruction [18]. Additional approaches extend these methods to incorporate alternative noise
114"
RELATED WORK,0.19047619047619047,"models that may better reflect the underlying firing properties of neurons [16, 30]. While nonlinear,
115"
RELATED WORK,0.1921182266009852,"the readouts of these models lacked injectivity in their mapping from latent activity to neural activity.
116"
RELATED WORK,0.19376026272577998,"Many alternative models seek to capture interpretable latent features of a system from observations.
117"
RELATED WORK,0.19540229885057472,"One popular approach uses a sparsity penalty on a high-dimensional basis set to derive a sparse
118"
RELATED WORK,0.19704433497536947,"symbolic estimate of the governing equations for the system [31]. However, it is unclear whether
119"
RELATED WORK,0.1986863711001642,"such sparse symbolic representation is necessarily a benefit when modeling dynamics in the brain.
120"
RELATED WORK,0.20032840722495895,"Another recent model uses contrastive loss and auxiliary behavioral variables to learn low-dimensional
121"
RELATED WORK,0.2019704433497537,"representations of latent activity [32]. This approach does not have an explicit dynamics model,
122"
RELATED WORK,0.20361247947454844,"however, so is not amenable to the dynamical analyses performed in this manuscript.
123"
RELATED WORK,0.20525451559934318,"Normalizing flows – a type of invertible neural network – have recently become a staple for generative
124"
RELATED WORK,0.20689655172413793,"modeling and density estimation [20, 23]. Some latent variable models have used invertible networks
125"
RELATED WORK,0.20853858784893267,"to approximate the mapping from the latent space to neural activity [33] or for generative models of
126"
RELATED WORK,0.21018062397372742,"visual cortex activity [34]. To allow this mapping to change dimensionality between the latent space
127"
RELATED WORK,0.21182266009852216,"and neural activity, some of these models used a zero-padding procedure similar to the padding used
128"
RELATED WORK,0.2134646962233169,"in this manuscript (see Section 3.3.1), which makes the transformation injective rather than invertible
129"
RELATED WORK,0.21510673234811165,"[33, 23]. However, these previous approaches did not have explicit dynamics models, making our
130"
RELATED WORK,0.21674876847290642,"study, to our knowledge, the first to test whether injective readouts can improve the interpretability of
131"
RELATED WORK,0.21839080459770116,"neural population dynamics models.
132"
METHODS,0.2200328407224959,"3
Methods
133"
SYNTHETIC NEURAL DATA,0.22167487684729065,"3.1
Synthetic Neural Data
134"
SYNTHETIC NEURAL DATA,0.2233169129720854,"To determine whether different models can distill an interpretable latent system from observed
135"
SYNTHETIC NEURAL DATA,0.22495894909688013,"population activity, we first used reference datasets that were generated using simple ground-truth
136"
SYNTHETIC NEURAL DATA,0.22660098522167488,"dynamics f and embedding g. Our synthetic test cases emulate the empirical properties of neural
137"
SYNTHETIC NEURAL DATA,0.22824302134646962,"systems, specifically low-dimensional latent dynamics observed through noisy spiking activity [13, 35–
138"
SYNTHETIC NEURAL DATA,0.22988505747126436,"37]. We sampled latent trajectories from the Arneodo system (f, D = 3) and nonlinearly embedded
139"
SYNTHETIC NEURAL DATA,0.2315270935960591,"these trajectories into neural activity via an embedding g. We consider models that can recover the
140"
SYNTHETIC NEURAL DATA,0.23316912972085385,"dynamics f and embedding g used to generate these data as providing an interpretable description of
141"
SYNTHETIC NEURAL DATA,0.2348111658456486,"Figure 1: A) Synthetic neural data generation (left to right). Trajectories from the Arneodo system
are projected onto random encoding vectors to compute activations at each timepoint. A scaled
sigmoid nonlinearity is applied to convert the activations into firing rates. B) Zero-padded latent
dynamics (green) are reversibly warped into higher-dimensional neural activity space (blue). C) The
Flow readout maps from latent space to neural space by applying a sequence of K small updates
(parameterized by an MLP, bottom). Reverse pass maps from neural space to latent space and is
implemented by serial subtraction of updates from the same MLP."
SYNTHETIC NEURAL DATA,0.23645320197044334,"the latent system and its relation to the neural activity. Additional detail on data generation, models,
142"
SYNTHETIC NEURAL DATA,0.23809523809523808,"and metrics can be found in the Supplementary Material.
143"
SYNTHETIC NEURAL DATA,0.23973727422003285,"We generated activations for N neurons (N = 12) by projecting the simulated latent trajectories Z
144"
SYNTHETIC NEURAL DATA,0.2413793103448276,"through a 3 × N matrix whose columns were random encoding vectors with elements sampled from a
145"
SYNTHETIC NEURAL DATA,0.24302134646962234,"uniform distribution U[−0.5, 0.5] (Fig. 1A, left). We standardized these activations to have zero mean
146"
SYNTHETIC NEURAL DATA,0.24466338259441708,"and unit variance and applied a different scaled sigmoid function to each neuron, yielding a matrix of
147"
SYNTHETIC NEURAL DATA,0.24630541871921183,"non-negative time-varying firing rates Y. The scaling of each sigmoid function was evenly spaced on
148"
SYNTHETIC NEURAL DATA,0.24794745484400657,"a logarithmic scale between 100.2 and 10. This process created a diverse set of activation functions
149"
SYNTHETIC NEURAL DATA,0.24958949096880131,"ranging from quasi-linear to nearly step-function-like behavior (Fig. 1A, Activation Functions).
150"
SYNTHETIC NEURAL DATA,0.2512315270935961,"We simulated spiking activity X by sampling from inhomogeneous Poisson processes with time-
151"
SYNTHETIC NEURAL DATA,0.25287356321839083,"varying rate parameters equal to the firing rate Y of the simulated neurons (Fig. 1A, right). We
152"
SYNTHETIC NEURAL DATA,0.2545155993431856,"randomly split 70-point segments of these trials into training and validation datasets (training and
153"
SYNTHETIC NEURAL DATA,0.2561576354679803,"validation proportions were 0.8 and 0.2, respectively).
154"
BIOLOGICAL NEURAL DATA,0.25779967159277506,"3.2
Biological Neural Data
155"
BIOLOGICAL NEURAL DATA,0.2594417077175698,"We evaluated how well our model could reconstruct biological neural activity on a well-characterized
156"
BIOLOGICAL NEURAL DATA,0.26108374384236455,"dataset [38] included in the Neural Latents Benchmark (NLB) [27]. This dataset is composed of
157"
BIOLOGICAL NEURAL DATA,0.2627257799671593,"single-unit recordings from primary and pre-motor cortices of a monkey performing a visually-guided
158"
BIOLOGICAL NEURAL DATA,0.26436781609195403,"reaching task with obstacles, referred to as the Maze task. Trials were trimmed to the window [-250,
159"
BIOLOGICAL NEURAL DATA,0.2660098522167488,"350] ms relative to movement onset, and spiking activity was binned at 20 ms. To compare the
160"
BIOLOGICAL NEURAL DATA,0.2676518883415435,"reconstruction performance of our model directly against the benchmark, we split the neural activity
161"
BIOLOGICAL NEURAL DATA,0.26929392446633826,"into held-in and held-out neurons, comprising 137 and 35 neurons, respectively, using the same sets
162"
BIOLOGICAL NEURAL DATA,0.270935960591133,"of neurons as were used to assess models for the NLB leaderboard.
163"
MODEL ARCHITECTURE,0.27257799671592775,"3.3
Model Architecture
164"
MODEL ARCHITECTURE,0.2742200328407225,"We used three sequential autoencoder (SAE) variants in this study, with the main difference be-
165"
MODEL ARCHITECTURE,0.27586206896551724,"ing the choice of readout module, ˆg(·). In brief, a sequence of binned spike counts x1:T was
166"
MODEL ARCHITECTURE,0.277504105090312,"passed through a bidirectional GRU encoder, whose final hidden states were converted to an initial
167"
MODEL ARCHITECTURE,0.2791461412151067,"condition ˆz0 via a mapping ϕ(·). A modified NODE generator unrolled the initial condition into
168"
MODEL ARCHITECTURE,0.28078817733990147,"time-varying latent states ˆz1:T . These were subsequently mapped to inferred rates via the readout
169"
MODEL ARCHITECTURE,0.2824302134646962,"ˆg(·) ∈{Linear, MLP, Flow}. All models were trained for a fixed number of epochs to infer firing
170"
MODEL ARCHITECTURE,0.28407224958949095,"rates ˆy1:T that minimize the negative Poisson log-likelihood of the observed spikes x1:T .
171"
MODEL ARCHITECTURE,0.2857142857142857,"hT =

hfwd
hbwd

= BiGRU(x1:T )
(4)"
MODEL ARCHITECTURE,0.28735632183908044,"ˆz0 = ϕ(hT )
(5)
ˆzt+1 = ˆzt + α · MLP(ˆzt)
(6)
ˆyt = exp ˆg(ˆzt)
(7)"
MODEL ARCHITECTURE,0.2889983579638752,"For models with Linear and MLP readouts, ϕ(·) was a linear map to R ˆ
D. For models with Flow
172"
MODEL ARCHITECTURE,0.29064039408866993,"readouts, ϕ(·) was a linear map to RN followed by the reverse pass of the Flow (see Section 3.3.1).
173"
MODEL ARCHITECTURE,0.2922824302134647,"We unrolled the NODE using Euler’s method with a fixed step size equal to the bin width and trained
174"
MODEL ARCHITECTURE,0.2939244663382594,"using standard backpropagation for efficiency. A scaling factor (α = 0.1) was applied to the output
175"
MODEL ARCHITECTURE,0.2955665024630542,"of the NODE’s MLP to stabilize the dynamics during early training. Readouts were implemented as
176"
MODEL ARCHITECTURE,0.29720853858784896,"either a single linear layer (Linear), an MLP with two 150-unit ReLU hidden layers (MLP), or a Flow
177"
MODEL ARCHITECTURE,0.2988505747126437,"readout (Flow) which contains an MLP with two 150-unit ReLU hidden layers. We refer to these
178"
MODEL ARCHITECTURE,0.30049261083743845,"three models as Linear-NODE, MLP-NODE, and ODIN, respectively.
179"
FLOW READOUT,0.3021346469622332,"3.3.1
Flow Readout
180"
FLOW READOUT,0.30377668308702793,"The Flow readout resembles a simplified invertible ResNet [23]. Flow learns a vector field that can
181"
FLOW READOUT,0.3054187192118227,"reversibly transform data between latent and neural representations (Figure 1B). The Flow readout
182"
FLOW READOUT,0.3070607553366174,"has three steps: first, we increase the dimensionality of the latent activity zt to match that of the
183"
FLOW READOUT,0.30870279146141216,"neural activity by padding the latent state with zeros. This corresponds to an initial estimate of
184"
FLOW READOUT,0.3103448275862069,"the log-firing rates, log ˆyt,0. Note that zero-padding makes our mapping injective rather than fully
185"
FLOW READOUT,0.31198686371100165,"invertible (see [33, 23]). The Flow network then uses an MLP to iteratively refine log ˆyt,k over K
186"
FLOW READOUT,0.3136288998357964,"steps (K = 20) after which we apply an exponential to produce the final firing rate predictions, ˆyt.
187"
FLOW READOUT,0.31527093596059114,"A scaling factor (β = 0.1) was applied to the output of the Flow’s MLP to stabilize the dynamics
188"
FLOW READOUT,0.3169129720853859,"during early training.
189"
FLOW READOUT,0.3185550082101806,"log ˆyt,0 = [ˆzt|0]T
(8)
log ˆyt,k+1 = log ˆyt,k + β · MLP(log ˆyt,k)
(9)
ˆg (ˆzt) = log ˆyt,K = log ˆyt
(10)"
FLOW READOUT,0.32019704433497537,"We also use the approximate inverse of the Flow to transform the output of the encoders to initial
190"
FLOW READOUT,0.3218390804597701,"conditions in the latent space via ϕ(·). We approximate the inverse using a simplified version of
191"
FLOW READOUT,0.32348111658456485,"the fixed-point iteration procedure described in [23]. Our method subtracts the output of the MLP
192"
FLOW READOUT,0.3251231527093596,"from the state rather than adding it as in the forward mode (Fig 1C). From here, we trim the excess
193"
FLOW READOUT,0.32676518883415434,"dimensions to recover ˆz ∈R ˆ
D (in effect, removing the zero-padding dimensions).
194"
FLOW READOUT,0.3284072249589491,"log ˆyt,k−1 = log ˆyt,k −β · MLP(log ˆyt,k)
(11)"
FLOW READOUT,0.33004926108374383,"ˆg−1 (log ˆyt) = [log ˆyt,0,1, . . . , log ˆyt,0, ˆ
D]T = ˆzt
(12)"
FLOW READOUT,0.33169129720853857,"The Flow mapping is only guaranteed to be injective if changes in the output of the MLP are
195"
FLOW READOUT,0.3333333333333333,"sufficiently small relative to changes in the input (i.e., Lipschitz constants for the MLP that is
196"
FLOW READOUT,0.33497536945812806,"strictly less than 1) [23]. The model can be made fully injective by either restricting the weights
197"
FLOW READOUT,0.3366174055829228,"of the MLP (e.g., spectral norm [39]), or using a variable step-size ODE solver that can prevent
198"
FLOW READOUT,0.33825944170771755,"crossing trajectories (e.g., continuous normalizing flows [19]. In practice, we found that using a
199"
FLOW READOUT,0.3399014778325123,"moderate number of steps allows Flow to preserve approximate injectivity of the readout at all tested
200"
FLOW READOUT,0.3415435139573071,"dimensionalities (Supp. Fig. 1).
201"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.34318555008210183,"3.4
Metrics and characterization of dynamics
202"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3448275862068966,"All metrics were evaluated on validation data. Reconstruction performance for the synthetic data was
203"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3464696223316913,"assessed using two key metrics. The first, spike negative log-likelihood (Spike NLL), was defined
204"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.34811165845648606,"as the Poisson NLL employed during model training. The second, Rate R2, was the coefficient of
205"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3497536945812808,"determination between the inferred and true firing rates, averaged across neurons. We used Spike
206"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.35139573070607555,"NLL to assess how well the inferred rates explain the spiking activity, while Rate R2 reflects the
207"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3530377668308703,"model’s ability to find the true firing rates. These metrics quantify how well the model captures
208"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.35467980295566504,"the embedded system’s dynamics (i.e., that ˆf captures the system described by f), but give no
209"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3563218390804598,"indication of the interpretability of the learned latent representation (i.e., that the learned ˆf is simple
210"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3579638752052545,"and low-dimensional).
211"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.35960591133004927,"To assess the interpretability of the latent activity inferred by the model ˆz, we used a previously
212"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.361247947454844,"published metric called the State R2 [15]. State R2 is defined as the coefficient of determination (R2)
213"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.36288998357963875,"of a linear regression from simulated latent trajectories z to the inferred latent trajectories ˆz. State R2
214"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3645320197044335,"will be low if the inferred latent trajectories contain features that cannot be explained by an affine
215"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.36617405582922824,"transformation of the true latent trajectories. We use this to assess the degree to which models can
216"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.367816091954023,"preserve the simplicity and low dimensionality of the embedded dynamics, thereby maintaining an
217"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3694581280788177,"interpretable latent representation. Together, high Rate R2 and State R2 indicate that the modeled
218"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.37110016420361247,"latent activity reflects the simulated latent dynamics without inventing extra features that make the
219"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3727422003284072,"model harder to interpret (i.e., ˆz ≈z).
220"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.37438423645320196,"Figure 2: Flow-NODE (ODIN) recovers latent activity more accurately than alternative models and
is robust to overestimates of latent dimensionality. A) Diagram of model readouts tested, including
Linear (green), Flow (red), MLP (orange). B) Inferred latent activity of representative model at each
state dimensionality ˆD. True latent activity (affine-transformed to overlay inferred latent activity)
shown in light blue. C) All: Model metrics as a function of ˆD. Shaded areas represent one standard
deviation around the mean. Dashed vertical line indicates ˆD = 3 Top: Spike NLL, Middle: Rate R2,
Bottom: State R2."
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3760262725779967,"As a direct comparison of the estimated dynamics ˆf to the simulated dynamics f, we extracted
221"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.37766830870279144,"the fixed-point (FP) structure from our trained models and compared it to the FP structure of the
222"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3793103448275862,"underlying system. We used previously published FP-finding techniques [40] to identify regions of
223"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.38095238095238093,"the generator’s dynamics where the magnitude of the vector field was close to zero, calling this set of
224"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3825944170771757,"locations the putative FPs. We linearized the dynamics around the FPs and computed the eigenvalues
225"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3842364532019704,"of the Jacobian of ˆf to characterize each FP. Capturing FP location and character gives an indication
226"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.38587848932676516,"of how closely the estimated dynamics resemble the simulated dynamics (i.e., ˆf ≈f).
227"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.38752052545155996,"To determine how well our embedding ˆg captures the simulated embedding g, we projected the
228"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3891625615763547,"encoding vectors used to generate the synthetic neural activity from the ground-truth system into our
229"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.39080459770114945,"model’s latent space using the same affine transformation from ground-truth latent activity to inferred
230"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3924466338259442,"latent activity as was used to compute State R2. We projected the inferred latent activity onto each
231"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.39408866995073893,"neuron’s affine-transformed encoding vector to find the predicted activation of each synthetic neuron.
232"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3957307060755337,"We then related the predicted firing rates of each neuron to its corresponding activations to derive
233"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.3973727422003284,"an estimate of each neuron’s activation function. Because the inferred latent activity is arbitrarily
234"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.39901477832512317,"scaled/translated relative to the true latent activity, we fit an affine transformation from the predicted
235"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.4006568144499179,"activation function to the ground-truth activation function. The coefficient of determination R2 of
236"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.40229885057471265,"this fit quantifies how well our models were able to recover the synthetic warping applied to each
237"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.4039408866995074,"neuron (i.e., ˆg ≈g).
238"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.40558292282430214,"For the biological neural data, we measured model performance using two metrics from the Neural
239"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.4072249589490969,"Latents Benchmark (NLB) [27], co-smoothing bits-per-spike (co-bps) and velocity decoding perfor-
240"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.4088669950738916,"mance on predicted firing rates (Vel R2). co-bps quantifies how well the model predicts the spiking of
241"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.41050903119868637,"the held-out neurons, while Vel R2 quantifies how well the denoised rates can predict the monkey’s
242"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.4121510673234811,"hand velocity during the reach. We compare these metrics to models from the NLB leaderboard. Of
243"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.41379310344827586,"note, models submitted to NLB are assessed by their performance on a hidden test set, while our
244"
METRICS AND CHARACTERIZATION OF DYNAMICS,0.4154351395730706,"model performance is computed on the validation data.
245"
RESULTS,0.41707717569786534,"4
Results
246"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.4187192118226601,"4.1
Finding interpretable latent activity across state dimensionalities with ODIN
247"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.42036124794745483,"We began by training Linear-, MLP-, and Flow-NODEs (i.e., ODIN) (Fig 2A) to reconstruct synthetic
248"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.4220032840722496,"neural activity from the Arneodo system [41] and compared reconstruction performance (i.e. Spike
249"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.4236453201970443,"NLL and Rate R2) and latent recovery (i.e. State R2) as functions of the dimensionality ˆD of
250"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.42528735632183906,"the state space. We trained 5 different random seeds for each of the 3 model types and 5 state
251"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.4269293924466338,"dimensionalities (75 total models, model hyperparameters in Supp. Table 1). First, we observed that
252"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.42857142857142855,"the Linear-NODE learned latent states that did not closely resemble the simulated latent activity, with
253"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.4302134646962233,"all tested dimensionalities performing worse than either the Flow or the MLP readout at ˆD = 3 (Fig
254"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.4318555008210181,"2B,C, mean State R2 = 0.70 for Linear vs. 0.89, 0.93 for MLP, Flow respectively). We also found
255"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.43349753694581283,"that Linear-NODE required many more dimensions to reach the peak reconstruction performance
256"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.4351395730706076,"Figure 3: Flow-NODE (ODIN) recovers fixed-point properties accurately at the correct dimensionality.
A,B) Representative latent activity and fixed-points from the true (blue, ◦), ODIN (red, ×), and Linear
(green, +) systems. Each fixed point is labeled with reference to C. C) Plots of the real vs. imaginary
part of the eigenvalues of the Jacobian evaluated at each fixed point. Unit circle in the complex plane
(black curve) shows boundary between attractive and repulsive behavior (the attractive and repulsive
sides of the boundary are indicated by inset)."
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.4367816091954023,"(Fig 2C, Rate R2). These results demonstrate that models that are unable to account for nonlinear
257"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.43842364532019706,"embeddings are vulnerable to learning more complex and higher dimensional dynamics than those
258"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.4400656814449918,"learned by models with nonlinear readouts.
259"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.44170771756978655,"Next, we compared ODIN to MLP-NODE and found that at the correct dimensionality ( ˆD = 3),
260"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.4433497536945813,"these models had similar performance for both reconstruction and latent recovery. However, we found
261"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.44499178981937604,"that as the dimensionality increased beyond the true dimensionality ( ˆD > 3), the latent recovery of
262"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.4466338259441708,"the MLP-NODE degraded rapidly while ODIN’s latent recovery remained high (Fig 2C, as ˆD > 3).
263"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.4482758620689655,"This result provides evidence that readouts that lack injectivity (like MLPs) tend to learn misleading
264"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.44991789819376027,"latent activity that can make their representations less interpretable when the true dimensionality ˆD is
265"
FINDING INTERPRETABLE LATENT ACTIVITY ACROSS STATE DIMENSIONALITIES WITH ODIN,0.451559934318555,"unknown.
266"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.45320197044334976,"4.2
Recovering fixed-point structure with ODIN
267"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.4548440065681445,"A common method to compare how well dynamics models capture the underlying dynamics from
268"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.45648604269293924,"synthetic data is to examine the character and structure of the inferred fixed-points (FPs) to the FPs
269"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.458128078817734,"of the ground-truth system[15]. At a high-level, FPs enable a concise description of the dynamics
270"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.45977011494252873,"in a small region of state-space around the FP, and can collectively provide a qualitative picture of
271"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.4614121510673235,"the overall dynamical landscape. To obtain a set of candidate FPs, we searched the latent space for
272"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.4630541871921182,"points at which the magnitude of the vector field ∥ˆf∥is minimized (as in [1, 40]). We computed the
273"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.46469622331691296,"eigenvalues (λs) of the Jacobian of ˆf at each FP location. The real and imaginary components of
274"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.4663382594417077,"these eigenvalues identify each FP as attractive, repulsive, etc.
275"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.46798029556650245,"We found that 3D ODIN models and 3D Linear-NODEs were both able to recover three fixed-points
276"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.4696223316912972,"that generally matched the location of the three fixed points of the Arneodo system (Fig 3A), However,
277"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.47126436781609193,"while ODIN was also able to capture the eigenspectra of all three FPs (Fig. 3B, red ×), the Linear-
278"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.4729064039408867,"NODE failed to capture the rotational dynamics of the central FP (Fig 3B, middle column, green +).
279"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.4745484400656814,"Both models were able to approximately recover the eigenspectra of outermost FPs of the system
280"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.47619047619047616,"(Fig. 3B, left, right columns). We found that the MLP-NODE was also able to find FPs with similar
281"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.47783251231527096,"accuracy to ODIN at 3D. These results show that the inability to model the nonlinear embedding can
282"
RECOVERING FIXED-POINT STRUCTURE WITH ODIN,0.4794745484400657,"lead to impoverished estimates of the underlying dynamics ˆf.
283"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.48111658456486045,"4.3
Recovering simulated activation functions with ODIN
284"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.4827586206896552,"Figure 4: Flow-NODE (ODIN) can re-
cover nonlinear activation functions of
neurons. A) True encoding vectors
(numbered lines over true latent ac-
tivity (blue)) were affine-transformed
into a representative model’s latent
space. B) Inferred activation function
for two example neurons (columns),
color coded by readout type (Linear
= green, MLP = orange, Flow = red,
True = black). Plots show the predicted
firing rate vs. the activation of the se-
lected neuron. C) Comparison of the
R2 values of the fits from B across
model types. Left: Flow vs. MLP.
Right: Flow vs. Linear"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.48440065681444994,"While obtaining interpretable dynamics is our primary goal,
285"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.4860426929392447,"models that allow unsupervised recovery of the embedding
286"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.4876847290640394,"geometry may provide additional insight about the compu-
287"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.48932676518883417,"tations performed by the neural system [42, 7]. For this
288"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.4909688013136289,"section, we considered a representative model from each
289"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.49261083743842365,"readout class with the correct number of latent dimensions
290"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.4942528735632184,"(D = 3). We performed an affine transformation from the
291"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.49589490968801314,"ground truth encoding vectors into the modeled latent space
292"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.4975369458128079,"and computed the projection of the modeled latent activ-
293"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.49917898193760263,"ity onto the affine-transformed encoding vectors (Fig 4A).
294"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5008210180623974,"From this projection, we derived an estimate of the activa-
295"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5024630541871922,"tion function for each neuron, and compared this estimate
296"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5041050903119869,"to the ground-truth activation function.
297"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5057471264367817,"We found, as expected, that the linear readout was unable to
298"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5073891625615764,"approximate the sigmoidal activation function of individual
299"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5090311986863711,"neurons (Fig 4B, green). On the other hand, both ODIN
300"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5106732348111659,"and MLP-NODE were able to capture activation functions
301"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5123152709359606,"ranging from nearly linear to step function-like in nature
302"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5139573070607554,"(Fig 4B, red, orange). Across all simulated neurons, we
303"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5155993431855501,"found that ODIN more accurately estimated the activation
304"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5172413793103449,"function of individual neurons compared to both Linear- and
305"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5188834154351396,"MLP-NODEs (Fig 4C), suggesting that the injectivity of the
306"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5205254515599343,"Flow readout allows more accurate estimation of nonlinear
307"
RECOVERING SIMULATED ACTIVATION FUNCTIONS WITH ODIN,0.5221674876847291,"embeddings.
308"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5238095238095238,"4.4
Modeling motor cortical activity with ODIN
309"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5254515599343186,"To validate ODIN’s ability to fit neural activity from a bio-
310"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5270935960591133,"logical neural circuit, we applied ODIN to the Maze dataset
311"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5287356321839081,"from the Neural Latents Benchmark, composed of record-
312"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5303776683087028,"ings from the motor and pre-motor cortices of a monkey
313"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5320197044334976,"performing a reaching task (Fig. 5A). After performing hy-
314"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5336617405582923,"perparameter sweeps across regularization parameters and
315"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.535303776683087,"network size (Supp. Table 2), we trained a set of ODIN
316"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5369458128078818,"and Linear-NODE models to reconstruct the neural activity
317"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5385878489326765,"with a range of state dimensionalities ˆD. We visualized
318"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5402298850574713,"the top 3 PCs of the condition-averaged latent trajectories
319"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.541871921182266,"and predicted single-neuron firing rates for example models
320"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5435139573070608,"from each readout type. We found no visually obvious differences in the inferred latent trajectories
321"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5451559934318555,"(Fig. 5B), but when we computed condition-averaged peri-stimulus time histograms (PSTHs) of
322"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5467980295566502,"single neuron firing rates, we found that ODIN typically produced firing rate estimates that more
323"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.548440065681445,"closely resembled the empirical PSTHs than those from the Linear-NODE (Fig. 5C).
324"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5500821018062397,"Without access to a ground truth dynamics f and embedding g that generated these biological data, the
325"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5517241379310345,"dimensionality required to reconstruct the neural activity was our primary measure of interpretability.
326"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5533661740558292,"We computed co-bps –a measure of reconstruction performance on held-out neurons– for each model
327"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.555008210180624,"and found that 10D ODIN models substantially outperformed Linear-NODE models, even when the
328"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5566502463054187,"Linear-NODE had more than twice as many dimensions (10D ODIN: 0.333, vs 25D Linear: 0.287).
329"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5582922824302134,"This suggests that ODIN’s injective non-linear readout is effective at reducing the required latent
330"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5599343185550082,"state dimensionality to capture the data relative to a simple linear readout.
331"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5615763546798029,"We also compared ODIN to other models on the NLB leaderboard for this dataset [27, 43]. The best
332"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5632183908045977,"reported AutoLFADS model (a RNN-based variational SAE with ˆD = 100) had only modestly higher
333"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5648604269293924,"co-bps than the 10D ODIN (0.333 vs 0.355) [44]. These results suggest that ODIN is effective at
334"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5665024630541872,"reducing the required dimensionality for neural reconstruction, which may provide more interpretable
335"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5681444991789819,"latent representations than alternative models.
336"
MODELING MOTOR CORTICAL ACTIVITY WITH ODIN,0.5697865353037767,"Figure 5: ODIN can reconstruct cortical activity with low-dimensional dynamics A) Top: Schematic
of task [38] Bottom: example hand trajectories and condition-averaged firing rates aligned to move
onset. B) Example condition-averaged latent activity from ODIN and Linear-NODE models ap-
plied to neural activity recorded during the Maze task. C) Example single-neuron peri-stimulus
time histograms for ODIN and Linear-NODE models across conditions. D) Effects of latent state
dimensionality ˆD on reconstruction (top, co-bps) and decoding (bottom, Vel R2) performance. Plot
shows mean (point) and standard deviation (shading) of 5 randomly initialized models at each ˆD.
Horizontal lines represent NLB performance by AutoLFADS (black) and GFPA (grey) [27]."
DISCUSSION,0.5714285714285714,"5
Discussion
337"
DISCUSSION,0.5730706075533661,"Dynamics models have had great success in reproducing neural activity patterns and relating brain
338"
DISCUSSION,0.5747126436781609,"activity to behavior [45, 27, 46]. However, it has been difficult to use these models to investigate neural
339"
DISCUSSION,0.5763546798029556,"computation directly. If neural population models could be trusted to find interpretable representations
340"
DISCUSSION,0.5779967159277504,"of latent dynamics, then recent techniques that can uncover computation in artificial networks could
341"
DISCUSSION,0.5796387520525451,"help to explain computations in the brain [1, 40, 47]. In this work, we created a new model called
342"
DISCUSSION,0.5812807881773399,"ODIN that can overcome major barriers to learning interpretable latent dynamical systems. By
343"
DISCUSSION,0.5829228243021346,"combining Neural ODE generators and approximately injective nonlinear readouts, ODIN offers
344"
DISCUSSION,0.5845648604269293,"significant advantages over the prior state-of-the-art, including lower latent dimensionality, simpler
345"
DISCUSSION,0.5862068965517241,"latent activity that is robust to the choice of latent dimensionality, and the ability to model arbitrary
346"
DISCUSSION,0.5878489326765188,"nonlinear activation functions.
347"
DISCUSSION,0.5894909688013136,"Circuits in the brain are densely interconnected, and so a primary limitation of this work is that
348"
DISCUSSION,0.5911330049261084,"ODIN is not yet able to account for inputs to the system that may be coming from areas that are not
349"
DISCUSSION,0.5927750410509032,"directly modeled. Thus ODIN is currently only able to model the dynamics of a given population of
350"
DISCUSSION,0.5944170771756979,"neurons as an autonomous system. Inferring inputs is difficult due to ambiguity in the role of inputs
351"
DISCUSSION,0.5960591133004927,"compared to internal dynamics for driving the state of the system. While some RNN-based models
352"
DISCUSSION,0.5977011494252874,"have methods for input inference [45], more work is needed to develop solutions for NODE-based
353"
DISCUSSION,0.5993431855500821,"models. Injective readouts are an important step towards addressing the fundamental difficulties of
354"
DISCUSSION,0.6009852216748769,"input inference, as models without injective readouts can be incentivized to imagine latent features
355"
DISCUSSION,0.6026272577996716,"that are actually the result of inputs.
356"
DISCUSSION,0.6042692939244664,"Interpretable dynamics derived from neural population recordings could answer critical scientific
357"
DISCUSSION,0.6059113300492611,"questions about the brain and help improve brain-machine interface technology. A potential negative
358"
DISCUSSION,0.6075533661740559,"consequence is that human neural interfaces combined with an understanding of neural computation
359"
DISCUSSION,0.6091954022988506,"might make it possible and profitable to develop strategies that are effective at influencing behavior.
360"
DISCUSSION,0.6108374384236454,"Future researchers should focus on applications of this research that are scientific and medical rather
361"
DISCUSSION,0.6124794745484401,"than commercial or political.
362"
REFERENCES,0.6141215106732348,"References
363"
REFERENCES,0.6157635467980296,"[1] David Sussillo and Omri Barak. Opening the black box: low-dimensional dynamics in high-
364"
REFERENCES,0.6174055829228243,"dimensional recurrent neural networks. Neural Computation, 25(3):626–649, March 2013.
365"
REFERENCES,0.6190476190476191,"ISSN 1530-888X. doi: 10.1162/NECO_a_00409.
366"
REFERENCES,0.6206896551724138,"[2] Valerio Mante, David Sussillo, Krishna Shenoy, and William Newsome. Context-dependent
367"
REFERENCES,0.6223316912972086,"computation by recurrent dynamics in prefrontal cortex. Nature, 503:78–84, November 2013.
368"
REFERENCES,0.6239737274220033,"doi: 10.1038/nature12742.
369"
REFERENCES,0.625615763546798,"[3] Evan D. Remington, Devika Narain, Eghbal A. Hosseini, and Mehrdad Jazayeri. Flexible
370"
REFERENCES,0.6272577996715928,"Sensorimotor Computations through Rapid Reconfiguration of Cortical Dynamics. Neuron, 98
371"
REFERENCES,0.6288998357963875,"(5):1005–1019.e5, June 2018. ISSN 1097-4199. doi: 10.1016/j.neuron.2018.05.020.
372"
REFERENCES,0.6305418719211823,"[4] Niru Maheswaranathan, Alex Williams, Matthew Golub, Surya Ganguli, and David Sus-
373"
REFERENCES,0.632183908045977,"sillo.
Reverse engineering recurrent networks for sentiment classification reveals line at-
374"
REFERENCES,0.6338259441707718,"tractor dynamics. In Advances in Neural Information Processing Systems, volume 32. Cur-
375"
REFERENCES,0.6354679802955665,"ran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/hash/
376"
REFERENCES,0.6371100164203612,"d921c3c762b1522c475ac8fc0811bb0f-Abstract.html.
377"
REFERENCES,0.638752052545156,"[5] Saurabh Vyas, Matthew D. Golub, David Sussillo, and Krishna V. Shenoy. Computation
378"
REFERENCES,0.6403940886699507,"Through Neural Population Dynamics.
Annual Review of Neuroscience, 43(1):249–275,
379"
REFERENCES,0.6420361247947455,"2020. doi: 10.1146/annurev-neuro-092619-094115. URL https://doi.org/10.1146/
380"
REFERENCES,0.6436781609195402,"annurev-neuro-092619-094115. _eprint: https://doi.org/10.1146/annurev-neuro-092619-
381"
REFERENCES,0.645320197044335,"094115.
382"
REFERENCES,0.6469622331691297,"[6] Krishna V. Shenoy, Maneesh Sahani, and Mark M. Churchland. Cortical control of arm
383"
REFERENCES,0.6486042692939245,"movements: a dynamical systems perspective. Annual Review of Neuroscience, 36:337–359,
384"
REFERENCES,0.6502463054187192,"July 2013. ISSN 1545-4126. doi: 10.1146/annurev-neuro-062111-150509.
385"
REFERENCES,0.6518883415435139,"[7] Mehrdad Jazayeri and Srdjan Ostojic. Interpreting neural computations by examining intrinsic
386"
REFERENCES,0.6535303776683087,"and embedding dimensionality of neural activity. Technical Report arXiv:2107.04084, arXiv,
387"
REFERENCES,0.6551724137931034,"August 2021. URL http://arxiv.org/abs/2107.04084. arXiv:2107.04084 [q-bio] type:
388"
REFERENCES,0.6568144499178982,"article.
389"
REFERENCES,0.6584564860426929,"[8] Ian H. Stevenson and Konrad P. Kording. How advances in neural recording affect data analysis.
390"
REFERENCES,0.6600985221674877,"Nature Neuroscience, 14(2):139–142, February 2011. ISSN 1546-1726. doi: 10.1038/nn.2731.
391"
REFERENCES,0.6617405582922824,"[9] Nicholas A Steinmetz, Cagatay Aydin, Anna Lebedeva, Michael Okun, Marius Pachitariu,
392"
REFERENCES,0.6633825944170771,"Marius Bauza, Maxime Beau, Jai Bhagat, Claudia Böhm, Martijn Broux, Susu Chen, Jennifer
393"
REFERENCES,0.6650246305418719,"Colonell, Richard J Gardner, Bill Karsh, Fabian Kloosterman, Dimitar Kostadinov, Carolina
394"
REFERENCES,0.6666666666666666,"Mora-Lopez, John O’Callaghan, Junchol Park, Jan Putzeys, Britton Sauerbrei, Rik J J van
395"
REFERENCES,0.6683087027914614,"Daal, Abraham Z Vollan, Shiwei Wang, Marleen Welkenhuysen, Zhiwen Ye, Joshua T Dudman,
396"
REFERENCES,0.6699507389162561,"Barundeb Dutta, Adam W Hantman, Kenneth D Harris, Albert K Lee, Edvard I Moser, John
397"
REFERENCES,0.6715927750410509,"O’Keefe, Alfonso Renart, Karel Svoboda, Michael Häusser, Sebastian Haesler, Matteo Caran-
398"
REFERENCES,0.6732348111658456,"dini, and Timothy D Harris. Neuropixels 2.0: A miniaturized high-density probe for stable,
399"
REFERENCES,0.6748768472906403,"long-term brain recordings. Science, 372(6539), April 2021.
400"
REFERENCES,0.6765188834154351,"[10] Jeffrey Demas, Jason Manley, Frank Tejera, Kevin Barber, Hyewon Kim, Francisca Martínez
401"
REFERENCES,0.6781609195402298,"Traub, Brandon Chen, and Alipasha Vaziri. High-speed, cortex-wide volumetric recording
402"
REFERENCES,0.6798029556650246,"of neuroactivity at cellular resolution using light beads microscopy. Nature Methods, 18(9):
403"
REFERENCES,0.6814449917898193,"1103–1111, September 2021. ISSN 1548-7105. doi: 10.1038/s41592-021-01239-8. URL
404"
REFERENCES,0.6830870279146142,"https://www.nature.com/articles/s41592-021-01239-8. Number: 9 Publisher: Na-
405"
REFERENCES,0.6847290640394089,"ture Publishing Group.
406"
REFERENCES,0.6863711001642037,"[11] Peiran Gao and Surya Ganguli. On simplicity and complexity in the brave new world of
407"
REFERENCES,0.6880131362889984,"large-scale neuroscience. Current Opinion in Neurobiology, 32:148–155, June 2015. ISSN
408"
REFERENCES,0.6896551724137931,"0959-4388. doi: 10.1016/J.CONB.2015.04.003. URL https://www.sciencedirect.com/
409"
REFERENCES,0.6912972085385879,"science/article/pii/S0959438815000768. Publisher: Elsevier Current Trends.
410"
REFERENCES,0.6929392446633826,"[12] Lea Duncker and Maneesh Sahani. Dynamics on the manifold: Identifying computational
411"
REFERENCES,0.6945812807881774,"dynamical activity from neural population recordings. Current Opinion in Neurobiology, 70:
412"
REFERENCES,0.6962233169129721,"163–170, October 2021. ISSN 0959-4388. doi: 10.1016/j.conb.2021.10.014. URL https:
413"
REFERENCES,0.6978653530377669,"//www.sciencedirect.com/science/article/pii/S0959438821001264.
414"
REFERENCES,0.6995073891625616,"[13] David Sussillo, Rafal Jozefowicz, L. F. Abbott, and Chethan Pandarinath. LFADS - Latent
415"
REFERENCES,0.7011494252873564,"Factor Analysis via Dynamical Systems. Technical Report arXiv:1608.06315, arXiv, August
416"
REFERENCES,0.7027914614121511,"2016. URL http://arxiv.org/abs/1608.06315. arXiv:1608.06315 [cs, q-bio, stat] type:
417"
REFERENCES,0.7044334975369458,"article.
418"
REFERENCES,0.7060755336617406,"[14] Marine Schimel, Ta-Chu Kao, Kristopher T. Jensen, and Guillaume Hennequin. iLQR-VAE
419"
REFERENCES,0.7077175697865353,": control-based learning of input-driven dynamics with applications to neural data. Technical
420"
REFERENCES,0.7093596059113301,"report, bioRxiv, October 2021. URL https://www.biorxiv.org/content/10.1101/2021.
421"
REFERENCES,0.7110016420361248,"10.07.463540v1. Section: New Results Type: article.
422"
REFERENCES,0.7126436781609196,"[15] Andrew R. Sedler, Christopher Versteeg, and Chethan Pandarinath. Expressive architectures
423"
REFERENCES,0.7142857142857143,"enhance interpretability of dynamics-based neural population models, February 2023. URL
424"
REFERENCES,0.715927750410509,"http://arxiv.org/abs/2212.03771. arXiv:2212.03771 [cs, q-bio].
425"
REFERENCES,0.7175697865353038,"[16] Yuanjun Gao, Evan Archer, Liam Paninski, and John P. Cunningham. Linear dynamical neural
426"
REFERENCES,0.7192118226600985,"population models through nonlinear embeddings. Technical Report arXiv:1605.08454, arXiv,
427"
REFERENCES,0.7208538587848933,"October 2016. URL http://arxiv.org/abs/1605.08454. arXiv:1605.08454 [q-bio, stat]
428"
REFERENCES,0.722495894909688,"type: article.
429"
REFERENCES,0.7241379310344828,"[17] Anqi Wu, Nicholas A. Roy, Stephen Keeley, and Jonathan W Pillow.
Gaussian
430"
REFERENCES,0.7257799671592775,"process based nonlinear latent structure discovery in multivariate spike train data.
431"
REFERENCES,0.7274220032840722,"In Advances in Neural Information Processing Systems, volume 30. Curran Asso-
432"
REFERENCES,0.729064039408867,"ciates, Inc., 2017.
URL https://papers.nips.cc/paper_files/paper/2017/hash/
433"
REFERENCES,0.7307060755336617,"b3b4d2dbedc99fe843fd3dedb02f086f-Abstract.html.
434"
REFERENCES,0.7323481116584565,"[18] Yuan Zhao and Il Memming Park. Variational Online Learning of Neural Dynamics. Frontiers in
435"
REFERENCES,0.7339901477832512,"Computational Neuroscience, 14, 2020. ISSN 1662-5188. URL https://www.frontiersin.
436"
REFERENCES,0.735632183908046,"org/article/10.3389/fncom.2020.00071.
437"
REFERENCES,0.7372742200328407,"[19] Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. Neural Ordinary
438"
REFERENCES,0.7389162561576355,"Differential Equations. Technical Report arXiv:1806.07366, arXiv, December 2019. URL
439"
REFERENCES,0.7405582922824302,"http://arxiv.org/abs/1806.07366. arXiv:1806.07366 [cs, stat] type: article.
440"
REFERENCES,0.7422003284072249,"[20] Laurent Dinh, David Krueger, and Yoshua Bengio. Nice: Non-linear independent components
441"
REFERENCES,0.7438423645320197,"estimation. arXiv preprint arXiv:1410.8516, 2014.
442"
REFERENCES,0.7454844006568144,"[21] Durk P Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions.
443"
REFERENCES,0.7471264367816092,"Advances in neural information processing systems, 31, 2018.
444"
REFERENCES,0.7487684729064039,"[22] Lynton Ardizzone, Jakob Kruse, Sebastian Wirkert, Daniel Rahner, Eric W. Pellegrini, Ralf S.
445"
REFERENCES,0.7504105090311987,"Klessen, Lena Maier-Hein, Carsten Rother, and Ullrich Köthe. Analyzing Inverse Problems
446"
REFERENCES,0.7520525451559934,"with Invertible Neural Networks. Technical Report arXiv:1808.04730, arXiv, February 2019.
447"
REFERENCES,0.7536945812807881,"URL http://arxiv.org/abs/1808.04730. arXiv:1808.04730 [cs, stat] type: article.
448"
REFERENCES,0.7553366174055829,"[23] Jens Behrmann, Will Grathwohl, Ricky T. Q. Chen, David Duvenaud, and Joern-Henrik Jacob-
449"
REFERENCES,0.7569786535303776,"sen. Invertible Residual Networks. In Proceedings of the 36th International Conference on
450"
REFERENCES,0.7586206896551724,"Machine Learning, pages 573–582. PMLR, May 2019. URL https://proceedings.mlr.
451"
REFERENCES,0.7602627257799671,"press/v97/behrmann19a.html. ISSN: 2640-3498.
452"
REFERENCES,0.7619047619047619,"[24] Jakob H Macke, Lars Buesing, John P Cunningham, Byron M Yu, Krishna V Shenoy, and
453"
REFERENCES,0.7635467980295566,"Maneesh Sahani. Empirical models of spiking in neural populations. In Advances in Neural Infor-
454"
REFERENCES,0.7651888341543513,"mation Processing Systems, volume 24. Curran Associates, Inc., 2011. URL https://papers.
455"
REFERENCES,0.7668308702791461,"nips.cc/paper/2011/hash/7143d7fbadfa4693b9eec507d9d37443-Abstract.html.
456"
REFERENCES,0.7684729064039408,"[25] Evan Archer, Il Memming Park, Lars Buesing, John Cunningham, and Liam Paninski. Black
457"
REFERENCES,0.7701149425287356,"box variational inference for state space models, November 2015. URL http://arxiv.org/
458"
REFERENCES,0.7717569786535303,"abs/1511.07367. arXiv:1511.07367 [stat].
459"
REFERENCES,0.7733990147783252,"[26] David Pfau, Eftychios A Pnevmatikakis, and Liam Paninski. Robust learning of low-dimensional
460"
REFERENCES,0.7750410509031199,"dynamics from large neural ensembles. In Advances in Neural Information Processing Systems,
461"
REFERENCES,0.7766830870279147,"volume 26. Curran Associates, Inc., 2013. URL https://papers.nips.cc/paper_files/
462"
REFERENCES,0.7783251231527094,"paper/2013/hash/47a658229eb2368a99f1d032c8848542-Abstract.html.
463"
REFERENCES,0.7799671592775042,"[27] Felix Pei, Joel Ye, David Zoltowski, Anqi Wu, Raeed H. Chowdhury, Hansem Sohn, Joseph E.
464"
REFERENCES,0.7816091954022989,"O’Doherty, Krishna V. Shenoy, Matthew T. Kaufman, Mark Churchland, Mehrdad Jazayeri,
465"
REFERENCES,0.7832512315270936,"Lee E. Miller, Jonathan Pillow, Il Memming Park, Eva L. Dyer, and Chethan Pandarinath.
466"
REFERENCES,0.7848932676518884,"Neural Latents Benchmark ’21: Evaluating latent variable models of neural population activity.
467"
REFERENCES,0.7865353037766831,"Technical Report arXiv:2109.04463, arXiv, January 2022. URL http://arxiv.org/abs/
468"
REFERENCES,0.7881773399014779,"2109.04463. arXiv:2109.04463 [cs, q-bio] type: article.
469"
REFERENCES,0.7898193760262726,"[28] Timothy D Kim, Thomas Z Luo, Jonathan W Pillow, and Carlos Brody. Inferring latent
470"
REFERENCES,0.7914614121510674,"dynamics underlying neural population activity via neural differential equations. In International
471"
REFERENCES,0.7931034482758621,"Conference on Machine Learning, pages 5551–5561. PMLR, 2021.
472"
REFERENCES,0.7947454844006568,"[29] Matthew J. Johnson, David Duvenaud, Alexander B. Wiltschko, Sandeep R. Datta, and Ryan P.
473"
REFERENCES,0.7963875205254516,"Adams. Composing graphical models with neural networks for structured representations and
474"
REFERENCES,0.7980295566502463,"fast inference, July 2017. URL http://arxiv.org/abs/1603.06277. arXiv:1603.06277
475"
REFERENCES,0.7996715927750411,"[stat].
476"
REFERENCES,0.8013136288998358,"[30] Ian H. Stevenson. Flexible models for spike count data with both over- and under- dispersion.
477"
REFERENCES,0.8029556650246306,"Journal of Computational Neuroscience, 41(1):29–43, August 2016. ISSN 1573-6873. doi:
478"
REFERENCES,0.8045977011494253,"10.1007/s10827-016-0603-y. URL https://doi.org/10.1007/s10827-016-0603-y.
479"
REFERENCES,0.80623973727422,"[31] Steven L Brunton, Joshua L Proctor, and J Nathan Kutz. Discovering governing equations
480"
REFERENCES,0.8078817733990148,"from data by sparse identification of nonlinear dynamical systems. Proceedings of the national
481"
REFERENCES,0.8095238095238095,"academy of sciences, 113(15):3932–3937, 2016.
482"
REFERENCES,0.8111658456486043,"[32] Steffen Schneider, Jin Hwa Lee, and Mackenzie Weygandt Mathis. Learnable latent embeddings
483"
REFERENCES,0.812807881773399,"for joint behavioural and neural analysis. Nature, 617(7960):360–368, May 2023. ISSN 1476-
484"
REFERENCES,0.8144499178981938,"4687. doi: 10.1038/s41586-023-06031-6. URL https://www.nature.com/articles/
485"
REFERENCES,0.8160919540229885,"s41586-023-06031-6. Number: 7960 Publisher: Nature Publishing Group.
486"
REFERENCES,0.8177339901477833,"[33] Ding Zhou and Xue-Xin Wei. Learning identifiable and interpretable latent models of high-
487"
REFERENCES,0.819376026272578,"dimensional neural activity using pi-VAE, November 2020. URL http://arxiv.org/abs/
488"
REFERENCES,0.8210180623973727,"2011.04798. arXiv:2011.04798 [cs, q-bio, stat].
489"
REFERENCES,0.8226600985221675,"[34] Mohammad Bashiri, Edgar Walker, Konstantin-Klemens Lurz, Akshay Jagadish, Taliah
490"
REFERENCES,0.8243021346469622,"Muhammad, Zhiwei Ding, Zhuokun Ding, Andreas Tolias, and Fabian Sinz. A flow-based
491"
REFERENCES,0.825944170771757,"latent state generative model of neural population responses to natural images.
In Ad-
492"
REFERENCES,0.8275862068965517,"vances in Neural Information Processing Systems, volume 34, pages 15801–15815. Cur-
493"
REFERENCES,0.8292282430213465,"ran Associates, Inc., 2021. URL https://proceedings.neurips.cc/paper/2021/hash/
494"
REFERENCES,0.8308702791461412,"84a529a92de322be42dd3365afd54f91-Abstract.html.
495"
REFERENCES,0.8325123152709359,"[35] Jimmy T. H. Smith, Scott W. Linderman, and David Sussillo. Reverse engineering recur-
496"
REFERENCES,0.8341543513957307,"rent neural networks with Jacobian switching linear dynamical systems. Technical Report
497"
REFERENCES,0.8357963875205254,"arXiv:2111.01256, arXiv, November 2021.
URL http://arxiv.org/abs/2111.01256.
498"
REFERENCES,0.8374384236453202,"arXiv:2111.01256 [cs] type: article.
499"
REFERENCES,0.8390804597701149,"[36] Cole Hurwitz, Akash Srivastava, Kai Xu, Justin Jude, Matthew Perich, Lee Miller,
500"
REFERENCES,0.8407224958949097,"and Matthias Hennig.
Targeted Neural Dynamical Modeling.
In Advances in Neu-
501"
REFERENCES,0.8423645320197044,"ral Information Processing Systems, volume 34, pages 29379–29392. Curran Asso-
502"
REFERENCES,0.8440065681444991,"ciates, Inc., 2021.
URL https://papers.nips.cc/paper_files/paper/2021/hash/
503"
REFERENCES,0.8456486042692939,"f5cfbc876972bd0d031c8abc37344c28-Abstract.html.
504"
REFERENCES,0.8472906403940886,"[37] Kristopher Jensen, Ta-Chu Kao, Jasmine Stone, and Guillaume Hennequin.
Scalable
505"
REFERENCES,0.8489326765188834,"Bayesian GPFA with automatic relevance determination and discrete noise models. In Ad-
506"
REFERENCES,0.8505747126436781,"vances in Neural Information Processing Systems, volume 34, pages 10613–10626. Cur-
507"
REFERENCES,0.8522167487684729,"ran Associates, Inc., 2021. URL https://proceedings.neurips.cc/paper/2021/hash/
508"
REFERENCES,0.8538587848932676,"58238e9ae2dd305d79c2ebc8c1883422-Abstract.html.
509"
REFERENCES,0.8555008210180624,"[38] Mark M. Churchland, John P. Cunningham, Matthew T. Kaufman, Stephen I. Ryu, and Krishna V.
510"
REFERENCES,0.8571428571428571,"Shenoy. Cortical preparatory activity: representation of movement or first cog in a dynamical
511"
REFERENCES,0.8587848932676518,"machine? Neuron, 68(3):387–400, November 2010. ISSN 1097-4199. doi: 10.1016/j.neuron.
512"
REFERENCES,0.8604269293924466,"2010.09.015.
513"
REFERENCES,0.8620689655172413,"[39] Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral Normaliza-
514"
REFERENCES,0.8637110016420362,"tion for Generative Adversarial Networks, February 2018. URL http://arxiv.org/abs/
515"
REFERENCES,0.8653530377668309,"1802.05957. arXiv:1802.05957 [cs, stat].
516"
REFERENCES,0.8669950738916257,"[40] Matthew D. Golub and David Sussillo. Fixedpointfinder: A tensorflow toolbox for identifying
517"
REFERENCES,0.8686371100164204,"and characterizing fixed points in recurrent neural networks. Journal of Open Source Software,
518"
REFERENCES,0.8702791461412152,"3(31):1003, 2018. doi: 10.21105/joss.01003. URL https://doi.org/10.21105/joss.
519"
REFERENCES,0.8719211822660099,"01003.
520"
REFERENCES,0.8735632183908046,"[41] A Arneodo, P Coullet, and C Tresser. Occurence of strange attractors in three-dimensional
521"
REFERENCES,0.8752052545155994,"Volterra equations.
Physics Letters A, 79(4):259–263, October 1980.
ISSN 0375-9601.
522"
REFERENCES,0.8768472906403941,"doi: 10.1016/0375-9601(80)90342-4. URL https://www.sciencedirect.com/science/
523"
REFERENCES,0.8784893267651889,"article/pii/0375960180903424.
524"
REFERENCES,0.8801313628899836,"[42] Richard J. Gardner, Erik Hermansen, Marius Pachitariu, Yoram Burak, Nils A. Baas, Ben-
525"
REFERENCES,0.8817733990147784,"jamin A. Dunn, May-Britt Moser, and Edvard I. Moser. Toroidal topology of population activity
526"
REFERENCES,0.8834154351395731,"in grid cells. Technical report, bioRxiv, February 2021. URL https://www.biorxiv.org/
527"
REFERENCES,0.8850574712643678,"content/10.1101/2021.02.25.432776v1. Section: New Results Type: article.
528"
REFERENCES,0.8866995073891626,"[43] EvalAI: Neural Latents Benchmark ’21 - MC Maze 20ms. URL https://eval.ai/web/
529"
REFERENCES,0.8883415435139573,"challenges/challenge-page/1256/leaderboard/3183.
530"
REFERENCES,0.8899835796387521,"[44] Mohammad Reza Keshtkaran, Andrew R. Sedler, Raeed H. Chowdhury, Raghav Tandon,
531"
REFERENCES,0.8916256157635468,"Diya Basrai, Sarah L. Nguyen, Hansem Sohn, Mehrdad Jazayeri, Lee E. Miller, and Chethan
532"
REFERENCES,0.8932676518883416,"Pandarinath. A large-scale neural network training framework for generalized estimation
533"
REFERENCES,0.8949096880131363,"of single-trial population dynamics. Nature Methods, 19(12):1572–1577, December 2022.
534"
REFERENCES,0.896551724137931,"ISSN 1548-7105. doi: 10.1038/s41592-022-01675-0. URL https://www.nature.com/
535"
REFERENCES,0.8981937602627258,"articles/s41592-022-01675-0. Number: 12 Publisher: Nature Publishing Group.
536"
REFERENCES,0.8998357963875205,"[45] Chethan Pandarinath, Daniel J. O’Shea, Jasmine Collins, Rafal Jozefowicz, Sergey D. Stavisky,
537"
REFERENCES,0.9014778325123153,"Jonathan C. Kao, Eric M. Trautmann, Matthew T. Kaufman, Stephen I. Ryu, Leigh R. Hochberg,
538"
REFERENCES,0.90311986863711,"Jaimie M. Henderson, Krishna V. Shenoy, L. F. Abbott, and David Sussillo. Inferring single-trial
539"
REFERENCES,0.9047619047619048,"neural population dynamics using sequential auto-encoders. Nature Methods, 15(10):805–815,
540"
REFERENCES,0.9064039408866995,"October 2018. ISSN 1548-7105. doi: 10.1038/s41592-018-0109-9. URL https://www.
541"
REFERENCES,0.9080459770114943,"nature.com/articles/s41592-018-0109-9. Number: 10 Publisher: Nature Publishing
542"
REFERENCES,0.909688013136289,"Group.
543"
REFERENCES,0.9113300492610837,"[46] Jimmy T. H. Smith, Andrew Warrington, and Scott W. Linderman. Simplified State Space
544"
REFERENCES,0.9129720853858785,"Layers for Sequence Modeling, March 2023. URL http://arxiv.org/abs/2208.04933.
545"
REFERENCES,0.9146141215106732,"arXiv:2208.04933 [cs].
546"
REFERENCES,0.916256157635468,"[47] Laura Driscoll, Krishna Shenoy, and David Sussillo. Flexible multitask computation in recur-
547"
REFERENCES,0.9178981937602627,"rent networks utilizes shared dynamical motifs, August 2022. URL https://www.biorxiv.
548"
REFERENCES,0.9195402298850575,"org/content/10.1101/2022.08.15.503870v1. Pages: 2022.08.15.503870 Section: New
549"
REFERENCES,0.9211822660098522,"Results.
550"
REFERENCES,0.922824302134647,"Checklist
551"
REFERENCES,0.9244663382594417,"1. For all authors...
552"
REFERENCES,0.9261083743842364,"(a) Do the main claims made in the abstract and introduction accurately reflect the paper’s
553"
REFERENCES,0.9277504105090312,"contributions and scope? Yes, we ensured that the abstract was supported by the
554"
REFERENCES,0.9293924466338259,"main body of the article
555"
REFERENCES,0.9310344827586207,"(b) Did you describe the limitations of your work? Yes, we included a section in the
556"
REFERENCES,0.9326765188834154,"discussion where we describe where our work is currently limited, and offer
557"
REFERENCES,0.9343185550082101,"suggestions for ways to extend the work to address these limitations
558"
REFERENCES,0.9359605911330049,"(c) Did you discuss any potential negative societal impacts of your work? We’ve included
559"
REFERENCES,0.9376026272577996,"a short description of how this work might adversely impact societal health in the
560"
REFERENCES,0.9392446633825944,"Broader Impacts section
561"
REFERENCES,0.9408866995073891,"(d) Have you read the ethics review guidelines and ensured that your paper conforms to
562"
REFERENCES,0.9425287356321839,"them? Yes, we’ve read the ethical review guidelines and confirmed that our paper
563"
REFERENCES,0.9441707717569786,"meets their standards
564"
REFERENCES,0.9458128078817734,"2. If you are including theoretical results...
565"
REFERENCES,0.9474548440065681,"(a) Did you state the full set of assumptions of all theoretical results?
566"
REFERENCES,0.9490968801313628,"(b) Did you include complete proofs of all theoretical results?
567"
REFERENCES,0.9507389162561576,"3. If you ran experiments...
568"
REFERENCES,0.9523809523809523,"(a) Did you include the code, data, and instructions needed to reproduce the main experi-
569"
REFERENCES,0.9540229885057471,"mental results (either in the supplemental material or as a URL)? We plan to include
570"
REFERENCES,0.9556650246305419,"these components in the supplementary pdf for final submission
571"
REFERENCES,0.9573070607553367,"(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they
572"
REFERENCES,0.9589490968801314,"were chosen)? We’ve included these details, split between the main text and the
573"
REFERENCES,0.9605911330049262,"supplement, depending on their relative importance
574"
REFERENCES,0.9622331691297209,"(c) Did you report error bars (e.g., with respect to the random seed after running experi-
575"
REFERENCES,0.9638752052545156,"ments multiple times)? Yes, we’ve included error bars on relevant plots
576"
REFERENCES,0.9655172413793104,"(d) Did you include the total amount of compute and the type of resources used (e.g., type
577"
REFERENCES,0.9671592775041051,"of GPUs, internal cluster, or cloud provider)? Yes, we’ve included the details of our
578"
REFERENCES,0.9688013136288999,"internal cluster in the supplementary materials
579"
REFERENCES,0.9704433497536946,"4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
580"
REFERENCES,0.9720853858784894,"(a) If your work uses existing assets, did you cite the creators? Yes, we credit these assets
581"
REFERENCES,0.9737274220032841,"in the supplementary materials
582"
REFERENCES,0.9753694581280788,"(b) Did you mention the license of the assets? We plan to include the license of each
583"
REFERENCES,0.9770114942528736,"asset in the supplement
584"
REFERENCES,0.9786535303776683,"(c) Did you include any new assets either in the supplemental material or as a URL? Yes,
585"
REFERENCES,0.9802955665024631,"we plan to include our code and data-generation in the final submission
586"
REFERENCES,0.9819376026272578,"(d) Did you discuss whether and how consent was obtained from people whose data you’re
587"
REFERENCES,0.9835796387520526,"using/curating?
588"
REFERENCES,0.9852216748768473,"(e) Did you discuss whether the data you are using/curating contains personally identifiable
589"
REFERENCES,0.986863711001642,"information or offensive content?
590"
REFERENCES,0.9885057471264368,"5. If you used crowdsourcing or conducted research with human subjects...
591"
REFERENCES,0.9901477832512315,"(a) Did you include the full text of instructions given to participants and screenshots, if
592"
REFERENCES,0.9917898193760263,"applicable?
593"
REFERENCES,0.993431855500821,"(b) Did you describe any potential participant risks, with links to Institutional Review
594"
REFERENCES,0.9950738916256158,"Board (IRB) approvals, if applicable?
595"
REFERENCES,0.9967159277504105,"(c) Did you include the estimated hourly wage paid to participants and the total amount
596"
REFERENCES,0.9983579638752053,"spent on participant compensation?
597"
