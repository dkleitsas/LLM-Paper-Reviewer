Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0021929824561403508,"The recent framework of performative prediction (Perdomo et al., 2020) is aimed
at capturing settings where predictions inﬂuence the target/outcome they want to
predict. In this paper, we introduce a natural multi-agent version of this frame-
work, where multiple decision makers try to predict the same outcome. We show-
case that such competition can result in interesting phenomena by proving the
possibility of phase transitions from stability to instability and eventually chaos.
Speciﬁcally, we present settings of multi-agent performative prediction where un-
der sufﬁcient conditions their dynamics lead to global stability and optimality. In
the opposite direction, when the agents are not sufﬁciently cautious in their learn-
ing/updates rates, we show that instability and in fact formal chaos is possible. We
complement our theoretical predictions with simulations showcasing the predic-
tive power of our results."
INTRODUCTION,0.0043859649122807015,"1
INTRODUCTION"
INTRODUCTION,0.006578947368421052,"Performative prediction (Perdomo et al., 2020) is a recently introduced framework that focuses on a
natural but largely unexplored element of supervised learning. In many practical cases the predictive
model can affect the very outcome that it is trying to predict. For example, predictions about which
part of a road network will have high congestion trigger responses from the drivers which affect the
resulting trafﬁc realization leading to a shift of the target distribution. In such settings, (Perdomo
et al., 2020) explored conditions for the existence and approximate optimality of stable equilibria of
such processes."
INTRODUCTION,0.008771929824561403,"One possible way to interpret the performative prediction setting is a single agent “game”, where the
predictive agent is playing a game against himself. An agent chooses the parameters of his model
as his actions but the predictive accuracy/cost of the model depends on his own past actions. Fixed
points of this process do not allow for proﬁtable deviations. Once cast in this light, it becomes
self-evident that the restriction to a single predictive agent/model is arguably only the ﬁrst step in
capturing more general phenomena where there is a closed loop between predictive models and their
environment. This motivates our central question: What is the interplay between stability, optimality
in cases where multiple predictive models operate in parallel to each other? Can the competition be-
tween multiple models lead to novel phenomena such as phase transitions from stability to instability
and chaos?"
INTRODUCTION,0.010964912280701754,"A natural setting to consider for example is market competition, where multiple hedge funds are
trying to simultaneously predict future prices, volatility of ﬁnancial instruments. Of course as they
act upon their predictions they also move the prices of these commodities in a highly correlated
way. As more agents enter the market and the competition becomes increasingly ﬁerce, is it possible
that at some point the market ﬂips from quickly discovering accurate stable predictions reﬂecting
the underlying market fundamentals to self-induced unpredictability and chaos? When it comes to
performative prediction can too many cooks spoil the soup?"
INTRODUCTION,0.013157894736842105,"Our model
Standard supervised learning consists of three components: a set of predictive mod-
els, a loss function, and a data distribution. The learner (agent) observes samples of the distribution,
and then decides a predictive model. When predictions are performative, the agent’s decision of a
predictive model inﬂuences the data distribution. Thus, instead of a ﬁxed data distribution, a pre-
dictive prediction also has a distribution map: a mapping from the agent’s predictive models to"
INTRODUCTION,0.015350877192982455,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.017543859649122806,"data distributions. We further propose multi-agent performative prediction which model the inﬂu-
ence of multiple agents’ decisions on the data distribution, and ask whether these inﬂuence leads to
convergent or chaotic systems."
INTRODUCTION,0.019736842105263157,"To understand the framework of multi-agent performative prediction, we study a natural regression
problem with multi-agent location-scale distribution maps (deﬁnition 2.2) where the agents’ inﬂu-
ence is linear in the agents’ models. Speciﬁcally, the data consist of features and outcomes. For
each agent i ∈[n], his inﬂuence on the distribution of outcome is his model weighted by a scalar
λi > 0. When n = 1, our multi-agent location-scale distribution map is a special case of location-
scale family in Miller et al. (2021). In the market example, each hedge fund company tries to predict
the price (outcome) based on macroeconomic data or other information (features). These inﬂuence
parameters λ1, . . . , λn can be seen as each hedge fund’s capital that can inﬂuence the distribution of
the future price."
INTRODUCTION,0.021929824561403508,"Finally, we consider the agents do not know the dependency between their model and the data
distribution, and they can only improve their predictive models myopically and iteratively. In this
paper, the agents myopically use a reinforcement learning algorithm, exponentiated gradient for
linear regression (Kivinen & Warmuth, 1997), to improve their predictive models in rounds. We
study the long-term behavior, and ask if the system converge to the performative stable and optimal
point, or behave chaotically."
INTRODUCTION,0.02412280701754386,"Our results
We ﬁrst study basic properties of our multi-agent preformative prediction with multi-
agent location-scale distribution map. We show 1) the existence of performative stable point in our
setting (proposition 3.1) and 2) the performative stability and performative optimality are equivalent
(proposition 3.2). This equivalence allows us to focus on the dynamical behavior of the system."
INTRODUCTION,0.02631578947368421,"In section 4, we introduce learning dynamics to the multi-agent performative prediction, and study
their long-term behavior. We provide a threshold result which depends on the learning rates of
exponentiated gradient descent and the collective inﬂuence. Theorem 4.1 shows the dynamics of
exponential gradient descent converge to the performative stable and optimal point when the learn-
ing rate is small enough. Our convergence result in theorem 4.1 holds when the feature space is
multi-dimensional, and every learning agent can use different learning rates starting at arbitrarily
interior states. Our exact convergence result also works in the single-agent performative predic-
tion setting. Contrarily, previous convergent results in Perdomo et al. (2020); Miller et al. (2021);
Mendler-D¨unner et al. (2020) only show that their dynamics converge to a small neighborhood of
the performative stable point."
INTRODUCTION,0.02850877192982456,"On the other hand, section 4.2 shows the dynamics can have chaotic behavior if the collective in-
ﬂuence Ln is large enough. Speciﬁcally, theorem 4.6 shows that even when the feature space is
in R2 these systems provably exhibit Li-Yorke chaos, when the collective inﬂuence P"
INTRODUCTION,0.03070175438596491,"i λi is large
enough. This implies that there exists an uncountable “scrambled” set so that given any two initial
conditions in the set, the liminf of the distance between these two dynamics is zero, but the lim-
sup of their distance is positive. (deﬁnition 2.4) The chaotic result in theorem 4.6 also holds for
the original single-agent performative prediction so long as the agent’s inﬂuence is large enough,
and, thus, complements previous performative prediction works on convergence behavior, which
primarily consider that the agent’s inﬂuence on the data distribution is sufﬁciently small. Moreover,
no matter how small the agents’ learning rates, theorem 4.6 shows that chaos is inevitable in some
performative predictions settings when the number of agents exceeds a carrying capacity. After that
the system becomes totally unpredictable with small perturbations exploding exponentially fast. 1"
INTRODUCTION,0.03289473684210526,"Finally, section 5 provides numerical examples of our dynamics and show convergent and chaotic
behavior. Additionally, through simulation, we demonstrate that our convergent and chaotic results
also hold when the agents can only access noisy estimation of the gradient and conduct stochastic
exponentiated gradient descent."
INTRODUCTION,0.03508771929824561,"Related work
Data distribution shift is not a new topic in ML, but earlier works focused primarily
on exogenous changes to the data generating distribution. Performativity is machine learning was
introduced by Perdomo et al. (2020). The original work and several follow-ups study the discrep-
ancy between performative stability and performative optimality and prove approximated conver-"
INTRODUCTION,0.03728070175438596,1We highlight our revision in blue color.
INTRODUCTION,0.039473684210526314,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.041666666666666664,"gence of learning dynamics, e.g., stochastic gradient descent, or iterative empirical risk minimiza-
tion. (Mendler-D¨unner et al., 2020; Drusvyatskiy & Xiao, 2020; Izzo et al., 2021) Performativity of
prediction is also related to several applications: strategic classiﬁcation (Hardt et al., 2016), retrain-
ing Bartlett (1992); Kuh et al. (1990)."
INTRODUCTION,0.043859649122807015,"Inspired by the instability of training algorithms in ML applications such as Generative Adversarial
Networks (GANs), there has been a lot of recent interest in understanding conditions (particularly
in multi-agent systems) where learning behavior may be non-equilibrating/unstable (Cheung & Tao,
2020; Balduzzi et al., 2020; Flokas et al., 2020; Andrade et al., 2021; Letcher, 2021; Giannou et al.,
2021). The (in)stability and performance of exponentiated gradient descent in particular (also re-
ferred to as Multiplicative Weights Updates) and other closely related dynamics has attracted a lot
of attention (Cohen et al., 2017; Bailey & Piliouras, 2018; Cheung, 2018; Panageas et al., 2019;
Cheung & Piliouras, 2020; Vadori et al., 2021). The technique of Li-Yorke chaos has recently found
applications across several different domains such as routing games, Cournot games and blockchain
protocols (Palaiopanos et al., 2017; Chotibut et al., 2020; Bielawski et al., 2021; Cheung et al., 2021;
Leonardos et al., 2021). To our knowledge, this is the ﬁrst time where such formal chaotic results
are established in settings related to performative prediction and supervised learning more generally."
INTRODUCTION,0.046052631578947366,"Another line of related works is learning in games. Speciﬁcally, our dynamics can be seen as special
cases multiplicative weight update (Hedge algorithms) on congestion games. Previous works on
Hedge algorithms only show exact convergence when the learning rate is decreasing Kleinberg et al.
(2009); Cohen et al. (2017), and, to our best knowledge, our results are the ﬁrst that shows exact
convergence of Hedge algorithms with small constant learning rates. Our results also complement
the exact convergence result of the linear variant of multiplicative weight update by Palaiopanos
et al. (2017)."
PRELIMINARY,0.04824561403508772,"2
PRELIMINARY"
MULTI-AGENT PERFORMATIVE PREDICTION,0.05043859649122807,"2.1
MULTI-AGENT PERFORMATIVE PREDICTION"
MULTI-AGENT PERFORMATIVE PREDICTION,0.05263157894736842,"A multi-agent performative prediction comprises n agents deploying their predictive models
fθ1, . . . , fθn with parameters θ1, θ2, . . . , θn ∈Θ that collectively inﬂuence the future data dis-
tribution. We formalize such dependency via a distribution map D(·) which outputs a distribution
on the data, D(⃗θ), given a models proﬁle ⃗θ := (θ1, . . . , θn) ∈Θn. A loss function ℓ(z, θ′) mea-
sures the loss of a model fθ′ on a data point z ∈Z, and the expected loss on a distribution D is
Ez∼D[ℓ(z, θ′)]. For performative prediction, we further deﬁne the decoupled performative loss on a
distribution mapping D as
ℓ(⃗θ, θ′) := Ez∼D(⃗θ)ℓ(z, θ′)"
MULTI-AGENT PERFORMATIVE PREDICTION,0.05482456140350877,"where θ′ ∈Θ denotes a predictive model, while ⃗θ ∈Θn denotes a deployed model proﬁle."
MULTI-AGENT PERFORMATIVE PREDICTION,0.05701754385964912,"Given the set of model Θ, the loss function ℓ, and the distribution mapping D, each agent in a
multi-agent performative prediction (Θ, ℓ, D) pursues minimal loss on the distribution that they
collectively induce. We consider two solution concepts performative optimality and performative
stability which generalizes the original ones in Perdomo et al. (2020)."
MULTI-AGENT PERFORMATIVE PREDICTION,0.05921052631578947,"Deﬁnition 2.1. Given (Θ, ℓ, D), a models proﬁle ⃗θ∗∈Θn is performatively optimal if the total loss
is minimized,
⃗θ∗∈arg min
⃗θ∈Θn X"
MULTI-AGENT PERFORMATIVE PREDICTION,0.06140350877192982,"i
ℓ(⃗θ, θi)."
MULTI-AGENT PERFORMATIVE PREDICTION,0.06359649122807018,"Another desirable property of a model proﬁle is that, given all agents deploy their models, their
models are also simultaneously optimal for distribution that their model induces. Formally, ⃗θ∗is
performatively stable if for all i ∈[n]"
MULTI-AGENT PERFORMATIVE PREDICTION,0.06578947368421052,"(θ∗)i ∈arg min
θi∈Θ"
MULTI-AGENT PERFORMATIVE PREDICTION,0.06798245614035088,"ℓ(⃗θ∗, θi)."
MULTI-AGENT PERFORMATIVE PREDICTION,0.07017543859649122,"The performative optimality does not implies the performative stable point. For performative opti-
mal point, the variable for minimization ⃗θ affects both the ﬁrst and the second argument, but only
affect the second one for performative stable point. Now we introduce our model in this paper."
MULTI-AGENT PERFORMATIVE PREDICTION,0.07236842105263158,Under review as a conference paper at ICLR 2022
MULTI-AGENT PERFORMATIVE PREDICTION,0.07456140350877193,"Location-scale distribution map
In this paper, we study the family of multi-agent location-scale
map for regression problem where a data point consists of d-dimensional feature and scalar outcome,
z = (x, y). These are natural classes of distribution maps in which performative effects enter
through an additive or multiplicative factor that is linear in ⃗θ.
Deﬁnition 2.2. Given d ∈N and d ≥2, and Θn ⊆Rd, a distribution map D : Θn →Rd × R
is a multi-agent location-scale distribution map on n parties if there exists a static distribution DX
on Rd+1, θ0 ∈Rd, and n linear functions Λ1, . . . , Λn from Rd to Rd so that the distribution of
(x, y) ∼D(⃗θ) has the following form: The feature is x ∈Rd and noise x0 ∈R is jointly sampled
from DX. Given feature x ∈Rd and noise x0 ∈R, and the the outcome is y = * θ0 − n
X"
MULTI-AGENT PERFORMATIVE PREDICTION,0.07675438596491228,"i=1
Λi(θi), x + + x0."
MULTI-AGENT PERFORMATIVE PREDICTION,0.07894736842105263,"In this paper, we consider the scaling maps Λi(θ) = λiθ for all θ ∈Θ with scalar λi > 0 for
all i ∈[d]. We call λ := (λ1, . . . , λn) the inﬂuence parameters, and Ln := Pn
i=1 λi collective
inﬂuence. Furthermore, we let A := E

xx⊤
∈Rd×d be the covariance matrix of the feature, and
b := Aθ0 + E[x0x] ∈Rd. We will specify the multi agent location-scale distribution map with
parameters n, d, λ, A, and b."
MULTI-AGENT PERFORMATIVE PREDICTION,0.08114035087719298,"When n = 1, our multi-agent location-scale distribution map is a special case of location-scale
family in Miller et al. (2021) where the model θ may both the outcome y as well as the feature x."
MULTI-AGENT PERFORMATIVE PREDICTION,0.08333333333333333,"Predictive Models and Loss Function
We consider linear predictive model with constraint where
fθ′(x) = ⟨θ′, x⟩, and the collection of parameter is the d-simplex, Θ = {θ : Pd
k=1 θk = 1, θk ≥
0}. We use mean squared error to measure a predictive model θ′ ∈Θ on a distribution map with a
deployed model proﬁle ⃗θ ∈Θn, ℓ(⃗θ, θ′) = E(x,y)∼D(⃗θ)[(y−fθ′(x))2] = E(x,y)∼D(⃗θ)[(y−θ′ ·x)2]."
MULTI-AGENT PERFORMATIVE PREDICTION,0.08552631578947369,"Given a deployed model proﬁle ⃗θ and a predictive model θ′, the gradient of the decoupled loss is
g(⃗θ, θ′) := ∇θ′ℓ(⃗θ, θ′), and if D is a location-scale distribution map, g(⃗θ, θ′) = E(x,y)∼D(⃗θ)[2(θ′ ·
x −y)x]. Furthermore, with A and b deﬁned in deﬁnition 2.2, the gradient can be written as"
MULTI-AGENT PERFORMATIVE PREDICTION,0.08771929824561403,"g(⃗θ, θ′) = ∇θ′ℓ(⃗θ, θ′) = 2A "
MULTI-AGENT PERFORMATIVE PREDICTION,0.08991228070175439,"θ′ +
X"
MULTI-AGENT PERFORMATIVE PREDICTION,0.09210526315789473,"i
λiθi
!"
MULTI-AGENT PERFORMATIVE PREDICTION,0.09429824561403509,"−2b.
(1)"
MULTI-AGENT PERFORMATIVE PREDICTION,0.09649122807017543,"Additionally, given a deployed model proﬁle ⃗θ and a predictive model proﬁle ⃗θ′, we deﬁne the
gradient of agent i’s decoupled loss as gi(⃗θ, ⃗θ′) := g(⃗θ, (θ′)i), and gi(⃗θ) := gi(⃗θ, ⃗θ) when the
deployed model proﬁle is identical to the predictive model proﬁle. We denote the gradient of agent
i’s average loss as ¯gi(⃗θ) := P
l θi
lgi
l(⃗θ) for all ⃗θ ∈Θn. Finally, we deﬁne ⃗ξ(⃗θ) = (ξ1, . . . , ξn)
with ξi ∈Rd so that for all i ∈[n] and k ∈[d] ξi
k(⃗θ) := θi
k(P θi
lgi
l −gi
k). For brevity, we omit ⃗θ
and deﬁne ⃗g := ⃗g(⃗θ) and ⃗ξ := ⃗ξ(⃗θ) when there is no ambiguity."
LEARNING DYNAMICS,0.09868421052631579,"2.2
LEARNING DYNAMICS"
LEARNING DYNAMICS,0.10087719298245613,"We consider the agents myopically use a reinforcement learning algorithm exponentiated gradient
for linear regression to improve their predictive models in rounds. We ﬁrst deﬁne the original single
agent’s exponentiated gradient for linear regression on a sequence of data points here and will state
our dynamics on multi agent performative prediction in section 4.
Deﬁnition 2.3 (Kivinen & Warmuth (1997)). Given a learning rate η > 0, an initial parameter
θ0 ∈Θ and a sequential of data points (xt, yt)t≥1, the exponentiated gradient descent for linear
regression iteratively updates the model as follows: At round t + 1, with previous parameter θt ∈Θ
the exponentiated gradient algorithm updates it to θt+1 so that"
LEARNING DYNAMICS,0.10307017543859649,"θt+1,k =
θt,k exp(−2η(θt · xt −yt)xt,k)
P"
LEARNING DYNAMICS,0.10526315789473684,"l θt,l exp(−2η(θt · xt −yt)xt,l) for all k ∈[d]."
LEARNING DYNAMICS,0.1074561403508772,"Note that each exponent 2(θt · xt −yt)xt,k is the k-th coordinate of the gradient of squared error
ℓ((xt, yt), θt) at θt which yields the name of exponentiated gradient descent."
LEARNING DYNAMICS,0.10964912280701754,Under review as a conference paper at ICLR 2022
DYNAMICAL SYSTEM,0.1118421052631579,"2.3
DYNAMICAL SYSTEM"
DYNAMICAL SYSTEM,0.11403508771929824,"Deﬁnition 2.4. Let (X, f) be a dynamical system where X is a metric space and f is a mapping on
X. We say (x, x′) ∈X × X is a Li-Yorke pair if"
DYNAMICAL SYSTEM,0.1162280701754386,"lim inf
t
dist(f t(x), f t(x′)) = 0 and lim sup
t
dist(f t(x), f t(x′) > 0."
DYNAMICAL SYSTEM,0.11842105263157894,"(X, f) is Li-Yorke chaotic if there is an uncountable set S ⊂X (scrambled set) such that any pair
of points x ̸= x′ ∈S is Li-Yorke pair."
DYNAMICAL SYSTEM,0.1206140350877193,"3
MULTI-AGENT PERFORMATIVE LEARNING: STABILITY AND OPTIMALITY"
DYNAMICAL SYSTEM,0.12280701754385964,"Having introduced multi-agent performative prediction, we show some basic property of our
location-scale distribution map with mean squared error as a warm-up. Using the ﬁrst order condi-
tion and a potential function argument, we show 1) the existence of performative stable point in our
model (proposition 3.1) and 2) the performative stability and performative optimality are equivalent
(proposition 3.2). The proofs of both propositions are in appendix A."
DYNAMICAL SYSTEM,0.125,"We ﬁrst show the existence and uniqueness of performative stable point through a potential function
argument. The ﬁrst part is due to the ﬁrst order condition of convex optimization. The second part
also use the ﬁrst order condition, and
∂
∂θi
k Φ(⃗θ) = λigi
k(⃗θ) for all i ∈[n] and k ∈[d]."
DYNAMICAL SYSTEM,0.12719298245614036,"Proposition 3.1 (existence). Given the family of linear predictive models with constrains Θ, mean
squared error ℓand multi-agent location-scale distribution map with parameters n, d, λ, A, b in
deﬁnition 2.2, ⃗θ∗on (Θ, ℓ, D) is performative stable if and only if the gradient (deﬁned in eq. (1))
satisﬁes gi
k(⃗θ∗) ≤gi
l(⃗θ∗) for all i ∈[n] and k ∈[d] with θi
k > 0."
DYNAMICAL SYSTEM,0.12938596491228072,"Furthermore, if A is positive deﬁnite, there exists a unique performative stable point ⃗θ∗, and ⃗θ∗is
also a global minimizer of the following convex function for all ⃗θ ∈Θn"
DYNAMICAL SYSTEM,0.13157894736842105,"Φ(⃗θ) := (
X"
DYNAMICAL SYSTEM,0.1337719298245614,"i
λiθi)⊤A(
X"
DYNAMICAL SYSTEM,0.13596491228070176,"i
λiθi) +
X"
DYNAMICAL SYSTEM,0.13815789473684212,"i
λi(θi)⊤Aθi −2b⊤X"
DYNAMICAL SYSTEM,0.14035087719298245,"i
λiθi.
(2)"
DYNAMICAL SYSTEM,0.1425438596491228,"While model proﬁle is performative stable does not necessary mean the loss is minimized, the fol-
lowing proposition shows that optimality and stability are equivalent in our setting."
DYNAMICAL SYSTEM,0.14473684210526316,"Proposition 3.2. Given (Θ, ℓ, D) deﬁned in proposition 3.1, ⃗θ∗is performative stable if and only if
⃗θ∗is performatively optimal deﬁned in deﬁnition 2.1."
DYNAMICAL SYSTEM,0.14692982456140352,"4
MULTI-AGENT PERFORMATIVE LEARNING: CONVERGENCE AND CHAOS"
DYNAMICAL SYSTEM,0.14912280701754385,"In section 3, we study the stability and optimality of location-scale distribution map with mean
squared error. Now we ask when each agent myopically improves his predictive model through
reinforcement learning but their predictions are performative, what is the long term behavior of the
system? Can the system converges to performative stable and optimal point, or behave chaotically?"
DYNAMICAL SYSTEM,0.1513157894736842,"We provide a threshold result depending on the learning rate and the collective inﬂuence Ln. Sec-
tion 4.1 shows the dynamics converge to the performative stable and optimal point when when the
learning rate is small enough. On the other hand, section 4.2 shows the dynamics can have chaotic
behavior if the collective inﬂuence Ln is large enough."
DYNAMICAL SYSTEM,0.15350877192982457,"Now, we deﬁne our dynamics (⃗θt)t≥0 formally. At each round, each agent accesses the data dis-
tribution which inﬂuenced by their previous model, and updates his model through exponentiated
gradient descent. Speciﬁcally, given an initial model proﬁle ⃗θ0 ∈Θn and a learning rate proﬁle
η := (η1, . . . , ηn), each agent i applies the exponentiated gradient descent with initial parameter θi
0
and learning rate ηi > 0: At round t + 1 > 1, each agent i use D(⃗θt) and estimates the gradient of
the (expected) loss, gi(⃗θt) deﬁned in eq. (1), and updates his model according to deﬁnition 2.3,"
DYNAMICAL SYSTEM,0.15570175438596492,"θi
t+1,k =
θi
t,k exp(−ηigi
k(⃗θt))
Pd
l=1 θi
t,l exp(−ηigi
l(⃗θt))
for all t ≥0, i ∈[n], and k ∈[d].
(3)"
DYNAMICAL SYSTEM,0.15789473684210525,Under review as a conference paper at ICLR 2022
DYNAMICAL SYSTEM,0.1600877192982456,"We will use superscript to denote agent, i ∈[n], and subscript for time, t ≥0, and index of feature,
k, l ∈[d]. Recall that the gradient of agent i’s average loss is ¯gi(⃗θ) := P"
DYNAMICAL SYSTEM,0.16228070175438597,"l θi
lgi
l(⃗θ), and eq. (3)"
DYNAMICAL SYSTEM,0.16447368421052633,"can be rewritten as
θi
k exp(−ηigi
k(⃗θt))
P"
DYNAMICAL SYSTEM,0.16666666666666666,"l θi
l exp(−ηigi
l(⃗θt)) =
θi
k exp(ηi(¯gi(⃗θt)−gi
k(⃗θt)))
P"
DYNAMICAL SYSTEM,0.16885964912280702,"l θi
l exp(ηi(¯gi(⃗θt)−gi
l(⃗θt))). Finally, given ⃗θ∗and i ∈[d],"
DYNAMICAL SYSTEM,0.17105263157894737,"we deﬁne the support of ⃗θ∗as Si ⊆[d] = {k : (θ∗)i
k > 0}, and ¯Si := [d] \ Si. Then ⃗θ∗is an
equilibrium (or ﬁxed point) of eq. (3) if"
DYNAMICAL SYSTEM,0.17324561403508773,"gi
k(⃗θ∗) = ¯gi(⃗θ∗), for all i ∈[n], k ∈Si.
(4)
We say a ﬁxed point of eq. (3) is isolated if there exists an open set of it so that no other ﬁxed point
is in the set. Additionally, the performative stable condition in proposition 3.1 is equivalent to"
DYNAMICAL SYSTEM,0.17543859649122806,"gi
k(⃗θ∗) = ¯gi(⃗θ∗) and gi
l(⃗θ∗) ≥¯gi(⃗θ∗), for all i ∈[n], k ∈Si, l ∈¯Si.
(5)
Therefore, the set of ﬁxed points of eq. (3) contains the performative stable point."
CONVERGING WITH SMALL LEARNING RATE,0.17763157894736842,"4.1
CONVERGING WITH SMALL LEARNING RATE"
CONVERGING WITH SMALL LEARNING RATE,0.17982456140350878,"In this section, we show when the learning rate of each agent is small enough the the dynamics in
eq. (3) converge to performative stable point. Speciﬁcally, if the parameter of multi-agent perfor-
mative learning (n, d, A, λ) is ﬁxed, the dynamics in eq. (3) converge to performative stable point
when η is “small” enough."
CONVERGING WITH SMALL LEARNING RATE,0.18201754385964913,"By eq. (5), ⃗θ∗is a performative stable if the gradient in the support is no less than the average
gradient. We call a performative stable point ⃗θ∗proper if the gradient of non-support coordinate
is greater than the average gradient: for all i ∈[n] l ∈¯Si, gi
l(⃗θ∗) > ¯gi(⃗θ∗). The below theorem
shows if the performative stable point is proper and equilibria satisfying eq. (4) are isolated, eq. (3)
converges when maxi ηi is small enough and the ratio of ηi/ηj is bounded for all i and j.
Theorem 4.1 (Convergence). Consider a constant Rη > 0, and a multi-agent performative learning
setting with parameter n, d, A, b, λ such that A is positive deﬁnite, the performative stable point ⃗θ∗
is proper and its equilibria (deﬁned in eq. (4)) are isolated. There exists η∗> 0 so that dynamic in
eq. (3) with learning rate proﬁle η converges to the performative stable point, limt→∞⃗θt = ⃗θ∗, if
the initial state is an interior point and η satisﬁes maxi ηi ≤η∗and maxi ηi/ mini ηi ≤Rη."
CONVERGING WITH SMALL LEARNING RATE,0.18421052631578946,"Informally, when the learning rate η are small, ⃗θt in eq. (3) can be approximated by a solution of an
ordinary differential equation, ⃗ϑ(t∥η∥1), where the initial condition is ⃗ϑ(0) = ⃗θ0 and
d
dtϑi
k(t) =
ηi
∥η∥1
ϑi
k(t)(¯gi(⃗ϑ(t)) −gi
k(⃗ϑ(t)))
(6)"
CONVERGING WITH SMALL LEARNING RATE,0.18640350877192982,"for all t ≥0, i ∈[n], and k ∈[d]. We formalize this intuition in the proof of lemma 4.4. Note that
the set of ﬁxed points of eq. (6) is identical to eq. (3) and satisﬁes eq. (4)."
CONVERGING WITH SMALL LEARNING RATE,0.18859649122807018,"The proof of theorem 4.1 has two parts. First we show the continuous approximation eq. (6) con-
verges to the performative stable point. Then we study the relationship between eq. (3) and eq. (6),
and prove the eq. (3) also converges to a performative stable point."
CONVERGING WITH SMALL LEARNING RATE,0.19078947368421054,"From Potential Function to Convergence of Equation (6)
In this section, theorem 4.2 shows
the dynamics of eq. (6) converge to performative stable point which will be useful to show the
convergence of eq. (3)."
CONVERGING WITH SMALL LEARNING RATE,0.19298245614035087,"Theorem 4.2. If all points satisfying eq. (4) are isolated and A is positive deﬁnite, and ⃗ϑ(0) is in
the interior of Θn, the limit limt→∞⃗ϑ(t) = ⃗θ∗is the performative stable point."
CONVERGING WITH SMALL LEARNING RATE,0.19517543859649122,"Theorem 4.2 can be seen as the continuous version of theorem 4.1. Compared to theorem 4.1, theo-
rem 4.2 does not require that the performative stable point is proper, but theorem 4.2 also implicitly
requires the ratio of learning rate between any two agents is bounded."
CONVERGING WITH SMALL LEARNING RATE,0.19736842105263158,"To prove theorem 4.2. we prove lemma 4.3 which shows that Φ in eq. (2) is a potential function
for eq. (6) so that time derivative of Φ is decreasing for all non-ﬁxed points. Then, in the proof of
theorem 4.2, we further prove that the dynamics in eq. (6) converge to performative stable points
when the initial condition ⃗ϑ(0) is an interior point. The proof is similar to a proof in Kleinberg et al.
(2009), and is presented in appendix B."
CONVERGING WITH SMALL LEARNING RATE,0.19956140350877194,Under review as a conference paper at ICLR 2022
CONVERGING WITH SMALL LEARNING RATE,0.20175438596491227,"Lemma 4.3. Given a solution of eq. (6), the time derivative of Φ in eq. (2) is 0 at ﬁxed points of
eq. (6), and negative at all other points. Furthermore,"
CONVERGING WITH SMALL LEARNING RATE,0.20394736842105263,"d
dtΦ(⃗ϑ(t)) ≤
−1
2 P"
CONVERGING WITH SMALL LEARNING RATE,0.20614035087719298,"i ηi
P"
CONVERGING WITH SMALL LEARNING RATE,0.20833333333333334,i λiηi  X
CONVERGING WITH SMALL LEARNING RATE,0.21052631578947367,"i,k
λiηi|ϑi
k(
X"
CONVERGING WITH SMALL LEARNING RATE,0.21271929824561403,"l
ϑi
lgi
l −gi
k)|   2"
CONVERGING WITH SMALL LEARNING RATE,0.2149122807017544,"≤
−mini λiηi
2 P"
CONVERGING WITH SMALL LEARNING RATE,0.21710526315789475,"i ηi
P"
CONVERGING WITH SMALL LEARNING RATE,0.21929824561403508,"i λiηi
∥⃗ξ(⃗ϑ)∥2
1."
CONVERGING WITH SMALL LEARNING RATE,0.22149122807017543,"From Approximation to Convergence of Equation (3)
Given the convergence of eq. (6), we
show the dynamics of eq. (3) also converges to a performative stable point. The argument has two
stages. We ﬁrst show given any neighborhood of performative stable points D, eq. (3) will hits D
and stay in D in ﬁnite amount of steps in lemma 4.4. Then lemma 4.5 shows that eq. (3) converges
to a performative stable point which completes the proof of theorem 4.1."
CONVERGING WITH SMALL LEARNING RATE,0.2236842105263158,"Lemma 4.4. Given any open set D ∈Θn that contains the performative stable point, there exists
η∗small enough so that for all ⃗θ0 ∈Θn, there exists τ so that ⃗θt ∈D for all t ≥τ."
CONVERGING WITH SMALL LEARNING RATE,0.22587719298245615,"The proof is based on standard approximation result of numerical solution to ordinary differential
equations, and is presented in appendix C."
CONVERGING WITH SMALL LEARNING RATE,0.22807017543859648,"Lemma 4.5. Let ⃗θ∗is the performative stable point and D is a small enough neighborhood of ⃗θ∗.
Besides the condition in theorem 4.1, if the initial condition of eq. (3), ⃗θ0, is in D and ⃗θt ∈D for
all t ≥0, the limit of eq. (3) is the performative stable point limt→∞⃗θt = ⃗θ∗."
CONVERGING WITH SMALL LEARNING RATE,0.23026315789473684,"The proof uses the fact that the right-hand side of eq. (3) decreases as the dynamic converges to the
ﬁxed point. Therefore, even though the learning rate proﬁle is ﬁxed, the error between eq. (3) and
eq. (6) vanishes as they converge to the ﬁxed point. We present the proof in appendix D."
CHAOS WITH CONSTANT LEARNING RATE,0.2324561403508772,"4.2
CHAOS WITH CONSTANT LEARNING RATE"
CHAOS WITH CONSTANT LEARNING RATE,0.23464912280701755,"Now we want to ask the converse question in section 4.1. Do the dynamics in eq. (3) still converge, if
the learning rate is ﬁxed, as the number of agent increases? Alternatively, do the dynamics converge
when the agents have overwhelming inﬂuence on the data distribution?"
CHAOS WITH CONSTANT LEARNING RATE,0.23684210526315788,Theorem 4.6 shows that the dynamics is Li-York chaotic when Ln = P
CHAOS WITH CONSTANT LEARNING RATE,0.23903508771929824,"i λi is large even with d = 2.
Note that large Ln may be due to a ﬁxed number of agent which have overwhelming inﬂuence, or
the number of agents is large. The later case implies for any small η, no matter how cautious the
agents are, as number of agent increases the chaos inevitably occurs."
CHAOS WITH CONSTANT LEARNING RATE,0.2412280701754386,"Theorem 4.6. Given a multi-party induced location scale family distribution with A, b, d = 2,
and a common learning rate η > 0, if all n agents use the exponentiated gradient with a common
learning rate η in eq. (3) and A is diagonally dominant, there exists a carrying capacity L∗such
that if Ln = Pn
i=1 λi ≥L∗the dynamics (⃗θt)t∈N is Li-Yorke chaotic and thus has periodic orbits
of all possible periods."
CHAOS WITH CONSTANT LEARNING RATE,0.24342105263157895,"To prove theorem 4.6, we show there exists an uncountable scrambled set deﬁned in deﬁnition 2.4.
First we consider all agents start from the same initial model, and show the dynamics eq. (3) can be
captured by the following function,"
CHAOS WITH CONSTANT LEARNING RATE,0.24561403508771928,"fu,v(x) =
x
x + (1 −x) exp(u(x −v)) ∀x ∈[0, 1]
(7)"
CHAOS WITH CONSTANT LEARNING RATE,0.24780701754385964,"with proper choice of u ∈R and v ∈R. Note that v is an equilibrium, and u controls steepness.
First, when all agents start from the same initial model, θi
0 = θ0 for all i ∈[n], and use the same
learning rate η, their models are identical for all t ≥0. For all t there exists θt so that θi
t = θt for
all i. Additionally, since d = 2, we can use a single parameter to encode a linear predictive model
with constraints. Given θ ∈Θ = ∆2, we deﬁne p(θ) = θ1 ∈[0, 1] and omit the input θ when it
is clear. Thus, we can rewrite the dynamics as pt = p(θt) which are one-dimensional dynamics on
[0, 1], and pt+1 =
pt
pt+(1−pt)eη(gi
1(⃗
θt)−gi
2(⃗
θt)) . We set"
CHAOS WITH CONSTANT LEARNING RATE,0.25,"α(L) =2η (1 + L) (A1,1 −A1,2 −A2,1 + A2,2) and β(L) =
(1 + L)(A2,2 −A2,1) + (b1 −b2)
(1 + L)(A1,1 −A1,2 −A2,1 + A2,2),"
CHAOS WITH CONSTANT LEARNING RATE,0.25219298245614036,Under review as a conference paper at ICLR 2022
CHAOS WITH CONSTANT LEARNING RATE,0.2543859649122807,and write αn = α(Ln) and βn = β(Ln). By direct computation the dynamic of pt is
CHAOS WITH CONSTANT LEARNING RATE,0.2565789473684211,"pt+1 = fαn,βn(pt)
(8)"
CHAOS WITH CONSTANT LEARNING RATE,0.25877192982456143,"where αn encodes the update pace and βn is an equilibrium of the dynamic. We further set β∞:=
A2,2−A2,1
A1,1−A1,2−A2,1+A2,2 and δ(L) := β(L)−β∞which converges to zero as L →∞. If A is diagonally
dominant α(L) is positive and increasing for all L ≥0. Additionally, because A1,1 −A1,2 and
A2,2 −A2,1 are positive, we can permute the coordinate so that β∞∈(0, 1/2]. With Li et al.
(1982), the lemma below implies the existence of period three points and the proof is in appendix E."
CHAOS WITH CONSTANT LEARNING RATE,0.26096491228070173,"Lemma 4.7. If β∞∈(0, 1/2), there exists a constant L∗> 0 so that if L ≥L∗, there exists a
trajectory x0, x1, x2, and x3 with fα(L),β(L)(xi) = xi+1 such that x3 < x0 < x1."
CHAOS WITH CONSTANT LEARNING RATE,0.2631578947368421,"Proof of theorem 4.6. First by lemma 4.7, for all L ≥L∗, there exists a trajectory x0, x1, x2, x3 so
that x3 < x0 < x1. Additionally, existence of such trajectory implies the exists of period three
points by Li et al. (1982). Finally, by the seminal work of Li & Yorke (1975), it implies that the map
is Li-York chaotic."
SIMULATION,0.26535087719298245,"5
SIMULATION"
SIMULATION,0.2675438596491228,"(a) (14, 0.001) without noise
(b) (1.4, 0.05) without noise
(c) (14, 0.05) without noise"
SIMULATION,0.26973684210526316,"(d) (14, 0.001) with noise
(e) (1.4, 0.05) with noise
(f) (14, 0.05) with noise"
SIMULATION,0.2719298245614035,"Figure 1: Here we plot the temporal behavior of pt starting at p0 = 0.2 for 100 rounds under various
L and η, and noisy estimation of gradient of mean squared error with m samples. The top row
(ﬁgs. 1a to 1c) present different combination of (L, η), and bottom row (ﬁgs. 1d to 1f) consider the
gradient is estimated from m = 10 and m = 100 samples."
SIMULATION,0.2741228070175439,"Now we simulate the one-dimensional dynamics in eq. (8) of one agent with different learning rate
η and collective inﬂuence L."
SIMULATION,0.27631578947368424,"We ﬁrst deﬁne a location-scale distribution map. Let the feature x1, x2 and noise x0 are mutually
independent Gaussian distribution with zero mean, and the variance are E[x2
1] = 3, E[x2
2] = 7, and
E[x2
0] = 1. Finally, θ0 = 0. Therefore,"
SIMULATION,0.27850877192982454,"A = E[xx⊤] =

3
0
0
7"
SIMULATION,0.2807017543859649,"
, and b = Aθ0 + E[x0x] =

0
0 
."
SIMULATION,0.28289473684210525,Under review as a conference paper at ICLR 2022
SIMULATION,0.2850877192982456,"Given learning rate η > 0, and collective inﬂuence L, we have α(L) = 20η(1 + L), and the
performative stable point β(L) = 0.7."
SIMULATION,0.28728070175438597,"The top row of ﬁg. 1 shows the temporal behavior of pt under different (L, η). The bottom row in
ﬁg. 1 demonstrates our (convergent and chaotic) results are robust even when the value of gradient is
noisy. Speciﬁcally, we consider at each round t, instead of gi
1(⃗θt)−gi
2(⃗θt) = 2(1+L)(1, −1)Aθt−
2(1, −1)b, the agent replace A and b with empirical moments on m samples. This process can
be seen as a stochastic exponentiated gradient descent which uses a stochastic estimation of the
gradient."
SIMULATION,0.2894736842105263,"We can see chaotic behavior happens in ﬁg. 1c with L = 14 and η = 0.05, and such behavior
persists in ﬁg. 1f when the evaluations of gradient are noisy. On the other hand, when the learning
rate is small enough (ﬁgs. 1a and 1b) the dynamics converge to the performative stable point 0.7.
Furthermore, in ﬁgs. 1d and 1e the dynamics converge even with noisy estimation of gradient."
SIMULATION,0.2916666666666667,"Finally, ﬁg. 2 shows the temporal behavior of the loss. Under the same setting as ﬁg. 1c, ﬁg. 2b
shows not only the temporal behavior pt is chaotic, but also the mean squared loss. On the other
hand, under the same setting as ﬁg. 1a, ﬁg. 2a shows convergent behavior of loss."
SIMULATION,0.29385964912280704,"(a) (14, 0.001) without noise
(b) (14, 0.05) without noise"
SIMULATION,0.29605263157894735,Figure 2: The temporal behavior of the total cost for 100 rounds under various η.
CONCLUSION,0.2982456140350877,"6
CONCLUSION"
CONCLUSION,0.30043859649122806,"We introduce a framework of multi-agent performative prediction and investigate whether classical
reinforcement learning algorithms can converge or behave chaotically depending on the collective
inﬂuence of the agents model and learning rate. However, we view our example as only scratching
the surface of the work of multi-agent performative predictions."
CONCLUSION,0.3026315789473684,"Our framework leads to several new theoretical problems. In particular, it would be interesting
to understand whether this threshold is generic and if our results still hold on other reinforcement
learning algorithms or other general multi-agent distribution maps. Our framework also provides a
new viewpoint to several applications. One natural application is strategic classiﬁcation. Hardt et al.
(2016) In this context, our framework can be seen as strategic learners in strategic classiﬁcation
problem where both data and classiﬁers are strategic. However, the features also respond to the
deployed models in conventional strategic classiﬁcation, which is not captured in our multi-agent
location-scale distribution map. It would be interesting to investigate our dynamics in the context of
strategic prediction. Another application is pricing strategy/prediction, where multiple companies
predict the demand function and set their prices."
CONCLUSION,0.3048245614035088,"Both our digital and real-world environments are increasingly under the inﬂuence of or ever more
powerful and numerous ML systems. As these algorithms trigger actions that change the state of
the system that produces their joint input data (e.g., AI-triggered ads shown to users affecting their
behavior, or automated trading systems affecting stock prices, etc), they are effectively forming
closed loop systems and can no longer be understood fully in isolation. As we show in this paper,
even fairly simple and innocuous such settings can exhibit phase transitions going from optimal
behavior to chaos. We believe such phenomena are worthy of a careful investigation and we hope
that this paper sets out some useful building blocks by bringing together optimization/performance
analysis with Lyapunov theory and chaos theory."
CONCLUSION,0.30701754385964913,Under review as a conference paper at ICLR 2022
ETHICS STATEMENT,0.3092105263157895,ETHICS STATEMENT
ETHICS STATEMENT,0.31140350877192985,"Our work showcases the possibility of competing prediction algorithms leading to instability and
chaos. Extra steps should be taken, whenever possible, so that related systems operate within the
range of parameters leading to stability. We hope that our work helps both by identifying a potential
threat for ML systems as well as providing some guidance on how to counter or minimize it."
ETHICS STATEMENT,0.31359649122807015,REPRODUCIBILITY
ETHICS STATEMENT,0.3157894736842105,"All of our theoretical results are stated fully, including previous deﬁnitions and results on which they
are based. They are accompanied by proofs, either in the main paper or in the appendix. The setting
of our simulation results are stated fully in the main paper."
REFERENCES,0.31798245614035087,REFERENCES
REFERENCES,0.3201754385964912,"Gabriel P Andrade, Rafael Frongillo, and Georgios Piliouras. Learning in matrix games can be
arbitrarily complex. In Conference on Learning Theory (COLT), 2021."
REFERENCES,0.3223684210526316,"James P. Bailey and Georgios Piliouras. Multiplicative weights update in zero-sum games. In ACM
Confernce on Economics and Computation, pp. 321–338, 2018."
REFERENCES,0.32456140350877194,"David Balduzzi, Wojciech M Czarnecki, Thomas W Anthony, Ian M Gemp, Edward Hughes, Joel Z
Leibo, Georgios Piliouras, and Thore Graepel. Smooth markets: A basic mechanism for organiz-
ing gradient-based learners. 2020."
REFERENCES,0.3267543859649123,"Peter L Bartlett. Learning with a slowly changing distribution. In Proceedings of the ﬁfth annual
workshop on Computational learning theory, pp. 243–252, 1992."
REFERENCES,0.32894736842105265,"Jakub Bielawski, Thiparat Chotibut, Fryderyk Falniowski, Grzegorz Kosiorowski, Michał Misi-
urewicz, and Georgios Piliouras. Follow-the-regularized-leader routes to chaos in routing games.
ICML, 2021."
REFERENCES,0.33114035087719296,"Yun Kuen Cheung. Multiplicative weights updates with constant step-size in graphical constant-sum
games. In NeurIPS 2018, pp. 3532–3542, 2018."
REFERENCES,0.3333333333333333,"Yun Kuen Cheung and Georgios Piliouras. Chaos, extremism and optimism: Volume analysis of
learning in games. In NeurIPS 2020, 2020."
REFERENCES,0.3355263157894737,"Yun Kuen Cheung and Yixin Tao. Chaos of learning beyond zero-sum and coordination via game
decompositions. In International Conference on Learning Representations, 2020."
REFERENCES,0.33771929824561403,"Yun Kuen Cheung, Stefanos Leonardos, and Georgios Piliouras. Learning in markets: Greed leads
to chaos but following the price is right. In Zhi-Hua Zhou (ed.), Proceedings of the Thirtieth
International Joint Conference on Artiﬁcial Intelligence, IJCAI 2021, Virtual Event / Montreal,
Canada, 19-27 August 2021, pp. 111–117. ijcai.org, 2021. doi: 10.24963/ijcai.2021/16."
REFERENCES,0.3399122807017544,"Thiparat Chotibut, Fryderyk Falniowski, Michał Misiurewicz, and Georgios Piliouras. The route to
chaos in routing games: When is price of anarchy too optimistic? NeurIPS, 2020."
REFERENCES,0.34210526315789475,"Johanne Cohen, Am´elie H´eliou, and Panayotis Mertikopoulos. Learning with bandit feedback in
potential games. In Proceedings of the 31st International Conference on Neural Information
Processing Systems, pp. 6372–6381, 2017."
REFERENCES,0.3442982456140351,"Dmitriy Drusvyatskiy and Lin Xiao. Stochastic optimization with decision-dependent distributions,
2020."
REFERENCES,0.34649122807017546,"Lampros Flokas, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Thanasis Lianeas, Panayotis Mer-
tikopoulos, and Georgios Piliouras. No-regret learning and mixed nash equilibria: They do not
mix. In Conference on Neural Information Processing Systems (NeurIPS), 2020."
REFERENCES,0.34868421052631576,Under review as a conference paper at ICLR 2022
REFERENCES,0.3508771929824561,"Angeliki Giannou, Emmanouil-Vasileios Vlatakis-Gkaragkounis, and Panayotis Mertikopoulos.
Survival of the strictest: Stable and unstable equilibria under regularized learning with partial
information. COLT, 2021."
REFERENCES,0.3530701754385965,"Moritz Hardt, Nimrod Megiddo, Christos Papadimitriou, and Mary Wootters. Strategic classiﬁca-
tion. In Proceedings of the 2016 ACM conference on innovations in theoretical computer science,
pp. 111–122, 2016."
REFERENCES,0.35526315789473684,"Zachary Izzo, Lexing Ying, and James Zou. How to learn when data reacts to your model: perfor-
mative gradient descent. arXiv preprint arXiv:2102.07698, 2021."
REFERENCES,0.3574561403508772,"Jyrki Kivinen and Manfred K Warmuth. Exponentiated gradient versus gradient descent for linear
predictors. information and computation, 132(1):1–63, 1997."
REFERENCES,0.35964912280701755,"Robert Kleinberg, Georgios Piliouras, and ´Eva Tardos. Multiplicative updates outperform generic
no-regret learning in congestion games. In Proceedings of the forty-ﬁrst annual ACM symposium
on Theory of computing, pp. 533–542, 2009."
REFERENCES,0.3618421052631579,"Anthony Kuh, Thomas Petsche, and Ronald L Rivest. Learning time-varying concepts. In NIPS, pp.
183–189, 1990."
REFERENCES,0.36403508771929827,"Stefanos Leonardos, Barnab´e Monnot, Dani¨el Reijsbergen, Stratis Skoulakis, and Georgios Pil-
iouras. Dynamical analysis of the eip-1559 ethereum fee market, 2021."
REFERENCES,0.36622807017543857,"Alistair Letcher. On the impossibility of global convergence in multi-loss optimization. In Interna-
tional Conference on Learning Representations, 2021."
REFERENCES,0.3684210526315789,"Tien-Yien Li and James A. Yorke.
Period three implies chaos.
The American Mathematical
Monthly, 82(10):985–992, 1975. ISSN 00029890, 19300972. URL http://www.jstor.
org/stable/2318254."
REFERENCES,0.3706140350877193,"Tien-Yien Li, Michał Misiurewicz, Giulio Pianigiani, and James A. Yorke.
Odd chaos.
Physics Letters A, 87(6):271–273, 1982.
ISSN 0375-9601.
doi:
https://doi.org/10.
1016/0375-9601(82)90692-2.
URL https://www.sciencedirect.com/science/
article/pii/0375960182906922."
REFERENCES,0.37280701754385964,"Celestine Mendler-D¨unner, Juan C Perdomo, Tijana Zrnic, and Moritz Hardt. Stochastic optimiza-
tion for performative prediction. arXiv preprint arXiv:2006.06887, 2020."
REFERENCES,0.375,"John Miller, Juan C Perdomo, and Tijana Zrnic. Outside the echo chamber: Optimizing the perfor-
mative risk. arXiv preprint arXiv:2102.08570, 2021."
REFERENCES,0.37719298245614036,"Gerasimos Palaiopanos, Ioannis Panageas, and Georgios Piliouras.
Multiplicative weights up-
date with constant step-size in congestion games: Convergence, limit cycles and chaos. CoRR,
abs/1703.01138, 2017. URL http://arxiv.org/abs/1703.01138."
REFERENCES,0.3793859649122807,"Ioannis Panageas, Georgios Piliouras, and Xiao Wang. Multiplicative weights updates as a dis-
tributed constrained optimization algorithm: Convergence to second-order stationary points al-
most always. In International Conference on Machine Learning, pp. 4961–4969. PMLR, 2019."
REFERENCES,0.3815789473684211,"Juan Perdomo, Tijana Zrnic, Celestine Mendler-D¨unner, and Moritz Hardt. Performative prediction.
In International Conference on Machine Learning, pp. 7599–7609. PMLR, 2020."
REFERENCES,0.38377192982456143,"Nelson Vadori, Rahul Savani, Thomas Spooner, and Sumitra Ganesh.
Consensus multiplica-
tive weights update: Learning to learn using projector-based game signatures. arXiv preprint
arXiv:2106.02615, 2021."
REFERENCES,0.38596491228070173,Under review as a conference paper at ICLR 2022
REFERENCES,0.3881578947368421,"A
PROOFS AND DETAILS IN SECTION 3"
REFERENCES,0.39035087719298245,"Proof of proposition 3.1. First under the mean squared loss function, each agent i’s decoupled per-
formative loss function ℓ(⃗θ′, θi) is convex in θi. Thus, for linear predictive model, we can apply the
KKT conditions on deﬁnition 2.1 so that a collection of predictive models ⃗θ ∈Θn is performatively
stable if and only if for all i ∈[n], k ∈[d] with θi
k > 0,
∂
∂θi
k ℓ(⃗θ′, θi) ≤
∂
∂θi
l ℓ(⃗θ′, θi) for all l ∈[d]"
REFERENCES,0.3925438596491228,"where ⃗θ′ = ⃗θ. Therefore, with eq. (1), ⃗θ∗is performative stable if"
REFERENCES,0.39473684210526316,"gi
k(⃗θ∗) ≤gi
l(⃗θ∗)
(9)"
REFERENCES,0.3969298245614035,"holds for all i ∈[n] and k ∈[d] with θi
k > 0."
REFERENCES,0.3991228070175439,"With eq. (9), we now show that there exists a unique performative stable point ⃗θ∗by proving that 1)
Φ in eq. (2) is strictly convex, and 2) ⃗θ∗is a minimizer of Φ. First, to show Φ is strictly convex, it is
sufﬁcient to show the Hessian of Φ positive deﬁnite. Because Φ is a quadratic function on Θn, the
Hessian of Φ is a constant matrix in Rnd×nd By the partial derivative of eq. (2), for all i, j ∈[n] and
k, l ∈[d], we have (∇2Φ)ik,jl =
∂2"
REFERENCES,0.40131578947368424,"∂θi
k∂θj
l Φ = 2λiλjAk,l if i ̸= j and (∇2Φ)ik,il = 2λi(λi +1)Ak,l."
REFERENCES,0.40350877192982454,"Let L ∈Rn×n with Lij = 2λiλj if i ̸= j and 2λi(1 + λi) which is positive deﬁnite because λi > 0
for all i ∈[n]. Then, the Hessian of Φ is the Kronecker product of L and A, ∇2Φ =  
"
REFERENCES,0.4057017543859649,"2λ1(1 + λ1)A
. . .
2λ1λnA
...
...
...
2λnλ1A
. . .
2λn(1 + λn)A "
REFERENCES,0.40789473684210525,"
= L ⊗A."
REFERENCES,0.4100877192982456,"Because L and A are both positive deﬁnite, the Hessian is also positive deﬁnite. Therefore, Φ is
strictly convex, and there exist a unique minimum of Φ in the compact set Θn. Now we show ⃗θ∗is
performative stable if and only if ⃗θ∗is a minimizer of Φ. By the ﬁrst order condition and the partial
derivative of eq. (2), the minimum of eq. (2) at ⃗θ∗if and only if gi
k(⃗θ∗) ≤gi
l(⃗θ∗) for all i ∈[n]
k, l ∈[d] with (θ∗)i
k > 0. Therefore, ⃗θ∗is the minimum of Φ if and only if ⃗θ∗is a performative
stable point."
REFERENCES,0.41228070175438597,"Proof of proposition 3.2. Given a proﬁle of models ⃗θ, the total cost is
X"
REFERENCES,0.4144736842105263,"i
ℓ(⃗θ, (θ)i) =
X"
REFERENCES,0.4166666666666667,"i
E(x,y)∼D(⃗θ)[(y −θi · x)2] =
X i
E     *"
REFERENCES,0.41885964912280704,"x, θ0 −
X"
REFERENCES,0.42105263157894735,"j
λjθj −θi
+ + x0   2 "
REFERENCES,0.4232456140350877,"which is a convex function on ⃗θ ∈Θn. Additionally,"
REFERENCES,0.42543859649122806,"∂
∂θi
k X"
REFERENCES,0.4276315789473684,"ı
ℓ(⃗θ, θı) = (1 + λi)gi
k(⃗θ, ⃗θ) +
X"
REFERENCES,0.4298245614035088,"ı∈[n]:ı̸=i
λigi
k(⃗θ, ⃗θ) = (1 + nλi)gi
k(⃗θ, ⃗θ)"
REFERENCES,0.43201754385964913,"which is the gradient of decoupled performative loss scaled by (1 + nλi). Thus, we can apply the
KKT conditions and the minimum happens if and only if eq. (9) holds."
REFERENCES,0.4342105263157895,"B
PROOF AND DETAILS FOR THEOREM 4.2"
REFERENCES,0.43640350877192985,"Proof of lemma 4.3. By chain rule,"
REFERENCES,0.43859649122807015,"d
dtΦ(⃗ϑ(t)) =
X"
REFERENCES,0.4407894736842105,"i∈[n],k∈[d]"
REFERENCES,0.44298245614035087,"∂
∂θi
k
(⃗ϑ(t)) · d"
REFERENCES,0.4451754385964912,"dt
⃗ϑ(t),
(10)"
REFERENCES,0.4473684210526316,so the time derivative of the potential function is zero if the dynamics is at a ﬁxed point of eq. (6).
REFERENCES,0.44956140350877194,Under review as a conference paper at ICLR 2022
REFERENCES,0.4517543859649123,"Now we compute a closed form of the time derivative and show the derivative is zero only if the
dynamics is at a ﬁxed point of eq. (6). Here we omit the input t to simplify the notation."
REFERENCES,0.45394736842105265,"d
dtΦ(⃗ϑ(t)) =
X i,k"
REFERENCES,0.45614035087719296,"∂
∂θi
k
(⃗ϑ(t)) ·
ηi
∥η∥1
ϑi
k(t)(
X"
REFERENCES,0.4583333333333333,"l
ϑi
l(t)gi
l(⃗ϑ(t)) −gi
k(⃗ϑ(t))) (by eqs. (6) and (10))"
REFERENCES,0.4605263157894737,"=
1
∥η∥1 X"
REFERENCES,0.46271929824561403,"i
λiηi X k"
REFERENCES,0.4649122807017544," 
gi
k

· ϑi
k X"
REFERENCES,0.46710526315789475,"l
ϑi
lgi
l −gi
k !!"
REFERENCES,0.4692982456140351,(by the partial derivative of eq. (2))
REFERENCES,0.47149122807017546,"=
1
2∥η∥1 X"
REFERENCES,0.47368421052631576,"i
λiηi
X"
REFERENCES,0.4758771929824561,"k,l∈[d]
ϑi
kϑi
l(2gi
kgi
l −2(gi
k)2)
(because P"
REFERENCES,0.4780701754385965,"l ϑi
l = 1) = −1 2∥η∥1 X"
REFERENCES,0.48026315789473684,"i
λiηi
X"
REFERENCES,0.4824561403508772,"k,l∈[d]
ϑi
kϑi
l(gi
k −gi
l)2"
REFERENCES,0.48464912280701755,Now we bound the time derivative.
REFERENCES,0.4868421052631579,−2∥η∥1 X
REFERENCES,0.48903508771929827,"i
λiηi"
REFERENCES,0.49122807017543857,"!
d
dtΦ(⃗ϑ(t)) =  
X"
REFERENCES,0.4934210526315789,"i∈[n],k,l∈[d]
λiηiϑi
kϑi
l    
X"
REFERENCES,0.4956140350877193,"i∈[n],k,l∈[d]
λiηiϑi
kϑi
l(gi
k −gi
l)2 "
REFERENCES,0.49780701754385964,"
(P
k ϑi
k = P
l ϑi
l = 1) ≥  
X"
REFERENCES,0.5,"i∈[n],k,l∈[d]
λiηiϑi
kϑi
l|gi
k −gi
l|   2"
REFERENCES,0.5021929824561403,".
(by Cauchy inequality) ≥  
X"
REFERENCES,0.5043859649122807,"i∈[n],k∈[d]
λiηi"
REFERENCES,0.506578947368421,"ϑi
k
X"
REFERENCES,0.5087719298245614,"l∈[d]
ϑi
l(gi
k −gi
l)    2"
REFERENCES,0.5109649122807017,(by triangle inequality)
REFERENCES,0.5131578947368421,"Therefore, d"
REFERENCES,0.5153508771929824,"dtΦ(⃗ϑ(t)) = 0 only if ϑi
k

gi
k −P"
REFERENCES,0.5175438596491229,"l∈[d] ϑi
lgi
l

= 0 for all i ∈[n] and k ∈[d] which is a
ﬁxed point of eq. (6)."
REFERENCES,0.5197368421052632,"We can further simplify the bound by
⃗ξ.
Because P"
REFERENCES,0.5219298245614035,"i,k λiηi|ϑi
k(P"
REFERENCES,0.5241228070175439,"l ϑi
lgi
l −gi
k)|
≥"
REFERENCES,0.5263157894736842,(mini λiηi) P
REFERENCES,0.5285087719298246,"i,k |ξi
k(⃗ϑ)| = (mini λiηi) ∥⃗ξ(⃗ϑ)∥1, d"
REFERENCES,0.5307017543859649,"dtΦ(⃗ϑ(t)) ≤
−mini λiηi
2 P"
REFERENCES,0.5328947368421053,"i ηi
P"
REFERENCES,0.5350877192982456,"i λiηi ∥⃗ξ(⃗ϑ)∥2
1."
REFERENCES,0.5372807017543859,"Proof of theorem 4.2. When the ﬁxed points are isolated satisfying eq. (4), by lemma 4.3, the dy-
namics in eq. (6) converges to a ﬁxed point of eq. (6), ⃗θ∗∈Θn. Because ⃗θ∗is a ﬁxed point, for all
i ∈[n], k ∈[d],"
REFERENCES,0.5394736842105263,"(θ∗)i
k

¯gi(⃗θ∗) −gi
k(⃗θ∗)

= (θ∗)i
k
X"
REFERENCES,0.5416666666666666,"l
(θ∗)i
lgi
l(⃗θ∗) −gi
k(⃗θ∗) = 0"
REFERENCES,0.543859649122807,"By proposition 3.1, the ﬁxed point condition implies each coordinate of the gradient of loss in the
support are identical, gi
k(⃗θ∗) = ¯gi(⃗θ∗) for all i and k ∈Si. Thus, if the ﬁxed point ⃗θ∗is not
performative stable, there exists ı and κ with (θ∗)ı
κ = 0 so that gı
κ(⃗θ∗) < ¯gı(⃗θ∗). Furthermore,
exp(−ηıgı
κ(⃗θ∗)) > P"
REFERENCES,0.5460526315789473,"l(θ∗)ı
l exp(−ηıgı
l(⃗θ∗)). We can pick a small enough ϵ > 0 and deﬁne"
REFERENCES,0.5482456140350878,"Uϵ := {⃗θ : exp(−ηıgı
κ) >
X"
REFERENCES,0.5504385964912281,"l
θı
l exp(−ηıgı
l) + ϵ}
(11)"
REFERENCES,0.5526315789473685,"which contains ⃗θ∗and is an open set because ⃗g and the exponential function are continuous. Since
⃗ϑ(t) converges to ⃗θ∗as t →∞, there exists a time tϵ so that for all t ≥tϵ, ⃗ϑ(t) ∈Uϵ. However,
if ⃗ϑ(t) ∈Uϵ and ⃗ϑ(t) is an interior point, we get
d
dtϑi
k(t) > 0 by eqs. (6) and (11). Therefore,
ϑi
k(t) is positive and increasing for t ≥tϵ. We reached a contradiction because ϑi
k(t) →(θ∗)i
k = 0.
Therefore, ⃗θ∗is a performative stable point."
REFERENCES,0.5548245614035088,Under review as a conference paper at ICLR 2022
REFERENCES,0.5570175438596491,"C
PROOF ANS DETAILS FOR LEMMA 4.4"
REFERENCES,0.5592105263157895,"To prove lemma 4.4, show the dynamic eq. (3) can be approximated by eq. (6) and the error vanishes
as η∗decreases. Thus, we can show the dynamic can hit an arbitrary neighborhood of the performa-
tive stable point. We further use Φ to show the dynamic will stay in the neighborhood. Below we
state two ancillary lemmas to control the error of our approximation."
REFERENCES,0.5614035087719298,We deﬁne an error vector ⃗e(⃗θ) ∈Rn×d between eqs. (3) and (6) so that
REFERENCES,0.5635964912280702,"η2
i ei
k(⃗θ) :=
θi
k exp(ηi(¯gi −gi
k))
P"
REFERENCES,0.5657894736842105,"l θi
l exp(ηi(¯gi −gi
l)) −θi
k −ηiξi
k"
REFERENCES,0.5679824561403509,"We omit the input ⃗θ of ⃗e and ⃗et := ⃗e(⃗θt) when there is no ambiguity. We show if the the error
vector is small, Φ is decreasing in dynamics eq. (3)."
REFERENCES,0.5701754385964912,"Claim C.1 (Approximated potential). There exist C4, so that for all t and ⃗θ0 ∈Θn, the difference
of eq. (2) on eq. (3) satisﬁes"
REFERENCES,0.5723684210526315,"Φ(⃗θt+1) −Φ(⃗θt) ≤−mini λ2
i η2
i
2 P"
REFERENCES,0.5745614035087719,"i λiηi
∥⃗ξt∥2
1 + max
i
λiη2
i max
i,k,⃗θ
|gi
k(⃗θ)| · ∥⃗et∥1 + d2C4
⃗θt+1 −⃗θt

2 1 ."
REFERENCES,0.5767543859649122,"Claim C.2. If maxi ηi is small enough and satisﬁes eq. (12), there exists a constant C so that"
REFERENCES,0.5789473684210527,"|ei
k(⃗θ)| ≤C for all i ∈[n], k ∈[d], and ⃗θ ∈Θn."
REFERENCES,0.581140350877193,The proofs of these two claims are based on ﬁrst order approximation.
REFERENCES,0.5833333333333334,"Proof of claim C.1. By the partial derivative of eq. (2), we have
∂2"
REFERENCES,0.5855263157894737,"∂θi
k∂θj
l Φ(⃗θ) = 2λiλjAl,k if i ̸= j"
REFERENCES,0.5877192982456141,"and
∂2"
REFERENCES,0.5899122807017544,"∂θi
k∂θi
l Φ(⃗θ) = 2λi(1 + λi)Al,k. Thus, the second order partial derivatives of Φ can bounded by
the twice of C4 := maxı λı(λı + 1) maxk,l Ak,l. By Taylor’s expansion, we have"
REFERENCES,0.5921052631578947,Φ(⃗θt+1) −Φ(⃗θt)
REFERENCES,0.5942982456140351,"≤∇Φ(⃗θt) ·

⃗θt+1 −⃗θt

+ d22C4 2"
REFERENCES,0.5964912280701754,"⃗θ(t + 1) −⃗θ(t)

2 2 ≤
X"
REFERENCES,0.5986842105263158,"i∈[n],k∈[d]
λigi
k(⃗θt)(ηiξi
k(⃗θt) + η2
i ei
k(⃗θt)) + d2C4
⃗θ(t + 1) −⃗θ(t)

2 1"
REFERENCES,0.6008771929824561,"(by the partial derivative of eq. (2)) =
X"
REFERENCES,0.6030701754385965,"i∈[n],k∈[d]
λiηigi
t,kξi
t,k + λiη2
i gi
t,kei
t,k + d2C4
⃗θt+1 −⃗θt

2 1"
REFERENCES,0.6052631578947368,"≤
−1
2 P"
REFERENCES,0.6074561403508771,i λiηi  X
REFERENCES,0.6096491228070176,"i,k
λiηi|ξi
t,k|   2 +
X"
REFERENCES,0.6118421052631579,"i∈[n],k∈[d]
λiη2
i gi
t,kei
t,k + d2C4
⃗θt+1 −⃗θt

2"
REFERENCES,0.6140350877192983,"1
(by lemma 4.3)"
REFERENCES,0.6162280701754386,"Therefore, we have"
REFERENCES,0.618421052631579,"Φ(⃗θt+1) −Φ(⃗θt) ≤−mini λ2
i η2
i
2 P"
REFERENCES,0.6206140350877193,"i λiηi
∥⃗ξt∥2
1 + max
i
λiη2
i max
i,k,⃗θ
|gi
k(⃗θ)| · ∥⃗et∥1 + d2C4
⃗θt+1 −⃗θt

2 1"
REFERENCES,0.6228070175438597,which completes the proof.
REFERENCES,0.625,"Proof of claim C.2. By if η∗is small enough and satisﬁes eq. (12), we have ηi(¯gi −gi
k) ≤1, and
θi
k +ηiθi
k(¯gi −gi
k) ≤θi
keηi(¯gi−gi
k) ≤θi
k +ηiθi
k(¯gi −gi
k)+ e"
REFERENCES,0.6271929824561403,"2η2
i θi
k(¯gi −gi
k)2 for all i, k and ⃗θ ∈Θn.
Additionally, with ξi
k = θi
k(¯gi −gi
k), we can rewrite it as"
REFERENCES,0.6293859649122807,"θi
k ≤θi
keηi(¯gi−gi
k) −ηiξi
k ≤θi
k + e"
REFERENCES,0.631578947368421,"2η2
i θi
k(¯gi −gi
k)2."
REFERENCES,0.6337719298245614,Under review as a conference paper at ICLR 2022
REFERENCES,0.6359649122807017,"Therefore, the error can be upper bounded as"
REFERENCES,0.6381578947368421,"η2
i ei
k ≤θi
k + ηiξi
k + e"
REFERENCES,0.6403508771929824,"2η2
i θi
k(¯gi −gi
k)2
P
l θi
l + ηiξi
l
−(θi
k + ηiξi
k) = e"
REFERENCES,0.6425438596491229,"2η2
i θi
k(¯gi −gi
k)2,"
REFERENCES,0.6447368421052632,because P
REFERENCES,0.6469298245614035,"l θi
l = 1 and P"
REFERENCES,0.6491228070175439,"l ξi
l = 0. For lower bound, we have,"
REFERENCES,0.6513157894736842,"η2
i ei
k ≥
θi
k + ηiξi
k
P"
REFERENCES,0.6535087719298246,"l θi
l + ηiξi
l + e"
REFERENCES,0.6557017543859649,"2η2
i θi
l(¯gi −gi
l)2 −(θi
k + ηiξi
k) ≥−(θi
k + ηiξi
k)"
REFERENCES,0.6578947368421053,"eη2
i
2 X"
REFERENCES,0.6600877192982456,"l
θi
l(¯gi −gi
l)2
! ."
REFERENCES,0.6622807017543859,"If we set C := e max⃗θ
P"
REFERENCES,0.6644736842105263,"l θi
l(¯gi −gi
l)2, because |ηiξi
k| ≤ηi2 maxk |gi
k| ≤1 by eq. (12) and"
REFERENCES,0.6666666666666666,"θi
k ≤1, we have
ei
k(⃗θ)
 ≤C."
REFERENCES,0.668859649122807,"Proof of lemma 4.4. Because D is open, we can set D′ so that ⃗θ∗
∈D′, D′
⊂D, and
sup⃗θ∈D′ Φ(⃗θ) <
1
2 inf ⃗θ /∈D Φ(⃗θ).
We will pick η∗small enough so that ⃗θt+1 ∈D for all
⃗θt ∈D′ ⊂D. The proof has two parts: we ﬁrst show the dynamics eq. (3) hits the set D. Then we
prove eq. (3) stays in D afterward."
REFERENCES,0.6710526315789473,"By theorem 4.2, there exists τ so that ⃗ϑ(τ) ∈D′. Now by Gronwall’s inequality we can set η∗small
enough so that ⃗θτ/∥η∥1 ∈D. Formally, given the dynamics in eq. (3), we deﬁne right-continuous
step functions ⃗θ(t) = ⃗θ⌊t⌋and ⃗e(t) := ⃗e(⃗θ⌊t⌋) for all t ≥0. Then the dynamics in eq. (3) can be
written as"
REFERENCES,0.6732456140350878,"θi
k(t) −θi
k(0) = t−1
X"
REFERENCES,0.6754385964912281,"s=0
(θi
s+1,k −θi
s,k) = t−1
X s=0"
REFERENCES,0.6776315789473685,"
ηiξi
k(⃗θs) + η2
i ei
k(⃗θs)

= ηi Z t"
REFERENCES,0.6798245614035088,"0
ξi
k(⃗θ(s)) + ηiei
k(s) ds"
REFERENCES,0.6820175438596491,"On the other hand, the solution of eq. (6) can be written as"
REFERENCES,0.6842105263157895,"ϑi
k(ηit) −ϑi
k(0) =
ηi
∥η∥1"
REFERENCES,0.6864035087719298,"Z
t
∥η∥1"
REFERENCES,0.6885964912280702,"0
ξi
k(⃗ϑ(s)) ds = ηi Z t"
REFERENCES,0.6907894736842105,"0
ξi
k(⃗ϑ(∥η∥1s)) ds"
REFERENCES,0.6929824561403509,"Because ξi
k are continuous and Θn is compact, there exists L > 0 so that ξi
k is L-Lipschitz with
respect to one norm for all i and k. Thus, the difference between above equations is"
REFERENCES,0.6951754385964912,"θi
k(t) −ϑi
k(∥η∥1t)
 ≤ηi Z t 0"
REFERENCES,0.6973684210526315,"ξi
k(⃗θ(s)) −ξi
k(⃗ϑ(∥η∥1s))
 ds + η2
i Z t"
REFERENCES,0.6995614035087719,"0
|ei
k(s)| ds"
REFERENCES,0.7017543859649122,"≤ηiL
Z t 0"
REFERENCES,0.7039473684210527,"⃗θ(s) −⃗ϑ(ηis)

1 ds + η2
i Ct
(L-Lipschitz and claim C.2)"
REFERENCES,0.706140350877193,"Therefore, by Gronwall’s inequality and ηi ≤η∗, we have
⃗θ(t) −⃗ϑ(∥η∥1t)

1 ≤η∗ndL
Z t 0"
REFERENCES,0.7083333333333334,"⃗θ(s) −⃗ϑ(∥η∥1s)

1 ds + (η∗)2ndCt ≤(η∗)2ndCteη∗ndLt"
REFERENCES,0.7105263157894737,"Because ⃗ϑ(τ) ∈D′, we can pick η∗small enough so that ⃗θ(τ/∥η∥1) = ⃗θ⌊τ/∥η∥1⌋∈D and
Φ(⃗θ⌊τ/∥η∥1⌋) < inf ⃗θ /∈D Φ(⃗θ)."
REFERENCES,0.7127192982456141,"Now we show the second part that ⃗θt ∈D for all t ≥⌊τ/∥η∥1⌋. First, with claim C.1, we will prove
that the potential function is decreasing for all ⃗θt /∈D′ when η∗small enough. We estimate three
terms in claim C.1 separately. First, because ⃗θ∗∈D′ and Θn\D′ is compact, min⃗θ /∈D′ ∥⃗ξ(⃗θ)∥1 > 0"
REFERENCES,0.7149122807017544,"exists. Then mini λ2
i η2
i
2 P"
REFERENCES,0.7171052631578947,"i λiηi ∥⃗ξt∥2
1 = Ω(maxi ηi) By claim C.2, maxi λiη2
i maxi,k,⃗θ |gi
k(⃗θ)| · ∥⃗et∥1 ="
REFERENCES,0.7192982456140351,"O(maxi η2
i ). Finally, d2C4
⃗θt+1 −⃗θt

2"
REFERENCES,0.7214912280701754,"1 = O(maxi η2
i ). Therefore, there exists η∗small enough"
REFERENCES,0.7236842105263158,"so that the potential function Φ(⃗θt+1) −Φ(⃗θt) < 0 for all ⃗θt /∈D′ and η. Therefore Φ(⃗θt) <
min⃗θ /∈D Φ(⃗θ) for all t ≥⌊τ/∥η∥1⌋which completes the proof."
REFERENCES,0.7258771929824561,Under review as a conference paper at ICLR 2022
REFERENCES,0.7280701754385965,"D
PROOFS AND DETAILS FOR LEMMA 4.5"
REFERENCES,0.7302631578947368,"Lemma 4.3, shows the value of Φ is decreasing in eq. (6), and the decrease rate is lower bounded by
the one norm of ⃗ξ. Thus, if we can show the error between eq. (3) and eq. (6) is bounded by ∥⃗ξ∥1,
we have the value of Φ is also decreasing on eq. (3). The main challenge is that because ⃗ξ(⃗θ∗) = 0,
we need to control the error as ⃗ξ converges to zero but η∗is ﬁxed."
REFERENCES,0.7324561403508771,"We ﬁrst show three ancillary claims, claim D.1 to D.3. Claim D.1 show the vanishing components
of ⃗θt decrease rapidly once the dynamic is in D. Claim D.2 and D.3 show the supporting component
also decrease once the vanishing components are small enough."
REFERENCES,0.7346491228070176,"Given (n, d, A, λ), we deﬁne the following constants C1 := 1"
REFERENCES,0.7368421052631579,"4 maxi,l,θ∈Θn |gi
l|, C2 :=
2
mini,k(θ∗)i
k ,
C3 := ed max(C1, C2), and C4 := maxı λı(λı +1) maxk,l Ak,l. We require the maximum learning
rate is bounded by η∗which satisﬁes the following conditions."
REFERENCES,0.7390350877192983,"η∗
max
i,k,⃗θ∈Θn |gi
k(⃗θ)| ≤1"
REFERENCES,0.7412280701754386,"2
(12)"
REFERENCES,0.743421052631579,"η∗ndC3 max
⃗θ
∥⃗ξ(⃗θ)∥1 ≤1
(13)"
REFERENCES,0.7456140350877193,"Additionally, given the bound of learning rate ratio, maxi ηi"
REFERENCES,0.7478070175438597,"mini ηi ≤Rη, we requires"
REFERENCES,0.75,"R2
ηη3
∗< mini λ2
i
16 P"
REFERENCES,0.7521929824561403,"i λi
min

4
C3 maxi(λi) max⃗θ ∥⃗g∥1
,
1
d2C4"
REFERENCES,0.7543859649122807,"
(14)"
REFERENCES,0.756578947368421,"Note that max η3
i
min η2
i is less then the right hand side of eq. (14). On the other hand, by lemma 4.4, we
can pick D small enough so that the following conditions holds."
REFERENCES,0.7587719298245614,"1
2
min
i∈[n],k∈Si(θ∗)i
k ≤
min
i∈[n],k∈Si,⃗θ∈D
θi
k
(15)"
REFERENCES,0.7609649122807017,"We ﬁrst show for all i and k ∈¯Si, θi
t,k is decreasing and converges to zero exponentially fast"
REFERENCES,0.7631578947368421,"as t increases. Because ⃗θ∗is a proper performative stable, P"
REFERENCES,0.7653508771929824,"l(θ∗)i
le−ηigi
l(⃗θ∗) = e−ηi¯gi(⃗θ∗) >
e−ηigi
k(⃗θ∗) for all i and k ∈¯Si. We can take η∗, ϵ1, and D small enough so that for all ⃗θ ∈D and
all learning rate proﬁle η with max ηi ≤η∗,"
REFERENCES,0.7675438596491229,"e−ηigi
k < (1 −ϵ1)
X"
REFERENCES,0.7697368421052632,"l
θi
le−ηigi
l , i ∈[n], k ∈¯Si
(16)"
REFERENCES,0.7719298245614035,"Claim D.1 (Vanishing components). Given η∗, ϵ1, and D in eq. (16), if ⃗θt ∈D for all t ≥0, for all
i ∈[n] and k ∈Si, θi
k(t) is decreasing in t and for all t ≥0"
REFERENCES,0.7741228070175439,"0 ≤θi
t,k ≤θi
0,ke−ϵ1t."
REFERENCES,0.7763157894736842,"Proof of claim D.1. By eq. (16), for all t ≥0, θi
t+1,k = θi
t,k
exp(−ηigi
t,k)
P"
REFERENCES,0.7785087719298246,"l θi
t,l exp(−ηigi
t,l) ≤(1 −ϵ1)θi
t,k."
REFERENCES,0.7807017543859649,"Therefore, θi
t,k is decreasing, and θi
t,k ≤θi
0,ke−ϵ1t."
REFERENCES,0.7828947368421053,"Claim D.2. There exists a constant C3 such that for all ⃗θ ∈Θn with δ1 > 0 so that ∥⃗ξ(⃗θ)∥1 ≥
2√δ1, and |ξi
k(⃗θ)| ≤δ1 for all i ∈[n] and k ∈¯Si, then"
REFERENCES,0.7850877192982456,"|ei
k(⃗θ)| ≤C3∥⃗ξ(⃗θ)∥2
1,
(17)"
REFERENCES,0.7872807017543859,for all i ∈[n] and k ∈[d].
REFERENCES,0.7894736842105263,"Claim D.2 shows if the one norm of ⃗ξ is much bigger than the vanishing components, the error term
⃗e can be bounded by the ∥⃗ξ∥2
1. Moreover, claim D.1 ensures that the vanishing components decrease
rapidly, so the condition of claim D.2 readily holds."
REFERENCES,0.7916666666666666,Under review as a conference paper at ICLR 2022
REFERENCES,0.793859649122807,"Proof of claim D.2. Given ⃗θ and δ1 > 0 that satisfy the condition, we ﬁrst show two inequalities to
bound θi
k(¯gi −gi
k)2 for supporting and vanishing component respectively. For a vanishing compo-
nent k ∈¯Si,"
REFERENCES,0.7960526315789473,"θi
k(¯gi −gi
k)2 ≤
max
i,l,θ∈Θn |gi
l| · |θi
k(¯gi −gi
k)| ≤4C1 · δ1 ≤C1∥⃗ξ∥2
1.
(18)"
REFERENCES,0.7982456140350878,"Then for a supporting component k ∈Si, with eq. (15) we have"
REFERENCES,0.8004385964912281,"θi
k(¯gi −gi
k)2 ≤
1
mini,l,⃗θ∈D θi
l
(θi
k(gi −gi
k))2 ≤
2
mini,k(θ∗)i
k
|ξi
k|2 ≤C2∥⃗ξ∥2
1.
(19)"
REFERENCES,0.8026315789473685,"Now we use above two inequalities to approximate eq. (3). For nominator, because 1 + x ≤
exp(x) ≤1+x+ e"
REFERENCES,0.8048245614035088,"2x2 for all x ≤1, θi
k exp(ηi(¯gi −gi
k)) ≥θi
k +ηiθi
k(¯gi −gi
k) = θi
k +ηiξi
k. On the
other hand, because ηi(¯gi−gi
k) ≤1 by eq. (12), θi
k exp(ηi(¯gi−gi
k)) ≤θi
k+ηiξi
k+ e"
REFERENCES,0.8070175438596491,"2θi
kη2
i (¯gi−gi
k)2.
By eqs. (18) and (19), we have"
REFERENCES,0.8092105263157895,"0 ≤θi
keηi(¯gi−gi
k) −θi
k −ηiξi
k ≤e"
REFERENCES,0.8114035087719298,"2 max(C1, C2)η2
i ∥⃗ξ∥2
1
(20)"
REFERENCES,0.8135964912280702,"For denominator, we sum over eq. (20). Because P"
REFERENCES,0.8157894736842105,"l θi
l = 1 and P"
REFERENCES,0.8179824561403509,"l θk
l (¯gi −gi
l) = 0, we have 0 ≤
X"
REFERENCES,0.8201754385964912,"l
θi
leηi(¯gi−gi
l) −1 ≤ed"
REFERENCES,0.8223684210526315,"2 max(C1, C2)η2
i ∥⃗ξ∥2
1
(21)"
REFERENCES,0.8245614035087719,"Given i ∈[n] and k ∈[d], we apply the above equation to eq. (3). For upper bounds, we have"
REFERENCES,0.8267543859649122,"η2
i ei
k(⃗θt) = θi
k exp(ηi(¯gi −gi
k))
P"
REFERENCES,0.8289473684210527,"l θi
l exp(ηi(¯gi −gi
l)) −θi
t,k −ηiξi
t,k"
REFERENCES,0.831140350877193,"≤θi
t,ke−ηigi
k(⃗θt) −θi
t,k −ηiξi
t,k
(by eq. (21))"
REFERENCES,0.8333333333333334,"≤e max(C1, C2)"
REFERENCES,0.8355263157894737,"2
η2
i ∥⃗ξ∥2
1
(by eq. (20))"
REFERENCES,0.8377192982456141,"For lower bounds,"
REFERENCES,0.8399122807017544,"η2
i ei
k(⃗θt) = θi
k exp(ηi(¯gi −gi
k))
P"
REFERENCES,0.8421052631578947,"l θi
l exp(ηi(¯gi −gi
l)) −θi
t,k −ηiξi
t,k"
REFERENCES,0.8442982456140351,"≥
θi
t,k + ηiξi
t,k
1 + ed max(C1,C2)"
REFERENCES,0.8464912280701754,"2
η2
i ∥⃗ξ∥2
1
−θi
t,k −ηiξi
t,k
(by eqs. (20) and (21))"
REFERENCES,0.8486842105263158,"≥−(θi
t,k + ηiξi
t,k)
ed max(C1, C2)"
REFERENCES,0.8508771929824561,"2
η2
i ∥⃗ξ∥2
1"
REFERENCES,0.8530701754385965,"
(1/(1 + x) ≥1 −x)"
REFERENCES,0.8552631578947368,"≥−ed max(C1, C2)η2
i ∥⃗ξ∥2
1
(θi
t,k ≤1 and ηiξi
t,k ≤1 by eq. (12))"
REFERENCES,0.8574561403508771,"Therefore, with C3 := ed max(C1, C2) we ﬁnish the proof."
REFERENCES,0.8596491228070176,"Claim D.3. There exists ϵ2 > 0 so that for all ⃗θt ∈Θn and δ1 > 0 so that ∥⃗ξ(⃗θt)∥1 ≥2√δ1, and
|ξi
k(⃗θt)| ≤δ1 for all i ∈[n] and k ∈¯Si, then Φ(⃗θt+1) −Φ(⃗θt) ≤ϵ2∥⃗ξ(⃗θt)∥2
1."
REFERENCES,0.8618421052631579,"Proof for claim D.3. By claim C.1,"
REFERENCES,0.8640350877192983,"Φ(⃗θt+1) −Φ(⃗θt) ≤−mini λ2
i η2
i
2 P"
REFERENCES,0.8662280701754386,"i λiηi
∥⃗ξt∥2
1 + max
i
λiη2
i max
i,k,⃗θ
|gi
k(⃗θ)| · ∥⃗et∥1 + d2C4
⃗θt+1 −⃗θt

2 1 ."
REFERENCES,0.868421052631579,"We can bound the later two terms by claim D.2. For the second term, ∥⃗et∥1 ≤ndC3∥⃗ξt∥2
1. For the
third term,
⃗θt+1 −⃗θt

1 ≤
X i,k"
REFERENCES,0.8706140350877193,"
ηi|ξi
t,k| + C3η2
i ∥⃗ξ∥2
1
"
REFERENCES,0.8728070175438597,"≤max
i
ηi∥⃗ξ∥1 + ndC3 max
i
η2
i ∥⃗ξ∥2
1."
REFERENCES,0.875,"≤2 max
i
ηi∥⃗ξ∥1
( by eq. (13))"
REFERENCES,0.8771929824561403,Under review as a conference paper at ICLR 2022
REFERENCES,0.8793859649122807,"With above inequalities, by eq. (14), we have mini λ2
i η2
i
4 P"
REFERENCES,0.881578947368421,"i λiηi > maxi λiη2
i maxi,k,⃗θ |gi
k(⃗θ)|ndC3 and"
REFERENCES,0.8837719298245614,"mini λ2
i η2
i
4 P"
REFERENCES,0.8859649122807017,"i λiηi > 4d2C4 maxi η2
i . Therefore there exists a constant"
REFERENCES,0.8881578947368421,"ϵ2 := mini λ2
i η2
i
2 P"
REFERENCES,0.8903508771929824,"i λiηi
−max
i
λiη2
i max
i,k,⃗θ
|gi
k(⃗θ)|ndC3 −4d2C4 max
i
η2
i > 0"
REFERENCES,0.8925438596491229,"so that Φ(⃗θt+1) −Φ(⃗θt) < −ϵ2∥⃗ξt∥2
1."
REFERENCES,0.8947368421052632,"Proof of lemma 4.5. To prove limt→∞⃗θt = ⃗θ∗, there are two equivalent ways to measure the
progress, besides ∥⃗θt −⃗θ∗∥1. First because ⃗θ∗is an isolated ﬁxed point of eq. (6), ⃗θt converges to
⃗θ∗if and only if limt→∞⃗ξ(⃗θt) = ⃗0. On the other hand, because Φ is strictly convex and and ⃗θ∗is
the minimum point, ⃗θt converges to ⃗θ∗if and only if limt→∞Φ(⃗θt) = min⃗θ Φ(⃗θ). With these two
equivalent conditions, given any ϵ > 0, there exists δ > 0 so that ∥⃗θ −⃗θ∗∥1 < ϵ when"
REFERENCES,0.8969298245614035,⃗θ ∈Vδ :=
REFERENCES,0.8991228070175439,"(
⃗θ : Φ(⃗θ) ≤
max
⃗θ′:∥⃗ξ(⃗θ′)∥1≤δ
Φ(⃗θ′) ) ."
REFERENCES,0.9013157894736842,"Therefore, it is sufﬁcient for us to show for all δ > 0, there is tδ so that ⃗θt ∈Vδ for all t ≥tδ. With
technical claim D.1 to D.2, our proof has two parts. First we show that the dynamic hits Vδ. Then,
the dynamic stays in Vδ."
REFERENCES,0.9035087719298246,"For the ﬁrst part, given δ > 0 and 0 < C < 1, by claim D.1 there exists T1 such that each vanishing
component |ξi
t,k| ≤C2δ2/4 for all t ≥T1. Then by claim D.3, there exists T2 ≥T1 such that
∥⃗ξT2∥1 ≤Cδ. Otherwise, the value of Φ decreases by a nonzero constant ϵ2∥⃗ξt∥2
1 ≥Cϵ2δ2 > 0 at
each round which contradicts that the minimum of Φ bounded."
REFERENCES,0.9057017543859649,"For the second part, if ∥⃗ξt∥1 ≤Cδ ≤δ for all t ≥T2, then we ﬁnish the proof.
Other-
wise, there exists τ ≥T2 so that ∥⃗ξτ∥1 ≤Cδ < ∥⃗ξτ+1∥1. Now we prove that Φ(⃗θτ+1) ≤
max⃗θ′:∥⃗ξ(⃗θ′)∥1≤δ Φ(⃗θ′).
Because the difference between ⃗θτ+1 and ⃗θτ is ∥⃗θτ+1 −⃗θτ∥1
≤"
REFERENCES,0.9078947368421053,"maxi ηi∥⃗ξτ∥1 +maxi η2
i ∥⃗eτ∥1 ≤2 maxi ηi∥⃗ξτ∥1 when η∗is small enough, and ⃗ξ is a Lξ-Lipschitz
⃗θ for some constant Lξ in one norm, we have"
REFERENCES,0.9100877192982456,"Cδ < ∥⃗ξτ+1∥1 ≤∥⃗ξτ∥1 + ∥⃗ξτ+1 −⃗ξτ∥1 ≤∥⃗ξτ∥1 + 2Lξ max
i
ηi∥⃗ξτ∥1 ≤δ,
(22)"
REFERENCES,0.9122807017543859,"when C is small enough so that C(1 + 2Lξ maxi ηi) ≤1. Therefore, ∥⃗ξτ+1∥1 ≤δ and Φ(⃗θτ+1) ≤
max⃗θ′:∥⃗ξ(⃗θ′)∥1≤δ Φ(⃗θ′). Finally, because |ξi
t,k| ≤C2δ2/4 for all t ≥τ + 1, by claim D.3, the"
REFERENCES,0.9144736842105263,"potential function is decreasing for all t ≥τ + 1, unless ∥⃗ξ∥t ≤Cδ. Both make the potential
function less than max⃗θ′:∥⃗ξ(⃗θ′)∥1≤δ Φ(⃗θ′) which completes the proof."
REFERENCES,0.9166666666666666,"E
PROOF AND DETAIL FOR THEOREM 4.6"
REFERENCES,0.918859649122807,"Proof of lemma 4.7. Deﬁne PL(x) := α(L)(x−β(L)) which is increasing for all L because α(L) >
0. With PL, fα(L),β(L)(x) =
x
x+(1−x) exp(PL(x)). Take x1(L) = x1 := 1−1/α(L), x2(L) = x2 :=
fα(L),β(L)(x1(L)), and x3(L) = x3 := fα(L),β(L)(x2(L)). We will deﬁne x0(L) later. We will
omit L and use x1, x2, and x3."
REFERENCES,0.9210526315789473,"To deﬁne x0(L), we set y(L) := β(L)/2, and want to show"
REFERENCES,0.9232456140350878,"fα(L),β(L)(y) > x1,
(23)"
REFERENCES,0.9254385964912281,"which is equivalent to (α(L) −1)(1 −y(L)) exp(PL(y(L))) < y(L). When L is large enough, we
have β(L) ∈( 2β∞"
REFERENCES,0.9276315789473685,"3 , 4β∞"
REFERENCES,0.9298245614035088,"3 ). Additionally because α(L) > 0, we have PL(y(L)) = −1"
REFERENCES,0.9320175438596491,"2α(L)β(L) <
−1"
REFERENCES,0.9342105263157895,"3α(L)β∞. Therefore, we have (α(L) −1)(1 −y(L))ePL(y(L)) ≤α(L)e−α(L) β∞"
REFERENCES,0.9364035087719298,"3
<
β∞"
REFERENCES,0.9385964912280702,"3
<
y(L) when L is large enough, and prove eq. (23). On the other hand, because β(L) < 4"
REFERENCES,0.9407894736842105,3β∞and
REFERENCES,0.9429824561403509,Under review as a conference paper at ICLR 2022
REFERENCES,0.9451754385964912,"PL(β(L)) = 0, we have fα(L),β(L)(β(L)) = β(L) < 1"
REFERENCES,0.9473684210526315,"2(β∞+1). Moreover, 1"
REFERENCES,0.9495614035087719,"2(β∞+1) < 1−
1
α(L),
holds when L is large enough. These two imply"
REFERENCES,0.9517543859649122,"fα(L),β(L)(β(L)) = β(L) < x1(L).
(24)"
REFERENCES,0.9539473684210527,"Combining eqs. (23) and (24), by intermediate value theorem, there exists x0 such that"
REFERENCES,0.956140350877193,"fα(L),β(L)(x0) = x1 with y < x0 < β(L) < x1.
(25)"
REFERENCES,0.9583333333333334,"Now we show x3 < x0. With 1−x1(L) = 1/α(L) and 0 < x1 < 1, we have x2 = fα(L),β(L)(x1) ="
REFERENCES,0.9605263157894737,"x1
x1+α(L)−1 exp(PL(x1)) ≤
α(L)
exp(PL(x1)). Because β∞< 1/2, when L is large enough, x1(L) ="
REFERENCES,0.9627192982456141,"1 −
1
α(L) > 1"
REFERENCES,0.9649122807017544,"4(2β(L) + 3) and, thus, PL(x1) > α(L)

3
4 −β(L)"
REFERENCES,0.9671052631578947,"2

. Therefore, we have"
REFERENCES,0.9692982456140351,"x2 ≤α(L) exp

−α(L)
3"
REFERENCES,0.9714912280701754,4 −β(L) 2
REFERENCES,0.9736842105263158,"
(26)"
REFERENCES,0.9758771929824561,"Finally, because PL(x2) ≥PL(0) = −β(L), we get"
REFERENCES,0.9780701754385965,"x3 =fα(L),β(L)(x2) ≤
x2
x2 + (1 −x2) exp(−α(L)β(L))"
REFERENCES,0.9802631578947368,"=
x2 exp(α(L)β(L))
1 + x2(exp(α(L)β(L)) −1)
≤x2 exp(α(L)β(L))
(since exp(α(L)β(L)) > 1 when L is large)"
REFERENCES,0.9824561403508771,"≤α(L) exp

α(L)

β(L) −
3"
REFERENCES,0.9846491228070176,4 −β(L) 2
REFERENCES,0.9868421052631579,"
(eq. (26))"
REFERENCES,0.9890350877192983,"=α(L) exp
3α(L) 2"
REFERENCES,0.9912280701754386,"
β(L) −1 2 "
REFERENCES,0.993421052631579,"Finally, because β∞< 1/2, x3 converges to 0 when L is large enough. Therefore,"
REFERENCES,0.9956140350877193,"x3 < y < x0.
(27)"
REFERENCES,0.9978070175438597,"By eqs. (25) and (27), we have x3 < x0 < x1 which completes the proof."
