Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0034965034965034965,"Bayesian Optimization has been challenged by the large-scale and high-
dimensional datasets, which are common in real-world scenarios. Recent works
attempt to handle such input by applying neural networks ahead of the classical
Gaussian process to learn a (low-dimensional) latent representation. We show
that even with proper network design, such learned representation often leads to
collision in the latent space: two points with signiﬁcantly different observations
collide in the learned latent space, leading to degraded optimization performance.
To address this issue, we propose LOCO, an efﬁcient deep Bayesian optimiza-
tion framework which employs a novel regularizer to reduce the collision in the
learned latent space and encourage the mapping from the latent space to the ob-
jective value to be Lipschitz continuous. LOCO takes in pairs of data points and
penalizes those too close in the latent space compared to their target space dis-
tance. We provide a rigorous theoretical justiﬁcation for LOCO by inspecting the
regret of this dynamic-embedding-based Bayesian optimization algorithm, where
the neural network is iteratively retrained with the regularizer. Our empirical re-
sults further demonstrate the effectiveness of LOCO on several synthetic and real-
world benchmark Bayesian optimization tasks."
INTRODUCTION,0.006993006993006993,"1
INTRODUCTION"
INTRODUCTION,0.01048951048951049,"Bayesian optimization is a classical sequential optimization method and is widely used in various
ﬁelds in science and engineering, including recommender systems (Galuzzi et al., 2019), medical
trials (Sui et al., 2018), robotic controller optimization (Berkenkamp et al., 2016), scientiﬁc exper-
imental design (Yang et al., 2019), and hyper-parameter tuning (Snoek et al., 2012), among many
others. Many of these applications involve evaluating an expensive blackbox function; therefore,
the number of queries should be minimized. A common way to model the unknown function is
via Gaussian processes (GPs) (Rasmussen and Williams, 2006), which have been extensively stud-
ied under the bandit setting, as an effective surrogate model of the unknown objective function in a
broad class of blackbox function optimization problems (Srinivas et al., 2010; Djolonga et al., 2013)."
INTRODUCTION,0.013986013986013986,"A key computational challenge for learning with GPs lies in optimizing speciﬁc kernels used for
modeling the covariance structures. Such an optimization task depends on the dimension of the
input space. For high-dimensional data, it is often prohibitive to train a GP model. Meanwhile,
local kernel machines are known to suffer from the curse of dimensionality (Bengio et al., 2005),
while the required number of training samples could grow exponentially with the dimensionality of
the data. Therefore, dimensionality reduction and representation learning algorithms are needed to
optimize the learning process."
INTRODUCTION,0.017482517482517484,"Recently, Gaussian process optimization has been investigated in the context of latent space models.
For example, deep kernel learning (Wilson et al., 2016) learns a (low-dimensional) data represen-
tation and a scalable kernel simultaneously via an end-to-end trainable deep neural network. In
general, the neural network is trained to learn a simpler latent representation with reduced dimen-
sion and has the structure information already embedded for the GP. Combining the representation
learned via a neural network with GP could improve the scalability and extensibility of classical
Bayesian optimization, but it also poses new challenges for the optimization task, such as dealing
with the tradeoff between representation learning and function optimization (Tripp et al., 2020)."
INTRODUCTION,0.02097902097902098,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.024475524475524476,"As we later demonstrate, a critical challenge brought by introducing representation learning into
Bayesian optimization is that the latent representation is prone to collisions: two points with signiﬁ-
cantly different observations can get too close, and therefore collide in the latent space. The collision
effect in latent space models for Bayesian optimization is especially evident when information is lost
during dimensionality reduction and/or when the training data is limited in size. As illustrated in
Figure 1, when passed through the neural network, data points with drastically different observations
are mapped to close positions in the latent space. Such collisions could be regarded as additional
noise introduced by the neural network. Although Bayesian optimization is known to be robust to
mild noisy observations (Bogunovic et al., 2018), the collision in latent space could be harmful to
the optimization performance, as it is non-trivial to model the collision into the acquisition function
explicitly. Also, the additional noise induced by the collision effect will further loosen the regret
bound for classical Bayesian optimization algorithms (Srinivas et al., 2010)."
INTRODUCTION,0.027972027972027972,"Figure 1:
The collision effect in
latent space-based BO tasks when
having 100 data points and observa-
tions. Because the data points around
the optimum severely collided, BO is
misguided to the sub-optimum. Dif-
ferent from noise which normally as-
sumed to be Gaussian, the collision
could be much more divergent. See
extended discussion in Appendix B.1."
INTRODUCTION,0.03146853146853147,"Overview of main results
To mitigate the collision effect, we
propose a novel regularization scheme that can be applied as a
simple plugin amendment for the latent space based Bayesian
optimization models. The proposed algorithm, namely Latent
Space Optimization via Collision-free regularization (LOCO),
leverages a regularized regression loss function to optimize the
latent space for Bayesian optimization periodically."
INTRODUCTION,0.03496503496503497,"Concretely, our collision-free regularizer is encoded by a novel
pairwise collision penalty function deﬁned jointly on the latent
space and the output domain. In order to mitigate the risk of
collision in the latent space (and consequently boost the opti-
mization performance), LOCO applies the regularizer to mini-
mize the collisions uniformly in the latent space."
INTRODUCTION,0.038461538461538464,"We further note that for Bayesian optimization tasks, collisions
in regions close to the optimum are more likely to mislead the
optimization algorithm. Based on this insight, we propose an
optimization-aware regularization scheme that assigns higher
weight to the collision penalty on those pairs of points closer to
the optimum region in the latent space. This algorithm, which
we refer to as Dynamically-Weighted LOCO, is designed to dy-
namically assess the importance of a collision during optimiza-
tion. Compared with the uniform collision penalty in the latent space, the dynamic weighting mech-
anism has demonstrated drastic improvement over the state-of-the-art latent space based Bayesian
optimization models."
INTRODUCTION,0.04195804195804196,We summarize our key contributions as follows:
INTRODUCTION,0.045454545454545456,"I. We investigate latent space based Bayesian optimization, and expose the limitations of existing
latent space optimization approaches due to the collision effect on the latent space (Section 3).
II. We propose a novel regularization scheme as a simple plugin amendment for latent space
based Bayesian optimization models. Our regularizer penalizes collisions in the latent space
and effectively reduces the collision effect. Furthermore, we propose an optimization-aware
dynamic weighting mechanism for adjusting the collision penalty to improve the effectiveness
of regularization for Bayesian optimization (Section 4).
III. We provide theoretical analysis for the performance of Bayesian optimization on regularized
latent space (Section 5).
IV. We conducted an extensive empirical study on several synthetic and real-world datasets, in-
cluding a real-world case study for cosmic experimental design, and demonstrate the promis-
ing empirical performance for our algorithm (Section 6)."
RELATED WORK,0.04895104895104895,"2
RELATED WORK"
RELATED WORK,0.05244755244755245,"This section provides a short survey on recent work in Bayesian learning, which was designed to
overcome the high-dimensionality challenge for Gaussian process regression tasks and Bayesian
optimization."
RELATED WORK,0.055944055944055944,Under review as a conference paper at ICLR 2022
RELATED WORK,0.05944055944055944,"Different surrogate models with internal latent space
Some alternative surrogate models have
been proposed to replace classical GP in Bayesian optimization to overcome the challenge of high-
dimensional and highly-structured input in BO. Deep Network for Global Optimization (DNGO)
Snoek et al. (2015) uses a pre-trained deep neural network with a Bayesian linear regressor at the
last hidden layer of the network as the surrogate model. More generally, Deep Kernel Learning
(DKL) combines the power of the Gaussian process and neural network by introducing a deep
neural network g to learn a mapping g : X →Z from the input domain X to a latent space Z
(Wilson et al., 2016). It uses the latent representation z ∈Z as the input of the base Gaussian
process. The neural network g and a spectral mixture-based kernel k form a scalable expressive
closed-form deep covariance kernel, denoted by kDK(xi, xj) →k(g(xi), g(xj)). The deep kernel
allows end-to-end learning and Bayesian optimization on the original input space."
RELATED WORK,0.06293706293706294,"Representation learning and latent space optimization
Instead of reducing the dimensionality
and performing optimization in an end-to-end process, other methods aim to optimize in a related
low-dimensional space ﬁrst and then map the solution back to the original input space. Djolonga
et al. (2013) assume that only a subset of input dimensions varies, and the kernel is smooth (i.e. with
bounded RKHS norm). Under these assumptions, the underlying subspace is learned via low-rank
matrix recovery. Random feature is another solution under this setting (Rahimi et al., 2007; Letham
et al., 2020; Binois et al., 2015; Nayebi et al., 2019; Wang et al., 2016). It is known that a random
representation space of sufﬁciently large dimension is guaranteed to contain the optima with high
probability. Mutn`y and Krause (2019) consider Quadrature Fourier Features (QFF)—as opposed to
Random Fourier Feature (RFF) in Rahimi et al. (2007)—to overcome the variance starvation prob-
lem, and proved that Thompson sampling and GP-UCB achieve no-regret with squared exponential
kernel in optimization tasks. However, both RFF and QFF methods rely on a key assumption that
the function to be optimized has a low effective dimension. In contrast, as discussed in Section 6 and
the supplemental materials, we show that LOCO performs well for challenging high-dimensional
BO problems where algorithms relying on the low effective dimension assumption may fail."
RELATED WORK,0.06643356643356643,"Another line of work on latent space optimization uses autoencoders to learn low-dimensional rep-
resentations of the inputs to improve the scalability and capability to leverage the structural infor-
mation (Mathieu et al., 2019), (Ding et al., 2020), (G´omez-Bombarelli et al., 2018; Huang et al.,
2015; Tripp et al., 2020; Lu et al., 2018). Mathieu et al. (2019), Ding et al. (2020) focus on disentan-
gled representation learning that breaks down, or disentangles, each feature into narrowly deﬁned
variables and encodes them as separate dimensions.Tripp et al. (2020) iteratively train the autoen-
coder with a dynamic weighting scheme when performing optimization to improve the embedding.
Grifﬁths and Hern´andez-Lobato (2020) and Letham et al. (2020) enforce certain properties on the
representation space to improve the optimization performance. To the best of the authors’ knowl-
edge, collision of the embeddings has not been explicitly studied. Binois et al. (2015) propose a
warped kernel to guarantee the injectivity in the random linear embedding, which is not applicable
in neural network-based methods."
RELATED WORK,0.06993006993006994,"A common challenge in applying these techniques to generic optimization tasks lies in the assump-
tion on the accessibility of training data: Bayesian optimization often assumes limited access to
labeled data, while surrogate models built on deep neural networks often rely on abundant access to
data for pretraining. Another problem lies in the training objective: During the training phase, these
surrogate models typically focus on improving the regression performance, and do not explicitly
address the artifact caused by collisions of the learned embeddings, which—as we later demonstrate
in Section 3.3—could be harmful to sequential decision-making tasks."
PROBLEM STATEMENT,0.07342657342657342,"3
PROBLEM STATEMENT"
PROBLEM STATEMENT,0.07692307692307693,"In this section, we introduce necessary notations and formally state the problem. We focus on the
problem of sequentially optimizing a function f : X →R, where X ⊆Rd is the input domain.
At iteration t, we pick a point xt ∈X, and observe the function value perturbed by additive noise:
yt = f(xt) + ϵt with ϵt ∼N(0, σ2) being i.i.d. Gaussian noise. Our goal is to maximize the
sum of rewards PT
t=1 f(xt) over T iterations, or equivalently, to minimize the cumulative regret
RT := PT
t=1 rt, where rt := max
x∈X f(x) −f(xt) denotes the instantaneous regret of xt."
PROBLEM STATEMENT,0.08041958041958042,Under review as a conference paper at ICLR 2022
BAYESIAN OPTIMIZATION,0.08391608391608392,"3.1
BAYESIAN OPTIMIZATION"
BAYESIAN OPTIMIZATION,0.08741258741258741,"Formally, we assume that the underlying function f is drawn from a Gaussian process
GP(m(x), k(x, x′)), where m(x) is the mean function and k(x, x′) is the covariance function.
At iteration t, given the selected points At = {x1, . . . , xt} and the corresponding noisy evalua-
tions yt = [y1, . . . , yt]⊤, the posterior over f also takes the form of a GP, with mean µt(x) =
kt(x)⊤(Kt + σ2I)−1yt, covariance kt(x, x′) = k(x, x′) −kt(x)⊤(Kt + σ2I)−1kt(x′), and vari-
ance σ2
t (x) = kt(x, x), where kt(x) = [k(x1, x), . . . , k(xt, x)]⊤and Kt is the positive deﬁnite
kernel matrix [k(x, x′)]x,x′∈At (Rasmussen and Williams, 2005). After obtaining the posterior, one
can compute the acquisition function α : X →R, which is used to select the next point to be
evaluated. Various acquisition functions have been proposed in the literature, including popular
choices such as Upper Conﬁdence Bound (UCB) (Srinivas et al., 2010) and Thompson sampling
(TS) (Thompson, 1933)."
BAYESIAN OPTIMIZATION,0.09090909090909091,"Remark. Regret is commonly used as performance metric for BO methods. In this work we focus
on the simple regret r∗
T = max
x∈X f(x) −max
t≤T f(xt) and cumulative regret R(T) = PT
t=1 rt."
LATENT SPACE OPTIMIZATION,0.0944055944055944,"3.2
LATENT SPACE OPTIMIZATION"
LATENT SPACE OPTIMIZATION,0.0979020979020979,"Recently, Latent Space Optimization (LSO) has been proposed to solve Bayesian optimization prob-
lems on complex input domains (G´omez-Bombarelli et al., 2018; Huang et al., 2015; Tripp et al.,
2020; Lu et al., 2018). LSO learns a latent space mapping g : X →Z to convert the input
space X to the latent space Z. Then, it constructs an objective mapping h : Z →R such that
f(x) ≈h(g(x)), ∀z ∈Z. In this paper, we model the latent space mapping g as a neural net-
work; the neural network g and the base kernel k together are regarded as a deep kernel, denote by
knn(x, x′) = k(g(x), g(x′)) (Wilson et al., 2016). In this context, the actual input space for BO is
the latent space Z and the objective function is h. With the acquisition function αnn(x) := α(g(x)),
we do not compute an inverse mapping g−1 as opposed to the aforementioned autoencoder-based
LSO algorithms (e.g. Tripp et al. (2020)), since BO directly select xt = arg max
x∈X
αnn(x) ∀t ≤T. In"
LATENT SPACE OPTIMIZATION,0.10139860139860139,"our analysis, we use squared exponential kernel, i.e. kSE(x, x′) = σ2
SE exp

−(x−x′)2"
L,0.1048951048951049,"2l

."
THE COLLISION EFFECT OF LSO,0.10839160839160839,"3.3
THE COLLISION EFFECT OF LSO"
THE COLLISION EFFECT OF LSO,0.11188811188811189,"When the mapping g : X →Z is represented by a neural network, it may cause undesirable
collisions between different input points in the latent space Z. Under the noise-free setting, we say
there exists a collision in Z, if ∃xi, xj ∈X, such that when g(xi) = g(xj), |f(xi) −f(xj)| > 0.
Such collision could be regarded as additional (unknown) noise on the observations introduced by
the neural network g. Given a representation function g, noisy observations y = f(x)+ϵ, we say that
there exists a collision, if for λ > 0, there exist xi, xj ∈X, such that |g(xi) −g(xj)| < λ|yi −yj|."
THE COLLISION EFFECT OF LSO,0.11538461538461539,"When the distance between a pair of points (xi, xj) in the latent space is too close compared to
their difference in the output space, the different output values yi, yj for the collided points in the
latent space could be interpreted as the effect of additional observation noise for g(xi) (or g(xj)).
In general, collisions could degrade the performance of LSO. Since the collision effect is a priori
unknown, it is often challenging to be dealt with in LSO, even if we regard it as additional obser-
vation noise and increase the (default) noise variance in the Gaussian process. Thus, it is necessary
to mitigate the collision effect by directly restraining it in the representation learning phase. One
potential method to avoid collision could be tuning the design of neural networks. However, we
empirically show that increasing the network complexity often does not help to reduce the collision.
The study is posed in Appendix B.2."
THE COLLISION EFFECT OF LSO,0.11888111888111888,"We consider a low-noise setting where the collision can play a more signiﬁcant role in degrading the
optimization performance. As is shown in Figure 1 that the collision could result in larger difﬁculty
in the optimization task. And when a collision exists, it is hard to distinguish it from the observation.
Therefore we focused on treating the collision when deﬁning the penalty instead of dealing with the
stochasticity."
THE COLLISION EFFECT OF LSO,0.12237762237762238,Under review as a conference paper at ICLR 2022
LATENT SPACE OPTIMIZATION VIA COLLISION-FREE REGULARIZATION,0.1258741258741259,"4
LATENT SPACE OPTIMIZATION VIA COLLISION-FREE REGULARIZATION"
LATENT SPACE OPTIMIZATION VIA COLLISION-FREE REGULARIZATION,0.12937062937062938,We now introduce LOCO as a novel algorithmic framework to mitigate the collision effect.
OVERVIEW OF THE LOCO ALGORITHM,0.13286713286713286,"4.1
OVERVIEW OF THE LOCO ALGORITHM"
OVERVIEW OF THE LOCO ALGORITHM,0.13636363636363635,"The major challenge in restraining collisions in the latent space is that—unlike the formulation of
the classical regression loss—we cannot quantify it based on a single training example. We can,
however, quantify collisions by grouping pairs of data points and inspecting their corresponding
observations. GP"
OVERVIEW OF THE LOCO ALGORITHM,0.13986013986013987,collision
OVERVIEW OF THE LOCO ALGORITHM,0.14335664335664336,penalty
OVERVIEW OF THE LOCO ALGORITHM,0.14685314685314685,square loss
OVERVIEW OF THE LOCO ALGORITHM,0.15034965034965034,pair loss
OVERVIEW OF THE LOCO ALGORITHM,0.15384615384615385,latent space
OVERVIEW OF THE LOCO ALGORITHM,0.15734265734265734,Figure 2: Schematic of LOCO
OVERVIEW OF THE LOCO ALGORITHM,0.16083916083916083,"We deﬁne the collision penalty based on pairs of inputs
and further introduce a pair loss function to characterize
the collision effect. Based on this pair loss, we propose
a novel regularized latent space optimization algorithm1,
as summarized in Algorithm 1. The proposed algorithm
concurrently feeds the pair-wise input into the same net-
work and calculates the pair loss function. We demon-
strate this process in Figure 2."
OVERVIEW OF THE LOCO ALGORITHM,0.16433566433566432,"Given a set of labeled data points, we can train the neu-
ral network to create an initial latent space representation
similar to DKL (Wilson et al., 2016)2. Once provided
with the initial representation, we can then reﬁne the la-
tent space by running LOCO and periodically update the latent space (i.e. updating the learned
representation after collecting a batch of data points) to mitigate the collision effect as we gather
more labels."
OVERVIEW OF THE LOCO ALGORITHM,0.16783216783216784,Algorithm 1 Latent Space Optimization via Collision-free Regularization (LOCO)
OVERVIEW OF THE LOCO ALGORITHM,0.17132867132867133,"1: Input: Penalty parameter λ (cf. Equation 1), regularization weight ρ (cf. Equation 3), impor-
tance weight parameter ζ (cf. Equation 2), neural network g, parameters θt = (θh,t, θg,t), total
time steps T;
2: for t = 1 to T do
3:
xt ←arg max
x∈D
α(g(x, θg,t))
▷maximize acquisition function"
OVERVIEW OF THE LOCO ALGORITHM,0.17482517482517482,"4:
yt ←evaluation on xt
▷update observation
5:
θt+1 ←retrain θt with the pair loss function Lρ,λ,ζ,g(θt, Dt) as in Equation 3"
OVERVIEW OF THE LOCO ALGORITHM,0.17832167832167833,"6: Output: max
t
yt"
COLLISION PENALTY,0.18181818181818182,"4.2
COLLISION PENALTY"
COLLISION PENALTY,0.1853146853146853,"This subsection aims to quantify the collision effect based on the deﬁnition proposed in Section 3.3.
As illustrated in Figure 2, we feed pairs of data points into the neural network and obtain their latent
space representations. Apart from maximizing the GP’s likelihood, we concurrently calculate the
amount of collision on each pair and incur a penalty when the value is positive. For xi, xj ∈X,
yi = f(xi) + ϵ, yj = f(xj) + ϵ are the corresponding observations, and zi = g(xi), zj = g(xj) are
the corresponding latent space representations. We deﬁne the collision penalty as"
COLLISION PENALTY,0.1888111888111888,"pij = max(λ|yi −yj| −|zi −zj|, 0)
(1)"
COLLISION PENALTY,0.19230769230769232,"where λ is a penalty parameter that controls the smoothness of the target function h : Z →R. As a
rule of thumb, one can estimate λ by sampling from the original data distribution P(X, Y ), (X, Y ) ∈
X ×R, and choose the λ to be the maximum value such that P"
COLLISION PENALTY,0.1958041958041958,"i,j max(λ|yi−yj|−|xi−xj|, 0) = 0
(i.e. to provide an upper bound for λ by keeping the total collision in the input domain to be zero)."
COLLISION PENALTY,0.1993006993006993,"1Note that we have introduced several hyper-parameters in the algorithm design; we will defer our discus-
sion on the choice of these parameters to Section 6.
2To obtain an initial embedding in the latent space, the process does not require the labels to be exact and
allows the labels to be collected from a related task of cheaper cost."
COLLISION PENALTY,0.20279720279720279,Under review as a conference paper at ICLR 2022
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER,0.2062937062937063,"4.3
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER"
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER,0.2097902097902098,"Note that it is challenging to universally reduce the collisions by minimizing the collision penalty
and the GP’s regression loss—this is particularly the case with a limited amount of training data.
Fortunately, for optimization tasks, it is often unnecessary to learn ﬁne-grained representation for
suboptimal regions. Therefore, we can dedicate more training resources to improve the learned
latent space pertaining to the potentially near-optimal regions. Following this insight, we propose
to use a weighted collision penalty function, which uses the objective values for each pair as an
importance weight in each iteration. Formally, for any pair ((xj, zj, yj), (xi, zi, yi)) in a batch of
observation pairs Dt = {((xm, zm, ym), (xn, zn, yn))}m,n where xn, xm ∈At and yn, ym ∈yt,
we deﬁne the importance-weighted penalty function as"
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER,0.21328671328671328,"˜pij = pijwij
with
wij =
eζ(yi+yj)
P"
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER,0.21678321678321677,"(m,n)∈Dt
eζ(ym+yn) .
(2)"
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER,0.2202797202797203,Here the importance weight ζ is used to control the aggressiveness of the weighting strategy.
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER,0.22377622377622378,"Combining the kernel learning objective—negative log likelihood and the collision penalty for GP,
we deﬁne the pair loss function Lρ,λ,ζ,g as"
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER,0.22727272727272727,"Lρ,λ,ζ,g(θt, Dt) = −log(P(yt|At, θt)) +
ρ
||Dt||2
X"
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER,0.23076923076923078,"i∈Dt,j∈Dt
˜pij
(3)"
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER,0.23426573426573427,"Here, −log(P(yt|At, θt)) = −1"
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER,0.23776223776223776,"2y⊤
t (Kt + σ2I)−1yt −1"
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER,0.24125874125874125,2|(Kt + σ2I)| −t
IMPORTANCE-WEIGHTED COLLISION-FREE REGULARIZER,0.24475524475524477,"2 log(2π) is the learning
objective for the GP (Rasmussen and Williams, 2005). ρ denotes the regularization weight; as we
demonstrate in Section 6, we initialize the regularization weight ρ to keep the penalty at the same
order of magnitude as the negative log likelihood. An alternative training process is to minimize the
regression loss and the collision penalty alternatively. We observe in our empirical study that both
training processes could lead to reasonable convergence behavior of the LOCO training loss."
DISCUSSION AND THEORETICAL INSIGHT,0.24825174825174826,"5
DISCUSSION AND THEORETICAL INSIGHT"
DISCUSSION AND THEORETICAL INSIGHT,0.2517482517482518,"This subsection discusses the theoretical insight underlying the collision-free regularizer, by inspect-
ing the effect of regularization on the regret bound of LOCO where the constantly trained neural
network feeds a dynamic embedding to the Gaussian process."
DISCUSSION AND THEORETICAL INSIGHT,0.25524475524475526,"While the key idea for bounding the regret of UCB-based GP bandit optimization algorithms follows
the analysis of Srinivas et al. (2010), two unique challenges are posed in the analysis of LOCO.
Firstly, unlike previous work in Srinivas et al. (2010), the neural network is constantly retrained
along with the new observations. Thus, the input space for the downstream Gaussian process could
be highly variant."
DISCUSSION AND THEORETICAL INSIGHT,0.25874125874125875,"For the discussion below, we consider a stationary and monotonic kernel, and assume that retraining
the neural network g does not decrease the distance between data points in the latent space. It is
worth noting that, although not strictly enforced, such monotonicity behavior is naturally encour-
aged by our proposed regularization, which only penalizes the pair of too-close data in the latent
space. Under the above assumption, the internal complexity of neural network training still makes
it challenging to bound the regret w.r.t the dynamics of the neural network. Thus, we investigate the
dynamics of the mutual information term in the regret bound, and justify the proposed collision-free
regularizer by showing that penalizing the collisions tends to reduces the upper bound on the regret."
DISCUSSION AND THEORETICAL INSIGHT,0.26223776223776224,"We ﬁrst consider a discrete decision set and then leverage the desired Lipschitz continuity on the
regularized space to extend our results to the continuous setting (cf full proofs in Appendix A).
Proposition 1. Let Z be a ﬁnite discrete set. Let δ ∈(0, 1), and deﬁne βt = 2 log
 
|Z|t2/6δ

.
Suppose that the objective function h : Z × θ −→R deﬁned on Z and parameterized by θ is a sam-
ple from GP. Furthermore, consider a stationary and monotonic kernel, and assume that retraining
the neural network g does not decrease the distance between data points in the latent space. Run-
ning GP-UCB with βt for a sample h of a GP with mean function zero and stationary covariance
function k(x, x′), we obtain a regret bound of O∗(
p"
DISCUSSION AND THEORETICAL INSIGHT,0.26573426573426573,"log(|Z|)T(γT −I (h(zT , θh,0); φT )) with high
probability."
DISCUSSION AND THEORETICAL INSIGHT,0.2692307692307692,Under review as a conference paper at ICLR 2022
DISCUSSION AND THEORETICAL INSIGHT,0.2727272727272727,"More speciﬁcally, with C1 = 8/ log
 
1 + σ−2
, we have"
DISCUSSION AND THEORETICAL INSIGHT,0.2762237762237762,"P

RT ≤
q"
DISCUSSION AND THEORETICAL INSIGHT,0.27972027972027974,"C1TβT (γT −I (h(zT , θh,0); φT ))

≥1 −δ."
DISCUSSION AND THEORETICAL INSIGHT,0.28321678321678323,"Here γT is the maximum information gain after T iterations, and φT as the identiﬁcation of the
collided data points on Z. γT is deﬁned as γT :=
max
A⊂Z,|A|=T I (yA, φT ; h(A, θT ))."
DISCUSSION AND THEORETICAL INSIGHT,0.2867132867132867,"The collision regularization reduced the maximum mutual information by a speciﬁc term dependent
on the distribution of the noise caused by the collision of data points. The distribution is dynamic
and determined by the complex learning process of the neural network. In the following, we show
that the mutual information is bounded within a given interval:"
DISCUSSION AND THEORETICAL INSIGHT,0.2902097902097902,"Assume φt is a random variable that identify zt ∈Z, yt ∈Y from its collided points, and the
variance of the collision is σ2
col, then we have"
DISCUSSION AND THEORETICAL INSIGHT,0.2937062937062937,"0 ≤I (h(zT , θh,0); φT ) ≤1/2 log |2πeσ2
colI|"
DISCUSSION AND THEORETICAL INSIGHT,0.2972027972027972,"This means that if φt is a random variable sampled from a Gaussian distribution deﬁned on h, then
I (h(zT , θh,0); φT ) is maximized."
DISCUSSION AND THEORETICAL INSIGHT,0.3006993006993007,"The regularization also constrains the function h to be Lipschitz-continuous with a Lipschitz con-
stant, enabling a slightly narrower regret bound.
Proposition 2. Let Z ⊂[0, r]d be compact and convex, d ∈N, r > 0 and λ ≥0.
Sup-
pose that the objective function h : Z × θ −→R deﬁned on Z and parameterized by θ is a
sample from GP and is Lipschitz continuous with Lipschitz constant λ.
Let δ ∈(0, 1), and
deﬁne βt = 2 log
 
π2t2/6δ

+ 2d log
 
λrdt2
.
Furthermore, consider a stationary and mono-
tonic kernel, and assume that retraining the neural network g does not decrease the distance
between data points in the latent space.
Running GP-UCB with βt for a sample h of a GP
with mean function zero and stationary covariance function k(x, x′), we obtain a regret bound of
O∗(
p"
DISCUSSION AND THEORETICAL INSIGHT,0.3041958041958042,"dT(γT −I (h(zT , θh,0); φT )) with high probability."
DISCUSSION AND THEORETICAL INSIGHT,0.3076923076923077,"More speciﬁcally, with C1 = 8/ log
 
1 + σ−2
, we have"
DISCUSSION AND THEORETICAL INSIGHT,0.3111888111888112,"P

RT ≤
q"
DISCUSSION AND THEORETICAL INSIGHT,0.3146853146853147,"C1TβT (γT −I (h(zT , θh,0); φT )) + 2

≥1 −δ."
DISCUSSION AND THEORETICAL INSIGHT,0.3181818181818182,"Here γT is the maximum information gain after T iterations, and φT as the identiﬁcation of the
collided data points on Z. γT is deﬁned as γT :=
max
A⊂Z,|A|=T I (yA, φT ; h(A, θT ))."
EXPERIMENTS,0.32167832167832167,"6
EXPERIMENTS"
EXPERIMENTS,0.32517482517482516,"In this section, we empirically evaluate our algorithm on several synthetic and real-world bench-
mark blackbox function optimization tasks. All experiments are conducted on Google Cloud GPU
instance (4 vCPUs, 15 GB memory, Tesla T4 GPU) and Google CoLab high-RAM GPU instance."
EXPERIMENTAL SETUP,0.32867132867132864,"6.1
EXPERIMENTAL SETUP"
EXPERIMENTAL SETUP,0.3321678321678322,"We consider ﬁve baselines in our experiments. Three popular optimization algorithms—particle
swarm optimization (PSO) (Miranda, 2018), Tree-structured Parzen Estimator Approach (TPE)
(Bergstra et al., 2011), a BoTorch (Balandat et al., 2020) implementation of Trust Region Bayesian
Optimization (TuRBO) (Eriksson et al., 2019), and standard Bayesian optimization (BO) (Nogueira,
2014) which uses Gaussian processes as the statistical model—are tuned in each task. Another base-
line we consider is the sample-efﬁcient LSO (SE LSO) algorithm, which is implemented based on
the algorithm proposed by Tripp et al. (2020). We also compare the non-regularized latent space
optimization (LSO), LOCO with uniform weights (i.e. ζ = 0, referred to as LOCO), and the
dynamically-weighted LOCO (i.e. with ζ > 0, referred to as DW LOCO) proposed in this paper."
EXPERIMENTAL SETUP,0.3356643356643357,"One crucial problem in practice is tuning the hyper-parameters. The hyper-parameters for GP are
tuned for periodically retraining in the optimization process by minimizing the loss function on a"
EXPERIMENTAL SETUP,0.33916083916083917,Under review as a conference paper at ICLR 2022
EXPERIMENTAL SETUP,0.34265734265734266,"(a) Max Area
(b) Sum 200D
(c) Rastrigin 2D"
EXPERIMENTAL SETUP,0.34615384615384615,"(d) Water Converter
(e) Supernova
(f) SPOKES"
EXPERIMENTAL SETUP,0.34965034965034963,"Figure 3: Experiment results on six pre-collected datasets. Each experiment is repeated at least
eight times.The colored area around the mean curve denotes the
ˆσ
√n. Here ˆσ denotes the empirical
standard deviation. n denotes the number of cases repeated in experiments. Note that the BO and
TPE implementation we tested can not ﬁnish in reasonable time for ﬁgure 3a and ﬁgure 3b."
EXPERIMENTAL SETUP,0.3531468531468531,"validation set. For all our tasks, we choose a simple neural network architecture due to the reasoning
in section 3.3, as well as due to limited and expensive access to labeled data under the BO setting.
The coefﬁcient ρ is, in general, selected to guarantee a similar order for the collision penalty to GP
loss. The λ should be tolerant of the additive noise in the evaluation. In practice, we choose the
simple setting λ = 1 and ﬁnd it perform well. We also include a study of the parameter choice in
the appendix. ζ controls the aggressiveness of the importance weight. While ζ should not be too
close to zero (equivalent to uniform weight) , an extremely high value could make the regularization
overly biased. Such a severe bias could allow a heavily collided representation in most of the latent
space and degrade regularization effectiveness. The value choice is similar to the inverse of the
temperature parameter of softmax in deep learning (Hinton et al., 2015). Here we use ζ = 1 for
simplicity and ﬁnd it robust to different tasks. All experiments are conducted on the pre-collected
datasets. We defer the detailed experimental setup to Appendix C."
DATASETS AND RESULTS,0.35664335664335667,"6.2
DATASETS AND RESULTS"
DATASETS AND RESULTS,0.36013986013986016,"We now evaluate LOCO on three synthetic datasets and three real-world datasets. We demon-
strated the improvement in LOCO that is enabled by the explicit collision mitigation in the lower-
dimensional latent space in terms of average simple regret."
D SHAPE AREA MAXIMIZATION,0.36363636363636365,"2D Shape Area Maximization
The dSprites dataset (Matthey et al., 2017) consists of images of
size 64 × 64 containing 2d Shapes with different scales, rotations, and positions. Each pixel value
of the images are binary, hence x ∈{0, 1}64×64. The goal is to generate a shape x with maximum
area, which is equivalent to ﬁnding arg max
x"
D SHAPE AREA MAXIMIZATION,0.36713286713286714,"P64×64
i
xi where i corresponds to the pixel index. The"
D SHAPE AREA MAXIMIZATION,0.3706293706293706,"neural network is pretrained on 50 data points. To meet the limitation of memory on our computing
instance, we uniformly sample 10000 points from the original dataset and approximately maintain
the original distribution of the objective value. The DW LOCO and LOCO outperform or matches
the baseline methods on this dataset."
D SHAPE AREA MAXIMIZATION,0.3741258741258741,Under review as a conference paper at ICLR 2022
D SHAPE AREA MAXIMIZATION,0.3776223776223776,"Sum 200D
We create a synthetic dataset Sum 200D of 200 dimensions. Each dimension is inde-
pendently sampled from a standard normal distribution to maximize the uncertainty on that dimen-
sions and examine the algorithm’s capability to solve the medium-dimensional problem. We want
to maximize the label f(x) = P200
i=1 exi which bears an additive structure and of non-linearity. The
neural network is pretrained on 100 data points. As illustrated by ﬁgure 3b DW LOCO and LOCO
could signiﬁcantly outperform baselines that do not speciﬁcally leverage the additive structures of
the problem."
D SHAPE AREA MAXIMIZATION,0.3811188811188811,"Rastrigin-2D
The Rastrigin function is a non-convex function used as a performance test problem
for optimization algorithms. It was ﬁrst proposed by Rastrigin (1974) and used as a popular bench-
mark dataset for evaluating Gaussian process regression algorithms (Cully et al., 2018). Formally,
the 2D Rastrigin function is f(x) = 10d + Pd
i=1 x2
i −10 cos(2πxi), d = 2. For convenience of
comparison, we take the −f(x) as the objective value to make the optimization tasks a maximization
task."
D SHAPE AREA MAXIMIZATION,0.38461538461538464,"Supernova-3D
Our ﬁrst real-world task is to perform maximum likelihood inference on three
cosmological parameters, the Hubble constant H0 ∈(60, 80), the dark matter fraction ΩM ∈(0, 1),
and the dark energy fraction ΩA ∈(0, 1). The likelihood is given by the Robertson-Walker metric,
which requires a one-dimensional numerical integration for each point in the dataset from Davis
et al. (2007). The neural network is pretrained on 100 data points. As illustrated by ﬁgure 3e, both
LOCO and DW LOCO demonstrate its consistent robustness. Among them, DW LOCO slightly
outperform LOCO the early stage."
D SHAPE AREA MAXIMIZATION,0.3881118881118881,"Water Converter Conﬁguration-16D
This UCI dataset we use consists of positions and absorbed
power outputs of wave energy converters (WECs) from the southern coast of Sydney. The applied
converter model is a fully submerged three-tether converter called CETO. 16 WECs locations are
placed and optimized in a size-constrained environment."
D SHAPE AREA MAXIMIZATION,0.3916083916083916,"Redshift Distribution-14D
Careful accounting of all the requirements and features of these ex-
periments becomes increasingly necessary to achieve the goals of a given cosmic survey. SPOKES
(SPectrOscopic KEn Simulation) is an end-to-end framework that can simulate all the operations and
critical decisions of a cosmic survey (Nord et al., 2016). In this work, we use SPOKES to generate
galaxies within a speciﬁed window of distances from Earth. We then minimize the Hausdorff dis-
tance between the desired redshift distribution and the simulation of speciﬁc cosmological surveys
generated by SPOKES. In our experiments, the neural network is pretrained with 400 data points.
As illustrated by ﬁgure 3f, the simple regret of DW LOCO drops slower yet eventually outperforms
or matches other baselines’ performances."
D SHAPE AREA MAXIMIZATION,0.3951048951048951,"In general, our experimental results consistently demonstrate the robustness of our methods against
collisions in the learned latent space. Our method outperforms or matches the performance of the
best baselines in all scenarios. When compared to the sample-efﬁcient LSO, DW LOCO performs
better in most cases and shows a steady capability to reach the optimum by explicitly mitigating the
collision in the latent space. Due to the dynamics of representation learning process, it is difﬁcult to
claim that the performance improvement brought by dynamic weighting is universal. This aligned
with the observation in the experiments that DW LOCO brings observable improvement in the regret
curve at a certain stage for an optimization task and achieve an ultimate performance that at least
matches LOCO. In contrast, the sample-efﬁcient LSO might fail due to the collision problem."
CONCLUSION,0.3986013986013986,"7
CONCLUSION"
CONCLUSION,0.4020979020979021,"We have proposed a novel regularization scheme for latent-space-based Bayesian optimization. Our
algorithm—namely LOCO—addresses the collision problem induced by dimensionality reduction
and improves the performance for latent space-based optimization algorithms. We show that the
regularization effectively mitigates the collision problem in the learned latent spaces and, therefore,
can boost the performance of the Bayesian optimization in the latent space. We demonstrate solid
empirical results for LOCO on several synthetic and real-world datasets. Furthermore, we demon-
strate that LOCO can deal with high-dimensional input that could be highly valuable for real-world
experiment design tasks such as cosmological survey scheduling."
CONCLUSION,0.40559440559440557,Under review as a conference paper at ICLR 2022
REFERENCES,0.4090909090909091,REFERENCES
REFERENCES,0.4125874125874126,"Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, An-
drew Gordon Wilson, and Eytan Bakshy. BoTorch: A Framework for Efﬁcient Monte-Carlo
Bayesian Optimization. In Advances in Neural Information Processing Systems 33, 2020. URL
http://arxiv.org/abs/1910.06403."
REFERENCES,0.4160839160839161,"Yoshua Bengio, Olivier Delalleau, and Nicolas Le Roux. The curse of dimensionality for local
kernel machines. Techn. Rep, 1258:12, 2005."
REFERENCES,0.4195804195804196,"James Bergstra, R´emi Bardenet, Yoshua Bengio, and Bal´azs K´egl. Algorithms for hyper-parameter
optimization. In J. Shawe-Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Q. Weinberger, edi-
tors, Advances in Neural Information Processing Systems, volume 24, pages 2546–2554. Curran
Associates, Inc., 2011."
REFERENCES,0.4230769230769231,"Felix Berkenkamp, Angela P Schoellig, and Andreas Krause.
Safe controller optimization for
quadrotors with gaussian processes. 2016."
REFERENCES,0.42657342657342656,"Micka¨el Binois, David Ginsbourger, and Olivier Roustant. A warped kernel improving robustness
in bayesian optimization via random embeddings. In International Conference on Learning and
Intelligent Optimization, pages 281–286. Springer, 2015."
REFERENCES,0.43006993006993005,"Ilija Bogunovic, Jonathan Scarlett, Stefanie Jegelka, and Volkan Cevher. Adversarially robust opti-
mization with gaussian processes. In NeurIPS, 2018."
REFERENCES,0.43356643356643354,"A. Cully, K. Chatzilygeroudis, F. Allocati, and J.-B. Mouret. Limbo: A Flexible High-performance
Library for Gaussian Processes modeling and Data-Efﬁcient Optimization. The Journal of Open
Source Software, 3(26):545, 2018. doi: 10.21105/joss.00545."
REFERENCES,0.4370629370629371,"T. M. Davis, E. Mortsell, J. Sollerman, A. C. Becker, S. Blondin, P. Challis, A. Clocchiatti, A. V. Fil-
ippenko, R. J. Foley, P. M. Garnavich, S. Jha, K. Krisciunas, R. P. Kirshner, B. Leibundgut, W. Li,
T. Matheson, G. Miknaitis, G. Pignata, A. Rest, A. G. Riess, B. P. Schmidt, R. C. Smith, J. Spy-
romilio, C. W. Stubbs, N. B. Suntzeff, J. L. Tonry, W. M. Wood-Vasey, and A. Zenteno. Scruti-
nizing exotic cosmological models using ESSENCE supernova data combined with other cosmo-
logical probes. The Astrophysical Journal, 666(2):716–725, sep 2007. doi: 10.1086/519988."
REFERENCES,0.4405594405594406,"Zheng Ding, Yifan Xu, Weijian Xu, Gaurav Parmar, Yang Yang, Max Welling, and Zhuowen Tu.
Guided variational autoencoder for disentanglement learning. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition, pages 7920–7929, 2020."
REFERENCES,0.44405594405594406,"Josip Djolonga, Andreas Krause, and V. Cevher. High-dimensional gaussian process bandits. In
Neural Information Processing Systems, 2013."
REFERENCES,0.44755244755244755,"David Eriksson, Michael Pearce, Jacob Gardner, Ryan D Turner, and Matthias Poloczek. Scalable
global optimization via local bayesian optimization. Advances in Neural Information Processing
Systems, 32:5496–5507, 2019."
REFERENCES,0.45104895104895104,"Bruno Giovanni Galuzzi, Ilaria Giordani, Antonio Candelieri, Riccardo Perego, and Francesco
Archetti. Bayesian optimization for recommender system. In World Congress on Global Op-
timization, pages 751–760. Springer, 2019."
REFERENCES,0.45454545454545453,"Jacob R Gardner, Geoff Pleiss, David Bindel, Kilian Q Weinberger, and Andrew Gordon Wilson.
Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu acceleration. In Advances
in Neural Information Processing Systems, 2018."
REFERENCES,0.458041958041958,"Rafael G´omez-Bombarelli, Jennifer N Wei, David Duvenaud, Jos´e Miguel Hern´andez-Lobato,
Benjam´ın S´anchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D Hirzel,
Ryan P Adams, and Al´an Aspuru-Guzik. Automatic chemical design using a data-driven contin-
uous representation of molecules. ACS central science, 4(2):268–276, 2018."
REFERENCES,0.46153846153846156,"Ryan-Rhys Grifﬁths and Jos´e Miguel Hern´andez-Lobato. Constrained bayesian optimization for
automatic chemical design using variational autoencoders. Chemical science, 11(2):577–586,
2020."
REFERENCES,0.46503496503496505,Under review as a conference paper at ICLR 2022
REFERENCES,0.46853146853146854,"Geoffrey E. Hinton, Oriol Vinyals, and J. Dean. Distilling the knowledge in a neural network. ArXiv,
abs/1503.02531, 2015."
REFERENCES,0.47202797202797203,"Wenbing Huang, Deli Zhao, Fuchun Sun, Huaping Liu, and Edward Chang. Scalable gaussian
process regression using deep neural networks. In Proceedings of the 24th International Con-
ference on Artiﬁcial Intelligence, IJCAI’15, pages 3576 – 3582. AAAI Press, 2015.
ISBN
9781577357384."
REFERENCES,0.4755244755244755,"Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014."
REFERENCES,0.479020979020979,"Ben Letham, Roberto Calandra, Akshara Rai, and Eytan Bakshy. Re-examining linear embeddings
for high-dimensional bayesian optimization. Advances in Neural Information Processing Systems,
33, 2020."
REFERENCES,0.4825174825174825,"Xiaoyu Lu, Javier Gonzalez, Zhenwen Dai, and Neil Lawrence.
Structured variationally auto-
encoded optimization. volume 80 of Proceedings of Machine Learning Research, pages 3267–
3275, Stockholm International Fairs, Stockholm Sweden, 10–15 Jul 2018. PMLR."
REFERENCES,0.486013986013986,"Emile Mathieu, Tom Rainforth, Nana Siddharth, and Yee Whye Teh. Disentangling disentanglement
in variational autoencoders. In International Conference on Machine Learning, pages 4402–4412.
PMLR, 2019."
REFERENCES,0.48951048951048953,"Loic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner. dsprites: Disentanglement
testing sprites dataset. https://github.com/deepmind/dsprites-dataset/, 2017."
REFERENCES,0.493006993006993,"Lester James V. Miranda. PySwarms, a research-toolkit for Particle Swarm Optimization in Python.
Journal of Open Source Software, 3, 2018. doi: 10.21105/joss.00433."
REFERENCES,0.4965034965034965,"Mojm´ır Mutn`y and Andreas Krause. Efﬁcient high dimensional bayesian optimization with addi-
tivity and quadrature fourier features. Advances in Neural Information Processing Systems 31,
pages 9005–9016, 2019."
REFERENCES,0.5,"Amin Nayebi, Alexander Munteanu, and Matthias Poloczek. A framework for bayesian optimization
in embedded subspaces. In International Conference on Machine Learning, pages 4752–4761.
PMLR, 2019."
REFERENCES,0.5034965034965035,"Fernando Nogueira. Bayesian Optimization: Open source constrained global optimization tool for
Python, 2014."
REFERENCES,0.506993006993007,"B. Nord, A. Amara, A. R´efr´egier, La. Gamper, Lu. Gamper, B. Hambrecht, C. Chang, J.E. Forero-
Romero, S. Serrano, C. Cunha, O. Coles, A. Nicola, M. Busha, A. Bauer, W. Saunders, S. Jouvel,
D. Kirk, and R. Wechsler. Spokes: An end-to-end simulation facility for spectroscopic cosmolog-
ical surveys. Astronomy and Computing, 15:1 – 15, 2016. ISSN 2213-1337."
REFERENCES,0.5104895104895105,"Ali Rahimi, Benjamin Recht, et al. Random features for large-scale kernel machines. In Neural
Information Processing Systems, volume 3, page 5. Citeseer, 2007."
REFERENCES,0.513986013986014,"C. E. Rasmussen and C. K. I. Williams. Gaussian Processes for Machine Learning. MIT Press,
2006."
REFERENCES,0.5174825174825175,"Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine Learning
(Adaptive Computation and Machine Learning). The MIT Press, 2005. ISBN 026218253X."
REFERENCES,0.5209790209790209,"Leonard Andreeviˇc Rastrigin. Systems of extremal control. Nauka, 1974."
REFERENCES,0.5244755244755245,"Jasper Snoek, Hugo Larochelle, and Ryan P Adams. Practical bayesian optimization of machine
learning algorithms. In 26th Annual Conference on Neural Information Processing Systems 2012,
pages 2951–2959, 2012."
REFERENCES,0.527972027972028,"Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram,
Mostofa Patwary, Mr Prabhat, and Ryan Adams.
Scalable bayesian optimization using deep
neural networks. In International conference on machine learning, pages 2171–2180. PMLR,
2015."
REFERENCES,0.5314685314685315,Under review as a conference paper at ICLR 2022
REFERENCES,0.534965034965035,"Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. Gaussian process opti-
mization in the bandit setting: No regret and experimental design. In Proceedings of the 27th
International Conference on International Conference on Machine Learning, ICML’10, pages
1015–1022, Madison, WI, USA, 2010. Omnipress. ISBN 9781605589077."
REFERENCES,0.5384615384615384,"Yanan Sui, Joel Burdick, Yisong Yue, et al. Stagewise safe bayesian optimization with gaussian
processes. In International Conference on Machine Learning, pages 4781–4789. PMLR, 2018."
REFERENCES,0.541958041958042,"William R Thompson. On the likelihood that one unknown probability exceeds another in view of
the evidence of two samples. Biometrika, 25(3/4):285–294, 1933."
REFERENCES,0.5454545454545454,"Austin Tripp, Erik Daxberger, and Jos´e Miguel Hern´andez-Lobato. Sample-efﬁcient optimization
in the latent space of deep generative models via weighted retraining. Advances in Neural Infor-
mation Processing Systems, 33, 2020."
REFERENCES,0.548951048951049,"Ziyu Wang, Frank Hutter, Masrour Zoghi, David Matheson, and Nando de Feitas. Bayesian op-
timization in a billion dimensions via random embeddings.
Journal of Artiﬁcial Intelligence
Research, 55:361–387, 2016."
REFERENCES,0.5524475524475524,"Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P. Xing. Deep kernel learning.
volume 51 of Proceedings of Machine Learning Research, pages 370–378, Cadiz, Spain, 09–11
May 2016. PMLR."
REFERENCES,0.5559440559440559,"Kevin K Yang, Zachary Wu, and Frances H Arnold. Machine-learning-guided directed evolution for
protein engineering. Nature methods, 16(8):687–694, 2019."
REFERENCES,0.5594405594405595,Under review as a conference paper at ICLR 2022
REFERENCES,0.5629370629370629,"A
PROOFS"
REFERENCES,0.5664335664335665,"In this section, we provide proofs for our main theoretical results (Proposition 1 and Proposition 2)."
REFERENCES,0.5699300699300699,"A.1
PROOF OF PROPOSITION 1:
REGRET BOUND ON DISCRETE DECISION SET"
REFERENCES,0.5734265734265734,"We follow the proof structure in Srinivas et al. (2010) and introduce new notations to characterize
the learning process of the neural network and the collision in the proof."
REFERENCES,0.5769230769230769,"Before proving Proposition 1, we ﬁrst introduce a few useful lemmas."
REFERENCES,0.5804195804195804,"Lemma 1. Pick δ ∈(0, 1) and set βt = 2 log(|D|πt/δ), where P
t≥1 π−1
t
= 1, πt > 0. Then with
probability ≥1 −δ, ∀x ∈D, ∀t ≥1"
REFERENCES,0.583916083916084,"|h(g(x, θg,t−1), θt−1) −µt1| ≤β1/2
t
σt−1(g(x, θg,t−1))"
REFERENCES,0.5874125874125874,"Here θg,t−1 is the parameter for g at time step t−1. θh,t−1 is the parameter for h at time step t−1."
REFERENCES,0.5909090909090909,"Proof. ∀x ∈D, ∀t ≥1, Conditioned on yt−1 = (y1, ..., yt−1), {x1, ..., xt−1} are deterministic,
and h(g(x, θg,t−1), θh,t−1) ∼N(µt−1(g(x, θg,t−1)), σ2
t−1(g(x, θg,t−1))). Then using the subgaus-
sianity of h, we have"
REFERENCES,0.5944055944055944,"Pr{|h(g(x, θg,t−1), θt−1) −µt1| ≥β1/2
t
σt−1(g(x, θg,t−1))} ≤e−βt/2"
REFERENCES,0.5979020979020979,"Applying the union bound, with probability ≥1 −|D|e−βt/2, ∀x ∈D"
REFERENCES,0.6013986013986014,"|h(g(x, θg,t−1), θt−1) −µt1| ≤β1/2
t
σt−1(g(x, θg,t−1))"
REFERENCES,0.6048951048951049,"Let |D|e−βt/2 = δ/πt, applying the union bound for ∀t ∈N the statement holds."
REFERENCES,0.6083916083916084,"Lemma 2. Consider a stationary and monotonic kernel, and assume that retraining the neural
network g does not decrease the distance between data points in the latent space. Then ∀t ≥1,"
REFERENCES,0.6118881118881119,"rt(θt−1) ≤2β1/2
t
σt−1(g(x, θg,t−1)) ≤2β1/2
t
σt−1(g(x, θg,T ))."
REFERENCES,0.6153846153846154,"Here θg,T is the parameter for g at time step T."
REFERENCES,0.6188811188811189,Proof.
REFERENCES,0.6223776223776224,"rt(θt−1) = h(g(x∗, θg,t−1), θh,t−1) −h(g(xt, θg,t−1), θh,t−1)"
REFERENCES,0.6258741258741258,"≤β1/2
t
σt−1(g(x∗, θg,t−1)) + µt−1(g(x∗, θg,t−1) −h(g(xt, θg,t−1), θh,t−1)"
REFERENCES,0.6293706293706294,"≤β1/2
t
σt−1(g(xt, θg,t−1)) + µt−1(g(xt, θg,t−1) −h(g(xt, θg,t−1), θh,t−1)"
REFERENCES,0.6328671328671329,"≤2β1/2
t
σt−1(g(xt, θg,t−1))"
REFERENCES,0.6363636363636364,"≤2β1/2
t
σt−1(g(xt, θg,T ))"
REFERENCES,0.6398601398601399,"The last line is because the non-decreasing distance between g(x, θg,T ) and g(x′, θg,T ) ∀x, x′ ∈D
leads to larger variance σt when using a stationary and monotonic kernel."
REFERENCES,0.6433566433566433,"Lemma 3. The information gain for the points selected can be expressed in terms of the predictive
variance. If hT = (h(g(xt, θg,T ), θh,T )) ∈RT :"
REFERENCES,0.6468531468531469,"I (yT ; hT ) = 1 2 T
X"
REFERENCES,0.6503496503496503,"t=1
log
 
1 + σ−2σ2
t−1(g(xt, θg,T ))
"
REFERENCES,0.6538461538461539,Under review as a conference paper at ICLR 2022
REFERENCES,0.6573426573426573,"Proof. First, we get I (yT ; hT ) = H(yT ) −1"
REFERENCES,0.6608391608391608,"2 log |2πeσ2I|. Then,"
REFERENCES,0.6643356643356644,H(yT ) = H(yT −1) + H(yT |yT −1)
REFERENCES,0.6678321678321678,"= H(yT −1) + log
 
2πe(σ2
t−1(g(xT , θg,T )))
"
REFERENCES,0.6713286713286714,"Since x1, ..., xT are deterministic conditioned on yT −1. The result follows by induction."
REFERENCES,0.6748251748251748,"Lemma 4. The gap of the mutual information between collision-free g(xt, θg,T ) and unregularized
g(xt, θg,0) is"
REFERENCES,0.6783216783216783,"I (yT ; h(zT , θh,T )) = I (yT ; h(zT , θh,T )|φT )
= I (yT ; h(zT , θh,0)|φT )
= I (yT , φT ; h(zT , θh,0)) −I (h(zT , θh,0); φT ))"
REFERENCES,0.6818181818181818,"Here zt = g(xt, θg,T ). φ is the identiﬁcation of collided data points."
REFERENCES,0.6853146853146853,"The result is a simple application of the chain rule of mutual information.
I (yT ; hT ) =
I (yT ; h(zT , θh,T )) corresponds to the information gain under fully regularized and assumed
collision-free setting. I (yT , φT ; h(zT , θh,0)) corresponds to information gain under unregularized
setting."
REFERENCES,0.6888111888111889,"Lemma 5. Pick δ ∈(0, 1) and let βt be deﬁned as in Lemma 1. Then, the following holds with
probability ≥1 −δ, ∀T ≥1, T
X"
REFERENCES,0.6923076923076923,"t=1
r2
t ≤βT C1I (yT ; hT ) ≤C1βT (γT −I (h(zT , θh,0); φT ))."
REFERENCES,0.6958041958041958,"Here C1 :=
8
log(1+σ−2) ≥8σ2."
REFERENCES,0.6993006993006993,Proof. We ﬁrst observe that
REFERENCES,0.7027972027972028,"4βtσ2
t−1(g(xt, θg,T )) ≤4βtσ2(σ−2σ2
t−1(g(xt, θg,T )))"
REFERENCES,0.7062937062937062,"≤4βtσ2(
σ−2"
REFERENCES,0.7097902097902098,"log(1 + σ−2)) log
 
1 + σ−2σ2
t−1(g(xt, θg,T ))
"
REFERENCES,0.7132867132867133,"Combining the above inequality with Lemma 2, Lemma 3 and Lemma 4 completes the proof."
REFERENCES,0.7167832167832168,Now we are ready to prove Proposition 1.
REFERENCES,0.7202797202797203,"Proof of Proposition 1. Proposition 1 is a simple consequence of Lemma 4 and Lemma 5 and
Cauchy-Schwarz inequality."
REFERENCES,0.7237762237762237,"A.2
PROOF OF PROPOSITION 2:
REGRET BOUND WITH LIPSCHITZ-CONTINUOUS OBJECTIVE FUNCTION"
REFERENCES,0.7272727272727273,"We ﬁrst modify Lemma 5.7 and Lemma 5.8 in Srinivas et al. (2010) since we are assuming the deter-
ministic Lipschitz-continuity for h. Use the same analysis tool Zt deﬁned as a set of discretization
Zt ⊂Z where Zt will be used at time t in the analysis."
REFERENCES,0.7307692307692307,"We choose a discretization Zt of size (τt)d. so that ∀z ∈Z,"
REFERENCES,0.7342657342657343,"||z −[z]t||1 ≤rd/τt
(4)"
REFERENCES,0.7377622377622378,where [z]t denotes the closest point in Zt to z.
REFERENCES,0.7412587412587412,"Lemma 6. Pick δ ∈(0, 1) and set β = 2 log(πtδ)+2d log
 
Lrdt2
, where P"
REFERENCES,0.7447552447552448,"t≥1 π−1
t
= 1, πt > 0.
Let τt = Lrdt2. Hence then"
REFERENCES,0.7482517482517482,"|h(z∗, θh,t−1) −µt−1([z∗]t)| ≤β1/2
t
σt−1([z∗]t) + 1/t2
∀t ≥1"
REFERENCES,0.7517482517482518,holds with probability ≥1 −δ.
REFERENCES,0.7552447552447552,Under review as a conference paper at ICLR 2022
REFERENCES,0.7587412587412588,"Proof. Using the Lipschitz-continuity and equation 4, we have that"
REFERENCES,0.7622377622377622,"∀z ∈Z, |h(z, θh,t−1) −h([z]t, , θh,t−1)| ≤Lrd/τt"
REFERENCES,0.7657342657342657,"By choosing τt = Lrdt2, we have |Zt| = (Lrdt2)d and"
REFERENCES,0.7692307692307693,"∀z ∈Z, |h(z, θh,t−1) −h([z]t, θh,t−1)| ≤1/t2"
REFERENCES,0.7727272727272727,"Then using Lemma 1, we reach the expected result."
REFERENCES,0.7762237762237763,"Based on Lemma 2 and Lemma 6, we could have the following result directly."
REFERENCES,0.7797202797202797,"Lemma 7. Pick δ ∈(0, 1) and set β = 2 log(2πtδ)+2d log
 
Lrdt2
, where P
t≥1 π−1
t
= 1, πt > 0.
Then with probability ≥1 −δ, for all t ∈N, the regret is bounded as follows:"
REFERENCES,0.7832167832167832,"rt ≤2β1/2
t
σt−1(zt) + 1/t2"
REFERENCES,0.7867132867132867,"Proof. Using the union bound of δ/2 in both Lemma 2 and Lemma 6, we have that with probability
1 −δ:"
REFERENCES,0.7902097902097902,rt = h(z∗) −h(zt)
REFERENCES,0.7937062937062938,"≤β1/2
t
σt−1(zt) + 1/t2 + µt−1(zt) −h(zt)"
REFERENCES,0.7972027972027972,"≤2β1/2
t
σt−1(zt) + 1/t2"
REFERENCES,0.8006993006993007,which complete the proof.
REFERENCES,0.8041958041958042,Now we are ready to prove Proposition 2.
REFERENCES,0.8076923076923077,"Proof of Proposition 2. Using Lemma 7, we have that with probability ≥1 −δ: T
X"
REFERENCES,0.8111888111888111,"t=1
4βtσ2
t−1(xt) ≤C1βT (γT −I (h(zT , θh,0); φT ))
∀T ≥1"
REFERENCES,0.8146853146853147,"By Cauchy-Schwarz: T
X"
REFERENCES,0.8181818181818182,"t=1
2β1/2
t
σt−1(xt) ≤
q"
REFERENCES,0.8216783216783217,"C1βT (γT −I (h(zT , θh,0); φT ))
∀T ≥1"
REFERENCES,0.8251748251748252,"Finally, substitute πt with π2t2/6 (since P 1/t2 = π2/6). Proposition 2 follows."
REFERENCES,0.8286713286713286,Under review as a conference paper at ICLR 2022
REFERENCES,0.8321678321678322,"B
DEMONSTRATION OF THE COLLISION EFFECT"
REFERENCES,0.8356643356643356,"B.1
VISUALIZATION OF THE COLLISION EFFECT IN THE LATENT SPACE"
REFERENCES,0.8391608391608392,"We demonstrate the collision effect in the latent space. We train the same neural network on Feyn-
man dataset with 101 data points which demonstrate the latent space after two retrains with the
retrain interval set to be 50 data points. The regularized one employs DW LOCO, with the regu-
larization parameter ρ = 1e5, penalty parameter λ = 1e−2, retrain interval ˜T, weighting parameter
γ = 1e−2 and the base kernel set to be square exponential kernel. The non-regularized one employs
LSO."
REFERENCES,0.8426573426573427,"(a) 1-D regularized latent space
(b) 1-D non-regularized latent space"
REFERENCES,0.8461538461538461,"Figure 5: Illustrate the 1-D latent space of Feynman III.9.52 dataset. The second row shows the
ratio that the penalty deﬁne as equation 1 is non-zero. The third row shows point-wise estimation of
λ. 5a shows a regularized latent space with a few observable collisions. 5b shows a non-regularized
latent space with bumps of collisions especially around the maxima among the observed data points.
Besides, having fewer collisions in the latent space contribute to the optimization through improving
the learned Gaussian process. We observe in this comparison that the next point selected by the
acquisition function of the regularized version is approaching the global optima, while the next
point in the non-regularized version is trying to solve the uncertainty brought by the severe collision
near the currently observed maxima."
REFERENCES,0.8496503496503497,"B.2
THE COLLISION EFFECT ON PROPER NEURAL NETWORKS"
REFERENCES,0.8531468531468531,"In this section, we provide empirical results supporting the claim in section 3.3 that increasing the
network complexity often does not help to reduce the collision in the latent space."
REFERENCES,0.8566433566433567,"For Feynman task, we test the single-layer neural network, which consists of 10, 1001, 5000, or
6000 neurons with Leaky Relu activation functions."
REFERENCES,0.8601398601398601,"For Max Area task, we test the three-layer dense neural network. The ﬁrst layer consists of 50,
100, 1000 or 1500 neurons with Tanh activation functions. The second layer consists of 50 neurons
with Tanh activation functions. The third layer consists of 10 neurons with Leaky Relu activation
functions."
REFERENCES,0.8636363636363636,"For Rastrigin-2D task, we test the single-layer neural network, which consists of 10, 100, 1000, or
5000 neurons with Leaky Relu activation functions."
REFERENCES,0.8671328671328671,"For SPOKES task, we test the single-layer neural network, which consists of 10, 100, 1000, or 2000
neurons with Leaky Relu activation functions."
REFERENCES,0.8706293706293706,Under review as a conference paper at ICLR 2022
REFERENCES,0.8741258741258742,(a) Feynman
REFERENCES,0.8776223776223776,(b) Max Area
REFERENCES,0.8811188811188811,(c) Rastrigin-2D
REFERENCES,0.8846153846153846,(d) SPOKES
REFERENCES,0.8881118881118881,(e) Water Converter
REFERENCES,0.8916083916083916,"Figure 6: These curves show the network design test results. The collision value shown here is the
penalty term proposed in equation 1. The x-axis denotes the neural network’s general complexity.
The collisions for model with lowest test MSE are still signiﬁcant."
REFERENCES,0.8951048951048951,"For the Water Converter task, we test the three-layer dense neural network. The ﬁrst layer consists
of 512, 1024, 2048, or 4096 neurons with Tanh activation functions. The second layer consists of
half of the ﬁrst layer’s neurons with Tanh activation functions. The third layer consists of half of the
second layer’s neurons with Leaky Relu activation functions."
REFERENCES,0.8986013986013986,We demonstrate the collision effect on regression task on Rastrigin-2D.
REFERENCES,0.9020979020979021,Under review as a conference paper at ICLR 2022
REFERENCES,0.9055944055944056,"(a) non-regularized latent space
(b) Negative Log Likelihood
(c) Mean Squared Error"
REFERENCES,0.9090909090909091,"Figure 7: Illustrate regression task on Rastrigin-2D dataset. 7a shows a non-regularized latent space
after sufﬁciently trained as is demonstrated in 7b. 7b shows the NLL of the training process. 7a
shows the corresponding MSE."
REFERENCES,0.9125874125874126,"As illustrated in ﬁgure 7a, even after being sufﬁciently trained after 3000 iterations, there is still
collisions in the latent space especially around the optima. ﬁgure 7a shows that by regularizing the
latent space, the ultimate MSE could also be improved."
REFERENCES,0.916083916083916,Under review as a conference paper at ICLR 2022
REFERENCES,0.9195804195804196,"C
SUPPLEMENTAL MATERIALS ON ALGORITHMIC DETAILS"
REFERENCES,0.9230769230769231,"Our implementation of LOCO and DW LOCO is built upon the open source package GPytorch
(Gardner et al., 2018). The deep kernel is trained with back propogation. We use the Adam (Kingma
and Ba, 2014) optimizer with learning rate set to be 1e−2. Below we discuss the detailed conﬁgura-
tion of the underlying neural network and the choice of the key parameters used by the algorithm."
REFERENCES,0.9265734265734266,"C.1
ALGORITHMIC DETAILS ON NEURAL NETWORK ARCHITECTURE"
REFERENCES,0.9300699300699301,"As the primary goal of our paper was to showcase the performance of a novel collision-free reg-
ularizer, we pick our network architectures to be basic multi-layer dense neural network. We use
a 4-layer dense neural network. Its hidden layers consist of 1000, 500, 50 neurons respectively,
each with Leaky Relu activation functions. The output layer also uses Leaky Relu as its activation
function and generates a 1-dimensional output. x0 x1 ... xD"
REFERENCES,0.9335664335664335,"y(1)
0"
REFERENCES,0.9370629370629371,"y(1)
1 ..."
REFERENCES,0.9405594405594405,"y(1)
2L . . . . . . . . ."
REFERENCES,0.9440559440559441,"y(L)
0"
REFERENCES,0.9475524475524476,"y(L)
1"
REFERENCES,0.951048951048951,"y(L+1)
1"
REFERENCES,0.9545454545454546,input layer
"ST HIDDEN LAYER
LTH HIDDEN LAYER",0.958041958041958,"1st hidden layer
Lth hidden layer"
"ST HIDDEN LAYER
LTH HIDDEN LAYER",0.9615384615384616,output layer
"ST HIDDEN LAYER
LTH HIDDEN LAYER",0.965034965034965,"Figure 8: Network graph of a (L + 1)-layer dense network with D input units and 1 output units. In
our experiments, L is set to be 3."
"ST HIDDEN LAYER
LTH HIDDEN LAYER",0.9685314685314685,"Pre-training of the Neural Network
We randomly select the points from the bottom of the dataset
to avoid the pre-training simplifying the optimization task while helping with initializing the param-
eters of the model. The points are used to initialize the neural network instead of being served as
initial selections of the optimization task. Without the pre-training stage, the latent embedding fed
by the neural network to the gaussian process would be random. The practical problem with such
randomness could be a much larger variance for the results since it inﬂuences the following neural
network training process and the optimization process. In practice, it’s always possible to collect
pre-training datasets from relative domains when aiming at optimizing unknown objective functions.
This pre-training method was also reported in the literature (Snoek et al., 2015)."
"ST HIDDEN LAYER
LTH HIDDEN LAYER",0.972027972027972,Under review as a conference paper at ICLR 2022
"ST HIDDEN LAYER
LTH HIDDEN LAYER",0.9755244755244755,"C.2
PARAMETER CHOICES"
"ST HIDDEN LAYER
LTH HIDDEN LAYER",0.9790209790209791,"We investigate the robustness of parameter choices of the regularization parameter λ on the Rastrigin
2D dataset. We show the results in the ﬁgure below."
"ST HIDDEN LAYER
LTH HIDDEN LAYER",0.9825174825174825,"Figure 9: Simple regret under different parameter settings on the Rastrigin 2D dataset. The colored
area represents the standard error of the tests at certain iteration. Each experiments are repeated
eight times. The ﬁgure shows that a moderately large λ sufﬁces to achieve decent performance in
terms of simple regret. We believe that the wide range of objective values of the test dataset, which
otherwise would hurt the optimization performance, can be regularized by the collision penalty. The
curves demonstrate the decent performance of DW LOCO as long as the parameters are not set to
be too small."
"ST HIDDEN LAYER
LTH HIDDEN LAYER",0.986013986013986,Under review as a conference paper at ICLR 2022
"ST HIDDEN LAYER
LTH HIDDEN LAYER",0.9895104895104895,"D
ADDITIONAL RESULTS"
"ST HIDDEN LAYER
LTH HIDDEN LAYER",0.993006993006993,"Random EMbedding Bayesian Optimization (REMBO) (Wang et al., 2016) leverages simple random
linear transformations to improve the efﬁciency in low-effective-dimension high-dimensional tasks.
We compare LOCO and DW LOCO with the performance of this random-embedding-based method
and empirically exposed the failure case of REMBO when its modeling assumption does not hold
(i.e. when dealing with dataset that has large effective dimensions)."
"ST HIDDEN LAYER
LTH HIDDEN LAYER",0.9965034965034965,"Figure 10: Experiment results on six synthetic & real datasets. Each experiment is repeated at least
eight times. The shaded area around the mean curve denotes the
ˆσ
√n. Here ˆσ denotes the empirical
standard deviation. n denotes the number of cases repeated in experiments. As illustrated in the
ﬁgure, the random-embedding-based methods have been signiﬁcantly outperformed by LOCO and
DW LOCO. We place the discussion over REMBO here for two reasons. Firstly, there has been
several problems about REMBO as discussed in section 2. Secondly, the experiments are conducted
on tasks where the effective dimensions are at a similar scale as the dimensionality of the original
inputs and doesn’t align with the assumption of REMBO."
