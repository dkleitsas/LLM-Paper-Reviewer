Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0010362694300518134,"The recent integration of spiking neurons into graph neural networks has been
1"
ABSTRACT,0.002072538860103627,"gaining much attraction due to its superior energy efficiency. Especially because
2"
ABSTRACT,0.0031088082901554403,"the irregular connection among graph nodes fits the nature of the spiking neural
3"
ABSTRACT,0.004145077720207254,"networks, spiking graph neural networks are considered strong alternatives to
4"
ABSTRACT,0.0051813471502590676,"vanilla graph neural networks. However, there is still a large performance gap for
5"
ABSTRACT,0.0062176165803108805,"graph tasks between the spiking neural networks and artificial neural networks. The
6"
ABSTRACT,0.007253886010362694,"gaps are especially large when they are adapted to graph classification tasks, where
7"
ABSTRACT,0.008290155440414507,"none of the nodes in the testset graphs are connected to the training set graphs. We
8"
ABSTRACT,0.00932642487046632,"diagnose the problem as the existence of neurons under starvation, caused by the
9"
ABSTRACT,0.010362694300518135,"irregular connections among the nodes and the neurons. To alleviate the problem,
10"
ABSTRACT,0.011398963730569948,"we propose TAS-GNN. Based on a set of observations on spiking neurons on
11"
ABSTRACT,0.012435233160621761,"graph classification tasks, we devise several techniques to utilize more neurons to
12"
ABSTRACT,0.013471502590673576,"deliver meaningful information to the connected neurons. Experiments on diverse
13"
ABSTRACT,0.014507772020725389,"datasets show up to 27.20% improvement, demonstrating the effectiveness of the
14"
ABSTRACT,0.015544041450777202,"TAS-GNN.
15"
INTRODUCTION,0.016580310880829015,"1
Introduction
16"
INTRODUCTION,0.017616580310880828,"Graph neural networks (GNNs) are types of popular neural networks to learn the representations from
17"
INTRODUCTION,0.01865284974093264,"graphs, which comprise multiple nodes and edges between them. Because of their flexibility to model
18"
INTRODUCTION,0.019689119170984457,"any kind of connection existing in nature, it has various applications ranging from drug discovery [6,
19"
INTRODUCTION,0.02072538860103627,"47, 9], social influence prediction [39, 2], traffic forecasting [3, 7], and recommendation systems [38,
20"
INTRODUCTION,0.021761658031088083,"15, 61]. One known challenge of GNNs is their sparse memory and computational pattern. Because
21"
INTRODUCTION,0.022797927461139896,"many messages are passed between randomly connected nodes, there is a significant inefficiency in
22"
INTRODUCTION,0.02383419689119171,"processing them with conventional systems [53, 58, 57, 19].
23"
INTRODUCTION,0.024870466321243522,"To address the inefficiency, spiking neural networks (SNNs) are considered strong alternatives.
24"
INTRODUCTION,0.025906735751295335,"Inspired by the way biological behavior of brains, SNNs process information by communicating
25"
INTRODUCTION,0.02694300518134715,"binary spikes between the neurons. Because SNNs utilize intermittently occurring spikes, they have
26"
INTRODUCTION,0.027979274611398965,"superior energy efficiency, especially for the domain of GNNs [1].
27"
INTRODUCTION,0.029015544041450778,"Although the spiking graph neural network (SGNN) has been recently studied by many researchers [32,
28"
INTRODUCTION,0.03005181347150259,"64, 48], we find that its performance experiences a huge drop when adapted to graph classification,
29"
INTRODUCTION,0.031088082901554404,"compared to that of the conventional GNNs implemented with artificial neural networks (ANNs).
30"
INTRODUCTION,0.03212435233160622,"Upon closer analysis of the performance degradation, we identify spike frequency deviation of the
31"
INTRODUCTION,0.03316062176165803,"neurons within the model. In our investigation, many neurons experience starvation, which do not
32"
INTRODUCTION,0.03419689119170984,"emit any spike during the inference. This leads to severe information loss, due to being unable to
33"
INTRODUCTION,0.035233160621761656,"deliver signals to the subsequent neurons.
34"
INTRODUCTION,0.03626943005181347,"Such a problem was less exposed in previous spiking GNNs. This is because the testset nodes are
35"
INTRODUCTION,0.03730569948186528,"available during the training time (transductive learning [27]) or they are part of the training graph
36"
INTRODUCTION,0.0383419689119171,"(inductive learning [21]). In such settings, the model could be trained to mitigate the performance
37"
INTRODUCTION,0.039378238341968914,"drop. However, in graph classification tasks, the graphs are independent of each other, and the testset
38"
INTRODUCTION,0.04041450777202073,"comprises multiple unseen graphs, aggravating the problem.
39"
INTRODUCTION,0.04145077720207254,"Fortunately, our further analysis reveals that such phenomena are related to the topology of the input
40"
INTRODUCTION,0.04248704663212435,"graphs. We discover that a strong pattern exists among the neurons in the GNN, where 1) neurons in a
41"
INTRODUCTION,0.043523316062176166,"node have similar behaviors, 2) each feature causes different behaviors, and 3) neurons in high-degree
42"
INTRODUCTION,0.04455958549222798,"nodes tend to emit more spikes.
43"
INTRODUCTION,0.04559585492227979,"Motivated by the observations, we propose to group the neurons according to the degree of the node
44"
INTRODUCTION,0.046632124352331605,"(topology-aware group-adaptive neurons). The neurons in each group adapt the threshold together to
45"
INTRODUCTION,0.04766839378238342,"steer the firing rate toward ideal rates. To further mitigate the initial value sensitivity problem, we
46"
INTRODUCTION,0.04870466321243523,"further propose to learn the initial values.
47"
INTRODUCTION,0.049740932642487044,"We evaluate TAS-GNN over multiple GNN models and datasets. Experiments reveal that the proposed
48"
INTRODUCTION,0.05077720207253886,"TAS-GNN achieves superior performance over the baselines, setting a new state-of-the-art method
49"
INTRODUCTION,0.05181347150259067,"for graph classification. Our contributions are summarized as the following:
50"
INTRODUCTION,0.05284974093264249,"• We identify starvation problem of spiking neurons in GNNs for graph classification tasks.
51"
INTRODUCTION,0.0538860103626943,"• We observe the spike frequency patterns have a strong correlation with the graph topology.
52"
INTRODUCTION,0.054922279792746116,"• Based on the observations, we propose topology-aware group-adaptive neurons, which
53"
INTRODUCTION,0.05595854922279793,"dynamically adjusts the threshold together with the other neurons in the group to address
54"
INTRODUCTION,0.05699481865284974,"the spike frequency deviations.
55"
INTRODUCTION,0.058031088082901555,"• We propose techniques to reduce the initial value sensitivity caused by the topology-aware
56"
INTRODUCTION,0.05906735751295337,"group-adaptive neurons.
57"
INTRODUCTION,0.06010362694300518,"• We evaluate TAS-GNN on several public datasets and achieve superior performance over
58"
INTRODUCTION,0.061139896373056994,"existing techniques.
59"
BACKGROUND,0.06217616580310881,"2
Background
60"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.06321243523316063,"2.1
Spiking Neural Networks and Spike Training
61"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.06424870466321243,"Spiking neural networks (SNNs) are third-generation neural network designs that mimic the human
62"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.06528497409326425,"biological neural systems [35]. They use spike-based communication and adopt event-driven charac-
63"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.06632124352331606,"teristics that promote better energy efficiency than current ANNs. Similar to human neural systems,
64"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.06735751295336788,"SNNs consist of spiking neurons that can model spatio-temporal dynamics of the actual biological
65"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.06839378238341969,"neurons. The early forms of such neuron models are Hodgkin-Huxley neurons [23], which accurately
66"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.0694300518134715,"model the biophysical characteristics of the membrane through differential equations. However, its
67"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.07046632124352331,"mathematical complexity prohibits its practical use and scalability. Instead, Leaky Integrated-and-Fire
68"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.07150259067357513,"(LIF) model finds a middle ground between mathematical simplificity and biological plausibility, and
69"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.07253886010362694,"is popularly adopted as the baseline architecture [23]. In the LIF neuron, the weighted sum of input
70"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.07357512953367876,"spikes is accumulated over time within the neuron as membrane potential, and the output spike is
71"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.07461139896373056,"generated only when the membrane potential exceeds a present threshold value. This is represented
72"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.07564766839378238,"as a differential function:
73"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.0766839378238342,τ dV (t)
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.07772020725388601,"dt
= −V (t) + I(t),
(1)"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.07875647668393783,"where V (t) denotes the membrane potential value at time t, τ a time constant of membrane, and I(t)
74"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.07979274611398963,"is the input from connected synapses at time t. To make this time-varying function computationally
75"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.08082901554404145,"feasible, we discretize and rewrite it iteratively for sequential simulation as follows:
76"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.08186528497409326,"V (t) = V (t −1) + β(WX(t) −(V (t −1) −Vreset)),
(2)
V (t) = V (t)(1 −S(t)) + VresetS(t),
(3)"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.08290155440414508,"S(t) =
1,
if V (t) ≥Vth
0,
otherwise,
(4)"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.08393782383419689,"where β is simplified decay rate constant, Vreset is the reset value and Vth the threshold for the
77"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.0849740932642487,"membrane potential. Note that I(t) is simplified as weighted input WX(t) which can be obtained
78"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.08601036269430051,"through any operations with learnable weights including convolutional operation, self-attention, or a
79"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.08704663212435233,"simple MLP. We will denote this process of forwarding through LIF neuron as SNN(·) in this paper.
80"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.08808290155440414,"Direct SNN Training.
The initial adoption of SNNs was through ANN-SNN conversion, primarily
81"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.08911917098445596,"due to their remarkable potential for reducing energy consumption. Various studies have aimed to
82"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.09015544041450778,"address the accuracy degradation that occurs during the conversion from ANNS to SNNs [22, 41, 24,
83"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.09119170984455958,"42].
84"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.0922279792746114,"The spike generation by the step function in Equation (4) interfered with direct training without
85"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.09326424870466321,"modifying the functions. To bypass the step function, which is non-differentiable and thus unsuitable
86"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.09430051813471503,"for backpropagation, several approaches have been proposed [43, 5, 13, 14, 8, 51, 10]. Recent
87"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.09533678756476684,"research has demonstrated that directly training SNNs can yield competitive results by addressing
88"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.09637305699481866,"the challenges posed by non-differentiability. Our work focuses on directly training graph neural
89"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.09740932642487046,"networks (GNNs) with SNNs and exploring a different domain, such as ANN-SNN conversion
90"
SPIKING NEURAL NETWORKS AND SPIKE TRAINING,0.09844559585492228,"methods, which do not focus on using backpropagation concepts directly.
91"
GRAPH NEURAL NETWORKS,0.09948186528497409,"2.2
Graph Neural Networks
92"
GRAPH NEURAL NETWORKS,0.10051813471502591,"Graph neural networks (GNNs) take graph-represented data as input, which consist of nodes and
93"
GRAPH NEURAL NETWORKS,0.10155440414507771,"their connected edges G = (V, E), with node features X ∈R|V |×F and optionally edge features
94"
GRAPH NEURAL NETWORKS,0.10259067357512953,"E ∈R|E|×D. The common GNN architectures follow a message passing paradigm [20], which
95"
GRAPH NEURAL NETWORKS,0.10362694300518134,"learns node or edge representations through aggregating information from its neighboring nodes
96"
GRAPH NEURAL NETWORKS,0.10466321243523316,"and updating the node features iteratively. Thus a single forward of message passing layer consists
97"
GRAPH NEURAL NETWORKS,0.10569948186528498,"of message passing, aggregation, and update: h(l+1)
i
= ϕ(h(l)
i , L"
GRAPH NEURAL NETWORKS,0.10673575129533679,"j∈N(i) ψ(h(l)
i , h(l)
j , eij)), where
98"
GRAPH NEURAL NETWORKS,0.1077720207253886,"l and i are indices for layer and node, respectively, and ψ(·) denote message passing function.
99"
GRAPH NEURAL NETWORKS,0.10880829015544041,"After aggregation of neighboring features, ϕ(·) is used for feature update. For graph convolutional
100"
GRAPH NEURAL NETWORKS,0.10984455958549223,"network [27], the overall process can be simplified as:
101"
GRAPH NEURAL NETWORKS,0.11088082901554404,"X(l+1) = AX(l)W (l),
(5)"
GRAPH NEURAL NETWORKS,0.11191709844559586,"where the feature matrix is a concatenation of node features X(l) = [h(l)
0 ||h(l)
1 ||...||h(l)
(|V |−1)]T which
102"
GRAPH NEURAL NETWORKS,0.11295336787564766,"is updated through iterations of aggregation (AX) and combination (XW). After iterative updates of
103"
GRAPH NEURAL NETWORKS,0.11398963730569948,"X through the layers, the learned node or edge embeddings are passed through additional classification
104"
GRAPH NEURAL NETWORKS,0.11502590673575129,"layer for node-level or edge-level predictions.
105"
GRAPH NEURAL NETWORKS,0.11606217616580311,"Graph Classification
In this paper we put emphasis on graph-level classification tasks where each
106"
GRAPH NEURAL NETWORKS,0.11709844559585492,"graph is considered an individual input. Graph classification follows the same node-wise message
107"
GRAPH NEURAL NETWORKS,0.11813471502590674,"passing framework to obtain node embeddings, but appends a readout layer to turn them into a single
108"
GRAPH NEURAL NETWORKS,0.11917098445595854,"graph embedding:
109"
GRAPH NEURAL NETWORKS,0.12020725388601036,"hG = R(h(L)
i
|Vi ∈G),
(6)
where R denotes readout function. Readout function reduces the node dimension to a single channel
110"
GRAPH NEURAL NETWORKS,0.12124352331606218,"regardless of the input size. This is due to the inductive nature of graph classification task where
111"
GRAPH NEURAL NETWORKS,0.12227979274611399,"the number of nodes is not known in advance. While all the other GNN layers focus on aggregating
112"
GRAPH NEURAL NETWORKS,0.12331606217616581,"only the local features, the readout layer considers the entire graph to generate global features,
113"
GRAPH NEURAL NETWORKS,0.12435233160621761,"and is unique to the graph classification tasks. The obtained graph embedding is passed through a
114"
GRAPH NEURAL NETWORKS,0.12538860103626942,"classification layer for graph predictions. Graph classification tasks usually hold more difficulty than
115"
GRAPH NEURAL NETWORKS,0.12642487046632125,"node-level classification due to its inductive nature, where inference is done on unseen graphs and
116"
GRAPH NEURAL NETWORKS,0.12746113989637306,"thus cannot utilize any graph-specific statistics from the train set.
117"
SPIKING GRAPH NEURAL NETWORKS,0.12849740932642487,"2.3
Spiking Graph Neural Networks
118"
SPIKING GRAPH NEURAL NETWORKS,0.12953367875647667,"In this paper, we adopt conventional SNN designs where LIF neurons are connected through learn-
119"
SPIKING GRAPH NEURAL NETWORKS,0.1305699481865285,"abled weights, and apply is to GNN framework [64]. As mentioned in Section 2.2, each GNN layer
120"
SPIKING GRAPH NEURAL NETWORKS,0.1316062176165803,"outputs updated feature matrix X(l+1) ∈R|V |×F . This is converted to spike representation through
121"
SPIKING GRAPH NEURAL NETWORKS,0.13264248704663212,"SNN layer:
122"
SPIKING GRAPH NEURAL NETWORKS,0.13367875647668392,"X(l+1) = SNN(AX(l)W (l)).
(7)"
SPIKING GRAPH NEURAL NETWORKS,0.13471502590673576,"After passing the GNN layer, all of the updated h(l)
i
directly pass through the SNN layer, consist the
123"
SPIKING GRAPH NEURAL NETWORKS,0.13575129533678756,"feature matrix X(l) always contains spike information consistently.
124"
SPIKING GRAPH NEURAL NETWORKS,0.13678756476683937,"(a) Histogram plotting distribution of total spikes counted over time for each node. X-axis denotes spike counts
from each node, while y-axis denotes density of each bin. max min max min max min 3 2 1"
SPIKING GRAPH NEURAL NETWORKS,0.1378238341968912,"(b) Spike frequency visualization using each layer output. X-axis denotes feature dimension, while y-axis
denotes nodes grouped and sorted by degree in descending order, top to bottom. Brighter spots denote higher
frequency."
SPIKING GRAPH NEURAL NETWORKS,0.138860103626943,Figure 1: Analysis on spike frequency variation of GCN using IMDB-BINARY [54] dataset.
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.13989637305699482,"3
Analysis on Spike Frequency Variation of GNNs
125"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.14093264248704662,"To analyze the cause of the accuracy drop, we plot the behavior of the neurons during inference in
126"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.14196891191709846,"Figure 1a, on a IMDB-BINARY dataset over five timesteps (T = 5). We create a histogram of spike
127"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.14300518134715026,"counts created from each node, which is associated with 128 neurons. As depicted in the plot, it is
128"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.14404145077720207,"clear that most of the neurons are under starvation. This is caused by the inputs of those neurons
129"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.14507772020725387,"being insufficient to reach the threshold, and this leads to severe information loss between the layers.
130"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.1461139896373057,"While unveiling the exact dynamics would require more research, we hypothesize that this is caused
131"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.14715025906735751,"by the topology of the real-world graphs.
132"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.14818652849740932,"To validate the hypothesis and further investigate the phenomena, we display the spike frequency
133"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.14922279792746113,"heatmap of the neurons sorted by the degree of the nodes in Figure 1b. From the heatmap, we make
134"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.15025906735751296,"three observations:
135"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.15129533678756477,"1 (Brighter on the top and darker at the bottom) High-degree nodes tend to exhibit higher spike
136"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.15233160621761657,"frequencies.
137"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.1533678756476684,"2 (The horizontal strips) The spike frequencies are associated with the corresponding nodes.
138"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.1544041450777202,"3 (The vertical strips) The feature neurons within a node behave differently according to their
139"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.15544041450777202,"positions.
140"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.15647668393782382,"We believe such patterns come from the connectivity of the nodes, and the distinct role of the neurons
141"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.15751295336787566,"assigned to each node. The connectivity will affect the number of receiving spikes of neurons
142"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.15854922279792746,"associated with each node. It is known that most of the real-world graphs exhibit an extremely skewed
143"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.15958549222797927,"distribution of degrees (i.e., power-law distribution [30]). Due to such a characteristic, there are a few
144"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.16062176165803108,"nodes with very high degrees, while a majority of nodes have low degrees. Because a GNN layer
145"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.1616580310880829,"communicates signals between the neighbors, a high-degree node will likely receive a lot of spikes,
146"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.16269430051813472,"while a low-degree node will receive only a few.
147 t"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.16373056994818652,Input Graphs ⊕
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.16476683937823836,Classification
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.16580310880829016,"Poisson 
Encoder"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.16683937823834197,GNN Layer
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.16787564766839377,"Topology-Aware  
Group-Adaptive Neurons F"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.1689119170984456,Readout Layer c
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.1699481865284974,Classification Head F t = 1
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.17098445595854922,SNN Layer t = T
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.17202072538860103,GNN Layer
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.17305699481865286,"N layers
×"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.17409326424870467,"Poisson 
Encoder"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.17512953367875647,GNN Layer
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.17616580310880828,"Topology-Aware  
Group-Adaptive Neurons F"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.1772020725388601,Readout Layer c
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.17823834196891192,Classification Head F
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.17927461139896372,"SNN Layer
GNN Layer"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.18031088082901556,"N layers
×"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.18134715025906736,Figure 2: Overall graph classification architecture with proposed methods.
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.18238341968911917,"In addition, the neurons assigned to each node are known to have different semantic functionality
148"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.18341968911917098,"according to their positions, analogous to channels in convolutional neural networks or heads in
149"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.1844559585492228,"large language models. For example, the input first layer of a molecular graph will have information
150"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.18549222797927462,"such as its energy, x/y/z location, and atom numbers. In the intermediate layers, they represent a
151"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.18652849740932642,"specific pattern sensed by the network (such as high energy + hydrogen atom), even though the exact
152"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.18756476683937823,"behaviors are yet to be human-interpretable. In such a manner, the neurons in the same position are
153"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.18860103626943006,"expected to behave similarly, even though they correspond to different nodes.
154"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.18963730569948187,"These three observations shed light on how to close the performance gap between spiking GNNs are
155"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.19067357512953367,"ANN-based GNNs. In the next section, we describe how the observations are used to build better
156"
ANALYSIS ON SPIKE FREQUENCY VARIATION OF GNNS,0.19170984455958548,"spiking GNNs for graph classification.
157"
PROPOSED METHOD,0.1927461139896373,"4
Proposed Method
158"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.19378238341968912,"4.1
Overall Graph Classification Architecture
159"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.19481865284974093,"Many recent studies have tried to adapt SNN architectures into GNN tasks, however, they simply
160"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.19585492227979276,"try to contact with only node classification tasks. In this work, we propose a spiking neural network
161"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.19689119170984457,"specifically designed for graph classification tasks and show that it can be trained using spikes. We
162"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.19792746113989637,"demonstrate the overall architecture of our graph classification model TAS-GNN in Figure 2. For each
163"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.19896373056994818,"timestep, the input graphs are first translated into spike representations through the poisson encoder,
164"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.2,"then the message passing is done in spike format. After the combination phase in the GNN layer, the
165"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.20103626943005182,"node features are once again binarized into spike format through passing the SNN layer. In the last
166"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.20207253886010362,"layer, we perform an extra operation of aggregation and combination on the spike features before
167"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.20310880829015543,"passing the readout layer. The readout layer is essential to graph classification and is responsible for
168"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.20414507772020726,"aggregating all the node embeddings in the graph into a single graph representation. A batch of graph
169"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.20518134715025907,"embeddings is passed through a classification head that outputs logits for that timestep. To make the
170"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.20621761658031088,"final prediction, we simply take the sum of logits from all timesteps and use softmax to obtain the
171"
OVERALL GRAPH CLASSIFICATION ARCHITECTURE,0.20725388601036268,"class probabilities.
172"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.20829015544041452,"4.2
Topology-Aware Group-Adaptive Neurons
173"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.20932642487046632,"As discussed in Section 3, GNNs suffer from a huge gap in spike frequencies between neurons. As
174"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.21036269430051813,"observed, there exist some patterns (Figure 5) that we can utilize to address the issue. One naive
175"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.21139896373056996,"way of addressing the issue is to use learnable [49], or adaptive [4] threshold for each neuron. By
176"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.21243523316062177,"adjusting the threshold, one can expect the neurons to naturally change, such that neurons under
177"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.21347150259067357,"starvation will have lower thresholds to fire more often, and a few neurons with high firing rates will
178"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.21450777202072538,"have higher thresholds to shift toward an ideal distribution.
179"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.2155440414507772,"Unfortunately, such an idea cannot be directly applied unless all the testset nodes are available at
180"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.21658031088082902,"training time (i.e., transductive task). However, such a setting would be considered a data leak for
181"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.21761658031088082,"graph classification, and would also lose the advantage SNNs have on lightweight inference.
182"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.21865284974093263,"Moreover, the number of nodes in a real-world dataset often ranges from at least thousands to several
183"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.21968911917098446,"billions. Considering that GNNs often involve only a sub-million number of learnable parameters,
184"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.22072538860103627,"storing such a large number of thresholds is considered too much overhead.
185"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.22176165803108808,"To address the aforementioned issues, we propose topology-aware group adaptive neurons (TAG),
186"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.22279792746113988,"which partitions the neurons by their degrees. Note that Vg denotes the node group to which the
187"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.22383419689119172,"node is mapped, considering degree information. Sgi(t) and V gi(t) represent the output spike and
188"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.22487046632124352,"membrane potential of the i-th node in group g at time t, respectively, as reformulated by Equation (4).
189"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.22590673575129533,"We use g to represent the unique degree distribution of the training sets. When an unseen node is
190"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.22694300518134716,"encountered, we apply the initial threshold, as it has not been trained at all.
191"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.22797927461139897,"Sgi(t) =
1,
if V gi(t) ≥V g
th(t −1)
0,
otherwise
(8)"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.22901554404145077,"Sg(t) =
1
|Vg| X"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.23005181347150258,"i∈Vg
Sgi(t)
(9)"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.23108808290155441,"V g
th(t) = γV g
th(t −1) + (1 −γ)Sg(t)
(10)"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.23212435233160622,"The major advantage of this scheme is that it is straightforward to put an unseen node or an unseen
192"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.23316062176165803,"graph into a group at inference. To further consider intra-node deviation, we split the group into
193"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.23419689119170983,"F (number of features) neurons, which is a fixed parameter determined by the model architecture.
194"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.23523316062176167,"For any unseen node, finding out its degree is trivial because visiting its neighbors is one of the
195"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.23626943005181347,"fundamental requirements of graph data structures [26, 50, 36, 28]. Based on the observation 1
196"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.23730569948186528,"from Section 3 that the neuron behavior is related to the degree, this will let neurons in the group
197"
TOPOLOGY-AWARE GROUP-ADAPTIVE NEURONS,0.23834196891191708,"collaboratively find an adequate threshold.
198"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.23937823834196892,"4.3
Reducing the Initial Threshold Sensitivity
199"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.24041450777202072,"Figure 3: Sensitivity of neurons to its
initial threshold."
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.24145077720207253,"The proposed Group-adaptive threshold scheme effec-
200"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.24248704663212436,"tively reduces the spike frequency variation issue. How-
201"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.24352331606217617,"ever, we find that the adaptive neurons in the proposed
202"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.24455958549222798,"TAG are sensitive to their initial thresholds. As depicted
203"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.24559585492227978,"in Figure 3, the performance of the adaptive neurons can
204"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.24663212435233162,"severely drop when the initial threshold value is not care-
205"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.24766839378238342,"fully tuned, which aligns with the findings from [4]. More-
206"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.24870466321243523,"over, manually tuning the initial thresholds individually is
207"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.24974093264248703,"difficult because there are thousands of neuron groups.
208"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.25077720207253884,"To address the problem, we choose to learn the two pa-
209"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.25181347150259065,"rameters: the initial threshold per group (V g
th(0)) and the
210"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.2528497409326425,"decay rate (β). During training, we adopted the backprop-
211"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.2538860103626943,"agation algorithm [51, 10, 8] to update the value of V g
th(0)
212"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.2549222797927461,"with the gradients at time step t=1. This is done because V g
th(t) keeps updating with TAG Section 4.2
213"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.2559585492227979,"as time passes. During training, we also learn the decay rate (β) [16], which prevents the membrane
214"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.25699481865284973,"voltage of neurons in low-degree nodes from leaking faster than it accumulates. For evaluation, we
215"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.25803108808290154,"use the V g
th(0) values obtained during the training phase, adjusted for each group. The overall training
216"
REDUCING THE INITIAL THRESHOLD SENSITIVITY,0.25906735751295334,"procedure is in the Appendix.
217"
EVALUATION,0.2601036269430052,"5
Evaluation
218"
EXPERIMENT SETTINGS,0.261139896373057,"5.1
Experiment Settings
219"
EXPERIMENT SETTINGS,0.2621761658031088,"We use a total of 5 graph datasets commonly used for benchmarking GNNs: MUTAG [9], PRO-
220"
EXPERIMENT SETTINGS,0.2632124352331606,"TEINS [6], ENZYMES [6], NCI1 [47], and IMDB-Binary [54]. For the GNN layer in our architecture,
221"
EXPERIMENT SETTINGS,0.26424870466321243,"we use 3 different designs, including GCN [27], GAT [45], and GIN [52]. The baselines include
222"
EXPERIMENT SETTINGS,0.26528497409326424,"3 works from SNN that are applicable to graph datasets: SpikingGNN [64], SpikeNet [32], and
223"
EXPERIMENT SETTINGS,0.26632124352331604,Table 1: Performance comparison against baseline methods.
EXPERIMENT SETTINGS,0.26735751295336785,"Model
Method
MUTAG
PROTEINS
ENZYMES
NCI1
IMDB-BINARY GCN"
EXPERIMENT SETTINGS,0.2683937823834197,"ANN [27]
88.86 ± 5.48
77.81 ± 3.46
72.00 ± 4.37
76.42 ± 2.98
56.80 ± 4.80
SpikingGNN [64]
90.96 ± 3.99
74.39 ± 2.68
50.67 ± 4.91
73.41 ± 1.60
68.40 ± 2.96
SpikeNet [32]
87.81 ± 5.60
74.75 ± 3.20
50.00 ± 3.33
73.92 ± 1.54
70.30 ± 2.17
PGNN [16]
87.28 ± 5.87
77.36 ± 2.68
56.33 ± 3.17
76.52 ± 1.46
71.60 ± 2.17
TAS-GNN
96.32 ± 3.10 (+5.35)
77.45 ± 1.94 (+0.09)
56.50 ± 3.87 (+0.17)
77.81 ± 1.28 (+1.29)
80.10 ± 2.49 (+8.50) GAT"
EXPERIMENT SETTINGS,0.2694300518134715,"ANN [45]
83.04 ± 4.23
77.54 ± 3.22
59.67 ± 3.48
67.88 ± 3.00
54.50 ± 2.14
SpikingGNN [64]
78.71 ± 5.34
59.66 ± 0.21
29.17 ± 3.14
66.25 ± 1.77
50.00 ± 0.00
SpikeNet [32]
78.22 ± 3.67
64.60 ± 3.22
51.67 ± 4.96
66.84 ± 1.60
50.00 ± 0.00
PGNN [16]
82.49 ± 4.98
64.06 ± 2.37
39.50 ± 2.87
68.32 ± 1.49
50.00 ± 0.00
TAS-GNN
96.32 ± 3.10 (+13.83)
71.34 ± 3.03 (+6.74)
52.33 ± 3.47 (+0.67)
75.33 ± 2.41 (+7.01)
77.90 ± 2.18 (+27.90) GIN"
EXPERIMENT SETTINGS,0.2704663212435233,"ANN [52]
95.23 ± 5.61
78.79 ± 3.74
33.67 ± 4.66
79.17 ± 3.07
70.40 ± 4.14
SpikingGNN [64]
92.60 ± 4.41
77.81 ± 2.71
45.17 ± 5.01
70.29 ± 2.01
74.30 ± 1.47
SpikeNet [32]
93.66 ± 4.62
78.43 ± 2.63
44.33 ± 3.98
74.77 ± 1.63
74.80 ± 2.74
PGNN [16]
94.18 ± 4.84
79.16 ± 2.61
43.33 ± 5.45
75.38 ± 1.41
72.80 ± 4.63
TAS-GNN
95.76 ± 3.47 (+1.58)
80.32 ± 2.42 (+1.17)
48.00 ± 4.01 (+2.83)
77.52 ± 1.49 (+2.14)
73.70 ± 3.11 (-1.10)"
EXPERIMENT SETTINGS,0.27150259067357513,†Did not converge
EXPERIMENT SETTINGS,0.27253886010362693,Table 2: Ablation study on the proposed method
EXPERIMENT SETTINGS,0.27357512953367874,"Model
Method
MUTAG
PROTEINS
ENZYMES
NCI1
IMDB-BINARY"
EXPERIMENT SETTINGS,0.27461139896373055,"GCN
Baseline
90.96
74.39
50.67
73.41
68.40
+ TAG
93.66 (+2.69)
75.65 (+1.26)
49.00 (-1.67)
73.65 (+0.24)
71.90 (+3.50)
TAS-GNN (Proposed)
96.32 (+5.35)
77.45 (+3.06)
56.50 (+5.83)
77.81 (+4.40)
80.10 (+11.70)"
EXPERIMENT SETTINGS,0.2756476683937824,"GAT
Baseline
78.71
59.66
29.17
66.25
50.00
+ TAG
80.35 (+1.64)
66.48 (+6.82)
51.83 (+22.67)
67.98 (+1.73)
50.00 (+0.00)
TAS-GNN (Proposed)
96.32 (+17.60)
71.34 (+11.68)
52.33 (+23.16)
75.33 (+9.08)
77.90 (+27.90)"
EXPERIMENT SETTINGS,0.2766839378238342,"GIN
Baseline
92.60
77.81
45.17
70.29
74.30
+ TAG
93.66 (+1.05)
78.35 (+0.53)
46.16 (+0.99)
73.67 (+3.38)
75.20 (+0.90)
TAS-GNN (Proposed)
95.76 (+3.16)
80.32 (+2.51)
48.00 (+2.83)
77.52 (+7.23)
73.70 (-0.60)"
EXPERIMENT SETTINGS,0.277720207253886,"PGNN [16]. Since this is the first SNN design to target graph classification, we apply minor modi-
224"
EXPERIMENT SETTINGS,0.2787564766839378,"fications to each architecture, such as appending a readout layer. Note that SpikingGNN [64] was
225"
EXPERIMENT SETTINGS,0.27979274611398963,"originally proposed for GCN, but we extend it to both GAT and GIN. More details on the experiment
226"
EXPERIMENT SETTINGS,0.28082901554404144,"setting are included in the Appendix.
227"
RESULTS ON GRAPH CLASSIFICATION,0.28186528497409324,"5.2
Results on Graph Classification
228"
RESULTS ON GRAPH CLASSIFICATION,0.28290155440414505,"We compare TAS-GNN against prior works that adopt a spiking neural network to graph the dataset,
229"
RESULTS ON GRAPH CLASSIFICATION,0.2839378238341969,"shown in Table 1. We also report the performance of conventional ANN for comparison. In all but 2
230"
RESULTS ON GRAPH CLASSIFICATION,0.2849740932642487,"cases, TAS-GNN outperforms the baselines by a noticeable margin. In the cases where TAS-GNN
231"
RESULTS ON GRAPH CLASSIFICATION,0.2860103626943005,"underperforms, the gaps are less than 1.1%p, smaller than the error bounds. In the opposite cases, the
232"
RESULTS ON GRAPH CLASSIFICATION,0.28704663212435233,"improvement is up to 27.90%p, showing a great amount of improvement.
233"
RESULTS ON GRAPH CLASSIFICATION,0.28808290155440414,"An intriguing result is that TAS-GNN performs better than ANN-based GNNs in several cases.
234"
RESULTS ON GRAPH CLASSIFICATION,0.28911917098445594,"Improvements beyond the error bounds are found in MUTAG (GCN and GAT), NCI1 (GAT), and
235"
RESULTS ON GRAPH CLASSIFICATION,0.29015544041450775,"IMDB-BINARY (GCN and GAT). Note that the model architecture and the number of learnable
236"
RESULTS ON GRAPH CLASSIFICATION,0.2911917098445596,"parameters are the same in all methods. We believe this could come from the spiking neurons
237"
RESULTS ON GRAPH CLASSIFICATION,0.2922279792746114,"efficiently capturing the irregular connections over several timesteps, thereby showing an advantage
238"
RESULTS ON GRAPH CLASSIFICATION,0.2932642487046632,"over ANNs.
239"
ABLATION STUDY,0.29430051813471503,"5.3
Ablation Study
240"
ABLATION STUDY,0.29533678756476683,"In this section, we break down individual components of TAS-GNN and perform an ablation study,
241"
ABLATION STUDY,0.29637305699481864,"which is reported in Table 2. Starting from baseline implementation, which does not differentiate
242"
ABLATION STUDY,0.29740932642487045,"neurons used by each node, we apply TAG to show the effect of topology-aware group-adaptive
243"
ABLATION STUDY,0.29844559585492225,"neurons. Then, we add our learnable initial threshold scheme to complete TAS-GNN. The results
244"
ABLATION STUDY,0.2994818652849741,"show that TAG alone can improve the performance across all datasets and models. This means that
245"
ABLATION STUDY,0.3005181347150259,"uneven spike distribution caused by indegree variance is a general problem shared across different
246"
ABLATION STUDY,0.3015544041450777,"graph datasets, and simply grouping the nodes with similar indegree to share the same threshold helps
247"
ABLATION STUDY,0.30259067357512953,"alleviate this problem. Lastly, adding a learnable initial threshold scheme further boosts the accuracy
248"
ABLATION STUDY,0.30362694300518134,"in almost all cases, demonstrating its efficacy and stability.
249"
ABLATION STUDY,0.30466321243523314,"Model
Method
Vinit
0.50
1.50
2.50
5.00
7.00
10.00"
ABLATION STUDY,0.30569948186528495,"GCN
TAG
87.84
86.75
88.33
89.91
88.30
68.16
Ours
95.79
97.37
96.32
95.79
95.23
90.99"
ABLATION STUDY,0.3067357512953368,"GAT
TAG
85.70
81.96
80.35
80.85
77.72
77.19
Ours
94.18
93.65
96.32
93.68
91.58
92.60"
ABLATION STUDY,0.3077720207253886,"GIN
TAG
92.08
93.13
92.57
94.21
92.08
93.68
Ours
94.18
94.74
95.76
93.68
94.71
89.94"
ABLATION STUDY,0.3088082901554404,Figure 4: Sensitivity study of neurons to its initial threshold.
SENSITIVITY STUDY,0.30984455958549223,"5.4
Sensitivity Study
250"
SENSITIVITY STUDY,0.31088082901554404,"Table 3: Sensitivity study on threshold learning
rate using MUTAG. η"
SENSITIVITY STUDY,0.31191709844559584,"Model
0.001
0.005
0.01
0.05
0.1
0.5"
SENSITIVITY STUDY,0.31295336787564765,"GCN
93.68
96.84
96.32
96.84
96.84
84.15
GAT
86.78
94.18
96.32
94.18
94.71
92.05
GIN
89.97
95.26
95.76
93.16
93.13
91.02"
SENSITIVITY STUDY,0.3139896373056995,"To validate our method’s efficacy in alleviat-
251"
SENSITIVITY STUDY,0.3150259067357513,"ing the sensitivity of the initial threshold value,
252"
SENSITIVITY STUDY,0.3160621761658031,"we perform a sensitivity study varying the val-
253"
SENSITIVITY STUDY,0.3170984455958549,"ues from 0.0 to 10.0. We compare our scheme
254"
SENSITIVITY STUDY,0.31813471502590673,"against the TAG method, which also adaptively
255"
SENSITIVITY STUDY,0.31917098445595854,"modulates the threshold during inference but
256"
SENSITIVITY STUDY,0.32020725388601035,"does not learn it from training. Our method
257"
SENSITIVITY STUDY,0.32124352331606215,"consistently performs indifferently to the initial
258"
SENSITIVITY STUDY,0.322279792746114,"threshold value, which means arduous search or
259"
SENSITIVITY STUDY,0.3233160621761658,"tuning is unnecessary to achieve stable accuracy.
260"
SENSITIVITY STUDY,0.3243523316062176,"On the other hand, TAG is highly sensitive to the initial threshold and shows a performance gap up to
261"
SENSITIVITY STUDY,0.32538860103626943,"19.68%p except for GIN architecture, which is capturing structure well.
262"
SENSITIVITY STUDY,0.32642487046632124,"Since our scheme uses a learnable initial threshold, we also study its sensitivity for the learning rate,
263"
SENSITIVITY STUDY,0.32746113989637304,"shown in Table 3. TAS-GNN performs best around η = [0.005, 0.1], and starts to degrade for further
264"
SENSITIVITY STUDY,0.32849740932642485,"increment or decrement. As denoted in the experimental setting, we use η = 0.01 as the default.
265"
ADDITIONAL ANALYSIS,0.3295336787564767,"5.5
Additional Analysis
266"
ADDITIONAL ANALYSIS,0.3305699481865285,"In this section, we give additional analysis on TAS-GNN by studying its spike frequency distribution.
267"
ADDITIONAL ANALYSIS,0.3316062176165803,"In Figure 5, we provide the same spike frequency visualization as done in Section 3, but using
268"
ADDITIONAL ANALYSIS,0.33264248704663213,"TAS-GNN. Unlike Figure 1, which showed severe starvation with most nodes not generating spikes,
269"
ADDITIONAL ANALYSIS,0.33367875647668394,"Figure 5a reveals that most nodes fire spikes, significantly alleviating the starvation problem. This
270"
ADDITIONAL ANALYSIS,0.33471502590673574,"is further illustrated Figure 5b, where most neurons have non-zero spike values and, what’s more,
271"
ADDITIONAL ANALYSIS,0.33575129533678755,"meaningfully reflect the topology of the graph. For nodes with higher degrees, the spikes are more
272"
ADDITIONAL ANALYSIS,0.33678756476683935,"frequent (close to 5) due to having more incoming spikes from their neighbors. For GNNs, such
273"
ADDITIONAL ANALYSIS,0.3378238341968912,"information is essential to capture the global topology of the graph. This shows that our design of
274"
ADDITIONAL ANALYSIS,0.338860103626943,"TAS-GNN faithfully reflects such information and can successfully propagate such information using
275"
ADDITIONAL ANALYSIS,0.3398963730569948,"spikes.
276"
RELATED WORKS,0.34093264248704663,"6
Related Works
277"
RELATED WORKS,0.34196891191709844,"Graph Classification
Graph classification requires identifying the global characteristics of each
278"
RELATED WORKS,0.34300518134715025,"graph and is commonly applied to domains such as bioinformatics [6], chemoinformatics [63], or
279"
RELATED WORKS,0.34404145077720205,"social network analysis [21, 37]. Popular examples include the molecular classification of chemical
280"
RELATED WORKS,0.3450777202072539,"compounds, proteins, or RNAs, where identifying the graph structural information is crucial. Due
281"
RELATED WORKS,0.3461139896373057,"to the success of GNNs, [27, 45, 52, 57] Most GNNs use a message passing paradigm [20] that
282"
RELATED WORKS,0.3471502590673575,"only aggregates local features. Thus, to obtain global features representing the entire graph, graph
283"
RELATED WORKS,0.34818652849740933,"pooling [56] is often used. Global pooling summarizes the entire graph into a fixed-size graph
284"
RELATED WORKS,0.34922279792746114,"embedding, which can be done by simply averaging or taking minimum or maximum values of the
285"
RELATED WORKS,0.35025906735751294,"node-wise embeddings. Other variations replace such simple operations with neural networks [46,
286"
RELATED WORKS,0.35129533678756475,"33] or integrate sorting to selectively choose which node embeddings to include [60]. More advanced
287"
RELATED WORKS,0.35233160621761656,"techniques such as hiearchical pooling utilze hiearchical information of graphs [40, 29, 18, 11] and
288"
RELATED WORKS,0.3533678756476684,"usually show better representation learning. [60]
289"
RELATED WORKS,0.3544041450777202,"(a) Histogram plotting the distribution of total spikes counted over time for each node. X-axis denotes spike
counts from each node, while y-axis denotes density of each bin. max min max min max min"
RELATED WORKS,0.35544041450777203,"(b) Spike frequency visualization on TAS-GNN using each layer output. X-axis denotes feature dimension,
while y-axis denotes nodes grouped and sorted by degree in descending order, top to bottom. Brighter spots
denote higher frequency."
RELATED WORKS,0.35647668393782384,Figure 5: Analysis on spike frequency variation of GCN using IMDB-BINARY [54] dataset.
RELATED WORKS,0.35751295336787564,"Spiking Neural Networks
SNNs are a type of neural network where information is transmitted
290"
RELATED WORKS,0.35854922279792745,"using spikes, similar to how biological neurons work. They use different neuron models for capturing
291"
RELATED WORKS,0.35958549222797925,"spike signals effectively [23, 24] or adjusting parameters dynamically to compromise the accuracy
292"
RELATED WORKS,0.3606217616580311,"[16, 49, 4, 34]. One major area of SNN research is converting traditional ANNs into SNNs by
293"
RELATED WORKS,0.3616580310880829,"mapping ANN activation functions into spike signals [22, 41, 24, 42, 17]. Another focus is training
294"
RELATED WORKS,0.3626943005181347,"SNNs directly using backpropagation, similar to ANNs, which involves using various techniques
295"
RELATED WORKS,0.36373056994818653,"such as surrogate functions for backpropagation [43, 8] and adapting normalization techniques to
296"
RELATED WORKS,0.36476683937823834,"SNNs [42, 12, 25, 62].
297"
RELATED WORKS,0.36580310880829014,"SNN for Graphs
Previous attempts to apply SNNs to graph datasets have primarily focused on
298"
RELATED WORKS,0.36683937823834195,"node-level classification tasks [59, 44, 64] and have not yet been extended to graph-level tasks. While
299"
RELATED WORKS,0.36787564766839376,"[48] explored the application of spike training to Graph Attention Networks (GAT), it implemented the
300"
RELATED WORKS,0.3689119170984456,"message passing phase after the spiking phase, which deviates from previous structures. Additionally,
301"
RELATED WORKS,0.3699481865284974,"recent efforts have begun to integrate SNNs with other techniques for contrastive learning [31],
302"
RELATED WORKS,0.37098445595854923,"particularly in dynamic graphs [55], to adopt collaboration between GNNs and SNNs.
303"
CONCLUSION,0.37202072538860104,"7
Conclusion
304"
CONCLUSION,0.37305699481865284,"In this paper, we explore the application of SNNs to graph neural networks for graph classification
305"
CONCLUSION,0.37409326424870465,"for the first time. After thoroughly analyzing the graph’s uneven spike distribution, we identify that
306"
CONCLUSION,0.37512953367875645,"the degree of each node correlates to this phenomenon. To better accommodate such characteristics
307"
CONCLUSION,0.3761658031088083,"of graphs, we propose topology-aware group-adaptive neurons, which uses separate neurons for each
308"
CONCLUSION,0.3772020725388601,"degree group in the graph. In addition, we propose to learn the initial threshold and adaptively adjust
309"
CONCLUSION,0.37823834196891193,"the threshold simultaneously to reduce its sensitivity and facilitate training using spikes. Combined
310"
CONCLUSION,0.37927461139896373,"with the modified architecture for graph classification, we name our method TAS-GNN, and show
311"
CONCLUSION,0.38031088082901554,"that it outperforms existing works by a noticeable margin.
312"
REFERENCES,0.38134715025906735,"References
313"
REFERENCES,0.38238341968911915,"[1]
James B. Aimone et al. “Provable Advantages for Graph Algorithms in Spiking Neural
314"
REFERENCES,0.38341968911917096,"Networks”. In: SPAA ’21. Virtual Event, USA: Association for Computing Machinery, 2021,
315"
REFERENCES,0.3844559585492228,"pp. 35–47. ISBN: 9781450380706. DOI: 10.1145/3409964.3461813. URL: https://doi.
316"
REFERENCES,0.3854922279792746,"org/10.1145/3409964.3461813.
317"
REFERENCES,0.38652849740932643,"[2]
Marco Arazzi et al. “Predicting tweet engagement with graph neural networks”. In: Proceedings
318"
REFERENCES,0.38756476683937824,"of the 2023 ACM International Conference on Multimedia Retrieval. 2023, pp. 172–180.
319"
REFERENCES,0.38860103626943004,"[3]
Lei Bai et al. “Adaptive graph convolutional recurrent network for traffic forecasting”. In:
320"
REFERENCES,0.38963730569948185,"Advances in neural information processing systems 33 (2020), pp. 17804–17815.
321"
REFERENCES,0.39067357512953366,"[4]
Guillaume Bellec et al. “Long short-term memory and learning-to-learn in networks of spiking
322"
REFERENCES,0.3917098445595855,"neurons”. In: Advances in neural information processing systems 31 (2018).
323"
REFERENCES,0.3927461139896373,"[5]
Sander M Bohte, Joost N Kok, and Han La Poutre. “Error-backpropagation in temporally
324"
REFERENCES,0.39378238341968913,"encoded networks of spiking neurons”. In: Neurocomputing 48.1-4 (2002), pp. 17–37.
325"
REFERENCES,0.39481865284974094,"[6]
Karsten M Borgwardt et al. “Protein function prediction via graph kernels”. In: Bioinformatics
326"
REFERENCES,0.39585492227979274,"21.suppl_1 (2005), pp. i47–i56.
327"
REFERENCES,0.39689119170984455,"[7]
Defu Cao et al. “Spectral temporal graph neural network for multivariate time-series forecast-
328"
REFERENCES,0.39792746113989635,"ing”. In: Advances in neural information processing systems 33 (2020), pp. 17766–17778.
329"
REFERENCES,0.39896373056994816,"[8]
Kaiwei Che et al. “Differentiable hierarchical and surrogate gradient search for spik-
330"
REFERENCES,0.4,"ing neural networks”. In: Advances in Neural Information Processing Systems. Ed.
331"
REFERENCES,0.40103626943005183,"by S. Koyejo et al. Vol. 35. Curran Associates, Inc., 2022, pp. 24975–24990. URL:
332"
REFERENCES,0.40207253886010363,"https : / / proceedings . neurips . cc / paper _ files / paper / 2022 / file /
333"
REFERENCES,0.40310880829015544,"9e8c2895db691eaab85af37bddee75aa-Paper-Conference.pdf.
334"
REFERENCES,0.40414507772020725,"[9]
Asim Kumar Debnath et al. “Structure-activity relationship of mutagenic aromatic and het-
335"
REFERENCES,0.40518134715025905,"eroaromatic nitro compounds. Correlation with molecular orbital energies and hydrophobicity”.
336"
REFERENCES,0.40621761658031086,"In: Journal of Medicinal Chemistry 34.2 (1991), pp. 786–797. DOI: 10.1021/jm00106a046.
337"
REFERENCES,0.4072538860103627,"eprint: https://doi.org/10.1021/jm00106a046. URL: https://doi.org/10.1021/
338"
REFERENCES,0.4082901554404145,"jm00106a046.
339"
REFERENCES,0.40932642487046633,"[10]
Shikuang Deng et al. “Temporal Efficient Training of Spiking Neural Network via Gradient
340"
REFERENCES,0.41036269430051814,"Re-weighting”. In: International Conference on Learning Representations. 2022. URL: https:
341"
REFERENCES,0.41139896373056994,"//openreview.net/forum?id=_XNtisL32jv.
342"
REFERENCES,0.41243523316062175,"[11]
Frederik Diehl. “Edge contraction pooling for graph neural networks”. In: arXiv preprint
343"
REFERENCES,0.41347150259067356,"arXiv:1905.10990 (2019).
344"
REFERENCES,0.41450777202072536,"[12]
Chaoteng Duan et al. “Temporal Effective Batch Normalization in Spiking Neural Networks”.
345"
REFERENCES,0.4155440414507772,"In: Advances in Neural Information Processing Systems. Ed. by S. Koyejo et al. Vol. 35.
346"
REFERENCES,0.41658031088082903,"Curran Associates, Inc., 2022, pp. 34377–34390. URL: https://proceedings.neurips.
347"
REFERENCES,0.41761658031088084,"cc/paper_files/paper/2022/file/de2ad3ed44ee4e675b3be42aa0b615d0-Paper-
348"
REFERENCES,0.41865284974093264,"Conference.pdf.
349"
REFERENCES,0.41968911917098445,"[13]
Steve K Esser et al. “Backpropagation for Energy-Efficient Neuromorphic Computing”. In:
350"
REFERENCES,0.42072538860103625,"Advances in Neural Information Processing Systems. Ed. by C. Cortes et al. Vol. 28. Curran
351"
REFERENCES,0.42176165803108806,"Associates, Inc., 2015. URL: https://proceedings.neurips.cc/paper_files/paper/
352"
REFERENCES,0.4227979274611399,"2015/file/10a5ab2db37feedfdeaab192ead4ac0e-Paper.pdf.
353"
REFERENCES,0.42383419689119173,"[14]
Steven K Esser et al. “From the cover: Convolutional networks for fast, energy-efficient
354"
REFERENCES,0.42487046632124353,"neuromorphic computing”. In: Proceedings of the National Academy of Sciences of the United
355"
REFERENCES,0.42590673575129534,"States of America 113.41 (2016), p. 11441.
356"
REFERENCES,0.42694300518134715,"[15]
Wenqi Fan et al. “Graph neural networks for social recommendation”. In: The world wide web
357"
REFERENCES,0.42797927461139895,"conference. 2019, pp. 417–426.
358"
REFERENCES,0.42901554404145076,"[16]
Wei Fang et al. “Incorporating learnable membrane time constant to enhance learning of
359"
REFERENCES,0.43005181347150256,"spiking neural networks”. In: Proceedings of the IEEE/CVF international conference on
360"
REFERENCES,0.4310880829015544,"computer vision. 2021, pp. 2661–2671.
361"
REFERENCES,0.43212435233160623,"[17]
Wei Fang et al. “Parallel Spiking Neurons with High Efficiency and Ability to Learn
362"
REFERENCES,0.43316062176165804,"Long-term Dependencies”. In: Advances in Neural Information Processing Systems.
363"
REFERENCES,0.43419689119170984,"Ed. by A. Oh et al. Vol. 36. Curran Associates, Inc., 2023, pp. 53674–53687. URL:
364"
REFERENCES,0.43523316062176165,"https : / / proceedings . neurips . cc / paper _ files / paper / 2023 / file /
365"
REFERENCES,0.43626943005181346,"a834ac3dfdb90da54292c2c932c997cc-Paper-Conference.pdf.
366"
REFERENCES,0.43730569948186526,"[18]
Hongyang Gao and Shuiwang Ji. “Graph u-nets”. In: international conference on machine
367"
REFERENCES,0.4383419689119171,"learning. PMLR. 2019, pp. 2083–2092.
368"
REFERENCES,0.43937823834196893,"[19]
Tong Geng et al. “AWB-GCN: A graph convolutional network accelerator with runtime
369"
REFERENCES,0.44041450777202074,"workload rebalancing”. In: 2020 53rd Annual IEEE/ACM International Symposium on Mi-
370"
REFERENCES,0.44145077720207254,"croarchitecture (MICRO). IEEE. 2020, pp. 922–936.
371"
REFERENCES,0.44248704663212435,"[20]
Justin Gilmer et al. “Neural message passing for Quantum chemistry”. In: Proceedings of the
372"
REFERENCES,0.44352331606217615,"34th International Conference on Machine Learning-Volume 70. 2017, pp. 1263–1272.
373"
REFERENCES,0.44455958549222796,"[21]
Will Hamilton, Zhitao Ying, and Jure Leskovec. “Inductive representation learning on large
374"
REFERENCES,0.44559585492227977,"graphs”. In: Advances in neural information processing systems (2017).
375"
REFERENCES,0.4466321243523316,"[22]
Bing Han, Gopalakrishnan Srinivasan, and Kaushik Roy. “Rmp-snn: Residual membrane
376"
REFERENCES,0.44766839378238343,"potential neuron for enabling deeper high-accuracy and low-latency spiking neural network”.
377"
REFERENCES,0.44870466321243524,"In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition.
378"
REFERENCES,0.44974093264248705,"2020, pp. 13558–13567.
379"
REFERENCES,0.45077720207253885,"[23]
Alan L Hodgkin and Andrew F Huxley. “A quantitative description of membrane current and
380"
REFERENCES,0.45181347150259066,"its application to conduction and excitation in nerve”. In: The Journal of physiology 117.4
381"
REFERENCES,0.45284974093264246,"(1952), p. 500.
382"
REFERENCES,0.4538860103626943,"[24]
Eric Hunsberger and Chris Eliasmith. “Spiking deep networks with LIF neurons”. In: arXiv
383"
REFERENCES,0.45492227979274613,"preprint arXiv:1510.08829 (2015).
384"
REFERENCES,0.45595854922279794,"[25]
Haiyan Jiang et al. “TAB: Temporal Accumulated Batch Normalization in Spiking Neural
385"
REFERENCES,0.45699481865284974,"Networks”. In: The Twelfth International Conference on Learning Representations. 2024. URL:
386"
REFERENCES,0.45803108808290155,"https://openreview.net/forum?id=k1wlmtPGLq.
387"
REFERENCES,0.45906735751295336,"[26]
Farzad Khorasani et al. “CuSha: vertex-centric graph processing on GPUs”. In: Proceedings of
388"
REFERENCES,0.46010362694300516,"the 23rd international symposium on High-performance parallel and distributed computing.
389"
REFERENCES,0.46113989637305697,"2014.
390"
REFERENCES,0.46217616580310883,"[27]
Thomas N Kipf and Max Welling. “Semi-Supervised Classification with Graph Convolutional
391"
REFERENCES,0.46321243523316064,"Networks”. In: International Conference on Learning Representations. 2016.
392"
REFERENCES,0.46424870466321244,"[28]
Jinho Lee et al. “Extrav: boosting graph processing near storage with a coherent accelerator”.
393"
REFERENCES,0.46528497409326425,"In: Proceedings of the VLDB Endowment (2017).
394"
REFERENCES,0.46632124352331605,"[29]
Junhyun Lee, Inyeop Lee, and Jaewoo Kang. “Self-attention graph pooling”. In: International
395"
REFERENCES,0.46735751295336786,"conference on machine learning. PMLR. 2019, pp. 3734–3743.
396"
REFERENCES,0.46839378238341967,"[30]
Jure Leskovec et al. “Patterns of Cascading Behavior in Large Blog Graphs”. In: Proceedings
397"
REFERENCES,0.4694300518134715,"of the 2007 SIAM International Conference on Data Mining (SDM), pp. 551–556. DOI:
398"
REFERENCES,0.47046632124352333,"10.1137/1.9781611972771.60. URL: https://epubs.siam.org/doi/abs/10.1137/
399"
REFERENCES,0.47150259067357514,"1.9781611972771.60.
400"
REFERENCES,0.47253886010362695,"[31]
Jintang Li et al. “A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets Spik-
401"
REFERENCES,0.47357512953367875,"ing Neural Networks”. In: The Twelfth International Conference on Learning Representations.
402"
REFERENCES,0.47461139896373056,"2024. URL: https://openreview.net/forum?id=LnLySuf1vp.
403"
REFERENCES,0.47564766839378236,"[32]
Jintang Li et al. “Scaling up dynamic graph representation learning via spiking neural net-
404"
REFERENCES,0.47668393782383417,"works”. In: Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. 7. 2023,
405"
REFERENCES,0.47772020725388603,"pp. 8588–8596.
406"
REFERENCES,0.47875647668393784,"[33]
Yujia Li et al. “Gated Graph Sequence Neural Networks”. In: Proceedings of ICLR’16. 2016.
407"
REFERENCES,0.47979274611398964,"[34]
Shuang Lian et al. “IM-LIF: Improved Neuronal Dynamics With Attention Mechanism for
408"
REFERENCES,0.48082901554404145,"Direct Training Deep Spiking Neural Network”. In: IEEE Transactions on Emerging Topics in
409"
REFERENCES,0.48186528497409326,"Computational Intelligence (2024).
410"
REFERENCES,0.48290155440414506,"[35]
Wolfgang Maass. “Networks of spiking neurons: the third generation of neural network
411"
REFERENCES,0.48393782383419687,"models”. In: Neural networks 10.9 (1997), pp. 1659–1671.
412"
REFERENCES,0.48497409326424873,"[36]
Kiran Kumar Matam et al. “GraphSSD: graph semantics aware SSD”. In: Proceedings of the
413"
REFERENCES,0.48601036269430054,"46th international symposium on computer architecture. 2019.
414"
REFERENCES,0.48704663212435234,"[37]
Andrew Kachites McCallum et al. “Automating the construction of internet portals with
415"
REFERENCES,0.48808290155440415,"machine learning”. In: Information Retrieval 3 (2000), pp. 127–163.
416"
REFERENCES,0.48911917098445595,"[38]
Aditya Pal et al. “Pinnersage: Multi-modal user embedding framework for recommendations at
417"
REFERENCES,0.49015544041450776,"pinterest”. In: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge
418"
REFERENCES,0.49119170984455957,"Discovery & Data Mining. 2020, pp. 2311–2320.
419"
REFERENCES,0.49222797927461137,"[39]
Jiezhong Qiu et al. “Deepinf: Social influence prediction with deep learning”. In: Proceedings
420"
REFERENCES,0.49326424870466323,"of the 24th ACM SIGKDD international conference on knowledge discovery & data mining.
421"
REFERENCES,0.49430051813471504,"2018, pp. 2110–2119.
422"
REFERENCES,0.49533678756476685,"[40]
Ekagra Ranjan, Soumya Sanyal, and Partha Talukdar. “Asap: Adaptive structure aware pooling
423"
REFERENCES,0.49637305699481865,"for learning hierarchical graph representations”. In: Proceedings of the AAAI conference on
424"
REFERENCES,0.49740932642487046,"artificial intelligence. Vol. 34. 04. 2020, pp. 5470–5477.
425"
REFERENCES,0.49844559585492226,"[41]
Bodo Rueckauer et al. “Conversion of continuous-valued deep networks to efficient event-
426"
REFERENCES,0.49948186528497407,"driven networks for image classification”. In: Frontiers in neuroscience 11 (2017), p. 294078.
427"
REFERENCES,0.5005181347150259,"[42]
Abhronil Sengupta et al. “Going deeper in spiking neural networks: VGG and residual archi-
428"
REFERENCES,0.5015544041450777,"tectures”. In: Frontiers in neuroscience 13 (2019), p. 95.
429"
REFERENCES,0.5025906735751295,"[43]
Sumit B Shrestha and Garrick Orchard. “Slayer: Spike layer error reassignment in time”. In:
430"
REFERENCES,0.5036269430051813,"Advances in neural information processing systems 31 (2018).
431"
REFERENCES,0.5046632124352332,"[44]
Yundong Sun et al. “SpikeGraphormer: A High-Performance Graph Transformer with Spiking
432"
REFERENCES,0.505699481865285,"Graph Attention”. In: arXiv preprint arXiv:2403.15480 (2024).
433"
REFERENCES,0.5067357512953368,"[45]
Petar Veliˇckovi´c et al. “Graph Attention Networks”. In: International Conference on Learning
434"
REFERENCES,0.5077720207253886,"Representations. 2018.
435"
REFERENCES,0.5088082901554404,"[46]
Oriol Vinyals, Samy Bengio, and Manjunath Kudlur. “Order matters: Sequence to sequence
436"
REFERENCES,0.5098445595854922,"for sets”. In: arXiv preprint arXiv:1511.06391 (2015).
437"
REFERENCES,0.510880829015544,"[47]
Nikil Wale, Ian A Watson, and George Karypis. “Comparison of descriptor spaces for chemical
438"
REFERENCES,0.5119170984455959,"compound retrieval and classification”. In: Knowledge and Information Systems 14 (2008),
439"
REFERENCES,0.5129533678756477,"pp. 347–375.
440"
REFERENCES,0.5139896373056995,"[48]
Beibei Wang and Bo Jiang. “Spiking gats: Learning graph attentions via spiking neural
441"
REFERENCES,0.5150259067357513,"network”. In: arXiv preprint arXiv:2209.13539 (2022).
442"
REFERENCES,0.5160621761658031,"[49]
Siqi Wang, Tee Hiang Cheng, and Meng-Hiot Lim. “LTMD: learning improvement of spiking
443"
REFERENCES,0.5170984455958549,"neural networks with learnable thresholding neurons and moderate dropout”. In: Advances in
444"
REFERENCES,0.5181347150259067,"Neural Information Processing Systems 35 (2022), pp. 28350–28362.
445"
REFERENCES,0.5191709844559586,"[50]
Yangzihao Wang et al. “Gunrock: A high-performance graph processing library on the GPU”.
446"
REFERENCES,0.5202072538860104,"In: Proceedings of the 21st ACM SIGPLAN symposium on principles and practice of parallel
447"
REFERENCES,0.5212435233160622,"programming. 2016.
448"
REFERENCES,0.522279792746114,"[51]
Yujie Wu et al. “Spatio-temporal backpropagation for training high-performance spiking neural
449"
REFERENCES,0.5233160621761658,"networks”. In: Frontiers in neuroscience 12 (2018), p. 323875.
450"
REFERENCES,0.5243523316062176,"[52]
Keyulu Xu et al. “How Powerful are Graph Neural Networks?” In: International Conference
451"
REFERENCES,0.5253886010362694,"on Learning Representations. 2019.
452"
REFERENCES,0.5264248704663212,"[53]
Mingyu Yan et al. “Hygcn: A gcn accelerator with hybrid architecture”. In: 2020 IEEE
453"
REFERENCES,0.5274611398963731,"International Symposium on High Performance Computer Architecture (HPCA). IEEE. 2020,
454"
REFERENCES,0.5284974093264249,"pp. 15–29.
455"
REFERENCES,0.5295336787564767,"[54]
Pinar Yanardag and SVN Vishwanathan. “Deep graph kernels”. In: Proceedings of the 21th
456"
REFERENCES,0.5305699481865285,"ACM SIGKDD international conference on knowledge discovery and data mining. 2015,
457"
REFERENCES,0.5316062176165803,"pp. 1365–1374.
458"
REFERENCES,0.5326424870466321,"[55]
Nan Yin et al. “Dynamic spiking graph neural networks”. In: Proceedings of the AAAI Confer-
459"
REFERENCES,0.533678756476684,"ence on Artificial Intelligence. Vol. 38. 15. 2024, pp. 16495–16503.
460"
REFERENCES,0.5347150259067357,"[56]
Zhitao Ying et al. “Hierarchical graph representation learning with differentiable pooling”. In:
461"
REFERENCES,0.5357512953367876,"Advances in neural information processing systems 31 (2018).
462"
REFERENCES,0.5367875647668394,"[57]
Mingi Yoo et al. “Sgcn: Exploiting compressed-sparse features in deep graph convolutional net-
463"
REFERENCES,0.5378238341968912,"work accelerators”. In: 2023 IEEE International Symposium on High-Performance Computer
464"
REFERENCES,0.538860103626943,"Architecture (HPCA). IEEE. 2023, pp. 1–14.
465"
REFERENCES,0.5398963730569948,"[58]
Mingi Yoo et al. “Slice-and-Forge: Making Better Use of Caches for Graph Convolutional Net-
466"
REFERENCES,0.5409326424870466,"work Accelerators”. In: Proceedings of the International Conference on Parallel Architectures
467"
REFERENCES,0.5419689119170984,"and Compilation Techniques. 2022, pp. 40–53.
468"
REFERENCES,0.5430051813471503,"[59]
Huizhe Zhang et al. “SGHormer: An Energy-Saving Graph Transformer Driven by Spikes”.
469"
REFERENCES,0.5440414507772021,"In: arXiv preprint arXiv:2403.17656 (2024).
470"
REFERENCES,0.5450777202072539,"[60]
Muhan Zhang et al. “An end-to-end deep learning architecture for graph classification”. In:
471"
REFERENCES,0.5461139896373057,"Proceedings of the AAAI conference on artificial intelligence. Vol. 32. 1. 2018.
472"
REFERENCES,0.5471502590673575,"[61]
Yiming Zhang et al. “Graph learning augmented heterogeneous graph neural network for social
473"
REFERENCES,0.5481865284974093,"recommendation”. In: ACM Transactions on Recommender Systems 1.4 (2023), pp. 1–22.
474"
REFERENCES,0.5492227979274611,"[62]
Yaoyu Zhu et al. “Online Stabilization of Spiking Neural Networks”. In: The Twelfth Inter-
475"
REFERENCES,0.550259067357513,"national Conference on Learning Representations. 2024. URL: https://openreview.net/
476"
REFERENCES,0.5512953367875648,"forum?id=CIj1CVbkpr.
477"
REFERENCES,0.5523316062176166,"[63]
Yuanyuan Zhu et al. “Graph classification: a diversified discriminative feature selection ap-
478"
REFERENCES,0.5533678756476684,"proach”. In: Proceedings of the 21st ACM international conference on Information and
479"
REFERENCES,0.5544041450777202,"knowledge management. 2012, pp. 205–214.
480"
REFERENCES,0.555440414507772,"[64]
Zulun Zhu et al. “Spiking graph convolutional networks”. In: arXiv preprint arXiv:2205.02767
481"
REFERENCES,0.5564766839378238,"(2022).
482"
REFERENCES,0.5575129533678757,"A
Appendix / supplemental material
483"
REFERENCES,0.5585492227979275,"A.1
Limitation
484"
REFERENCES,0.5595854922279793,"Currently, our work is experimenting with the small-scale dataset for the graph classification that is
485"
REFERENCES,0.5606217616580311,"generally used. However, we will extend our work into the large-scale dataset that could apply to
486"
REFERENCES,0.5616580310880829,"the real. In addition, we will continue our future work for theoretical proof for updating the initial
487"
REFERENCES,0.5626943005181347,"threshold that is fused with adaptative changes in the timestep.
488"
REFERENCES,0.5637305699481865,"A.2
Code
489"
REFERENCES,0.5647668393782384,"The code which includes our implementation of this work is included in a zip archive of the sup-
490"
REFERENCES,0.5658031088082901,"plementary material. The code is under Nvidia Source Code License-NC and GNU General Public
491"
REFERENCES,0.566839378238342,"License v3.0.
492"
REFERENCES,0.5678756476683938,"A.3
Detailed Experiment Settings
493"
REFERENCES,0.5689119170984456,"Dataset Details
Given the diverse properties of graph datasets, we selected five datasets from the
494"
REFERENCES,0.5699481865284974,"well-known TUDatasets, commonly used for graph classification. We compiled statistics for these
495"
REFERENCES,0.5709844559585492,"datasets to briefly represent their key properties.
496"
REFERENCES,0.572020725388601,Table 4: Summary of datasets used in the study.
REFERENCES,0.5730569948186528,"Dataset
# Graphs
Avg.
Nodes
# Nodes
(1stgraph)
Avg.
Edges
# Edges
(1stgraph)
# Classes"
REFERENCES,0.5740932642487047,"MUTAG [9]
188
17.93
17
19.79
38
2
PROTEINS [6]
1113
39.06
42
72.82
162
2
ENZYMES [6]
600
32.6
37
62.1
168
6
NCI1 [47]
4110
29.87
21
32.30
42
2
IMDB-BINARY [54]
1000
19.77
20
96.53
146
2"
REFERENCES,0.5751295336787565,"Network Architecture
In this work, we consider the following three GNN architectures where the
497"
REFERENCES,0.5761658031088083,"distinctions lie in their update rules:
498"
REFERENCES,0.5772020725388601,"• Graph Convolution Network [27] (GCN): h(l+1)
i
= σ(P"
REFERENCES,0.5782383419689119,"j∈N(i) S{i}
W h(l)
j
√"
REFERENCES,0.5792746113989637,"|N(i)||N(j)|), where
499"
REFERENCES,0.5803108808290155,"ϕ(·) is replaced by affine transformation W followed by nonlinearity σ.
500"
REFERENCES,0.5813471502590674,"• Graph Attention Network [45] (GAT): h(l+1)
i
= αi,iWh(l)
i
+ P"
REFERENCES,0.5823834196891192,"j∈N(i) αijWh(l)
j , where
501"
REFERENCES,0.583419689119171,"αij is the normalized attention score between node i and j.
502"
REFERENCES,0.5844559585492228,"• Graph Isomorphism Network [52] (GIN): h(l+1)
i
= MLP((1 + ϵ)h(l)
i
+ P
j∈N(i) h(l)
j ),
503"
REFERENCES,0.5854922279792746,"where ϵ is a learnable constant.
504"
REFERENCES,0.5865284974093264,"For the GCN layers, 128 dimensions were used for hidden dimensions, and GAT layers were used for
505"
REFERENCES,0.5875647668393782,"4 multi-head attentions. GIN was used for 2-MLP layers for the above equation.
506"
REFERENCES,0.5886010362694301,"Experiment Settings
We trained and evaluated our models using 10-fold cross-validation for all
507"
REFERENCES,0.5896373056994819,"datasets. Note that the IMDB-BINARY dataset lacks inherent features, so we constructed features
508"
REFERENCES,0.5906735751295337,"using the node degrees for the GNN layer. Additionally, we did not apply any multiplier to adjust
509"
REFERENCES,0.5917098445595855,"the width of the sigmoid function. The details of our evaluation procedure are outlined below. Our
510"
REFERENCES,0.5927461139896373,"experiment was evaluated on a single RTX-4090 GPU for the full batch GNN training.
511"
REFERENCES,0.5937823834196891,"• Epochs: 1000
512"
REFERENCES,0.5948186528497409,"• Surrogate function: σ(x) =
1
1+e−x
513"
REFERENCES,0.5958549222797928,"• Learning rate(η): 0.01 (for main table)
514"
REFERENCES,0.5968911917098445,"• Optimizer: Adamw
515"
REFERENCES,0.5979274611398964,"• Loss function: Cross entropy
516"
REFERENCES,0.5989637305699482,"• Adaptive step size(γ): 0.2
517"
REFERENCES,0.6,"A.4
Analysis on Spike Frequency
518"
REFERENCES,0.6010362694300518,"We provide additional figures that we referenced on Section 3. Appendix A.4 shows MUTAG,
519"
REFERENCES,0.6020725388601036,"PROTEINS, ENZYMES, NCI1 dataset total spike histogram bins.
520 521"
REFERENCES,0.6031088082901555,"A.5
Overall training procedure
522"
REFERENCES,0.6041450777202072,"As referred on Section 4 our TAG method and overall updating initial values of group threshold is
523"
REFERENCES,0.6051813471502591,"reffed on Algorithm 1. Note that our initial group values updated after timestep T.
524"
REFERENCES,0.6062176165803109,"Algorithm 1 Updataing V g
th(0) procedure"
REFERENCES,0.6072538860103627,"1: Inputs: Initial start points of threshold Vinit, graph’s vertex feature X ∈RV XF , learning rate for training
η, total time step T, l-th layer’s threshold V (l)
th , l-th layer’s GNN layer GNN (l), true label Y ,
2: Initialize: V g
th(0) = [Vinit, ... Vinit ]
▷Initialize all of the g threshold groups with initial values
3: for ep = 1 to epochs do
4:
for t = 1 to T do
5:
X = PoissonEncoder(X)
▷Binarize first input layer with Poisson encoder
6:
for l = 1 to L do
7:
for g in group G do
8:
Xg,(l) = GNN (l)(Xg,(l))
▷Operate by GCN, GAT, GIN architectures
9:
for i = 1 to |Vg| do
10:
Xgi,(l) = Sgi,(l)(t) = SNN (l)(Xgi,(l))
▷Xgi,(l) represents i-th row of Xg,(l)"
REFERENCES,0.6082901554404145,"11:
Sg,(l)(t) =
1
|Vg|
P"
REFERENCES,0.6093264248704663,"i∈Vg Sgi(t)
12:
end for
13:
V g,(l)
th
(t) = γV g,(l)
th
(t −1) + (1 −γ)Sg,(l)(t) ▷Update threshold through TAG Equation (10)
14:
end for
15:
end for
16:
Ot ←FC(POOL(GNN(X(L)))) + Ot−1"
REFERENCES,0.6103626943005181,"17:
end for
18:
Vth(0) = Vth(0) −η∇Vth(0)L(Ot=1, Y )
19: end for"
REFERENCES,0.6113989637305699,"A.6
Sensitivity Study on Degree Group
525"
REFERENCES,0.6124352331606218,"Our experiments were conducted on a number of degree groups. Please refer Table 5 for the sensitivity
526"
REFERENCES,0.6134715025906736,"depending on the number of degree groups. Please note that the optimal values of the degree groups
527"
REFERENCES,0.6145077720207254,"are different depending on the graph datasets. We reported to the max degree group setting that
528"
REFERENCES,0.6155440414507772,"unseen nodes will use the initial values Vinit that represents the Vth(0) that does not trained at all.
529"
REFERENCES,0.616580310880829,"A.7
Sensitivity Study on Learning Rate
530"
REFERENCES,0.6176165803108808,"Our experiments were conducted under various learning rate conditions η ∈[0.001, 0.5] to assess their
531"
REFERENCES,0.6186528497409326,"impact. As reported in Table 3 for the MUTAG dataset, we also present results for the PROTEINS,
532"
REFERENCES,0.6196891191709845,"ENZYMES, NCI1, and IMDB-BINARY datasets across GCN, GAT, and GIN architectures. Our
533"
REFERENCES,0.6207253886010363,"model’s ability to learn Vinit demonstrates a sensitivity to learning rate similar to other ANN models.
534"
REFERENCES,0.6217616580310881,"We found that the optimal performance was achieved at a learning rate of η = 0.01.
535"
REFERENCES,0.6227979274611399,(a) MUTAG-SpikingGNN spikes per node
REFERENCES,0.6238341968911917,(b) MUTAG-TASGNN spikes per node
REFERENCES,0.6248704663212435,(c) PROTEINS-SpikingGNN spikes per node
REFERENCES,0.6259067357512953,(d) PROTEINS-TASGNN spikes per node
REFERENCES,0.6269430051813472,(e) ENZYMES-SpikingGNN spikes per node
REFERENCES,0.627979274611399,(f) ENZYMES-TASGNN spikes per node
REFERENCES,0.6290155440414508,(g) NCI1-SpikingGNN spikes per node
REFERENCES,0.6300518134715026,(h) NCI1-TASGNN spikes per node
REFERENCES,0.6310880829015544,"Figure 6: Histogram plotting distribution of total spikes counted over time for each node. X-axis
denotes spike counts from each node, while y-axis denotes density of each bin."
REFERENCES,0.6321243523316062,"NeurIPS Paper Checklist
536"
REFERENCES,0.633160621761658,"The checklist is designed to encourage best practices for responsible machine learning research,
537"
REFERENCES,0.6341968911917099,"addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove
538"
REFERENCES,0.6352331606217616,"the checklist: The papers not including the checklist will be desk rejected. The checklist should
539"
REFERENCES,0.6362694300518135,"follow the references and precede the (optional) supplemental material. The checklist does NOT
540"
REFERENCES,0.6373056994818653,"count towards the page limit.
541"
REFERENCES,0.6383419689119171,"Please read the checklist guidelines carefully for information on how to answer these questions. For
542"
REFERENCES,0.6393782383419689,"each question in the checklist:
543"
REFERENCES,0.6404145077720207,"• You should answer [Yes] , [No] , or [NA] .
544"
REFERENCES,0.6414507772020726,"• [NA] means either that the question is Not Applicable for that particular paper or the
545"
REFERENCES,0.6424870466321243,"relevant information is Not Available.
546"
REFERENCES,0.6435233160621762,"• Please provide a short (1–2 sentence) justification right after your answer (even for NA).
547"
REFERENCES,0.644559585492228,"The checklist answers are an integral part of your paper submission. They are visible to the
548"
REFERENCES,0.6455958549222798,"reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it
549"
REFERENCES,0.6466321243523316,"(after eventual revisions) with the final version of your paper, and its final version will be published
550"
REFERENCES,0.6476683937823834,"with the paper.
551"
REFERENCES,0.6487046632124353,"The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.
552"
REFERENCES,0.649740932642487,"While ""[Yes] "" is generally preferable to ""[No] "", it is perfectly acceptable to answer ""[No] "" provided a
553"
REFERENCES,0.6507772020725389,"proper justification is given (e.g., ""error bars are not reported because it would be too computationally
554"
REFERENCES,0.6518134715025907,"expensive"" or ""we were unable to find the license for the dataset we used""). In general, answering
555"
REFERENCES,0.6528497409326425,"""[No] "" or ""[NA] "" is not grounds for rejection. While the questions are phrased in a binary way, we
556"
REFERENCES,0.6538860103626943,"acknowledge that the true answer is often more nuanced, so please just use your best judgment and
557"
REFERENCES,0.6549222797927461,"write a justification to elaborate. All supporting evidence can appear either in the main paper or the
558"
REFERENCES,0.655958549222798,"supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification
559"
REFERENCES,0.6569948186528497,"please point to the section(s) where related material for the question can be found.
560"
REFERENCES,0.6580310880829016,"IMPORTANT, please:
561"
REFERENCES,0.6590673575129534,"• Delete this instruction block, but keep the section heading “NeurIPS paper checklist"",
562"
REFERENCES,0.6601036269430052,"• Keep the checklist subsection headings, questions/answers and guidelines below.
563"
REFERENCES,0.661139896373057,"• Do not modify the questions and only use the provided macros for your answers.
564"
REFERENCES,0.6621761658031088,Table 5: Comparison on using different number of degree group
REFERENCES,0.6632124352331606,"Dataset
#Degree
Group
GCN
GAT
GIN"
REFERENCES,0.6642487046632124,"MUTAG
1
87.81
80.88
94.71
2
96.84
87.78
96.32
3
93.10
95.79
95.79
4(max)
96.32
96.32
95.76"
REFERENCES,0.6652849740932643,PROTEINS
REFERENCES,0.666321243523316,"1
78.89
64.33
78.89
2
78.98
63.88
78.98
5
75.83
67.39
75.83
10
77.45
69.55
77.45
15
77.99
70.54
77.99
17(max)
77.45
71.34
80.32"
REFERENCES,0.6673575129533679,"ENZYMES
1
58.33
41.33
45.17
2
56.50
40.50
44.33
5
52.00
45.00
41.50
10(max)
56.50
52.33
48.00 NCI1"
REFERENCES,0.6683937823834197,"1
75.74
67.86
73.82
2
75.77
68.08
75.06
3
77.86
72.48
76.86
4
77.81
74.26
76.74
5(max)
77.81
75.33
77.52"
REFERENCES,0.6694300518134715,IMDB-BINARY
REFERENCES,0.6704663212435233,"1
71.70
50.00
74.60
2
70.40
50.30
72.90
5
69.30
56.80
71.00
10
66.70
56.40
66.70
20
64.00
61.30
66.20
50
65.99
64.51
65.55
65(max)
80.10
77.90
73.70"
CLAIMS,0.6715025906735751,"1. Claims
565"
CLAIMS,0.672538860103627,"Question: Do the main claims made in the abstract and introduction accurately reflect the
566"
CLAIMS,0.6735751295336787,"paper’s contributions and scope?
567"
CLAIMS,0.6746113989637306,"Answer: [Yes]
568"
CLAIMS,0.6756476683937824,"Justification: Our paper contributes on the scope of Spiking Neural Networks and Graph
569"
CLAIMS,0.6766839378238342,"Neural Networks scopes in graph classification task specifically
570"
CLAIMS,0.677720207253886,"Guidelines:
571"
CLAIMS,0.6787564766839378,"• The answer NA means that the abstract and introduction do not include the claims
572"
CLAIMS,0.6797927461139897,"made in the paper.
573"
CLAIMS,0.6808290155440414,"• The abstract and/or introduction should clearly state the claims made, including the
574"
CLAIMS,0.6818652849740933,"contributions made in the paper and important assumptions and limitations. A No or
575"
CLAIMS,0.6829015544041451,"NA answer to this question will not be perceived well by the reviewers.
576"
CLAIMS,0.6839378238341969,"• The claims made should match theoretical and experimental results, and reflect how
577"
CLAIMS,0.6849740932642487,"much the results can be expected to generalize to other settings.
578"
CLAIMS,0.6860103626943005,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
579"
CLAIMS,0.6870466321243524,"are not attained by the paper.
580"
LIMITATIONS,0.6880829015544041,"2. Limitations
581"
LIMITATIONS,0.689119170984456,"Question: Does the paper discuss the limitations of the work performed by the authors?
582"
LIMITATIONS,0.6901554404145078,"Answer: [Yes]
583"
LIMITATIONS,0.6911917098445596,"Justification: We discuss the limitation on the Appendix.
584"
LIMITATIONS,0.6922279792746114,"Guidelines:
585"
LIMITATIONS,0.6932642487046632,"• The answer NA means that the paper has no limitation while the answer No means that
586"
LIMITATIONS,0.694300518134715,"the paper has limitations, but those are not discussed in the paper.
587"
LIMITATIONS,0.6953367875647668,Table 6: Extended sensitivity study on threshold learning rate.
LIMITATIONS,0.6963730569948187,"η
Dataset
Model
0.001
0.005
0.01
0.05
0.1
0.5"
LIMITATIONS,0.6974093264248704,"MUTAG
GCN
93.68
96.84
96.32
96.84
96.84
84.15
GAT
86.78
94.18
96.32
94.18
94.71
92.05
GIN
89.97
95.26
95.76
93.16
93.13
91.02"
LIMITATIONS,0.6984455958549223,"PROTEINS
GCN
75.11
76.82
77.45
77.36
76.82
65.67
GAT
64.14
70.35
71.34
73.23
74.93
70.53
GIN
77.72
79.07
80.32
78.17
76.55
75.65"
LIMITATIONS,0.6994818652849741,"ENZYMES
GCN
45.00
51.17
56.50
56.83
54.67
29.17
GAT
32.00
45.00
52.33
55.83
42.67
34.33
GIN
37.33
44.33
48.00
35.17
31.33
29.33"
LIMITATIONS,0.7005181347150259,"NCI1
GCN
73.87
77.37
77.81
80.07
78.81
66.95
GAT
66.93
73.31
75.33
76.06
73.48
66.69
GIN
72.80
76.57
77.52
70.54
69.05
64.94"
LIMITATIONS,0.7015544041450777,"IMDB-Binary
GCN
78.90
79.90
80.10
80.50
80.60
73.60
GAT
74.80
75.80
77.90
75.60
75.90
75.30
GIN
74.10
73.00
73.70
75.40
74.70
73.60"
LIMITATIONS,0.7025906735751295,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
588"
LIMITATIONS,0.7036269430051814,"• The paper should point out any strong assumptions and how robust the results are to
589"
LIMITATIONS,0.7046632124352331,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
590"
LIMITATIONS,0.705699481865285,"model well-specification, asymptotic approximations only holding locally). The authors
591"
LIMITATIONS,0.7067357512953368,"should reflect on how these assumptions might be violated in practice and what the
592"
LIMITATIONS,0.7077720207253886,"implications would be.
593"
LIMITATIONS,0.7088082901554404,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
594"
LIMITATIONS,0.7098445595854922,"only tested on a few datasets or with a few runs. In general, empirical results often
595"
LIMITATIONS,0.7108808290155441,"depend on implicit assumptions, which should be articulated.
596"
LIMITATIONS,0.7119170984455958,"• The authors should reflect on the factors that influence the performance of the approach.
597"
LIMITATIONS,0.7129533678756477,"For example, a facial recognition algorithm may perform poorly when image resolution
598"
LIMITATIONS,0.7139896373056995,"is low or images are taken in low lighting. Or a speech-to-text system might not be
599"
LIMITATIONS,0.7150259067357513,"used reliably to provide closed captions for online lectures because it fails to handle
600"
LIMITATIONS,0.7160621761658031,"technical jargon.
601"
LIMITATIONS,0.7170984455958549,"• The authors should discuss the computational efficiency of the proposed algorithms
602"
LIMITATIONS,0.7181347150259068,"and how they scale with dataset size.
603"
LIMITATIONS,0.7191709844559585,"• If applicable, the authors should discuss possible limitations of their approach to
604"
LIMITATIONS,0.7202072538860104,"address problems of privacy and fairness.
605"
LIMITATIONS,0.7212435233160622,"• While the authors might fear that complete honesty about limitations might be used by
606"
LIMITATIONS,0.722279792746114,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
607"
LIMITATIONS,0.7233160621761658,"limitations that aren’t acknowledged in the paper. The authors should use their best
608"
LIMITATIONS,0.7243523316062176,"judgment and recognize that individual actions in favor of transparency play an impor-
609"
LIMITATIONS,0.7253886010362695,"tant role in developing norms that preserve the integrity of the community. Reviewers
610"
LIMITATIONS,0.7264248704663212,"will be specifically instructed to not penalize honesty concerning limitations.
611"
THEORY ASSUMPTIONS AND PROOFS,0.7274611398963731,"3. Theory Assumptions and Proofs
612"
THEORY ASSUMPTIONS AND PROOFS,0.7284974093264248,"Question: For each theoretical result, does the paper provide the full set of assumptions and
613"
THEORY ASSUMPTIONS AND PROOFS,0.7295336787564767,"a complete (and correct) proof?
614"
THEORY ASSUMPTIONS AND PROOFS,0.7305699481865285,"Answer: [NA]
615"
THEORY ASSUMPTIONS AND PROOFS,0.7316062176165803,"Justification: Our work does not include theoretical results.
616"
THEORY ASSUMPTIONS AND PROOFS,0.7326424870466322,"Guidelines:
617"
THEORY ASSUMPTIONS AND PROOFS,0.7336787564766839,"• The answer NA means that the paper does not include theoretical results.
618"
THEORY ASSUMPTIONS AND PROOFS,0.7347150259067358,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
619"
THEORY ASSUMPTIONS AND PROOFS,0.7357512953367875,"referenced.
620"
THEORY ASSUMPTIONS AND PROOFS,0.7367875647668394,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
621"
THEORY ASSUMPTIONS AND PROOFS,0.7378238341968912,"• The proofs can either appear in the main paper or the supplemental material, but if
622"
THEORY ASSUMPTIONS AND PROOFS,0.738860103626943,"they appear in the supplemental material, the authors are encouraged to provide a short
623"
THEORY ASSUMPTIONS AND PROOFS,0.7398963730569948,"proof sketch to provide intuition.
624"
THEORY ASSUMPTIONS AND PROOFS,0.7409326424870466,"• Inversely, any informal proof provided in the core of the paper should be complemented
625"
THEORY ASSUMPTIONS AND PROOFS,0.7419689119170985,"by formal proofs provided in appendix or supplemental material.
626"
THEORY ASSUMPTIONS AND PROOFS,0.7430051813471502,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
627"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7440414507772021,"4. Experimental Result Reproducibility
628"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7450777202072539,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
629"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7461139896373057,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
630"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7471502590673575,"of the paper (regardless of whether the code and data are provided or not)?
631"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7481865284974093,"Answer: [Yes]
632"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7492227979274612,"Justification: We provided our codes that able to reproduce our model’s result.
633"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7502590673575129,"Guidelines:
634"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7512953367875648,"• The answer NA means that the paper does not include experiments.
635"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7523316062176166,"• If the paper includes experiments, a No answer to this question will not be perceived
636"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7533678756476684,"well by the reviewers: Making the paper reproducible is important, regardless of
637"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7544041450777202,"whether the code and data are provided or not.
638"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.755440414507772,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
639"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7564766839378239,"to make their results reproducible or verifiable.
640"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7575129533678756,"• Depending on the contribution, reproducibility can be accomplished in various ways.
641"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7585492227979275,"For example, if the contribution is a novel architecture, describing the architecture fully
642"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7595854922279792,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
643"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7606217616580311,"be necessary to either make it possible for others to replicate the model with the same
644"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7616580310880829,"dataset, or provide access to the model. In general. releasing code and data is often
645"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7626943005181347,"one good way to accomplish this, but reproducibility can also be provided via detailed
646"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7637305699481866,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
647"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7647668393782383,"of a large language model), releasing of a model checkpoint, or other means that are
648"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7658031088082902,"appropriate to the research performed.
649"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7668393782383419,"• While NeurIPS does not require releasing code, the conference does require all submis-
650"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7678756476683938,"sions to provide some reasonable avenue for reproducibility, which may depend on the
651"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7689119170984456,"nature of the contribution. For example
652"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7699481865284974,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
653"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7709844559585493,"to reproduce that algorithm.
654"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.772020725388601,"(b) If the contribution is primarily a new model architecture, the paper should describe
655"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7730569948186529,"the architecture clearly and fully.
656"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7740932642487046,"(c) If the contribution is a new model (e.g., a large language model), then there should
657"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7751295336787565,"either be a way to access this model for reproducing the results or a way to reproduce
658"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7761658031088083,"the model (e.g., with an open-source dataset or instructions for how to construct
659"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7772020725388601,"the dataset).
660"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.778238341968912,"(d) We recognize that reproducibility may be tricky in some cases, in which case
661"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7792746113989637,"authors are welcome to describe the particular way they provide for reproducibility.
662"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7803108808290156,"In the case of closed-source models, it may be that access to the model is limited in
663"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7813471502590673,"some way (e.g., to registered users), but it should be possible for other researchers
664"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7823834196891192,"to have some path to reproducing or verifying the results.
665"
OPEN ACCESS TO DATA AND CODE,0.783419689119171,"5. Open access to data and code
666"
OPEN ACCESS TO DATA AND CODE,0.7844559585492228,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
667"
OPEN ACCESS TO DATA AND CODE,0.7854922279792746,"tions to faithfully reproduce the main experimental results, as described in supplemental
668"
OPEN ACCESS TO DATA AND CODE,0.7865284974093264,"material?
669"
OPEN ACCESS TO DATA AND CODE,0.7875647668393783,"Answer: [Yes]
670"
OPEN ACCESS TO DATA AND CODE,0.78860103626943,"Justification: We provide our codes that are able to reproduce our full experiments.
671"
OPEN ACCESS TO DATA AND CODE,0.7896373056994819,"Guidelines:
672"
OPEN ACCESS TO DATA AND CODE,0.7906735751295336,"• The answer NA means that paper does not include experiments requiring code.
673"
OPEN ACCESS TO DATA AND CODE,0.7917098445595855,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
674"
OPEN ACCESS TO DATA AND CODE,0.7927461139896373,"public/guides/CodeSubmissionPolicy) for more details.
675"
OPEN ACCESS TO DATA AND CODE,0.7937823834196891,"• While we encourage the release of code and data, we understand that this might not be
676"
OPEN ACCESS TO DATA AND CODE,0.794818652849741,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
677"
OPEN ACCESS TO DATA AND CODE,0.7958549222797927,"including code, unless this is central to the contribution (e.g., for a new open-source
678"
OPEN ACCESS TO DATA AND CODE,0.7968911917098446,"benchmark).
679"
OPEN ACCESS TO DATA AND CODE,0.7979274611398963,"• The instructions should contain the exact command and environment needed to run to
680"
OPEN ACCESS TO DATA AND CODE,0.7989637305699482,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
681"
OPEN ACCESS TO DATA AND CODE,0.8,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
682"
OPEN ACCESS TO DATA AND CODE,0.8010362694300518,"• The authors should provide instructions on data access and preparation, including how
683"
OPEN ACCESS TO DATA AND CODE,0.8020725388601037,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
684"
OPEN ACCESS TO DATA AND CODE,0.8031088082901554,"• The authors should provide scripts to reproduce all experimental results for the new
685"
OPEN ACCESS TO DATA AND CODE,0.8041450777202073,"proposed method and baselines. If only a subset of experiments are reproducible, they
686"
OPEN ACCESS TO DATA AND CODE,0.805181347150259,"should state which ones are omitted from the script and why.
687"
OPEN ACCESS TO DATA AND CODE,0.8062176165803109,"• At submission time, to preserve anonymity, the authors should release anonymized
688"
OPEN ACCESS TO DATA AND CODE,0.8072538860103627,"versions (if applicable).
689"
OPEN ACCESS TO DATA AND CODE,0.8082901554404145,"• Providing as much information as possible in supplemental material (appended to the
690"
OPEN ACCESS TO DATA AND CODE,0.8093264248704664,"paper) is recommended, but including URLs to data and code is permitted.
691"
OPEN ACCESS TO DATA AND CODE,0.8103626943005181,"6. Experimental Setting/Details
692"
OPEN ACCESS TO DATA AND CODE,0.81139896373057,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
693"
OPEN ACCESS TO DATA AND CODE,0.8124352331606217,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
694"
OPEN ACCESS TO DATA AND CODE,0.8134715025906736,"results?
695"
OPEN ACCESS TO DATA AND CODE,0.8145077720207254,"Answer: [Yes]
696"
OPEN ACCESS TO DATA AND CODE,0.8155440414507772,"Justification: We wrote experiment setting in the experiment settings including GNN layers,
697"
OPEN ACCESS TO DATA AND CODE,0.816580310880829,"hyperparameter for the hidden dimension, and learning rate of the whole dataset. Also, we
698"
OPEN ACCESS TO DATA AND CODE,0.8176165803108808,"wrote epochs and dataset we split was used by 10 fold CV for our evaluations.
699"
OPEN ACCESS TO DATA AND CODE,0.8186528497409327,"Guidelines:
700"
OPEN ACCESS TO DATA AND CODE,0.8196891191709844,"• The answer NA means that the paper does not include experiments.
701"
OPEN ACCESS TO DATA AND CODE,0.8207253886010363,"• The experimental setting should be presented in the core of the paper to a level of detail
702"
OPEN ACCESS TO DATA AND CODE,0.8217616580310881,"that is necessary to appreciate the results and make sense of them.
703"
OPEN ACCESS TO DATA AND CODE,0.8227979274611399,"• The full details can be provided either with the code, in appendix, or as supplemental
704"
OPEN ACCESS TO DATA AND CODE,0.8238341968911918,"material.
705"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8248704663212435,"7. Experiment Statistical Significance
706"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8259067357512954,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
707"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8269430051813471,"information about the statistical significance of the experiments?
708"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.827979274611399,"Answer: [Yes]
709"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8290155440414507,"Justification: We reported error of confidence level in the main table.
710"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8300518134715026,"Guidelines:
711"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8310880829015544,"• The answer NA means that the paper does not include experiments.
712"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8321243523316062,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
713"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8331606217616581,"dence intervals, or statistical significance tests, at least for the experiments that support
714"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8341968911917098,"the main claims of the paper.
715"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8352331606217617,"• The factors of variability that the error bars are capturing should be clearly stated (for
716"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8362694300518134,"example, train/test split, initialization, random drawing of some parameter, or overall
717"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8373056994818653,"run with given experimental conditions).
718"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8383419689119171,"• The method for calculating the error bars should be explained (closed form formula,
719"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8393782383419689,"call to a library function, bootstrap, etc.)
720"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8404145077720208,"• The assumptions made should be given (e.g., Normally distributed errors).
721"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8414507772020725,"• It should be clear whether the error bar is the standard deviation or the standard error
722"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8424870466321244,"of the mean.
723"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8435233160621761,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
724"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.844559585492228,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
725"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8455958549222798,"of Normality of errors is not verified.
726"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8466321243523316,"• For asymmetric distributions, the authors should be careful not to show in tables or
727"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8476683937823835,"figures symmetric error bars that would yield results that are out of range (e.g. negative
728"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8487046632124352,"error rates).
729"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8497409326424871,"• If error bars are reported in tables or plots, The authors should explain in the text how
730"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8507772020725388,"they were calculated and reference the corresponding figures or tables in the text.
731"
EXPERIMENTS COMPUTE RESOURCES,0.8518134715025907,"8. Experiments Compute Resources
732"
EXPERIMENTS COMPUTE RESOURCES,0.8528497409326425,"Question: For each experiment, does the paper provide sufficient information on the com-
733"
EXPERIMENTS COMPUTE RESOURCES,0.8538860103626943,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
734"
EXPERIMENTS COMPUTE RESOURCES,0.8549222797927462,"the experiments?
735"
EXPERIMENTS COMPUTE RESOURCES,0.8559585492227979,"Answer: [Yes]
736"
EXPERIMENTS COMPUTE RESOURCES,0.8569948186528498,"Justification: It refers to the appendix for experimental settings.
737"
EXPERIMENTS COMPUTE RESOURCES,0.8580310880829015,"Guidelines:
738"
EXPERIMENTS COMPUTE RESOURCES,0.8590673575129534,"• The answer NA means that the paper does not include experiments.
739"
EXPERIMENTS COMPUTE RESOURCES,0.8601036269430051,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
740"
EXPERIMENTS COMPUTE RESOURCES,0.861139896373057,"or cloud provider, including relevant memory and storage.
741"
EXPERIMENTS COMPUTE RESOURCES,0.8621761658031089,"• The paper should provide the amount of compute required for each of the individual
742"
EXPERIMENTS COMPUTE RESOURCES,0.8632124352331606,"experimental runs as well as estimate the total compute.
743"
EXPERIMENTS COMPUTE RESOURCES,0.8642487046632125,"• The paper should disclose whether the full research project required more compute
744"
EXPERIMENTS COMPUTE RESOURCES,0.8652849740932642,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
745"
EXPERIMENTS COMPUTE RESOURCES,0.8663212435233161,"didn’t make it into the paper).
746"
CODE OF ETHICS,0.8673575129533678,"9. Code Of Ethics
747"
CODE OF ETHICS,0.8683937823834197,"Question: Does the research conducted in the paper conform, in every respect, with the
748"
CODE OF ETHICS,0.8694300518134715,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
749"
CODE OF ETHICS,0.8704663212435233,"Answer: [Yes]
750"
CODE OF ETHICS,0.8715025906735752,"Justification: Research conducted in the paper conforms, in every respect, with the NeurIPS
751"
CODE OF ETHICS,0.8725388601036269,"Code of Ethics
752"
CODE OF ETHICS,0.8735751295336788,"Guidelines:
753"
CODE OF ETHICS,0.8746113989637305,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
754"
CODE OF ETHICS,0.8756476683937824,"• If the authors answer No, they should explain the special circumstances that require a
755"
CODE OF ETHICS,0.8766839378238342,"deviation from the Code of Ethics.
756"
CODE OF ETHICS,0.877720207253886,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
757"
CODE OF ETHICS,0.8787564766839379,"eration due to laws or regulations in their jurisdiction).
758"
BROADER IMPACTS,0.8797927461139896,"10. Broader Impacts
759"
BROADER IMPACTS,0.8808290155440415,"Question: Does the paper discuss both potential positive societal impacts and negative
760"
BROADER IMPACTS,0.8818652849740932,"societal impacts of the work performed?
761"
BROADER IMPACTS,0.8829015544041451,"Answer: [Yes]
762"
BROADER IMPACTS,0.883937823834197,"Justification: SNN would be one of the breakthrough idea in respect of energy consumption.
763"
BROADER IMPACTS,0.8849740932642487,"Guidelines:
764"
BROADER IMPACTS,0.8860103626943006,"• The answer NA means that there is no societal impact of the work performed.
765"
BROADER IMPACTS,0.8870466321243523,"• If the authors answer NA or No, they should explain why their work has no societal
766"
BROADER IMPACTS,0.8880829015544042,"impact or why the paper does not address societal impact.
767"
BROADER IMPACTS,0.8891191709844559,"• Examples of negative societal impacts include potential malicious or unintended uses
768"
BROADER IMPACTS,0.8901554404145078,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
769"
BROADER IMPACTS,0.8911917098445595,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
770"
BROADER IMPACTS,0.8922279792746114,"groups), privacy considerations, and security considerations.
771"
BROADER IMPACTS,0.8932642487046633,"• The conference expects that many papers will be foundational research and not tied
772"
BROADER IMPACTS,0.894300518134715,"to particular applications, let alone deployments. However, if there is a direct path to
773"
BROADER IMPACTS,0.8953367875647669,"any negative applications, the authors should point it out. For example, it is legitimate
774"
BROADER IMPACTS,0.8963730569948186,"to point out that an improvement in the quality of generative models could be used to
775"
BROADER IMPACTS,0.8974093264248705,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
776"
BROADER IMPACTS,0.8984455958549222,"that a generic algorithm for optimizing neural networks could enable people to train
777"
BROADER IMPACTS,0.8994818652849741,"models that generate Deepfakes faster.
778"
BROADER IMPACTS,0.900518134715026,"• The authors should consider possible harms that could arise when the technology is
779"
BROADER IMPACTS,0.9015544041450777,"being used as intended and functioning correctly, harms that could arise when the
780"
BROADER IMPACTS,0.9025906735751296,"technology is being used as intended but gives incorrect results, and harms following
781"
BROADER IMPACTS,0.9036269430051813,"from (intentional or unintentional) misuse of the technology.
782"
BROADER IMPACTS,0.9046632124352332,"• If there are negative societal impacts, the authors could also discuss possible mitigation
783"
BROADER IMPACTS,0.9056994818652849,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
784"
BROADER IMPACTS,0.9067357512953368,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
785"
BROADER IMPACTS,0.9077720207253887,"feedback over time, improving the efficiency and accessibility of ML).
786"
SAFEGUARDS,0.9088082901554404,"11. Safeguards
787"
SAFEGUARDS,0.9098445595854923,"Question: Does the paper describe safeguards that have been put in place for responsible
788"
SAFEGUARDS,0.910880829015544,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
789"
SAFEGUARDS,0.9119170984455959,"image generators, or scraped datasets)?
790"
SAFEGUARDS,0.9129533678756476,"Answer: [NA]
791"
SAFEGUARDS,0.9139896373056995,"Justification: Our paper poses no such risks for high risk for misuse.
792"
SAFEGUARDS,0.9150259067357513,"Guidelines:
793"
SAFEGUARDS,0.9160621761658031,"• The answer NA means that the paper poses no such risks.
794"
SAFEGUARDS,0.917098445595855,"• Released models that have a high risk for misuse or dual-use should be released with
795"
SAFEGUARDS,0.9181347150259067,"necessary safeguards to allow for controlled use of the model, for example by requiring
796"
SAFEGUARDS,0.9191709844559586,"that users adhere to usage guidelines or restrictions to access the model or implementing
797"
SAFEGUARDS,0.9202072538860103,"safety filters.
798"
SAFEGUARDS,0.9212435233160622,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
799"
SAFEGUARDS,0.9222797927461139,"should describe how they avoided releasing unsafe images.
800"
SAFEGUARDS,0.9233160621761658,"• We recognize that providing effective safeguards is challenging, and many papers do
801"
SAFEGUARDS,0.9243523316062177,"not require this, but we encourage authors to take this into account and make a best
802"
SAFEGUARDS,0.9253886010362694,"faith effort.
803"
LICENSES FOR EXISTING ASSETS,0.9264248704663213,"12. Licenses for existing assets
804"
LICENSES FOR EXISTING ASSETS,0.927461139896373,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
805"
LICENSES FOR EXISTING ASSETS,0.9284974093264249,"the paper, properly credited and are the license and terms of use explicitly mentioned and
806"
LICENSES FOR EXISTING ASSETS,0.9295336787564766,"properly respected?
807"
LICENSES FOR EXISTING ASSETS,0.9305699481865285,"Answer: [Yes]
808"
LICENSES FOR EXISTING ASSETS,0.9316062176165804,"Justification: We reported owners of assets used in the paper in the Appendix
809"
LICENSES FOR EXISTING ASSETS,0.9326424870466321,"Guidelines:
810"
LICENSES FOR EXISTING ASSETS,0.933678756476684,"• The answer NA means that the paper does not use existing assets.
811"
LICENSES FOR EXISTING ASSETS,0.9347150259067357,"• The authors should cite the original paper that produced the code package or dataset.
812"
LICENSES FOR EXISTING ASSETS,0.9357512953367876,"• The authors should state which version of the asset is used and, if possible, include a
813"
LICENSES FOR EXISTING ASSETS,0.9367875647668393,"URL.
814"
LICENSES FOR EXISTING ASSETS,0.9378238341968912,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
815"
LICENSES FOR EXISTING ASSETS,0.938860103626943,"• For scraped data from a particular source (e.g., website), the copyright and terms of
816"
LICENSES FOR EXISTING ASSETS,0.9398963730569948,"service of that source should be provided.
817"
LICENSES FOR EXISTING ASSETS,0.9409326424870467,"• If assets are released, the license, copyright information, and terms of use in the
818"
LICENSES FOR EXISTING ASSETS,0.9419689119170984,"package should be provided. For popular datasets, paperswithcode.com/datasets
819"
LICENSES FOR EXISTING ASSETS,0.9430051813471503,"has curated licenses for some datasets. Their licensing guide can help determine the
820"
LICENSES FOR EXISTING ASSETS,0.944041450777202,"license of a dataset.
821"
LICENSES FOR EXISTING ASSETS,0.9450777202072539,"• For existing datasets that are re-packaged, both the original license and the license of
822"
LICENSES FOR EXISTING ASSETS,0.9461139896373058,"the derived asset (if it has changed) should be provided.
823"
LICENSES FOR EXISTING ASSETS,0.9471502590673575,"• If this information is not available online, the authors are encouraged to reach out to
824"
LICENSES FOR EXISTING ASSETS,0.9481865284974094,"the asset’s creators.
825"
NEW ASSETS,0.9492227979274611,"13. New Assets
826"
NEW ASSETS,0.950259067357513,"Question: Are new assets introduced in the paper well documented and is the documentation
827"
NEW ASSETS,0.9512953367875647,"provided alongside the assets?
828"
NEW ASSETS,0.9523316062176166,"Answer: [Yes]
829"
NEW ASSETS,0.9533678756476683,"Justification: Considering our implemtation code is our asset, our work provides necessary
830"
NEW ASSETS,0.9544041450777202,"license and documents for further usage.
831"
NEW ASSETS,0.9554404145077721,"Guidelines:
832"
NEW ASSETS,0.9564766839378238,"• The answer NA means that the paper does not release new assets.
833"
NEW ASSETS,0.9575129533678757,"• Researchers should communicate the details of the dataset/code/model as part of their
834"
NEW ASSETS,0.9585492227979274,"submissions via structured templates. This includes details about training, license,
835"
NEW ASSETS,0.9595854922279793,"limitations, etc.
836"
NEW ASSETS,0.960621761658031,"• The paper should discuss whether and how consent was obtained from people whose
837"
NEW ASSETS,0.9616580310880829,"asset is used.
838"
NEW ASSETS,0.9626943005181348,"• At submission time, remember to anonymize your assets (if applicable). You can either
839"
NEW ASSETS,0.9637305699481865,"create an anonymized URL or include an anonymized zip file.
840"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9647668393782384,"14. Crowdsourcing and Research with Human Subjects
841"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9658031088082901,"Question: For crowdsourcing experiments and research with human subjects, does the paper
842"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.966839378238342,"include the full text of instructions given to participants and screenshots, if applicable, as
843"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9678756476683937,"well as details about compensation (if any)?
844"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9689119170984456,"Answer: [NA]
845"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9699481865284975,"Justification: Our work does not involve crowdsourcing nor research with human subjects.
846"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9709844559585492,"Guidelines:
847"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9720207253886011,"• The answer NA means that the paper does not involve crowdsourcing nor research with
848"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9730569948186528,"human subjects.
849"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9740932642487047,"• Including this information in the supplemental material is fine, but if the main contribu-
850"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9751295336787564,"tion of the paper involves human subjects, then as much detail as possible should be
851"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9761658031088083,"included in the main paper.
852"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9772020725388602,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
853"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9782383419689119,"or other labor should be paid at least the minimum wage in the country of the data
854"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9792746113989638,"collector.
855"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9803108808290155,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
856"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9813471502590674,"Subjects
857"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9823834196891191,"Question: Does the paper describe potential risks incurred by study participants, whether
858"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.983419689119171,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
859"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9844559585492227,"approvals (or an equivalent approval/review based on the requirements of your country or
860"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9854922279792746,"institution) were obtained?
861"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9865284974093265,"Answer: [NA]
862"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9875647668393782,"Justification: Our work does not require IRB approvals and does not involve human subjects.
863"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9886010362694301,"Guidelines:
864"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9896373056994818,"• The answer NA means that the paper does not involve crowdsourcing nor research with
865"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9906735751295337,"human subjects.
866"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9917098445595854,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
867"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9927461139896373,"may be required for any human subjects research. If you obtained IRB approval, you
868"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9937823834196892,"should clearly state this in the paper.
869"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9948186528497409,"• We recognize that the procedures for this may vary significantly between institutions
870"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9958549222797928,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
871"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9968911917098445,"guidelines for their institution.
872"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9979274611398964,"• For initial submissions, do not include any information that would break anonymity (if
873"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9989637305699481,"applicable), such as the institution conducting the review.
874"
