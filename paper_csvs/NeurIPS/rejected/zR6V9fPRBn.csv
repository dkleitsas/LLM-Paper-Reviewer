Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0018315018315018315,"Healthcare analytics, particularly binary diagnosis or prognosis problems, present
1"
ABSTRACT,0.003663003663003663,"unique challenges due to the inherent asymmetry between positive and negative
2"
ABSTRACT,0.005494505494505495,"samples. While positive samples, representing patients who develop a disease,
3"
ABSTRACT,0.007326007326007326,"are defined through rigorous medical criteria, negative samples are defined in an
4"
ABSTRACT,0.009157509157509158,"open-ended manner, resulting in a vast potential set. Despite this fundamental
5"
ABSTRACT,0.01098901098901099,"asymmetry, previous research has underexplored the role of negative samples,
6"
ABSTRACT,0.01282051282051282,"possibly due to the enormous challenge of investigating an infinitely large negative
7"
ABSTRACT,0.014652014652014652,"sample space. To bridge this gap, we propose an approach to facilitate cohort
8"
ABSTRACT,0.016483516483516484,"discovery within negative samples, which could yield valuable insights into the
9"
ABSTRACT,0.018315018315018316,"studied disease, as well as its comorbidity and complications. We measure each
10"
ABSTRACT,0.020146520146520148,"sample’s contribution using data Shapley values and construct the Negative Sample
11"
ABSTRACT,0.02197802197802198,"Shapley Field to model the distribution of all negative samples. Then we transform
12"
ABSTRACT,0.023809523809523808,"this field via manifold learning, preserving the data structure information while
13"
ABSTRACT,0.02564102564102564,"imposing an isotropy constraint in data Shapley values. Within this transformed
14"
ABSTRACT,0.027472527472527472,"space, we identify cohorts of medical interest through density-based clustering. We
15"
ABSTRACT,0.029304029304029304,"empirically evaluate the effectiveness of our approach on our hospital’s electronic
16"
ABSTRACT,0.031135531135531136,"medical records. The medical insights revealed in the discovered cohorts are
17"
ABSTRACT,0.03296703296703297,"validated by clinicians, which affirms the medical value of our proposal in unveiling
18"
ABSTRACT,0.0347985347985348,"meaningful insights consistent with existing domain knowledge, thereby bolstering
19"
ABSTRACT,0.03663003663003663,"medical research and well-informed clinical decision-making.
20"
INTRODUCTION,0.038461538461538464,"1
Introduction
21"
INTRODUCTION,0.040293040293040296,"Healthcare analytics leverages diverse healthcare data sources to perform many analytic tasks in-
22"
INTRODUCTION,0.04212454212454213,"cluding diagnosis [28] and prognosis [35]. Electronic Medical Records (EMR) are perhaps the
23"
INTRODUCTION,0.04395604395604396,"most important of these data sources, since they play a crucial role in recording patients’ essential
24"
INTRODUCTION,0.045787545787545784,"information and providing a comprehensive view of their health conditions. The recently increasing
25"
INTRODUCTION,0.047619047619047616,"availability of EMR data has spawned the development of healthcare analytics models for effective
26"
INTRODUCTION,0.04945054945054945,"patient management and medical resource allocation.
27"
INTRODUCTION,0.05128205128205128,"Without loss of generality, let us delve into a diagnosis or prognosis problem of predicting whether a
28"
INTRODUCTION,0.05311355311355311,"patient has developed/will develop a certain disease based on the EMR data. This problem is a binary
29"
INTRODUCTION,0.054945054945054944,"classification, where patients who develop the disease are “positive samples”, while those who do
30"
INTRODUCTION,0.056776556776556776,"not are “negative samples”. Notably, we identify the unique nature of such binary classifications in
31"
INTRODUCTION,0.05860805860805861,"healthcare analytics, as compared to traditional classification tasks. For instance, when classifying
32"
INTRODUCTION,0.06043956043956044,"cats vs. dogs, both positive and negative samples are based on objective facts. However, in healthcare
33"
INTRODUCTION,0.06227106227106227,"analytics, positive samples are defined according to rigorous medical criteria, based on medical
34"
INTRODUCTION,0.0641025641025641,"theories and experience. Contrarily, negative samples are defined in an unrestricted manner, as the
35"
INTRODUCTION,0.06593406593406594,"complementary set of the positive samples. Consequently, the set of negative samples may encompass
36"
INTRODUCTION,0.06776556776556776,"a vast number of diverse individuals who are outside the scope of the studied disease or who are
37"
INTRODUCTION,0.0695970695970696,"healthy. This leads to an inherent asymmetry between positive and negative samples, as positive
38"
INTRODUCTION,0.07142857142857142,"samples are well-defined and bounded, while negative samples are diverse and open-ended.
39"
INTRODUCTION,0.07326007326007326,"Despite such fundamental asymmetry in healthcare analytics, previous research has not adequately
40"
INTRODUCTION,0.07509157509157509,"addressed the role of negative samples. One potential reason for this research gap is the enormous
41"
INTRODUCTION,0.07692307692307693,"challenge posed by investigating an infinitely large negative sample space, which cannot be easily
42"
INTRODUCTION,0.07875457875457875,"addressed using existing approaches, e.g., it could be difficult to understand why general healthy
43"
INTRODUCTION,0.08058608058608059,"individuals do not develop a disease. Nonetheless, it is crucial to probe into negative samples for a
44"
INTRODUCTION,0.08241758241758242,"more comprehensive investigation of the studied disease. Although it may not have developed in
45"
INTRODUCTION,0.08424908424908426,"these samples, some may exhibit similar symptoms or even develop related conditions such as its
46"
INTRODUCTION,0.08608058608058608,"comorbidity or complications. Hence, these negative samples are in urgent need of close medical
47"
INTRODUCTION,0.08791208791208792,"attention, as they provide an opportunity for clinicians to gain a deeper understanding of the studied
48"
INTRODUCTION,0.08974358974358974,"disease, leading to more accurate and comprehensive diagnoses, prognoses, and treatment plans.
49"
INTRODUCTION,0.09157509157509157,"In this paper, we aim to address the gap by exploring negative samples in healthcare analytics.
50"
INTRODUCTION,0.09340659340659341,"Given the diversity of negative samples, it may not be meaningful to consider them all as one
51"
INTRODUCTION,0.09523809523809523,"“group”. Instead, we examine the underlying distribution of negative samples to automatically identify
52"
INTRODUCTION,0.09706959706959707,"medically insightful groups of patients with shared characteristics, referred to as “cohorts” [32, 49].
53"
INTRODUCTION,0.0989010989010989,"Such cohort discovery among negative samples can provide fresh insights to clinicians on the
54"
INTRODUCTION,0.10073260073260074,"studied disease, e.g., comprehending the factors contributing to the absence of the disease and the
55"
INTRODUCTION,0.10256410256410256,"development of related conditions.
56"
INTRODUCTION,0.1043956043956044,"As front-line clinicians and medical researchers, we bring a unique perspective to guide our method-
57"
INTRODUCTION,0.10622710622710622,"ology design in effectively discovering cohorts among negative samples. In Sec. 3, we elaborate
58"
INTRODUCTION,0.10805860805860806,"on our approach with three components. Firstly, we propose to quantify each sample’s contribution
59"
INTRODUCTION,0.10989010989010989,"to the prediction task using data Shapley values [38, 12]. We then construct the Negative Sample
60"
INTRODUCTION,0.11172161172161173,"Shapley Field, an inherently existing scalar field describing the distribution and characteristics of all
61"
INTRODUCTION,0.11355311355311355,"negative samples (Sec. 3.1). Secondly, to effectively discover cohorts, we transform the original field
62"
INTRODUCTION,0.11538461538461539,"by manifold learning [3] while preserving the original data structure information and ensuring that
63"
INTRODUCTION,0.11721611721611722,"changes in data Shapley values are isotropic in all orientations (Sec. 3.2). Thirdly, in the transformed
64"
INTRODUCTION,0.11904761904761904,"manifold space, we identify densely-connected clusters among the negative samples with high data
65"
INTRODUCTION,0.12087912087912088,"Shapley values through DBSCAN (Sec. 3.3). These clusters help us locate “hot zones”, which are our
66"
INTRODUCTION,0.1227106227106227,"desired cohorts to discover, exhibiting similar medical characteristics with high data Shapley values.
67"
INTRODUCTION,0.12454212454212454,"Our contributions are summarized below: (i) We bridge the research gap caused by the asymmetry
68"
INTRODUCTION,0.12637362637362637,"between positive and negative samples in healthcare analytics by exploring negative samples for
69"
INTRODUCTION,0.1282051282051282,"cohort discovery. (ii) We propose an innovative approach for effective cohort discovery: constructing
70"
INTRODUCTION,0.13003663003663005,"the Negative Sample Shapley Field, transforming the field by manifold learning with structure
71"
INTRODUCTION,0.13186813186813187,"preservation and isotropy constraint, and discovering cohorts in the manifold space via DBSCAN.
72"
INTRODUCTION,0.1336996336996337,"(iii) We empirically evaluate the effectiveness of our approach using our hospital’s EMR (Sec. 4).
73"
INTRODUCTION,0.13553113553113552,"The experimental results validate the efficacy of each component and demonstrate the capability of
74"
INTRODUCTION,0.13736263736263737,"our approach for cohort discovery, unveiling meaningful insights that align with existing domain
75"
INTRODUCTION,0.1391941391941392,"knowledge and have been verified by clinicians. These findings have the potential to benefit medical
76"
INTRODUCTION,0.14102564102564102,"practitioners by facilitating medical research and clinical decision-making in healthcare delivery.
77"
PROBLEM AND OUR SOLUTION,0.14285714285714285,"2
Problem and Our Solution
78"
PROBLEM AND OUR SOLUTION,0.1446886446886447,"Distinctiveness of negative samples and the unbounded negative sample space. Let us take
79"
PROBLEM AND OUR SOLUTION,0.14652014652014653,"hospital-acquired acute kidney injury (AKI), a disease we strive to handle in practice, as an example.
80"
PROBLEM AND OUR SOLUTION,0.14835164835164835,"AKI is defined according to KDIGO criteria [19] based on a lab test, serum creatinine (sCr). The
81"
PROBLEM AND OUR SOLUTION,0.15018315018315018,"disease definition has two criteria: absolute AKI and relative AKI. Absolute AKI criterion is met
82"
PROBLEM AND OUR SOLUTION,0.152014652014652,"when sCr exhibits a rise exceeding 26.5 umol/L within the last two days, whereas relative AKI is
83"
PROBLEM AND OUR SOLUTION,0.15384615384615385,"defined by a rise of sCr 1.5 times or higher over the lowest sCr value within 7 days. In this AKI
84"
PROBLEM AND OUR SOLUTION,0.15567765567765568,"prediction task, we aim to predict if a patient will develop AKI in the near future. A positive sample
85"
PROBLEM AND OUR SOLUTION,0.1575091575091575,"is a patient who meets the stringent criteria above, and hence, has a closed definition, whereas a
86"
PROBLEM AND OUR SOLUTION,0.15934065934065933,"negative sample has an open definition without restrictions. Hence, negative samples in nature form
87"
PROBLEM AND OUR SOLUTION,0.16117216117216118,"an unbounded space, demonstrating an asymmetry compared to positive samples.
88"
PROBLEM AND OUR SOLUTION,0.163003663003663,"Construction of the Negative Sample Shapley Field for cohort discovery. To facilitate the analysis
89"
PROBLEM AND OUR SOLUTION,0.16483516483516483,"of negative samples, we need to investigate their distribution and identify those that are most relevant
90"
PROBLEM AND OUR SOLUTION,0.16666666666666666,"to the prediction task (e.g., AKI prediction task above) and hence worth exploring. In this regard,
91"
PROBLEM AND OUR SOLUTION,0.1684981684981685,"we propose to measure the valuation of each negative sample to the task by its data Shapley value.
92"
PROBLEM AND OUR SOLUTION,0.17032967032967034,"Based on such valuations, we construct a scalar field, the Negative Sample Shapley Field, in which
93"
PROBLEM AND OUR SOLUTION,0.17216117216117216,"each point is a negative sample, and the point’s value is its data Shapley value. This field depicts the
94"
PROBLEM AND OUR SOLUTION,0.17399267399267399,(b) Mis-discovered hot zones in the
PROBLEM AND OUR SOLUTION,0.17582417582417584,"Negative Sample Shapley Field
(a) Discovered hot zone in the Negative Sample Shapley"
PROBLEM AND OUR SOLUTION,0.17765567765567766,Field by clustering high-value negative samples
PROBLEM AND OUR SOLUTION,0.1794871794871795,(c) Manifold space integrating data structure
PROBLEM AND OUR SOLUTION,0.1813186813186813,information and isotropy constraint
PROBLEM AND OUR SOLUTION,0.18315018315018314,Figure 1: Discovery of hot zones in the Negative Sample Shapley Field.
PROBLEM AND OUR SOLUTION,0.184981684981685,"distribution and characteristics of negative samples (see Figure 1(a) for an example). We define “hot
95"
PROBLEM AND OUR SOLUTION,0.18681318681318682,"zones” in this field, identified by points with high data Shapley values, as “cohorts”. Our objective
96"
PROBLEM AND OUR SOLUTION,0.18864468864468864,"is to automatically detect these cohorts, revealing medically meaningful patterns.
97"
PROBLEM AND OUR SOLUTION,0.19047619047619047,"Cohort discovery via manifold learning and density-based clustering. We note that the vast
98"
PROBLEM AND OUR SOLUTION,0.19230769230769232,"number of negative samples renders an exhaustive search infeasible. Although the Negative Sample
99"
PROBLEM AND OUR SOLUTION,0.19413919413919414,"Shapley Field is continuously differentiable, the high computational overhead makes it intractable to
100"
PROBLEM AND OUR SOLUTION,0.19597069597069597,"find local optima via gradient descent. To overcome this obstacle, we make the assumption that a
101"
PROBLEM AND OUR SOLUTION,0.1978021978021978,"subset of negative samples collected in clinical practice carries significant medical value, e.g., patients
102"
PROBLEM AND OUR SOLUTION,0.19963369963369965,"who visit hospitals for examinations but do not develop the disease. We posit that these real-world
103"
PROBLEM AND OUR SOLUTION,0.20146520146520147,"negative samples should be proximate to our desired hot zones in the space and can effectively sample
104"
PROBLEM AND OUR SOLUTION,0.2032967032967033,"our hot zone boundaries, which are hence of medical interest.
105"
PROBLEM AND OUR SOLUTION,0.20512820512820512,"In Figure 1, we exemplify how to discover hot zones in the Negative Sample Shapley Field. Figure 1(a)
106"
PROBLEM AND OUR SOLUTION,0.20695970695970695,"and (b) demonstrate four points situated on the same contour line, indicating their inclusion in the
107"
PROBLEM AND OUR SOLUTION,0.2087912087912088,"same hot zone. However, only the former case yields the expected discovered cohort, while the latter
108"
PROBLEM AND OUR SOLUTION,0.21062271062271062,"leads to mis-discovery. This highlights that the originally constructed Negative Sample Shapley
109"
PROBLEM AND OUR SOLUTION,0.21245421245421245,"Field is suboptimal for cohort discovery among negative samples, due to its anisotropy in data
110"
PROBLEM AND OUR SOLUTION,0.21428571428571427,"Shapley values. To overcome this issue, we propose a manifold learning approach. Specifically,
111"
PROBLEM AND OUR SOLUTION,0.21611721611721613,"we leverage manifold learning to reduce the dimensionality of the raw sparse EMR data to derive
112"
PROBLEM AND OUR SOLUTION,0.21794871794871795,"compact representations that not only preserve the underlying data structure information but also
113"
PROBLEM AND OUR SOLUTION,0.21978021978021978,"benefit subsequent spatial clustering analysis. Further, we introduce an isotropy constraint to ensure
114"
PROBLEM AND OUR SOLUTION,0.2216117216117216,"uniform changes in data Shapley values across all orientations, which prevents the mis-discovery
115"
PROBLEM AND OUR SOLUTION,0.22344322344322345,"as in Figure 1(b). This transformed space, integrating data structure information and the isotropy
116"
PROBLEM AND OUR SOLUTION,0.22527472527472528,"constraint, is more suitable for subsequent cohort discovery as illustrated in Figure 1(c).
117"
PROBLEM AND OUR SOLUTION,0.2271062271062271,"Our objective is then to identify medically meaningful cohorts, specifically dense regions formed by
118"
PROBLEM AND OUR SOLUTION,0.22893772893772893,"negative samples with high data Shapley values in the manifold space. We set a data Shapley value
119"
PROBLEM AND OUR SOLUTION,0.23076923076923078,"threshold to extract negative samples with high values and employ the DBSCAN algorithm to detect
120"
PROBLEM AND OUR SOLUTION,0.2326007326007326,"the hot zones among them. The derived cohorts could shed light on the studied disease, its related
121"
PROBLEM AND OUR SOLUTION,0.23443223443223443,"comorbidity, and complications, thereby empowering clinicians in practical healthcare delivery.
122"
METHODOLOGY,0.23626373626373626,"3
Methodology
123"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.23809523809523808,"3.1
Negative Sample Shapley Field Construction
124"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.23992673992673993,"Given EMR data D = {di}, where di is a sample with i ∈{0, . . . , N −1} and N denotes the
125"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.24175824175824176,"total sample number. We focus on binary classification, and each di consists of input features and a
126"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.24358974358974358,"binary label. To investigate negative samples for cohort discovery, we divide D into D+ and D−,
127"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2454212454212454,"representing positive and negative samples. We denote D−= {d−
i }, where d−
i is a negative sample
128"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.24725274725274726,"with i ∈{0, . . . , N −−1} and N −is the negative sample number.
129"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2490842490842491,"Each negative sample d−
i = (xi, yi) comprises the input features xi and its corresponding binary
130"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2509157509157509,"label yi. Our objective is to measure the value of each negative sample by quantifying its contribution
131"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.25274725274725274,"to the prediction performance, which we refer to as data valuation. Data Shapley value [12], stemming
132"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.25457875457875456,"from Shapley value in cooperative game theory, has made significant advances in data valuation [38],
133"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2564102564102564,"which inspires our proposal to calculate the data Shapley value of each negative sample as its value.
134"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.25824175824175827,"Specifically, let F denote the prediction model and suppose we are interested in evaluating F’s
135"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2600732600732601,"performance on a subset of negative samples Q ⊆D−, along with all the positive samples D+. We
136"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2619047619047619,"define M as the performance metric function, and then M(D+ ∪Q, F) is the performance achieved
137"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.26373626373626374,"on the combined set of D+ and Q. We define si as the data Shapley value for the negative sample
138"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.26556776556776557,"d−
i . si satisfies three properties of Shapley values: (i) null player, (ii) symmetry, and (iii) linearity,
139"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2673992673992674,"which are the essential properties of an equitable data valuation [12]. We calculate si as follows.
140"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2692307692307692,"Proposition 1 The data Shapley value si for a negative sample d−
i is given by:
141"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.27106227106227104,"si = H
X"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.27289377289377287,"Q⊆D−−{d−
i }"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.27472527472527475,"M(D+ ∪Q ∪{d−
i }, F) −M(D+ ∪Q, F)

N −−1
|Q| 
(1)"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2765567765567766,"where H is a constant and the summation is taken over all subsets of negative samples, except d−
i .
142"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2783882783882784,"As the computation of data Shapley value for negative samples has exponential complexity, we
143"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2802197802197802,"further employ Monte Carlo permutation sampling for approximation [6]. Let Π represent a uniform
144"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.28205128205128205,"distribution of all the permutations among D−, si can be approximated as the following expectation:
145"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2838827838827839,"si = Eπ∼Π[M(D+ ∪A
d−
i
π
∪{d−
i }, F) −M(D+ ∪A
d−
i
π , F)]
(2)"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2857142857142857,"where A
d−
i
π
denotes all the negative samples before d−
i in a permutation π. By repeating this
146"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2875457875457875,"approximation, we can derive the estimated data Shapley value si efficiently. After computing the
147"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2893772893772894,"data Shapley value of each negative sample, we define the Negative Sample Shapley Field below.
148"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.29120879120879123,"Definition 1 (Negative Sample Shapley Field) We define the Negative Sample Shapley Field S as an
149"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.29304029304029305,"inherently existing scalar field representing the distribution of data Shapley values across all negative
150"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2948717948717949,"samples in space. In this field, each point denotes a negative sample d−
i and is associated with its
151"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.2967032967032967,"data Shapley value si. Therefore, S is a mathematical function that maps the input of each negative
152"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.29853479853479853,"sample to its corresponding data Shapley value: xi 7→si.
153"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.30036630036630035,"With this field S constructed, our goal of cohort discovery within negative samples can be reframed
154"
NEGATIVE SAMPLE SHAPLEY FIELD CONSTRUCTION,0.3021978021978022,"as the task of identifying “hot zones” - grouped regions within S exhibiting high data Shapley values.
155"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.304029304029304,"3.2
Manifold Learning with Structure Preservation and Isotropy Constraint
156"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.3058608058608059,"As in Figure 1(a) and (b), although we hope to detect a similarly clustered cohort in the Negative
157"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.3076923076923077,"Sample Shapley Field in both scenarios, the anisotropic nature of the space, i.e., the non-uniform
158"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.30952380952380953,"distribution of negative samples with similar data Shapley values, present significant challenges. To
159"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.31135531135531136,"mitigate these challenges, we propose to employ manifold learning [3] to transform the original space
160"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.3131868131868132,"S into a new geometric space S′. As elaborated in Sec. 2, to avoid mis-discovery such as Figure 1(b),
161"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.315018315018315,"we should simultaneously preserve the underlying structural information in the data while imposing
162"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.31684981684981683,"an isotropy constraint on the data Shapley values in S′. The resulting S′ will be more amenable to
163"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.31868131868131866,"effective cohort discovery, enabling us to identify medically relevant cohorts more accurately.
164"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.32051282051282054,"We employ a stacked denoising autoencoder (SDAE) [44] as the backbone model for manifold
165"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.32234432234432236,"learning and integrate the isotropy constraint while preserving the data structure information in xi.
166"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.3241758241758242,"Autoencoders (AE) [23, 22] are well-known for capturing data structures by reconstructing input data.
167"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.326007326007326,"Denoising autoencoders (DAE) [43] are further developed to enhance the learned representations
168"
MANIFOLD LEARNING WITH STRUCTURE PRESERVATION AND ISOTROPY CONSTRAINT,0.32783882783882784,"with the capability of handling input data corruption. By stacking multiple layers of DAE, SDAE can
169"
ABSTRACT,0.32967032967032966,"abstract higher-level robust representations. The model architecture is illustrated in Figure 2.
170"
ABSTRACT,0.3315018315018315,"Consider an SDAE consisting of K DAEs. For the k-th DAE (k ∈{0, . . . , K −1}), the encoder takes
171"
ABSTRACT,0.3333333333333333,"h(k)
i
as input, where h(0)
i
= xi corresponds to the original input. We define ˜h(k)
i
as the corrupted
172"
ABSTRACT,0.33516483516483514,"version of h(k)
i
with masking noise generated by a stochastic mapping, ˜h(k)
i
∼gD(˜h(k)
i
|h(k)
i
), which
173"
ABSTRACT,0.336996336996337,"randomly sets a fraction of the elements of h(k)
i
to 0. The encoder transforms the corrupted ˜h(k)
i
174"
ABSTRACT,0.33882783882783885,"into an abstract representation ˆh(k+1)
i
, which is then used by the decoder to recover the uncorrupted
175"
ABSTRACT,0.34065934065934067,"h(k)
i
. This process equips the DAE with the capability of extracting useful information for denoising,
176"
ABSTRACT,0.3424908424908425,"which is crucial for healthcare analytics, due to missing data and noise in real-world EMR data [26].
177"
ABSTRACT,0.3443223443223443,"Encoder of the k-th DAE. The encoder of the k-th DAE transforms the corrupted representation
178"
ABSTRACT,0.34615384615384615,"using an affine transformation followed by a non-linear activation function:
179"
ABSTRACT,0.34798534798534797,"ˆh(k+1)
i
= f (k+1)
θ
(˜h(k)
i
) = σ(W(k+1)
θ
˜h(k)
i
+ b(k+1)
θ
)
(3) 𝐳! ""
""𝐡! "" 𝒈𝓓 %𝐡! ""$% 𝑓&"
ABSTRACT,0.3498168498168498,"""$%
𝑓'"
ABSTRACT,0.3516483516483517,"""$%
ℒ()*"
ABSTRACT,0.3534798534798535,"""
ℒ!+, "" 𝐡! ""
𝐡! "" 𝑓& ""$% 𝐡!"
ABSTRACT,0.3553113553113553,"""$%
𝐡! "" 𝐡! ""$% 𝐱!"
ABSTRACT,0.35714285714285715,"(a) 𝑘-th DAE
(b) Trained encoder is applied on clean input
(c) Repeated procedure"
ABSTRACT,0.358974358974359,Figure 2: Model architecture of SDAE-based manifold learning.
ABSTRACT,0.3608058608058608,"where f (k+1)
θ
(·) is the encoder with W(k+1)
θ
and b(k+1)
θ
as the weight matrix and bias vector,
180"
ABSTRACT,0.3626373626373626,"respectively. The rectified linear unit (ReLU) activation function σ(·) is used for non-linearity.
181"
ABSTRACT,0.36446886446886445,"Decoder of the k-th DAE. The derived abstract representation ˆh(k+1)
i
is subsequently mapped back
182"
ABSTRACT,0.3663003663003663,"to the original space in the decoder, with the aim of recovering the uncorrupted representation:
183"
ABSTRACT,0.36813186813186816,"z(k)
i
= f (k+1)
ϕ
(ˆh(k+1)
i
) = σ(W(k+1)
ϕ
ˆh(k+1)
i
+ b(k+1)
ϕ
)
(4)"
ABSTRACT,0.36996336996337,"where f (k+1)
ϕ
(·) is the decoder of the k-th DAE, with W(k+1)
ϕ
, b(k+1)
ϕ
and the ReLU activation.
184"
ABSTRACT,0.3717948717948718,"Structure Preservation. To attain a stable and robust abstract representation that is resilient to data
185"
ABSTRACT,0.37362637362637363,"corruption, it is crucial to recover the uncorrupted representation as accurately as possible. To achieve
186"
ABSTRACT,0.37545787545787546,"this, we adopt a reconstruction loss that preserves the data structure information. Given a batch of
187"
ABSTRACT,0.3772893772893773,"negative samples B, the reconstruction loss for this batch is:
188"
ABSTRACT,0.3791208791208791,"L(k)
rec =
X"
ABSTRACT,0.38095238095238093,"i∈B
∥h(k)
i
−z(k)
i
∥2
(5)"
ABSTRACT,0.38278388278388276,"Isotropy Constraint. In addition to the reconstruction loss, it is essential to enforce an isotropy
189"
ABSTRACT,0.38461538461538464,"constraint to ensure that data Shapley value changes are uniform across orientations. To achieve this,
190"
ABSTRACT,0.38644688644688646,"we introduce a penalty that accounts for the change in data Shapley values relative to the Euclidean
191"
ABSTRACT,0.3882783882783883,"distance between two samples:
192"
ABSTRACT,0.3901098901098901,"L(k)
iso =
X"
ABSTRACT,0.39194139194139194,"i,j∈B
(sj −si"
ABSTRACT,0.39377289377289376,"µij
)2
(6)"
ABSTRACT,0.3956043956043956,"where i, j are two samples with si, sj as their data Shapley values, µij as the distance between ˆh(k+1)
i
193"
ABSTRACT,0.3974358974358974,"and ˆh(k+1)
j
derived from the encoder. The overall loss is then a weighted sum of the reconstruction loss
194"
ABSTRACT,0.3992673992673993,"and the isotropy penalty, jointly integrating the structural information and the isotropy information:
195"
ABSTRACT,0.4010989010989011,L(k) = −1
ABSTRACT,0.40293040293040294,"|B|(ωrecL(k)
rec + ωisoL(k)
iso)
(7)"
ABSTRACT,0.40476190476190477,"The weights ωrec and ωiso are introduced to address the issue of the two loss terms being on different
196"
ABSTRACT,0.4065934065934066,"scales. This ensures that both losses are decreased at similar rates, leading to a better balance
197"
ABSTRACT,0.4084249084249084,"between the optimization objectives [14, 29]. Specifically, the weights are set to the ratio between the
198"
ABSTRACT,0.41025641025641024,"respective loss in the current iteration (t) and the loss in the previous iteration (t −1):
199"
ABSTRACT,0.41208791208791207,"ωrec = L(k)
rec(t)/L(k)
rec(t −1),
ωiso = L(k)
iso(t)/L(k)
iso(t −1)
(8)"
ABSTRACT,0.4139194139194139,"We have introduced how to learn the k-th DAE using the loss function in Equation 7, as shown
200"
ABSTRACT,0.4157509157509158,"in Figure 2(a). The corrupted input is only used during the initial training to learn robust feature
201"
ABSTRACT,0.4175824175824176,"extractors. After the encoder f (k+1)
θ
(·) is trained, it will be applied to the clean input as in Figure 2(b):
202"
ABSTRACT,0.4194139194139194,"h(k+1)
i
= f (k+1)
θ
(h(k)
i
) = σ(W(k+1)
θ
h(k)
i
+ b(k+1)
θ
)
(9)"
ABSTRACT,0.42124542124542125,"h(k+1)
i
will be used as input for the (k+1)-th DAE, as in Figure 2(c), to continue the repeated training
203"
ABSTRACT,0.4230769230769231,"process. When the last DAE, i.e., (K −1)-th DAE, is trained, we obtain the encoded representation
204"
ABSTRACT,0.4249084249084249,"h(K)
i
in the manifold space S′, which preserves the data structure information in xi and integrates
205"
ABSTRACT,0.4267399267399267,"the desired isotropy constraint. h(K)
i
will serve as input for subsequent medical cohort discovery.
206"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.42857142857142855,"3.3
Cohort Discovery Among High Data Shapley Value Negative Samples
207"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.43040293040293043,"We proceed to perform cohort discovery in the encoded manifold space S′, where each negative
208"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.43223443223443225,"sample’s input xi is transformed into h(K)
i
. We begin by setting a threshold value τ to filter out
209"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.4340659340659341,"negative samples with data Shapley values below τ, which focuses our analysis on negative samples
210"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.4358974358974359,"with high data Shapley values, i.e., high contributions to the prediction task. Among the remaining
211"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.43772893772893773,"negative samples with high data Shapley values, we target to detect the hot zones in S′, which may
212"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.43956043956043955,"represent medically meaningful cohorts of arbitrary shape.
213"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.4413919413919414,"To achieve this, we employ DBSCAN, short for density-based spatial clustering of applications with
214"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.4432234432234432,"noise [9, 10, 39] on such samples. The core idea of DBSCAN is to group samples that are close
215"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.44505494505494503,"to each other in the manifold space S′ into clusters, which could locate potential cohorts, whereas
216"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.4468864468864469,"treating the remaining samples as noise or outliers. DBSCAN has three main steps: (i) identify the
217"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.44871794871794873,"points within each point’s ε- neighborhood and determine the “core points” with over Pmin neighbors;
218"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.45054945054945056,"(ii) detect the connected components of the core points in the neighbor graph, disregarding any non-
219"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.4523809523809524,"core points; (iii) assign each non-core point to the clusters which are the ε-neighborhood of the point;
220"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.4542124542124542,"otherwise, label the point as noise. This process results in a set of clusters {C1, C2, . . . , CR} and a
221"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.45604395604395603,"set of noisy samples Ψ. Given the clusters, we define cohorts as follows.
222"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.45787545787545786,"Definition 2 (Cohorts) For a dense cluster Cr identified by the DBSCAN algorithm, we consider
223"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.4597069597069597,"each of its core points and define a spherical space with the core point as its center and ε as its
224"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.46153846153846156,"radius. The joint space of all such spherical spaces is the cohort we aim to discover from this cluster.
225"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.4633699633699634,"These discovered cohorts provide a promising avenue for further exploration of medically meaningful
226"
COHORT DISCOVERY AMONG HIGH DATA SHAPLEY VALUE NEGATIVE SAMPLES,0.4652014652014652,"patterns in EMR data analytics, potentially revealing important insights.
227"
EXPERIMENTAL EVALUATION,0.46703296703296704,"4
Experimental Evaluation
228"
EXPERIMENTAL EVALUATION,0.46886446886446886,"We evaluate our proposal using our hospital’s EMR data, on which we utilize 709 lab tests to predict
229"
EXPERIMENTAL EVALUATION,0.4706959706959707,"whether a patient will develop AKI in each admission in two days (as defined in Section 2). In total,
230"
EXPERIMENTAL EVALUATION,0.4725274725274725,"we receive 20,732 admissions, of which 911 develop AKI. We partition the dataset into training
231"
EXPERIMENTAL EVALUATION,0.47435897435897434,"data (90%) and testing data (10%). We employ the logistic regression model to compute the data
232"
EXPERIMENTAL EVALUATION,0.47619047619047616,"Shapley value for each negative sample as detailed in Section 3.1, using the area under the ROC
233"
EXPERIMENTAL EVALUATION,0.47802197802197804,"curve (AUC) as the evaluation metric, and perform Monte Carlo permutation sampling 100,000 times
234"
EXPERIMENTAL EVALUATION,0.47985347985347987,"with early stopping. For the manifold learning step, we utilize an SDAE comprising 3 DAEs. The
235"
EXPERIMENTAL EVALUATION,0.4816849816849817,"709-dimension inputs are transformed using encoders with dimensions 256, 128, and 64, respectively.
236"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.4835164835164835,"4.1
Cohort Discovery in Clinical Validation
237"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.48534798534798534,"We present the cohort discovery results on our dataset in Figure 3, where we first display the data
238"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.48717948717948717,"Shapley value histogram among all the negative samples in Figure 3(a). It is noteworthy that this
239"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.489010989010989,"histogram can be well fitted by a Gaussian mixture model, consisting of three distinct and interesting
240"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.4908424908424908,"components. We next examine each component in detail. The first component on the left represents
241"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.4926739926739927,"the negative samples with negative data Shapley values. These samples have a negative impact on
242"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.4945054945054945,"the prediction task, meaning that they are detrimental to predicting the AKI occurrence. In prior
243"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.49633699633699635,"studies, one generally plausible explanation for the presence of such samples is the existence of
244"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.4981684981684982,"mislabeled data [12]. However, for a representative acute disease like AKI, these negative samples
245"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5,"are highly likely to be positive samples in the future but have not yet exhibited symptoms of AKI
246"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5018315018315018,"within the monitored time duration. Moving on to the second component in the middle, we observe
247"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5036630036630036,"that its data Shapley values are centered around a mean value close to zero. This implies that these
248"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5054945054945055,"negative samples are generally healthy without any apparent AKI-related symptoms. Notably, these
249"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5073260073260073,"healthy samples constitute a relatively significant portion of the data, which is commonly observed in
250"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5091575091575091,"clinical practice and aligns with our initial expectations. The third component on the right represents
251"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.510989010989011,"negative samples that are particularly valuable for the prediction task and merit special attention in
252"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5128205128205128,"our study. To further investigate these samples, we introduce a separation line between the second
253"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5146520146520146,"and third components, i.e., a threshold 60% to exclude the lower 60% negative samples based on
254"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5164835164835165,"their data Shapley values while retaining the remaining 40% for further analysis. Our focus is on
255"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5183150183150184,"these remaining 40% samples for identifying the hot zones, as illustrated in Figure 1.
256"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5201465201465202,"The distribution of all negative samples, in terms of their data Shapley values in the manifold space,
257"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.521978021978022,"is presented in Figure 3(b). Upon performing DBSCAN on the extracted 40% samples with high
258"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5238095238095238,"data Shapley values (points brighter than dark blue), we identify seven distinct cohorts of interest,
259"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5256410256410257,(a) Data Shapley value histogram
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5274725274725275,among all negative samples
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5293040293040293,(b) Data Shapley value distribution among all negative
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5311355311355311,samples in the manifold space
COHORT DISCOVERY IN CLINICAL VALIDATION,0.532967032967033,(c) Discovered cohorts among high data
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5347985347985348,Shapley value negative samples
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5366300366300366,Figure 3: Cohort discovery on our dataset.
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5384615384615384,"(a) Cohort 2
(b) Cohort 4
(c) Cohort 6"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5402930402930403,"Figure 4: Lab test patterns of discovered Cohorts 2, 4, and 6. In each cohort, the colored region (blue,
green, and yellow) represents the lab test value probability density of the samples in the cohort, while
the grey region denotes that of all the other samples outside the cohort."
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5421245421245421,"which are visually displayed using t-SNE plots in Figure 3(c), in which grey points are either with
260"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5439560439560439,"low data Shapley values or labeled as noise by DBSCAN. We observe that these discovered cohorts
261"
COHORT DISCOVERY IN CLINICAL VALIDATION,0.5457875457875457,"are distinguishable from one another, potentially corresponding to medically meaningful patterns.
262"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5476190476190477,"4.2
In-depth Analysis of Discovered Cohorts
263"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5494505494505495,"Cohort 2: inflammatory cohort. Figure 4(a) indicates a pronounced neutrophil-to-lymphocyte
264"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5512820512820513,"ratio (NLR) [48] in this patient group, marked by an increase in neutrophils (FNM) and a decrease
265"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5531135531135531,"in lymphocytes (FLM). This pattern, often tied to infectious, inflammatory, and stress conditions,
266"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.554945054945055,"suggests an overactive immune response leading to reduced lymphocyte counts [36, 8]. An elevated
267"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5567765567765568,"NLR, a reliable inflammatory marker, indicates a propensity for invasive infections [16]. Meanwhile,
268"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5586080586080586,"the levels of Cotrimoxazole (SXT2) and Vancomycin (VAN), both administered to treat infections
269"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5604395604395604,"including those associated with methicillin-resistant staphylococcus [15], are found to be elevated in
270"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5622710622710623,"the bodies of these patients. The findings suggest that this patient cohort comprises individuals expe-
271"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5641025641025641,"riencing infections and acute inflammation, and receiving antibiotic treatment. Severe infections can
272"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5659340659340659,"cause systemic inflammatory response syndrome and kidney injury. Antibiotics like vancomycin can
273"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5677655677655677,"worsen kidney stress and have nephrotoxic properties [47], potentially leading to kidney dysfunction
274"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5695970695970696,"during treatment. However, modern medical practice can effectively manage these cases. Infections
275"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5714285714285714,"are promptly treated with broad-spectrum antibiotics and at appropriate doses within safety limits;
276"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5732600732600732,"hence, the patients do not develop significant AKI [13].
277"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.575091575091575,"Cohort 4: hepatic and hematological disorders cohort. As delineated in Figure 3(c), Cohort 4
278"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5769230769230769,"exhibits an augmented region and an increased quantity of sampling points, indicative of a more
279"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5787545787545788,"expansive patient population. A comprehensive analysis of the lab test indicator distribution for
280"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5805860805860806,"this cohort, portrayed in Figure 4(b), reveals differences in levels of serum proteins. Specifically,
281"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5824175824175825,"derangements in levels of albumin (ALB) and the albumin-globulin ratio (AGR) signify aberrant
282"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5842490842490843,"protein synthesis in patients. These may be associated with hepatic dysfunction or hematological
283"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5860805860805861,"diseases such as myeloma [41, 27]. Hepatic diseases can lead to impaired production of other
284"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5879120879120879,"proteins such as antithrombin III (AT3) [21]; AT3 may also be lost excessively in nephrotic syndrome
285"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5897435897435898,"LR
GBDT
AdaBoost
RF
MLP
0.5 0.6 0.7 0.8 0.9 1.0 AUC"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5915750915750916,"All d −
i
d −
i  with si > 0
z(0)
i
 of all d −
i"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5934065934065934,"Figure 5: AKI prediction performance of widely
adopted classifiers in three different settings."
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5952380952380952,"−15
−10
−5
0
5
101e-5
1e-5
1e-5
1e-5
1e-5
1e-5
1e-5
1e-5"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5970695970695971,"Outliers
Cohort 0
Cohort 1
Cohort 2
Cohort 3
Cohort 4
Cohort 5
Cohort 6"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.5989010989010989,"Figure 6: Data Shapley value histogram of the
samples within our discovered cohorts."
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6007326007326007,"which is a kidney disorder [18], or undergo accelerated consumption in disseminated intravascular
286"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6025641025641025,"coagulation [34]. Diminished reticulocyte hemoglobin (RETH) is associated with iron deficiency
287"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6043956043956044,"anemia [2], and could either be linked to hematological disorders or nutritional deficiency. In
288"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6062271062271062,"addition, imbalances in albumin and globulin may also be associated with dehydration. Therefore,
289"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.608058608058608,"our observation derived from Cohort 4 may support the pathophysiological relationship that exists
290"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6098901098901099,"between disorders of the hematological and hepatic systems, which increases the propensity for
291"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6117216117216118,"kidney disease. Clinicians should exercise vigilance in care when managing these cases.
292"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6135531135531136,"Cohort 6: respiratory failure and metabolic acidosis cohort. Figure 4(c) reveals significant
293"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6153846153846154,"metabolic imbalances in patients, leading to an acid-base imbalance. Specifically, increased carbon
294"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6172161172161172,"dioxide pressure (PCO2), reduced oxygen pressure (PO2), and insufficient blood oxygen saturation
295"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6190476190476191,"(SAT) suggest respiratory failure [5]. Concurrently, reduced base excess (BE), bicarbonate ion (HCO3)
296"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6208791208791209,"levels, and blood pH values hint at metabolic acidosis, indicating possible acute illnesses causing
297"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6227106227106227,"lactic or ketoacidosis [24]. These results suggest potential severe respiratory complications, such
298"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6245421245421245,"as advanced pneumonia, heart failure-induced pulmonary edema, or chronic obstructive pulmonary
299"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6263736263736264,"disease (COPD)[20]. Alternatively, acute conditions like hypoxia, shock, or severe infection could
300"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6282051282051282,"disrupt aerobic metabolism, leading to anaerobic glucose conversion to lactate, which accumulates in
301"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.63003663003663,"the bloodstream and causes acidosis. This puts significant strain on the kidneys, potentially resulting
302"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6318681318681318,"in renal disease symptoms[25]. This cohort of patients under examination does not advance to AKI,
303"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6336996336996337,"leading to the inference that renal dysfunction may not constitute an end-organ complication Rather,
304"
IN-DEPTH ANALYSIS OF DISCOVERED COHORTS,0.6355311355311355,"this patient cohort appears to exhibit a heightened disposition to respiratory failure.
305"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6373626373626373,"4.3
Validation of Effectiveness for Each Component
306"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6391941391941391,"We validate the effectiveness of each component in our approach for AKI prediction. Specifically,
307"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6410256410256411,"we evaluate three settings of the negative sample usage in the training data (with positive samples
308"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6428571428571429,"the same): (i) all d−
i : use all negative samples; (ii) d−
i with si > 0: only use the negative samples
309"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6446886446886447,"with positive data Shapley values; (iii) z(0)
i
of all d−
i : use the decoded representations from the
310"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6465201465201466,"SDAE-based manifold learning. z(0)
i
is in the same dimension as the raw input but is in the decoding
311"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6483516483516484,"space after transformation by SDAE. To ensure the credibility of our conclusions across different
312"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6501831501831502,"settings, we evaluate several widely adopted classifiers: logistic regression (LR), gradient-boosting
313"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.652014652014652,"decision tree (GBDT), adaptive boosting (AdaBoost), random forest (RF), and multilayer perceptron
314"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6538461538461539,"(MLP). The experimental results in AUC (mean ± std) from five repeats are illustrated in Figure 5.
315"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6556776556776557,"Effectiveness of the Negative Sample Shapley Field. By comparing settings (i) and (ii), we explore
316"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6575091575091575,"the effectiveness of our constructed Negative Sample Shapley Field. The results clearly demonstrate
317"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6593406593406593,"that by removing negative samples with data Shapley values smaller than 0, all the classifiers
318"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6611721611721612,"exhibit an improvement in AUC. This finding supports the rationale behind our approach of linking
319"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.663003663003663,"samples of great medical concern with their data Shapley values. Additionally, the effectiveness of
320"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6648351648351648,"approximating data Shapley values through Monte Carlo permutation sampling is further validated.
321"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6666666666666666,"Thus, this confirms the efficacy of our constructed Negative Sample Shapley Field.
322"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6684981684981685,"Effectiveness of Manifold Learning. By changing the input data from the raw space to the decoder’s
323"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6703296703296703,"output space after our proposed SDAE-based manifold learning (settings (i) vs. (iii)), we observe
324"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6721611721611722,"a moderate decrease in AUC, approximately 5% in most classifiers. This decrease aligns with our
325"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.673992673992674,"expectations, as the transformation in SDAE introduces a certain level of information loss. However,
326"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6758241758241759,"the performance degradation remains within an acceptable range. These findings demonstrate that
327"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6776556776556777,"our proposed manifold learning manages to preserve the original data structure information and
328"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6794871794871795,"effectively model the original raw data space, despite a significant reduction in data dimension from
329"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6813186813186813,"709 to 64. Thus, this corroborates our design rationale of employing SDAE for manifold learning
330"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6831501831501832,"with structure preservation and isotropy constraint.
331"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.684981684981685,"Effectiveness of Cohort Discovery. We further validate our method’s ability to decompose high
332"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6868131868131868,"data Shapley value samples into distinct, medically relevant cohorts. Figure 6 presents the data
333"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6886446886446886,"Shapley value histogram of our identified cohorts, with the upper part aligned with Figure 3(a)
334"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6904761904761905,"but color-coded by cohort proportion. The lower part shows each cohort’s data Shapley value
335"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6923076923076923,"distribution. We note seven cohorts effectively partition Figure 3(a)’s third component into Gaussian
336"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6941391941391941,"distributions, implying consistent data Shapley values within each cohort. Cohort 2, identified as
337"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6959706959706959,"the inflammatory group, exhibits relatively lower data Shapley values, as immune abnormalities
338"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6978021978021978,"cannot serve as specific features for kidney injury. Conversely, Cohorts 4 and 6, involving critical
339"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.6996336996336996,"metabolic systems, display higher data Shapley values, which indicates their significant medical
340"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.7014652014652014,"relevance to AKI prediction. These observations confirm the homogeneity within each cohort due
341"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.7032967032967034,"to DBSCAN’s detection capability, and similarity in data Shapley values, further substantiating our
342"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.7051282051282052,"proposed isotropy constraint in manifold learning. In essence, our approach effectively identifies
343"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.706959706959707,"proximate cohorts with similar data Shapley values, providing valuable medical insights for the
344"
VALIDATION OF EFFECTIVENESS FOR EACH COMPONENT,0.7087912087912088,"prediction task.
345"
RELATED WORK,0.7106227106227107,"5
Related Work
346"
RELATED WORK,0.7124542124542125,"Shapley value, originally introduced in cooperative game theory [40], offers a solution for the equi-
347"
RELATED WORK,0.7142857142857143,"table distribution of a team’s collective value among its individual members [7]. Notable applications
348"
RELATED WORK,0.7161172161172161,"of the Shapley value in machine learning encompass data valuation, feature selection, explainable ma-
349"
RELATED WORK,0.717948717948718,"chine learning, etc [38, 12, 46, 31, 31, 30]. Among these applications, data valuation holds particular
350"
RELATED WORK,0.7197802197802198,"significance in quantifying the contributions of individual data samples toward predictive models. In
351"
RELATED WORK,0.7216117216117216,"this research line, the data Shapley value [12] presents an equitable valuation framework for data value
352"
RELATED WORK,0.7234432234432234,"quantification with subsequent research focusing on enhancing computational efficiency [17, 11].
353"
RELATED WORK,0.7252747252747253,"Representation learning is a crucial research area contributing to the success of many machine
354"
RELATED WORK,0.7271062271062271,"learning algorithms [3]. Among the representation learning methods, manifold learning stands out
355"
RELATED WORK,0.7289377289377289,"due to its capability of reducing the dimensionality and visualizing the underlying structure of the
356"
RELATED WORK,0.7307692307692307,"data. Traditional manifold learning methods include Isomap [42], locally linear embedding [37], and
357"
RELATED WORK,0.7326007326007326,"multi-dimensional scaling [4]. In recent years, AEs have gained significant attention in representation
358"
RELATED WORK,0.7344322344322345,"learning, offering efficient and effective representations of unlabeled data. Researchers develop
359"
RELATED WORK,0.7362637362637363,"various AE variants for specific application scenarios, e.g., regularized AEs [1], sparse AEs [33],
360"
RELATED WORK,0.7380952380952381,"DAEs (denoising AEs) [43]. Specifically, DAEs and their advanced stacked variant SDAEs [44] are
361"
RELATED WORK,0.73992673992674,"highly suitable to tackle EMR data, in which missing and noisy data remains a notorious issue [26].
362"
RELATED WORK,0.7417582417582418,"DBSCAN, short for density-based spatial clustering of applications with noise, is introduced to
363"
RELATED WORK,0.7435897435897436,"alleviate the burden of parameter selection for users, facilitate the discovery of arbitrarily-shaped
364"
RELATED WORK,0.7454212454212454,"clusters, and demonstrate satisfactory efficiency when dealing with large datasets [9, 10, 39].
365"
CONCLUSION,0.7472527472527473,"6
Conclusion
366"
CONCLUSION,0.7490842490842491,"This paper proposes to examine negative samples for cohort discovery in healthcare analytics, which
367"
CONCLUSION,0.7509157509157509,"has not been explored in prior research. In particular, we propose to measure each negative sample’s
368"
CONCLUSION,0.7527472527472527,"contribution to the prediction task via its data Shapley value and construct the Negative Sample
369"
CONCLUSION,0.7545787545787546,"Shapley Field to model the distribution of all negative samples. To enhance the cohort discovery
370"
CONCLUSION,0.7564102564102564,"quality, we transform this original field into an embedded space using manifold learning, incorporating
371"
CONCLUSION,0.7582417582417582,"the original data structure information and isotropy constraint. In the transformed space, we manage
372"
CONCLUSION,0.76007326007326,"to identify medically meaningful cohorts within negative samples by DBSCAN. The experiments on
373"
CONCLUSION,0.7619047619047619,"our hospital’s EMR data empirically demonstrate the effectiveness of our proposal, and the medical
374"
CONCLUSION,0.7637362637362637,"insights derived from our discovered cohorts are validated by clinicians, highlighting the medical
375"
CONCLUSION,0.7655677655677655,"value of our approach. Future work includes conducting a long-term validation to further verify the
376"
CONCLUSION,0.7673992673992674,"conclusions drawn from cohort discovery. Additionally, more detailed analyses and fine-grained
377"
CONCLUSION,0.7692307692307693,"clinical validation are required to explore the detected cohorts that exhibit a hierarchical structure.
378"
REFERENCES,0.7710622710622711,"References
379"
REFERENCES,0.7728937728937729,"[1] Guillaume Alain and Yoshua Bengio. What regularized auto-encoders learn from the data-
380"
REFERENCES,0.7747252747252747,"generating distribution. J. Mach. Learn. Res., 15(1):3563–3593, 2014.
381"
REFERENCES,0.7765567765567766,"[2] Michael Auerbach, Steven J Staffa, and Carlo Brugnara. Using reticulocyte hemoglobin
382"
REFERENCES,0.7783882783882784,"equivalent as a marker for iron deficiency and responsiveness to iron therapy. In Mayo Clinic
383"
REFERENCES,0.7802197802197802,"Proceedings, volume 96, pages 1510–1519. Elsevier, 2021.
384"
REFERENCES,0.782051282051282,"[3] Yoshua Bengio, Aaron C. Courville, and Pascal Vincent. Representation learning: A review
385"
REFERENCES,0.7838827838827839,"and new perspectives. IEEE Trans. Pattern Anal. Mach. Intell., 35(8):1798–1828, 2013.
386"
REFERENCES,0.7857142857142857,"[4] Ingwer Borg and Patrick JF Groenen. Modern multidimensional scaling: Theory and applica-
387"
REFERENCES,0.7875457875457875,"tions. Springer Science & Business Media, 2005.
388"
REFERENCES,0.7893772893772893,"[5] Peter H Breen.
Arterial blood gas and ph analysis: clinical approach and interpretation.
389"
REFERENCES,0.7912087912087912,"Anesthesiology Clinics of North America, 19(4):885–906, 2001.
390"
REFERENCES,0.793040293040293,"[6] Javier Castro, Daniel Gómez, and Juan Tejada. Polynomial calculation of the shapley value
391"
REFERENCES,0.7948717948717948,"based on sampling. Comput. Oper. Res., 36(5):1726–1730, 2009.
392"
REFERENCES,0.7967032967032966,"[7] Georgios Chalkiadakis, Edith Elkind, and Michael J. Wooldridge. Computational Aspects of
393"
REFERENCES,0.7985347985347986,"Cooperative Game Theory. Synthesis Lectures on Artificial Intelligence and Machine Learning.
394"
REFERENCES,0.8003663003663004,"Morgan & Claypool Publishers, 2011.
395"
REFERENCES,0.8021978021978022,"[8] Firdaus S Dhabhar. Enhancing versus suppressive effects of stress on immune function: implica-
396"
REFERENCES,0.8040293040293041,"tions for immunoprotection and immunopathology. Neuroimmunomodulation, 16(5):300–317,
397"
REFERENCES,0.8058608058608059,"2009.
398"
REFERENCES,0.8076923076923077,"[9] Martin Ester, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. A density-based algorithm for
399"
REFERENCES,0.8095238095238095,"discovering clusters in large spatial databases with noise. In KDD, pages 226–231. AAAI Press,
400"
REFERENCES,0.8113553113553114,"1996.
401"
REFERENCES,0.8131868131868132,"[10] Junhao Gan and Yufei Tao. DBSCAN revisited: Mis-claim, un-fixability, and approximation.
402"
REFERENCES,0.815018315018315,"In SIGMOD Conference, pages 519–530. ACM, 2015.
403"
REFERENCES,0.8168498168498168,"[11] Amirata Ghorbani, Michael P. Kim, and James Zou. A distributional framework for data
404"
REFERENCES,0.8186813186813187,"valuation. In ICML, volume 119 of Proceedings of Machine Learning Research, pages 3535–
405"
REFERENCES,0.8205128205128205,"3544. PMLR, 2020.
406"
REFERENCES,0.8223443223443223,"[12] Amirata Ghorbani and James Y. Zou. Data shapley: Equitable valuation of data for machine
407"
REFERENCES,0.8241758241758241,"learning. In ICML, volume 97 of Proceedings of Machine Learning Research, pages 2242–2251.
408"
REFERENCES,0.826007326007326,"PMLR, 2019.
409"
REFERENCES,0.8278388278388278,"[13] Stuart L Goldstein, Theresa Mottes, Kendria Simpson, Cynthia Barclay, Stephen Muething,
410"
REFERENCES,0.8296703296703297,"David B Haslam, and Eric S Kirkendall. A sustained quality improvement program reduces
411"
REFERENCES,0.8315018315018315,"nephrotoxic medication-associated acute kidney injury. Kidney international, 90(1):212–221,
412"
REFERENCES,0.8333333333333334,"2016.
413"
REFERENCES,0.8351648351648352,"[14] Rick Groenendijk, Sezer Karaoglu, Theo Gevers, and Thomas Mensink. Multi-loss weighting
414"
REFERENCES,0.836996336996337,"with coefficient of variations. In WACV, pages 1468–1477. IEEE, 2021.
415"
REFERENCES,0.8388278388278388,"[15] Natasha E Holmes and Benjamin P Howden. What’s new in the treatment of serious mrsa
416"
REFERENCES,0.8406593406593407,"infection? Current opinion in infectious diseases, 27(6):471–478, 2014.
417"
REFERENCES,0.8424908424908425,"[16] Zhiwei Huang, Zhaoyin Fu, Wujun Huang, and Kegang Huang. Prognostic value of neutrophil-
418"
REFERENCES,0.8443223443223443,"to-lymphocyte ratio in sepsis: A meta-analysis. The American journal of emergency medicine,
419"
REFERENCES,0.8461538461538461,"38(3):641–647, 2020.
420"
REFERENCES,0.847985347985348,"[17] Ruoxi Jia, David Dao, Boxin Wang, Frances Ann Hubis, Nick Hynes, Nezihe Merve Gürel,
421"
REFERENCES,0.8498168498168498,"Bo Li, Ce Zhang, Dawn Song, and Costas J. Spanos. Towards efficient data valuation based
422"
REFERENCES,0.8516483516483516,"on the shapley value. In AISTATS, volume 89 of Proceedings of Machine Learning Research,
423"
REFERENCES,0.8534798534798534,"pages 1167–1176. PMLR, 2019.
424"
REFERENCES,0.8553113553113553,"[18] Robert H Kauffmann, Jan J Veltkamp, Nico H Van Tilburg, and Leendert A Van Es. Acquired
425"
REFERENCES,0.8571428571428571,"antithrombin iii deficiency and thrombosis in the nephrotic syndrome. The American journal of
426"
REFERENCES,0.8589743589743589,"medicine, 65(4):607–613, 1978.
427"
REFERENCES,0.8608058608058609,"[19] John A Kellum, Norbert Lameire, Peter Aspelin, Rashad S Barsoum, Emmanuel A Burdmann,
428"
REFERENCES,0.8626373626373627,"Stuart L Goldstein, Charles A Herzog, Michael Joannidis, Andreas Kribben, Andrew S Levey,
429"
REFERENCES,0.8644688644688645,"et al. Kidney disease: improving global outcomes (kdigo) acute kidney injury work group.
430"
REFERENCES,0.8663003663003663,"kdigo clinical practice guideline for acute kidney injury. Kidney international supplements,
431"
REFERENCES,0.8681318681318682,"2(1):1–138, 2012.
432"
REFERENCES,0.86996336996337,"[20] Jordan A Kempker, Maria K Abril, Yunyun Chen, Michael R Kramer, Lance A Waller, and
433"
REFERENCES,0.8717948717948718,"Greg S Martin. The epidemiology of respiratory failure in the united states 2002–2017: A serial
434"
REFERENCES,0.8736263736263736,"cross-sectional study. Critical Care Explorations, 2(6), 2020.
435"
REFERENCES,0.8754578754578755,"[21] E Knot, JW Ten Cate, HR Drijfhout, LH Kahlé, and GN Tytgat. Antithrombin iii metabolism in
436"
REFERENCES,0.8772893772893773,"patients with liver disease. Journal of clinical pathology, 37(5):523–530, 1984.
437"
REFERENCES,0.8791208791208791,"[22] Mark A Kramer. Nonlinear principal component analysis using autoassociative neural networks.
438"
REFERENCES,0.8809523809523809,"AIChE journal, 37(2):233–243, 1991.
439"
REFERENCES,0.8827838827838828,"[23] Mark A Kramer.
Autoassociative neural networks.
Computers & chemical engineering,
440"
REFERENCES,0.8846153846153846,"16(4):313–328, 1992.
441"
REFERENCES,0.8864468864468864,"[24] Jeffrey A Kraut and Nicolaos E Madias. Metabolic acidosis: pathophysiology, diagnosis and
442"
REFERENCES,0.8882783882783882,"management. Nature Reviews Nephrology, 6(5):274–285, 2010.
443"
REFERENCES,0.8901098901098901,"[25] Jeffrey A Kraut and Nicolaos E Madias. Lactic acidosis. New England Journal of Medicine,
444"
REFERENCES,0.891941391941392,"371(24):2309–2319, 2014.
445"
REFERENCES,0.8937728937728938,"[26] Thomas A Lasko, Joshua C Denny, and Mia A Levy. Computational phenotype discovery
446"
REFERENCES,0.8956043956043956,"using unsupervised feature learning over noisy, sparse, and irregular clinical data. PloS one,
447"
REFERENCES,0.8974358974358975,"8(6):e66341, 2013.
448"
REFERENCES,0.8992673992673993,"[27] Garrick Edouard Laudin, Peter F Levay, and Buks Coetzer. Globulin fraction and albumin: glob-
449"
REFERENCES,0.9010989010989011,"ulin ratio as a predictor of mortality in a south african multiple myeloma cohort. International
450"
REFERENCES,0.9029304029304029,"Journal of Hematologic Oncology, 9(3):IJH27, 2020.
451"
REFERENCES,0.9047619047619048,"[28] Zachary Chase Lipton, David C. Kale, Charles Elkan, and Randall C. Wetzel. Learning to
452"
REFERENCES,0.9065934065934066,"diagnose with LSTM recurrent neural networks. In ICLR (Poster), 2016.
453"
REFERENCES,0.9084249084249084,"[29] Shikun Liu, Edward Johns, and Andrew J. Davison. End-to-end multi-task learning with
454"
REFERENCES,0.9102564102564102,"attention. In CVPR, pages 1871–1880. Computer Vision Foundation / IEEE, 2019.
455"
REFERENCES,0.9120879120879121,"[30] Zelei Liu, Yuanyuan Chen, Han Yu, Yang Liu, and Lizhen Cui. Gtg-shapley: Efficient and
456"
REFERENCES,0.9139194139194139,"accurate participant contribution evaluation in federated learning. ACM Trans. Intell. Syst.
457"
REFERENCES,0.9157509157509157,"Technol., 13(4):60:1–60:21, 2022.
458"
REFERENCES,0.9175824175824175,"[31] Scott M. Lundberg and Su-In Lee. A unified approach to interpreting model predictions. In
459"
REFERENCES,0.9194139194139194,"NIPS, pages 4765–4774, 2017.
460"
REFERENCES,0.9212454212454212,"[32] Syed S Mahmood, Daniel Levy, Ramachandran S Vasan, and Thomas J Wang. The framingham
461"
REFERENCES,0.9230769230769231,"heart study and the epidemiology of cardiovascular disease: a historical perspective. The lancet,
462"
REFERENCES,0.924908424908425,"383(9921):999–1008, 2014.
463"
REFERENCES,0.9267399267399268,"[33] Alireza Makhzani and Brendan J. Frey. k-sparse autoencoders. In ICLR (Poster), 2014.
464"
REFERENCES,0.9285714285714286,"[34] Eberhard F Mammen. Antithrombin: its physiological importance and role in dic. In Seminars
465"
REFERENCES,0.9304029304029304,"in thrombosis and hemostasis, volume 24, pages 19–25. Copyright© 1998 by Thieme Medical
466"
REFERENCES,0.9322344322344323,"Publishers, Inc., 1998.
467"
REFERENCES,0.9340659340659341,"[35] DR Mould. Models for disease progression: new approaches and uses. Clinical Pharmacology
468"
REFERENCES,0.9358974358974359,"& Therapeutics, 92(1):125–131, 2012.
469"
REFERENCES,0.9377289377289377,"[36] Carl Nathan. Neutrophils and immunity: challenges and opportunities. Nature reviews immunol-
470"
REFERENCES,0.9395604395604396,"ogy, 6(3):173–182, 2006.
471"
REFERENCES,0.9413919413919414,"[37] Sam T Roweis and Lawrence K Saul. Nonlinear dimensionality reduction by locally linear
472"
REFERENCES,0.9432234432234432,"embedding. science, 290(5500):2323–2326, 2000.
473"
REFERENCES,0.945054945054945,"[38] Benedek Rozemberczki, Lauren Watson, Péter Bayer, Hao-Tsung Yang, Oliver Kiss, Sebastian
474"
REFERENCES,0.9468864468864469,"Nilsson, and Rik Sarkar. The shapley value in machine learning. In IJCAI, pages 5572–5579.
475"
REFERENCES,0.9487179487179487,"ijcai.org, 2022.
476"
REFERENCES,0.9505494505494505,"[39] Erich Schubert, Jörg Sander, Martin Ester, Hans-Peter Kriegel, and Xiaowei Xu. DBSCAN
477"
REFERENCES,0.9523809523809523,"revisited, revisited: Why and how you should (still) use DBSCAN. ACM Trans. Database Syst.,
478"
REFERENCES,0.9542124542124543,"42(3):19:1–19:21, 2017.
479"
REFERENCES,0.9560439560439561,"[40] Lloyd S Shapley et al. A value for n-person games. 1953.
480"
REFERENCES,0.9578754578754579,"[41] Rosaria Spinella, Rohit Sawhney, and Rajiv Jalan. Albumin in chronic liver disease: structure,
481"
REFERENCES,0.9597069597069597,"functions and therapeutic implications. Hepatology international, 10:124–132, 2016.
482"
REFERENCES,0.9615384615384616,"[42] Joshua B Tenenbaum, Vin de Silva, and John C Langford. A global geometric framework for
483"
REFERENCES,0.9633699633699634,"nonlinear dimensionality reduction. science, 290(5500):2319–2323, 2000.
484"
REFERENCES,0.9652014652014652,"[43] Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. Extracting
485"
REFERENCES,0.967032967032967,"and composing robust features with denoising autoencoders. In ICML, volume 307 of ACM
486"
REFERENCES,0.9688644688644689,"International Conference Proceeding Series, pages 1096–1103. ACM, 2008.
487"
REFERENCES,0.9706959706959707,"[44] Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and Pierre-Antoine Manzagol.
488"
REFERENCES,0.9725274725274725,"Stacked denoising autoencoders: Learning useful representations in a deep network with a local
489"
REFERENCES,0.9743589743589743,"denoising criterion. J. Mach. Learn. Res., 11:3371–3408, 2010.
490"
REFERENCES,0.9761904761904762,"[45] John Burnard West. Respiratory physiology: the essentials. Lippincott Williams & Wilkins,
491"
REFERENCES,0.978021978021978,"2012.
492"
REFERENCES,0.9798534798534798,"[46] Brian D. Williamson and Jean Feng. Efficient nonparametric statistical inference on population
493"
REFERENCES,0.9816849816849816,"feature importance using shapley values. In ICML, volume 119 of Proceedings of Machine
494"
REFERENCES,0.9835164835164835,"Learning Research, pages 10282–10291. PMLR, 2020.
495"
REFERENCES,0.9853479853479854,"[47] Huizi Wu and Jiaguo Huang. Drug-induced nephrotoxicity: pathogenic mechanisms, biomarkers
496"
REFERENCES,0.9871794871794872,"and prevention strategies. Current drug metabolism, 19(7):559–567, 2018.
497"
REFERENCES,0.989010989010989,"[48] R Zahorec et al. Ratio of neutrophil to lymphocyte counts-rapid and simple parameter of
498"
REFERENCES,0.9908424908424909,"systemic inflammation and stress in critically ill. Bratislavske lekarske listy, 102(1):5–14, 2001.
499"
REFERENCES,0.9926739926739927,"[49] Fei Zhou, Ting Yu, Ronghui Du, Guohui Fan, Ying Liu, Zhibo Liu, Jie Xiang, Yeming Wang,
500"
REFERENCES,0.9945054945054945,"Bin Song, Xiaoying Gu, et al. Clinical course and risk factors for mortality of adult inpatients
501"
REFERENCES,0.9963369963369964,"with covid-19 in wuhan, china: a retrospective cohort study. The lancet, 395(10229):1054–1062,
502"
REFERENCES,0.9981684981684982,"2020.
503"
