Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0015360983102918587,"Fairness in clustering has been considered extensively in the past; however, the
trade-off between the two objectives — e.g., can we sacrifice just a little in the
quality of the clustering to significantly increase fairness, or vice-versa? — has
rarely been addressed. We introduce novel algorithms for tracing the complete
trade-off curve, or Pareto front, between quality and fairness in clustering problems;
that is, computing all clusterings that are not dominated in both objectives by other
clusterings. Unlike previous work that deals with specific objectives for quality
and fairness, we deal with all objectives for fairness and quality in two general
classes encompassing most of the special cases addressed in previous work. Our
algorithm must take exponential time in the worst case as the Pareto front itself
can be exponential. Even when the Pareto front is polynomial, our algorithm may
take exponential time, and we prove that this is inevitable unless P = NP. However,
we also present a new polynomial-time algorithm for computing the entire Pareto
front when the cluster centers are fixed, and for a fairness objective that minimizes
the sum, over all clusters, of the imbalance between the two groups in each cluster."
INTRODUCTION,0.0030721966205837174,"1
Introduction"
INTRODUCTION,0.004608294930875576,"Clustering is a fundamental problem in unsupervised learning with many applications, in which data
points must be grouped into clusters so that the quality or cost of the clustering is optimized — where
the cost can be k-median or k-center, among a long array of different quality objectives treated in the
literature. In some of these applications, the data points being clustered are people — for example,
when households are clustered to determine the location of a bus stop or a hospital — and in those
cases considerations such as fairness and equity come into play. In recent work, various frameworks
and methods have been proposed for improving the representation of different sensitive groups in
clustering, in cases where optimizing for clustering cost alone may be quite unfair. In such works,
the fairness criterion is often set as a constraint, for which we must compute the optimal solution.
This is generally an intractable computational problem even for the simplest fairness objectives, since
clustering on its own is NP-hard. The best one could hope for is an approximate solution based on
a vanilla approximation algorithm for clustering that improves fairness; such approaches have indeed
been recently proposed, e.g., Esmaeili et al. [26], see Chhabra et al. [18] for a survey."
INTRODUCTION,0.006144393241167435,"We take a more general approach to fair clustering: We aim to recover the entire Pareto front
of clustering cost and fairness, rather than a single point of that front (such as the best-quality
clustering under a fairness constraint). Our work aims to enable a practitioner to choose any trade-off
point, rather than computing one of them. We give general sufficient conditions for which we can
recover the Pareto front, up to an approximation inherited from the clustering problem itself, and
encompassing a variety of quality and fairness objectives used in the literature."
OUR CONTRIBUTIONS,0.007680491551459293,"1.1
Our Contributions"
OUR CONTRIBUTIONS,0.009216589861751152,"We present a novel family of algorithms for tracing the Pareto front between a quality/cost objective
and a fairness objective, where each objective can belong in a general class that encompasses most
of the ones previously proposed in the literature. Our algorithm requires that the fairness objective
satisfy an intuitive property: that it is pattern-based. Informally, a fairness objective is pattern-based if
it is solely a function of the number of nodes of different attributes in each cluster (see Definition 2.1).
Many fairness objectives used in the literature are pattern-based, from the well-known balance [19]
to objectives that measure the proportional violation of pre-specified upper and lower bounds for a
sensitive attribute within a cluster [10, 40, 2, 9, 26, 32, 22]. For the quality objective, we consider
metric-based cost functions. We study the computation of the quality/fairness trade-off in two settings:
in the assignment problem, the centers of the clusters are given and the cost is the sum of the distances
of the data points from their cluster center; whereas in the clustering problem, determining the centers
is a part of the problem. We show that our algorithm finds the exact Pareto front of the assignment
problem, and an approximation of the Pareto front of the clustering problem (Theorems 3.4, 3.5), with
an approximation ratio that depends on the baseline approximation ratio (denoted α) for the minimum
cost clustering problem without a fairness objective. The running time is O(knl(k−1)), where k is
the number of clusters, l is the number of sensitive attribute values, and n is the size of the dataset."
OUR CONTRIBUTIONS,0.010752688172043012,"Our Pareto front algorithms take time exponential in ℓand k, and this is necessary. One reason is
that the Pareto front may be exponential in size. For many fairness objectives the Pareto front is
provably polynomial in size, but even in those cases exponential time is still necessary in general
because the baseline problem is NP-hard. Importantly, we also present the first nontrivial algorithmic
result for the quality/fairness Pareto front problem in clustering: A polynomial-time algorithm for
computing the Pareto front for a new fairness objective, namely the one minimizing the sum (or
the maximum), over all clusters, of the deviations from parity of the two protected attributes in each
cluster (see Theorem 3.6)."
OUR CONTRIBUTIONS,0.01228878648233487,"We empirically explore faster methods for computing an approximate Pareto front by adapting
constraint optimization methods from fair clustering [26] in Section 4. These experiments explore
the trade-off between accuracy and speed for our problem by comparing the tighter approximation
obtained through our proposed algorithms with the looser Pareto front approximation obtained using
faster methods."
OUR CONTRIBUTIONS,0.013824884792626729,"We believe that our work is the first to address and carry out the computation of the entire Pareto front,
and also the first to simultaneously cover a large range of quality and fairness criteria. In comparison,
extant literature on fair clustering typically optimizes one objective subject to a constraint on the other
objective, with an individualized approach for each combination. Our work is particularly applicable
in cases where a decision-maker may be willing to be suboptimal in one objective in order to achieve
a better value in a second objective, but does not know a priori what bounds to set on either objective.
Our algorithms allow them to explore the entire trade-off, from the highest quality clustering all the
way down to the fairest clustering. Finally, our polynomial-time algorithm for computing the Pareto
front when the fairness objective is the sum or maximum of imbalances (see Theorem 3.6) is another
novel contribution to the subject of fair clustering."
RELATED WORK,0.015360983102918587,"1.2
Related Work"
RELATED WORK,0.016897081413210446,"Our work is inspired by a plethora of recent studies on fair clustering that propose various metrics for
improving the representation of different sensitive attributes within clusters. Unsupervised clustering
is known to be NP-hard even in simple settings [4]. A variety of algorithms have been proposed to ap-
proximate the best possible clustering, with approximation ratios differing for different cost objectives
(e.g., k-means [3], k-median [14], k-center [38]). Fair clustering goals range from maximizing the
worst ratio between two groups across clusters [19], to minimizing the discrepancy between cluster
representation and proportional representation of a group in a population [2, 9, 10, 22, 32, 26, 40],
and to equalizing the clustering cost for various groups [7, 15, 31, 50, 54, 62]. Many of these
works focus on building specialized approaches for each of the fairness objectives defined, and their
objective is to find the best quality clustering that satisfies a specified fairness constraint. Optimizing
even for simplest fairness objectives can be NP-hard [26], with approximation guarantees involving
a multiplicative and additive factor, which may depend on the particular objective form and data
topology. Our work differs in two significant ways: first, we compute the entire trade-off curve
rather than a single optimization point on the curve; second, we provide algorithms that are agnostic"
RELATED WORK,0.018433179723502304,"to the specific objectives used, giving sufficient conditions on the objectives. We note that our
conditions favor most group-fairness objectives defined in the literature. We discuss extensions to
other definitions of fairness and limitations of our work in Section 5."
RELATED WORK,0.019969278033794162,"Our work takes a different approach, by aiming to compute the entire Pareto front between seemingly
opposing objectives. Knowing the entire Pareto front can aid decision-makers when faced with
choosing optimal trade-offs. Many real-world applications are faced with such trade-offs: for
example, in facility location problems where a central agent decides on the location of facilities (e.g.,
buses, hospitals, etc.) based on the location of individuals within a certain region. It is well-known
that people of lower socio-economic status often travel longer distances [57] and have fewer health
facilities in their region [29]. A decision maker has multiple objectives to balance: minimal travel
time for the entire population and equal access to facilities for different populations. The Pareto front
allows the decision maker to balance these objectives in the optimal way: how much improvement
can a group of people gain by moving a facility slightly away from the solution given by a single
objective (e.g., by performing k-means)? Computing the Pareto front for facility location problems
with multiple objectives has a long history motivated by such questions, with real-world case studies
in the Singapore road network [39] and ambulance placement in Barbados [35]. Further applications
are found in extensive surveys [28]."
RELATED WORK,0.021505376344086023,"From a theoretical standpoint, computing the entire Pareto front remains a difficult problem. When
an underlying single-objective optimization problem is NP-hard, such as in many combinatorial
optimization problems, computing an approximation for the Pareto front is the best one could hope
for [55], for example for the multi-objective shortest path problem [11, 36, 44, 64], zero one knapsack
problem [25, 42, 63], the multi-objective spanning tree problem [8, 21, 55], among others. To our
knowledge, our work is novel in proposing algorithms for solving a bi-objective optimization problem
based on clustering and fairness objectives which require only general properties for the fairness
objectives to recover an approximate Pareto front with theoretical guarantees."
RELATED WORK,0.02304147465437788,"More generally, multi-objective optimization has seen a variety of methods for computing
points close to the Pareto front in various domains, with methods ranging from evolutionary
algorithms [20, 56, 61, 65] to gradient-based methods [12, 47, 49, 51], and more recently to
hypernetworks [16, 37, 48, 60] (often requiring inputting a preference vector of the objective values
that will output a point on the Pareto front). These methods have also been applied to a problem
closely related to clustering: that of facility location with multiple objectives [34, 58, 59], considering
specific objectives and without theoretical approximation guarantees."
PRELIMINARIES,0.02457757296466974,"2
Preliminaries"
PRELIMINARIES,0.026113671274961597,"We denote by X the set of data points in Rd. Assume that X = {x1, . . . , xn}, and for j ≤n define
Xj = {x1, . . . , xj}. A clustering map is defined as ϕ : X →S, where S is a set of k cluster centers
in Rd and k is the number of clusters, considered fixed. A cluster Ci is defined as all the data points
for which ϕ(x) = si, where si ∈S is the center for the i-th cluster. We call a clustering C the set
of all clusters Ci (so |C| = k), and by K the set of all possible clusterings. Finally, we denote by
σ : X →[l] the map between data points and a set of sensitive attributes, indexed from 1 to l (which
may represent demographic groups, interest groups, etc). We denote by Ca the set of data points
in a cluster C with attribute a, and by X a the set of data points with attribute a."
PRELIMINARIES,0.027649769585253458,"Clustering and Assignment Problems.
Unsupervised clustering optimizes a clustering cost objec-
tive c, often defined as the sum of distances between points and a set of candidate cluster centers. In a
general form, the cost of a clustering is
 P"
PRELIMINARIES,0.029185867895545316,"x∈X dp(x, ϕ(x))
1/p, for metric d and some value of p.
We call such objectives metric-based. By varying p = 1, 2, ∞we can obtain the k-median, k-means,
and k-center objectives, respectively. The clustering problem is thus finding the clustering that has
the minimum cost, over all possible sets of centers and maps from X to the set of centers. Since the
clustering problem is hard, one often considers, as a stepping stone, the assignment problem, where
the centers have been fixed. We shall consider both problems in this paper. In the fair clustering
problem we have two objectives, the clustering cost objective c, and a fairness objective f, that aims
to balance the representation of sensitive attributes in clusters, further detailed below."
PRELIMINARIES,0.030721966205837174,"Pareto Front.
Consider the set of all clusterings K of X, and the two objectives c (the cost
objective) and f (the fairness objective1), each mapping K to R. We say that clustering C dominates
clustering C′ if c(C) ≤c(C′), f(C) ≤f(C′), and one of the inequalities is strict. Intuitively, if a
clustering C′ is dominated, it is unworthy of further consideration, because it lags behind in both
objectives of interest. If however a clustering C is undominated, that is, there is no clustering in K
that is simultaneously better on both fronts, then it is part of the solution. The Pareto front is the
set of all undominated clusterings."
PRELIMINARIES,0.03225806451612903,"Fairness Objectives.
Our main contribution is an algorithm for computing the Pareto front of the
clustering and assignment problems for any metric-based quality function, and any fairness objective
– always a function to be minimized – that satisfies the following general condition."
PRELIMINARIES,0.03379416282642089,"Definition 2.1 (Pattern-based objectives). For a clustering C ∈K, i ∈[k], and a ∈[l], let its pattern
P C[i, a] be the number of data points in cluster Ci with attribute value a. A fairness objective f
that maps K to R is called pattern-based if f(C) only depends on the values in P C[i, a].
Definition 2.2 (Mergeable objectives). Consider two clusterings C and C′. We say that C′ is the
result of a merging of C (or C is a refinement of C′) if every non-empty cluster of C′ is the union
of clusters of C. A fairness objective f that maps K to R is called mergeable if, whenever C′ is the
result of a merging of C, f(C′) ≤f(C)."
PRELIMINARIES,0.03533026113671275,"We discuss the pattern-based and mergeability properties in Appendix B, where we give examples
of fairness objectives that are not pattern-based or mergeable. Below, we introduce several fairness
objectives commonly found in the literature, which we use in our experiments. All of these objectives
are pattern-based and mergeable, as proved formally in Appendix B.1."
PRELIMINARIES,0.03686635944700461,"Balance objective (Definition 1 in Chierichetti et al. [19]): For sensitive attributes that can
take two values, indexed 1 and 2, the balance of a cluster C is defined as BALANCE(C) =
min
 
|C1|/|C2|, |C2|/|C1|

. The balance objective for a clustering C is then defined as
BALANCE(C) = max min
C∈C BALANCE(C)
(1)"
PRELIMINARIES,0.03840245775729647,"The aim is to maximize balance,
or equivalently,
to minimize the negative balance
f(C) = −BALANCE(C). BALANCE has been used in fair clustering as a measure of equalizing
proportions of different groups across clusters [19]. In practice, optimizing BALANCE is both difficult
and does not measure how far the proportions of sensitive groups in a clustering are from their true
proportions in the population. For this reason, objectives based on proportional violation have been
proposed, allowing a central decision-maker to input upper and lower bounds for desired proportions
of groups in each cluster, and measured the deviation from these bounds [2, 9, 10, 22, 26, 32, 40]."
PRELIMINARIES,0.039938556067588324,"Proportional violation objectives: As defined in Esmaeili et al. [26], for every sensitive attribute
a ∈[l], define upper and lower bounds αa and βa with the aim of satisfying βa|C| ≤|Ca| ≤αa|C|
for all clusters C ∈C. Since this is not always feasible, we define the worst proportional violation of
attribute a in cluster C as the minimum non-negative value ∆C
a ∈[0, 1] such that
 
βa −∆C
a

|C| ≤|Ca| ≤
 
αa + ∆C
a

|C|
(2)
Then, the proportional violation-based objectives are defined as:"
PRELIMINARIES,0.041474654377880185,"GROUP UTILITARIAN = min
X"
PRELIMINARIES,0.043010752688172046,"a∈[l]
max
C∈C ∆C
a ,
GROUP UTILITARIAN-SUM = min
X"
PRELIMINARIES,0.0445468509984639,"a∈[l],C∈C
∆C
a , (3)"
PRELIMINARIES,0.04608294930875576,"GROUP EGALITARIAN = min
max
a∈[l],C∈C ∆C
a ,
GROUP EGALITARIAN-SUM = min max
a∈[l] X"
PRELIMINARIES,0.047619047619047616,"C∈C
∆C
a (4)"
PRELIMINARIES,0.04915514592933948,"These objective operationalize utilitarian and egalitarian concepts from social choice [13], minimizing
either the sum of proportional violations or the worst violation across attributes."
PRELIMINARIES,0.05069124423963134,"Sum of imbalances objective: Finally, for two interest groups in the population (l = 2) the following
objective is quite natural:"
PRELIMINARIES,0.05222734254992319,"SUM OF IMBALANCES =
X"
PRELIMINARIES,0.053763440860215055,"i∈[k]
|C1
i −C2
i |,"
PRELIMINARIES,0.055299539170506916,"1We will treat f as a minimization objective, thus minimizing the unfairness of a clustering."
PRELIMINARIES,0.05683563748079877,"that is to say, the sum of the deviations from equality between the two attribute values in the clusters.
This objective is most appropriate when datasets contain relatively equal proportions of the two
groups. Rather remarkably, the Pareto front for this objective can be computed in polynomial time."
ALGORITHMS FOR COMPUTING THE PARETO FRONT,0.05837173579109063,"3
Algorithms for Computing the Pareto Front"
A DYNAMIC PROGRAMMING ALGORITHM FOR RECOVERING THE ASSIGNMENT PARETO FRONT,0.059907834101382486,"3.1
A Dynamic Programming Algorithm for Recovering the Assignment Pareto Front"
A DYNAMIC PROGRAMMING ALGORITHM FOR RECOVERING THE ASSIGNMENT PARETO FRONT,0.06144393241167435,"We shall now present the main Algorithm. Define an X-pattern P to be a k-tuple of l-tuples of non-
negative integers such that P"
A DYNAMIC PROGRAMMING ALGORITHM FOR RECOVERING THE ASSIGNMENT PARETO FRONT,0.0629800307219662,"i∈[k] P[i, a] = |X a|, ∀a ∈[l]. P[i, a] specifies the number of data points
in cluster i of attribute a. That is, an X-pattern is a clustering except only the attribute values of the
points have been specified.2 Complete proofs to all subsequent results can be found in Appendix A."
A DYNAMIC PROGRAMMING ALGORITHM FOR RECOVERING THE ASSIGNMENT PARETO FRONT,0.06451612903225806,Algorithm 1 Dynamic Programming Algorithm for Computing the Assignment Pareto Front
A DYNAMIC PROGRAMMING ALGORITHM FOR RECOVERING THE ASSIGNMENT PARETO FRONT,0.06605222734254992,"1: Input: Number of clusters k, a set of n data points X with l attribute values, k centers S =
{s1, . . . , sk}, and metric-based cost objective c parameterized by d, p.
2: Output: A table Tn containing the solutions of the assignment problem for X for all X-patterns.
3: Method: Dynamic programming. We shall compute T0, T1, . . . Tn.
4: Initialize T0 to contain the null pattern with cost 0 and the empty clustering.
5: for j = 1 to n do
6:
Generate all Xj-patterns, where Xj = {x1, . . . , xj}.
7:
For each Xj-pattern P, and for each cluster i such that P[i, a] > 0, where a is the attribute
8:
value of xj, look up in Tj−1 the cost of the pattern Pi, which is P with xj omitted from
9:
cluster i, and compute Tj−1(Pi) + dp(xj, si).
10:
Let i∗be the cluster index that minimizes Tj−1(Pi) + dp(xj, si).
11:
Set Tj(P) ←Tj−1(Pi∗) + dp(xj, si∗).
12:
Store at Tj(P) the clustering from T[Pi∗], with xj added at cluster i∗.
return Tn"
A DYNAMIC PROGRAMMING ALGORITHM FOR RECOVERING THE ASSIGNMENT PARETO FRONT,0.06758832565284179,"At the conclusion of the algorithm, the table Tn contains the lowest cost clustering C for each
X-pattern P, such that P C = P, together with its cost c(C). Then, we can find the Pareto front by
first sorting these clusterings for all X-patterns P in increasing c, and then traversing them in order,
computing the unfairness of each pattern, remembering the smallest unfairness we have seen so far,
and omitting any pattern that has unfairness larger than the smallest seen so far.
Remark 3.1. The above calculation of Tn can be achieved alternatively by a simpler to state but
slightly slower algorithm: first generate all X-patterns, and then compute the optimum assignment
of each by min-cost flow."
A DYNAMIC PROGRAMMING ALGORITHM FOR RECOVERING THE ASSIGNMENT PARETO FRONT,0.06912442396313365,"Theorem 3.2. Algorithm 1 finds the Pareto front of the assignment problem in time O(knl(k−1)),
for any metric-based clustering objective and any pattern-based fairness objective."
A DYNAMIC PROGRAMMING ALGORITHM FOR RECOVERING THE ASSIGNMENT PARETO FRONT,0.0706605222734255,"Proof Sketch: We prove this theorem by finding an invariant of Algorithm 1: Tj[P] stores the lowest
cost assignment of Xj that maps to pattern P. We maintain this invariant as we build up our table
by searching over possible smaller patterns that we can add our next datapoint xj to and creating the
lowest cost assignment that maps to P. Therefore, the assignments stored at Tn[P] are the candidate
points for the Pareto front. A simple filtering heuristic, as described above, removes the dominated
points from this set of candidates. In terms of running time, the number of possible patterns of total
size up to n is upper bounded by nl(k−1), since each of the lk entries of P takes values between
0 and n, and the tuple corresponding to the last cluster k is fully determined by the other clusters.
For each considered pattern, we need to look up at most k previous entries of the table T."
APPROXIMATING THE PARETO FRONT FOR THE CLUSTERING PROBLEM,0.07219662058371736,"3.2
Approximating the Pareto Front for the Clustering Problem"
APPROXIMATING THE PARETO FRONT FOR THE CLUSTERING PROBLEM,0.07373271889400922,"As we saw, Algorithm 1 computes the Pareto front of the Assignment problem exactly for any input
centers S. We next show that it also provides an approximation for the Pareto front of the clustering
problem. For this purpose, we first use a vanilla clustering algorithm A for the single-objective"
APPROXIMATING THE PARETO FRONT FOR THE CLUSTERING PROBLEM,0.07526881720430108,"2Each clustering C maps to a pattern P C, with many different clusterings mapping to the same pattern."
APPROXIMATING THE PARETO FRONT FOR THE CLUSTERING PROBLEM,0.07680491551459294,"problem of minimizing the cost c, to obtain the set S of cluster centers, and then apply Algorithm 1
with this set of centers S. Let α be the approximation ratio of algorithm A."
APPROXIMATING THE PARETO FRONT FOR THE CLUSTERING PROBLEM,0.07834101382488479,"Definition 3.3 (W-approximation of the Pareto Set for clustering). For parameters W = (wc, wf),
we define the W-approximation of the Pareto set XP as a set of feasible points X′
P such that
∀x ∈XP , ∃x′ ∈X′
P such that c(x′) ≤wc · c(x) and f(x′) ≤wf · f(x)."
APPROXIMATING THE PARETO FRONT FOR THE CLUSTERING PROBLEM,0.07987711213517665,"This definition is a direct generalization of ϵ-approximate Pareto set defined by Papadimitriou and
Yannakakis [55]. One may recover the ϵ-approximate definition by setting ϵ = max(wc, wf) −1."
APPROXIMATING THE PARETO FRONT FOR THE CLUSTERING PROBLEM,0.08141321044546851,"Theorem 3.4. Algorithm 1 finds a (2 + α, 1)-approximation of the Pareto set of the clustering
problem with a metric-based cost objective c and a pattern-based and mergeable fairness objective f."
APPROXIMATING THE PARETO FRONT FOR THE CLUSTERING PROBLEM,0.08294930875576037,"Proof Sketch:
We argue that for any clustering map ϕ∗with centers S∗in the Pareto set for
clustering, there exists an assignment to the centers S found by an approximate vanilla clustering
algorithm that achieves the same or better fairness and at most (2 + α) times the clustering cost.
Then, since Algorithm 1 finds the Pareto set of the assignment problem, we are guaranteed the stated
approximation. We construct this assignment using a “routing” argument, first introduced in Bera
et al. [9]: we create an assignment ϕ′ by routing all points in ϕ∗with center s∗∈S∗to the center
in S nearest to s∗. Given that the clustering cost is metric-based, we use the triangle inequality
on the cost objective to argue that the cost of ϕ′ w.r.t. S is not more than (2 + α) times the cost of
ϕ∗w.r.t. S∗. Then, we use the mergeability property of the fairness objective to argue that ϕ′ has
a weakly better fairness than ϕ∗. We can, in fact, modify Algorithm 1 to include non-mergeable
fairness objectives, guaranteeing the same approximation ratio and time complexity:"
APPROXIMATING THE PARETO FRONT FOR THE CLUSTERING PROBLEM,0.08448540706605223,"Theorem 3.5. We can compute a (2+α, 1)-approximation of the Pareto set for the clustering problem
with a metric-based cost objective c and a pattern-based fairness objective f in time O(knl(k−1))."
APPROXIMATING THE PARETO FRONT FOR THE CLUSTERING PROBLEM,0.08602150537634409,"Proof Sketch: The trick here is to transform non-mergeable fairness objectives into mergeable ones,
and then apply Algorithm 1. In doing so, we control this transformation through re-assigning the cen-
ters of potentially empty clusters (which become an issue in non-mergeable fairness functions). Specif-
ically, for patterns that have empty clusters, we search for the best possible fairness over all ways to re-
assign the empty clusters’ centers to other centers’ locations and divide up the points in the non-empty
centers. A detailed description and proof for this modified algorithm can be found in Appendix A."
INTRACTABILITY,0.08755760368663594,"3.3
Intractability"
INTRACTABILITY,0.0890937019969278,"The running time of Algorithm 1 for computing the Pareto front has the parameters k, l in the exponent
of n. What evidence do we have that this computation is necessary?"
INTRACTABILITY,0.09062980030721966,"One reason would be that the sheer size of the Pareto front may be exponential. For some objectives,
including the BALANCE and the GROUP EGALITARIAN objectives defined in Section 2, the Pareto
front is provably of polynomial size. The reason is that all possible values of these objectives are
rational numbers involving integers that are all smaller than n, and there are O(n2) possible different
such rational numbers. For other objectives, there may be instances of exponential Pareto fronts, as
the objectives that sum over the clusters."
INTRACTABILITY,0.09216589861751152,"However, a different argument provides a justification of the algorithm’s exponential performance: In
several papers in recent literature (e.g., see [26, 27]), it is shown that, for a variety of cost functions
c and fairness objectives f (including all mentioned proportional violation based objectives), it is
NP-hard to find the assignment C that has the smallest c(C) under the constraint that f(C) ≤F
(for some bound F). We conclude that, unless P = NP, there is no polynomial-time algorithm for
outputting the Pareto front, for at least some combinations of c and f. As a footnote to this discussion,
the above complexity argument rules out polynomial algorithms, but not exponential algorithms of
the form, for example, O(2kn3), which is much more benign than O(n(k−1)l). These would be ruled
out, subject to complexity conjectures, if the problem of finding the least costly clustering subject to
fairness constraints were shown to be W-complete, a more severe form of complexity that rules out
this more benign exponential performance [23]. We leave this as an interesting open question in the
theory of the fairness-cost trade-off of clustering."
A POLYNOMIAL ALGORITHM FOR THE PARETO FRONT OF THE SUM OF IMBALANCES,0.09370199692780339,"3.4
A Polynomial Algorithm for the Pareto Front of the Sum of Imbalances"
A POLYNOMIAL ALGORITHM FOR THE PARETO FRONT OF THE SUM OF IMBALANCES,0.09523809523809523,"For specific cost and fairness objectives, there is still hope that polynomial-time algorithms exist.
As we show below, for a simple objective derived from the BALANCE objective, such an algorithm
is possible. For the SUM OF IMBALANCES fairness objective and a clustering objective defined
in Section 2, we want to compute the Pareto front when l = 2. Surprisingly, it turns out that this
problem can be solved in polynomial time by a reduction to the weighted matching problem."
A POLYNOMIAL ALGORITHM FOR THE PARETO FRONT OF THE SUM OF IMBALANCES,0.0967741935483871,Theorem 3.6. If l = 2 and the fairness objective f is the sum of imbalances f(C) = P
A POLYNOMIAL ALGORITHM FOR THE PARETO FRONT OF THE SUM OF IMBALANCES,0.09831029185867896,"i∈[k] |C1
i −C2
i |,
then the Pareto front of the assignment problem can be computed in polynomial time."
A POLYNOMIAL ALGORITHM FOR THE PARETO FRONT OF THE SUM OF IMBALANCES,0.09984639016897082,"Proof Sketch: The image of f is contained in the integer set {1, · · · , n}. For each potential value
j, we construct a graph Gj that contains X as nodes and another j ‘dummy’ nodes. We put an
edge (u, v) between every u, v ∈X with different sensitive attribute value with weight equal to the
cost mini(dp(u, i) + dp(v, i)). Between every data point u ∈X and dummy point v put an edge
(u, v) with cost mini dp(x, si). Finding the minimum cost perfect matching in this graph gives the
minimum cost of an assignment with fairness value j. The same result can be shown similarly for
the MAX IMBALANCE objective, maxi∈[k] |C1
i −C2
i | (Theorem A.5).
Remark 3.7. These objectives are quite natural extensions of the BALANCE objective, as they
minimize the sum or max, over the k clusters, of the deviation from equality between the two
groups. It is worth noting that slight modification of these objectives place the problem back in the
NP-complete space: A construction of Bercea et al. [10] (see also Esmaeili et al. [26], Theorem 5.1)
implies that for minimizing the deviations not from equality (1 : 1) but from the ratio 1 : 3, it is
NP-complete to find even the point of the Pareto front with the best fairness value."
EXPERIMENTS,0.10138248847926268,"4
Experiments"
EXPERIMENTS,0.10291858678955453,"We implement our proposed algorithm (Algorithm 1) for finding the Pareto front on three real-world
datasets and five fairness objectives, as detailed below."
EXPERIMENTS,0.10445468509984639,"Datasets:
We use the following real-world datasets for our experiments: the Adult dataset and
the Census dataset retrieved from the UCI repository (as the Census1990 version) [43, 46], and the
BlueBike trip history dataset.3 The Adult and Census datasets contain numeric attributes such as
income, age, education level, often used in applications of fair clustering [6, 19, 26]. The BlueBike
dataset contains the starting location, ending location, as well as various user attributes for users
of the BlueBike bike sharing system in the Boston area. We use as features the starting and ending
longitude and latitude values for all rides during a period of a week in May, 2016. These routes are
a proxy for common traffic patterns, for which clustering can inform of high-density areas, with
the purpose of deciding on new locations for bike stations or public transportation. Clustering and
related framings have long been used in facility location problems, for which fairness is a central
question [1, 41, 53, 62]. As the datasets are prohibitively large, we sample from each 1, 000 data
points. Further details about the datasets can be found in Appendix C."
EXPERIMENTS,0.10599078341013825,"Objectives:
We implement the k-means clustering objective and five different fairness objectives,
as defined in Section 2 (BALANCE, GROUP UTILITARIAN, GROUP UTILITARIAN-SUM, GROUP
EGALITARIAN, and GROUP EGALITARIAN-SUM)."
EXPERIMENTS,0.10752688172043011,"Experimental details:
We first note that our approach for finding the Pareto front is agnostic to
the specific vanilla clustering algorithm used. For our datasets, we use the k-means++ clustering
algorithm as the vanilla clustering that has an approximation ratio of O(log(k)) [5]. All datasets have
numeric attributes, allowing a direct embedding into Euclidean space and using k-means++ directly
on the features. We use the self-reported gender (male or female) as the sensitive attribute for all
datasets. Each sensitive attribute a has a proportion pa in the general population. For the proportional
violation objectives, we set upper and lower bounds as a δ-deviation from the true proportions (pa)a:
αa = (1 + δ)pa, βa = (1 −δ)pa. We set δ ∈[0.005, 0.05] for all experiments and k = 2 clusters.
Additional experiments for k = 3 are reported in Appendix E, noting qualitatively similar results.
All experiments are run on local computers, using Python 3.9, k-means++ [5], NetworkX [33], and"
EXPERIMENTS,0.10906298003072197,3The BlueBike trip history dataset is retrieved from https://bluebikes.com/system-data.
EXPERIMENTS,0.11059907834101383,"CPLEX for the implementation of the FCBC algorithm [52, 26] with ϵ = 2−10 and N = 50 runs. An
empirical analysis of the running time for Algorithms 1 and 2 can be found in Section D, Figure 5.4"
PARETO FRONT ON REAL-WORLD DATA,0.11213517665130568,"4.1
Pareto Front on Real-World Data"
PARETO FRONT ON REAL-WORLD DATA,0.11367127496159754,"Figure 1 illustrates the Pareto front recovered by our dynamic programming approach (Algorithm 1)
on the real-world datasets: the curves obtained are an exact recovery of the Pareto front for the
assignment problem (as we are not re-computing the clusters centers during the implementation), and
thus an approximation for the true Pareto front of the clustering problem. We note that the BALANCE
objective and the proportional violation objectives differ: higher balance is considered fairer, whereas
lower proportional violation is considered fairer, hence the different shapes of the Pareto fronts.
From an evaluation point of view, for each assignment found on the Pareto front, we compute its
clustering cost with respect to its actual centers, rather than the initial centers found by k-means++."
PARETO FRONT ON REAL-WORLD DATA,0.1152073732718894,"We note that the Pareto front is often, but not always strictly convex or concave, as it simply contains
all the undominated points. We note that the proportional violation values will always be worse for
the summed objectives than for their min-max equivalents, since the worst proportional violation
∆C
a is always non-negative, ∀a ∈[l], C ∈C."
PARETO FRONT ON REAL-WORLD DATA,0.11674347158218126,"A particular advantage of finding the entire Pareto front is visible for the BALANCE objective in
all datasets: as the clustering cost increases, the gain in the BALANCE objective becomes negligible;
thus, a practitioner wishing to achieve some level of fairness may gain a lot in quality by allowing
BALANCE to decrease by a minimal amount."
PARETO FRONT ON REAL-WORLD DATA,0.11827956989247312,"4200
4220
4240
4260
4280
4300
Clustering cost 0.27 0.28 0.29 0.30 0.31 0.32 0.33"
PARETO FRONT ON REAL-WORLD DATA,0.11981566820276497,Balance Adult
PARETO FRONT ON REAL-WORLD DATA,0.12135176651305683,(a) Balance
PARETO FRONT ON REAL-WORLD DATA,0.1228878648233487,"4200
4205
4210
Clustering cost 0.00 0.02 0.04 0.06 0.08 0.10"
PARETO FRONT ON REAL-WORLD DATA,0.12442396313364056,Proportional violation Adult
PARETO FRONT ON REAL-WORLD DATA,0.1259600614439324,(b) Group Util
PARETO FRONT ON REAL-WORLD DATA,0.12749615975422426,"4200
4205
4210
Clustering cost 0.00 0.05 0.10 0.15"
PARETO FRONT ON REAL-WORLD DATA,0.12903225806451613,Proportional violation Adult
PARETO FRONT ON REAL-WORLD DATA,0.130568356374808,(c) Group Util-Sum
PARETO FRONT ON REAL-WORLD DATA,0.13210445468509985,"4200
4205
4210
Clustering cost 0.00 0.01 0.02 0.03 0.04 0.05 0.06"
PARETO FRONT ON REAL-WORLD DATA,0.1336405529953917,Proportional violation Adult
PARETO FRONT ON REAL-WORLD DATA,0.13517665130568357,(d) Group Egalit
PARETO FRONT ON REAL-WORLD DATA,0.13671274961597543,"4200
4205
4210
Clustering cost 0.00 0.01 0.02 0.03 0.04 0.05 0.06"
PARETO FRONT ON REAL-WORLD DATA,0.1382488479262673,Proportional violation Adult
PARETO FRONT ON REAL-WORLD DATA,0.13978494623655913,(e) Group Egalit-Sum
PARETO FRONT ON REAL-WORLD DATA,0.141321044546851,"53000
54000
55000
56000
Clustering cost 0.485 0.486 0.487 0.488 0.489 0.490 0.491"
PARETO FRONT ON REAL-WORLD DATA,0.14285714285714285,Balance
PARETO FRONT ON REAL-WORLD DATA,0.1443932411674347,Census
PARETO FRONT ON REAL-WORLD DATA,0.14592933947772657,(f) Balance
PARETO FRONT ON REAL-WORLD DATA,0.14746543778801843,53150 53200 53250 53300 53350 53400
PARETO FRONT ON REAL-WORLD DATA,0.1490015360983103,Clustering cost 0.00 0.01 0.02 0.03 0.04
PARETO FRONT ON REAL-WORLD DATA,0.15053763440860216,Proportional violation
PARETO FRONT ON REAL-WORLD DATA,0.15207373271889402,Census
PARETO FRONT ON REAL-WORLD DATA,0.15360983102918588,(g) Group Util
PARETO FRONT ON REAL-WORLD DATA,0.15514592933947774,53150 53200 53250 53300 53350 53400
PARETO FRONT ON REAL-WORLD DATA,0.15668202764976957,Clustering cost 0.00 0.01 0.02 0.03 0.04 0.05 0.06
PARETO FRONT ON REAL-WORLD DATA,0.15821812596006143,Proportional violation
PARETO FRONT ON REAL-WORLD DATA,0.1597542242703533,Census
PARETO FRONT ON REAL-WORLD DATA,0.16129032258064516,(h) Group Util-Sum
PARETO FRONT ON REAL-WORLD DATA,0.16282642089093702,53150 53200 53250 53300 53350 53400
PARETO FRONT ON REAL-WORLD DATA,0.16436251920122888,Clustering cost 0.000 0.005 0.010 0.015 0.020
PARETO FRONT ON REAL-WORLD DATA,0.16589861751152074,Proportional violation
PARETO FRONT ON REAL-WORLD DATA,0.1674347158218126,Census
PARETO FRONT ON REAL-WORLD DATA,0.16897081413210446,(i) Group Egalit
PARETO FRONT ON REAL-WORLD DATA,0.17050691244239632,53150 53200 53250 53300 53350 53400
PARETO FRONT ON REAL-WORLD DATA,0.17204301075268819,Clustering cost 0.000 0.005 0.010 0.015 0.020 0.025 0.030
PARETO FRONT ON REAL-WORLD DATA,0.17357910906298002,Proportional violation
PARETO FRONT ON REAL-WORLD DATA,0.17511520737327188,Census
PARETO FRONT ON REAL-WORLD DATA,0.17665130568356374,(j) Group Egalit-Sum
PARETO FRONT ON REAL-WORLD DATA,0.1781874039938556,"2388
2389
2390
2391
2392
Clustering cost 0.250 0.252 0.254 0.256 0.258 0.260"
PARETO FRONT ON REAL-WORLD DATA,0.17972350230414746,Balance
PARETO FRONT ON REAL-WORLD DATA,0.18125960061443933,BlueBike
PARETO FRONT ON REAL-WORLD DATA,0.1827956989247312,(k) Balance
PARETO FRONT ON REAL-WORLD DATA,0.18433179723502305,"2388
2389
2390
2391
Clustering cost 0.00 0.01 0.02 0.03 0.04"
PARETO FRONT ON REAL-WORLD DATA,0.1858678955453149,Proportional violation
PARETO FRONT ON REAL-WORLD DATA,0.18740399385560677,BlueBike
PARETO FRONT ON REAL-WORLD DATA,0.1889400921658986,(l) Group Util
PARETO FRONT ON REAL-WORLD DATA,0.19047619047619047,"2388
2389
2390
2391
Clustering cost 0.00 0.01 0.02 0.03 0.04 0.05 0.06"
PARETO FRONT ON REAL-WORLD DATA,0.19201228878648233,Proportional violation
PARETO FRONT ON REAL-WORLD DATA,0.1935483870967742,BlueBike
PARETO FRONT ON REAL-WORLD DATA,0.19508448540706605,(m) Group Util-Sum
PARETO FRONT ON REAL-WORLD DATA,0.1966205837173579,"2388
2389
2390
2391
Clustering cost 0.000 0.005 0.010 0.015 0.020"
PARETO FRONT ON REAL-WORLD DATA,0.19815668202764977,Proportional violation
PARETO FRONT ON REAL-WORLD DATA,0.19969278033794163,BlueBike
PARETO FRONT ON REAL-WORLD DATA,0.2012288786482335,(n) Group Egalit
PARETO FRONT ON REAL-WORLD DATA,0.20276497695852536,"2388
2389
2390
2391
Clustering cost 0.000 0.005 0.010 0.015 0.020 0.025 0.030"
PARETO FRONT ON REAL-WORLD DATA,0.20430107526881722,Proportional violation
PARETO FRONT ON REAL-WORLD DATA,0.20583717357910905,BlueBike
PARETO FRONT ON REAL-WORLD DATA,0.2073732718894009,(o) Group Egalit-Sum
PARETO FRONT ON REAL-WORLD DATA,0.20890937019969277,"Figure 1: Pareto front recovered by Algorithm 1 for the Adult, Census, and BlueBike datasets (by
row), for various fairness objectives (by column), for k = 2 clusters."
EXPLORING FASTER PARETO FRONT APPROXIMATIONS,0.21044546850998463,"4.2
Exploring Faster Pareto Front Approximations"
EXPLORING FASTER PARETO FRONT APPROXIMATIONS,0.2119815668202765,"We explore faster algorithms for recovering the Pareto front for the clustering problem. In particular,
we leverage a recently proposed linear programming approach that imposes an upper bound on the
clustering objective and optimizes a fairness objective, the FCBC algorithm proposed by Esmaeili
et al. [26]. For the GROUP UTILITARIAN and GROUP EGALITARIAN objectives with a clustering"
EXPLORING FASTER PARETO FRONT APPROXIMATIONS,0.21351766513056836,4All code and data used in the paper can be found at this link.
EXPLORING FASTER PARETO FRONT APPROXIMATIONS,0.21505376344086022,"cost upper bound input U, FCBC presents a polynomial-time approach for finding an approximation
of a point x on the Pareto front that has a clustering cost upper bounded by a quantity (2 + α)U
with a fairness additive approximation of η. Here, α is the approximation ratio of a vanilla clustering
algorithm for the clustering objective, and η is an additive approximation for the fairness objective.
Thus, we can extend the W-approximation of a Pareto set definition (Definition 3.3) to include an
additive approximation term: for parameters W = ((wc, vc), (wf, vf)), we can define the (W, V)-
approximation of the Pareto set XP as a set of feasible points X′
P such that ∀x ∈XP , ∃x′ ∈X′
P
such that c(x′) ≤wc · c(x) + vc and f(x′) ≤wf · f(x) + vf. We note that Algorithm 1 gives only a
multiplicative approximation, so vc = vf = 0. In contrast, for a point x ∈XP on the true Pareto
front, FCBC recovers a ((2 + α, 0), (1, η))-approximation.5"
EXPLORING FASTER PARETO FRONT APPROXIMATIONS,0.21658986175115208,"We extend the FCBC algorithm by allowing a sweep over the clustering cost upper bound U, thus, in
theory, obtaining an approximation of the Pareto front in polynomial time (for a detailed description,
see Algorithm 2 in Appendix D)."
EXPLORING FASTER PARETO FRONT APPROXIMATIONS,0.21812596006144394,"Figure 2 shows that repeated FCBC (Algorithm 2) recovers few points on the Pareto front recovered
by Algorithm 1: sometimes it recovered the vanilla clustering cost and fairness (the upper most
left point in panels b,c,e,f), whereas in other cases it recovers dominated clustering assignments (in
panels a-d). We attribute this inaccuracy in recovery to the additive approximation in the fairness
objective. Furthermore, whereas both our dynamic programming approach and repeated FCBC have
an approximation ratio of (2 + α) in the clustering objective, dynamic programming often gets a
strictly better cost for similar fairness values. In other words, where repeated FCBC gains in running
time,6 it loses in recovery accuracy and clustering cost. This is particularly problematic when the
only point recovered by FCBC is the vanilla clustering assignment: this means that even when a
practitioner may be willing to trade-off significant clustering cost in order to improve fairness, that
trade-off is not realizable in practice solely through FCBC."
EXPLORING FASTER PARETO FRONT APPROXIMATIONS,0.2196620583717358,"Furthermore, the FCBC algorithm does not work for objectives summing over the clusters, such
as GROUP UTILITARIAN-SUM and GROUP EGALITARIAN-SUM. For such objectives, there is no
polynomial time algorithm that can recover the Pareto front to within an additive approximation of
O(nδ), for δ ∈[0, 1) (see Theorem 7.1 in Esmaeili et al. [26]). Our approach, however, can also
include such objectives, as we show both in theory and in practice."
DISCUSSION,0.22119815668202766,"5
Discussion"
DISCUSSION,0.2227342549923195,"Overall, our work shows the versatility of our proposed algorithms for a variety of fairness and
clustering objectives. We provide simple properties sufficient in theory for the recovery of the Pareto
front for the (clustering, fairness)-biobjective optimization problem, with extensive experiments
on real-world datasets. We discuss limitations and future directions of our work in this section."
DISCUSSION,0.22427035330261136,"First, while our approach has the advantage of being agnostic to specific objectives, it loses in running
time as compared to approaches that optimize for specific fairness objectives. While previous work
provides approximation algorithms for optimization clustering under a fairness constraint, none offers
a method for computing the Pareto front. On the question ‘can we have faster algorithms with worse
approximation bounds?’, the answer is yes. Our paper provides (the first, to our knowledge) such ex-
ploration: We show in Section 4.2 that we can adapt such polynomial-time methods to compute an ap-
proximation of the Pareto front; however, what we gain in runtime, we lose in approximation bounds:
the repeated FCBC algorithm has an additive approximation on the fairness objective that can get large
in practice (we get a different Pareto front, with points quite far away in the objective cost, compared to
the dynamic programming approach), and with no theoretical bounds on the additive approximation."
DISCUSSION,0.22580645161290322,"A future direction could study faster algorithms that can recover a similar approximation of the
Pareto front. Interesting theoretical open questions emerge: while our analysis ruled out polynomial
algorithms for general objectives, are there exponential algorithms (i.e. of the form O(2kn3)), that
still provide an improvement from O(n(k−1)l)-type of algorithms? And, are there other objectives"
DISCUSSION,0.22734254992319508,"5In particular, η is dependent on the fairness objective, on U, and on the specific instance of the fair clustering
problem (see Theorem 6.1 in Esmaeili et al. [26]). A potential limitation of this approximation is that η is not
efficiently computable in closed-form for a particular instance.
6The FCBC algorithm uses linear programming through the simplex method, with a worst-case running time
of O(2n); in practice, it is faster than that, as noted in the Appendix."
DISCUSSION,0.22887864823348694,"4200
4225
4250
4275
4300
Clustering cost 0.00 0.02 0.04 0.06 0.08 0.10"
DISCUSSION,0.2304147465437788,Proportional violation Adult
DISCUSSION,0.23195084485407066,"Dyn Progr
FCBC"
DISCUSSION,0.23348694316436253,(a) Group Util
DISCUSSION,0.2350230414746544,"55000
57500
60000
62500
65000
Clustering cost 0.00 0.01 0.02 0.03 0.04"
DISCUSSION,0.23655913978494625,Proportional violation
DISCUSSION,0.23809523809523808,Census
DISCUSSION,0.23963133640552994,"Dyn Progr
FCBC"
DISCUSSION,0.2411674347158218,(b) Group Util
DISCUSSION,0.24270353302611367,"2388
2389
2390
2391
Clustering cost 0.00 0.01 0.02 0.03 0.04"
DISCUSSION,0.24423963133640553,Proportional violation
DISCUSSION,0.2457757296466974,BlueBike
DISCUSSION,0.24731182795698925,"Dyn Progr
FCBC"
DISCUSSION,0.2488479262672811,(c) Group Util
DISCUSSION,0.250384024577573,"4200
4225
4250
4275
4300
4325
Clustering cost 0.00 0.02 0.04 0.06"
DISCUSSION,0.2519201228878648,Proportional violation Adult
DISCUSSION,0.2534562211981567,"Dyn Progr
FCBC"
DISCUSSION,0.25499231950844853,(d) Group Egalit
DISCUSSION,0.2565284178187404,"53500
54000
54500
55000
Clustering cost 0.00 0.01 0.02 0.03 0.04 0.05"
DISCUSSION,0.25806451612903225,Proportional violation
DISCUSSION,0.25960061443932414,Census
DISCUSSION,0.261136712749616,"Dyn Progr
FCBC"
DISCUSSION,0.2626728110599078,(e) Group Egalit
DISCUSSION,0.2642089093701997,"2388
2389
2390
2391
Clustering cost 0.000 0.005 0.010 0.015 0.020"
DISCUSSION,0.26574500768049153,Proportional violation
DISCUSSION,0.2672811059907834,BlueBike
DISCUSSION,0.26881720430107525,"Dyn Progr
FCBC"
DISCUSSION,0.27035330261136714,(f) Group Egalit
DISCUSSION,0.271889400921659,"Figure 2: Pareto front recovered by Algorithm 1 (labeled ‘Dyn Progr’, blue) and by Algorithm 2
(labeled ‘FCBC’, orange), for k = 2 clusters."
DISCUSSION,0.27342549923195086,"that admit polynomial-time algorithms for computing an approximate Pareto, aside from SUM/MAX
OF IMBALANCES? Furthermore, future work could investigate algorithms for recovering the Pareto
front for fairness objectives that are not pattern-based, which is a prerequisite for our algorithms. We
provide some examples of such objectives in the Appendix."
DISCUSSION,0.2749615975422427,"Our approach is best suited for group fairness definitions. Extending this work to other definitions
would be an excellent avenue for future work. We note that for some individual fairness definitions,
the notion of a Pareto front does not apply: for example, the socially fair k-means clustering notion
proposed by Ghadiri et al. [31] defines a single optimization objective that already incorporates
fairness (by minimizing the max distance between points in each group and their cluster centers).
With this definition, the fairness objective and the clustering objective are not separated in a
multi-objective optimization problem, but rather combined in a single objective. Therefore, there
is no Pareto front, since this notion applies to a multi-objective optimization problem. For other
definitions of individual fairness, such as recent adaptations of individual fairness under bi-criteria
optimization problems [50], one can apply a repeated approximation algorithm under an upper
bound on one of the objectives (similar to the repeated-FCBC algorithm). In doing so, one would
obtain loose approximation guarantees (see, for example, the approximation guarantee for individual
fairness proved by Mahabadi and Vakilian [50]). Dynamic programming approaches would not
directly apply; however, we think this would be an excellent avenue for future work."
DISCUSSION,0.2764976958525346,"Finally, we assumed that the sensitive attributes are disjoint. For overlapping attributes, one could
assign a new sensitive attribute to every overlap set and apply our approach, however, with a
significant increase in running time. Future work could investigate alternative approaches that
optimize running time for overlapping attributes."
DISCUSSION,0.2780337941628264,Acknowledgments and Disclosure of Funding
DISCUSSION,0.27956989247311825,"The authors would like to thank Vivian Y. Nastl for valuable feedback on earlier drafts of the paper.
A.-A. S. acknowledges support from the Tübingen AI Center. M. Y. acknowledges support from NSF
grants CCF-2332922 and CCF-2212233."
REFERENCES,0.28110599078341014,References
REFERENCES,0.282642089093702,"[1] Mohsen Abbasi, Aditya Bhaskara, and Suresh Venkatasubramanian. Fair clustering via equitable
group representations. In Proceedings of the 2021 ACM Conference on Fairness, Accountability,
and Transparency, pages 504–514, 2021."
REFERENCES,0.28417818740399386,"[2] Sara Ahmadian, Alessandro Epasto, Ravi Kumar, and Mohammad Mahdian. Clustering without
over-representation. In Proceedings of the 25th ACM SIGKDD International Conference on
Knowledge Discovery & Data Mining, pages 267–275, 2019."
REFERENCES,0.2857142857142857,"[3] Sara Ahmadian, Ashkan Norouzi-Fard, Ola Svensson, and Justin Ward. Better guarantees for
k-means and euclidean k-median by primal-dual algorithms. SIAM Journal on Computing, 49
(4):FOCS17–97, 2019."
REFERENCES,0.2872503840245776,"[4] Daniel Aloise, Amit Deshpande, Pierre Hansen, and Preyas Popat. NP-hardness of Euclidean
sum-of-squares clustering. Machine learning, 75:245–248, 2009."
REFERENCES,0.2887864823348694,"[5] David Arthur, Sergei Vassilvitskii, et al. k-means++: The advantages of careful seeding. In
ACM-SIAM Symposium on Discrete Algorithms, volume 7, pages 1027–1035, 2007."
REFERENCES,0.2903225806451613,"[6] Arturs Backurs, Piotr Indyk, Krzysztof Onak, Baruch Schieber, Ali Vakilian, and Tal Wagner.
Scalable fair clustering. In International Conference on Machine Learning, pages 405–413.
PMLR, 2019."
REFERENCES,0.29185867895545314,"[7] MohammadHossein Bateni, Vincent Cohen-Addad, Alessandro Epasto, and Silvio Lattanzi.
A scalable algorithm for individually fair k-means clustering. In International Conference on
Artificial Intelligence and Statistics, pages 3151–3159. PMLR, 2024."
REFERENCES,0.29339477726574503,"[8] Cristina Bazgan, Laurent Gourvès, and Jérôme Monnot. Approximation with a fixed number of
solutions of some multiobjective maximization problems. Journal of Discrete Algorithms, 22:
19–29, 2013."
REFERENCES,0.29493087557603687,"[9] Suman Bera, Deeparnab Chakrabarty, Nicolas Flores, and Maryam Negahbani. Fair algorithms
for clustering. Advances in Neural Information Processing Systems, 32, 2019."
REFERENCES,0.2964669738863287,"[10] Ioana O Bercea, Martin Groß, Samir Khuller, Aounon Kumar, Clemens Rösner, Daniel R
Schmidt, and Melanie Schmidt. On the cost of essentially fair clusterings. arXiv preprint
arXiv:1811.10319, 2018."
REFERENCES,0.2980030721966206,"[11] Fritz Bökler and Markus Chimani. Approximating multiobjective shortest path in practice. In
2020 Proceedings of the Twenty-Second Workshop on Algorithm Engineering and Experiments
(ALENEX), pages 120–133. SIAM, 2020."
REFERENCES,0.2995391705069124,"[12] Stephen P Boyd and Lieven Vandenberghe. Convex optimization. Cambridge University Press,
2004."
REFERENCES,0.3010752688172043,"[13] Felix Brandt, Vincent Conitzer, Ulle Endriss, Jérôme Lang, and Ariel D Procaccia. Handbook
of computational social choice. Cambridge University Press, 2016."
REFERENCES,0.30261136712749614,"[14] Jarosław Byrka, Thomas Pensyl, Bartosz Rybicki, Aravind Srinivasan, and Khoa Trinh. An
improved approximation for k-median and positive correlation in budgeted optimization. ACM
Transactions on Algorithms (TALG), 13(2):1–31, 2017."
REFERENCES,0.30414746543778803,"[15] Darshan Chakrabarti, John P Dickerson, Seyed A Esmaeili, Aravind Srinivasan, and Leonidas
Tsepenekas. A new notion of individually fair clustering: α-equitable k-center. In International
Conference on Artificial Intelligence and Statistics, pages 6387–6408. PMLR, 2022."
REFERENCES,0.30568356374807987,"[16] Weiyu Chen and James Kwok. Multi-objective deep learning with adaptive reference vectors.
Advances in Neural Information Processing Systems, 35:32723–32735, 2022."
REFERENCES,0.30721966205837176,"[17] Xingyu Chen, Brandon Fain, Liang Lyu, and Kamesh Munagala. Proportionally fair clustering.
In International Conference on Machine Learning, pages 1032–1041. PMLR, 2019."
REFERENCES,0.3087557603686636,"[18] Anshuman Chhabra, Karina Masalkovait˙e, and Prasant Mohapatra. An overview of fairness in
clustering. IEEE Access, 9:130698–130720, 2021."
REFERENCES,0.3102918586789555,"[19] Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, and Sergei Vassilvitskii. Fair clustering
through fairlets. Advances in Neural Information Processing Systems, 30, 2017."
REFERENCES,0.3118279569892473,"[20] Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan. A fast and elitist
multiobjective genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation,
6(2):182–197, 2002."
REFERENCES,0.31336405529953915,"[21] Ilias Diakonikolas and Mihalis Yannakakis. Small approximate Pareto sets for biobjective
shortest paths and other problems. SIAM Journal on Computing, 39(4):1340–1371, 2010."
REFERENCES,0.31490015360983103,"[22] John Dickerson, Seyed Esmaeili, Jamie H Morgenstern, and Claire Jie Zhang. Doubly con-
strained fair clustering. Advances in Neural Information Processing Systems, 36, 2024."
REFERENCES,0.31643625192012287,"[23] Rodney G Downey and Michael Ralph Fellows. Parameterized complexity. Springer Science &
Business Media, 2012."
REFERENCES,0.31797235023041476,"[24] Jack Edmonds. Maximum matching and a polyhedron with 0,1 vertices. J. Res. Nat. Bur.
Standards, 69B:125–130, 1965."
REFERENCES,0.3195084485407066,"[25] Thomas Erlebach, Hans Kellerer, and Ulrich Pferschy. Approximating multiobjective knapsack
problems. Management Science, 48(12):1603–1612, 2002."
REFERENCES,0.3210445468509985,"[26] Seyed Esmaeili, Brian Brubach, Aravind Srinivasan, and John Dickerson. Fair clustering under
a bounded cost. Advances in Neural Information Processing Systems, 34:14345–14357, 2021."
REFERENCES,0.3225806451612903,"[27] Seyed A Esmaeili, Sharmila Duppala, John P Dickerson, and Brian Brubach. Fair labeled
clustering. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and
Data Mining, pages 327–335, 2022."
REFERENCES,0.3241167434715822,"[28] Reza Zanjirani Farahani, Maryam SteadieSeifi, and Nasrin Asgari. Multiple criteria facility
location problems: A survey. Applied mathematical modelling, 34(7):1689–1709, 2010."
REFERENCES,0.32565284178187404,"[29] Laurie E Felland, Johanna R Lauer, and Peter J Cunningham. Suburban poverty and the health
care safety net. Center for Studying Health System Change Washington (DC), 2009."
REFERENCES,0.3271889400921659,"[30] Harold N. Gabow. Data structures for weighted matching and extensions to b-matching and
f-factors. ACM Trans. Algorithms, 14(3):39:1–39:80, 2018."
REFERENCES,0.32872503840245776,"[31] Mehrdad Ghadiri, Samira Samadi, and Santosh Vempala. Socially fair k-means clustering. In
Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pages
438–448, 2021."
REFERENCES,0.3302611367127496,"[32] Shivam Gupta, Ganesh Ghalme, Narayanan C Krishnan, and Shweta Jain. Efficient algorithms
for fair clustering with a new notion of fairness. Data Mining and Knowledge Discovery, 37(5):
1959–1997, 2023."
REFERENCES,0.3317972350230415,"[33] Aric Hagberg, Dan Schult, Pieter Swart, D Conway, L Séguin-Charbonneau, C Ellison, B Ed-
wards, and J Torrents. Networkx. high productivity software for complex networks. Webová
strá nka https://networkx. lanl. gov/wiki, 2013."
REFERENCES,0.3333333333333333,"[34] Vahid Hajipour, Parviz Fattahi, Madjid Tavana, and Debora Di Caprio. Multi-objective multi-
layer congested facility location-allocation problem optimization with Pareto-based meta-
heuristics. Applied Mathematical Modelling, 40(7-8), 2016."
REFERENCES,0.3348694316436252,"[35] SI Harewood. Emergency ambulance deployment in barbados: a multi-objective approach.
Journal of the Operational Research Society, 53(2):185–192, 2002."
REFERENCES,0.33640552995391704,"[36] Mordechai I Henig. The shortest path problem with two objective functions. European Journal
of Operational Research, 25(2):281–291, 1986."
REFERENCES,0.3379416282642089,"[37] Long P Hoang, Dung D Le, Tran Anh Tuan, and Tran Ngoc Thang. Improving Pareto front
learning via multi-sample hypernetworks. In Proceedings of the AAAI Conference on Artificial
Intelligence, volume 37, pages 7875–7883, 2023."
REFERENCES,0.33947772657450076,"[38] Dorit S Hochbaum and David B Shmoys. A unified approach to approximation algorithms for
bottleneck problems. Journal of the ACM (JACM), 33(3):533–550, 1986."
REFERENCES,0.34101382488479265,"[39] Bo Huang, P Fery, L Xue, and Y Wang. Seeking the pareto front for multiobjective spatial
optimization problems. International Journal of Geographical Information Science, 22(5):
507–526, 2008."
REFERENCES,0.3425499231950845,"[40] Lingxiao Huang, Shaofeng Jiang, and Nisheeth Vishnoi. Coresets for clustering with fairness
constraints. Advances in Neural Information Processing Systems, 32, 2019."
REFERENCES,0.34408602150537637,"[41] Christopher Jung, Sampath Kannan, and Neil Lutz. A center in your neighborhood: Fairness in
facility location. arXiv preprint arXiv:1908.09041, 2019."
REFERENCES,0.3456221198156682,"[42] Kathrin Klamroth and Margaret M Wiecek. Dynamic programming approaches to the multiple
criteria knapsack problem. Naval Research Logistics (NRL), 47(1):57–76, 2000."
REFERENCES,0.34715821812596004,"[43] Ron Kohavi. Scaling up the accuracy of naive-bayes classifiers: A decision-tree hybrid. In
Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining,
volume 96, pages 202–207, 1996."
REFERENCES,0.3486943164362519,"[44] Michael M Kostreva and Malgorzata M Wiecek. Time dependency in multiple objective
dynamic programming. Journal of Mathematical Analysis and Applications, 173:289–289,
1993."
REFERENCES,0.35023041474654376,"[45] Bo Li, Lijun Li, Ankang Sun, Chenhao Wang, and Yingfan Wang. Approximate group fairness
for clustering. In International Conference on Machine Learning, pages 6381–6391. PMLR,
2021."
REFERENCES,0.35176651305683565,"[46] Moshe Lichman. UCI machine learning repository, 2013."
REFERENCES,0.3533026113671275,"[47] Xi Lin, Hui-Ling Zhen, Zhenhua Li, Qing-Fu Zhang, and Sam Kwong. Pareto multi-task
learning. Advances in Neural Information Processing Systems, 32, 2019."
REFERENCES,0.3548387096774194,"[48] Xi Lin, Zhiyuan Yang, Qingfu Zhang, and Sam Kwong. Controllable Pareto multi-task learning.
arXiv preprint arXiv:2010.06313, 2020."
REFERENCES,0.3563748079877112,"[49] Suyun Liu and Luis Nunes Vicente. The stochastic multi-gradient algorithm for multi-objective
optimization and its application to supervised machine learning. Annals of Operations Research,
pages 1–30, 2021."
REFERENCES,0.3579109062980031,"[50] Sepideh Mahabadi and Ali Vakilian. Individual fairness for k-clustering. In International
Conference on Machine Learning, pages 6586–6596. PMLR, 2020."
REFERENCES,0.35944700460829493,"[51] Debabrata Mahapatra and Vaibhav Rajan. Multi-task learning with user preferences: Gradient
descent with controlled ascent in Pareto optimization. In International Conference on Machine
Learning, pages 6597–6607. PMLR, 2020."
REFERENCES,0.36098310291858676,"[52] IBM CPLEX User’s Manual. Version 12 release 7. IBM ILOG CPLEX Optimization, 2016."
REFERENCES,0.36251920122887865,"[53] Michael T Marsh and David A Schilling. Equity measurement in facility location analysis: A
review and framework. European Journal of Operational Research, 74(1):1–17, 1994."
REFERENCES,0.3640552995391705,"[54] Maryam Negahbani and Deeparnab Chakrabarty. Better algorithms for individually fair k-
clustering. Advances in Neural Information Processing Systems, 34:13340–13351, 2021."
REFERENCES,0.3655913978494624,"[55] Christos H Papadimitriou and Mihalis Yannakakis. On the approximability of trade-offs and
optimal access of web sources. In Proceedings 41st Annual Symposium on Foundations of
Computer Science, pages 86–92. IEEE, 2000."
REFERENCES,0.3671274961597542,"[56] Konstantinos E Parsopoulos and Michael N Vrahatis. Particle swarm optimization method in
multiobjective problems. In Proceedings of the 2002 ACM Symposium on Applied Computing,
pages 603–607, 2002."
REFERENCES,0.3686635944700461,"[57] John Preston and Fiona Rajé. Accessibility, mobility and transport-related social exclusion.
Journal of transport geography, 15(3):151–160, 2007."
REFERENCES,0.37019969278033793,"[58] Seyed Habib A Rahmati, Vahid Hajipour, and Seyed Taghi Akhavan Niaki. A soft-computing
Pareto-based meta-heuristic algorithm for a multi-objective multi-server facility location prob-
lem. Applied Soft Computing, 13(4):1728–1740, 2013."
REFERENCES,0.3717357910906298,"[59] Juana L Redondo, José Fernández, José Domingo Álvarez Hervás, Aránzazu Gila Arrondo, and
Pilar M Ortigosa. Approximating the Pareto-front of a planar bi-objective competitive facility
location and design problem. Computers & Operations Research, 62:337–349, 2015."
REFERENCES,0.37327188940092165,"[60] Michael Ruchte and Josif Grabocka. Scalable Pareto front approximation for deep multi-
objective learning. In 2021 IEEE International Conference on Data Mining (ICDM), pages
1306–1311. IEEE, 2021."
REFERENCES,0.37480798771121354,"[61] Hisashi Tamaki, Hajime Kita, and Shigenobu Kobayashi. Multi-objective optimization by
genetic algorithms: A review. In Proceedings of IEEE International Conference on Evolutionary
Computation, pages 517–522. IEEE, 1996."
REFERENCES,0.3763440860215054,"[62] Ali Vakilian and Mustafa Yalciner. Improved approximation algorithms for individually fair
clustering. In International Conference on Artificial Intelligence and Statistics, pages 8758–
8779. PMLR, 2022."
REFERENCES,0.3778801843317972,"[63] Bernardo Villarreal and Mark H Karwan. Multicriteria integer programming: A (hybrid)
dynamic programming recursive approach. Mathematical programming, 21:204–223, 1981."
REFERENCES,0.3794162826420891,"[64] Arthur Warburton. Approximation of Pareto optima in multiple-objective, shortest-path prob-
lems. Operations research, 35(1):70–79, 1987."
REFERENCES,0.38095238095238093,"[65] Qingfu Zhang and Hui Li. MOEA/D: A multiobjective evolutionary algorithm based on
decomposition. IEEE Transactions on Evolutionary Computation, 11(6):712–731, 2007."
REFERENCES,0.3824884792626728,"A
Complete Proofs"
REFERENCES,0.38402457757296465,"Proof of Theorem 3.2: Define VP as the set of clusterings C that have the pettern P C = P and C is a
clustering of Xj. Let c be the metric-based cost function for the assignment to centers S, which is
parameterized by a distance function d and non-negative exponent p. We will argue that, for all j, the
clustering C stored at Tj[P] has the property that C = arg minC′∈VP c(C′). We will show that this
invariant always holds by induction on the number of data points in the current level of the table j
(equivalently, the number of points clustered by C in the main loop of Algorithm 1). The base case is
j = 0, where we store the empty clustering, the unique clustering of 0 points."
REFERENCES,0.38556067588325654,"Suppose we have some pattern P for the set of the first j points in our ordering, Xj. Let C∗=
arg minC∈VP c(C), so C∗is optimal cost for P. Point xj must be in some cluster Ci ∈C∗. The
clustering C′
i of the remaining points (which are exactly the first j −1 points from the data) induces
some pattern P ′
i = P C′
i which is an Xj−1-pattern. Since C∗was assumed to be of optimal quality, the
clustering C′
i must have the property that C′
i = arg minC∈Vp′
i c(C). Otherwise, C′
i could be replaced in
C∗with the lower cost clustering that has the same pattern and reduce the cost of C∗(a contradiction)."
REFERENCES,0.3870967741935484,"We have shown that C∗= Ci, where Ci = C′
i + xj is generated by assigning the first j −1 points
according to C′
i, and then adding point xj to cluster i. By the inductive assumption Tj−1[P ′
i] correctly
stores the optimal C′
i."
REFERENCES,0.38863287250384027,"Since Algorithm 1 minimizes c(Ci) over cluster indices i, we correctly compute the optimal clustering
of j points that maps to P. All candidate points for the Pareto set of the assignment problem are
stored in Tn, meaning that every clustering C′ of X is weakly dominated by some clustering in
Tn. This is because every clustering C ∈K must map to some X-pattern P. By our algorithm
invariant, C∗∈Tn[P] is the clustering that minimizes assignment cost across clusterings that have
pattern P, and thus c(C∗) ≤c(C). In addition, since P C∗= P C′, and f is a pattern-based fairness
objective, f(C∗) = f(C). So, C is weakly dominated by C∗∈Tn. Therefore, filtering dominated
points out of the clusterings in Tn gives us the complete Pareto set for the assignment problem with
pattern-based fairness objectives and metric-based cost objectives on n data points. Note that the
output of Algorithm 1 recovers the Pareto set {C} as well as the Pareto front {(c(C), f(C)}, since the
Pareto front is just the image of the Pareto set under the two objectives."
REFERENCES,0.3901689708141321,"Proof of Theorem 3.4: Theorem 3.2 states that Algorithm 1 finds (exactly) the Pareto front of the
assignment problem. Let ϕ∗, S∗be the optimal cost clustering map and set of centers, respectively,
that satisfy a particular fairness bound F. Let ϕ, S be the clustering map and set of centers found by
a vanilla clustering algorithm A, which achieves an α-approximation to the best clustering cost. We
define a new assignment ϕ′, S, by applying a “routing” argument, first introduced in Bera et al. [9]
and reused in Esmaeili et al. [27]."
REFERENCES,0.391705069124424,"Define a function nrst(s∗) = arg mins∈S dp(s, s∗) which returns the nearest center in S to an input
center s∗. Now define an assignment map ϕ′ where vertices are routed from their center s∗
i ∈S∗to
nrst(s∗
i ) ∈S. In other words, for every point x, ϕ′(x) = nrst(ϕ∗(x)). Now we can write:"
REFERENCES,0.3932411674347158,"dp(x, ϕ′(x)) = dp(x, nrst(ϕ∗(x))) ≤dp(x, ϕ∗(x)) + dp(ϕ∗(x), nrst(ϕ∗(x)))
≤dp(x, ϕ∗(x)) + dp(ϕ∗(x), ϕ(x))
≤2dp(x, ϕ∗(x)) + dp(x, ϕ(x))"
REFERENCES,0.39477726574500765,"The first and third inequalities follow from the triangle inequality on dp and the second in-
equality is due to the definition of the nrst function.
In addition, α (P"
REFERENCES,0.39631336405529954,"x dp(x, ϕ∗(x)))1/p ≥
(P"
REFERENCES,0.3978494623655914,"x dp(x, ϕ(x)))1/p, since ϕ is the clustering found by the vanilla clustering algorithm A. Ap-
plying our previous inequality together with the triangle inequality on the p-norm:
 X"
REFERENCES,0.39938556067588327,"x
dp(x, ϕ′(x) !1/p ≤ X"
REFERENCES,0.4009216589861751,"x
2dp(x, ϕ∗(x)) !1/p + X"
REFERENCES,0.402457757296467,"x
dp(x, ϕ(x)) !1/p"
REFERENCES,0.4039938556067588,≤(2 + α) X
REFERENCES,0.4055299539170507,"x
dp(x, ϕ∗(x)) !1/p"
REFERENCES,0.40706605222734255,"This implies that ϕ′S is an assignment map with respect to centers S that has at most (2 + α) times
the cost of ϕ∗with respect to centers S∗."
REFERENCES,0.40860215053763443,"In addition, the clustering C′ associated with ϕ′ can be generated by, for each sj ∈S, merging all clus-
ters C∗
i ∈C∗such that nrst(s∗
i ) = sj. This procedure can be done by sequentially merging pairs of
clusters. Since the fairness objective is mergeable (see Def. 2.2), this implies that f(C∗) ≥f(C′). So,
the assignment map ϕ′ with respect to centers S also satisfies the fairness bound F. There exists an as-
signment to centers S that is a (2+α, 1)-approximation to ϕ∗, S∗, so the Pareto front of the assignment
problem is a (2 + α, 1)-approximation to the Pareto front of the clustering problem as desired."
REFERENCES,0.41013824884792627,"Proof of Theorem 3.5. We describe in detail the algorithm modification needed to compute the Pareto
front for non-mergeable fairness objectives. First, we give some necessary preliminaries:"
REFERENCES,0.4116743471582181,"Definition A.1 (Refinement of a pattern and refinement DAG D). Consider the directed graph D
with the X-patterns as nodes and edges (P1, P2) if merging two nonempty rows of the pattern P2
yields the pattern P1. A pattern P ′ is a refinement of another pattern P iff there is a path from P to
P ′ in D, i.e. if P can be obtained from P ′ by merging different parts of P ′. Note that D is a directed
acyclic graph (DAG). Let RP be the set of P ′ that are refinements of P."
REFERENCES,0.41321044546851,"Similarly, one can define the refinement of a clustering C. Note that if a clustering C′ is a refinement
of another clustering C, then its pattern P C′ is a refinement of the pattern of cluster C, P C."
REFERENCES,0.4147465437788018,"Next, we define a modified fairness function created from the non-mergeable function f, with the
purpose of reducing it to a mergeable function and applying Algorithm 1."
REFERENCES,0.4162826420890937,"Definition A.2 (Modified fairness function). If f is a pattern-based fairness function, define its
associated modified function ˆf to be ˆf(P) = minP ′∈RP (f(P ′)) for every pattern P."
REFERENCES,0.41781874039938555,"Note that f is still required to be pattern-based, and thus modified function is well-defined. By
definition, ˆf is a mergeable function. Furthermore, if f is mergeable then ˆf = f."
REFERENCES,0.41935483870967744,"Lemma A.3. We can compute in O(nl(k−1)) time the modified function ˆf for all X-patterns P, and
compute for each P a refinement P ′ such that ˆf(P) = f(P ′)."
REFERENCES,0.42089093701996927,"Proof. We compute ˆf bottom up in the DAG D. We also compute for each node a pointer to its
refinement pattern that has the minimum fairness cost. At the sinks P (patterns that have no outward
edge pointing from them to other patterns), ˆf(P) = f(P) and P points to itself only. For every
non-sink node P, we set ˆf(P) = minv∈N(P ) ˆf(v) where N(P) is the set of neighbors of P, and we
set the pointer of P to the descendant pointed by the neighbor v of P with the minimum ˆf(v)."
REFERENCES,0.42242703533026116,"The total time complexity is linear in the number of nodes and edges of D. The number of edges is
at most k2 times the number of nodes, since every node P ′ has at most k2 incoming edges (there are
at most k2 choices for the two parts of P ′ that are merged to form a parent pattern). The number of
nodes of D, i.e. X-patterns, is at most 4k( n"
REFERENCES,0.423963133640553,"2 )l(k−1): All the components of all the rows of a pattern
P, except possibly at most two components, are less than n/2; furthermore, specifying k −1 rows of
P determines also the last row because the sum for each attribute value must match the given set of
points. From the bounds on the number of nodes and edges of D, it follows that the time complexity
is O(nl(k−1))."
REFERENCES,0.4254992319508449,"Recall that in a clustering we associate a center with each cluster, and the cost of a clustering is com-
puted from the distances of the points from the center of their cluster. We allow different clusters to
have the same point as their center. We show the following result, needed in the proof of Theorem 3.5:"
REFERENCES,0.4270353302611367,"Lemma A.4. If we are given a clustering C with centers S and P ′ is a refinement of P C then we
can compute efficiently a clustering C′ with centers S′, which we call a center reassignment of C,
such that P C′ = P ′ and c(C′, S′) = c(C, S). The centers S′ will be a subset of the points in S but
with multiplicity (i.e. different clusters may have the same center)."
REFERENCES,0.42857142857142855,"Proof. Suppose that row i of pattern P is formed by merging a set Ji of two or more nonempty parts of
P ′. Then we split the cluster Ci of C into a set of |Ji| subclusters, one for each part in Ji, and we place
in each subcluster a number of points from Ci for each attribute value that matches the corresponding
entry in the row of P ′; we assign to all the subclusters the same center as the center of Ci."
REFERENCES,0.43010752688172044,"After performing the above splitting for all parts i of P that are refined in the pattern P ′, we obtain
a clustering C′ such that P C′ = P ′. Since the subclusters created from splitting a cluster Ci of C
are assigned the same center as the center of Ci, it follows from the definition of a metric-based
cost function, that C and C′ have the same cost."
REFERENCES,0.43164362519201227,"We now describe the algorithm modification for non-mergeable fairness objectives.
For a
non-mergeable fairness objective f, let ˆf = minP ′∈RP (f(P ′)) be its associated modified function.
Apply the algorithm of Lemma A.3 to compute ˆf(P) for every X-pattern P, and the corresponding
pointer to its optimal refinement P ′. As before, use a vanilla clustering approximation algorithm
A to compute a clustering that approximates the minimum cost. Use the centers of this clustering
in Algorithm 1 to construct the dynamic programming table Tn. Process the patterns P as before
in order of increasing cost, but now use the modified function ˆf as the fairness objective to filter
out dominated patterns, and for each undominated pattern P, replace the clustering C in Tn[P]
by the center reassignment clustering C′ constructed as in Lemma A.4. The algorithm returns the
set of these center reassignment clusterings C′ for all undominated patterns. By the definition of
the modified fairness function and Lemma A.4, these are undominated clusterings for the original
(non-mergeable) fairness function f and the clustering cost c."
REFERENCES,0.43317972350230416,"From our timing analysis, the time complexity of the algorithm is O(knl(k−1))."
REFERENCES,0.434715821812596,"The proof of the approximation follows the proof of Theorem 3.4. We define ϕ∗, S∗, ϕ, S, and ϕ′, S
similarly as before. Observe that in the construction of ϕ′, we simply merged clusters from ϕ∗and
gave them new centers. Since the pattern of a clustering is independent of the identities of the centers,
the pattern of ϕ∗is a refinement of the pattern of ϕ′. So by Lemma A.4, there exists a clustering
ϕ′′ that is a center reassignment of ϕ′ and has the same pattern as ϕ∗."
REFERENCES,0.4362519201228879,"Therefore, ϕ′′, which is one of the reassignments we search over in the algorithm, has f(C′′) = f(ϕ∗)
and c(C′′) = c(ϕ′) (here, we used interchangeably the clustering cost function c applied to the
clustering or the clustering assignment map, which are equivalent). Since ϕ′ has at most 2 + α worse
cost than ϕ∗(see proof of Theorem 3.4), so does C′′. Therefore, the Pareto front computed by the
algorithm is a (2 + α, 1)-approximation to the Pareto front of the clustering problem, as desired."
REFERENCES,0.4377880184331797,"Proof of Theorem 3.6: First we notice that in this case f can take at most n + 1 values: If n = |X| is
even, then it can take only values the even integers between 0 and n, and if it is odd all odd integers
between 1 and n −1. We shall treat the case of even n, the case of even n being very similar."
REFERENCES,0.4393241167434716,"Given dataset X, metric d, and exponent p, for each even number F between 0 and n we must
compute the best assignment that has fairness F. Once this is done, we only have to sort with respect
to fairness and remove the dominated assignments (in a similar vein to the filtering heuristic of
Algorithm 1). Clearly, this step is polynomial time since we can sort the points in O(n log(n)) and
then make a single pass over them to remove the dominated points. All that remains to show is that
we can compute the best assignment with fairness F also in polynomial time. We do so as follows."
REFERENCES,0.44086021505376344,"Given an even number F, we construct a weighted graph GF with n nodes corresponding to the data
points, plus F dummy nodes. We join every data point x with every dummy node z by an edge of
weight mini∈[k] dp(x, si). We join any two data points x, y with different attribute value (recall that
there are only two attribute values) by an edge of length mink
i=1(dp(x, si) + dp(y, si)). We call an
edge of GF to be of type i ∈[k] if the i-th cluster achieves the minimum that defines the weight of
the edge. (In other words, i is the argmin of the minimization expression.)"
REFERENCES,0.4423963133640553,"A perfect matching in a graph is a set of disjoint edges that includes all the nodes. The weight of a
matching M is defined as the sum of the weights of edges that are contained in the matching: w(M) =
P"
REFERENCES,0.44393241167434716,"e∈M w(e). Compute the minimum weight perfect matching ˆ
M in the graph GF . This can be done"
REFERENCES,0.445468509984639,"in polynomial time using Edmonds’ algorithm [24], specifically in time O(N(E + N log N)) for a
graph with N nodes and E edges [30]; in our case the graph GF has at most 2n nodes and 2n2 edges."
REFERENCES,0.4470046082949309,"We will show that the minimum weight of a perfect matching is equal to the minimum cost of a
clustering with fairness F, and furthermore we can derive a minimum cost clustering from the
minimum weight matching ˆ
M."
REFERENCES,0.4485407066052227,"Consider any clustering C with f(C) = F. Starting from C, we construct a perfect matching M
of GF as follows: For each cluster C ∈C, choose the attribute value a that has fewer nodes in
C (breaking ties arbitrarily). Now, match these nodes of attribute a in C arbitrarily with nodes of
the larger attribute group in C. Finally, match any remaining nodes of the other group (the larger
attribute group) to dummy nodes."
REFERENCES,0.4500768049155146,"We claim that such a matching M is possible, because the total number of nodes that cannot be
matched is precisely F, the number of dummy nodes. We claim now that the weight of this matching
w(M) is at most the cost of the clustering, c(C); that is, w(M) ≤c(C)."
REFERENCES,0.45161290322580644,"The weight of the matching is at most the clustering cost for the following reason: each matched
pair x, y contributes to c(C) at least the weight of the corresponding matched edge; and any data
point matched to a dummy node again contributes to c(C) at least the weight of the matched edge."
REFERENCES,0.45314900153609833,"Now consider the minimum weight perfect matching ˆ
M of the weighted graph GF . Clearly,
w( ˆ
M) ≤c(C). Construct from ˆ
M a corresponding clustering ˆC as follows: any matched data point
whose edge is of type i is placed in cluster i, while any data point matched in ˆ
M with a dummy node
with an edge of type i is added to cluster i. This clustering satisfies c( ˆC) = w( ˆ
M) ≤c(C). Since
C was assumed to be an arbitrary clustering with f(C) = F, ˆC is the optimum such clustering."
REFERENCES,0.45468509984639016,The same result can be shown for the MAX IMBALANCE objective.
REFERENCES,0.45622119815668205,"Theorem A.5. If l = 2 and the fairness objective f is the max imbalance f(C) = maxi∈[k] ||C1
i | −
|C2
i ||, then the Pareto front of the assignment problem can be computed in polynomial time."
REFERENCES,0.4577572964669739,"Proof. The objective can take again at most n+1 values (more precisely, at most 1+max(|X 1|, |X 2|)
values). For each possible value F, construct a weighted graph GF , whose set NF of nodes consists
of n nodes corresponding to the given set X of data points, a set Di of F dummy nodes for each
i ∈[k], and if n + kF is odd, then NF has one more dummy node so that the total number of nodes
is even. The edge set EF of GF consists of the following edges: for each pair x, y of data points with
different attribute values, we include an edge (x, y) with weight mink
i=1(dp(x, si) + dp(y, si)) and
associate with the edge as its type the index i ∈[k] that achieves the minimum in the weight; for each
data point x and dummy node z in Di, we include an edge (x, z) with weight dp(x, si) and associate
type i to the edge; for every pair z, w of dummy nodes we include an edge (z, w) with weight 0 (we
do not associate a type with these edges)."
REFERENCES,0.4592933947772657,"We then compute the minimum weight perfect matching ˆ
M of the graph GF . Just like in the proof of
Theorem 3.6, the minimum weight perfect matching can be found in polynomial time. The matching
ˆ
M induces an assignment ˆC of the data points: every point x is assigned to the cluster i corresponding
to the type of the edge of ˆ
M incident to x. By construction, the cost of the assignment is equal to
the weight w( ˆ
M) of the matching. Furthermore, for every cluster i ∈[k], the number of data points
in the cluster that are matched with dummy nodes in Di is at most F, hence || ˆC1
i | −| ˆC2
i || ≤F.
Therefore the fairness cost of the assignment is at most F."
REFERENCES,0.4608294930875576,"Conversely, any assignment C with fairness F induces a perfect matching M of GF , as follows: For
each cluster i, match data points of cluster Ci in C with opposite attribute values arbitrarily in pairs,
and match the remaining ||C1
i | −|C2
i || data points to dummy nodes in Di. The rest of the dummy
nodes that are not matched to a data point are matched arbitrarily in pairs. The weight of this matching
M is then at most the cost of the clustering C, w(M) ≤c(C). Therefore, c(C) ≥w( ˆ
M) = c( ˆC),
that is, any assignment C with fairness F is dominated by the assignment ˆC that we derived from the
minimum weight perfect matching."
REFERENCES,0.46236559139784944,"B
Analyzing Fairness Objectives"
REFERENCES,0.46390168970814133,"B.1
Balance and proportional violation-based objectives are pattern-based and mergeable"
REFERENCES,0.46543778801843316,"Proposition B.1. The fairness objectives BALANCE, SUM OF IMBALANCES, GROUP UTILITARIAN,
GROUP UTILITARIAN-SUM, GROUP EGALITARIAN, and GROUP EGALITARIAN-SUM are pattern-
based and mergeable."
REFERENCES,0.46697388632872505,"Proof. Balance-based Objectives: As defined in equation 1, the BALANCE objective is always
pattern-based by definition. As above, say that we have two sensitive attributes (as this objective
is originally defined for l = 2), called R and B. Then, for a cluster C ∈C, |CR| and |CB| are the
number of R and B data points in cluster C, respectively. For two clusterings C and C′ that induce
the same pattern p, it means that we can pair each C ∈C with a different cluster C′ ∈C′ such that
|CR| = |C′R| and |CB| = |C′B|. Thus BALANCE(C) = BALANCE(C′) for all such pairs, and thus
BALANCE(C) = BALANCE(C)′."
REFERENCES,0.4685099846390169,"We show that BALANCE is also mergeable through a simple induction over the number of clusters to
be merged. For the base case, take a clustering C and construct a clustering C′ in which two clusters
from C have been merged (assume without loss of generality that C = {C1, C2, · · · , Ck} and C′ =
{∅, C1 ∪C2, · · · , Ck}). For ease of notation, denote by a = |CR
1 |, b = |CB
1 |, c = |CR
2 |, d = |CB
2 |.
Then, a + c = |(C1 ∪C2)R|, b + d = |(C1 ∪C2)B|. Note that all variables are non-negative. We
assume that neither C1 and C2 are empty. We need to show that the fairness objective is at least as
good for the merged clustering than for the original clustering. It is sufficient to show that"
REFERENCES,0.4700460829493088,"min

min
a b , b a"
REFERENCES,0.4715821812596006,"
, min
 c d, d c"
REFERENCES,0.4731182795698925,"
≤min
a + c"
REFERENCES,0.47465437788018433,"b + d, b + d a + c 
(5)"
REFERENCES,0.47619047619047616,"First, this property is true as we can easily prove by considering possible cases:"
REFERENCES,0.47772657450076805,"1. If a ≤b and c ≤d ⇒
a
b = min
  a b , b"
REFERENCES,0.4792626728110599,"a

, c"
REFERENCES,0.4807987711213518,"d = min
  c d, d"
REFERENCES,0.4823348694316436,"c

, a+c"
REFERENCES,0.4838709677419355,"b+d = min

a+c
b+d, b+d"
REFERENCES,0.48540706605222733,"a+c

."
REFERENCES,0.4869431643625192,Without loss of generality a
REFERENCES,0.48847926267281105,"b = min
  a b , c"
REFERENCES,0.49001536098310294,"d

. Then, it is easy to see that a"
REFERENCES,0.4915514592933948,"b ≤
a+c
b+d ⇔
ab + ad ≤ab + bc ⇔ad ≤bc ⇔a b ≤c d."
REFERENCES,0.4930875576036866,2. If a ≥b and c ≥d ⇒b
REFERENCES,0.4946236559139785,"a = min
  a b , b"
REFERENCES,0.49615975422427033,"a

, d"
REFERENCES,0.4976958525345622,"c = min
  c d, d"
REFERENCES,0.49923195084485406,"c

, b+d"
REFERENCES,0.500768049155146,"a+c = min

a+c
b+d, b+d"
REFERENCES,0.5023041474654378,"a+c

. Then,
the argument from the first case follows identically."
REFERENCES,0.5038402457757296,"3. If a ≤b and c ≥d, then we need to show that min
  a b , d"
REFERENCES,0.5053763440860215,"c

≤min

a+c
b+d, b+d"
REFERENCES,0.5069124423963134,"a+c

. Without"
REFERENCES,0.5084485407066052,"loss of generality, a+c"
REFERENCES,0.5099846390168971,"b+d = min

a+c
b+d, b+d"
REFERENCES,0.511520737327189,"a+c

. Now we have two cases:"
REFERENCES,0.5130568356374808,• If a b ≤d
REFERENCES,0.5145929339477726,"c, then a"
REFERENCES,0.5161290322580645,b ≤a+c
REFERENCES,0.5176651305683564,b+d ⇔ab + ad ≤ab + ac ⇔ad ≤bc ⇔a b ≤c
REFERENCES,0.5192012288786483,"d, which is true
since a b ≤d c ≤c d."
REFERENCES,0.5207373271889401,• If a b ≥d
REFERENCES,0.522273425499232,"c , then d"
REFERENCES,0.5238095238095238,c ≤a+c
REFERENCES,0.5253456221198156,"b+d ⇔bd + d2 ≤ac + c2, which is true since bd ≤ac ⇔a b ≥d"
REFERENCES,0.5268817204301075,"c
and d2 ≤c2 ⇔d ≤c."
REFERENCES,0.5284178187403994,"4. If a ≥b and c ≤d, then the proof follows identically to case 3."
REFERENCES,0.5299539170506913,"Then,
if equation 5 holds,
then BALANCE(C)
≤
BALANCE(C′).
To see this,
we
there is a cluster index i
>
2 for which BALANCE(C)
=
BALANCE(Ci).
Then,
BALANCE(Ci)
≤
min
 
min
  a b , b"
REFERENCES,0.5314900153609831,"a

, min
  c d, d"
REFERENCES,0.533026113671275,"c

, so BALANCE(C′)
=
BALANCE(Ci)
⇒
BALANCE(C) = BALANCE(C′).
If there is no such cluster i > 2, then BALANCE(C) =
min
 
min
  a b , b"
REFERENCES,0.5345622119815668,"a

, min
  c d, d"
REFERENCES,0.5360983102918587,"c

≤BALANCE(Ci), ∀i > 2. Then, it follows that BALANCE(C) ≤
BALANCE(C′)."
REFERENCES,0.5376344086021505,"The SUM OF IMBALANCES and MAX IMBALANCE objectives are derived from the BALANCE
objective. As they are only a function of the number of data points of different attributes in each
cluster, they are also clearly pattern-based. To see that SUM OF IMBALANCES is also mergeable, we"
REFERENCES,0.5391705069124424,"consider again the base case of the induction proof, for 2 clusters. For the SUM OF IMBALANCES
objective, note that |C1
i −C2
i | + |C1
i −C2
i | ≥|C1
i −C2
i + C1
i −C2
i | by the triangle inquality for
any clusters Ci, Cj. In merging two clusters Ci and Cj from a clustering C, obtaining a clustering C′,
the contribution to the objective of Ci ∪Cj and the empty cluster is exactly |C1
i −C2
i + C1
i −C2
i |
(an empty cluster has an imbalance of 0). Since all other clusters remained unchanged, we conclude
that SUM OF IMBALANCES(C) ≥SUM OF IMBALANCES(C′), and thus, merging two clusters can
only improve the objective.
Remark B.2. As a note, the MAX IMBALANCE objective is not mergeable. As a simple objective,
take the follwing clustering C: each of the clusters C1 and C2 has one data point of attribute 1 and
two data points of attribute 2. Then, MAX IMBALANCE(C) = 1. The clustering C′ obtained by
merging clusters C1 and C2 has MAX IMBALANCE(C′) = 2."
REFERENCES,0.5407066052227343,"Finally, for the induction step, if mergeability holds for merging a set of w clusters, then it holds
for merging a set of w + 1 clusters as well, by reducing to the base case: without loss of generality,
denote the w + 1 clusters to be merged by C1, · · · , Cw+1. By the induction hypothesis, mergeability
holds for merging any w clusters, so for ∪j∈[w]Cj. Then, the base case applies for the clusters
∪j∈[w]Cj and Cw+1."
REFERENCES,0.5422427035330261,"Proportional violation objectives: First, we easily note that for any two clusterings C and C′ that
induce the same pattern ∆C
a , we pair each cluster C ∈C with a different cluster C′ ∈C′ such
that |C| = |C′| and |Ca| = |C′a| for all attributes a ∈[l]. Thus, from equation 2 it follows that
∆C
a = ∆C′
a , ∀a ∈[l]. Since all proportional violation-based objectives defined are only a function of
(∆C
a )a,C, it follows that all clusterings that have the same pattern will also have the same objective
value for all four of the proportional violation-based objectives."
REFERENCES,0.543778801843318,"Finally, we will show that they are also mergeable. We show this again by induction over the number
of merged clusters for each of the objectives. We start with the base case of two clusters, denoted
without loss of generality by C1 and C2. We assume that neither C1 and C2 are empty. We say that
C1 and C2 are part of a clustering C, and we aim to show that the clustering C′ in which C1 and
C2 got merged will have OBJECTIVE(C′) ≤OBJECTIVE(C), for OBJECTIVE is one of the GROUP
UTILITARIAN, GROUP UTILITARIAN-SUM, GROUP EGALITARIAN, GROUP EGALITARIAN-SUM
objectives. For a sensitive attribute a ∈[l], assume without loss of generality that |Ca
1 |
|C1| ≤|Ca
2 |
|C2| . Then,
the following property holds, also known as the mediant inequality:"
REFERENCES,0.5453149001536098,"|Ca
1 |
|C1| ≤|Ca
1 | + |Ca
2 |
|C1| + |C2| ≤|Ca
2 |
|C2|
(6)"
REFERENCES,0.5468509984639017,"To see this, note that the left hand side is equivalent to:"
REFERENCES,0.5483870967741935,"|Ca
1 |
|C1| ≤|Ca
1 | + |Ca
2 |
|C1| + |C2| ⇔|Ca
1 | · |C1| + |Ca
1 | · |C2| ≤|Ca
1 | · |C1| + |C1| · |Ca
2 | ⇔"
REFERENCES,0.5499231950844854,"|Ca
1 | · |C2| ≤|C1| · |Ca
2 | ⇔|Ca
1 |
|C1| ≤|Ca
2 |
|C2| (7)"
REFERENCES,0.5514592933947773,The right hand side is equivalent to:
REFERENCES,0.5529953917050692,"|Ca
1 | + |Ca
2 |
|C1| + |C2| ≤|Ca
2 |
|C2| ⇔|Ca
1 | · |C2| + |Ca
2 | · |C2| ≤|C1| · |Ca
2 | + |C2| · |Ca
2 | ⇔"
REFERENCES,0.554531490015361,"|Ca
1 | · |C2| ≤|C1| · |Ca
2 | ⇔|Ca
1 |
|C1| ≤|Ca
2 |
|C2| (8)"
REFERENCES,0.5560675883256528,"By the definition from equation 2, we have"
REFERENCES,0.5576036866359447,"βa −∆C1
a
≤|Ca
1 |
|C1| ≤αa + ∆C1
a ,"
REFERENCES,0.5591397849462365,"βa −∆C2
a
≤|Ca
2 |
|C2| ≤αa + ∆C2
a ,
(9)"
REFERENCES,0.5606758832565284,"for clusters C1, C2 ∈C. As C1 and C2 got merged in C′, they got replaced by the empty cluster
C∅and the merged cluster C1 ∪C2 in C′. We note that ∆C∅
a
= βa, while ∆C1∪C2
a
is the minimum
value that satisfies"
REFERENCES,0.5622119815668203,"βa −∆C1∪C2
a
≤|Ca
1 | + |Ca
2 |
|C1| + |C2| ≤αa + ∆C1∪C2
a
(10)"
REFERENCES,0.5637480798771122,"Using inequalities 9 and 10 with the mediant inequality, we get that"
REFERENCES,0.565284178187404,"βa −∆C1
a
≤|Ca
1 | + |Ca
2 |
|C1| + |C2| ≤αa + ∆C2
a
⇒"
REFERENCES,0.5668202764976958,"βa −max(∆C1
a , ∆C2
a ) ≤|Ca
1 | + |Ca
2 |
|C1| + |C2| ≤αa + max(∆C1
a , ∆C2
a )
(11)"
REFERENCES,0.5683563748079877,"Since by definition, ∆C1∪C2
a
is the minimum value that satisfies equation 10, we get that"
REFERENCES,0.5698924731182796,"∆C1∪C2
a
≤max(∆C1
a , ∆C2
a )
(12)"
REFERENCES,0.5714285714285714,"Note that the empty cluster will have ∆∅
a = 0, ∀a ∈[l], so max(∆∅
a, ∆C1∪C2
a
) = ∆C1∪C2
a
. This also
implies that max
C∈C ∆C
a ≥max
C∈C′ ∆C
a . Since the attribute a ∈[l] was chosen arbitrarily, we also get that X"
REFERENCES,0.5729646697388633,"a∈[l]
max
C∈C ∆C
a ≥
X"
REFERENCES,0.5745007680491552,"a∈[l]
max
C∈C′ ∆C
a ,
(13)"
REFERENCES,0.576036866359447,"and thus the GROUP UTILITARIAN objective cannot increase by merging two clusters. Similarly, for
the GROUP UTILITARIAN-SUM, since 0 = ∆∅
a ≤min(∆C1
a , ∆C2
a ) and ∆C1∪C2
a
≤max(∆C1
a , ∆C2
a ),
and all other clusters have the same proportional violation in both clusterings, we also get that
P"
REFERENCES,0.5775729646697388,"C∈C
∆C
a ≥P"
REFERENCES,0.5791090629800307,"C∈C′ ∆C
a . Since the attribute a ∈[l] was chosen arbitrarily, we also get that X a∈[l] X"
REFERENCES,0.5806451612903226,"C∈C
∆C
a ≥
X a∈[l] X"
REFERENCES,0.5821812596006144,"C∈C′
∆C
a ,
(14)"
REFERENCES,0.5837173579109063,"and thus the GROUP UTILITARIAN-SUM objective can also not increase by merging two clusters.
Furthermore, equation 12 implies that max(∆∅
a, ∆C1∪C2
a
) ≤max(∆C1
a , ∆C2
a ) which in turn implies
that max
C∈C ∆C
a ≥max
C∈C′ ∆C
a . Since this holds for any arbitrary a ∈[l], it also implies that"
REFERENCES,0.5852534562211982,"max
a∈[l],C∈C ∆C
a ≥
max
a∈[l],C∈C′ ∆C
a
(15)"
REFERENCES,0.5867895545314901,"and thus the GROUP EGALITARIAN objective cannot increase by merging two clusters. Finally, since
0 = ∆∅
a ≤min(∆C1
a , ∆C2
a ) and ∆C1∪C2
a
≤max(∆C1
a , ∆C2
a ), and all other clusters have the same
proportional violation in both clusterings, we also get that P"
REFERENCES,0.5883256528417818,"C∈C
∆C
a ≥P"
REFERENCES,0.5898617511520737,"C∈C′ ∆C
a . Since the attribute"
REFERENCES,0.5913978494623656,"a ∈[l] was chosen arbitrarily, we also get that"
REFERENCES,0.5929339477726574,"max
a∈[l] X"
REFERENCES,0.5944700460829493,"C∈C
∆C
a ≥max
a∈[l] X"
REFERENCES,0.5960061443932412,"C∈C′
∆C
a ,
(16)"
REFERENCES,0.5975422427035331,and thus the GROUP EGALITARIAN-SUM objective cannot increase by merging two clusters.
REFERENCES,0.5990783410138248,"For the induction step, the proof is identical to the proof for the BALANCE objective: if mergeability
holds for merging a set of w clusters, then it holds for merging a set of w + 1 clusters as well, by
reducing to the base case: without loss of generality, denote the w + 1 clusters to be merged by
C1, · · · , Cw+1. By the induction hypothesis, mergeability holds for merging any w clusters, so for
∪j∈[w]Cj. Then, the base case applies for the clusters ∪j∈[w]Cj and Cw+1 for all objectives. R
BB R
BB C2 C1 x x R
BB R
BB C2’ C1’ x x"
REFERENCES,0.6006144393241167,"(a)
(b)"
REFERENCES,0.6021505376344086,"Figure 3: (a) An illustration of clustering under for non-pattern based fairness objectives. (b) An
illustration of the (Pi)i∈[8] sets for non-mergeable fairness objectives."
REFERENCES,0.6036866359447005,"B.2
A discussion on pattern-based and mergeability properties"
REFERENCES,0.6052227342549923,"Example of non-pattern based fairness objectives.
As mentioned in the introduction, informally,
a pattern-based fairness objective computes a per-cluster fairness quantity that only depends on the
number of data points from each sensitive attribute. In practice, many fairness objectives satisfy this
property, as they aim to operationalize different versions of proportional representation, with the
goal of having balanced clusters among different sensitive attributes. Objectives that define fairness
through the proportion of k-centers that are closest to them are not pattern-based, since they do
not depend on the number of other nodes of different attributes in the same cluster but rather on
equalizing the proportions of k-center assignments to different attributes [17, 41, 45] or the max
average distance between points of different groups to their centers [31]. For example, the definition
in Ghadiri et al. [31] states that for two groups R (red) and B (blue), the fairness objective is defined
for a clustering C as"
REFERENCES,0.6067588325652842,"Φ(S, C) = max
f(S, C ∩X R)"
REFERENCES,0.6082949308755761,"|R|
, f(S, C ∩X B) |B|"
REFERENCES,0.6098310291858678,"
,
(17)"
REFERENCES,0.6113671274961597,"where X A is the subset of points from X with attribute A. Take the following set of points: 3 over-
lapping points x1, x2, x3, with x1, x2 ∈B, x3 ∈R, and 3 overlapping points x4, x5, x6 at different
coordinates than the first 3, with x4, x5 ∈B, x6 ∈R. Then, the clustering C1 = {x1, x2, x6},
C2 = {x3, x4, x5} has a non-zero fairness objective value with respect to its true centers (by
computing the centroids). The clustering C′
1 = {x1, x2, x3}, C′
2 = {x4, x5, x6}, however, has the
same pattern as (C1, C2), but a fairness objective value of 0 with respect to its true centroids. Even if
we evalute (C1, C2) with respect to the centroids of (C′
1, C′
2), it still has a non-zero fairness objective
value. See Figure 3 (a) for an illustration."
REFERENCES,0.6129032258064516,"Example of non-mergeable fairness objectives.
As discussed in the introduction, a mergeable
objective means that the objective value can only improve or stay the same when merging any
number of clusters. While many fairness objectives are mergeable, we give an example below of
non-mergeable objectives. We note that objectives that enforce a minimum number of data points
in each cluster tend to not be mergeable. For example, the τ-ratio objective defined by [32] is
non-mergeable, where the objective is defined as: X"
REFERENCES,0.6144393241167435,"xi∈X
I(xi ∈Cj)I(σ(xi)=a)≥τℓ
X"
REFERENCES,0.6159754224270353,"xi∈X
I(xi ∈Cj) ∀j ∈[k] and ∀a ∈[l]
(18)"
REFERENCES,0.6175115207373272,"The τ-ratio enforces a minimum number of the total points that must go in each cluster, so empty
clusters violate the mergeability condition on the fairness objective (since the number of clusters
k is fixed)."
REFERENCES,0.6190476190476191,"Pareto front approximation gap gets arbitrarily large without mergeability.
We rely on the
assignment problem to provide an approximation for the clustering problem when computing the"
REFERENCES,0.620583717357911,"Pareto front, which works for pattern-based and mergeable fairness objectives. However, for fairness
objectives that are pattern-based but are not mergeable, if we apply directly Algorithm 1, without
using a modified fairness function to filter the dominated patterns and adjust the clusterings, as we did
in the proof of Theorem 3.5, then the resulting approximation ratio is no longer necessarily bounded,
as we show in the example below. We showcase this for the τ-ratio objective."
REFERENCES,0.6221198156682027,"We construct a dataset X such that |X| = 8m that contains 8 sets of m points each on the plane.
Each point has a sensitive attribute, denote by b (blue) or r (red). We denote these sets by (Pi)i∈[8],
constructed in the Euclidean space with the following coordinates (see Figure 3 (b) for an illustration):"
REFERENCES,0.6236559139784946,"• P1 contains 2m −1 blue points situated at coordinates (−ϵ, 1)"
REFERENCES,0.6251920122887865,"• P2 contains 2m −1 red points situated at coordinates at (ϵ, 1)"
REFERENCES,0.6267281105990783,"• P3 contains 1 blue point situated at coordinates (1, 0)"
REFERENCES,0.6282642089093702,"• P4 contains 1 red point of situated at coordinates (1, 0)"
REFERENCES,0.6298003072196621,"• P5 contains 2m −1 blue points situated at coordinates (ϵ, −1)"
REFERENCES,0.631336405529954,"• P6 contains 2m −1 red points situated at coordinates (−ϵ, −1)"
REFERENCES,0.6328725038402457,"• P7 contains 1 blue point situated at coordinates (−1, 0)"
REFERENCES,0.6344086021505376,"• P8 contains 1 red point situated at coordinates (−1, 0)"
REFERENCES,0.6359447004608295,"Set ϵ <
1
8m, and k = 4. Then, the cost of not assigning the 4 points at (1, 0) and (−1, 0)
their own two centers outweighs the benefits of assigning 2 centers to the points clustered
near (0, 1) or (0, −1).
Therefore, the best k-means and k-median clustering yields centers
S = {(0, 1), (1, 0), (0, −1), (−1, 0)}."
REFERENCES,0.6374807987711214,We set τ = 1
REFERENCES,0.6390168970814132,"4 as our fairness constraint, which constrains every center to have exactly m red points
and exactly m blue points. Observe that the optimal quality way ϕ to assign such points to s2 is to
assign m −1 of the red points in P2 and m −1 of the blue points in P5 to S2 (in addition to the two
points assigned to s2 by the unfair k-means/medians clustering). So the center at s2 clusters together
2 sets of m −1 points separated by distance 2 on the plane. Even if we allow moving the location
of s2 after the assignment, the clustering cost is still lower bounded by(2m −2)1/p, since the best
center is unit distance from 2(m −1) points. Symmetrically, we do the corresponding assignment to
s4 and get a clustering cost lower bound of 2(2m −2)1/p."
REFERENCES,0.6405529953917051,"Setting our centers to be S∗= {(0, 1), (0, 1), (0, −1), (0, −1)}, the assignment function ϕ∗with
optimal quality under the fairness constraint maps m points from each of P1 and P2 to s∗
1 and maps the
remainder of the points from P1 and P2, as well as the points in P3 and P4 to s∗
2. Symmetrically, we
do the corresponding assignment to s∗
3 and s∗
4 with the points from P5, P6, P7, and P8. This clustering
achieves a clustering cost at most ((8m−4)ϵp+4(
√"
REFERENCES,0.642089093701997,"2)p)1/p, where the first term comes from the 8m−
4 points in sets P1, P2, P5, P6 and the second term comes from the 4 points in sets P3, P4, P7, P8."
REFERENCES,0.6436251920122887,"Let ϕ be the lowest cost assignment to centers S, and let Sm be the best possible centers for ϕ. Then
we have that:"
REFERENCES,0.6451612903225806,"c(ϕ, Sm)
c(ϕ∗, S∗) ≥
2(2m −2)1/p"
REFERENCES,0.6466973886328725,"((8m −4)ϵp + 4(
√"
REFERENCES,0.6482334869431644,"2)p)1/p
(19)"
REFERENCES,0.6497695852534562,"Considering the k-means or the k-median clustering objectives, we get (8m −4)ϵp ≤1, since we set
ϵ <
1
8m. Therefore,"
REFERENCES,0.6513056835637481,"lim
m→∞
c(ϕ, Sm)
c(ϕ∗, S∗) = ∞
(20)"
REFERENCES,0.65284178187404,"Thus, for any constant b, the assignment Pareto set is not a (b, 1) multiplicative approximation for
the clustering Pareto set for non-mergeable fairness functions. This justifies the need for a modified
algorithm for non-mergeable fairness objectives that can change the set of centers while searching for
the best assignment, as described in Appendix A."
REFERENCES,0.6543778801843319,"C
Datasets details"
REFERENCES,0.6559139784946236,"For all datasets, we subsample 1, 000 data points, as the datasets sizes are prohibitively large. For
the Adult and Census datasets, we use all numerical features available in the data and embed them
in Euclidean space. For the BlueBike dataset, we use the starting and ending latitude and longitude
as coordinates, directly embedded in Euclidean space. For all datasets, the gender of users is
self-reported. Table 1 describes the characteristics of all datasets."
REFERENCES,0.6574500768049155,Table 1: Data and experimental details.
REFERENCES,0.6589861751152074,"# of features
Sensitive attribute
δ"
REFERENCES,0.6605222734254992,"Adult
5
Gender
0.05
Census1990
66
Gender
0.001
BlueBike
4
Gender
0.01"
REFERENCES,0.6620583717357911,"We note that some datasets naturally cluster into fairer clusters than others. For this reason, setting
δ too high renders a single point on the Pareto front, since the vanilla clustering itself will be fair
for proportional violation-based objectives. In fact, the proportional violation value will be equal to
0. For this reason, we experiment with various values of δ, reported in Table 1 for the experiments
presented in the main text."
REFERENCES,0.663594470046083,"D
Repeated-FCBC: Experimental Details"
REFERENCES,0.6651305683563749,Clustering Objective
REFERENCES,0.6666666666666666,"Fairness Objective … U1
U0 μ"
REFERENCES,0.6682027649769585,FCBC(U0)
REFERENCES,0.6697388632872504,FCBC(U1)
REFERENCES,0.6712749615975423,"Figure 4: An illustration of implement-
ing the repeated FCBC algorithm as the
clustering cost upper bound U varies."
REFERENCES,0.6728110599078341,"As described in the main text, we investigate alternatives
for faster recovery of the Pareto front in the case of two
objectives: clustering cost and fairness. We employ a re-
cently proposed linear programming method that bounds
the clustering objective and optimizes a fairness objec-
tive, up to an approximation, denoted the FCBC algorithm
(Algorithm 1 in Esmaeili et al. [26]). We implement the
FCBC algorithm repeatedly by discretizing over the clus-
tering cost space. We perform a sweep over the upper
bound U values, setting its minimum value equal to the
clustering cost of a vanilla clustering algorithm and its
max value equal to a constant times the clustering cost of
a vanilla clustering algorithm, for some chosen constant.
We describe the approach formally in Algorithm 2, with
an illustration in Figure 4."
REFERENCES,0.674347158218126,"We compare the Pareto front recovered from Algorithm 2
with the Pareto front recovered from the dynamic
programming approach in Algorithm 1 on all the real-world datasets in Figure 2 in Section 4, setting
Umax = Umin · C, where Umin is the clustering cost of a vanilla clustering algorithm (in our case,
k-means++), C = 1.5, and N = 50. We note that setting C equal to 1 is equivalent to constraining
the clustering cost in the FCBC algorithm to be equal to the vanilla clustering algorithm cost."
REFERENCES,0.6758832565284179,"Running time comparison.
We illustrate in Figure 5 the running time comparison between the
dynamic programming approach from Algorithm 1, labeled as ‘Dyn Progr’, and the repeated FCBC
approach from Algorithm 2, labeled as ‘FCBC’, for samples of different sizes of all the datasets. We
showcase two objectives, GROUP UTILITARIAN and GROUP EGALITARIAN, since the original FCBC
algorithm [26] is designed only for these two, among the five objectives we described in Section 4.
We note that Algorithm 1 has a similar running time for all other objectives. The experimental running
time follows the analysis presented in Section 3: for k = 2 clusters and l = 2 sensitive attributes, one
would expect a running time of O(n2)."
REFERENCES,0.6774193548387096,Algorithm 2 Repeated FCBC for recovering the Pareto Front
REFERENCES,0.6789554531490015,"Input: Umin, Umax, N, CLUSTERING-OBJ, FAIRNESS-OBJ.
Step 1: Discretize the interval [Umin, Umax]: set η = (Umax −Umax) /N and
for i ←0 to N do"
REFERENCES,0.6804915514592934,"Set Ui = Umin + η · i
Step 2: apply the FCBC algorithm for the discretized clustering cost bound sequence (Ui)i, adding
results to the recovered Pareto front approximation XFCBC
P
, initialized to XFCBC
P
= ∅:
for i ←0 to N do"
REFERENCES,0.6820276497695853,"XFCBC
P
←XFCBC
P
∪{FCBC(Ui, CLUSTERING-OBJ, FAIRNESS-OBJ)}
Output: XFCBC
P"
REFERENCES,0.6835637480798771,"100
200
300
400
500
Dataset size 0 50 100 150 200"
REFERENCES,0.685099846390169,Running time (seconds) Adult
REFERENCES,0.6866359447004609,"Dyn Progr
FCBC"
REFERENCES,0.6881720430107527,(a) Group Util
REFERENCES,0.6897081413210445,"100
200
300
400
500
Dataset size 0 50 100 150 200 250"
REFERENCES,0.6912442396313364,Running time (seconds)
REFERENCES,0.6927803379416283,Census
REFERENCES,0.6943164362519201,"Dyn Progr
FCBC"
REFERENCES,0.695852534562212,(b) Group Util
REFERENCES,0.6973886328725039,"100
200
300
400
500
Dataset size 0 50 100 150 200"
REFERENCES,0.6989247311827957,Running time (seconds)
REFERENCES,0.7004608294930875,BlueBike
REFERENCES,0.7019969278033794,"Dyn Progr
FCBC"
REFERENCES,0.7035330261136713,(c) Group Util
REFERENCES,0.7050691244239631,"100
200
300
400
500
Dataset size 0 50 100 150 200"
REFERENCES,0.706605222734255,Running time (seconds) Adult
REFERENCES,0.7081413210445469,"Dyn Progr
FCBC"
REFERENCES,0.7096774193548387,(d) Group Egalit
REFERENCES,0.7112135176651305,"100
200
300
400
500
Dataset size 0 50 100 150 200 250"
REFERENCES,0.7127496159754224,Running time (seconds)
REFERENCES,0.7142857142857143,Census
REFERENCES,0.7158218125960062,"Dyn Progr
FCBC"
REFERENCES,0.717357910906298,(e) Group Egalit
REFERENCES,0.7188940092165899,"100
200
300
400
500
Dataset size 0 50 100 150 200"
REFERENCES,0.7204301075268817,Running time (seconds)
REFERENCES,0.7219662058371735,BlueBike
REFERENCES,0.7235023041474654,"Dyn Progr
FCBC"
REFERENCES,0.7250384024577573,(f) Group Egalit
REFERENCES,0.7265745007680492,"Figure 5: Running time comparison with our dynamic programming approach from Algorithm 1, la-
beled as ‘Dyn Progr’, and the repeated FCBC approach from Algorithm 2, labeled as ‘FCBC’, for each
dataset (by column) and for the GROUP UTILITARIAN and GROUP EGALITARIAN objective (by row)."
REFERENCES,0.728110599078341,"E
Additional Experiments"
REFERENCES,0.7296466973886329,"We present experimental results on the three datasets and the five fairness objectives defined in
Section 4 for k = 3 clusters in Figures 6 and 7. We note that results are qualitatively similar as for
k = 2 clusters. As mentioned in the main text, we note that the Pareto front need not be strictly
convex for two minimization objectives, nor strictly concave for a minimization objective and a
maximization objective (as in the case of the clustering objective and the balance objective), since
it simply consists of the undominated points."
REFERENCES,0.7311827956989247,"For the interested reader, we also showcase the Pareto front for the SUM OF IMBALANCES objective,
for all three datasets, for k = 2 and k = 3, in Figure 8. We note that since this objective is best suited
for data with relatively equal proportions between the two groups, we subsample equal proportions
of each gender for each of the three datasets, Adult, Census, and BlueBike."
REFERENCES,0.7327188940092166,"690
700
710
720
730
740
Clustering cost 0.20 0.22 0.24 0.26 0.28 0.30"
REFERENCES,0.7342549923195084,Balance Adult
REFERENCES,0.7357910906298003,(a) Balance
REFERENCES,0.7373271889400922,"690
700
710
720
730
740
Clustering cost 0.0 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.738863287250384,Proportional violation Adult
REFERENCES,0.7403993855606759,(b) Group Util
REFERENCES,0.7419354838709677,"690
700
710
720
730
740
Clustering cost 0.0 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.7434715821812596,Proportional violation Adult
REFERENCES,0.7450076804915514,(c) Group Util-Sum
REFERENCES,0.7465437788018433,"690
700
710
720
730
740
Clustering cost 0.0 0.1 0.2 0.3 0.4 0.5"
REFERENCES,0.7480798771121352,Proportional violation Adult
REFERENCES,0.7496159754224271,(d) Group Egalit
REFERENCES,0.7511520737327189,"690
700
710
720
730
740
Clustering cost 0.0 0.1 0.2 0.3 0.4 0.5"
REFERENCES,0.7526881720430108,Proportional violation Adult
REFERENCES,0.7542242703533026,(e) Group Egalit-Sum
REFERENCES,0.7557603686635944,"9000
9500
10000
10500
Clustering cost 0.350 0.375 0.400 0.425 0.450 0.475 0.500"
REFERENCES,0.7572964669738863,Balance
REFERENCES,0.7588325652841782,Census
REFERENCES,0.7603686635944701,(f) Balance
REFERENCES,0.7619047619047619,"8800
9000
9200
Clustering cost 0.00 0.05 0.10 0.15 0.20 0.25 0.30"
REFERENCES,0.7634408602150538,Proportional violation
REFERENCES,0.7649769585253456,Census
REFERENCES,0.7665130568356375,(g) Group Util
REFERENCES,0.7680491551459293,"9000
9500
10000
Clustering cost 0.0 0.1 0.2 0.3 0.4"
REFERENCES,0.7695852534562212,Proportional violation
REFERENCES,0.7711213517665131,Census
REFERENCES,0.7726574500768049,(h) Group Util-Sum
REFERENCES,0.7741935483870968,"8800
9000
9200
Clustering cost 0.000 0.025 0.050 0.075 0.100 0.125 0.150"
REFERENCES,0.7757296466973886,Proportional violation
REFERENCES,0.7772657450076805,Census
REFERENCES,0.7788018433179723,(i) Group Egalit
REFERENCES,0.7803379416282642,"9000
9500
10000
Clustering cost 0.00 0.05 0.10 0.15 0.20"
REFERENCES,0.7818740399385561,Proportional violation
REFERENCES,0.783410138248848,Census
REFERENCES,0.7849462365591398,(j) Group Egalit-Sum
REFERENCES,0.7864823348694316,"405
410
415
420
Clustering cost 0.22 0.24 0.26 0.28 0.30 0.32"
REFERENCES,0.7880184331797235,Balance
REFERENCES,0.7895545314900153,BlueBike
REFERENCES,0.7910906298003072,(k) Balance
REFERENCES,0.7926267281105991,"405
410
415
420
Clustering cost 0.00 0.05 0.10 0.15 0.20"
REFERENCES,0.794162826420891,Proportional violation
REFERENCES,0.7956989247311828,BlueBike
REFERENCES,0.7972350230414746,(l) Group Util
REFERENCES,0.7987711213517665,"405
410
415
420
Clustering cost 0.0 0.1 0.2 0.3 0.4"
REFERENCES,0.8003072196620584,Proportional violation
REFERENCES,0.8018433179723502,BlueBike
REFERENCES,0.8033794162826421,(m) Group Util-Sum
REFERENCES,0.804915514592934,"405
410
415
420
Clustering cost 0.00 0.02 0.04 0.06 0.08 0.10"
REFERENCES,0.8064516129032258,Proportional violation
REFERENCES,0.8079877112135176,BlueBike
REFERENCES,0.8095238095238095,(n) Group Egalit
REFERENCES,0.8110599078341014,"405
410
415
420
Clustering cost 0.00 0.05 0.10 0.15 0.20"
REFERENCES,0.8125960061443932,Proportional violation
REFERENCES,0.8141321044546851,BlueBike
REFERENCES,0.815668202764977,(o) Group Egalit-Sum
REFERENCES,0.8172043010752689,"Figure 6: Pareto front recovered by Algorithm 1 for the Adult, Census, and BlueBike datasets (by
row), for various fairness objectives (by column), for k = 3 clusters."
REFERENCES,0.8187403993855606,"700
725
750
775
800
Clustering cost 0.0 0.2 0.4 0.6 0.8 1.0"
REFERENCES,0.8202764976958525,Proportional violation Adult
REFERENCES,0.8218125960061444,"Dyn Progr
FCBC"
REFERENCES,0.8233486943164362,(a) Group Util
REFERENCES,0.8248847926267281,"9000
10000
11000
Clustering cost 0.0 0.1 0.2 0.3"
REFERENCES,0.82642089093702,Proportional violation
REFERENCES,0.8279569892473119,Census
REFERENCES,0.8294930875576036,"Dyn Progr
FCBC"
REFERENCES,0.8310291858678955,(b) Group Util
REFERENCES,0.8325652841781874,"410
420
430
440
Clustering cost 0.00 0.05 0.10 0.15 0.20 0.25"
REFERENCES,0.8341013824884793,Proportional violation
REFERENCES,0.8356374807987711,BlueBike
REFERENCES,0.837173579109063,"Dyn Progr
FCBC"
REFERENCES,0.8387096774193549,(c) Group Util
REFERENCES,0.8402457757296466,"700
720
740
760
Clustering cost 0.0 0.2 0.4 0.6"
REFERENCES,0.8417818740399385,Proportional violation Adult
REFERENCES,0.8433179723502304,"Dyn Progr
FCBC"
REFERENCES,0.8448540706605223,(d) Group Egalit
REFERENCES,0.8463901689708141,"9000
9500
10000
10500
Clustering cost 0.0 0.1 0.2 0.3 0.4 0.5"
REFERENCES,0.847926267281106,Proportional violation
REFERENCES,0.8494623655913979,Census
REFERENCES,0.8509984639016898,"Dyn Progr
FCBC"
REFERENCES,0.8525345622119815,(e) Group Egalit
REFERENCES,0.8540706605222734,"410
420
430
Clustering cost 0.00 0.05 0.10 0.15"
REFERENCES,0.8556067588325653,Proportional violation
REFERENCES,0.8571428571428571,BlueBike
REFERENCES,0.858678955453149,"Dyn Progr
FCBC"
REFERENCES,0.8602150537634409,(f) Group Egalit
REFERENCES,0.8617511520737328,"Figure 7: Pareto front recovered by Algorithm 1 (labeled as ‘Dyn Progr’, in blue) and by Algorithm 2
(labeled as ‘FCBC’, in orange) for the Adult, Census, and BlueBike datasets (by column) and for the
GROUP UTILITARIAN and GROUP EGALITARIAN objectives (by row), for k = 3 clusters."
REFERENCES,0.8632872503840245,"4100
4150
4200
4250
Clustering cost 0 1 2 3 4 5 6"
REFERENCES,0.8648233486943164,Sum of Imbalances Adult (a)
REFERENCES,0.8663594470046083,"52600
52800
53000
Clustering cost 0 10 20 30"
REFERENCES,0.8678955453149002,Sum of Imbalances
REFERENCES,0.869431643625192,Census (b)
REFERENCES,0.8709677419354839,"2300
2310
2320
Clustering cost 0 20 40 60"
REFERENCES,0.8725038402457758,Sum of Imbalances
REFERENCES,0.8740399385560675,BlueBike (c)
REFERENCES,0.8755760368663594,"620
640
660
680
700
Clustering cost 0 5 10 15 20 25 30"
REFERENCES,0.8771121351766513,Sum of Imbalances Adult (d)
REFERENCES,0.8786482334869432,"8900
9000
9100
9200
9300
Clustering cost 0 10 20 30"
REFERENCES,0.880184331797235,Sum of Imbalances
REFERENCES,0.8817204301075269,Census (e)
REFERENCES,0.8832565284178188,"385.0
387.5
390.0
392.5
395.0
Clustering cost 0 5 10 15 20 25 30"
REFERENCES,0.8847926267281107,Sum of Imbalances
REFERENCES,0.8863287250384024,BlueBike (f)
REFERENCES,0.8878648233486943,"Figure 8: Pareto front recovered for the SUM OF IMBALANCES objective for the Adult, Census, and
BlueBike datasets (by column), for k = 2 (top row) and k = 3 (bottom row) clusters."
REFERENCES,0.8894009216589862,NeurIPS Paper Checklist
CLAIMS,0.890937019969278,1. Claims
CLAIMS,0.8924731182795699,"Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?"
CLAIMS,0.8940092165898618,Answer: [Yes]
CLAIMS,0.8955453149001537,"Justification: We provide a clear summary of our results in the abstract and introduction,
stating all conditions needed for the results to hold. We summarize the experiments presented
in the paper, with details in the main section and the Appendix."
CLAIMS,0.8970814132104454,Guidelines:
CLAIMS,0.8986175115207373,"• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper."
LIMITATIONS,0.9001536098310292,2. Limitations
LIMITATIONS,0.901689708141321,Question: Does the paper discuss the limitations of the work performed by the authors?
LIMITATIONS,0.9032258064516129,Answer: [Yes]
LIMITATIONS,0.9047619047619048,"Justification: The paper discusses all the necessary conditions for the results to hold. In
particular, all our algorithms require that the first objective (the clustering objective) is
based on a metric and that the second objective (the fairness objective) is pattern-based.
Algorithm 1 also requires that the fairness objective is mergeable. We give theoretical
bounds for the running time of all algorithms and we showcase the running time empirically
for the algorithms present in the experimental section. We clearly state the datasets and
parameters used. We discuss limitations in the discussion section in detail."
LIMITATIONS,0.9062980030721967,Guidelines:
LIMITATIONS,0.9078341013824884,"• The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ""Limitations"" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best"
LIMITATIONS,0.9093701996927803,"judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3. Theory Assumptions and Proofs"
LIMITATIONS,0.9109062980030722,"Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: All our theoretical results clearly state the necessary conditions in the body
of the theorems (e.g., Theorems 3.2–3.6) require a clustering objective based on a metric
and a pattern-based fairness objective, while Theorem 3.4 also requires a mergeable fairness
objective. The main paper contains sketches of all proofs and the Appendix contains all the
detailed proofs.
Guidelines:"
LIMITATIONS,0.9124423963133641,"• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4. Experimental Result Reproducibility"
LIMITATIONS,0.9139784946236559,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We provide the pseudocode of all algorithms used in the paper and the
Appendix, with detailed parameters choices, instantiation details, and number of runs. All
the code and data is available at this link.
Guidelines:"
LIMITATIONS,0.9155145929339478,"• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully."
LIMITATIONS,0.9170506912442397,"(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results."
OPEN ACCESS TO DATA AND CODE,0.9185867895545314,5. Open access to data and code
OPEN ACCESS TO DATA AND CODE,0.9201228878648233,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?"
OPEN ACCESS TO DATA AND CODE,0.9216589861751152,Answer: [Yes]
OPEN ACCESS TO DATA AND CODE,0.9231950844854071,"Justification: All the code and data is available at this link. All experimental details are
provided in the main paper as well as in the Appendix for reproducibility of results."
OPEN ACCESS TO DATA AND CODE,0.9247311827956989,Guidelines:
OPEN ACCESS TO DATA AND CODE,0.9262672811059908,"• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted."
OPEN ACCESS TO DATA AND CODE,0.9278033794162827,6. Experimental Setting/Details
OPEN ACCESS TO DATA AND CODE,0.9293394777265745,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?"
OPEN ACCESS TO DATA AND CODE,0.9308755760368663,Answer: [Yes]
OPEN ACCESS TO DATA AND CODE,0.9324116743471582,"Justification: We provide all experimental details (choices of input, parameter settings, data
details, and number of runs) in the main paper as well as the Appendix."
OPEN ACCESS TO DATA AND CODE,0.9339477726574501,Guidelines:
OPEN ACCESS TO DATA AND CODE,0.9354838709677419,"• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9370199692780338,7. Experiment Statistical Significance
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9385560675883257,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9400921658986175,"Answer: [No]
Justification: The results do not require error bars, as there is always the same set of Pareto
points recovered for the Pareto front for the assignment problem when using a standard
vanilla k-means clustering algorithm (in our case, k-means++) as an input to our algorithms.
We subsample the data once and regarded fixed from there on.
Guidelines:"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9416282642089093,"• The answer NA means that the paper does not include experiments.
• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g., negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8. Experiments Compute Resources"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9431643625192012,"Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: We provide details on the machines used to run the experiments, the libraries
needed, as well as an empirical running time analysis in the paper, both in the Experiments
section as well as in the Appendix.
Guidelines:"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9447004608294931,"• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9. Code Of Ethics"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.946236559139785,"Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
Answer: [Yes]"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9477726574500768,"Justification: The paper conforms to the NeurIPS Code of Ethics. In particular, the datasets
used are open widely used in related work; we do not use human participants; we discuss
societal implications of our method with the purpose of improving fairness in clustering.
Guidelines:"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9493087557603687,• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9508448540706606,"• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction)."
BROADER IMPACTS,0.9523809523809523,10. Broader Impacts
BROADER IMPACTS,0.9539170506912442,"Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?"
BROADER IMPACTS,0.9554531490015361,"Answer: [Yes]
Justification: We discuss the broader impact of our paper, in particular potential use cases
by practitioners who wish to use our method for decision-making in choosing an optimal
trade-off between clustering and fairness objectives, in cases where the data points represent
people."
BROADER IMPACTS,0.956989247311828,Guidelines:
BROADER IMPACTS,0.9585253456221198,"• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML)."
SAFEGUARDS,0.9600614439324117,11. Safeguards
SAFEGUARDS,0.9615975422427036,"Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?"
SAFEGUARDS,0.9631336405529954,Answer: [NA]
SAFEGUARDS,0.9646697388632872,Justification: The paper poses no such risks.
SAFEGUARDS,0.9662058371735791,Guidelines:
SAFEGUARDS,0.967741935483871,"• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort."
LICENSES FOR EXISTING ASSETS,0.9692780337941628,12. Licenses for existing assets
LICENSES FOR EXISTING ASSETS,0.9708141321044547,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?"
LICENSES FOR EXISTING ASSETS,0.9723502304147466,Answer: [Yes]
LICENSES FOR EXISTING ASSETS,0.9738863287250384,"Justification: We cite all the datasets used, noting that they are open for use. We cite any
code used for the implementation of Algorithm 2 properly. All other code is written and
owned by the authors."
LICENSES FOR EXISTING ASSETS,0.9754224270353302,Guidelines:
LICENSES FOR EXISTING ASSETS,0.9769585253456221,"• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
• If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators."
NEW ASSETS,0.978494623655914,13. New Assets
NEW ASSETS,0.9800307219662059,"Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?"
NEW ASSETS,0.9815668202764977,Answer: [Yes]
NEW ASSETS,0.9831029185867896,"Justification: We describe all datasets used, with proper documentation of parameters used,
algorithms, and code instructions. All datasets and code are made available at this link."
NEW ASSETS,0.9846390168970814,Guidelines:
NEW ASSETS,0.9861751152073732,"• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used.
• At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9877112135176651,14. Crowdsourcing and Research with Human Subjects
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.989247311827957,"Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9907834101382489,Answer: [NA]
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9923195084485407,Justification: The paper does not involve crowdsourcing nor research with human subjects.
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9938556067588326,Guidelines:
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9953917050691244,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9969278033794163,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9984639016897081,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review."
