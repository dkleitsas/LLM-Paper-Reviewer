Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0017035775127768314,"The recent advancements in large language models (LLMs) have sparked a growing
1"
ABSTRACT,0.0034071550255536627,"apprehension regarding the potential misuse. One approach to mitigating this risk
2"
ABSTRACT,0.005110732538330494,"is to incorporate watermarking techniques into LLMs, allowing for the tracking and
3"
ABSTRACT,0.0068143100511073255,"attribution of model outputs. This study examines a crucial aspect of watermark-
4"
ABSTRACT,0.008517887563884156,"ing: how significantly watermarks impact the quality of model-generated outputs.
5"
ABSTRACT,0.010221465076660987,"Previous studies have suggested a trade-off between watermark strength and out-
6"
ABSTRACT,0.01192504258943782,"put quality. However, our research demonstrates that it is possible to integrate
7"
ABSTRACT,0.013628620102214651,"watermarks without affecting the output probability distribution with appropriate
8"
ABSTRACT,0.015332197614991482,"implementation. We refer to this type of watermark as an unbiased watermark.
9"
ABSTRACT,0.017035775127768313,"This has significant implications for the use of LLMs, as it becomes impossible
10"
ABSTRACT,0.018739352640545145,"for users to discern whether a service provider has incorporated watermarks or not.
11"
ABSTRACT,0.020442930153321975,"Furthermore, the presence of watermarks does not compromise the performance
12"
ABSTRACT,0.022146507666098807,"of the model in downstream tasks, ensuring that the overall utility of the language
13"
ABSTRACT,0.02385008517887564,"model is preserved. Our findings contribute to the ongoing discussion around
14"
ABSTRACT,0.02555366269165247,"responsible AI development, suggesting that unbiased watermarks can serve as
15"
ABSTRACT,0.027257240204429302,"an effective means of tracking and attributing model outputs without sacrificing
16"
ABSTRACT,0.028960817717206135,"output quality.
17"
INTRODUCTION,0.030664395229982964,"1
Introduction
18"
INTRODUCTION,0.03236797274275979,"In recent years, large language models (LLMs) [19, 39, 40] have become an indispensable tool for a
19"
INTRODUCTION,0.034071550255536626,"wide range of tasks, including text generation [27, 10], translation [7, 5], summarization [36], etc.
20"
INTRODUCTION,0.03577512776831346,"With the escalating misuse of LLMs, such as plagiarism, tracking the usage of text generated by
21"
INTRODUCTION,0.03747870528109029,"machines has become increasingly important. One viable method to monitor the usage of LLMs
22"
INTRODUCTION,0.039182282793867124,"is watermarking [20, 32, 59], which embeds imperceptible information within the generated text,
23"
INTRODUCTION,0.04088586030664395,"thereby allowing for efficient detection and tracking of the model’s potential abuse.
24"
INTRODUCTION,0.04258943781942078,"Watermarking techniques can serve multiple purposes, such as embedding ownership information
25"
INTRODUCTION,0.044293015332197615,"within the generated text to protect the intellectual property rights of the model. It can also help
26"
INTRODUCTION,0.04599659284497445,"mitigate potential harm caused by LLMs by monitoring where the model is being used and whether it
27"
INTRODUCTION,0.04770017035775128,"is being misused or abused.
28"
INTRODUCTION,0.049403747870528106,"A good watermarking method should not adversely affect the normal usage of the language model or
29"
INTRODUCTION,0.05110732538330494,"degrade the quality of the generated text. However, a prevailing belief holds that there is an inevitable
30"
INTRODUCTION,0.05281090289608177,"trade-off between the strength of the watermark and the quality of the output text. For instance,
31"
INTRODUCTION,0.054514480408858604,"recent work by Kirchenbauer et al. [32] introduced a method that augmented the logits of a randomly
32"
INTRODUCTION,0.056218057921635436,"selected set of ""green"" tokens. By tuning the “magnitude of logits adjustment”, they demonstrated a
33"
INTRODUCTION,0.05792163543441227,"trade-off between watermark strength and text quality.
34"
INTRODUCTION,0.059625212947189095,"Our primary contribution is to challenge this conventional wisdom. We show that with the right
35"
INTRODUCTION,0.06132879045996593,"implementation, watermarking can be accomplished without affecting the output quality. We refer to
36"
INTRODUCTION,0.06303236797274275,"this particular type of watermark as an unbiased watermark. We approach the problem of output
37"
INTRODUCTION,0.06473594548551959,"quality degradation from the perspective of watermark detection. We posit that if the watermark
38"
INTRODUCTION,0.06643952299829642,"causes a decline in output quality, there should be a method to guess the presence of the watermark
39"
INTRODUCTION,0.06814310051107325,"based on the quality. Conversely, if the watermark cannot be detected, it implies that the output
40"
INTRODUCTION,0.06984667802385008,"quality remains unaffected. Specifically, we provide a proof that with a suitable implementation,
41"
INTRODUCTION,0.07155025553662692,"watermarking does not affect the output probability distribution. This has significant implications,
42"
INTRODUCTION,0.07325383304940375,"as users who do not have the private key are unable to discern whether a service provider has
43"
INTRODUCTION,0.07495741056218058,"applied watermarking to the model. Furthermore, the addition of watermarking does not affect
44"
INTRODUCTION,0.07666098807495741,"the performance of the generated text in any downstream tasks. Our main contributions can be
45"
INTRODUCTION,0.07836456558773425,"summarized as follows:
46"
INTRODUCTION,0.08006814310051108,"• We introduce unbiased watermark, an innovative family of watermark methods that guarantee the
47"
INTRODUCTION,0.0817717206132879,"non-degradation of text quality. In addition, we offer a comprehensive framework that facilitates
48"
INTRODUCTION,0.08347529812606473,"the design and detection of unbiased watermarks.
49"
INTRODUCTION,0.08517887563884156,"• We propose two innovative and practical watermarking techniques known as δ-reweight and
50"
INTRODUCTION,0.0868824531516184,"γ-reweight. Through extensive experimentation, we demonstrate that these techniques preserve
51"
INTRODUCTION,0.08858603066439523,"output quality in machine translation and text summarization tasks.
52"
INTRODUCTION,0.09028960817717206,"• We develop an advanced maximin variant of the original log-likelihood ratio test for watermark
53"
INTRODUCTION,0.0919931856899489,"detection. This novel detection method comes with theoretical guarantees, specifically an upper
54"
INTRODUCTION,0.09369676320272573,"bound on type I error, thus enhancing the reliability of watermark detection in language models.
55"
PRELIMINARY,0.09540034071550256,"2
Preliminary
56"
PRELIMINARY,0.09710391822827939,"In this section, we delve into the problem of watermarking in the context of LLMs. We begin by
57"
PRELIMINARY,0.09880749574105621,"setting up the problem and defining essential concepts.
58"
PRELIMINARY,0.10051107325383304,"Problem Modeling: We first introduce several notations to formalize the problem. Let Σ denote the
59"
PRELIMINARY,0.10221465076660988,"vocabulary set, which is the set of all possible tokens an LLM can generate in a single step. We then
60"
PRELIMINARY,0.10391822827938671,"define the set Σ∗as the collection of all possible strings of any length, including those of length zero.
61"
PRELIMINARY,0.10562180579216354,"An LLM generates a sequence of tokens conditioned on a given context. In a single step, the
62"
PRELIMINARY,0.10732538330494037,"probability of generating the next token xn+1 ∈Σ given the current context, x1, x2, ..., xn, can be
63"
PRELIMINARY,0.10902896081771721,"denoted as PM(xn+1 | x1, x2, ..., xn). The LLM operates in an autoregressive fashion, which means
64"
PRELIMINARY,0.11073253833049404,"the joint probability of generating multiple tokens xn+1, . . . , xn+m can be written as:
65"
PRELIMINARY,0.11243611584327087,"PM(xn+1, . . . , xn+m | x1, x2, ..., xn) = m
Y"
PRELIMINARY,0.1141396933560477,"i=1
PM(xn+i | x1, x2, ..., xn, xn+1, . . . , xn+i−1)."
PRELIMINARY,0.11584327086882454,"For simplicity, we use the following notation: PM(xn+1:n+m | x1:n), where xn+1:n+m =
66"
PRELIMINARY,0.11754684838160136,"(xn+1, . . . , xn+m) ∈Σ∗.
67"
PRELIMINARY,0.11925042589437819,"In the context of watermarking, we introduce a service provider that holds a private key k from the key
68"
PRELIMINARY,0.12095400340715502,"space K. The key k ∈K is chosen at random from the prior distribution PK(k). The watermarked
69"
PRELIMINARY,0.12265758091993186,"output of the LLM follows distribution PM,w(xn+1 | x1, x2, ..., xn; k), which is conditioned on both
70"
PRELIMINARY,0.12436115843270869,"the key k and the context x1:n. Similarly, we use the notation PM,w(xn+1:n+m | x1:n; k) for the
71"
PRELIMINARY,0.1260647359454855,"probability of generating a sequence of tokens in a watermarked model.
72"
PRELIMINARY,0.12776831345826234,"Objective. Our goal is to devise a watermarking scheme that: a) is efficiently detectable by the
73"
PRELIMINARY,0.12947189097103917,"service provider; b) can’t be detected by users and does not negatively impact the quality of the
74"
PRELIMINARY,0.131175468483816,"output.
75"
PRELIMINARY,0.13287904599659284,"The reason we focus on the detection of watermarks by users is that it is closely related to the output
76"
PRELIMINARY,0.13458262350936967,"quality. If the watermark causes a degradation in the output quality, there should exist a method
77"
PRELIMINARY,0.1362862010221465,"to infer the presence of the watermark by examining the quality. Conversely, if the watermark is
78"
PRELIMINARY,0.13798977853492334,"undetectable, it implies that it does not impact the output quality.
79"
PRELIMINARY,0.13969335604770017,"From a statistical testing perspective, a watermark is considered strictly undetectable if the probability
80"
PRELIMINARY,0.141396933560477,"distributions of the watermarked and non-watermarked outputs are identical. To capture this notion,
81"
PRELIMINARY,0.14310051107325383,"we define several desirable properties of watermarking schemes.
82"
PRELIMINARY,0.14480408858603067,"Definition 1 (n-shot-undetectable). For a fixed input sequence a ∈Σ∗, we say that watermarked
83"
PRELIMINARY,0.1465076660988075,"LLM and key prior pair (PM,w, PK) is n-shot-undetectable compared to original LLM PM if
84 n
Y"
PRELIMINARY,0.14821124361158433,"i=1
PM(xi | a) =
X"
PRELIMINARY,0.14991482112436116,"k∈K
PK(k) n
Y"
PRELIMINARY,0.151618398637138,"i=1
PM,w(xi | a; k),
for any n number of strings xi ∈Σ∗."
PRELIMINARY,0.15332197614991483,"Definition 2 (downstream-invariant). We say the watermarked LLM and key prior pair (PM,w, PK)
85"
PRELIMINARY,0.15502555366269166,"are invariant compared to original LLM PM on downstream tasks iff
86"
PRELIMINARY,0.1567291311754685,"Ex∼PM,w(·|a;k),k∼PK[f(x)] = Ex∼PM(·|a)[f(x)],
for any strings x, a ∈Σ∗, and for any metric f : Σ∗→R.
87"
PRELIMINARY,0.15843270868824533,"Note that the one-shot-undetectable property implies the downstream invariant property. Interestingly,
88"
PRELIMINARY,0.16013628620102216,"this implication does not require the n-shot-undetectable property for n > 1, which means a water-
89"
PRELIMINARY,0.16183986371379896,"marking scheme that is one-shot-undetectable can still maintain the output quality for downstream
90"
PRELIMINARY,0.1635434412265758,"tasks even if the user might discern the existence of the watermark through multiple generation
91"
PRELIMINARY,0.16524701873935263,"requests.
92"
PRELIMINARY,0.16695059625212946,"In summary, we have outlined the preliminary concepts and objectives for developing a watermarking
93"
PRELIMINARY,0.1686541737649063,"scheme for LLMs. We highlight the desired properties of n-shot-undetectability and downstream
94"
PRELIMINARY,0.17035775127768313,"invariance, as they provide a rigorous theoretical guarantee of quality preservation and integrity in
95"
PRELIMINARY,0.17206132879045996,"the deployment of watermark schema. In Section 4, we will present a watermark framework that is
96"
PRELIMINARY,0.1737649063032368,"provably n-shot-undetectable for any given integer n ≥1.
97"
PRELIMINARY,0.17546848381601363,"3
Warm up: undetectability in a simplified toy environment
98"
PRELIMINARY,0.17717206132879046,"In this subsection, we aim to prove the feasibility of undetectability in a highly simplified toy
99"
PRELIMINARY,0.1788756388415673,"environment. This preliminary analysis serves as a foundation for understanding the more complex
100"
PRELIMINARY,0.18057921635434412,"scenarios that follow.
101"
PRELIMINARY,0.18228279386712096,"Settings. Consider a service provider that offers a random number generation service. The service
102"
PRELIMINARY,0.1839863713798978,"outputs a uniformly distributed random number in the set {0, 1}. The clean generation process can
103"
PRELIMINARY,0.18568994889267462,"be represented as PM(x) = 1/2, ∀x ∈{0, 1}. We assume that the key k belongs to the set {0, 1}
104"
PRELIMINARY,0.18739352640545145,"and is selected with equal probability. With the watermark added, the probability of the new output
105"
PRELIMINARY,0.1890971039182283,"can be expressed as: PM,w(x | k) = δk(x).
106"
PRELIMINARY,0.19080068143100512,Recall that the one-shot-undetectable property can be represented as PM(x) = P
PRELIMINARY,0.19250425894378195,"k∈K PM,w(x |
107"
PRELIMINARY,0.19420783645655879,"k)PK(k). Suppose that a user can only make a single request to the service. If the user is unaware
108"
PRELIMINARY,0.19591141396933562,"of the key, the user will be unable to distinguish whether the received result is watermarked or not.
109"
PRELIMINARY,0.19761499148211242,"Therefore, in this simplified scenario, the undetectability of the watermark is achieved.
110"
PRELIMINARY,0.19931856899488926,"However, there is a considerable gap between this toy example and the practical implementation of
111"
PRELIMINARY,0.2010221465076661,"watermarking in LLMs. Firstly, the symbol set Σ in LLMs is far more complex than the binary set
112"
PRELIMINARY,0.20272572402044292,"{0, 1}, and the probability distribution is not uniform. Besides, the generation process in LLMs is
113"
PRELIMINARY,0.20442930153321975,"autoregressive, which means that more than one symbol are generated iteratively. Furthermore, the
114"
PRELIMINARY,0.2061328790459966,"toy example does not satisfy the n-shot-undetectable property for n > 1.
115"
PRELIMINARY,0.20783645655877342,"Despite these differences, this simple example provides essential insights that help in understanding
116"
PRELIMINARY,0.20954003407155025,"the following sections where we address these challenges. The underlying principles of undetectability
117"
PRELIMINARY,0.21124361158432708,"remain constant, while their application becomes more intricate in a more complex environment.
118"
WATERMARKING WITH UNBIASED REWEIGHTING,0.21294718909710392,"4
Watermarking with unbiased reweighting
119"
WATERMARKING WITH UNBIASED REWEIGHTING,0.21465076660988075,"In this section, we build upon the intuition from the previous section and extend the approach to
120"
WATERMARKING WITH UNBIASED REWEIGHTING,0.21635434412265758,"LLMs’ generation. The section is structured as follows: Section 4.1 introduces a fundamental
121"
WATERMARKING WITH UNBIASED REWEIGHTING,0.21805792163543442,"mathematical tool for addressing the reweighting problem in general discrete probability distributions.
122"
WATERMARKING WITH UNBIASED REWEIGHTING,0.21976149914821125,"Section 4.2 applies the reweighting technique to LLMs. Section 4.3 presents the final framework.
123"
DISTRIBUTION REWEIGHTING,0.22146507666098808,"4.1
Distribution reweighting
124"
DISTRIBUTION REWEIGHTING,0.2231686541737649,"In its most general form, we consider a random watermark code E and a reweight function RE :
125"
DISTRIBUTION REWEIGHTING,0.22487223168654175,"∆Σ →∆Σ, which depends on the random watermark code E. The set of all possible probability
126"
DISTRIBUTION REWEIGHTING,0.22657580919931858,"distributions on the symbol set Σ is denoted as ∆Σ, which forms a simplex.
127"
DISTRIBUTION REWEIGHTING,0.2282793867120954,"Definition 3. A reweighting function is a tuple (E, PE, R) where E is called the watermark code
128"
DISTRIBUTION REWEIGHTING,0.22998296422487224,"space, PE is a probability distribution on space E, and R is a function R : E × ∆Σ →∆Σ.
129"
DISTRIBUTION REWEIGHTING,0.23168654173764908,"For a specific watermark code E ∈E, we denote the partially evaluated reweighting function as
130"
DISTRIBUTION REWEIGHTING,0.23339011925042588,"RE : ∆Σ →∆Σ.
131"
DISTRIBUTION REWEIGHTING,0.23509369676320271,"Definition 4. Given a random watermark code E and a reweighting function RE : ∆Σ →∆Σ, we
132"
DISTRIBUTION REWEIGHTING,0.23679727427597955,"say that R is an unbiased reweighting function if and only if for all P ∈∆Σ, EE[RE(P)] = P.
133"
EXISTING REWEIGHTING METHODS,0.23850085178875638,"4.1.1
Existing reweighting methods
134"
EXISTING REWEIGHTING METHODS,0.2402044293015332,"Kirchenbauer et al. [32] essentially comprise two reweighting methods in their work, but neither of
135"
EXISTING REWEIGHTING METHODS,0.24190800681431004,"them satisfies the unbiased property.
136"
EXISTING REWEIGHTING METHODS,0.24361158432708688,"Both methods have E as the set of mappings f : Σ →{red, green}, such that f maps half of the
137"
EXISTING REWEIGHTING METHODS,0.2453151618398637,"tokens in Σ to ‘red’ and the other half to ‘green’, and PE as a uniform distribution. Therefore, the
138"
EXISTING REWEIGHTING METHODS,0.24701873935264054,"random watermark code E assigns each symbol to either red or green. The “Hard Red List” method
139"
EXISTING REWEIGHTING METHODS,0.24872231686541738,"sets the probability of all red symbols to zero and renormalizes the probabilities of the remaining
140"
EXISTING REWEIGHTING METHODS,0.2504258943781942,"vocabulary. The second method is “Soft Red List” blocking, where they randomly select the same
141"
EXISTING REWEIGHTING METHODS,0.252129471890971,"“Red List” as the first method and decrease the corresponding probability for red symbols by adding a
142"
EXISTING REWEIGHTING METHODS,0.25383304940374785,"constant δ to the logits of the green symbols, then apply softmax to obtain the final probabilities.
143"
UNBIASED REWEIGHTING METHODS,0.2555366269165247,"4.1.2
Unbiased reweighting methods
144"
UNBIASED REWEIGHTING METHODS,0.2572402044293015,"In this section, we present two reweighting methods that satisfy the unbiased property.
145"
UNBIASED REWEIGHTING METHODS,0.25894378194207834,"δ-reweight: Let the watermark code space E be the interval [0, 1], and let PE be the uniform
146"
UNBIASED REWEIGHTING METHODS,0.2606473594548552,"probability on E. Leveraging Inverse Transform Sampling1 [14], we can sample from distribution
147"
UNBIASED REWEIGHTING METHODS,0.262350936967632,"P ∈∆Σ using a uniformly distributed random number in [0, 1]. Therefore, we have a mapping
148"
UNBIASED REWEIGHTING METHODS,0.26405451448040884,"samplingP : E →Σ. The δ-reweight just returns a delta distribution RE(P) = δsamplingP (E).
149"
UNBIASED REWEIGHTING METHODS,0.2657580919931857,"It is important to note that while the reweighted distribution for each individual random event E
150"
UNBIASED REWEIGHTING METHODS,0.2674616695059625,"is a delta distribution, the mean output token probabilities remain the original distribution P when
151"
UNBIASED REWEIGHTING METHODS,0.26916524701873934,"considering the randomness of E.
152"
UNBIASED REWEIGHTING METHODS,0.2708688245315162,"γ-reweight: Let the watermark code space E be the set of all bijective function between vocabularies
153"
UNBIASED REWEIGHTING METHODS,0.272572402044293,"set Σ and a set of indices [|Σ|] = {1, . . . , |Σ|}, where |Σ| is the size of vocabularies set Σ. Essentially,
154"
UNBIASED REWEIGHTING METHODS,0.27427597955706984,"any watermark code E is an indexing function for vocabularies set Σ, and is also equivalent to a total
155"
UNBIASED REWEIGHTING METHODS,0.27597955706984667,"order on Σ. Let PE be the uniform probability on E, it is easy to sample a watermark code E by
156"
UNBIASED REWEIGHTING METHODS,0.2776831345826235,"randomly shuffling the symbol list.
157"
UNBIASED REWEIGHTING METHODS,0.27938671209540034,"Assume the original distribution is PT (t) ∈∆Σ, ∀t ∈Σ. Given the watermark code E : Σ →[|Σ|],
158"
UNBIASED REWEIGHTING METHODS,0.28109028960817717,we construct auxiliary functions FI(i) = P
UNBIASED REWEIGHTING METHODS,0.282793867120954,"t∈Σ 1(E(t) ≤i)PT (t), FS(s) = max(2s −1, 0),
159"
UNBIASED REWEIGHTING METHODS,0.28449744463373083,"FI′(i) = FS(FI(i)). The γ-reweight yields new distribution PT ′(t) = FI′(E(t)) −FI′(E(t) −1).
160"
UNBIASED REWEIGHTING METHODS,0.28620102214650767,"...
“ but"" ...
“ized""
... E"
UNBIASED REWEIGHTING METHODS,0.2879045996592845,Reweight
UNBIASED REWEIGHTING METHODS,0.28960817717206133,"“ized"""
UNBIASED REWEIGHTING METHODS,0.29131175468483816,"0
1
Figure 1: Illustration of δ-reweight."
UNBIASED REWEIGHTING METHODS,0.293015332197615,"...
“ but"" ...
“ized""
..."
UNBIASED REWEIGHTING METHODS,0.29471890971039183,"...
“ized""
...
“ but"" ..."
UNBIASED REWEIGHTING METHODS,0.29642248722316866,"0
1/2
1"
UNBIASED REWEIGHTING METHODS,0.2981260647359455,Shuffle
UNBIASED REWEIGHTING METHODS,0.29982964224872233,Reweight
UNBIASED REWEIGHTING METHODS,0.30153321976149916,"“ized""
...
“ but""
..."
UNBIASED REWEIGHTING METHODS,0.303236797274276,"0
1
Figure 2: Illustration of γ-reweight."
UNBIASED REWEIGHTING METHODS,0.3049403747870528,"We provide illustrations of the δ-reweight and γ-reweight methods in Figures 1 and 2. Each block
161"
UNBIASED REWEIGHTING METHODS,0.30664395229982966,"represents a token, and the width represents the probability of that token, so the total length is 1 The
162"
UNBIASED REWEIGHTING METHODS,0.3083475298126065,"left panel shows the δ-reweight method, where each individual random watermark code E ∈[0, 1]
163"
UNBIASED REWEIGHTING METHODS,0.3100511073253833,"uniformly sampled from interval [0, 1] corresponds to a specific token according to the horizontal axis,
164"
UNBIASED REWEIGHTING METHODS,0.31175468483816016,"and the reweighted distribution is just a δ distribution on that token, such that the selected token has 1
165"
UNBIASED REWEIGHTING METHODS,0.313458262350937,"probability, and all other vocabulary tokens have a probability of 0. The right panel demonstrates the
166"
UNBIASED REWEIGHTING METHODS,0.3151618398637138,"γ-reweight method. First, the symbol set is shuffled. Then, the left half of the regions are rejected,
167"
UNBIASED REWEIGHTING METHODS,0.31686541737649065,"and the remaining regions are amplified with a factor of 2.
168"
UNBIASED REWEIGHTING METHODS,0.3185689948892675,"Both methods are unbiased1 when considering the randomness of the watermark code E. For δ-
169"
UNBIASED REWEIGHTING METHODS,0.3202725724020443,"reweight, we can see that by noticing that the probability of returning a δ distribution on a token is
170"
DETAILED DEFINITION AND RIGOROUS PROOF CAN BE FOUND IN APPENDIX D,0.3219761499148211,1Detailed definition and rigorous proof can be found in Appendix D
DETAILED DEFINITION AND RIGOROUS PROOF CAN BE FOUND IN APPENDIX D,0.32367972742759793,"just the original probability on that token, therefore the weighted average of all delta distributions is
171"
DETAILED DEFINITION AND RIGOROUS PROOF CAN BE FOUND IN APPENDIX D,0.32538330494037476,"still the original probability. In the case of γ-reweight, although certain regions are rejected and the
172"
DETAILED DEFINITION AND RIGOROUS PROOF CAN BE FOUND IN APPENDIX D,0.3270868824531516,"other regions are amplified, every token has the same probability to be in the rejected or amplified
173"
DETAILED DEFINITION AND RIGOROUS PROOF CAN BE FOUND IN APPENDIX D,0.3287904599659284,"region, thus ensuring the unbiased property.
174"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.33049403747870526,"4.2
Reweighting for autoregressive model
175"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.3321976149914821,"The reweighting methods presented in the previous section can be applied to single token-generation
176"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.3339011925042589,"directly. Given a prefix x1:n, the probability distribution for generating a new token without a
177"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.33560477001703576,"watermark is denoted as PM(·|x1:n) ∈∆Σ. For a random watermark code E, we sample from a
178"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.3373083475298126,"new distribution PM,w(·|x1:n) = RE(PM(·|x1:n)) ∈∆Σ. If the reweighting function is unbiased,
179"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.3390119250425894,"we have EE[RE(PM(·|x1:n))] = PM(·|x1:n). This ensures that, for an individual unaware of
180"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.34071550255536626,"the watermark code, it is impossible to determine whether a new token is sampled directly from
181"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.3424190800681431,"PM(·|x1:n) or from PM,w(·|x1:n; E) for a random watermark E. However, if the watermark code is
182"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.3441226575809199,"known, one can perform statistical hypothesis testing to determine the likelihood of a token being
183"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.34582623509369675,"sampled from either distribution.
184"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.3475298126064736,"The main challenge now is constructing the watermark code E. Since the LLM generation task is
185"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.3492333901192504,"autoregressive, multiple reweighting steps are required, with each step needing a watermark code Ei
186"
REWEIGHTING FOR AUTOREGRESSIVE MODEL,0.35093696763202725,"for reweighting the distribution of token xi.
187"
INDEPENDENCE OF WATERMARK CODES,0.3526405451448041,"4.2.1
Independence of watermark codes
188"
INDEPENDENCE OF WATERMARK CODES,0.3543441226575809,"It is crucial that Ei values are independent to ensure the unbiased nature of the entire sequence, rather
189"
INDEPENDENCE OF WATERMARK CODES,0.35604770017035775,"than just the single-token generation process.
190"
INDEPENDENCE OF WATERMARK CODES,0.3577512776831346,"Theorem 5. Given an unbiased reweighting function (E, PE, R), if Ei values are i.i.d. with the
191"
INDEPENDENCE OF WATERMARK CODES,0.3594548551959114,"distribution PE, we have:
EE1,...,En[PM,w(x1:n|a1:m)] = PM(x1:n|a1:m).
192"
INDEPENDENCE OF WATERMARK CODES,0.36115843270868825,"If the Ei values are not independent, we cannot guarantee that the generation probability of the entire
193"
INDEPENDENCE OF WATERMARK CODES,0.3628620102214651,"sequence remains unbiased. As an extreme example, consider a case where all Ei values are identical.
194"
INDEPENDENCE OF WATERMARK CODES,0.3645655877342419,"Referring to the random bit example in the previous section, assume that the correct distribution is
195"
INDEPENDENCE OF WATERMARK CODES,0.36626916524701875,"a sequence where each token is a random 0 or 1 with equal probability. Identical Ei values would
196"
INDEPENDENCE OF WATERMARK CODES,0.3679727427597956,"result in identical token outputs, ultimately producing sequences consisting solely of 0’s or 1’s, which
197"
INDEPENDENCE OF WATERMARK CODES,0.3696763202725724,"is clearly biased.
198"
CONTEXT CODE,0.37137989778534924,"4.2.2
Context code
199"
CONTEXT CODE,0.3730834752981261,"To construct a large number of independent watermark codes Ei during watermarking and to know
200"
CONTEXT CODE,0.3747870528109029,"the used Ei values during watermark detection, we follow an approach similar to Kirchenbauer et al.
201"
CONTEXT CODE,0.37649063032367974,"[32] by combining the information from the prefix and a secret key to construct Ei.
202"
CONTEXT CODE,0.3781942078364566,"For a single token generation process, given a prefix x1, x2, ..., xn, we consider an abstract context
203"
CONTEXT CODE,0.3798977853492334,"code space C and an abstract context code generation function cc : Σ∗→C. Based on the prefix,
204"
CONTEXT CODE,0.38160136286201024,"we construct the context code cn+1 = cc(x1, x2, ..., xn). Specific examples include using the entire
205"
CONTEXT CODE,0.3833049403747871,"prefix cn+1 = (x1, x2, ..., xn), and using the m most recent prefixes cn+1 = (xn−m+1, ..., xn). Our
206"
CONTEXT CODE,0.3850085178875639,"comprehensive framework accommodates diverse context code generation approaches, particularly
207"
CONTEXT CODE,0.38671209540034074,"those that integrate error-correcting mechanisms to augment watermark resilience in the face of text
208"
CONTEXT CODE,0.38841567291311757,"manipulation attacks. Nevertheless, we refrain from delving into these strategies within the confines
209"
CONTEXT CODE,0.3901192504258944,"of this paper and consider it a subject for subsequent investigation.
210"
CONTEXT CODE,0.39182282793867124,"The final watermark code is defined as Ei = ˆE(ci, k), using a watermark code generation function
211"
CONTEXT CODE,0.393526405451448,"ˆE : C × K →E.
212"
CONTEXT CODE,0.39522998296422485,"Definition 6. Given an unbiased reweighting function (E, PE, R) and a context code space C, an
213"
CONTEXT CODE,0.3969335604770017,"unbiased watermark code generation function is a tuple (E, PE, R, C, K, PK, ˆE) that satisfies:
214"
CONTEXT CODE,0.3986371379897785,"1. Unbiasedness: Ek∼PK[R ˆ
E(c,k)(P)] = P, ∀P ∈∆Σ, ∀c ∈C.
215"
CONTEXT CODE,0.40034071550255534,"2. Independence: For any n distinct c1, . . . , cn ∈C, the values R ˆ
E(ci,k)(P) are mutually
216"
CONTEXT CODE,0.4020442930153322,"independent.
217"
CONTEXT CODE,0.403747870528109,"Theorem 7. For any unbiased reweighting function and context code space, an unbiased watermark
218"
CONTEXT CODE,0.40545144804088584,"code generation function always exists.
219"
CONTEXT CODE,0.4071550255536627,"In practice, pseudorandom numbers can be used to implement the unbiased watermark code generation
220"
CONTEXT CODE,0.4088586030664395,"function in the above theorem. Specifically, the hash value hash(c, k) can be used as a random seed
221"
CONTEXT CODE,0.41056218057921634,"to sample E from PE as an implementation of E = ˆE(c, k). In this paper, we employ SHA-256 for
222"
CONTEXT CODE,0.4122657580919932,"hash function and a 1024-bit random bitstring as the key k.
223"
CONTEXT CODE,0.41396933560477,"An unbiased watermark code generation function ensures that watermark codes Ei are independent
224"
CONTEXT CODE,0.41567291311754684,"with each other if only their context codes are different. During the generation of a sequence,
225"
CONTEXT CODE,0.41737649063032367,"context codes may be repeated, although this is a rare event in practice. If ci and cj are equal,
226"
CONTEXT CODE,0.4190800681431005,"then Ei and Ej are also equal, violating the independence of Ei. A simple workaround is to skip
227"
CONTEXT CODE,0.42078364565587734,"reweighting for a token when encountering a previously used context code. In other words, we set
228"
CONTEXT CODE,0.42248722316865417,"PM,w(·|a1:m, x1:i−1) = PM(·|a1:m, x1:i−1) if the context code has appeared before.
229"
FRAMEWORK,0.424190800681431,"4.3
Framework
230"
FRAMEWORK,0.42589437819420783,Algorithm 1 Watermarking framework
FRAMEWORK,0.42759795570698467,"1: Input: key for watermark k ∈K, prompt a1:m ∈Σ∗, generate length n ∈N, initial code
history cch ∈2C, context code function cc : Σ∗→C, watermark code generation function
ˆE : C × K →E, and reweighting function R : E × ∆Σ →∆Σ.
2: for t = 1, . . . , n do
3:
Pi ←PM(· | a1:m, x1:i−1)
▷original distribution
4:
ci ←cc(· | a1:m, x1:i−1)
▷context code
5:
if ci ∈cch then
6:
Qi ←Pi
▷skip the reweighting
7:
else
8:
cch ←cch ∪{ci}
▷record history
9:
Ei ←ˆE(ci, k)
▷watermark code
10:
Qi ←REi(Pi)
▷reweighted distribution
11:
Sample the next token xi using distribution Qi
12: return x1:n"
FRAMEWORK,0.4293015332197615,"Integrating the tools discussed earlier, we present a general framework for watermarking here. The
231"
FRAMEWORK,0.43100511073253833,"algorithm for this framework is outlined in Algorithm 1.
232"
FRAMEWORK,0.43270868824531517,"We note that our abstract framework requires the specification of two key components in order to be
233"
FRAMEWORK,0.434412265758092,"practically implemented: the unbiased reweight function RE and the context code function cc.
234"
STATISTICAL HYPOTHESIS TESTING FOR WATERMARK DETECTION,0.43611584327086883,"5
Statistical hypothesis testing for watermark detection
235"
STATISTICAL HYPOTHESIS TESTING FOR WATERMARK DETECTION,0.43781942078364566,"In the previous section, we discussed the process of adding a watermark to a text based on a secret
236"
STATISTICAL HYPOTHESIS TESTING FOR WATERMARK DETECTION,0.4395229982964225,"key k and a given prompt a1:m. The watermark-embedded text can be sampled from the distribution
237"
STATISTICAL HYPOTHESIS TESTING FOR WATERMARK DETECTION,0.44122657580919933,"PM,w(x1:n|a1:m; k). In this section, we focus on the watermark detection task, which is the inverse
238"
STATISTICAL HYPOTHESIS TESTING FOR WATERMARK DETECTION,0.44293015332197616,"problem of watermark embedding.
239"
STATISTICAL HYPOTHESIS TESTING FOR WATERMARK DETECTION,0.444633730834753,"Given a text x1:n, the goal of watermark detection is to infer whether it is more likely to be generated
240"
STATISTICAL HYPOTHESIS TESTING FOR WATERMARK DETECTION,0.4463373083475298,"from the unmarked distribution PM(x1:n|a1:m) or the marked distribution PM,w(x1:n|a1:m; k).
241"
STATISTICAL HYPOTHESIS TESTING FOR WATERMARK DETECTION,0.44804088586030666,"This problem can be formulated as a statistical hypothesis test between two competing hypotheses:
242"
STATISTICAL HYPOTHESIS TESTING FOR WATERMARK DETECTION,0.4497444633730835,"H0, which posits that x1:n follows the unmarked distribution, and H1, which posits that x1:n follows
243"
STATISTICAL HYPOTHESIS TESTING FOR WATERMARK DETECTION,0.4514480408858603,"the marked distribution.
244"
SCORE-BASED TESING,0.45315161839863716,"5.1
Score-based tesing
245"
SCORE-BASED TESING,0.454855195911414,"We focus on a particular kind of score-based testing, which assigns a score to each token in the text.
246"
SCORE-BASED TESING,0.4565587734241908,"The score can be interpreted as the confidence that the token was generated by the watermark model
247"
SCORE-BASED TESING,0.45826235093696766,"rather than the original model. Scores si can be computed based on x1:i, in accordance with the
248"
SCORE-BASED TESING,0.4599659284497445,"autoregressive manner of the generation process.
249"
SCORE-BASED TESING,0.4616695059625213,"The total score S is given by S = Pn
i=1 si. A threshold ˆS is set such that if S < ˆS, the null
250"
SCORE-BASED TESING,0.46337308347529815,"hypothesis H0 is accepted, indicating insufficient evidence to conclude that the text contains a
251"
SCORE-BASED TESING,0.46507666098807493,"watermark. Otherwise, the null hypothesis is rejected. There are two types of error probabilities
252"
SCORE-BASED TESING,0.46678023850085176,"associated with this decision process: Type I error, which is the probability of incorrectly rejecting
253"
SCORE-BASED TESING,0.4684838160136286,"the null hypothesis under H0, denoted as PH0(S ≥ˆS), and Type II error, which is the probability of
254"
SCORE-BASED TESING,0.47018739352640543,"incorrectly accepting the null hypothesis under H1, denoted as PH1(S < ˆS).
255"
SCORE-BASED TESING,0.47189097103918226,"To derive theoretical results, we require the scores to have a specific property: under the null
256"
SCORE-BASED TESING,0.4735945485519591,"hypothesis H0, the exponential momentum of si is bounded, conditioned on the preceding context
257"
SCORE-BASED TESING,0.4752981260647359,"x1,i−1. This requirement leads to an upper bound on α, the Type I error probability.
258"
SCORE-BASED TESING,0.47700170357751276,"To derive theoretical results, we require that the scores have a particular property: the exponential
259"
SCORE-BASED TESING,0.4787052810902896,"moment of si under H0 should be bounded, conditioned on the previous text x1,i−1. This requirement
260"
SCORE-BASED TESING,0.4804088586030664,"leads to an upper bound on the Type I error rate.
261"
SCORE-BASED TESING,0.48211243611584326,"Theorem 8. Given a probability space (Ω, A, P) and a Σ-valued stochastic process xi : 1 ≤i ≤n,
262"
SCORE-BASED TESING,0.4838160136286201,"as well as an R-valued stochastic process si : 1 ≤i ≤n, let Fx
i
:= σ(xj | 1 ≤j ≤i) and
263"
SCORE-BASED TESING,0.4855195911413969,"Fs
i := σ(sj | 1 ≤j ≤i) be the corresponding filtrations, where σ(·) denotes the σ-algebra
264"
SCORE-BASED TESING,0.48722316865417375,"generated by random variables. If Fs
i ⊆Fx
i and E[exp(si)|Fx
i−1] ≤1, then P(Pn
i=1 si ≥t) ≤e−t.
265"
SCORE-BASED TESING,0.4889267461669506,"Therefore, to ensure that the Type I error probability has an upper bound α, we can set the threshold
266"
SCORE-BASED TESING,0.4906303236797274,"ˆS as ˆS = −log(α). In the following, we discuss two special scores.
267"
SCORE-BASED TESING,0.49233390119250425,"5.2
Log likelihood ratio (LLR) score
268"
SCORE-BASED TESING,0.4940374787052811,"According to the Neyman-Pearson lemma, the likelihood ratio test is the most powerful test among
269"
SCORE-BASED TESING,0.4957410562180579,"all tests with the same Type I error rate. Specifically, the log-likelihood ratio (LLR) score is defined
270"
SCORE-BASED TESING,0.49744463373083475,"as si = log PM,w(xi|a1:m,x1:i−1;k)"
SCORE-BASED TESING,0.4991482112436116,"PM(xi|a1:m,x1:i−1)
, and the total score becomes S = log PM,w(x1:n|a1:m;k)"
SCORE-BASED TESING,0.5008517887563884,"PM(x1:n|a1:m)
.
271"
SCORE-BASED TESING,0.5025553662691652,"We now provide an optimization derivation of the above si to gain intuition and set the foundation
272"
SCORE-BASED TESING,0.504258943781942,"for the maximin variant of the LLR score in the next section. Let Pi = PM(·|a1:m, x1:i−1),
273"
SCORE-BASED TESING,0.5059625212947189,"Qi = PM,w(·|a1:m, x1:i−1; k), and let si = Si(xi) ∈R denote the score corresponding to different
274"
SCORE-BASED TESING,0.5076660988074957,"xi. Note that Pi, Qi, and Si are all functions with signature Σ →R, therefore equivalent to vectors
275"
SCORE-BASED TESING,0.5093696763202725,"of dimension |Σ|. We can define the inner product as ⟨Pi, Si⟩= P"
SCORE-BASED TESING,0.5110732538330494,"x∈Σ Pi(x)Si(x).
276"
SCORE-BASED TESING,0.5127768313458262,"The requirement E[exp(si)|F x
i−1] ≤1 can be reformulated as ⟨Pi, exp(Si)⟩≤1, where the expo-
277"
SCORE-BASED TESING,0.514480408858603,"nential function is applied element-wise. Instead of minimizing the Type II error directly, we aim to
278"
SCORE-BASED TESING,0.5161839863713799,"maximize the average score under H1, i.e., ⟨Qi, Si⟩.
279"
SCORE-BASED TESING,0.5178875638841567,"The optimization problem becomes maxSi ⟨Qi, Si⟩, s.t. ⟨Pi, exp(Si)⟩≤1. The optimal solution is
280"
SCORE-BASED TESING,0.5195911413969335,given by Si(x) = log Qi(x)
SCORE-BASED TESING,0.5212947189097104,"Pi(x) , which recovers the optimal log likelihood ratio score.
281"
MAXIMIN VARIANT OF LLR SCORE,0.5229982964224872,"5.3
Maximin variant of LLR score
282"
MAXIMIN VARIANT OF LLR SCORE,0.524701873935264,"One major limitation of the LLR score described in the previous section is that when Qi(x) = 0,
283"
MAXIMIN VARIANT OF LLR SCORE,0.5264054514480409,"Si(x) = −∞. This means that as long as a single token does not come from the watermark model
284"
MAXIMIN VARIANT OF LLR SCORE,0.5281090289608177,"PM,w, the score becomes negative infinity, making it impossible to reject the null hypothesis H0.
285"
MAXIMIN VARIANT OF LLR SCORE,0.5298126064735945,"A more general reason for this issue is that the watermark model PM,w used in the detection process
286"
MAXIMIN VARIANT OF LLR SCORE,0.5315161839863713,"may not exactly match the true distribution of the watermarked text. In practice, potential sources of
287"
MAXIMIN VARIANT OF LLR SCORE,0.5332197614991482,"discrepancy include editing (e.g., a text sampled from PM,w may undergo some degree of editing
288"
MAXIMIN VARIANT OF LLR SCORE,0.534923339011925,"before being watermark detection) and imperfect estimation of the generation process (e.g., due to
289"
MAXIMIN VARIANT OF LLR SCORE,0.5366269165247018,"lack of knowledge of the exact prompt and temperature used during generation).
290"
MAXIMIN VARIANT OF LLR SCORE,0.5383304940374787,"To address this problem, we consider a perturbed generation distribution. Instead of the original
291"
MAXIMIN VARIANT OF LLR SCORE,0.5400340715502555,"hypothesis H1, where x1:n follows the watermark distribution PM,w, we now assume that x1:n
292"
MAXIMIN VARIANT OF LLR SCORE,0.5417376490630323,"follows a distribution P ′
M,w, which is similar to but not identical to PM,w. Specifically, during the
293"
MAXIMIN VARIANT OF LLR SCORE,0.5434412265758092,"generation of each token, the total variation (TV) distance between Q′
i and Qi is bounded by d.
294"
MAXIMIN VARIANT OF LLR SCORE,0.545144804088586,"The corresponding new optimization problem is
295"
MAXIMIN VARIANT OF LLR SCORE,0.5468483816013628,"max
Si
min
Q′
i∈∆Σ,T V (Q′
i,Qi)≤d
⟨Q′
i, Si⟩,
s.t. ⟨Pi, exp(Si)⟩≤1."
MAXIMIN VARIANT OF LLR SCORE,0.5485519591141397,"Intuitively, the optimal solution for Q′
i in the inner optimization decreases Q′
i(x) when Si(x) is large
296"
MAXIMIN VARIANT OF LLR SCORE,0.5502555366269165,"and increases Q′
i(x) when Si(x) is small.
297"
MAXIMIN VARIANT OF LLR SCORE,0.5519591141396933,"The computation of the maximin solution can be done efficiently in eO(|Σ|) time and the specific
298"
MAXIMIN VARIANT OF LLR SCORE,0.5536626916524702,"algorithm is shown in Appendix C.
299"
MAXIMIN VARIANT OF LLR SCORE,0.555366269165247,(a) Text summarization
MAXIMIN VARIANT OF LLR SCORE,0.5570698466780238,"No Watermark
δ-reweight"
MAXIMIN VARIANT OF LLR SCORE,0.5587734241908007,γ-reweight
MAXIMIN VARIANT OF LLR SCORE,0.5604770017035775,Soft(δ=0.0)
MAXIMIN VARIANT OF LLR SCORE,0.5621805792163543,Soft(δ=1.0)
MAXIMIN VARIANT OF LLR SCORE,0.5638841567291312,Soft(δ=2.0) 2 4 6 8 10
MAXIMIN VARIANT OF LLR SCORE,0.565587734241908,Perplexity
MAXIMIN VARIANT OF LLR SCORE,0.5672913117546848,(b) Machine translation
MAXIMIN VARIANT OF LLR SCORE,0.5689948892674617,"No Watermark
δ-reweight"
MAXIMIN VARIANT OF LLR SCORE,0.5706984667802385,γ-reweight
MAXIMIN VARIANT OF LLR SCORE,0.5724020442930153,Soft(δ=0.0)
MAXIMIN VARIANT OF LLR SCORE,0.5741056218057922,Soft(δ=1.0)
MAXIMIN VARIANT OF LLR SCORE,0.575809199318569,Soft(δ=2.0) 19 20 21 22 23 BLEU
MAXIMIN VARIANT OF LLR SCORE,0.5775127768313458,Figure 3: Distribution of perplexity of output for TS and BLEU score for MT.
MAXIMIN VARIANT OF LLR SCORE,0.5792163543441227,"It is important to note that the maximin variant of the LLR score is more robust than the standard
300"
MAXIMIN VARIANT OF LLR SCORE,0.5809199318568995,"LLR score, as it yields higher scores when the text has undergone some degree of editing. However,
301"
MAXIMIN VARIANT OF LLR SCORE,0.5826235093696763,"it is not specifically designed to defend against any attacks.
302"
MAXIMIN VARIANT OF LLR SCORE,0.5843270868824532,"A hyperparameter d ∈[0, 1] that represent the perturbation strength is introduced in the score.
303"
MAXIMIN VARIANT OF LLR SCORE,0.58603066439523,"Intuitively, if the text to be detected has undergone more editing and deviates further from the
304"
MAXIMIN VARIANT OF LLR SCORE,0.5877342419080068,"distribution PM,w, d should be larger. In practice, we recommend using grid search to select the best
305"
MAXIMIN VARIANT OF LLR SCORE,0.5894378194207837,"value of d. Assuming there are A candidate values for d, corresponding to A different scores s(a)
i
306"
MAXIMIN VARIANT OF LLR SCORE,0.5911413969335605,"(1 ≤a ≤A), we can modify Theorem 8 as follows.
307"
MAXIMIN VARIANT OF LLR SCORE,0.5928449744463373,"Theorem 9. Under the same conditions as Theorem 8, but with multiple scores s(a)
i
, we have
308 P "
MAXIMIN VARIANT OF LLR SCORE,0.5945485519591142,"max
1≤a≤A n
X"
MAXIMIN VARIANT OF LLR SCORE,0.596252129471891,"i=1
s(a)
i ! ≥t !"
MAXIMIN VARIANT OF LLR SCORE,0.5979557069846678,≤Ae−t.
MAXIMIN VARIANT OF LLR SCORE,0.5996592844974447,"Thus, when using grid search, the final threshold should be adjusted as ˆS = −log(α) + log(A). This
309"
MAXIMIN VARIANT OF LLR SCORE,0.6013628620102215,"ensures that the upper bound of the type I error is still α.
310"
EXPERIMENTS,0.6030664395229983,"6
Experiments
311"
EXPERIMENTS,0.6047700170357752,"We evaluate the performance of our Unbiased Watermarks on two important applications of seq2seq
312"
EXPERIMENTS,0.606473594548552,"models: text summarization (TS) and machine translation (MT). For the TS task, we use the BART-
313"
EXPERIMENTS,0.6081771720613288,"large model [37] and the CNN-DM [25] corpus as our training dataset. The MT task involves
314"
EXPERIMENTS,0.6098807495741057,"translating English to Romanian, for which we employ the Multilingual BART (MBart) [37] model
315"
EXPERIMENTS,0.6115843270868825,"on the WMT’14 En-Ro corpus. For further details on the experiment setup, please refer to Appendix E.
316"
EXPERIMENTS,0.6132879045996593,"Table 1: Performance of different watermarking methods on TS and MT. We use F1 scores of
BERTScore and scale BERTScore and ROUGE-1 with a factor of 100."
EXPERIMENTS,0.6149914821124361,"Text summarization
Machine translation
BERTScore ↑
ROUGE-1 ↑
Perplexity ↓
BERTScore ↑
BLEU ↑"
EXPERIMENTS,0.616695059625213,"No Watermark
32.70 ± 0.08
38.56 ± 0.09
5.024 ± 0.018
55.9 ± 0.3
21.8 ± 0.3
δ-reweight
32.71 ± 0.08
38.57 ± 0.09
5.022 ± 0.018
56.3 ± 0.3
21.7 ± 0.3
γ-reweight
32.69 ± 0.08
38.60 ± 0.09
5.019 ± 0.018
56.2 ± 0.3
21.8 ± 0.3
Soft(δ=0.0)
32.70 ± 0.08
38.56 ± 0.09
5.024 ± 0.018
55.9 ± 0.3
21.8 ± 0.3
Soft(δ=1.0)
32.35 ± 0.08
38.20 ± 0.09
5.313 ± 0.018
55.1 ± 0.3
21.0 ± 0.3
Soft(δ=2.0)
31.21 ± 0.08
37.17 ± 0.08
6.253 ± 0.022
53.8 ± 0.3
19.5 ± 0.3"
EXPERIMENTS,0.6183986371379898,"Our primary focus is to compare the performance of our proposed unbiased watermarking methods
317"
EXPERIMENTS,0.6201022146507666,"including the δ-reweight and γ-reweight, with the soft-red-list method presented by Kirchenbauer
318"
EXPERIMENTS,0.6218057921635435,"et al. [32]. The strength of the watermark in the soft-red-list approach is controlled by a parameter δ.
319"
EXPERIMENTS,0.6235093696763203,"The quality of output post-watermarking is presented in Table 1. We observed that the output quality
320"
EXPERIMENTS,0.6252129471890971,"remains unaffected by our unbiased watermark methods, both for the δ-reweight and γ-reweight,
321"
EXPERIMENTS,0.626916524701874,"Table 3: Text sampled from OPT-6.7B, with and without watermarks. For ""No watermark” (NW),
the score is computed based on δ-reweight. When watermarks are included, the corresponding
reweighting function is used for computing score. The optimal perturbation strengths d obtained by
grid search are 0.9, 0.0, 0.0 for three outputs respectively."
EXPERIMENTS,0.6286201022146508,"Prompt What is a watermark? What’s the purpose of it?
score p-value2"
EXPERIMENTS,0.6303236797274276,"NW
Why don’t you want it on there? I’m confused..\nI think he meant to say logo,
since he wrote ”watermark”, so the first word must be a typo.\nYes! Exactly typo."
EXPERIMENTS,0.6320272572402045,"Sorry, English is not my native language.. Thanks for the explanation!"
EXPERIMENTS,0.6337308347529813,0.30 8.14
EXPERIMENTS,0.6354344122657581,"δ-RW
\nIt is supposed to be watermarking the pictures that you took with your phone i
think. So, so you can share your pictures and not take credit for them.
75.9 1.2e−32"
EXPERIMENTS,0.637137989778535,"γ-RW
\nA watermark is a small image or logo (often in square pixels) that is placed
over the larger, original image. It serves primarily to distinguish copyright or
ownership of large images (such as banners and logos) and, on rare occasion, to
identify small images (such as thumbnail images for blog posts and pictures)."
EXPERIMENTS,0.6388415672913118,32.9 5.7e−14
EXPERIMENTS,0.6405451448040886,"irrespective of the task and metric. Conversely, the soft-red-list method, when δ = 0, does not
322"
EXPERIMENTS,0.6422487223168655,"introduce any watermark and hence does not affect output quality. However, for δ > 0, it significantly
323"
EXPERIMENTS,0.6439522998296422,"deteriorate the quality of output.
324"
EXPERIMENTS,0.645655877342419,"Figure 3 provides a more intuitive depiction of the score distributions. It is evident that our unbiased
325"
EXPERIMENTS,0.6473594548551959,"watermark methods not only ensure that the mean performance remains unaffected but also that the
326"
EXPERIMENTS,0.6490630323679727,"performance distribution is stable. Conversely, the soft-red-list method shows a notable performance
327"
EXPERIMENTS,0.6507666098807495,"decrease.
328"
EXPERIMENTS,0.6524701873935264,"Table 2: Mean and variance of score per token for
different reweighting methods and different tasks."
EXPERIMENTS,0.6541737649063032,"Text summarization
Machine translation"
EXPERIMENTS,0.65587734241908,"δ-RW
0.8784 ± 1.4354
0.4192 ± 1.1361
γ-RW
0.2207 ± 0.3678
0.1056 ± 0.2916"
EXPERIMENTS,0.6575809199318569,"In terms of watermark detection, we com-
329"
EXPERIMENTS,0.6592844974446337,"pute score associated with each token. The
330"
EXPERIMENTS,0.6609880749574105,"mean and variance of score per token for
331"
EXPERIMENTS,0.6626916524701874,"TS and MT are presented in Table 2. As
332"
EXPERIMENTS,0.6643952299829642,"a heuristic, if the sum of the scores for all
333"
EXPERIMENTS,0.666098807495741,"tokens in a sentence reaches 10, a p-value of
334"
EXPERIMENTS,0.6678023850085179,"less than 0.0005 is ensured. If the sum score
335"
EXPERIMENTS,0.6695059625212947,"hits 20, the p-value must be less than 3e−8.
336"
EXPERIMENTS,0.6712095400340715,"Additionally, we provide an example of watermarking applied to a completion task in Table 3. It
337"
EXPERIMENTS,0.6729131175468483,"visually demonstrates the score distribution across tokens: positive scores are represented in green,
338"
EXPERIMENTS,0.6746166950596252,"and negative ones in red. The intensity of the color corresponds to the magnitude of the score, with
339"
EXPERIMENTS,0.676320272572402,"darker shades representing larger absolute values.
340"
RELATED WORK,0.6780238500851788,"7
Related work
341"
RELATED WORK,0.6797274275979557,"The idea of watermarking text has been widely explored by many researchers [11, 31, 44, 45, 4, 28,
342"
RELATED WORK,0.6814310051107325,"49, 43], even before the advent of large language models. Several techniques involve editing existing
343"
RELATED WORK,0.6831345826235093,"text to add a watermark, such as changing synonyms [54, 57, 9, 59, 66] or visually indistinguishable
344"
RELATED WORK,0.6848381601362862,"words [46], altering sentence structures [56, 55, 38], and employing neural networks [22, 23, 67].
345"
RELATED WORK,0.686541737649063,"Recent advancements in generative models have opened new possibilities for directly generating
346"
RELATED WORK,0.6882453151618398,"watermarked results. Two relevant works in this domain are by Kirchenbauer et al. [32] and Aaronson
347"
RELATED WORK,0.6899488926746167,"[1]. Due to space constraints, we moved the in-depth analysis and other related work to Section B.
348"
CONCLUSION,0.6916524701873935,"8
Conclusion
349"
CONCLUSION,0.6933560477001703,"Overall, this paper provides a novel framework of watermarking for language models, demonstrating
350"
CONCLUSION,0.6950596252129472,"that it is possible to use watermark to protect intellectual property and monitor potential misuse
351"
CONCLUSION,0.696763202725724,"without compromising the quality of the generated text. This research serves as a valuable foundation
352"
CONCLUSION,0.6984667802385008,"for future work in the field of watermarking for large language models.
353"
CONCLUSION,0.7001703577512777,"2This is an upper bound computed based on Theorem 9. The upper bound could be larger than 1, but this
does not necessarily imply that the p-value exceeds 1."
REFERENCES,0.7018739352640545,"References
354"
REFERENCES,0.7035775127768313,"[1] Scott Aaronson.
My ai safety lecture for ut effective altruism.
November 2022.
URL https://
355"
REFERENCES,0.7052810902896082,"scottaaronson.blog/?p=6823.
356"
REFERENCES,0.706984667802385,"[2] Sahar Abdelnabi and Mario Fritz. Adversarial watermarking transformer: Towards tracing text provenance
357"
REFERENCES,0.7086882453151618,"with data hiding. In 2021 IEEE Symposium on Security and Privacy (SP), pages 121–140. IEEE, 2021.
358"
REFERENCES,0.7103918228279387,"[3] Yossi Adi, Carsten Baum, Moustapha Cisse, Benny Pinkas, and Joseph Keshet. Turning your weakness
359"
REFERENCES,0.7120954003407155,"into a strength: Watermarking deep neural networks by backdooring. In 27th USENIX Security Symposium,
360"
REFERENCES,0.7137989778534923,"pages 1615–1631, 2018.
361"
REFERENCES,0.7155025553662692,"[4] Mikhail J Atallah, Victor Raskin, Michael Crogan, Christian Hempelmann, Florian Kerschbaum, Dina
362"
REFERENCES,0.717206132879046,"Mohamed, and Sanket Naik. Natural language watermarking: Design, analysis, and a proof-of-concept
363"
REFERENCES,0.7189097103918228,"implementation. In Information Hiding: 4th International Workshop, IH 2001 Pittsburgh, PA, USA, April
364"
REFERENCES,0.7206132879045997,"25–27, 2001 Proceedings 4, pages 185–200. Springer, 2001.
365"
REFERENCES,0.7223168654173765,"[5] Loïc Barrault, Ondˇrej Bojar, Marta R. Costa-jussà, Christian Federmann, Mark Fishel, Yvette Graham,
366"
REFERENCES,0.7240204429301533,"Barry Haddow, Matthias Huck, Philipp Koehn, Shervin Malmasi, Christof Monz, Mathias Müller, Santanu
367"
REFERENCES,0.7257240204429302,"Pal, Matt Post, and Marcos Zampieri. Findings of the 2019 conference on machine translation (WMT19).
368"
REFERENCES,0.727427597955707,"In Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1),
369"
REFERENCES,0.7291311754684838,"pages 1–61, Florence, Italy, August 2019. Association for Computational Linguistics. doi: 10.18653/v1/
370"
REFERENCES,0.7308347529812607,"W19-5301.
371"
REFERENCES,0.7325383304940375,"[6] Franziska Boenisch. A systematic review on model watermarking for neural networks. Frontiers in big
372"
REFERENCES,0.7342419080068143,"Data, 4:729663, 2021.
373"
REFERENCES,0.7359454855195912,"[7] Ondˇrej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Shujian Huang,
374"
REFERENCES,0.737649063032368,"Matthias Huck, Philipp Koehn, Qun Liu, Varvara Logacheva, Christof Monz, Matteo Negri, Matt Post,
375"
REFERENCES,0.7393526405451448,"Raphael Rubino, Lucia Specia, and Marco Turchi. Findings of the 2017 conference on machine translation
376"
REFERENCES,0.7410562180579217,"(WMT17). In Proceedings of the Second Conference on Machine Translation, pages 169–214, Copenhagen,
377"
REFERENCES,0.7427597955706985,"Denmark, September 2017. Association for Computational Linguistics. doi: 10.18653/v1/W17-4717.
378"
REFERENCES,0.7444633730834753,"[8] Nicholas Boucher, Ilia Shumailov, Ross Anderson, and Nicolas Papernot. Bad characters: Imperceptible
379"
REFERENCES,0.7461669505962522,"nlp attacks. In 2022 IEEE Symposium on Security and Privacy (SP), pages 1987–2004. IEEE, 2022.
380"
REFERENCES,0.747870528109029,"[9] Yuei-Lin Chiang, Lu-Ping Chang, Wen-Tai Hsieh, and Wen-Chih Chen. Natural language watermarking
381"
REFERENCES,0.7495741056218058,"using semantic substitution for chinese text. In Digital Watermarking: Second International Workshop,
382"
REFERENCES,0.7512776831345827,"IWDW 2003, Seoul, Korea, October 20-22, 2003. Revised Papers 2, pages 129–140. Springer, 2004.
383"
REFERENCES,0.7529812606473595,"[10] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi
384"
REFERENCES,0.7546848381601363,"Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. arXiv
385"
REFERENCES,0.7563884156729132,"preprint arXiv:2210.11416, 2022.
386"
REFERENCES,0.75809199318569,"[11] Ingemar Cox, Matthew Miller, Jeffrey Bloom, Jessica Fridrich, and Ton Kalker. Digital watermarking and
387"
REFERENCES,0.7597955706984668,"steganography. Morgan kaufmann, 2007.
388"
REFERENCES,0.7614991482112436,"[12] Evan Crothers, Nathalie Japkowicz, and Herna Viktor. Machine generated text: A comprehensive survey
389"
REFERENCES,0.7632027257240205,"of threat models and detection methods. arXiv preprint arXiv:2210.07321, 2022.
390"
REFERENCES,0.7649063032367973,"[13] Falcon Z Dai and Zheng Cai.
Towards near-imperceptible steganographic text.
arXiv preprint
391"
REFERENCES,0.7666098807495741,"arXiv:1907.06679, 2019.
392"
REFERENCES,0.768313458262351,"[14] Luc Devroye. Non-Uniform Random Variate Generation. Springer New York, 1986.
393"
REFERENCES,0.7700170357751278,"[15] Tina Fang, Martin Jaggi, and Katerina Argyraki. Generating steganographic text with lstms. arXiv preprint
394"
REFERENCES,0.7717206132879046,"arXiv:1705.10742, 2017.
395"
REFERENCES,0.7734241908006815,"[16] Evgeniy Gabrilovich and Alex Gontmakher. The homograph attack. Communications of the ACM, 45(2):
396"
REFERENCES,0.7751277683134583,"128, 2002.
397"
REFERENCES,0.7768313458262351,"[17] Margherita Gambini, Tiziano Fagni, Fabrizio Falchi, and Maurizio Tesconi. On pushing deepfake tweet
398"
REFERENCES,0.778534923339012,"detection capabilities to the limits. In 14th ACM Web Science Conference 2022, pages 154–163, 2022.
399"
REFERENCES,0.7802385008517888,"[18] Riley Goodside. There are adversarial attacks for that proposal as well — in particular, generating
400"
REFERENCES,0.7819420783645656,"with emojis after words and then removing them before submitting defeats it.,. January 2023. URL
401"
REFERENCES,0.7836456558773425,"https://twitter.com/goodside/status/1610682909647671306.
402"
REFERENCES,0.7853492333901193,"[19] Google. Palm-2-llm. https://blog.google/technology/ai/google-palm-2-ai-large-language-model/, 2023.
403"
REFERENCES,0.787052810902896,"[20] Chenxi Gu, Chengsong Huang, Xiaoqing Zheng, Kai-Wei Chang, and Cho-Jui Hsieh. Watermarking
404"
REFERENCES,0.7887563884156729,"pre-trained language models with backdooring. arXiv preprint arXiv:2210.07543, 2022.
405"
REFERENCES,0.7904599659284497,"[21] Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. Badnets: Identifying vulnerabilities in the machine
406"
REFERENCES,0.7921635434412265,"learning model supply chain. arXiv preprint arXiv:1708.06733, 2017.
407"
REFERENCES,0.7938671209540034,"[22] Xuanli He, Qiongkai Xu, Lingjuan Lyu, Fangzhao Wu, and Chenguang Wang. Protecting intellectual
408"
REFERENCES,0.7955706984667802,"property of language generation apis with lexical watermark. In Proceedings of the AAAI Conference on
409"
REFERENCES,0.797274275979557,"Artificial Intelligence, volume 36, pages 10758–10766, 2022.
410"
REFERENCES,0.7989778534923339,"[23] Xuanli He, Qiongkai Xu, Yi Zeng, Lingjuan Lyu, Fangzhao Wu, Jiwei Li, and Ruoxi Jia. Cater: Intellectual
411"
REFERENCES,0.8006814310051107,"property protection on text generation apis via conditional watermarks. arXiv preprint arXiv:2209.08773,
412"
REFERENCES,0.8023850085178875,"2022.
413"
REFERENCES,0.8040885860306644,"[24] James N Helfrich and Rick Neff. Dual canonicalization: An answer to the homograph attack. In 2012
414"
REFERENCES,0.8057921635434412,"eCrime Researchers Summit, pages 1–10. IEEE, 2012.
415"
REFERENCES,0.807495741056218,"[25] Karl Moritz Hermann, Tomás Kociský, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman,
416"
REFERENCES,0.8091993185689949,"and Phil Blunsom. Teaching machines to read and comprehend. In Corinna Cortes, Neil D. Lawrence,
417"
REFERENCES,0.8109028960817717,"Daniel D. Lee, Masashi Sugiyama, and Roman Garnett, editors, Advances in Neural Information Processing
418"
REFERENCES,0.8126064735945485,"Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015,
419"
REFERENCES,0.8143100511073254,"Montreal, Quebec, Canada, pages 1693–1701, 2015.
420"
REFERENCES,0.8160136286201022,"[26] Daphne Ippolito, Daniel Duckworth, Chris Callison-Burch, and Douglas Eck. Automatic detection of
421"
REFERENCES,0.817717206132879,"generated text is easiest when humans are fooled. arXiv preprint arXiv:1911.00650, 2019.
422"
REFERENCES,0.8194207836456558,"[27] Srinivasan Iyer, Xi Victoria Lin, Ramakanth Pasunuru, Todor Mihaylov, Dániel Simig, Ping Yu, Kurt
423"
REFERENCES,0.8211243611584327,"Shuster, Tianlu Wang, Qing Liu, Punit Singh Koura, et al. Opt-iml: Scaling language model instruction
424"
REFERENCES,0.8228279386712095,"meta learning through the lens of generalization. arXiv preprint arXiv:2212.12017, 2022.
425"
REFERENCES,0.8245315161839863,"[28] Zunera Jalil and Anwar M Mirza. A review of digital watermarking techniques for text documents. In
426"
REFERENCES,0.8262350936967632,"2009 International Conference on Information and Multimedia Technology, pages 230–234. IEEE, 2009.
427"
REFERENCES,0.82793867120954,"[29] Ganesh Jawahar, Muhammad Abdul-Mageed, and Laks VS Lakshmanan. Automatic detection of machine
428"
REFERENCES,0.8296422487223168,"generated text: A critical survey. arXiv preprint arXiv:2011.01314, 2020.
429"
REFERENCES,0.8313458262350937,"[30] Hengrui Jia, Christopher A Choquette-Choo, Varun Chandrasekaran, and Nicolas Papernot. Entangled
430"
REFERENCES,0.8330494037478705,"watermarks as a defense against model extraction. In USENIX Security Symposium, pages 1937–1954,
431"
REFERENCES,0.8347529812606473,"2021.
432"
REFERENCES,0.8364565587734242,"[31] Nurul Shamimi Kamaruddin, Amirrudin Kamsin, Lip Yee Por, and Hameedur Rahman. A review of text
433"
REFERENCES,0.838160136286201,"watermarking: theory, methods, and applications. IEEE Access, 6:8011–8028, 2018.
434"
REFERENCES,0.8398637137989778,"[32] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein. A watermark
435"
REFERENCES,0.8415672913117547,"for large language models. arXiv preprint arXiv:2301.10226, 2023.
436"
REFERENCES,0.8432708688245315,"[33] Kalpesh Krishna, Yixiao Song, Marzena Karpinska, John Wieting, and Mohit Iyyer. Paraphrasing evades
437"
REFERENCES,0.8449744463373083,"detectors of ai-generated text, but retrieval is an effective defense. arXiv preprint arXiv:2303.13408, 2023.
438"
REFERENCES,0.8466780238500852,"[34] Zheng Li, Chengyu Hu, Yang Zhang, and Shanqing Guo. How to prove your model belongs to you: A
439"
REFERENCES,0.848381601362862,"blind-watermark based framework to protect intellectual property of dnn. In Proceedings of the 35th
440"
REFERENCES,0.8500851788756388,"Annual Computer Security Applications Conference, pages 126–137, 2019.
441"
REFERENCES,0.8517887563884157,"[35] Chin-Yew Lin. Rouge: A package for automatic evaluation of summaries. In Text summarization branches
442"
REFERENCES,0.8534923339011925,"out, pages 74–81, 2004.
443"
REFERENCES,0.8551959114139693,"[36] Yang Liu and Mirella Lapata. Text summarization with pretrained encoders. In Proceedings of the
444"
REFERENCES,0.8568994889267462,"2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint
445"
REFERENCES,0.858603066439523,"Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3730–3740, Hong Kong, China,
446"
REFERENCES,0.8603066439522998,"November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1387.
447"
REFERENCES,0.8620102214650767,"[37] Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, and
448"
REFERENCES,0.8637137989778535,"Luke Zettlemoyer. Multilingual denoising pre-training for neural machine translation. Transactions of the
449"
REFERENCES,0.8654173764906303,"Association for Computational Linguistics, 8:726–742, 2020.
450"
REFERENCES,0.8671209540034072,"[38] Hasan Mesut Meral, Bülent Sankur, A Sumru Özsoy, Tunga Güngör, and Emre Sevinç. Natural language
451"
REFERENCES,0.868824531516184,"watermarking via morphosyntactic alterations. Computer Speech & Language, 23(1):107–125, 2009.
452"
REFERENCES,0.8705281090289608,"[39] OpenAI. Chatgpt. https://openai.com/blog/chatgpt, 2023a.
453"
REFERENCES,0.8722316865417377,"[40] OpenAI. Gpt-4 technical report. arXiv, 2023b.
454"
REFERENCES,0.8739352640545145,"[41] Luca Pajola and Mauro Conti. Fall of giants: How popular text-based mlaas fall against a simple evasion
455"
REFERENCES,0.8756388415672913,"attack. In 2021 IEEE European Symposium on Security and Privacy (EuroS&P), pages 198–211. IEEE,
456"
REFERENCES,0.8773424190800682,"2021.
457"
REFERENCES,0.879045996592845,"[42] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation
458"
REFERENCES,0.8807495741056218,"of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational
459"
REFERENCES,0.8824531516183987,"Linguistics, pages 311–318, 2002.
460"
REFERENCES,0.8841567291311755,"[43] Fabien AP Petitcolas, Ross J Anderson, and Markus G Kuhn. Information hiding-a survey. Proceedings of
461"
REFERENCES,0.8858603066439523,"the IEEE, 87(7):1062–1078, 1999.
462"
REFERENCES,0.8875638841567292,"[44] Christine I Podilchuk and Edward J Delp. Digital watermarking: algorithms and applications. IEEE signal
463"
REFERENCES,0.889267461669506,"processing Magazine, 18(4):33–46, 2001.
464"
REFERENCES,0.8909710391822828,"[45] Vidyasagar M Potdar, Song Han, and Elizabeth Chang. A survey of digital image watermarking techniques.
465"
REFERENCES,0.8926746166950597,"In INDIN’05. 2005 3rd IEEE International Conference on Industrial Informatics, 2005., pages 709–716.
466"
REFERENCES,0.8943781942078365,"IEEE, 2005.
467"
REFERENCES,0.8960817717206133,"[46] Stefano Giovanni Rizzo, Flavio Bertini, and Danilo Montesi. Fine-grain watermarking for intellectual
468"
REFERENCES,0.8977853492333902,"property protection. EURASIP Journal on Information Security, 2019:1–20, 2019.
469"
REFERENCES,0.899488926746167,"[47] Vinu Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian, Wenxiao Wang, and Soheil Feizi. Can
470"
REFERENCES,0.9011925042589438,"ai-generated text be reliably detected? arXiv preprint arXiv:2303.11156, 2023.
471"
REFERENCES,0.9028960817717206,"[48] M Hassan Shirali-Shahreza and Mohammad Shirali-Shahreza. A new synonym text steganography. In
472"
REFERENCES,0.9045996592844975,"2008 international conference on intelligent information hiding and multimedia signal processing, pages
473"
REFERENCES,0.9063032367972743,"1524–1526. IEEE, 2008.
474"
REFERENCES,0.9080068143100511,"[49] Katzenbeisser Stefan, A Petitcolas Fabien, et al. Information hiding techniques for steganography and
475"
REFERENCES,0.909710391822828,"digital watermarking, 2000.
476"
REFERENCES,0.9114139693356048,"[50] Yuchen Sun, Tianpeng Liu, Panhe Hu, Qing Liao, Shouling Ji, Nenghai Yu, Deke Guo, and Li Liu. Deep
477"
REFERENCES,0.9131175468483816,"intellectual property: A survey. arXiv preprint arXiv:2304.14613, 2023.
478"
REFERENCES,0.9148211243611585,"[51] Reuben Tan, Bryan A Plummer, and Kate Saenko. Detecting cross-modal inconsistency to defend against
479"
REFERENCES,0.9165247018739353,"neural fake news. arXiv preprint arXiv:2009.07698, 2020.
480"
REFERENCES,0.9182282793867121,"[52] Ruixiang Tang, Yu-Neng Chuang, and Xia Hu. The science of detecting llm-generated texts. arXiv preprint
481"
REFERENCES,0.919931856899489,"arXiv:2303.07205, 2023.
482"
REFERENCES,0.9216354344122658,"[53] Yi Tay, Dara Bahri, Che Zheng, Clifford Brunk, Donald Metzler, and Andrew Tomkins. Reverse engineering
483"
REFERENCES,0.9233390119250426,"configurations of neural text generation models. arXiv preprint arXiv:2004.06201, 2020.
484"
REFERENCES,0.9250425894378195,"[54] Mercan Topkara, Cuneyt M Taskiran, and Edward J Delp III. Natural language watermarking. In Security,
485"
REFERENCES,0.9267461669505963,"Steganography, and Watermarking of Multimedia Contents VII, volume 5681, pages 441–452. SPIE, 2005.
486"
REFERENCES,0.9284497444633731,"[55] Mercan Topkara, Giuseppe Riccardi, Dilek Hakkani-Tür, and Mikhail J Atallah.
Natural language
487"
REFERENCES,0.9301533219761499,"watermarking: Challenges in building a practical system. In Security, Steganography, and Watermarking of
488"
REFERENCES,0.9318568994889267,"Multimedia Contents VIII, volume 6072, pages 106–117. SPIE, 2006.
489"
REFERENCES,0.9335604770017035,"[56] Mercan Topkara, Umut Topkara, and Mikhail J Atallah. Words are not enough: sentence level natural
490"
REFERENCES,0.9352640545144804,"language watermarking. In Proceedings of the 4th ACM international workshop on Contents protection
491"
REFERENCES,0.9369676320272572,"and security, pages 37–46, 2006.
492"
REFERENCES,0.938671209540034,"[57] Umut Topkara, Mercan Topkara, and Mikhail J Atallah. The hiding virtues of ambiguity: quantifiably
493"
REFERENCES,0.9403747870528109,"resilient watermarking of natural language text through synonym substitutions. In Proceedings of the 8th
494"
REFERENCES,0.9420783645655877,"workshop on Multimedia and security, pages 164–174, 2006.
495"
REFERENCES,0.9437819420783645,"[58] Honai Ueoka, Yugo Murawaki, and Sadao Kurohashi. Frustratingly easy edit-based linguistic steganography
496"
REFERENCES,0.9454855195911414,"with a masked language model. arXiv preprint arXiv:2104.09833, 2021.
497"
REFERENCES,0.9471890971039182,"[59] Ashish Venugopal, Jakob Uszkoreit, David Talbot, Franz Josef Och, and Juri Ganitkevitch. Watermarking
498"
REFERENCES,0.948892674616695,"the outputs of structured prediction with an application in statistical machine translation. In Proceedings of
499"
REFERENCES,0.9505962521294719,"the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1363–1372, 2011.
500"
REFERENCES,0.9522998296422487,"[60] Hong Wang, Xuan Luo, Weizhi Wang, and Xifeng Yan. Bot or human? detecting chatgpt imposters with a
501"
REFERENCES,0.9540034071550255,"single question. arXiv preprint arXiv:2305.06424, 2023.
502"
REFERENCES,0.9557069846678024,"[61] Alex Wilson and Andrew D Ker. Avoiding detection on twitter: embedding strategies for linguistic
503"
REFERENCES,0.9574105621805792,"steganography. Society of Photo-optical Instrumentation Engineers, 2016.
504"
REFERENCES,0.959114139693356,"[62] Alex Wilson, Phil Blunsom, and Andrew D Ker. Linguistic steganography on twitter: hierarchical language
505"
REFERENCES,0.9608177172061328,"modeling with manual interaction. In Media Watermarking, Security, and Forensics 2014, volume 9028,
506"
REFERENCES,0.9625212947189097,"pages 9–25. SPIE, 2014.
507"
REFERENCES,0.9642248722316865,"[63] Alex Wilson, Phil Blunsom, and Andrew Ker. Detection of steganographic techniques on twitter. In
508"
REFERENCES,0.9659284497444633,"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages
509"
REFERENCES,0.9676320272572402,"2564–2569, 2015.
510"
REFERENCES,0.969335604770017,"[64] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric
511"
REFERENCES,0.9710391822827938,"Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. Huggingface’s transformers: State-of-the-art
512"
REFERENCES,0.9727427597955707,"natural language processing. arXiv preprint arXiv:1910.03771, 2019.
513"
REFERENCES,0.9744463373083475,"[65] Max Wolff and Stuart Wolff. Attacking neural text detectors. arXiv preprint arXiv:2002.11768, 2020.
514"
REFERENCES,0.9761499148211243,"[66] Xi Yang, Jie Zhang, Kejiang Chen, Weiming Zhang, Zehua Ma, Feng Wang, and Nenghai Yu. Tracing text
515"
REFERENCES,0.9778534923339012,"provenance via context-aware lexical substitution. In Proceedings of the AAAI Conference on Artificial
516"
REFERENCES,0.979557069846678,"Intelligence, volume 36, pages 11613–11621, 2022.
517"
REFERENCES,0.9812606473594548,"[67] KiYoon Yoo, Wonhyuk Ahn, Jiho Jang, and Nojun Kwak. Robust natural language watermarking through
518"
REFERENCES,0.9829642248722317,"invariant features. arXiv preprint arXiv:2305.01904, 2023.
519"
REFERENCES,0.9846678023850085,"[68] Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, and Yejin
520"
REFERENCES,0.9863713798977853,"Choi. Defending against neural fake news. Advances in neural information processing systems, 32, 2019.
521"
REFERENCES,0.9880749574105622,"[69] Jialong Zhang, Zhongshu Gu, Jiyong Jang, Hui Wu, Marc Ph Stoecklin, Heqing Huang, and Ian Molloy.
522"
REFERENCES,0.989778534923339,"Protecting intellectual property of deep neural networks with watermarking. In Proceedings of the 2018 on
523"
REFERENCES,0.9914821124361158,"Asia Conference on Computer and Communications Security, pages 159–172, 2018.
524"
REFERENCES,0.9931856899488927,"[70] Xuandong Zhao, Yu-Xiang Wang, and Lei Li. Protecting language generation models via invisible
525"
REFERENCES,0.9948892674616695,"watermarking. arXiv preprint arXiv:2302.03162, 2023.
526"
REFERENCES,0.9965928449744463,"[71] Zachary M Ziegler, Yuntian Deng, and Alexander M Rush. Neural linguistic steganography. arXiv preprint
527"
REFERENCES,0.9982964224872232,"arXiv:1909.01496, 2019.
528"
