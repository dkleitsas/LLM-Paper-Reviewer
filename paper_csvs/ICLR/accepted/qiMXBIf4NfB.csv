Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.000946073793755913,"Self-training, a semi-supervised learning algorithm, leverages a large amount of
unlabeled data to improve learning when the labeled data are limited. Despite em-
pirical successes, its theoretical characterization remains elusive. To the best of
our knowledge, this work establishes the Ô¨Årst theoretical analysis for the known
iterative self-training paradigm and proves the beneÔ¨Åts of unlabeled data in both
training convergence and generalization ability. To make our theoretical analysis
feasible, we focus on the case of one-hidden-layer neural networks. However,
theoretical understanding of iterative self-training is non-trivial even for a shal-
low neural network. One of the key challenges is that existing neural network
landscape analysis built upon supervised learning no longer holds in the (semi-
supervised) self-training paradigm. We address this challenge and prove that itera-
tive self-training converges linearly with both convergence rate and generalization
accuracy improved in the order of 1/
‚àö"
ABSTRACT,0.001892147587511826,"M, where M is the number of unlabeled
samples. Experiments from shallow neural networks to deep neural networks are
also provided to justify the correctness of our established theoretical insights on
self-training."
INTRODUCTION,0.002838221381267739,"1
INTRODUCTION"
INTRODUCTION,0.003784295175023652,"Self-training (Scudder, 1965; Yarowsky, 1995; Lee et al., 2013; Han et al., 2019), one of the most
powerful semi-supervised learning (SemiSL) algorithms, augments a limited number of labeled data
with unlabeled data so as to achieve improved generalization performance on test data, compared
with the model trained by supervised learning using the labeled data only. Self-training has shown
empirical success in diversiÔ¨Åed applications such as few-shot image classiÔ¨Åcation (Su et al., 2020;
Xie et al., 2020; Chen et al., 2020a; Yalniz et al., 2019; Zoph et al., 2020), objective detection
(Rosenberg et al., 2005), robustness-aware model training against adversarial attacks (Carmon et al.,
2019), continual lifelong learning (Lee et al., 2019), and natural language processing (He et al.,
2019; Kahn et al., 2020). The terminology ‚Äúself-training‚Äù has been used to describe various SemiSL"
INTRODUCTION,0.004730368968779565,Published as a conference paper at ICLR 2022
INTRODUCTION,0.005676442762535478,"algorithms in the literature, while this paper is centered on the commonly-used iterative self-training
method in particular. In this setup, an initial teacher model (learned from the labeled data) is applied
to the unlabeled data to generate pseudo labels. One then trains a student model by minimizing the
weighted empirical risk of both the labeled and unlabeled data. The student model is then used as
the new teacher to update the pseudo labels of the unlabeled data. This process is repeated multiple
times to improve the eventual student model. We refer readers to Section 2 for algorithmic details."
INTRODUCTION,0.006622516556291391,"Despite the empirical achievement of self-training methods with neural networks, the theoretical
justiÔ¨Åcation of such success is very limited, even in the Ô¨Åeld of SemiSL. The majority of the theo-
retical results on general SemiSL are limited to linear networks (Chen et al., 2020b; Raghunathan
et al., 2020; Oymak & Gulcu, 2020; Oneto et al., 2011). The authors in (Balcan & Blum, 2010)
show that unlabeled data can improve the generalization bound if the unlabeled data distribution and
target model are compatible. For instance, the unlabeled data need to be well-chosen such that the
target function for labeled data can separate the unlabeled data clusters, which, however, may not be
able to be veriÔ¨Åed ahead. Moreover, (Rigollet, 2007; Singh et al., 2008) proves that unlabeled data
can improve the convergence rate and generalization error under a similar clustering assumption,
where the data contains clusters that have homogeneous labels. A recent work by Wei et al. (2020)
analyzes SemiSL on nonlinear neural networks and proves that an inÔ¨Ånite number of unlabeled data
can improve the generalization compared with training with labeled data only. However, Wei et al.
(2020) considers single shot rather than iterative SemiSL, and the training problem aims to minimize
the consistency regularization rather than the risk function in the conventional self-training method
(Lee et al., 2013). Moreover, Wei et al. (2020) directly analyzes the global optimum of the noncon-
vex training problem without any discussion about how to achieve the global optimum. To the best
of our knowledge, there exists no analytical characterization of how the unlabeled data affect the
generalization of the learned model by iterative self-training on nonlinear neural networks."
K,0.007568590350047304,"100K
200K
300K
400K
500K
Number of unlabeled data 5.5 6 6.5 7"
K,0.008514664143803218,Test accuracy
K,0.00946073793755913,Improvement (%)
K,0.010406811731315043,"Figure 1:
The trend of test accuracy
improvement (%) on CIFAR-10 by self-
training on CIFAR-10 (labeled) with dif-
ferent amount of unlabeled data from 80
Million Tiny Images matches our theoret-
ical prediction."
K,0.011352885525070956,"Contributions. This paper provides the Ô¨Årst theoretical
study of iterative self-training on nonlinear neural net-
works. Focusing on one-hidden-layer neural networks,
this paper provides a quantitative analysis of the gen-
eralization performance of iterative self-training as a
function of the number of labeled and unlabeled sam-
ples. SpeciÔ¨Åcally, our contributions include"
K,0.01229895931882687,"1.
Quantitative justiÔ¨Åcation of generalization im-
provement by unlabeled data.
Assuming the exis-
tence of a ground-truth model with weights W ‚àóthat
maps the features to the corresponding labels, we prove
that the learned model via iterative self-training moves
closer to W ‚àóas the number M of unlabeled data in-
creases, indicating a better testing performance. Specif-
ically, we prove that the Frobenius distance to W ‚àó,
which is approximately linear in the generalization er-
ror, decreases in the order of 1/
‚àö"
K,0.013245033112582781,"M.
As an exam-
ple, Figure 1 shows that the proposed theoretical bound
matches the empirical self-training performance versus the number of unlabeled data for image clas-
siÔ¨Åcation; see details in Section 4.2."
K,0.014191106906338695,"2. Analytical justiÔ¨Åcation of iterative self-training over single shot alternative. We prove that
the student models returned by the iterative self-training method converges linearly to a model close
to W ‚àó, with the rate improvement in the order of 1/
‚àö M."
K,0.015137180700094607,"3. Sample complexity analysis of labeled and unlabeled data for learning a proper model.
We quantify the impact of labeled and unlabeled data on the generalization of the learned model.
In particular, we prove that the sample complexity of labeled data can be reduced compared with
supervised learning."
RELATED WORKS,0.01608325449385052,"1.1
RELATED WORKS"
RELATED WORKS,0.017029328287606435,"Semi-supervised learning. Besides self-training, many recent SemiSL algorithms exploit either
consistency regularization or entropy minimization. Consistency regularization is based on the as-"
RELATED WORKS,0.017975402081362345,Published as a conference paper at ICLR 2022
RELATED WORKS,0.01892147587511826,"sumption that the learned model will return same or similar output when the input is perturbed
(Laine & Aila, 2016; Bachman et al., 2014; Sajjadi et al., 2016; Tarvainen & Valpola, 2017; Reed
et al., 2015). (Grandvalet & Bengio, 2005) claims that the unlabeled data are more informative if the
pseudo labels of the unlabeled data have lower entropy. Therefore, a line of works (Grandvalet &
Bengio, 2005; Miyato et al., 2018) adds a regularization term that minimizes the entropy of the out-
puts of the unlabeled data. In addition, hybrid algorithms that unify both the above regularizations
have been developed like (Berthelot et al., 2019a;b; Sohn et al., 2020)."
RELATED WORKS,0.019867549668874173,"Domain adaptation. Domain adaptation exploits abundant data in the source domain to learn a
model for the target domain, where only limited training data are available (Liebelt & Schmid,
2010; Vazquez et al., 2013; Zhang et al., 2013; Long et al., 2015; Tzeng et al., 2014). Source and
target domain are related but different. Unsupervised domain adaptation (Ganin & Lempitsky, 2015;
Ganin et al., 2016; Gong et al., 2013; Bousmalis et al., 2016), where training data in target domain
are unlabeled, is similar to SemiSL, and self-training methods have been used for analysis (Zou
et al., 2018; Tang et al., 2012; French et al., 2018). However, self-training and unsupervised domain
adaptation are fundamentally different. The former learns a model for the domain where there is
limited labeled data, with the help of a large number of unlabeled data from a different domain. The
latter learns a model for the domain where the training data are unlabeled, with the help of sufÔ¨Åcient
labeled data from a different domain."
RELATED WORKS,0.020813623462630087,"Generalization analysis of supervised learning. In theory, the testing error is upper bounded by the
training error plus the generalization gap between training and testing. These two quantities are often
analyzed separately and cannot be proved to be small simultaneously for deep neural networks. For
example, neural tangent kernel (NTK) method (Jacot et al., 2018; Du et al., 2018; Lee et al., 2018)
shows the training error can be zero, and the Rademacher complexity in (Bartlett & Mendelson,
2002) bounds the generalization gap (Arora et al., 2019a). For one-hidden-layer neural networks
(Safran & Shamir, 2018), the testing error can be proved to be zero under mild conditions. One
common assumption is that the input data belongs to the Gaussian distribution (Zhong et al., 2017;
Ge et al., 2018; Kalai et al., 2008; Bakshi et al., 2019; Zhang et al., 2016; Brutzkus & Globerson,
2017; Li & Yuan, 2017; Soltanolkotabi et al., 2018). Another line of approaches (Brutzkus et al.,
2018; Li & Liang, 2018; Wang et al., 2019) consider linearly separable data."
RELATED WORKS,0.021759697256385997,"The rest of this paper is organized as follows. Section 2 introduces the problem formulation and
self-training algorithm. Major results are summarized in Section 3, and empirical evaluations are
presented in Section 4. Section 5 concludes the whole paper. All the proofs are in the Appendix."
RELATED WORKS,0.02270577105014191,"2
FORMALIZING SELF-TRAINING: NOTATION, FORMULATION, AND
ALGORITHM"
RELATED WORKS,0.023651844843897825,"Problem formulation.
Given N labeled data sampled from distribution Pl, denoted by D =
{xn, yn}N
n=1, and M unlabeled data drawn from distribution Pu, denoted by eD = {exm}M
m=1. The
aim is to Ô¨Ånd a neural network model g(W ), where W denotes the trainable weights, that minimizes
the testing error on data sampled from Pl."
RELATED WORKS,0.02459791863765374,Table 1: Iterative Self-Training
RELATED WORKS,0.02554399243140965,"(S1) Initialize iteration ‚Ñì= 0 and obtain a model W (‚Ñì) as the teacher using labeled data D
only;
(S2) Use the teacher model to obtain pseudo labels eym of unlabeled data in eD;
(S3) Train the neural network by minimizing (1) via T-step mini-batch gradient descent
method using disjoint subsets {Dt}T ‚àí1
t=0 and { eDt}T ‚àí1
t=0 of eD. Let W (‚Ñì+1) denote the obtained
student model;
(S4) Use W (‚Ñì+1) as the current teacher model. Let ‚Ñì‚Üê‚Ñì+ 1 and go back to step (S2);"
RELATED WORKS,0.026490066225165563,"Iterative self-training. In each iteration, given the current teacher predictor g(W (‚Ñì)), the pseudo-
labels for the unlabeled data in eD are computed as Àúym = g(W (‚Ñì); exm). The method then minimizes
the weighted empirical risk ÀÜfD, e
D(W ) of both labeled and unlabeled data through stochastic gradient"
RELATED WORKS,0.027436140018921477,Published as a conference paper at ICLR 2022
RELATED WORKS,0.02838221381267739,"descent, where"
RELATED WORKS,0.0293282876064333,"ÀÜfD, e
D(W ) =
Œª
2N N
X n=1"
RELATED WORKS,0.030274361400189215," 
yn ‚àíg(W ; xn)
2 +
eŒª
2M M
X m=1"
RELATED WORKS,0.03122043519394513," 
eym ‚àíg(W ; exm)
2,
(1)"
RELATED WORKS,0.03216650898770104,"and Œª + eŒª = 1. The learned student model g(W (‚Ñì+1)) is used as the teacher model in the next iter-
ation. The initial model g(W (0)) is learned from labeled data. The formal algorithm is summarized
as in Table 1."
RELATED WORKS,0.033112582781456956,"Model and assumptions. This paper considers regression1, where g is a one-hidden-layer fully
connected neural network equipped with K neurons. Namely, given the input x ‚ààRd and weights
W = [w1, w2, ¬∑ ¬∑ ¬∑ , wK] ‚ààRd√óK, we have"
RELATED WORKS,0.03405865657521287,"g(W ; x) := 1 K K
X"
RELATED WORKS,0.03500473036896878,"j=1
œÜ(wT
j x),
(2)"
RELATED WORKS,0.03595080416272469,"where œÜ is the ReLU activation function2, and œÜ(z) = max{z, 0} for any input z ‚ààR. Here, we Ô¨Åx
the top layer weights as 1 for simplicity, and the equivalence of such a simpliÔ¨Åcation is discussed in
Appendix K."
RELATED WORKS,0.036896877956480605,"Moreover, we assume an unknown ground-truth model with weights W ‚àóthat maps all the features to
the corresponding labels drawn from Pl, i.e., y = g(W ‚àó; x), where (x, y) ‚àºPl. The generalization
function (GF) with respect to g(W ) is deÔ¨Åned as"
RELATED WORKS,0.03784295175023652,"I
 
g(W )

= E(x,y)‚àºPl
 
y ‚àíg(W ; x)
2 = E(x,y)‚àºPl
 
g(W ‚àó; x) ‚àíg(W ; x)
2.
(3)"
RELATED WORKS,0.03878902554399243,"By deÔ¨Ånition I
 
g(W ‚àó)

is zero. Clearly, W ‚àóis not unique because any column permutation of
W ‚àó, which corresponds to permuting neurons, represents the same function as W ‚àóand minimizes
GF in (3) too. To simplify the representation, we follow the convention and abuse the notation that
the distance from W to W ‚àó, denoted by ‚à•W ‚àíW ‚àó‚à•F , means the smallest distance from W to
any permutation of W ‚àó. Additionally, some important notations are summarized in Table 2."
RELATED WORKS,0.039735099337748346,"We assume the inputs of both the labeled and unlabeled data belong to the zero mean Gaussian
distribution, i.e., x ‚àºN(0, Œ¥2Id), and ex ‚àºN(0, ÀúŒ¥2Id). The Gaussian assumption is motivated
by the data whitening (LeCun et al., 2012) and batch normalization techniques (Ioffe & Szegedy,
2015) that are commonly used in practice to improve learning performance. Moreover, training one-
hidden-layer neural network with multiple neurons is NP-Complete (Blum & Rivest, 1992) without
any assumption."
RELATED WORKS,0.04068117313150426,"The focus of this paper. This paper will analyze three aspects about self-training: (1) the gener-
alization performance of W (L), the returned model by self-training after L iterations, measured by
‚à•W (L) ‚àíW ‚àó‚à•F 3; (2) the inÔ¨Çuence of parameter Œª in (1) on the training performance; and (3) the
impact of unlabeled data on the training and generalization performance."
RELATED WORKS,0.041627246925260174,Table 2: Some Important Notations
RELATED WORKS,0.04257332071901608,"D = {xn, yn}N
n=1 Labeled dataset with N number of samples;
eD = {exm}M
m=1
Unlabeled dataset with M number of samples;
d
Dimension of the input x or ex;
K
Number of neurons in the hidden layer;
Œ∫
Conditional number (the ratio of the largest and smallest singular values) of W ‚àó;
W (‚Ñì)
Model returned by self-training after ‚Ñìiterations; W (0) is the initial model;
W ‚àó
Weights of the ground truth model;"
RELATED WORKS,0.043519394512771994,"W [ÀÜŒª]
W [ÀÜŒª] = ÀÜŒªW ‚àó+ (1 ‚àíÀÜŒª)W (0);"
RELATED WORKS,0.04446546830652791,"1The results can be extended to binary classiÔ¨Åcation with a cross-entropy loss function.
Please see
Appendix-I."
RELATED WORKS,0.04541154210028382,"2Because ReLU is non-linear and non-smooth, (1) is non-convex and non-smooth, which poses analytical
challenges. The results can be easily extended to smooth functions with bounded gradients, e.g., Sigmoid."
WE USE THIS METRIC BECAUSE I,0.046357615894039736,"3We use this metric because I
 
g(W )

is shown to be linear in ‚à•W (L) ‚àíW ‚àó‚à•F numerically when W (L)"
WE USE THIS METRIC BECAUSE I,0.04730368968779565,"is close to W ‚àó, see Figure 4."
WE USE THIS METRIC BECAUSE I,0.048249763481551564,Published as a conference paper at ICLR 2022
THEORETICAL RESULTS,0.04919583727530748,"3
THEORETICAL RESULTS"
THEORETICAL RESULTS,0.050141911069063384,"Beyond supervised learning:
Challenge of self-training.
The existing theoretical works
such as (Zhong et al., 2017; Zhang et al., 2020a;b;c) verify that for one-hidden-layer neu-
ral networks, if only labeled data are available, and x are drawn from the standard Gaus-
sian distribution, then supervised learning by minimizing (1) with Œª
=
1 can return a
model with ground-truth weights W ‚àó(up to column permutation), as long as the num-
ber of labeled data N is at least N ‚àó, which depends on Œ∫, K and d.
In contrast, this
paper focuses on the low labeled-data regime when N is less than N ‚àó.
SpeciÔ¨Åcally, ùëæùëæ ùëæùëæ‚àó"
THEORETICAL RESULTS,0.0510879848628193,Generalization
THEORETICAL RESULTS,0.05203405865657521,function
THEORETICAL RESULTS,0.052980132450331126,"Objective function
with unlabeled data"
THEORETICAL RESULTS,0.05392620624408704,Local minima ùëæùëæ(0)
THEORETICAL RESULTS,0.05487228003784295,"Objective function 
without unlabeled data"
THEORETICAL RESULTS,0.05581835383159887,"Figure 2: Adding unlabeled data in the em-
pirical risk function drives its local minimum
closer to W ‚àó, which minimizes the generaliza-
tion function."
THEORETICAL RESULTS,0.05676442762535478,"N ‚àó/4 < N ‚â§N ‚àó.
(4)"
THEORETICAL RESULTS,0.05771050141911069,"Intuitively, if N < N ‚àó, the landscape of the empir-
ical risk of the labeled data becomes highly non-
convex, even in a neighborhood of W ‚àó, thus, the
existing analyses for supervised learning do not
hold in this region. With additional unlabeled data,
the landscape of the weighted empirical risk be-
comes smoother near W ‚àó. Moreover, as M in-
creases, and starting from a nearby initialization,
the returned model W (L) by iterative self-training
can converge to a local minimum that is closer to
W ‚àó(see illustration in Figure 2)."
THEORETICAL RESULTS,0.0586565752128666,"Compared with supervised learning, the formal analyses of self-training need to handle new techni-
cal challenges from two aspects. First, the existing analyses of supervised learning exploit the fact
that the GF and the empirical risk have the same minimizer, i.e., W ‚àó. This property does not hold
for self-training as W ‚àóno longer minimizes the weighted empirical risk in (1). Second, the iterative
manner of self-training complicates the analyses. SpeciÔ¨Åcally, the empirical risk in each iteration is
different and depends on the model trained in the previous iteration through the pseudo labels."
THEORETICAL RESULTS,0.059602649006622516,"In what follows, we provide theoretical insights and the formal theorems. Some important quantities
ÀÜŒª and ¬µ are deÔ¨Åned below"
THEORETICAL RESULTS,0.06054872280037843,"ÀÜŒª :=
ŒªŒ¥2"
THEORETICAL RESULTS,0.06149479659413434,"ŒªŒ¥2 + eŒªÀúŒ¥2 ,
and
¬µ = ¬µ(Œ¥, ÀúŒ¥) := s"
THEORETICAL RESULTS,0.06244087038789026,ŒªŒ¥2 + eŒªÀúŒ¥2
THEORETICAL RESULTS,0.06338694418164617,"ŒªœÅ(Œ¥) + eŒªœÅ(ÀúŒ¥)
,
(5)"
THEORETICAL RESULTS,0.06433301797540208,"where œÅ is a positive function deÔ¨Åned in (73). ÀÜŒª is an increasing function of Œª. Also, from Lemma
11 (in Appendix), œÅ(Œ¥) is in the order of Œ¥2 when Œ¥ ‚â§1 for ReLU activation functions. Thus, ¬µ is a
Ô¨Åxed constant, denoted by ¬µ‚àó, for all Œ¥, ÀúŒ¥ ‚â§1. When Œ¥ and ÀúŒ¥ are large, ¬µ increases as they increase.
The formal deÔ¨Ånition of N ‚àóin (4) is c(Œ∫)¬µ‚àó2K3d log q, where c(Œ∫) is some polynomial function of
Œ∫ and can be viewed as constant."
INFORMAL KEY THEORETICAL FINDINGS,0.065279091769158,"3.1
INFORMAL KEY THEORETICAL FINDINGS"
INFORMAL KEY THEORETICAL FINDINGS,0.06622516556291391,"ùëæùëæ(0)
ùëæùëæ‚àó ùëæùëæ(1) ùëæùëæ(2)"
INFORMAL KEY THEORETICAL FINDINGS,0.06717123935666983,"ùëæùëæ(ùêøùêø)
. . ."
INFORMAL KEY THEORETICAL FINDINGS,0.06811731315042574,ùëæùëæ[‡∑°ùúÜùúÜ] ùúüùúüùüéùüé
INFORMAL KEY THEORETICAL FINDINGS,0.06906338694418164,"ùúüùúüùüèùüè=
1 + ùí™ùí™
1
ùëÄùëÄ
»â Œî0
ùêæùêæ
ùìîùìîùüéùüé= 1 ‚àíÃÇùúÜùúÜ»â ùëæùëæ‚àó‚àíùëæùëæ(0)
ùë≠ùë≠"
INFORMAL KEY THEORETICAL FINDINGS,0.07000946073793755,"ùìîùìîùüèùüè=
1 + ùí™ùí™
1
ùëÄùëÄ
»â ‚Ñ∞0
ùêæùêæ"
INFORMAL KEY THEORETICAL FINDINGS,0.07095553453169347,"Figure 3: Illustration of the (1) ground truth W ‚àó,
(2) iterations {W (‚Ñì)}L
‚Ñì=0, (3) convergent point
W (L), and (4) W [ÀÜŒª] = ÀÜŒªW ‚àó+ (1 ‚àíÀÜŒª)W (0)."
INFORMAL KEY THEORETICAL FINDINGS,0.07190160832544938,"To the best of our knowledge, Theorems 1 and
2 provide the Ô¨Årst theoretical characterization of
iterative self-training on nonlinear neural net-
works.
Before formally presenting them, we
summarize the highlights as follows."
INFORMAL KEY THEORETICAL FINDINGS,0.0728476821192053,"1. Linear convergence of the learned models.
The learned models converge linearly to a model
close to W ‚àó. Thus, the iterative approach re-
turns a model with better generalization than that
by the single-shot method. Moreover, the con-
vergence rate is a constant term plus a term in
the order of 1/
‚àö"
INFORMAL KEY THEORETICAL FINDINGS,0.07379375591296121,"M (see ‚àÜ1 in Figure 3), indi-
cating a faster convergence with more unlabeled
data."
INFORMAL KEY THEORETICAL FINDINGS,0.07473982970671712,Published as a conference paper at ICLR 2022
INFORMAL KEY THEORETICAL FINDINGS,0.07568590350047304,"2. Returning a model with guaranteed generalization in the low labeled-data regime. Even
when the number of labeled data is much less than the required sample complexity to obtain W ‚àó
in supervised learning, we prove that with the help of unlabeled data, the iterative self-training can
return a model in the neighborhood of W [ÀÜŒª], where W [ÀÜŒª] is in the line segment of W (0) (ÀÜŒª = 0)
and ground truth W ‚àó(ÀÜŒª = 1). Moreover, ÀÜŒª is upper bounded by
p"
INFORMAL KEY THEORETICAL FINDINGS,0.07663197729422895,"N/N ‚àó. Thus W (L) moves
closer to W ‚àóas N increases (E0 in Figure 3), indicating a better generalization performance with
more labeled data."
INFORMAL KEY THEORETICAL FINDINGS,0.07757805108798486,3. Guaranteed generalization improvement by unlabeled data. The distance between W (L)
INFORMAL KEY THEORETICAL FINDINGS,0.07852412488174078,"and W [ÀÜŒª] (E1 in Figure 3) scales in the order of 1/
‚àö"
INFORMAL KEY THEORETICAL FINDINGS,0.07947019867549669,"M. With a larger number of unlabeled data
M, W (L) moves closer to W [ÀÜŒª] and thus W ‚àó, indicating an improved generalization performance
(Theorem 1). When N is close to N ‚àóbut still smaller as deÔ¨Åned in (12), both W (L) and W [ÀÜŒª]
converge to W ‚àó, and thus the learned model achieves zero generalization error (Theorem 2)."
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.0804162724692526,"3.2
FORMAL THEORY IN LOW LABELED-DATA REGIME"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08136234626300852,"Takeaways of Theorem 1: Theorem 1 characterizes the convergence rate of the proposed algorithm
and the accuracy of the learned model W (L) in a low labeled-data regime. SpeciÔ¨Åcally, the iterates
converge linearly, and the learned model is close to W [ÀÜŒª] and guaranteed to outperform the initial
model W (0).
Theorem 1. Suppose the initialization W (0) and the number of labeled data satisfy"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08230842005676443,"‚à•W (0) ‚àíW ‚àó‚à•F ‚â§p‚àí1 ¬∑
‚à•W ‚àó‚à•F
c(Œ∫)¬µ2K3/2
with
p ‚àà
 1"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08325449385052035,"2, 1

,
(6)"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08420056764427625,"and
max
n 1"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08514664143803216,"K , p ‚àí2p ‚àí1 ¬µ
‚àö K"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08609271523178808,"o2
¬∑ N ‚àó‚â§N ‚â§N ‚àó.
(7)"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08703878902554399,If the value of ÀÜŒª in (5) and unlabeled data amount M satisfy
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.0879848628192999,"max
n 1"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08893093661305582,"K , p ‚àí2p ‚àí1 ¬µ
‚àö K"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.08987701040681173,"o
‚â§ÀÜŒª ‚â§min
nr"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09082308420056764,"N
N ‚àó, p + 2p ‚àí1 ¬µ
‚àö K"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09176915799432356,"o
,
(8)"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09271523178807947,"and
M ‚â•(2p ‚àí1)‚àí2c(Œ∫)¬µ2 
1 ‚àíÀÜŒª
2K3d log q.
(9)
Then, when the number T of SGD iterations is large enough in each loop ‚Ñì, with probability at least
1 ‚àíq‚àíd, the iterates {W (‚Ñì)}L
‚Ñì=0 converge to W [ÀÜŒª] as"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09366130558183539,"‚à•W (L) ‚àíW [ÀÜŒª]‚à•F ‚â§

1 + Œò
  ¬µ(1‚àíÀÜŒª)
‚àö"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.0946073793755913,"M

¬∑ ÀÜŒª
L
¬∑ ‚à•W (0) ‚àíW [ÀÜŒª]‚à•2 +

1 + Œò
  ¬µ(1‚àíÀÜŒª)
‚àö"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09555345316934721,"M

¬∑ ‚à•W ‚àó‚àíW [ÀÜŒª]‚à•F ,"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09649952696310313,"(10)
where W [ÀÜŒª] = ÀÜŒªW ‚àó+ (1 ‚àíÀÜŒª)W (0). Typically, when the iteration number L is sufÔ¨Åcient large, we
have"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09744560075685904,"‚à•W (L) ‚àíW ‚àó‚à•F ‚â§

1 + Œò
 ¬µ(1 ‚àíÀÜŒª)
‚àö M"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09839167455061495,"
¬∑ 2(1 ‚àíÀÜŒª) ¬∑ ‚à•W ‚àó‚àíW (0)‚à•F .
(11)"
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.09933774834437085,"The accuracy of the learned model W (L) with respect to W ‚àóis characterized as (10), and the
learning model is better than initial model as in (11) if the following conditions hold. First, the
weights Œª in (1) are properly chosen as in (8). Second, the number of unlabeled data is sufÔ¨Åciently
large as in (9)."
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.10028382213812677,"Selection of Œª in self-training algorithms. When ÀÜŒª increases, the required number of unlabeled
data is reduced from (9), and the convergence point W (L) becomes closer to W ‚àófrom (11), which
indicates a smaller generalization error. Thus, a large ÀÜŒª within its feasible range (8) is desirable.
When the initial model W (0) is closer to W ‚àó(corresponding to a larger p), and the number of
labeled data N increases, the upper bound in (8) increases, and thus, one can select a larger ÀÜŒª."
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.10122989593188268,"The initial model W (0). The tensor initialization from (Zhong et al., 2017) can return a W (0) that
satisÔ¨Åes (6) when the number of labeled data is N = p2N ‚àó(see Lemma 3 in Appendix). Combining
with the requirement in (7), Theorem 1 applies to the case that N is at least N ‚àó/4."
FORMAL THEORY IN LOW LABELED-DATA REGIME,0.1021759697256386,Published as a conference paper at ICLR 2022
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10312204351939451,"3.3
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10406811731315042,"Takeaways of Theorem 2: Theorem 2 indicates the model returned by the proposed algorithm con-
verges linearly to the ground truth W ‚àó. Thus the distance between the learned model and the ground
truth can be arbitrarily small with the ability to achieve zero generalization error. The required sam-
ple complexity is reduced by a constant factor compared with supervised learning.
Theorem 2. Consider the number of unlabeled data satisÔ¨Åes
 
1 ‚àí1/(¬µ
‚àö"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10501419110690634,"K)
2 ¬∑ N ‚àó‚â§N ‚â§N ‚àó,
(12)"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10596026490066225,"we choose ÀÜŒª such that
1 ‚àí1/(¬µ
‚àö"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10690633869441817,"K) ‚â§ÀÜŒª ‚â§
p"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10785241248817408,"N/N ‚àó.
(13)"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.10879848628192999,Suppose the initial model W (0) and the number of unlabeled data M satisfy
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.1097445600756859,"‚à•W (0) ‚àíW ‚àó‚à•F ‚â§
‚à•W ‚àó‚à•F
c(Œ∫)¬µ2K3/2
and
M ‚â•c(Œ∫)¬µ2(1 ‚àíÀÜŒª)2K3d log q,
(14)"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.11069063386944182,"the iterates {W (‚Ñì)}L
‚Ñì=0 converge to the ground truth W ‚àóas follows,"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.11163670766319773,"‚à•W (L) ‚àíW ‚àó‚à•F ‚â§
h 
1 + c(Œ∫)ÀÜŒª
‚àö"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.11258278145695365,"N
+ c(Œ∫)(1 ‚àíÀÜŒª)
‚àö M"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.11352885525070956,"
¬∑ ¬µ
‚àö"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.11447492904446546,"K(1 ‚àíÀÜŒª)
iL
¬∑ ‚à•W (0) ‚àíW ‚àó‚à•F .
(15)"
FORMAL THEORY OF ACHIEVING ZERO GENERALIZATION ERROR,0.11542100283822138,"The models W (‚Ñì)‚Äôs converge linearly to the ground truth W ‚àóas (15) when the number of labeled
data satisÔ¨Åes (12). In contrast, supervised learning requires at least N ‚àólabeled samples to estimate
W ‚àóaccurately without unlabeled data, which suggests self-training at least saves a constant fraction
of labeled data."
THE MAIN PROOF IDEA,0.11636707663197729,"3.4
THE MAIN PROOF IDEA"
THE MAIN PROOF IDEA,0.1173131504257332,"Our proof builds upon and extends one recent line of works on supervised learning such as (Zhong
et al., 2017; Zhang et al., 2020b;c; 2021). The standard framework of these works is Ô¨Årst to show
that the generalization function I(g(W )) in (3) is locally convex near W ‚àó, which is its global
minimizer. Then, when M = 0 and N is sufÔ¨Åciently large, the empirical risk function using labeled
data only can approximate I(g(W )) well in the neighborhood of W ‚àó. Thus, if initialized in this
local convex region, the iterations, returned by applying gradient descent approach on the empirical
risk function, converge to W ‚àólinearly."
THE MAIN PROOF IDEA,0.11825922421948912,"The technical challenge here is that in self-training, when unlabeled data are paired with pseudo
labels, W ‚àóis no longer a global minimizer of the empirical risk ÀÜfD, e
D in (1), and ÀÜfD, e
D does not
approach I(g(W )) even when M and N increase to inÔ¨Ånity. Our new idea is to design a population
risk function f(W ; ÀÜŒª) in (17) (see appendix), which is a lower bound of ÀÜfD, e
D when M and N are"
THE MAIN PROOF IDEA,0.11920529801324503,"inÔ¨Ånity. f(W ; ÀÜŒª) is locally convex around its minimizer W [ÀÜŒª], and W [ÀÜŒª] approaches W ‚àóas ÀÜŒª
increases. Then we show the iterates generated by ÀÜfD, e
D stay close to f(W ; ÀÜŒª), and the returned"
THE MAIN PROOF IDEA,0.12015137180700095,"model W (L) is close to W [ÀÜŒª]. New technical tools are developed to bound the distance between the
functions ÀÜfD, e
D and f(W ; ÀÜŒª)."
EMPIRICAL RESULTS,0.12109744560075686,"4
EMPIRICAL RESULTS"
SYNTHETIC DATA EXPERIMENTS,0.12204351939451277,"4.1
SYNTHETIC DATA EXPERIMENTS"
SYNTHETIC DATA EXPERIMENTS,0.12298959318826869,"We generate a ground-truth neural network with the width K = 10. Each entry of W ‚àóis uniformly
selected from [‚àí2.5, 2.5]. The input of labeled data xn are generated from Gaussian distribution
N(0, Id) independently, and the corresponding label yn is generated through (2) using W ‚àó. The
unlabeled data exm are generated from N(0, eŒ¥2Id) independently with eŒ¥ = 1 except in Figure 7.
d is set as 50 except in Figure 9. The value of Œª is selected as
p"
SYNTHETIC DATA EXPERIMENTS,0.1239356669820246,"N/(2Kd) except in Figure 8.
We consider one-hidden-layer except in Figure 4. The initial teacher model W (0) in self-training
is randomly selected from {W |‚à•W ‚àíW ‚àó‚à•F /‚à•W ‚àó‚à•F ‚â§0.5} to reduce the computation. In"
SYNTHETIC DATA EXPERIMENTS,0.12488174077578051,Published as a conference paper at ICLR 2022
SYNTHETIC DATA EXPERIMENTS,0.12582781456953643,"each iteration, the maximum number of SGD steps T is 10. Self-training terminates if ‚à•W (‚Ñì+1) ‚àí
W (‚Ñì)‚à•F /‚à•W (‚Ñì)‚à•F ‚â§10‚àí4 or reaching 1000 iterations. In Figures 5 to 8, all the points on the
curves are averaged over 1000 independent trials, and the regions in lower transparency indicate
the corresponding one-standard-deviation error bars. Our empirical observations are summarized
below."
SYNTHETIC DATA EXPERIMENTS,0.12677388836329234,"(a) GF (testing performance) proportional to ‚à•W ‚àíW ‚àó‚à•F . Figure 4 illustrates the GF in (3)
against the distance to the ground truth W ‚àó. To visualize results for different networks together,
GF is normalized in [0, 1], divided by its largest value for each network architecture. All the results
are averaged over 100 independent choice of W . One can see that for one-hidden-layer neural
networks, in a large region near W ‚àó, GF is almost linear in ‚à•W ‚àíW ‚àó‚à•F . When the number of
hidden layers increases, this region decreases, but the linear dependence still holds locally. This is
an empirical justiÔ¨Åcation of using ‚à•W ‚àíW ‚àó‚à•F to evaluate the GF and, thus, the testing error in
Theorems 1 and 2."
SYNTHETIC DATA EXPERIMENTS,0.12771996215704826,"(b) ‚à•W (L) ‚àíW ‚àó‚à•F as a linear function of 1/
‚àö"
SYNTHETIC DATA EXPERIMENTS,0.12866603595080417,"M. Figure 5 shows the relative error ‚à•W (L) ‚àí
W ‚àó‚à•F /‚à•W ‚àó‚à•F when the number of unlabeled data and labeled data changes. One can see that the
relative error decreases when either M or N increases. Additionally, the dash-dotted lines represent
the best Ô¨Åtting of the linear functions of 1/
‚àö"
SYNTHETIC DATA EXPERIMENTS,0.12961210974456008,"M using the least square method. Therefore, the relative
error is indeed a linear function of 1/
‚àö"
SYNTHETIC DATA EXPERIMENTS,0.130558183538316,"M, as predicted by our results in (11) and (15)."
SYNTHETIC DATA EXPERIMENTS,0.1315042573320719,"0
0.1
0.2
0.3
0.4
0.5
0 0.2 0.4 0.6 0.8 1"
-HIDDEN-LAYER,0.13245033112582782,"1-hidden-layer
5-hidden-layer
10-hidden-layer
50-hidden-layer"
-HIDDEN-LAYER,0.13339640491958374,"Figure 4:
The generalization
function against the distance to
the ground truth neural network"
-HIDDEN-LAYER,0.13434247871333965,"200
400
600
800
1000
Number of unlabeled data (M) 3 3.5 4 4.3"
-HIDDEN-LAYER,0.13528855250709557,Relative error (%)
-HIDDEN-LAYER,0.13623462630085148,"Figure 5:
The relative error
against the number of unlabeled
data."
-HIDDEN-LAYER,0.13718070009460737,"0.018
0.0175
0.017
0.0165
0.9993"
-HIDDEN-LAYER,0.13812677388836328,0.99935
-HIDDEN-LAYER,0.1390728476821192,0.9994
-HIDDEN-LAYER,0.1400189214758751,0.99945
-HIDDEN-LAYER,0.14096499526963102,0.9995
-HIDDEN-LAYER,0.14191106906338694,0.99955
-HIDDEN-LAYER,0.14285714285714285,Convergence rate
-HIDDEN-LAYER,0.14380321665089876,"N = 250
N = 300
N = 350"
-HIDDEN-LAYER,0.14474929044465468,"Figure 6: The convergence rate
with different M when N
<
N ‚àó."
-HIDDEN-LAYER,0.1456953642384106,"(c) Convergence rate as a linear function of 1/
‚àö"
-HIDDEN-LAYER,0.1466414380321665,"M. Figure 6 illustrates the convergence rate
when M and N change. We can see that the convergence rate is a linear function of 1/
‚àö"
-HIDDEN-LAYER,0.14758751182592242,"M, as
predicted by our results (11) and (15). When M increases, the convergence rate is improved, and
the method converges faster."
-HIDDEN-LAYER,0.14853358561967833,"(d) Increase of eŒ¥ slows down convergence. Figure 7 shows that the convergence rate becomes
worse when the variance of the unlabeled data eŒ¥ increases from 1. When eŒ¥ is less than 1, the
convergence rate almost remains the same, which is consistent with our characterization in (10) that
the convergence rate is linear in ¬µ. From the discussion after (5), ¬µ increases as eŒ¥ increases from 1
and stays constant when eŒ¥ is less than 1."
-HIDDEN-LAYER,0.14947965941343425,"(e) ‚à•W (L)‚àíW ‚àó‚à•F /‚à•W ‚àó‚à•F is improved as a linear function of ÀÜŒª. Figure 8 shows that the relative
errors of W (L) with respect to W ‚àódecrease almost linearly when ÀÜŒª increases, which is consistent
with the theoretical result in (11). Moreover, when Œª exceeds a certain threshold positively correlated
with N, the relative error increases rather than decreases. That is consistent with the analysis in (8)
that ÀÜŒª has an upper limit, and such a limit increases as N increases."
-HIDDEN-LAYER,0.15042573320719016,"(f) Unlabeled data reduce the sample complexity to learn W ‚àó. Figure 9 depicts the phase tran-
sition of returning W (L). For every pair of d and N, we construct 100 independent trials, and each
trial is said to be successful if ‚à•W (L) ‚àíW ‚àó‚à•F /‚à•W ‚àó‚à•F ‚â§10‚àí2. The white blocks correspond to
the successful trials, while the block in black indicates all failures. When d increases, the required
number of labeled data to learn W ‚àóis linear in d. Thus, the sample complexity bound in (12) is
order-wise optimal for d. Moreover, the phase transition line when M = 1000 is below the one
when M = 0. Therefore, with unlabeled data, the required sample complexity of N is reduced."
-HIDDEN-LAYER,0.15137180700094607,Published as a conference paper at ICLR 2022
-HIDDEN-LAYER,0.152317880794702,"1
2
3
4
5 0.99 0.995 1"
-HIDDEN-LAYER,0.1532639545884579,Convergence rate
-HIDDEN-LAYER,0.15421002838221382,"Figure 7: Convergence rate
with different ÀÜŒ¥."
-HIDDEN-LAYER,0.15515610217596973,"0.1
0.2
0.3
0.4
0.5
5.3 5.7 6.1 6.5 6.9"
-HIDDEN-LAYER,0.15610217596972564,Relative error (%)
-HIDDEN-LAYER,0.15704824976348156,"N=200
N=240
N=280"
-HIDDEN-LAYER,0.15799432355723747,"Figure
8:
‚à•W (L)‚àíW ‚àó‚à•F"
-HIDDEN-LAYER,0.15894039735099338,"‚à•W ‚àó‚à•F
when ÀÜŒª and N change."
-HIDDEN-LAYER,0.1598864711447493,"20 26 32 38 44 50
200
260
320
380
440
500
560
620
680"
-HIDDEN-LAYER,0.1608325449385052,"20 26 32 38 44 50
200
260
320
380
440
500
560
620
680"
-HIDDEN-LAYER,0.16177861873226113,"Figure 9: Empirical phase transition of
the curves with (a) M = 0 and (b) M =
1000."
-HIDDEN-LAYER,0.16272469252601704,"4.2
IMAGE CLASSIFICATION ON AUGMENTED CIFAR-10 DATASET"
-HIDDEN-LAYER,0.16367076631977295,"We evaluate self-training on the augmented CIFAR-10 dataset, which has 50K labeled data. The
unlabeled data are mined from 80 Million Tiny Images following the setup in (Carmon et al., 2019)4,
and additional 50K images are selected for each class, which is a total of 500K images, to form the
unlabeled data. The self-training method is the same implementation as that in (Carmon et al., 2019).
Œª and eŒª is selected as N/(M + N) and M/(N + M), respectively, and the algorithm stops after
200 epochs. In Figure 10, the dash lines stand for the best Ô¨Åtting of the linear functions of 1/
‚àö"
-HIDDEN-LAYER,0.16461684011352887,"M
via the least square method. One can see that the test accuracy is improved by up to 7% using
unlabeled data, and the empirical evaluations match the theoretical predictions. Figure 11 shows the
convergence rate calculated based on the Ô¨Årst 50 epochs, and the convergence rate is almost a linear
function of 1/
‚àö"
-HIDDEN-LAYER,0.16556291390728478,"M, as predicted by (10)."
-HIDDEN-LAYER,0.1665089877010407,"0
100K
200K
300K
400K
500K
Number of unlabeled data (M) 80 85 90"
-HIDDEN-LAYER,0.16745506149479658,Test accuracy (%)
-HIDDEN-LAYER,0.1684011352885525,"Figure 10:
The test accuracy against the
number of unlabeled data"
-HIDDEN-LAYER,0.1693472090823084,"5
6
7
8
9
10 10-3 0.952 0.954 0.956 0.958 0.96 0.962"
-HIDDEN-LAYER,0.17029328287606432,Convergence rate
-HIDDEN-LAYER,0.17123935666982024,"N=15K
N=30K
N=50K"
-HIDDEN-LAYER,0.17218543046357615,"Figure 11: The convergence rate against the
number of unlabeled data"
CONCLUSION,0.17313150425733206,"5
CONCLUSION"
CONCLUSION,0.17407757805108798,"This paper provides new theoretical insights into understanding the inÔ¨Çuence of unlabeled data in
the iterative self-training algorithm. We show that the improved generalization error and conver-
gence rate is a linear function of 1/
‚àö"
CONCLUSION,0.1750236518448439,"M, where M is the number of unlabeled data. Moreover,
compared with supervised learning, using unlabeled data reduces the required sample complexity of
labeled data for achieving zero generalization error. Future directions include generalizing the anal-
ysis to multi-layer neural networks and other semi-supervised learning problems such as domain
adaptation."
CONCLUSION,0.1759697256385998,ACKNOWLEDGEMENT
CONCLUSION,0.17691579943235572,"This work was supported by AFOSR FA9550-20-1-0122, ARO W911NF-21-1-0255, NSF 1932196
and the Rensselaer-IBM AI Research Collaboration (http://airc.rpi.edu), part of the IBM AI Hori-
zons Network (http://ibm.biz/AIHorizons)."
CONCLUSION,0.17786187322611163,4The codes are downloaded from https://github.com/yaircarmon/semisup-adv
CONCLUSION,0.17880794701986755,Published as a conference paper at ICLR 2022
REFERENCES,0.17975402081362346,REFERENCES
REFERENCES,0.18070009460737937,"Zeyuan Allen-Zhu, Yuanzhi Li, and Yingyu Liang. Learning and generalization in overparameter-
ized neural networks, going beyond two layers. In Advances in neural information processing
systems, pp. 6158‚Äì6169, 2019."
REFERENCES,0.1816461684011353,"Sanjeev Arora, Simon Du, Wei Hu, Zhiyuan Li, and Ruosong Wang. Fine-grained analysis of op-
timization and generalization for overparameterized two-layer neural networks. In International
Conference on Machine Learning, pp. 322‚Äì332. PMLR, 2019a."
REFERENCES,0.1825922421948912,"Sanjeev Arora, Simon S Du, Wei Hu, Zhiyuan Li, and Ruosong Wang. Fine-grained analysis of
optimization and generalization for overparameterized two-layer neural networks. In 36th In-
ternational Conference on Machine Learning, ICML 2019, pp. 477‚Äì502. International Machine
Learning Society (IMLS), 2019b."
REFERENCES,0.18353831598864712,"Philip Bachman, Ouais Alsharif, and Doina Precup. Learning with pseudo-ensembles. Advances in
neural information processing systems, 2014."
REFERENCES,0.18448438978240303,"Ainesh Bakshi, Rajesh Jayaram, and David P Woodruff. Learning two layer rectiÔ¨Åed neural networks
in polynomial time. In Conference on Learning Theory, pp. 195‚Äì268. PMLR, 2019."
REFERENCES,0.18543046357615894,"Maria-Florina Balcan and Avrim Blum. A discriminative model for semi-supervised learning. Jour-
nal of the ACM (JACM), 57(3):1‚Äì46, 2010."
REFERENCES,0.18637653736991486,"Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463‚Äì482, 2002."
REFERENCES,0.18732261116367077,"David Berthelot, Nicholas Carlini, Ekin D Cubuk, Alex Kurakin, Kihyuk Sohn, Han Zhang, and
Colin Raffel. Remixmatch: Semi-supervised learning with distribution matching and augmenta-
tion anchoring. In International Conference on Learning Representations, 2019a."
REFERENCES,0.18826868495742669,"David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin
Raffel.
Mixmatch:
A holistic approach to semi-supervised learning.
arXiv preprint
arXiv:1905.02249, 2019b."
REFERENCES,0.1892147587511826,"Rajendra Bhatia. Matrix analysis, volume 169. Springer Science & Business Media, 2013."
REFERENCES,0.1901608325449385,"Avrim L Blum and Ronald L Rivest. Training a 3-node neural network is np-complete. Neural
Networks, 5(1):117‚Äì127, 1992."
REFERENCES,0.19110690633869443,"Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and Dumitru Erhan.
Domain separation networks. In Proceedings of the 30th International Conference on Neural
Information Processing Systems, pp. 343‚Äì351, 2016."
REFERENCES,0.19205298013245034,"Alon Brutzkus and Amir Globerson. Globally optimal gradient descent for a convnet with gaussian
inputs. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp.
605‚Äì614. JMLR. org, 2017."
REFERENCES,0.19299905392620625,"Alon Brutzkus, Amir Globerson, Eran Malach, and Shai Shalev-Shwartz.
Sgd learns over-
parameterized networks that provably generalize on linearly separable data.
In International
Conference on Learning Representations, 2018."
REFERENCES,0.19394512771996217,"Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John C Duchi, and Percy S Liang. Unlabeled
data improves adversarial robustness. Advances in Neural Information Processing Systems, 32:
11192‚Äì11203, 2019."
REFERENCES,0.19489120151371808,"Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey E Hinton. Big
self-supervised models are strong semi-supervised learners.
Advances in Neural Information
Processing Systems, 33:22243‚Äì22255, 2020a."
REFERENCES,0.195837275307474,"Yining Chen, Colin Wei, Ananya Kumar, and Tengyu Ma.
Self-training avoids using spurious
features under domain shift. Advances in Neural Information Processing Systems, 33, 2020b."
REFERENCES,0.1967833491012299,Published as a conference paper at ICLR 2022
REFERENCES,0.1977294228949858,"Simon S Du, Xiyu Zhai, Barnabas Poczos, and Aarti Singh. Gradient descent provably optimizes
over-parameterized neural networks. In International Conference on Learning Representations,
2018."
REFERENCES,0.1986754966887417,"Geoffrey French, Michal Mackiewicz, and Mark Fisher. Self-ensembling for visual domain adapta-
tion. In International Conference on Learning Representations, number 6, 2018."
REFERENCES,0.19962157048249762,"Haoyu Fu, Yuejie Chi, and Yingbin Liang. Guaranteed recovery of one-hidden-layer neural networks
via cross entropy. IEEE Transactions on Signal Processing, 68:3225‚Äì3235, 2020."
REFERENCES,0.20056764427625354,"Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In
International conference on machine learning, pp. 1180‚Äì1189. PMLR, 2015."
REFERENCES,0.20151371807000945,"Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran√ßois
Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural net-
works. The journal of machine learning research, 17(1):2096‚Äì2030, 2016."
REFERENCES,0.20245979186376536,"Rong Ge, Jason D. Lee, and Tengyu Ma. Learning one-hidden-layer neural networks with land-
scape design. In International Conference on Learning Representations, 2018. URL https:
//openreview.net/forum?id=BkwHObbRZ."
REFERENCES,0.20340586565752128,"Boqing Gong, Kristen Grauman, and Fei Sha. Connecting the dots with landmarks: Discrimina-
tively learning domain-invariant features for unsupervised domain adaptation. In International
Conference on Machine Learning, pp. 222‚Äì230. PMLR, 2013."
REFERENCES,0.2043519394512772,"Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Con-
ference d‚Äôapprentissage CAp, pp. 281, 2005."
REFERENCES,0.2052980132450331,"Jiangfan Han, Ping Luo, and Xiaogang Wang. Deep self-learning from noisy labels. In Proceedings
of the IEEE/CVF International Conference on Computer Vision, pp. 5138‚Äì5147, 2019."
REFERENCES,0.20624408703878902,"Junxian He, Jiatao Gu, Jiajun Shen, and Marc‚ÄôAurelio Ranzato. Revisiting self-training for neural
sequence generation. In International Conference on Learning Representations, 2019."
REFERENCES,0.20719016083254493,"Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. volume 37 of Proceedings of Machine Learning Research, pp.
448‚Äì456, Lille, France, 07‚Äì09 Jul 2015. PMLR."
REFERENCES,0.20813623462630085,"Arthur Jacot, Franck Gabriel, and Cl√©ment Hongler. Neural tangent kernel: Convergence and gen-
eralization in neural networks. In Proceedings of the 32nd International Conference on Neural
Information Processing Systems, 2018."
REFERENCES,0.20908230842005676,"Jacob Kahn, Ann Lee, and Awni Hannun.
Self-training for end-to-end speech recognition.
In
ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP), pp. 7084‚Äì7088. IEEE, 2020."
REFERENCES,0.21002838221381268,"Adam Tauman Kalai, Adam R Klivans, Yishay Mansour, and Rocco A Servedio. Agnostically
learning halfspaces. SIAM Journal on Computing, 37(6):1777‚Äì1805, 2008."
REFERENCES,0.2109744560075686,"Volodymyr Kuleshov, Arun Chaganty, and Percy Liang. Tensor factorization via matrix factoriza-
tion. In ArtiÔ¨Åcial Intelligence and Statistics, pp. 507‚Äì516, 2015."
REFERENCES,0.2119205298013245,"Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. arXiv preprint
arXiv:1610.02242, 2016."
REFERENCES,0.21286660359508042,"Yann A LeCun, L√©on Bottou, Genevieve B Orr, and Klaus-Robert M√ºller. EfÔ¨Åcient backprop. In
Neural networks: Tricks of the trade, pp. 9‚Äì48. Springer, 2012."
REFERENCES,0.21381267738883633,"Dong-Hyun Lee et al. Pseudo-label: The simple and efÔ¨Åcient semi-supervised learning method for
deep neural networks. In Workshop on challenges in representation learning, ICML, volume 3,
2013."
REFERENCES,0.21475875118259224,"Jaehoon Lee, Yasaman Bahri, Roman Novak, Samuel S Schoenholz, Jeffrey Pennington, and Jascha
Sohl-Dickstein. Deep neural networks as gaussian processes. In International Conference on
Learning Representations, 2018."
REFERENCES,0.21570482497634816,Published as a conference paper at ICLR 2022
REFERENCES,0.21665089877010407,"Kibok Lee, Kimin Lee, Jinwoo Shin, and Honglak Lee. Overcoming catastrophic forgetting with un-
labeled data in the wild. In Proceedings of the IEEE/CVF International Conference on Computer
Vision, pp. 312‚Äì321, 2019."
REFERENCES,0.21759697256385999,"Yuanzhi Li and Yingyu Liang. Learning overparameterized neural networks via stochastic gradient
descent on structured data. In Advances in Neural Information Processing Systems, pp. 8157‚Äì
8166, 2018."
REFERENCES,0.2185430463576159,"Yuanzhi Li and Yang Yuan. Convergence analysis of two-layer neural networks with ReLU activa-
tion. In Advances in Neural Information Processing Systems, pp. 597‚Äì607. 2017."
REFERENCES,0.2194891201513718,"Joerg Liebelt and Cordelia Schmid. Multi-view object class detection with a 3d geometric model.
In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp.
1688‚Äì1695. IEEE, 2010."
REFERENCES,0.22043519394512773,"Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with
deep adaptation networks. In International conference on machine learning, pp. 97‚Äì105. PMLR,
2015."
REFERENCES,0.22138126773888364,"Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a
regularization method for supervised and semi-supervised learning. IEEE transactions on pattern
analysis and machine intelligence, 41(8):1979‚Äì1993, 2018."
REFERENCES,0.22232734153263956,"Luca Oneto, Davide Anguita, Alessandro Ghio, and Sandro Ridella. The impact of unlabeled pat-
terns in rademacher complexity theory for kernel classiÔ¨Åers. Advances in neural information
processing systems, 24:585‚Äì593, 2011."
REFERENCES,0.22327341532639547,"Samet Oymak and Talha Cihad Gulcu.
Statistical and algorithmic insights for semi-supervised
learning with self-training. arXiv preprint arXiv:2006.11006, 2020."
REFERENCES,0.22421948912015138,"Samet Oymak and Mahdi Soltanolkotabi. End-to-end learning of a convolutional neural network via
deep tensor decomposition. arXiv preprint arXiv: 1805.06523, 2018."
REFERENCES,0.2251655629139073,"Aditi Raghunathan, Sang Michael Xie, Fanny Yang, John Duchi, and Percy Liang. Understanding
and mitigating the tradeoff between robustness and accuracy. In International Conference on
Machine Learning, pp. 7909‚Äì7919. PMLR, 2020."
REFERENCES,0.2261116367076632,"Scott E Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew
Rabinovich. Training deep neural networks on noisy labels with bootstrapping. In ICLR (Work-
shop), 2015."
REFERENCES,0.22705771050141912,"Philippe Rigollet. Generalization error bounds in semi-supervised classiÔ¨Åcation under the cluster
assumption. Journal of Machine Learning Research, 8(7), 2007."
REFERENCES,0.228003784295175,"Chuck Rosenberg, Martial Hebert, and Henry Schneiderman. Semi-supervised self-training of object
detection models. In Proceedings of the Seventh IEEE Workshops on Application of Computer
Vision (WACV/MOTION‚Äô05)-Volume 1-Volume 01, pp. 29‚Äì36, 2005."
REFERENCES,0.22894985808893092,"Itay Safran and Ohad Shamir. Spurious local minima are common in two-layer relu neural networks.
In International Conference on Machine Learning, pp. 4430‚Äì4438, 2018."
REFERENCES,0.22989593188268684,"Mehdi Sajjadi, Mehran Javanmardi, and Tolga Tasdizen. Regularization with stochastic transfor-
mations and perturbations for deep semi-supervised learning. Advances in neural information
processing systems, 29:1163‚Äì1171, 2016."
REFERENCES,0.23084200567644275,"Henry Scudder. Probability of error of some adaptive pattern-recognition machines. IEEE Transac-
tions on Information Theory, 11(3):363‚Äì371, 1965."
REFERENCES,0.23178807947019867,"Aarti Singh, Robert Nowak, and Jerry Zhu. Unlabeled data: Now it helps, now it doesn‚Äôt. Advances
in neural information processing systems, 21:1513‚Äì1520, 2008."
REFERENCES,0.23273415326395458,"Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A Raffel,
Ekin Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li. Fixmatch: Simplifying semi-supervised
learning with consistency and conÔ¨Ådence. Advances in Neural Information Processing Systems,
33, 2020."
REFERENCES,0.2336802270577105,Published as a conference paper at ICLR 2022
REFERENCES,0.2346263008514664,"Mahdi Soltanolkotabi, Adel Javanmard, and Jason D Lee. Theoretical insights into the optimization
landscape of over-parameterized shallow neural networks. IEEE Transactions on Information
Theory, 65(2):742‚Äì769, 2018."
REFERENCES,0.23557237464522232,"Jong-Chyi Su, Subhransu Maji, and Bharath Hariharan. When does self-supervision improve few-
shot learning? In European Conference on Computer Vision, pp. 645‚Äì666. Springer, 2020."
REFERENCES,0.23651844843897823,"Kevin Tang, Vignesh Ramanathan, Fei-Fei Li, and Daphne Koller.
Shifting weights: Adapting
object detectors from image to video. In Advances in Neural Information Processing Systems, pp.
647‚Äì655, 2012."
REFERENCES,0.23746452223273415,"Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consis-
tency targets improve semi-supervised deep learning results. In Proceedings of the 31st Interna-
tional Conference on Neural Information Processing Systems, pp. 1195‚Äì1204, 2017."
REFERENCES,0.23841059602649006,"Joel A Tropp. User-friendly tail bounds for sums of random matrices. Foundations of computational
mathematics, 12(4):389‚Äì434, 2012."
REFERENCES,0.23935666982024598,"Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain confusion:
Maximizing for domain invariance. arXiv preprint arXiv:1412.3474, 2014."
REFERENCES,0.2403027436140019,"David Vazquez, Antonio M Lopez, Javier Marin, Daniel Ponsa, and David Geronimo. Virtual and
real world adaptation for pedestrian detection. IEEE transactions on pattern analysis and machine
intelligence, 36(4):797‚Äì809, 2013."
REFERENCES,0.2412488174077578,"Roman Vershynin. Introduction to the non-asymptotic analysis of random matrices. arXiv preprint
arXiv:1011.3027, 2010."
REFERENCES,0.24219489120151372,"Gang Wang, Georgios B Giannakis, and Jie Chen. Learning relu networks on linearly separable
data: Algorithm, optimality, and generalization. IEEE Transactions on Signal Processing, 67(9):
2357‚Äì2370, 2019."
REFERENCES,0.24314096499526963,"Colin Wei, Kendrick Shen, Yining Chen, and Tengyu Ma. Theoretical analysis of self-training
with deep networks on unlabeled data. In International Conference on Learning Representations,
2020."
REFERENCES,0.24408703878902555,"Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le. Self-training with noisy student
improves imagenet classiÔ¨Åcation. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pp. 10687‚Äì10698, 2020."
REFERENCES,0.24503311258278146,"I Zeki Yalniz, Herv√© J√©gou, Kan Chen, Manohar Paluri, and Dhruv Mahajan. Billion-scale semi-
supervised learning for image classiÔ¨Åcation. arXiv preprint arXiv:1905.00546, 2019."
REFERENCES,0.24597918637653737,"David Yarowsky. Unsupervised word sense disambiguation rivaling supervised methods. In 33rd
annual meeting of the association for computational linguistics, pp. 189‚Äì196, 1995."
REFERENCES,0.2469252601702933,"Kun Zhang, Bernhard Sch√∂lkopf, Krikamol Muandet, and Zhikun Wang. Domain adaptation under
target and conditional shift. In International Conference on Machine Learning, pp. 819‚Äì827.
PMLR, 2013."
REFERENCES,0.2478713339640492,"Shuai Zhang, Meng Wang, Sijia Liu, Pin-Yu Chen, and Jinjun Xiong. Guaranteed convergence
of training convolutional neural networks via accelerated gradient descent. In 2020 54th An-
nual Conference on Information Sciences and Systems (CISS), 2020a. URL doi:10.1109/
CISS48834.2020.1570627111."
REFERENCES,0.24881740775780511,"Shuai Zhang, Meng Wang, Sijia Liu, Pin-Yu Chen, and Jinjun Xiong. Fast learning of graph neural
networks with guaranteed generalizability:one-hidden-layer case. In 2020 International Confer-
ence on Machine Learning (ICML), 2020b."
REFERENCES,0.24976348155156103,"Shuai Zhang, Meng Wang, Jinjun Xiong, Sijia Liu, and Pin-Yu Chen. Improved linear convergence
of training cnns with generalizability guarantees: A one-hidden-layer case. IEEE Transactions
on Neural Networks and Learning Systems, 32(6):2622‚Äì2635, 2020c."
REFERENCES,0.2507095553453169,Published as a conference paper at ICLR 2022
REFERENCES,0.25165562913907286,"Shuai Zhang, Meng Wang, Sijia Liu, Pin-Yu Chen, and Jinjun Xiong. Why lottery ticket wins? a the-
oretical perspective of sample complexity on pruned neural networks. In Thirty-Ô¨Åfth Conference
on Neural Information Processing Systems (NeurIPS), 2021."
REFERENCES,0.25260170293282874,"Xiao Zhang, Yaodong Yu, Lingxiao Wang, and Quanquan Gu.
Learning one-hidden-layer relu
networks via gradient descent. In The 22nd International Conference on ArtiÔ¨Åcial Intelligence
and Statistics, pp. 1524‚Äì1534. PMLR, 2019."
REFERENCES,0.2535477767265847,"Yuchen Zhang, Jason D. Lee, and Michael I. Jordan. L1-regularized neural networks are improperly
learnable in polynomial time. In Proceedings of The 33rd International Conference on Machine
Learning, volume 48, pp. 993‚Äì1001, 2016."
REFERENCES,0.25449385052034057,"Kai Zhong, Zhao Song, Prateek Jain, Peter L Bartlett, and Inderjit S Dhillon. Recovery guaran-
tees for one-hidden-layer neural networks. In Proceedings of the 34th International Conference
on Machine Learning-Volume 70, pp. 4140‚Äì4149. JMLR. org, https://arxiv.org/abs/1706.03175,
2017."
REFERENCES,0.2554399243140965,"Barret Zoph, Golnaz Ghiasi, Tsung-Yi Lin, Yin Cui, Hanxiao Liu, Ekin Dogus Cubuk, and Quoc Le.
Rethinking pre-training and self-training. Advances in Neural Information Processing Systems,
33, 2020."
REFERENCES,0.2563859981078524,"Yang Zou, Zhiding Yu, BVK Kumar, and Jinsong Wang. Unsupervised domain adaptation for se-
mantic segmentation via class-balanced self-training. In Proceedings of the European conference
on computer vision (ECCV), pp. 289‚Äì305, 2018."
REFERENCES,0.25733207190160834,Published as a conference paper at ICLR 2022
REFERENCES,0.2582781456953642,Appendix
REFERENCES,0.25922421948912017,"A
OVERVIEW OF THE PROOF TECHNIQUES"
REFERENCES,0.26017029328287605,We Ô¨Årst provide an overview of the techniques used in proving Theorems 1 and 2.
REFERENCES,0.261116367076632,"1. Characterization of a proper population risk function. To characterize the performance of the
iterative self-training algorithm via the stochastic gradient descent method, we need Ô¨Årst to deÔ¨Åne
a population risk function such that the following two properties hold. First, the landscape of the
population risk function should be analyzable near {W (‚Ñì)}L
‚Ñì=0. Second, the distance between the
empirical risk function in (1) and the population risk function should be bounded near {W (‚Ñì)}L
‚Ñì=0.
The generalization function deÔ¨Åned in (3), which is widely used in the supervised learning problem
with a sufÔ¨Åcient number of samples, failed the second requirement. To this end, we turn to Ô¨Ånd a
new population risk function deÔ¨Åned in (17), and the illustrations of the population risk function and
objection function are included in Figure 12."
REFERENCES,0.2620624408703879,"2. Local convex region of the population risk function. The purpose is to characterize the it-
erations via the stochastic gradient descent method in the population risk function. To obtain the
local convex region of the population risk function, we Ô¨Årst bound the Hessian of the population risk
function at its global optimal. Then, we utilize Lemma 12 in Appendix H.1 to obtain the Hessian of
the population risk function near the global optimal. The local convex region of the population risk
function is summarized in Lemma 1, and the proof of Lemma 1 is included in Appendix H.1."
REFERENCES,0.2630085146641438,"3. Bound between the population risk and empirical risk functions. After the characterization of
the iterations via the stochastic gradient descent method in the population risk function, we need to
bound the distance between the population risk function and empirical risk function. Therefore, the
behaviors of the iterations via the stochastic gradient descent method in the empirical risk function
can be described by the ones in the population risk function and the distance between these two. The
key lemma is summarized in Lemma 2 (see Appendix H.2), and the proof is included in Appendix
H.2. ùëæùëæ"
REFERENCES,0.2639545884578997,Local convex region
REFERENCES,0.26490066225165565,"of  ÃÇùëìùëìùíüùíünear ùëæùëæ(0,0)"
REFERENCES,0.26584673604541154,"ùëæùëæ‚àó
ùëæùëæ(0,2)
ùëæùëæ(0,1)
ùëæùëæ(0,ùëáùëá)"
REFERENCES,0.2667928098391675,"ùõΩùõΩ(ùëæùëæ0,1 ‚àíùëæùëæ(0,0))"
REFERENCES,0.26773888363292336,ùúÇùúÇùúÇùúÇÃÇùëìùëìùíüùíü . . .
REFERENCES,0.2686849574266793,Population risk function: ùëìùëì(ùëæùëæ; ùëùùëù)
REFERENCES,0.2696310312204352,Objective function: ÃÇùëìùëìùíüùíü(ùëæùëæ)
REFERENCES,0.27057710501419113,ùëæùëæ[ùëùùëù]
REFERENCES,0.271523178807947,Figure 12: The landscapes of the objection function and population risk function.
REFERENCES,0.27246925260170296,"In the following contexts, the details of the iterative self-training algorithm are included in Appendix
B. We then Ô¨Årst provide the proof of Theorem 2 in Appendix E, which can be viewed as a special
case of Theorem 1. Then, with the preliminary knowledge from proving Theorem 2, we turn to
present the full proof of a more general statement summarized in Theorem 3 (see Appendix F),
which is related to Theorem 1. The deÔ¨Ånition and relative proofs of ¬µ and œÅ are all included in
Appendix G. The proofs of preliminary lemmas are included in Appendix H."
REFERENCES,0.27341532639545885,"B
ITERATIVE SELF-TRAINING ALGORITHM"
REFERENCES,0.27436140018921473,"In this section, we implement the details of the mini-batch stochastic gradient descent used in each
stage of the iterative self-training algorithm. After t number of iterations via mini-batch stochastic"
REFERENCES,0.2753074739829707,Published as a conference paper at ICLR 2022
REFERENCES,0.27625354777672656,"gradient descent at ‚Ñì-th stage of self-training algorithm, the learned model is denoted as W (‚Ñì,t). One
can easily check that W (‚Ñì) in the main context is denoted as W (‚Ñì,0) in this section and the following
proofs. Last, the pseudo-code of the iterative self-training algorithm is summarized in Algorithm 1."
REFERENCES,0.2771996215704825,Algorithm 1 Iterative Self-Training Algorithm
REFERENCES,0.2781456953642384,"Input: labeled D = {(xn, yn)}N
n=1, unlabeled data eD = {exm}M
m=1, and gradient step size Œ∑;"
REFERENCES,0.27909176915799433,"Initialization: preliminary teacher model with weights W (0,0);"
REFERENCES,0.2800378429517502,"Partition: randomly and independently pick data from D and eD to form T subsets {Dt}T ‚àí1
t=0 and
{ eDt}T ‚àí1
t=0 , respectively;"
REFERENCES,0.28098391674550616,"for ‚Ñì= 0, 1, ¬∑ ¬∑ ¬∑ , L ‚àí1 do"
REFERENCES,0.28192999053926204,"ym = g(W (‚Ñì,0); exm) for m = 1, 2, ¬∑ ¬∑ ¬∑ , M"
REFERENCES,0.282876064333018,"for t = 0, 1, ¬∑ ¬∑ ¬∑ , T ‚àí1 do"
REFERENCES,0.28382213812677387,"W (‚Ñì,t+1) = W (‚Ñì,t) ‚àíŒ∑ ¬∑ ‚àáÀÜfDt, e
Dt(W (‚Ñì,t)) + Œ≤ ¬∑
 
W (‚Ñì,t) ‚àíW (‚Ñì,t‚àí1)"
REFERENCES,0.2847682119205298,end for
REFERENCES,0.2857142857142857,"W (‚Ñì+1,0) = W (‚Ñì,T )"
REFERENCES,0.28666035950804164,end for
REFERENCES,0.2876064333017975,"C
NOTATIONS"
REFERENCES,0.28855250709555347,"In this section, we Ô¨Årst introduce some important notations that will be used in the following proofs,
and the notations are summarized in Table 1."
REFERENCES,0.28949858088930935,"As shown in Algorithm 1, W (‚Ñì,t) denotes the learned model after t number of iterations via mini-
batch stochastic gradient descent at ‚Ñì-th stage of the iterative self-training algorithm. Given a student
model f
W , the pseudo label for ex ‚ààeD is generated as"
REFERENCES,0.2904446546830653,"Àúy = g(f
W ; ex).
(16)"
REFERENCES,0.2913907284768212,"Further, let W [p] = pW ‚àó+ (1 ‚àíp)W (0,0), we then deÔ¨Åne the population risk function as"
REFERENCES,0.2923368022705771,f(W ; p) = Œª
EX,0.293282876064333,"2 Ex

y‚àó(p) ‚àíg(W ; x)
2
+
eŒª
2 Eex

ey‚àó(p) ‚àíg(W ; ex)
2
,
(17)"
EX,0.29422894985808895,"where y‚àó(p) = g(W [p]; x) with x ‚àºN(0, Œ¥2I) and ey‚àó(p) = g(W [p]; ex) with ex ‚àºN(0, ÀúŒ¥2I).
When p = 1, we have W [p] = W ‚àóand y‚àó(p) = y for data in D."
EX,0.29517502365184484,"Moreover, we use œÉi to denote the i-th largest singular value of W ‚àó. Then, Œ∫ is deÔ¨Åned as œÉ1/œÉK,
and Œ≥ = QK
i=1 œÉi/œÉK. Additionally, to avoid high dimensional tensors, the Ô¨Årst order derivative of
the empirical risk function is deÔ¨Åned in the form of vectorized W as"
EX,0.2961210974456008,"‚àáÀÜf(W ) =
h ‚àÇf ‚àÇw1"
EX,0.29706717123935666,"T
, ‚àÇf ‚àÇw2"
EX,0.2980132450331126,"T
, ¬∑ ¬∑ ¬∑ , ‚àÇf ‚àÇwK"
EX,0.2989593188268685,"T iT
‚ààRdK
(18)"
EX,0.29990539262062443,"with W = [w1, w2, ¬∑ ¬∑ ¬∑ , wK] ‚ààRd√óK. Therefore, the second order derivative of the empiri-
cal risk function is in Rdk√ódk. Similar to (18), the high order derivatives of the population risk
functions are deÔ¨Åned based on vectorized W as well. In addition, without special descriptions,
Œ± = [Œ±T
1 , Œ±T
2 , ¬∑ ¬∑ ¬∑ , Œ±T
K]T stands for any unit vector that in RdK with Œ±j ‚ààRd. Therefore, we have"
EX,0.3008514664143803,"‚à•‚àá2 ÀÜf‚à•2 = max
Œ± ‚à•Œ±T ‚àá2 ÀÜfŒ±‚à•2 = max
Œ±  K
X"
EX,0.30179754020813626,"j=1
Œ±T
j
‚àÇÀÜf
‚àÇwj"
EX,0.30274361400189215,"2
.
(19)"
EX,0.30368968779564803,Published as a conference paper at ICLR 2022
EX,0.304635761589404,"Finally, since we focus on order-wise analysis, some constant numbers will be ignored in the major-
ity of the steps. In particular, we use h1(z) ‚â≥(or ‚â≤, ‚âÇ)h2(z) to denote there exists some positive
constant C such that h1(z) ‚â•(or ‚â§, =)C ¬∑ h2(z) when z ‚ààR is sufÔ¨Åciently large."
EX,0.30558183538315986,Table 3: Some Important Notations
EX,0.3065279091769158,"D = {xn, yn}N
n=1
Labeled dataset with N number of samples;"
EX,0.3074739829706717,"eD = {exm}M
m=1
Unlabeled dataset with M number of samples;"
EX,0.30842005676442763,"Dt = {xn, yn}Nt
n=1 a subset of D with Nt number of labeled data;"
EX,0.3093661305581835,"eDt = {exm}Mt
m=1
a subset of eD with Mt number of unlabeled data;"
EX,0.31031220435193946,"d
Dimension of the input x or ex;"
EX,0.31125827814569534,"K
Number of neurons in the hidden layer;"
EX,0.3122043519394513,"W ‚àó
Weights of the ground truth model;"
EX,0.31315042573320717,"W [p]
W [p] = pW ‚àó+ (1 ‚àíp)W (0,0);"
EX,0.3140964995269631,"W (‚Ñì,t)
Model returned by iterative self-training after t step mini-batch stochastic gradient de-
scent at stage ‚Ñì; W (0,0) is the initial model;
ÀÜfD, e
D( or ÀÜf)
The empirical risk function deÔ¨Åned in (1);"
EX,0.315042573320719,"f(W ; p)
The population risk function deÔ¨Åned in (17);
ÀÜŒª
The value of ŒªŒ¥2/(ŒªŒ¥2 + eŒªÀúŒ¥2);"
EX,0.31598864711447494,"¬µ
The value of
ŒªŒ¥2+eŒªÀúŒ¥2"
EX,0.3169347209082308,ŒªœÅ(Œ¥)+eŒªœÅ(ÀúŒ¥);
EX,0.31788079470198677,"œÉi
The i-th largest singular value of W ‚àó;"
EX,0.31882686849574265,"Œ∫
The value of œÉ1/œÉK;"
EX,0.3197729422894986,"Œ≥
The value of QK
i=1 œÉi/œÉK;"
EX,0.3207190160832545,"q
Some large constant in R+;"
EX,0.3216650898770104,"D
PRELIMINARY LEMMAS"
EX,0.3226111636707663,"We will Ô¨Årst start with some preliminary lemmas. As outlined at the beginning of the supplementary
material, Lemma 1 illustrates the local convex region of the population risk function, and Lemma
2 explains the error bound between the population risk and empirical risk functions. Then, Lemma
3 describes the returned initial model W (0,0) via tensor initialization method (Zhong et al., 2017)
purely using labeled data. Next, Lemma 4 is the well known Weyl‚Äôs inequality in the matrix setting.
Moreover, Lemma 5 is the concentration theorem for independent random matrices. The deÔ¨Ånitions
of the sub-Gaussian and sub-exponential variables are summarized in DeÔ¨Ånitions 1 and 2. Lemmas
6 and 7 serve as the technical tools in bounding matrix norms under the framework of the conÔ¨Ådence
interval."
EX,0.32355723746452225,"Lemma 1. Given any W ‚ààRd√óK, let p satisfy"
EX,0.32450331125827814,"p ‚â≤
œÉK
¬µ2K ¬∑ ‚à•W ‚àíW ‚àó‚à•F
.
(20)"
EX,0.3254493850520341,"Then, we have"
EX,0.32639545884578997,ŒªœÅ(Œ¥) + eŒªœÅ(ÀúŒ¥)
EX,0.3273415326395459,"12Œ∫2Œ≥K2
‚™Ø‚àá2f(W ; p) ‚™Ø7(ŒªŒ¥2 + eŒªÀúŒ¥2)"
EX,0.3282876064333018,"K
.
(21)"
EX,0.32923368022705773,Published as a conference paper at ICLR 2022
EX,0.3301797540208136,"Lemma 2. Let f and ÀÜf be the functions deÔ¨Åned in (17) and (1), respectively. Suppose the pseudo
label is generated through (16) with weights f
W . Then, we have"
EX,0.33112582781456956,‚à•‚àáf(W ) ‚àí‚àáÀÜf(W )‚à•2 ‚â≤ŒªŒ¥2 K r
EX,0.33207190160832545,d log q
EX,0.3330179754020814,"N
¬∑ ‚à•W ‚àíW ‚àó‚à•+
eŒªÀúŒ¥2 K r"
EX,0.3339640491958373,d log q
EX,0.33491012298959316,"M
¬∑ ‚à•W ‚àíf
W ‚à•2 +"
EX,0.3358561967833491,"ŒªŒ¥2 ¬∑
 f
W ‚àíW [p]
+ eŒªÀúŒ¥2 ¬∑
 
W ‚àó‚àíW [p]
2
2K (22)"
EX,0.336802270577105,with probability at least 1 ‚àíq‚àíd.
EX,0.33774834437086093,"Lemma 3 (Initialization, (Zhong et al., 2017)). Assuming the number of labeled data satisÔ¨Åes"
EX,0.3386944181646168,"N ‚â•p2N ‚àó
(23)"
EX,0.33964049195837276,for some large constant q and p ‚àà[ 1
EX,0.34058656575212864,"K , 1], the tensor initialization method, which is summarized in
Appendix I, outputs W (0,0) such that"
EX,0.3415326395458846,"‚à•W (0,0) ‚àíW ‚àó‚à•F ‚â§
œÉK
p ¬∑ c(Œ∫)¬µ2K
(24)"
EX,0.3424787133396405,with probability at least 1 ‚àíq‚àíd.
EX,0.3434247871333964,"Lemma 4 (Weyl‚Äôs inequality, (Bhatia, 2013)). Let B = A + E be a matrix with dimension m √ó m.
Let Œªi(B) and Œªi(A) be the i-th largest eigenvalues of B and A, respectively. Then, we have"
EX,0.3443708609271523,"|Œªi(B) ‚àíŒªi(A)| ‚â§‚à•E‚à•2,
‚àÄ
i ‚àà[m].
(25)"
EX,0.34531693472090824,"Lemma 5 ((Tropp, 2012), Theorem 1.6). Consider a Ô¨Ånite sequence {Zk} of independent, random
matrices with dimensions d1 √ó d2. Assume that such random matrix satisÔ¨Åes"
EX,0.34626300851466413,"E(Zk) = 0
and
‚à•Zk‚à•‚â§R
almost surely.
DeÔ¨Åne
Œ¥2 := max
n
X"
EX,0.34720908230842007,"k
E(ZkZ‚àó
k)
,

X"
EX,0.34815515610217596,"k
E(Z‚àó
kZk)

o
."
EX,0.3491012298959319,"Then for all t ‚â•0, we have Prob ( X k
Zk ‚â•t )"
EX,0.3500473036896878,"‚â§(d1 + d2) exp

‚àít2/2
Œ¥2 + Rt/3 
."
EX,0.3509933774834437,"DeÔ¨Ånition 1 (DeÔ¨Ånition 5.7, (Vershynin, 2010)). A random variable X is called a sub-Gaussian
random variable if it satisÔ¨Åes
(E|X|p)1/p ‚â§c1
‚àöp
(26)"
EX,0.3519394512771996,"for all p ‚â•1 and some constant c1 > 0. In addition, we have"
EX,0.35288552507095555,"Ees(X‚àíEX) ‚â§ec2‚à•X‚à•2
œà2s2
(27)"
EX,0.35383159886471144,"for all s ‚ààR and some constant c2 > 0, where ‚à•X‚à•œÜ2 is the sub-Gaussian norm of X deÔ¨Åned as
‚à•X‚à•œà2 = supp‚â•1 p‚àí1/2(E|X|p)1/p."
EX,0.3547776726584674,"Moreover, a random vector X ‚ààRd belongs to the sub-Gaussian distribution if one-dimensional
marginal Œ±T X is sub-Gaussian for any Œ± ‚ààRd, and the sub-Gaussian norm of X is deÔ¨Åned as
‚à•X‚à•œà2 = sup‚à•Œ±‚à•2=1 ‚à•Œ±T X‚à•œà2."
EX,0.35572374645222327,"DeÔ¨Ånition 2 (DeÔ¨Ånition 5.13, (Vershynin, 2010)). A random variable X is called a sub-exponential
random variable if it satisÔ¨Åes
(E|X|p)1/p ‚â§c3p
(28)"
EX,0.3566698202459792,"for all p ‚â•1 and some constant c3 > 0. In addition, we have"
EX,0.3576158940397351,"Ees(X‚àíEX) ‚â§ec4‚à•X‚à•2
œà1s2
(29)"
EX,0.35856196783349104,"for s ‚â§1/‚à•X‚à•œà1 and some constant c4 > 0, where ‚à•X‚à•œà1 is the sub-exponential norm of X
deÔ¨Åned as ‚à•X‚à•œà1 = supp‚â•1 p‚àí1(E|X|p)1/p."
EX,0.3595080416272469,Published as a conference paper at ICLR 2022
EX,0.36045411542100286,"Lemma 6 (Lemma 5.2, (Vershynin, 2010)). Let B(0, 1) ‚àà{Œ±
‚à•Œ±‚à•2 = 1, Œ± ‚ààRd} denote a
unit ball in Rd. Then, a subset SŒæ is called a Œæ-net of B(0, 1) if every point z ‚ààB(0, 1) can be
approximated to within Œæ by some point Œ± ‚ààB(0, 1), i.e., ‚à•z ‚àíŒ±‚à•2 ‚â§Œæ. Then the minimal
cardinality of a Œæ-net SŒæ satisÔ¨Åes
|SŒæ| ‚â§(1 + 2/Œæ)d.
(30)
Lemma 7 (Lemma 5.3, (Vershynin, 2010)). Let A be an d1 √ó d2 matrix, and let SŒæ(d) be a Œæ-net
of B(0, 1) in Rd for some Œæ ‚àà(0, 1). Then"
EX,0.36140018921475875,"‚à•A‚à•2 ‚â§(1 ‚àíŒæ)‚àí1
max
Œ±1‚ààSŒæ(d1),Œ±2‚ààSŒæ(d2) |Œ±T
1 AŒ±2|.
(31)"
EX,0.3623462630085147,"Lemma 8 (Mean Value Theorem). Let U ‚äÇRn1 be open and f : U ‚àí‚ÜíRn2 be continuously
differentiable, and x ‚ààU, h ‚ààRn1 vectors such that the line segment x + th, 0 ‚â§t ‚â§1 remains
in U. Then we have:"
EX,0.3632923368022706,"f(x + h) ‚àíf(x) =
Z 1"
EX,0.36423841059602646,"0
‚àáf(x + th)dt

¬∑ h,"
EX,0.3651844843897824,where ‚àáf denotes the Jacobian matrix of f.
EX,0.3661305581835383,"E
PROOF OF THEOREM 2"
EX,0.36707663197729423,"With p = 1 in (17), the population risk function is reduced as"
EX,0.3680227057710501,f(W ) = Œª
EX,0.36896877956480606,"2 Ex(y ‚àíg(W ; x)) +
eŒª
2 Eex(ey‚àó‚àíg(W ; ex)),
(32)"
EX,0.36991485335856195,"where y = g(W ‚àó; x) with x ‚àºN(0, Œ¥2I) and ey‚àó= g(W ‚àó; ex) with ex ‚àºN(0, ÀúŒ¥2I). In fact,
(32) can be viewed as the expectation of the empirical risk function in (1) given eym = g(W ‚àó; exm).
Moreover, the ground-truth model W ‚àóis the global optimal to (32) as well. Lemmas 9 and 10
are the special case of Lemmas 1 and 2 with p = 1. The proof of Theorem 2 is followed by the
presentation of the two lemmas."
EX,0.3708609271523179,"The main idea in proving Theorem 2 is to characterize the gradient descent term by the MVT in
Lemma 8 as shown in (36) and (37). The IVT is not directly applied in the empirical risk func-
tion because of its non-smoothness. However, the population risk functions deÔ¨Åned in (17) and
(32), which are the expectations over the Gaussian variables, are smooth. Then, as the distance
‚à•‚àáf(W ) ‚àí‚àáf(W ‚àó)‚à•F is upper bounded by a linear function of ‚à•W ‚àíW ‚àó‚à•F as shown in (47),
we can establish the connection between ‚à•W (‚Ñì,t+1) ‚àíW ‚àó‚à•F and ‚à•W (‚Ñì,t) ‚àíW ‚àó‚à•F as shown in
(50). Finally, by mathematical induction over ‚Ñìand t, one can characterize ‚à•W (L,0) ‚àíW ‚àó‚à•F by
‚à•W (0,0) ‚àíW ‚àó‚à•F as shown in (52), which completes the whole proof."
EX,0.3718070009460738,"Lemma 9 (Lemma 1 with p = 1). Let f and ÀÜf are the functions deÔ¨Åned in (32) and (1), respectively.
Then, for any W that satisÔ¨Åes,
‚à•W ‚àíW ‚àó‚à•F ‚â§œÉK"
EX,0.3727530747398297,"¬µ2K ,
(33)"
EX,0.3736991485335856,"we have
ŒªœÅ(Œ¥) + eŒªœÅ(ÀúŒ¥)"
EX,0.37464522232734154,"12Œ∫2Œ≥K2
‚™Ø‚àá2f(W ) ‚™Ø7(ŒªŒ¥2 + eŒªÀúŒ¥2)"
EX,0.37559129612109743,"K
.
(34)"
EX,0.37653736991485337,"Lemma 10 (Lemma 2 with p = 1). Let f and ÀÜf be the functions deÔ¨Åned in (32) and (1), respectively.
Suppose the pseudo label is generated through (16) with weights f
W . Then, we have"
EX,0.37748344370860926,"‚à•‚àáf(W ) ‚àí‚àáÀÜf(W )‚à•2 ‚â≤
ŒªŒ¥2 K r"
EX,0.3784295175023652,d log q
EX,0.3793755912961211,"N
+ (1 ‚àíŒª)ÀúŒ¥2 K r"
EX,0.380321665089877,d log q M
EX,0.3812677388836329,"
¬∑ ‚à•W ‚àíW ‚àó‚à•2"
EX,0.38221381267738885,+ (1 ‚àíŒª)ÀúŒ¥2 K r
EX,0.38315988647114474,"d log q M
+ 1 2"
EX,0.3841059602649007,"
¬∑ ‚à•f
W ‚àíW ‚àó‚à•2 (35)"
EX,0.38505203405865657,with probability at least 1 ‚àíq‚àíd.
EX,0.3859981078524125,Published as a conference paper at ICLR 2022
EX,0.3869441816461684,"Proof of Theorem 2. From Algorithm 1, in the ‚Ñì-th outer loop, we have"
EX,0.38789025543992434,"W (‚Ñì,t+1) =W (‚Ñì,t) ‚àíŒ∑‚àáÀÜfDt, e
Dt(W (‚Ñì,t)) + Œ≤(W (‚Ñì,t) ‚àíW (‚Ñì,t‚àí1))"
EX,0.3888363292336802,"=W (‚Ñì,t) ‚àíŒ∑‚àáf(W (‚Ñì,t)) + Œ≤(W (‚Ñì,t) ‚àíW (‚Ñì,t‚àí1))"
EX,0.38978240302743616,"+ Œ∑ ¬∑
 
‚àáf(W (‚Ñì,t)) ‚àí‚àáÀÜfDt, e
Dt(W (‚Ñì,t))

. (36)"
EX,0.39072847682119205,"Since ‚àáf is a smooth function and W ‚àóis a local (global) optimal to f, then we have"
EX,0.391674550614948,"‚àáf(W (‚Ñì,t)) =‚àáf(W (‚Ñì,t)) ‚àí‚àáf(W ‚àó) = Z 1"
EX,0.3926206244087039,"0
‚àá2f

W (‚Ñì,t) + u ¬∑ (W (‚Ñì,t) ‚àíW ‚àó)

du ¬∑ (W (‚Ñì,t) ‚àíW ‚àó),
(37)"
EX,0.3935666982024598,"where the last equality comes from MVT in Lemma 8. For notational convenience, we use H(‚Ñì,t)
to denote the integration as"
EX,0.3945127719962157,"H(‚Ñì,t) :=
Z 1"
EX,0.3954588457899716,"0
‚àá2f

W (‚Ñì,t) + u ¬∑ (W (‚Ñì,t) ‚àíW ‚àó)

du.
(38)"
EX,0.39640491958372753,"Then, we have
""
W (‚Ñì,t+1) ‚àíW ‚àó"
EX,0.3973509933774834,"W (‚Ñì,t) ‚àíW ‚àó # ="
EX,0.39829706717123936,"""
I ‚àíŒ∑H(‚Ñì,t)
Œ≤I I
0"
EX,0.39924314096499525,"# ""
W (‚Ñì,t) ‚àíW ‚àó"
EX,0.4001892147587512,"W (‚Ñì,t‚àí1) ‚àíW ‚àó # + Œ∑"
EX,0.4011352885525071,"""
‚àáf(W (‚Ñì,t)) ‚àí‚àáÀÜfDt, e
Dt(W (‚Ñì,t)) 0 # . (39)"
EX,0.402081362346263,"Let H(‚Ñì,t) = SŒõST be the eigen-decomposition of H(‚Ñì,t). Then, we deÔ¨Åne"
EX,0.4030274361400189,A(Œ≤) :=
EX,0.40397350993377484,"""
ST
0"
ST,0.40491958372753073,"0
ST # A(Œ≤) ""
S
0"
S,0.40586565752128667,"0
S # ="
S,0.40681173131504256,"""
I ‚àíŒ∑Œõ + Œ≤I
Œ≤I I
0 #"
S,0.4077578051087985,".
(40) Since ""
S
0"
S,0.4087038789025544,"0
S"
S,0.4096499526963103,"# ""
ST
0"
ST,0.4105960264900662,"0
ST # = ""
I
0"
I,0.41154210028382215,"0
I #"
I,0.41248817407757804,", we know A(Œ≤) and"
I,0.413434247871334,"""
I ‚àíŒ∑Œõ + Œ≤I
Œ≤I I
0 #"
I,0.41438032166508987,share the same
I,0.4153263954588458,"eigenvalues. Let Œ≥(Œõ)
i
be the i-th eigenvalue of ‚àá2f( b
w(t)), then the corresponding i-th eigenvalue
of (40), denoted by Œ≥(A)
i
, satisÔ¨Åes"
I,0.4162724692526017,"(Œ≥(A)
i
(Œ≤))2 ‚àí(1 ‚àíŒ∑Œ≥(Œõ)
i
+ Œ≤)Œ≥(A)
i
(Œ≤) + Œ≤ = 0.
(41)"
I,0.41721854304635764,"By simple calculation, we have"
I,0.4181646168401135,"|Œ≥(A)
i
(Œ≤)| = Ô£±
Ô£¥
Ô£≤ Ô£¥
Ô£≥"
I,0.41911069063386946,"‚àöŒ≤,
if
Œ≤ ‚â•
 
1 ‚àí
q"
I,0.42005676442762535,"Œ∑Œ≥(Œõ)
i
2, 1
2"
I,0.4210028382213813,"(1 ‚àíŒ∑Œ≥(Œõ)
i
+ Œ≤) +
q"
I,0.4219489120151372,"(1 ‚àíŒ∑Œ≥(Œõ)
i
+ Œ≤)2 ‚àí4Œ≤
 , otherwise.
(42)"
I,0.4228949858088931,"SpeciÔ¨Åcally, we have"
I,0.423841059602649,"Œ≥(A)
i
(0) > Œ≥(A)
i
(Œ≤),
for
‚àÄŒ≤ ‚àà
 
0, (1 ‚àíŒ∑Œ≥(Œõ)
i
)2
,
(43)"
I,0.4247871333964049,"and Œ≥(A)
i
achieves the minimum Œ≥(A)‚àó
i
=
1 ‚àí
q"
I,0.42573320719016083,"Œ∑Œ≥(Œõ)
i
 when Œ≤ =

1 ‚àí
q"
I,0.4266792809839167,"Œ∑Œ≥(Œõ)
i
2
. From Lemma"
I,0.42762535477767266,"9, for any a ‚ààRd with ‚à•a‚à•2 = 1, we have"
I,0.42857142857142855,"aT ‚àáf(W (‚Ñì,t))a =
Z 1"
I,0.4295175023651845,"0
aT ‚àá2f

W (‚Ñì,t) + u ¬∑ (W (‚Ñì,t) ‚àíW ‚àó)

adu ‚â§
Z 1"
I,0.4304635761589404,"0
Œ≥max‚à•a‚à•2
2du = Œ≥max,"
I,0.4314096499526963,"aT ‚àáf(W (‚Ñì,t))a =
Z 1"
I,0.4323557237464522,"0
aT ‚àá2f

W (‚Ñì,t) + u ¬∑ (W (‚Ñì,t) ‚àíW ‚àó)

adu ‚â•
Z 1"
I,0.43330179754020814,"0
Œ≥min‚à•a‚à•2
2du = Œ≥min, (44)"
I,0.43424787133396403,Published as a conference paper at ICLR 2022
I,0.43519394512771997,where Œ≥max = 7(ŒªŒ¥2+eŒªÀúŒ¥2)
I,0.43614001892147586,"K
, and Œ≥min = ŒªœÅ(Œ¥)+eŒªœÅ(ÀúŒ¥)"
I,0.4370860927152318,"12Œ∫2Œ≥K2 . Therefore, we have"
I,0.4380321665089877,"Œ≥(Œõ)
min = ŒªœÅ(Œ¥) + eŒªœÅ(ÀúŒ¥)"
I,0.4389782403027436,"12Œ∫2Œ≥K2
,
and
Œ≥(Œõ)
max = 7(ŒªŒ¥2 + eŒªÀúŒ¥2)"
I,0.4399243140964995,"K
.
(45)"
I,0.44087038789025546,"Thus, we can select Œ∑ =
 
1
‚àö"
I,0.44181646168401134,"Œ≥(Œõ)
max+
q"
I,0.4427625354777673,"Œ≥(Œõ)
min"
I,0.44370860927152317,"2, and ‚à•A(Œ≤)‚à•2 can be bounded by"
I,0.4446546830652791,"min
Œ≤ ‚à•A(Œ≤)‚à•2 ‚â§1 ‚àí s"
I,0.445600756859035, ŒªœÅ(Œ¥) + eŒªœÅ(ÀúŒ¥)
I,0.44654683065279094,"12Œ∫2Œ≥K2

/
 
2 ¬∑ 7(ŒªŒ¥2 + eŒªÀúŒ¥2) K
"
I,0.4474929044465468,"=1 ‚àí
¬µ(Œ¥, ÀúŒ¥)
p"
I,0.44843897824030277,"168Œ∫2Œ≥K
, (46)"
I,0.44938505203405865,"where ¬µ(Œ¥, ÀúŒ¥) =

ŒªœÅ(Œ¥)+eŒªœÅ(ÀúŒ¥)"
I,0.4503311258278146,"ŒªŒ¥2+eŒªÀúŒ¥2
1/2
."
I,0.4512771996215705,"From Lemma 10, we have"
I,0.4522232734153264,"‚à•‚àáf(W (‚Ñì,t)) ‚àí‚àáÀÜf(W (‚Ñì,t))‚à•2 =
ŒªŒ¥2 K r"
I,0.4531693472090823,d log q
I,0.45411542100283825,"Nt
+
eŒªÀúŒ¥2 K r"
I,0.45506149479659413,d log q Mt
I,0.45600756859035,"
¬∑ ‚à•W (‚Ñì,t) ‚àíW ‚àó‚à•2"
I,0.45695364238410596,"+
eŒªÀúŒ¥2 K r"
I,0.45789971617786185,d log q
I,0.4588457899716178,"Mt
+ 1 2"
I,0.4597918637653737,"
¬∑ ‚à•W (‚Ñì,0) ‚àíW ‚àó‚à•2. (47)"
I,0.4607379375591296,"Given Œµ > 0 and ÀúŒµ > 0 with Œµ + ÀúŒµ < 1, let"
I,0.4616840113528855,Œ∑ ¬∑ ŒªŒ¥2 K r
I,0.46263008514664145,d log q
I,0.46357615894039733,"Nt
‚â§
Œµ¬µ(Œ¥, ÀúŒ¥)
p"
I,0.4645222327341533,"168Œ∫2Œ≥K
,"
I,0.46546830652790916,"and
Œ∑ ¬∑
eŒªÀúŒ¥2 K r"
I,0.4664143803216651,d log q
I,0.467360454115421,"Mt
‚â§
ÀúŒµ¬µ(Œ¥, ÀúŒ¥)
p"
I,0.46830652790917693,"168Œ∫2Œ≥K
, (48)"
I,0.4692526017029328,where we need
I,0.47019867549668876,"Nt ‚â•Œµ‚àí2¬µ‚àí2 
ŒªŒ¥2"
I,0.47114474929044464,"ŒªŒ¥2 + eŒªÀúŒ¥2
2Œ∫2Œ≥K3d log q,"
I,0.4720908230842006,"and
Mt ‚â•ÀúŒµ‚àí2¬µ‚àí2 
eŒªÀúŒ¥2"
I,0.47303689687795647,"ŒªŒ¥2 + eŒªÀúŒ¥2
2Œ∫2Œ≥K3d log q. (49)"
I,0.4739829706717124,"Therefore, from (46), (47) and (48), we have"
I,0.4749290444654683,"‚à•W (‚Ñì,t+1) ‚àíW ‚àó‚à•2"
I,0.47587511825922424,"‚â§

1 ‚àí(1 ‚àíŒµ ‚àíÀúŒµ)¬µ(Œ¥, ÀúŒ¥)
p"
I,0.4768211920529801,168Œ∫2Œ≥K
I,0.47776726584673607,"
‚à•W (‚Ñì,t) ‚àíW ‚àó‚à•2 + Œ∑ ¬∑
eŒªÀúŒ¥2 K r"
I,0.47871333964049195,d log q
I,0.4796594134342479,"Mt
+ 1 2"
I,0.4806054872280038,"
¬∑ ‚à•W (‚Ñì,0) ‚àíW ‚àó‚à•2"
I,0.4815515610217597,"‚â§

1 ‚àí(1 ‚àíŒµ ‚àíÀúŒµ)¬µ(Œ¥, ÀúŒ¥)
p"
I,0.4824976348155156,168Œ∫2Œ≥K
I,0.48344370860927155,"
‚à•W (‚Ñì,t) ‚àíW ‚àó‚à•2 + Œ∑ ¬∑
eŒªÀúŒ¥2"
I,0.48438978240302744,"K ‚à•W (‚Ñì,0) ‚àíW ‚àó‚à•2 (50)"
I,0.4853358561967833,"when M ‚â•4d log q. By mathematical induction on (50) over t, we have"
I,0.48628192999053926,"‚à•W (‚Ñì,t) ‚àíW ‚àó‚à•2"
I,0.48722800378429515,"‚â§

1 ‚àí(1 ‚àíŒµ ‚àíÀúŒµ)¬µ
p"
I,0.4881740775780511,168Œ∫2Œ≥K
I,0.489120151371807,"t
¬∑ ‚à•W (‚Ñì,0) ‚àíW ‚àó‚à•2 + p"
I,0.4900662251655629,"168Œ∫2Œ≥K
(1 ‚àíŒµ ‚àíÀúŒµ)¬µ ¬∑ ‚àö K"
I,0.4910122989593188,"14(ŒªŒ¥2 + eŒªÀúŒ¥2)
¬∑
eŒªÀúŒ¥2"
I,0.49195837275307475,"K ‚à•W (‚Ñì,0) ‚àíW ‚àó‚à•2"
I,0.49290444654683063,"‚â§

1 ‚àí(1 ‚àíŒµ ‚àíÀúŒµ)¬µ
p"
I,0.4938505203405866,"168Œ∫2Œ≥K t
+ p"
I,0.49479659413434246,Œ∫2Œ≥eŒªÀúŒ¥2
I,0.4957426679280984,(1 ‚àíŒµ ‚àíÀúŒµ)¬µ(ŒªŒ¥2 + eŒªÀúŒ¥2)
I,0.4966887417218543,"
¬∑ ‚à•W (‚Ñì,0) ‚àíW ‚àó‚à•2 (51)"
I,0.49763481551561023,Published as a conference paper at ICLR 2022
I,0.4985808893093661,"By mathematical induction on (51) over ‚Ñì, we have"
I,0.49952696310312206,"‚à•W (‚Ñì,T ) ‚àíW ‚àó‚à•2"
I,0.5004730368968779,"‚â§

1 ‚àí(1 ‚àíŒµ ‚àíÀúŒµ)¬µ
p"
I,0.5014191106906338,"168Œ∫2Œ≥K T
+ p"
I,0.5023651844843898,Œ∫2Œ≥eŒªÀúŒ¥2
I,0.5033112582781457,(1 ‚àíŒµ ‚àíÀúŒµ)¬µ(ŒªŒ¥2 + eŒªÀúŒ¥2)
I,0.5042573320719016,"‚Ñì
¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2
(52)"
I,0.5052034058656575,"F
PROOF OF THEOREM 1"
I,0.5061494796594135,"Instead of proving Theorem 1, we turn to prove a stronger version, as shown in Theorem 3. One can
verify that Theorem 1 is a special case of Theorem 3 by selecting ÀÜŒª in the order of p and eŒµ is in the
order of (2p ‚àí1)."
I,0.5070955534531694,"The major idea in proving Theorem 3 is similar to that of Theorem 2. The Ô¨Årst step is to characterize
the gradient descent term on the population risk function by the MVT in Lemma 8 as shown in
(58) and (59). Then, the connection between ‚à•W (‚Ñì+1,0) ‚àíW [p]‚à•F and ‚à•W (‚Ñì,0) ‚àíW [p]‚à•F are
characterized in (64). Compared with proving Theorem 2, where the induction over ‚Ñìholds naturally
with large size of labeled data, the induction over ‚Ñìrequires a proper value of p as shown in (69). By
induction over ‚Ñìon (64), the relative error ‚à•W (L,0) ‚àíW [p]‚à•F can be characterized by ‚à•W (0,0) ‚àí
W [p]‚à•F as shown in (71)."
I,0.5080416272469253,"Theorem 3. Suppose the initialization W (0,0) satisÔ¨Åes with"
I,0.5089877010406811,"|p ‚àíÀÜŒª| ‚â§2(1 ‚àíeŒµ)p ‚àí1 ¬µ
‚àö K (53)"
I,0.5099337748344371,"for some constant eŒµ ‚àà(0, 1/2), where"
I,0.510879848628193,"ÀÜŒª :=
ŒªŒ¥2"
I,0.5118259224219489,"ŒªŒ¥2 + eŒªÀúŒ¥2 =
 
N
Œ∫2Œ≥K3¬µ2d log q
 1"
I,0.5127719962157048,"2
(54) and"
I,0.5137180700094608,"¬µ = ¬µ(Œ¥, ÀúŒ¥) =
ŒªŒ¥2 + eŒªÀúŒ¥2"
I,0.5146641438032167,"ŒªœÅ(Œ¥) + eŒªœÅ(ÀúŒ¥)
.
(55)"
I,0.5156102175969726,"Then, if the number of samples in eD further satisÔ¨Åes"
I,0.5165562913907285,"M ‚â≥ÀúŒµ‚àí2Œ∫2Œ≥¬µ2 
1 ‚àíÀÜŒª
2K3d log q,
(56)"
I,0.5175023651844843,"the iterates {W (‚Ñì,t)}L,T
‚Ñì,t=0 converge to W [p] with p satisÔ¨Åes (53) as"
I,0.5184484389782403,"lim
T ‚Üí‚àû‚à•W (‚Ñì,T ) ‚àíW [p]‚à•2"
I,0.5193945127719962,"‚â§
1
1 ‚àíÀúŒµ ¬∑

1 ‚àíp‚àó+ ¬µ
‚àö"
I,0.5203405865657521,"K
(ÀÜŒª ‚àíp‚àó)


¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2 +
ÀúŒµ
(1 ‚àíÀúŒµ) ¬∑ ‚à•W (‚Ñì,0) ‚àíW [p]‚à•2, (57)"
I,0.521286660359508,with probability at least 1 ‚àíq‚àíd.
I,0.522232734153264,"Proof of Theorem 3. From Algorithm 1, in the ‚Ñì-th outer loop, we have"
I,0.5231788079470199,"W (‚Ñì,t+1) =W (‚Ñì,t) ‚àíŒ∑‚àáÀÜfDt, e
Dt(W (‚Ñì,t)) + Œ≤(W (‚Ñì,t) ‚àíW (‚Ñì,t‚àí1))"
I,0.5241248817407758,"=W (‚Ñì,t) ‚àíŒ∑‚àáf(W (‚Ñì,t)) + Œ≤(W (‚Ñì,t) ‚àíW (‚Ñì,t‚àí1))"
I,0.5250709555345316,"+ Œ∑ ¬∑

‚àáf(W (‚Ñì,t)) ‚àí‚àáÀÜfDt, e
Dt(W (‚Ñì,t))

(58)"
I,0.5260170293282876,"Since ‚àáf is a smooth function and W [p] is a local (global) optimal to f, then we have"
I,0.5269631031220435,"‚àáf(W (‚Ñì,t)) =‚àáf(W (‚Ñì,t)) ‚àí‚àáf(W [p]) =
Z 1"
I,0.5279091769157994,"0
‚àá2f

W (‚Ñì,t) + u ¬∑ (W (‚Ñì,t) ‚àíW [p])

du ¬∑ (W (‚Ñì,t) ‚àíW [p]),
(59)"
I,0.5288552507095553,Published as a conference paper at ICLR 2022
I,0.5298013245033113,where the last equality comes from Lemma 8.
I,0.5307473982970672,"Similar to the proof of Theorem 2, we have"
I,0.5316934720908231,"‚à•W (‚Ñì,t+1)‚àíW [p]‚à•2 ‚â§‚à•A(Œ≤)‚à•2¬∑‚à•W (‚Ñì,t)‚àíW [p]‚à•2+Œ∑¬∑‚à•‚àáf(W (‚Ñì,t))‚àí‚àáÀÜfDt, e
Dt(W (‚Ñì,t))‚à•2. (60)"
I,0.532639545884579,"From Lemma 2, we have"
I,0.533585619678335,"‚à•‚àáf(W (‚Ñì,t)) ‚àí‚àáÀÜf(W (‚Ñì,t))‚à•2 ‚â≤ŒªŒ¥2 K r"
I,0.5345316934720908,d log q
I,0.5354777672658467,"Nt
¬∑ ‚à•W (‚Ñì,t) ‚àíW ‚àó‚à•+
eŒªÀúŒ¥2 K r"
I,0.5364238410596026,d log q
I,0.5373699148533586,"Mt
¬∑ ‚à•W (‚Ñì,t) ‚àíW (‚Ñì,0)‚à•2 +"
I,0.5383159886471145,"ŒªŒ¥2 ¬∑ (W (0,0) ‚àíW [p]) ‚àíeŒªÀúŒ¥2 ¬∑ (W ‚àó‚àíW [p]) K (61)"
I,0.5392620624408704,"When ‚Ñì= 0, following the similar steps from (41) to (46), we have"
I,0.5402081362346263,"‚à•‚àáf(W (‚Ñì,t)) ‚àí‚àáÀÜf(W (‚Ñì,t))‚à•2 ‚â≤ŒªŒ¥2 K r"
I,0.5411542100283823,d log q
I,0.5421002838221382,"Nt
¬∑ ‚à•W (‚Ñì,t) ‚àíW [p]‚à•+
eŒªÀúŒ¥2 K r"
I,0.543046357615894,d log q
I,0.5439924314096499,"Mt
¬∑ ‚à•W (‚Ñì,t) ‚àíW [p]‚à•2 + ŒªŒ¥2 K r"
I,0.5449385052034059,d log q
I,0.5458845789971618,"Nt
¬∑ ‚à•W ‚àó‚àíW [p]‚à•+
eŒªÀúŒ¥2 K r"
I,0.5468306527909177,d log q
I,0.5477767265846736,"Mt
¬∑ ‚à•W (0,0) ‚àíW [p]‚à•2 +"
I,0.5487228003784295,ŒªŒ¥2 ¬∑ (1 ‚àíp) ‚àíeŒªÀúŒ¥2 ¬∑ p
I,0.5496688741721855,"K
¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2 (62) and"
I,0.5506149479659413,"‚à•W (‚Ñì,t+1) ‚àíW [p]‚à•2"
I,0.5515610217596972,"‚â§

1 ‚àí
1 ‚àíÀúŒµ"
I,0.5525070955534531,"¬µ(Œ¥, ÀúŒ¥)
p"
I,0.5534531693472091,154Œ∫2Œ≥K
I,0.554399243140965,"
¬∑ ‚à•W (‚Ñì,t) ‚àíW [p]‚à•2"
I,0.5553453169347209,"+ Œ∑ ¬∑
ŒªŒ¥2(1 ‚àíp) K r"
I,0.5562913907284768,"d log q Nt
+"
I,0.5572374645222328,ŒªŒ¥2 ¬∑ (1 ‚àíp) ‚àíeŒªÀúŒ¥2 ¬∑ p K
I,0.5581835383159887,"
¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2"
I,0.5591296121097445,"+ Œ∑ ¬∑ ÀúŒµeŒªÀúŒ¥2 ¬∑ p K
¬∑ r"
I,0.5600756859035004,d log q
I,0.5610217596972564,"Mt
‚à•W (0,0) ‚àíW ‚àó‚à•2. (63)"
I,0.5619678334910123,"Therefore, we have"
I,0.5629139072847682,"lim
T ‚Üí‚àû‚à•W (‚Ñì,T ) ‚àíW [p]‚à•2 ‚â§¬µ
p"
I,0.5638599810785241,154Œ∫2Œ≥K
I,0.5648060548722801,"1 ‚àíÀúŒµ
¬∑ Œ∑ ¬∑
hŒªŒ¥2(1 ‚àíp) K r"
I,0.565752128666036,"d log q Nt
+"
I,0.5666982024597919,ŒªŒ¥2 ¬∑ (1 ‚àíp) ‚àíeŒªÀúŒ¥2 ¬∑ p K
I,0.5676442762535477,"
¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2"
I,0.5685903500473037,"+ ÀúŒµeŒªÀúŒ¥2 ¬∑ p K
¬∑ r"
I,0.5695364238410596,d log q
I,0.5704824976348155,"Mt
¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2
i ‚â§¬µ
p"
I,0.5714285714285714,154Œ∫2Œ≥K
I,0.5723746452223274,"1 ‚àíÀúŒµ
¬∑
K"
I,0.5733207190160833,"14(ŒªŒ¥2 + eŒªÀúŒ¥2)
¬∑
hŒªŒ¥2(1 ‚àíp) K r"
I,0.5742667928098392,"d log q Nt
+"
I,0.575212866603595,ŒªŒ¥2 ¬∑ (1 ‚àíp) ‚àíeŒªÀúŒ¥2 ¬∑ p K 
I,0.5761589403973509,"¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2 + ÀúŒµeŒªÀúŒ¥2 ¬∑ p K
¬∑ r"
I,0.5771050141911069,d log q
I,0.5780510879848628,"Mt
¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2
i"
I,0.5789971617786187,"‚âÉ
1
1 ‚àíÀúŒµ ¬∑

1 ‚àíp +
‚àö"
I,0.5799432355723746,"K ¬∑
(1 ‚àíp)¬µÀÜŒª ‚àíp¬µ(1 ‚àíÀÜŒª)


¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2"
I,0.5808893093661306,"+
ÀúŒµp
(1 ‚àíÀúŒµ) ¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2"
I,0.5818353831598865,"=
1
1 ‚àíÀúŒµ ¬∑

1 ‚àíp + ¬µ
‚àö"
I,0.5827814569536424,"K
bŒª ‚àíp


¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2 +
ÀúŒµp
(1 ‚àíÀúŒµ) ¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2, (64)"
I,0.5837275307473982,"where ÀÜŒª =
ŒªŒ¥2"
I,0.5846736045411542,ŒªŒ¥2+eŒªÀúŒ¥2 .
I,0.5856196783349101,Published as a conference paper at ICLR 2022
I,0.586565752128666,"To guarantee the convergence in the outer loop, we require"
I,0.5875118259224219,"lim
T ‚Üí‚àû‚à•W (‚Ñì,T ) ‚àíW [p]‚à•2 ‚â§‚à•W (0,0) ‚àíW [p]‚à•2 = p‚à•W (0,0) ‚àíW ‚àó‚à•2,"
I,0.5884578997161779,"and
lim
T ‚Üí‚àû‚à•W (‚Ñì,T ) ‚àíW ‚àó‚à•2 ‚â§‚à•W (0,0) ‚àíW ‚àó‚à•2.
(65)"
I,0.5894039735099338,Since we have
I,0.5903500473036897,"‚à•W (‚Ñì,T ) ‚àíW [p]‚à•2 ‚â§‚à•W (‚Ñì,T ) ‚àíW ‚àó‚à•2 + ‚à•W ‚àó‚àíW [p]‚à•2"
I,0.5912961210974456,"=‚à•W (‚Ñì,T ) ‚àíW ‚àó‚à•2 + (1 ‚àíp) ¬∑ ‚à•W ‚àó‚àíW (0,0)‚à•2,
(66)"
I,0.5922421948912016,it is clear that (65) holds if and only if
I,0.5931882686849574,"1
1 ‚àíÀúŒµ ¬∑

1 ‚àíp + eŒµp + ¬µ
‚àö"
I,0.5941343424787133,"K
ÀÜŒª ‚àíp


+ 1 ‚àíp ‚â§1.
(67)"
I,0.5950804162724692,"To guarantee the iterates strictly converges to the desired point, we let"
I,0.5960264900662252,"1
1 ‚àíÀúŒµ ¬∑

1 ‚àíp + eŒµp + ¬µ
‚àö"
I,0.5969725638599811,"K
ÀÜŒª ‚àíp


+ 1 ‚àíp ‚â§1 ‚àí1"
I,0.597918637653737,"C
(68)"
I,0.5988647114474929,"for some larger constant C, which is equivalent to"
I,0.5998107852412489,"|p ‚àíÀÜŒª| ‚â§2(1 ‚àíeŒµ)p ‚àí1 ¬µ
‚àö"
I,0.6007568590350048,"K
.
(69)"
I,0.6017029328287606,"To make the bound in (69) meaningful, we need"
I,0.6026490066225165,"p ‚â•
1
2(1 ‚àíeŒµ).
(70)"
I,0.6035950804162725,"When ‚Ñì> 1, following similar steps in (64), we have"
I,0.6045411542100284,"lim
T ‚Üí‚àû‚à•W (‚Ñì,T ) ‚àíW [p]‚à•2"
I,0.6054872280037843,"‚â§
1
1 ‚àíÀúŒµ ¬∑

1 ‚àíp + ¬µ
‚àö"
I,0.6064333017975402,"K
(ÀÜŒª ‚àíp)


¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2 +
ÀúŒµp
1 ‚àíÀúŒµ ¬∑ ‚à•W (‚Ñì,0) ‚àíW [p]‚à•2,
(71)"
I,0.6073793755912961,"Given (69) holds, from (71), we have"
I,0.6083254493850521,"lim
L‚Üí‚àû,T ‚Üí‚àû‚à•W (L,T ) ‚àíW [p]‚à•2"
I,0.609271523178808,"‚â§
1
1 ‚àíeŒµ ¬∑

1 ‚àíp + ¬µ
‚àö"
I,0.6102175969725638,"K
ÀÜŒª ‚àíp


¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2"
I,0.6111636707663197,"‚â§
1
1 ‚àíeŒµ ¬∑

1 ‚àíp + ¬µ
‚àö"
I,0.6121097445600757,"K
ÀÜŒª ‚àíp


¬∑ ‚à•W (0,0) ‚àíW ‚àó‚à•2. (72)"
I,0.6130558183538316,"G
DEFINITION AND RELATIVE PROOFS OF œÅ"
I,0.6140018921475875,"In this section, the formal deÔ¨Ånition of œÅ is included in DeÔ¨Ånition 3, and a corresponding claim about
œÅ is summarized in Lemma 11. One can quickly check that the ReLU activation function satisÔ¨Åes
the conditions in Lemma 11."
I,0.6149479659413434,"The major idea in proving Lemma 11 is to show Hr(Œ¥) and Jr(Œ¥) in DeÔ¨Ånition 3 are in the order of
Œ¥r when Œ¥ is small.
DeÔ¨Ånition 3. Let Hr(Œ¥) = Ez‚àºN(0,Œ¥2)
 
œÜ‚Ä≤(œÉKz)zr
and Jr(Œ¥) = Ez‚àºN(0,Œ¥2)
 
œÜ‚Ä≤2(œÉKz)zr
. Then,
œÅ = œÅ(Œ¥) is deÔ¨Åned as"
I,0.6158940397350994,"œÅ(Œ¥) = min
n
J0(Œ¥) ‚àíH2
0(Œ¥) ‚àíH2
1(Œ¥), J2(Œ¥) ‚àíH2
1(Œ¥) ‚àíH2
2(Œ¥), H0(Œ¥) ¬∑ H2(Œ¥) ‚àíH2
1(Œ¥)
o
, (73)"
I,0.6168401135288553,where œÉK is the minimal singular value of W ‚àó.
I,0.6177861873226111,Published as a conference paper at ICLR 2022
I,0.618732261116367,"Lemma 11 (Order analysis of œÅ). If œÅ(Œ¥) > 0 for Œ¥ ‚àà(0, Œæ) for some positive constant Œæ and the
sub-gradient of œÅ(Œ¥) at 0 can be non-zero, then œÅ(Œ¥) = Œò(Œ¥2) when Œ¥ ‚Üí0+. Typically, for ReLU
activation function, ¬µ in (5) is a Ô¨Åxed constant for all Œ¥, ÀúŒ¥ ‚â§1."
I,0.619678334910123,"Proof of Lemma 11 . From DeÔ¨Ånition 3, we know that Hr(Œ¥) = Ez‚àºN(0,Œ¥2)œÜ‚Ä≤(œÉKz)zr. Suppose
we have Hr(Œ¥) = Œò(Œ¥r) and Jr(Œ¥) = Œò(Œ¥r), then from (73) we have"
I,0.6206244087038789,"J0(Œ¥) ‚àíH2
0(Œ¥) ‚àíH2
1(Œ¥) ‚ààŒò(1) ‚àíŒò(Œ¥2),"
I,0.6215704824976348,"J2(Œ¥) ‚àíH2
1(Œ¥) ‚àíH2
2(Œ¥) ‚ààŒò(Œ¥2),"
I,0.6225165562913907,"H0(Œ¥) ¬∑ H2(Œ¥) ‚àíH2
1(Œ¥) ‚ààŒò(Œ¥2) ‚àíŒò(Œ¥4). (74)"
I,0.6234626300851467,"Because œÅ is a continuous function with œÅ(z) > 0 for some z > 0. Therefore, œÅ Ã∏= J0(Œ¥) ‚àíH2
0(Œ¥) ‚àí
H2
1(Œ¥) when Œ¥ ‚Üí0+, otherwise œÅ(z) < 0 for any z > 0. When Œ¥ ‚Üí0+, both J2(Œ¥) ‚àíH2
1(Œ¥) ‚àí
H2
2(Œ¥) and H0(Œ¥) ¬∑ H2(Œ¥) ‚àíH2
1(Œ¥) are in the order of Œ¥2, which indicates that ¬µ is a Ô¨Åxed constant
when both Œ¥ and ÀúŒ¥ are close to 0. In addition, J2(Œ¥) ‚àíH2
1(Œ¥) ‚àíH2
2(Œ¥) goes to +‚àûwhile both
J0(Œ¥) ‚àíH2
0(Œ¥) ‚àíH2
1(Œ¥) and H0(Œ¥) ¬∑ H2(Œ¥) ‚àíH2
1(Œ¥) go to ‚àí‚àûwhen Œ¥ ‚Üí+‚àû. Therefore, with a
large enough Œ¥, we have"
I,0.6244087038789026,"œÅ(Œ¥) ‚ààŒò(Œ¥2) ‚àíŒò(Œ¥4)
or
Œò(1) ‚àíŒò(Œ¥2),
(75)"
I,0.6253547776726585,which indicates that ¬µ is a strictly decreasing function when Œ¥ and ÀúŒ¥ are large enough.
I,0.6263008514664143,"Next, we provide the conditions that guarantee Hr(Œ¥) = Œò(Œ¥r) hold, and the relative proof for Jr(Œ¥)
can be derived accordingly following the similar steps as well. From DeÔ¨Ånition 3, we have"
I,0.6272469252601703,"lim
Œ¥‚Üí0+
Hr(Œ¥)"
I,0.6281929990539262,"Œ¥r
= lim
Œ¥‚Üí0+ Z +‚àû"
I,0.6291390728476821,"‚àí‚àû
œÜ‚Ä≤(œÉKz)
 z"
I,0.630085146641438,"Œ¥
r
1
‚àö"
I,0.631031220435194,2œÄŒ¥ e‚àíz2 Œ¥2 dz
I,0.6319772942289499,"(a)
= lim
Œ¥‚Üí0+ Z +‚àû"
I,0.6329233680227058,"‚àí‚àû
œÜ‚Ä≤(œÉKŒ¥t) tr ‚àö"
I,0.6338694418164617,2œÄ e‚àít2dt
I,0.6348155156102177,"= lim
Œ¥‚Üí0+ Z 0‚àí"
I,0.6357615894039735,"‚àí‚àû
œÜ‚Ä≤(œÉKŒ¥t) tr ‚àö"
I,0.6367076631977294,"2œÄ e‚àít2dt + lim
Œ¥‚Üí0+ Z +‚àû"
I,0.6376537369914853,"0+
œÜ‚Ä≤(œÉKŒ¥t) tr ‚àö"
I,0.6385998107852412,2œÄ e‚àít2dt
I,0.6395458845789972,"=œÜ‚Ä≤(0‚àí)
Z 0‚àí ‚àí‚àû tr
‚àö"
I,0.6404919583727531,"2œÄ e‚àít2dt + œÜ‚Ä≤(0+)
Z +‚àû"
I,0.641438032166509,"0+
tr
‚àö"
I,0.6423841059602649,"2œÄ e‚àít2dt, (76)"
I,0.6433301797540208,where equality (a) holds by letting t = z
I,0.6442762535477767,Œ¥ . It is easy to verify that Z +‚àû
I,0.6452223273415326,"0+
tr
‚àö"
I,0.6461684011352885,"2œÄ e‚àít2dt = (‚àí1)r
Z 0‚àí ‚àí‚àû tr
‚àö"
I,0.6471144749290445,"2œÄ e‚àít2dt,"
I,0.6480605487228004,"and both are bounded for a Ô¨Åxed r. Thus, as long as either œÜ‚Ä≤(0‚àí) or œÜ‚Ä≤(0+) is non-zero, we have
Hr(Œ¥) = Œò(Œ¥r) when Œ¥ ‚Üí0+."
I,0.6490066225165563,"If œÜ has bounded gradient as |œÜ‚Ä≤| ‚â§CœÜ for some positive constant CœÜ. Then, we have Hr(Œ¥)"
I,0.6499526963103122,"Œ¥r
 =

Z +‚àû"
I,0.6508987701040682,"‚àí‚àû
œÜ‚Ä≤(œÉKz)
 z"
I,0.651844843897824,"Œ¥
r
1
‚àö"
I,0.6527909176915799,2œÄŒ¥ e‚àíz2 Œ¥2 dz
I,0.6537369914853358,"=

Z +‚àû"
I,0.6546830652790918,"‚àí‚àû
œÜ‚Ä≤(œÉKŒ¥t) tr ‚àö"
I,0.6556291390728477,2œÄ e‚àít2dt
I,0.6565752128666036,"‚â§CœÜ ¬∑

Z +‚àû ‚àí‚àû tr
‚àö"
I,0.6575212866603595,2œÄ e‚àít2dt (77)
I,0.6584673604541155,"Therefore, we have Hr(Œ¥) = O(Œ¥r) for all Œ¥ > 0 when œÜ has bounded gradient."
I,0.6594134342478714,"Typiclly, for ReLU function, one can directly calculate that Hr(Œ¥) = Œ¥r for Œ¥ ‚ààR, and œÅ(Œ¥) = CŒ¥2
when Œ¥ ‚â§1 for some constant C = 0.091. Then, it is easy to check that ¬µ is a constant when
Œ¥, ÀúŒ¥ ‚â§1."
I,0.6603595080416272,Published as a conference paper at ICLR 2022
I,0.6613055818353831,"H
PROOF OF PRELIMINARY LEMMAS"
I,0.6622516556291391,"H.1
PROOF OF LEMMA 1"
I,0.663197729422895,"The eigenvalues of ‚àá2f(¬∑; p) at any Ô¨Åxed point W can be bounded in the form of (80) by Weyl‚Äôs
inequality (Lemma 4). Therefore, the primary technical challenge lies in bounding ‚à•‚àá2f(W ; p) ‚àí
‚àá2f(W [p]; p)‚à•2, which is summarized in Lemma 12. Lemma 13 provides the exact calulation of"
I,0.6641438032166509,"the lower bound of Ex
 PK
j=1 Œ±T
j xœÜ‚Ä≤(w[p]T
j
x)
2
when x belongs to Gaussian distribution with
zero mean, which is used in proving the lower bound of the Hessian matrix in (81)."
I,0.6650898770104068,"Lemma 12. Let f(W ; p) be the population risk function deÔ¨Åned in (17) with p and W satisfying
(20). Then, we have"
I,0.6660359508041628,‚à•‚àá2f(W [p]; p) ‚àí‚àá2f(W ; p)‚à•2 ‚â≤ŒªŒ¥2 + (1 ‚àíŒª)ÀúŒ¥2
I,0.6669820245979187,"K
¬∑ ‚à•W [p] ‚àíW ‚à•2"
I,0.6679280983916746,"œÉK
.
(78)"
I,0.6688741721854304,"Lemma 13 (Lemma D.6, (Zhong et al., 2017)). For any {wj}K
j=1 ‚ààRd, let Œ± ‚ààRdK be the unit
vector deÔ¨Åned in (19). When the œÜ is ReLU function, we have"
I,0.6698202459791863,"min
‚à•Œ±‚à•2=1 Ex‚àºN(0,œÉ2)
 K
X"
I,0.6707663197729423,"j=1
Œ±T
j xœÜ‚Ä≤(wT
j x)
2
‚â≥œÅ(œÉ),
(79)"
I,0.6717123935666982,where œÅ(œÉ) is deÔ¨Åned in DeÔ¨Ånition 3.
I,0.6726584673604541,"Proof of Lemma 1. Let Œªmax(W ) and Œªmin(W ) denote the largest and smallest eigenvalues of
‚àá2f(W ; p) at point W , respectively. Then, from Lemma 4, we have"
I,0.67360454115421,"Œªmax(W ) ‚â§Œªmax(W [p]) + ‚à•‚àá2f(W ; p) ‚àí‚àá2f(W [p]; p)‚à•2,"
I,0.674550614947966,"Œªmin(W ) ‚â•Œªmin(W [p])‚àí‚à•‚àá2f(W ; p) ‚àí‚àá2f(W [p]; p)‚à•2.
(80)"
I,0.6754966887417219,"Then, we provide the lower bound of the Hessian matrix of the population function at W [p]. For
any Œ± ‚ààRdK deÔ¨Åned in (19) with ‚à•Œ±‚à•2 = 1, we have"
I,0.6764427625354777,"min
‚à•Œ±‚à•2=1 Œ±T ‚àá2f(W [p]; p)Œ± = 1"
I,0.6773888363292336,"K2
min
‚à•Œ±‚à•2=1"
I,0.6783349101229896,"h
ŒªEx
 K
X"
I,0.6792809839167455,"j=1
Œ±T
j xœÜ‚Ä≤(w[p]T
j
x)
2
+ eŒªEex
 K
X"
I,0.6802270577105014,"j=1
Œ±T
j exœÜ‚Ä≤(w[p]T
j
ex)
2i ‚â•1"
I,0.6811731315042573,"K2
min
‚à•Œ±‚à•2=1 ŒªEx
 K
X"
I,0.6821192052980133,"j=1
Œ±T
j xœÜ‚Ä≤(w[p]T
j
x)
2
+
min
‚à•Œ±‚à•2=1
eŒªEex
 K
X"
I,0.6830652790917692,"j=1
Œ±T
j exœÜ‚Ä≤(w[p]T
j
ex)
2"
I,0.6840113528855251,‚â•ŒªœÅ(Œ¥) + eŒªœÅ(ÀúŒ¥)
I,0.684957426679281,"11Œ∫2Œ≥K2
, (81)"
I,0.6859035004730369,where the last inequality comes from Lemma 13.
I,0.6868495742667928,"Next, the upper bound can be bounded as"
I,0.6877956480605487,"max
‚à•Œ±‚à•2=1 Œ±T ‚àá2f(W [p]; p)Œ± = 1"
I,0.6887417218543046,"K2
max
‚à•Œ±‚à•2=1"
I,0.6896877956480606,"h
ŒªEx
 K
X"
I,0.6906338694418165,"j=1
Œ±T
j xœÜ‚Ä≤(w[p]T
j
x)
2
+ eŒªEex
 K
X"
I,0.6915799432355724,"j=1
Œ±T
j exœÜ‚Ä≤(w[p]T
j
ex)
2i ‚â§1"
I,0.6925260170293283,"K2
max
‚à•Œ±‚à•2=1 ŒªEx
 K
X"
I,0.6934720908230843,"j=1
Œ±T
j xœÜ‚Ä≤(w[p]T
j
x)
2
+ max
‚à•Œ±‚à•2=1
eŒªEex
 K
X"
I,0.6944181646168401,"j=1
Œ±T
j exœÜ‚Ä≤(w[p]T
j
ex)
2
. (82)"
I,0.695364238410596,Published as a conference paper at ICLR 2022
I,0.6963103122043519,"For Ex
 PK
j=1 Œ±T
j xœÜ‚Ä≤(w[p]T
j
x)
2
, we have"
I,0.6972563859981078,"Ex
 K
X"
I,0.6982024597918638,"j=1
Œ±T
j xœÜ‚Ä≤(w[p]T
j
x)
2 =Ex K
X j1=1 K
X"
I,0.6991485335856197,"j2=1
Œ±T
j1xœÜ‚Ä≤(w[p]T
j1
x)Œ±T
j2xœÜ‚Ä≤(w[p]T
j2
x) = K
X j1=1 K
X"
I,0.7000946073793756,"j2=1
ExŒ±T
j1xœÜ‚Ä≤(w[p]T
j1
x)Œ±T
j2xœÜ‚Ä≤(w[p]T
j2
x) ‚â§ K
X j1=1 K
X j2=1"
I,0.7010406811731315,"h
Ex(Œ±T
j1x)4Ex(œÜ‚Ä≤(w[p]T
j1
x))4Ex(Œ±T
j2x)4Ex(œÜ‚Ä≤(w[p]T
j2
x))4i1/4 ‚â§ K
X j1=1 K
X"
I,0.7019867549668874,"j2=1
3Œ¥2‚à•Œ±j1‚à•2‚à•Œ±j2‚à•2"
I,0.7029328287606433,"‚â§6Œ¥2
K
X j1=1 K
X j2=1"
I,0.7038789025543992,"1
2(‚à•Œ±j1‚à•2
2 + ‚à•Œ±j2‚à•2
2) =6KŒ¥2 (83)"
I,0.7048249763481551,"Therefore, we have"
I,0.7057710501419111,"max
‚à•Œ±‚à•2=1 Œ±T ‚àá2f(W [p]; p)Œ± ‚â§1"
I,0.706717123935667,"K2
max
‚à•Œ±‚à•2=1 ŒªEx
 K
X"
I,0.7076631977294229,"j=1
Œ±T
j xœÜ‚Ä≤(w[p]T
j
x)
2
+ max
‚à•Œ±‚à•2=1
eŒªEex
 K
X"
I,0.7086092715231788,"j=1
Œ±T
j exœÜ‚Ä≤(w[p]T
j
ex)
2"
I,0.7095553453169348,"‚â§6(ŒªŒ¥2 + eŒªÀúŒ¥2) K
. (84)"
I,0.7105014191106906,"Then, given (20), we have"
I,0.7114474929044465,"‚à•W (0,0) ‚àíW [p]‚à•F = p‚à•W (0,0) ‚àíW ‚àó‚à•F ‚â≤œÉK"
I,0.7123935666982024,"¬µ2K .
(85)"
I,0.7133396404919584,"Combining (85) and Lemma 12, we have"
I,0.7142857142857143,‚à•‚àá2f(W ; p) ‚àí‚àá2f(W [p]; p)‚à•2 ‚â≤ŒªœÅ(Œ¥) + eŒªœÅ(ÀúŒ¥)
I,0.7152317880794702,"132Œ∫2Œ≥K2
.
(86)"
I,0.7161778618732261,"Therefore, (86) and (80) completes the whole proof."
I,0.7171239356669821,"H.2
PROOF OF LEMMA 2"
I,0.718070009460738,"The task of bounding of the quantity between ‚à•‚àáÀÜf ‚àí‚àáf‚à•2 is dividing into bounding I1, I2, I3 and
I4 as shown in (89). I1 and I3 represent the deviation of the mean of several random variables to
their expectation, which can be bounded through concentration inequality, i.e, Chernoff bound. I2
and I4 come from the inconsistency of the output label y and pseudo label ey in the empirical risk
function in (1) and population risk function in (17). The major challenge lies in characterizing the
upper bound of I2 and I4 as the linear function of f
W ‚àíW [p] and W [p]‚àíW ‚àó, which is summarized
in (96)."
I,0.7190160832544938,Published as a conference paper at ICLR 2022
I,0.7199621570482497,"Proof of Lemma 2. From (1), we know that"
I,0.7209082308420057,"‚àÇÀÜf
‚àÇwk
(W ) = Œª N N
X n=1  1 K K
X"
I,0.7218543046357616,"j=1
œÜ(wT
j xn) ‚àíyn

xn + 1 ‚àíŒª M M
X m=1  1 K K
X"
I,0.7228003784295175,"j=1
œÜ(wT
j exm) ‚àíeyn

exm"
I,0.7237464522232734,"=
Œª
K2N N
X n=1 K
X j=1"
I,0.7246925260170294,"
œÜ(wT
j xn) ‚àíœÜ(w‚àóT
j xn)

xn"
I,0.7256385998107853,"+ 1 ‚àíŒª K2M M
X m=1 K
X j=1"
I,0.7265846736045412,"
œÜ(wT
j exm) ‚àíœÜ( e
wT
j exm)

exm."
I,0.727530747398297,"(87)
From (32), we know that"
I,0.7284768211920529,"‚àÇÀÜf
‚àÇwk
(W ) = Œª K2 Ex K
X j=1"
I,0.7294228949858089,"
œÜ(wT
j x) ‚àíœÜ(w‚àóT
j x)

x + 1 ‚àíŒª"
I,0.7303689687795648,"K2 Eex K
X j=1"
I,0.7313150425733207,"
œÜ(wT
j ex) ‚àíœÜ( e
wT
j ex)

ex."
I,0.7322611163670766,"(88)
Then, from (17), we have"
I,0.7332071901608326,"‚àÇÀÜf
‚àÇwk
(W ) ‚àí‚àÇf"
I,0.7341532639545885,"‚àÇwk
(W ; p)"
I,0.7350993377483444,"=
Œª
K2N K
X j=1 h
N
X n=1"
I,0.7360454115421002," 
œÜ(wT
j xn) ‚àíœÜ(w‚àóT
j xn)

xn ‚àíEx
 
œÜ(wT
j x) ‚àíœÜ(w[p]T
j
x)

x
i"
I,0.7369914853358562,"+ 1 ‚àíŒª K2M K
X j=1 h
M
X m=1"
I,0.7379375591296121," 
œÜ(wT
j exm) ‚àíœÜ( e
wT
j exm)
exm ‚àíEex
 
œÜ(wT
j ex) ‚àíœÜ(w[p]T
j
ex)
ex
i = Œª K2 K
X j=1 h 1 N N
X n=1"
I,0.738883632923368," 
œÜ(wT
j xn) ‚àíœÜ(w‚àóT
j xn)

xn ‚àíEx
 
œÜ(wT
j x) ‚àíœÜ(w‚àóT
j x)

x
i + Œª K2 K
X"
I,0.7398297067171239,"j=1
Ex
h 
œÜ(w‚àóT
j x) ‚àíœÜ(w[p]T
j
x)

x
i"
I,0.7407757805108799,"+ 1 ‚àíŒª K2 K
X j=1 h 1 M M
X m=1"
I,0.7417218543046358," 
œÜ(wT
j exm) ‚àíœÜ( e
wT
j exm)
exm ‚àíEex
 
œÜ(wT
j ex) ‚àíœÜ( e
wT
j ex)
ex
i"
I,0.7426679280983917,"+ 1 ‚àíŒª K2 K
X"
I,0.7436140018921475,"j=1
Eex
h 
œÜ( e
wT
j ex) ‚àíœÜ(w[p]T
j
(p)ex)
ex
i"
I,0.7445600756859035,:=I1 + I2 + I3 + I4. (89)
I,0.7455061494796594,"For any Œ±j ‚ààRd with ‚à•Œ±j‚à•2 ‚â§1, we deÔ¨Åne a random variable Z(j) =
 
œÜ(wT
j x)‚àíœÜ(w‚àóT
j x)

Œ±T
j x
and Zn(j) =
 
œÜ(wT
j xn)‚àíœÜ(w‚àóT
j xn)

Œ±T
j xn as the realization of Z(j) for n = 1, 2 ¬∑ ¬∑ ¬∑ , N. Then,
for any p ‚ààN+, we have
 
E|Z|p1/p =

E|œÜ(wT
j x) ‚àíœÜ(w‚àóT
j x)|p ¬∑ |Œ±T
j x|p1/p"
I,0.7464522232734153,"‚â§

E|(wj ‚àíw‚àó
j )T x|p ¬∑ |Œ±T
j x|p1/p"
I,0.7473982970671712,"‚â§C ¬∑ Œ¥2‚à•wj ‚àíw‚àó
j ‚à•2 ¬∑ p, (90)"
I,0.7483443708609272,"where C is a positive constant and the last inequality holds since x ‚àºN(0, Œ¥2). From DeÔ¨Ånition 2,
we know that Z belongs to sub-exponential distribution with ‚à•Z‚à•œà1 ‚â≤Œ¥2‚à•wj ‚àíw‚àó
j ‚à•2. Therefore,
by Chernoff inequality, we have"
I,0.7492904446546831,"P
 1 N N
X"
I,0.750236518448439,"n=1
Zn(j) ‚àíEZ(j)
 < t

‚â§1 ‚àíe‚àíC(Œ¥2‚à•wj‚àíw‚àó
j ‚à•2)2¬∑Ns2"
I,0.7511825922421949,"eNst
(91)"
I,0.7521286660359509,Published as a conference paper at ICLR 2022
I,0.7530747398297067,for some positive constant C and any s ‚ààR.
I,0.7540208136234626,"Let t = Œ¥2‚à•wj ‚àíw‚àó
j ‚à•2
q"
I,0.7549668874172185,d log q
I,0.7559129612109745,"N
and s =
2
CŒ¥2‚à•wj‚àíw‚àó
j ‚à•2 ¬∑ t for some large constant q > 0, we have 1 N N
X"
I,0.7568590350047304,"n=1
Zn(j) ‚àíEZ(j)
 ‚â≤Œ¥2‚à•wj ‚àíw‚àó
j ‚à•2 ¬∑ r"
I,0.7578051087984863,d log q
I,0.7587511825922422,"N
(92)"
I,0.759697256385998,"with probability at least 1 ‚àíq‚àíd. From Lemma 7, we have 1 N N
X n=1"
I,0.760643330179754," 
œÜ(wT
j xn) ‚àíœÜ(w‚àóT
j xn)

xn ‚àíEx
 
œÜ(wT
j x) ‚àíœÜ(w‚àóT
j x)

x

2"
I,0.7615894039735099,"‚â§2Œ¥2‚à•wj ‚àíw‚àó
j ‚à•2 ¬∑ r"
I,0.7625354777672658,d log q N (93)
I,0.7634815515610217,"with probability at least 1 ‚àí(q/5)‚àíd. Since q is a large constant, we release the probability as
1 ‚àíq‚àíd for simpliÔ¨Åcation. Similar to Z, we have 1 M M
X m=1"
I,0.7644276253547777," 
œÜ(wT
j exm) ‚àíœÜ( e
wT
j exm)
exm ‚àíEex
 
œÜ(wT
j ex) ‚àíœÜ( e
wT
j ex)
ex

2"
I,0.7653736991485336,"‚â≤ÀúŒ¥2‚à•wj ‚àíe
wj‚à•2 ¬∑ r"
I,0.7663197729422895,d log q M (94)
I,0.7672658467360454,with probability at least 1 ‚àíq‚àíd.
I,0.7682119205298014,"ùíòùíòùëóùëó
‚àó ùúÉùúÉ1 II
I III IV-A ùúÉùúÉ1"
I,0.7691579943235572,"ùíòùíòùëóùëó
[ùëùùëù]"
I,0.7701040681173131,"Figure 13: The subspace spanned by w‚àó
j and w[p]
j"
I,0.771050141911069,"For term Ex
h 
œÜ(w‚àóT
j x)‚àíœÜ(w[p]T
j
x)

x
i
, let us deÔ¨Åne the angle between w‚àó
j and w[p]
j
as Œ∏1. Figure
13 shows the subspace spanned by the vector w‚àó
j and e
wj. We divide the subspace by 4 pieces, where
the gray region denotes area I, and the blue area denotes area II. Areas III and IV are the symmetries
of II and I from the origin, respectively. Hence, we have"
I,0.771996215704825,"Ex
h 
œÜ(w‚àóT
j x) ‚àíœÜ(w[p]T
j
x)

x
i"
I,0.7729422894985809,"=Ex‚ààarea I
h 
œÜ(w‚àóT
j x) ‚àíœÜ(w[p]T
j
x)

x
i
+ Ex‚ààarea II
h 
œÜ(w‚àóT
j x) ‚àíœÜ(w[p]T
j
x)

x
i"
I,0.7738883632923368,"+ Ex‚ààarea III
h 
œÜ(w‚àóT
j x) ‚àíœÜ(w[p]T
j
x)

x
i
+ Ex‚ààarea IV
h 
œÜ(w‚àóT
j x) ‚àíœÜ(w[p]T
j
x)

x
i"
I,0.7748344370860927,"=Ex‚ààarea I
h 
œÜ(w‚àóT
j x) ‚àíœÜ(w[p]T
j
x)

x
i
+ Ex‚ààarea II

w‚àóT
j
exex

‚àíEx‚ààarea III

w[p]T
j
xx
"
I,0.7757805108798487,"=Ex‚ààarea I

(w‚àó
j ‚àíw[p]
j )T xx

+ Ex‚ààarea II

(w‚àó
j ‚àíw[p]
j )T xx
 =1"
EX,0.7767265846736046,"2Ex

(w‚àó
j ‚àíw[p]
j )T xx
 (95)"
EX,0.7776726584673604,Published as a conference paper at ICLR 2022
EX,0.7786187322611163,"Therefore, we have

Œª
K2 Ex
h 
œÜ(w‚àóT
j x) ‚àíœÜ(w[p]T
j
x)

x
i
+ 1 ‚àíŒª"
EX,0.7795648060548723,"K2 Eex
h 
œÜ( e
wT
j ex) ‚àíœÜ(w[p]T
j
ex)
ex
i
2"
EX,0.7805108798486282,"=

Œª
2K2 Ex

(w‚àó
j ‚àíw[p]
j )T xx

+ 1 ‚àíŒª"
EX,0.7814569536423841,"2K2 Eex

( e
wj ‚àíw[p]
j )T xx

2 ="
EX,0.78240302743614,"ŒªŒ¥2 ¬∑
  e
wj ‚àíw[p]
j

+ (1 ‚àíŒª)ÀúŒ¥2 ¬∑
 
w‚àó
j ‚àíw[p]
j

2
2K2
. (96)"
EX,0.783349101229896,"From (93), (94) and (96), we have
 ‚àÇÀÜf"
EX,0.7842951750236519,"‚àÇwk
(W ; p) ‚àí‚àÇf"
EX,0.7852412488174078,"‚àÇwk
(W )

2 ‚â§Œª K2 K
X j=1 1 N N
X n=1"
EX,0.7861873226111636," 
œÜ(wT
j xn) ‚àíœÜ(w‚àóT
j xn)

xn ‚àíEx
 
œÜ(wT
j x) ‚àíœÜ(w‚àóT
j x)

x

2"
EX,0.7871333964049196,"+ 1 ‚àíŒª K2 K
X j=1 1 M M
X m=1"
EX,0.7880794701986755," 
œÜ(wT
j exm) ‚àíœÜ( e
wT
j exm)
exm ‚àíEex
 
œÜ(wT
j ex) ‚àíœÜ( e
wT
j ex)
ex

2 + K
X j=1"
EX,0.7890255439924314,"Œª
K2 Ex
h 
œÜ(w‚àóT
j x) ‚àíœÜ(w[p]T
j
x)

x
i
+ 1 ‚àíŒª"
EX,0.7899716177861873,"K2 Eex
h 
œÜ( e
wT
j ex) ‚àíœÜ(w[p]T
j
ex)
ex
i
2 ‚â§Œª"
EX,0.7909176915799432,"K2 Œ¥2
r"
EX,0.7918637653736992,"d log q N
¬∑ K
X"
EX,0.7928098391674551,"j=1
‚à•wj ‚àíw‚àó
j ‚à•2 + 1 ‚àíŒª"
EX,0.793755912961211,"K2
¬∑ ÀúŒ¥2
r"
EX,0.7947019867549668,"d log q M
¬∑ K
X"
EX,0.7956480605487228,"j=1
‚à•wj ‚àíe
wj‚à•2"
EX,0.7965941343424787,"+
1
2K2 ¬∑ K
X j=1"
EX,0.7975402081362346,"ŒªŒ¥2 ¬∑
  e
wj ‚àíw[p]
j

+ eŒªÀúŒ¥2 ¬∑
 
w‚àó
j ‚àíw[p]
j

2"
EX,0.7984862819299905,"‚â§
Œª
K3/2 Œ¥2
r"
EX,0.7994323557237465,d log q
EX,0.8003784295175024,"N
¬∑ ‚à•W ‚àíW ‚àó‚à•2 + 1 ‚àíŒª"
EX,0.8013245033112583,"K3/2 ¬∑ ÀúŒ¥2
r"
EX,0.8022705771050141,d log q
EX,0.8032166508987701,"M
¬∑ ‚à•W ‚àíf
W ‚à•2"
EX,0.804162724692526,"+
1
2K3/2
ŒªŒ¥2 ¬∑
 f
W ‚àíW [p]
+ (1 ‚àíŒª)ÀúŒ¥2 ¬∑
 
W ‚àó‚àíW [p]
2 (97)"
EX,0.8051087984862819,with probability at least 1 ‚àíq‚àíd.
EX,0.8060548722800378,"In conclusion, let Œ± ‚ààRKd and Œ±j ‚ààRd with Œ± = [Œ±T
1 , Œ±T
2 , ¬∑ ¬∑ ¬∑ , Œ±T
K]T , we have"
EX,0.8070009460737938,"‚à•‚àáf(W ) ‚àí‚àáÀÜf(W )‚à•2 =
Œ±T  
‚àáf(W ) ‚àí‚àáÀÜf(W )
 ‚â§ K
X k=1"
EX,0.8079470198675497,"Œ±T
k
  ‚àÇÀÜf"
EX,0.8088930936613056,"‚àÇwk
(W ) ‚àí‚àÇf"
EX,0.8098391674550615,"‚àÇwk
(W )
 ‚â≤ K
X k=1 ‚àÇÀÜf"
EX,0.8107852412488175,"‚àÇwk
(W ) ‚àí‚àÇf"
EX,0.8117313150425733,"‚àÇwk
(W )

2 ¬∑ ‚à•Œ±k‚à•2 ‚â≤Œª"
EX,0.8126773888363292,"K Œ¥2
r"
EX,0.8136234626300851,d log q
EX,0.8145695364238411,"N
¬∑ ‚à•W ‚àíW ‚àó‚à•2 + 1 ‚àíŒª"
EX,0.815515610217597,"K
¬∑ ÀúŒ¥2
r"
EX,0.8164616840113529,d log q
EX,0.8174077578051088,"M
¬∑ ‚à•W ‚àíf
W ‚à•2"
EX,0.8183538315988647,"+
1
2K"
EX,0.8192999053926207,"ŒªŒ¥2 ¬∑
 f
W ‚àíW [p]
+ (1 ‚àíŒª)ÀúŒ¥2 ¬∑
 
W ‚àó‚àíW [p]
2
(98)"
EX,0.8202459791863765,with probability at least 1 ‚àíq‚àíd.
EX,0.8211920529801324,"H.3
PROOF OF LEMMA 12"
EX,0.8221381267738883,"The distance of the second order derivatives of the population risk function f(¬∑; p) at point W and
W [p] can be converted into bounding P1, P2, P3 and P4, which are deÔ¨Åned in (101). The major"
EX,0.8230842005676443,Published as a conference paper at ICLR 2022
EX,0.8240302743614002,"idea in proving P1 is to connect the error bound to the angle between W and W [p]. Similar ideas
apply in bounding the other three items as well."
EX,0.8249763481551561,"Proof of Lemma 12. From (17), we have"
EX,0.825922421948912,"‚àÇ2f
‚àÇwj1‚àÇwj2
(W [p]; p) = Œª"
EX,0.826868495742668,"K2 ExœÜ‚Ä≤(w[p]T
j1
x)œÜ‚Ä≤(w[p]T
j2
x)xxT + 1 ‚àíŒª"
EX,0.8278145695364238,"K2 EexœÜ‚Ä≤(w[p]T
j1
ex)œÜ‚Ä≤(w[p]T
j2
ex)exexT , (99)"
EX,0.8287606433301797,"and
‚àÇ2f
‚àÇwj1‚àÇwj2
(W ; p) = Œª"
EX,0.8297067171239356,"K2 ExœÜ‚Ä≤(wT
j1x)œÜ‚Ä≤(wT
j2x)xxT + 1 ‚àíŒª"
EX,0.8306527909176916,"K2 EexœÜ‚Ä≤(wT
j1 ex)œÜ‚Ä≤(wT
j2 ex)exexT , (100)"
EX,0.8315988647114475,"where w[p]
j
is the j-th column of W [p]. Then, we have"
EX,0.8325449385052034,"‚àÇ2f
‚àÇwj1‚àÇwj2
(W ‚àó) ‚àí
‚àÇ2f
‚àÇwj1‚àÇwj2
(W ) = Œª"
EX,0.8334910122989593,"K2 Ex
h"
EX,0.8344370860927153,"œÜ‚Ä≤(w[p]T
j1
x)œÜ‚Ä≤(w[p]T
j2
x) ‚àíœÜ‚Ä≤(wT
j1x)œÜ‚Ä≤(wT
j2x)
i
xxT"
EX,0.8353831598864712,+ 1 ‚àíŒª
EX,0.836329233680227,"K2 Eex
h
œÜ‚Ä≤(w[p]T
j1
ex)œÜ‚Ä≤(w[p]T
j2
ex) ‚àíœÜ‚Ä≤(wT
j1 ex)œÜ‚Ä≤(wT
j2 ex)
i
exexT = Œª"
EX,0.8372753074739829,"K2 Ex
h
œÜ‚Ä≤(w[p]T
j1
x)
 
œÜ‚Ä≤(w[p]T
j2
x) ‚àíœÜ‚Ä≤(wT
j2x)

+ œÜ‚Ä≤(wT
j2x)
 
œÜ‚Ä≤(w[p]T
j1
x) ‚àíœÜ‚Ä≤(wT
j1x)
i
xxT"
EX,0.8382213812677389,+ 1 ‚àíŒª
EX,0.8391674550614948,"K2 Eex
h
œÜ‚Ä≤(w[p]T
j1
ex)
 
œÜ‚Ä≤(w[p]T
j2
ex) ‚àíœÜ‚Ä≤(wT
j2 ex)

+ œÜ‚Ä≤(wT
j2 ex)
 
œÜ‚Ä≤(w[p]T
j1
ex) ‚àíœÜ‚Ä≤(wT
j1 ex)
i
exexT = Œª K2"
EX,0.8401135288552507,"h
ExœÜ‚Ä≤(w[p]T
j1
x)
 
œÜ‚Ä≤(w[p]T
j2
x) ‚àíœÜ‚Ä≤(wT
j2x)

xxT + ExœÜ‚Ä≤(wT
j2x)
 
œÜ‚Ä≤(w[p]T
j1
x) ‚àíœÜ‚Ä≤(wT
j1x)

xxT i"
EX,0.8410596026490066,+ 1 ‚àíŒª K2
EX,0.8420056764427626,"h
EexœÜ‚Ä≤(w[p]T
j1
ex)
 
œÜ‚Ä≤(w[p]T
j2
ex) ‚àíœÜ‚Ä≤(wT
j2 ex)
exexT + EexœÜ‚Ä≤(wT
j2 ex)
 
œÜ‚Ä≤(w[p]T
j1
ex) ‚àíœÜ‚Ä≤(wT
j1 ex)
exexT i := Œª"
EX,0.8429517502365185,K2 (P1 + P2) + 1 ‚àíŒª
EX,0.8438978240302744,K2 (P3 + P4). (101)
EX,0.8448438978240302,"For any a ‚ààRd with ‚à•a‚à•2 = 1, we have"
EX,0.8457899716177862,"aT P1a =ExœÜ‚Ä≤(w[p]T
j1
x)
 
œÜ‚Ä≤(w[p]T
j2
x) ‚àíœÜ‚Ä≤(wT
j2x)

(aT x)2
(102)"
EX,0.8467360454115421,"where a ‚ààRd. Let I = œÜ‚Ä≤(w[p]T
j1
x)
 
œÜ‚Ä≤(w[p]T
j2
x)‚àíœÜ‚Ä≤(wT
j2x)

¬∑(aT x)2. It is easy to verify there ex-
ists a group of orthonormal vectors such that B = {a, b, c, a‚ä•
4 , ¬∑ ¬∑ ¬∑ , a‚ä•
d } with {a, b, c} spans a sub-"
EX,0.847682119205298,"space that contains a, wj2 and w‚àó
j2. Then, for any x, we have a unique z =
h
z1,
z2,
¬∑ ¬∑ ¬∑ ,
zd
iT"
EX,0.8486281929990539,"such that
x = z1a + z2b + z3c + ¬∑ ¬∑ ¬∑ + zda‚ä•
d .
Also, since x ‚àºN(0, Œ¥2Id), we have z ‚àºN(0, Œ¥2Id). Then, we have"
EX,0.8495742667928098,"I =Ez1,z2,z3|œÜ‚Ä≤ 
wT
j2x

‚àíœÜ‚Ä≤ 
w[p]T
j2
x

| ¬∑ |aT x|2"
EX,0.8505203405865658,"=
Z
|œÜ‚Ä≤ 
wT
j2x

‚àíœÜ‚Ä≤ 
w[p]T
j2
x

| ¬∑ |aT x|2 ¬∑ fZ(z1, z2, z3)dz1dz2dz3,"
EX,0.8514664143803217,"where x = z1a + z2b + z3c and fZ(z1, z2, z3) is probability density function of (z1, z2, z3). Next,
we consider spherical coordinates with z1 = RcosœÜ1, z2 = RsinœÜ1sinœÜ2, z3 = RsinœÜ1cosœÜ2.
Hence,"
EX,0.8524124881740776,"I =
Z
|œÜ‚Ä≤ 
wT
j2x

‚àíœÜ‚Ä≤ 
w[p]T
j2
x

| ¬∑ |R cos œÜ1|2 ¬∑ fZ(R, œÜ1, œÜ2)R2 sin œÜ1dRdœÜ1dœÜ2.
(103)"
EX,0.8533585619678334,"It is easy to verify that œÜ‚Ä≤ 
wT
j2x

only depends on the direction of x and"
EX,0.8543046357615894,"fZ(R, œÜ1, œÜ2) =
1"
EX,0.8552507095553453,"(2œÄŒ¥2)
3
2 e‚àí
z2
1+z2
2+z2
3
2Œ¥2
=
1"
EX,0.8561967833491012,"(2œÄŒ¥2)
3
2 e‚àíR2 2Œ¥2"
EX,0.8571428571428571,Published as a conference paper at ICLR 2022
EX,0.8580889309366131,"only depends on R. Then, we have"
EX,0.859035004730369,"I(i2, j2)"
EX,0.8599810785241249,"=
Z
|œÜ‚Ä≤ 
wT
j2(x/R)

‚àíœÜ‚Ä≤ 
w[p]T
j2
(x/R)

| ¬∑ |R cos œÜ1|2 ¬∑ fZ(R)R2 sin œÜ1dRdœÜ1dœÜ2 =
Z ‚àû"
EX,0.8609271523178808,"0
R4fz(R)dR
Z œÄ 0 Z 2œÄ"
EX,0.8618732261116367,"0
| cos œÜ1|2 ¬∑ sin œÜ1 ¬∑ |œÜ‚Ä≤ 
wT
j2(x/R)

‚àíœÜ‚Ä≤ 
w[p]T
j2
(x/R)

|dœÜ1dœÜ2"
EX,0.8628192999053926,"(a)
‚â§3Œ¥2 ¬∑
Z ‚àû"
EX,0.8637653736991485,"0
R2fz(R)dR
Z œÄ 0 Z 2œÄ"
EX,0.8647114474929044,"0
sin œÜ1 ¬∑ |œÜ‚Ä≤ 
wT
j2(x/R)

‚àíœÜ‚Ä≤ 
w[p]T
j2
(x/R)

|dœÜ1dœÜ2"
EX,0.8656575212866604,"=3Œ¥2 ¬∑ Ez1,z2,z3
œÜ‚Ä≤ 
wT
j2x

‚àíœÜ‚Ä≤ 
w[p]T
j2
x

|"
EX,0.8666035950804163,"‚â§3Œ¥2 ¬∑ Ex
œÜ‚Ä≤ 
wT
j2x

‚àíœÜ‚Ä≤ 
w[p]T
j2
x

|,
(104)"
EX,0.8675496688741722,"where the inequality (a) is derived from the fact that |cosœÜ1| ‚â§1 and
Z ‚àû"
EX,0.8684957426679281,"0
R4
1"
EX,0.8694418164616841,"(2œÄŒ¥2)
3
2 e‚àíR2"
EX,0.8703878902554399,"2Œ¥2 dR =
Z ‚àû"
EX,0.8713339640491958,"0
‚àíR3Œ¥2"
EX,0.8722800378429517,"(2œÄŒ¥2)
3
2 d(e‚àíR2 2Œ¥2 ) =
Z ‚àû"
EX,0.8732261116367077,"0
e‚àíR2"
EX,0.8741721854304636,2Œ¥2 d R3Œ¥2
EX,0.8751182592242195,"(2œÄŒ¥2)
3
2"
EX,0.8760643330179754,"=3Œ¥2
Z ‚àû"
EX,0.8770104068117314,"0
R2
1"
EX,0.8779564806054873,"(2œÄŒ¥2)
3
2 e‚àíR2"
EX,0.8789025543992431,2Œ¥2 dR. (105)
EX,0.879848628192999,"DeÔ¨Åne a set A1 = {x|(w[p]T
j2
x)(wT
j2x) < 0}. If x ‚ààA1, then w[p]T
j2
x and wT
j2x have different"
EX,0.8807947019867549,"signs, which means the value of œÜ‚Ä≤(wT
j2x) and œÜ‚Ä≤(w[p]T
j2
x) are different. This is equivalent to say
that"
EX,0.8817407757805109,"|œÜ‚Ä≤(wT
j2x) ‚àíœÜ‚Ä≤(w[p]T
j2
x)| =

1, if x ‚ààA1
0, if x ‚ààAc
1
.
(106)"
EX,0.8826868495742668,"Moreover, if x ‚ààA1, then we have"
EX,0.8836329233680227,"|w[p]T
j2
x| ‚â§|w[p]T
j2
x ‚àíwT
j2x| ‚â§‚à•w[p]
j2 ‚àíwj2‚à•2 ¬∑ ‚à•x‚à•2.
(107)"
EX,0.8845789971617786,Let us deÔ¨Åne a set A2 such that
EX,0.8855250709555346,"A2 =
n
x

|w[p]T
j2
x|
‚à•w‚àó
j2‚à•2‚à•x‚à•2
‚â§‚à•w‚àó
j2 ‚àíwj2‚à•2"
EX,0.8864711447492905,"‚à•w‚àó
j2‚à•2"
EX,0.8874172185430463,"o
=
n
Œ∏x,w‚àó
j2"
EX,0.8883632923368022,"| cos Œ∏x,w[p]
j2 | ‚â§
‚à•w[p]
j2 ‚àíwj2‚à•2"
EX,0.8893093661305582,"‚à•w[p]
j2 ‚à•2"
EX,0.8902554399243141,"o
. (108)"
EX,0.89120151371807,"Hence, we have that"
EX,0.8921475875118259,"Ex|œÜ‚Ä≤(wT
j2x) ‚àíœÜ‚Ä≤(w[p]T
j2
x)|2 =Ex|œÜ‚Ä≤(wT
j2x) ‚àíœÜ‚Ä≤(w[p]T
j2
x)|"
EX,0.8930936613055819,"=Prob(x ‚ààA1)
‚â§Prob(x ‚ààA2). (109)"
EX,0.8940397350993378,"Since x ‚àºN(0, Œ¥2‚à•a‚à•2
2I), Œ∏x,w[p]
j2 belongs to the uniform distribution on [‚àíœÄ, œÄ], we have"
EX,0.8949858088930936,"Prob(x ‚ààA2) =
œÄ ‚àíarccos
‚à•w[p]
j2 ‚àíwj2‚à•2"
EX,0.8959318826868495,"‚à•w[p]
j2 ‚à•2
œÄ
‚â§1"
EX,0.8968779564806055,"œÄ tan(œÄ ‚àíarccos
‚à•w[p]
j2 ‚àíwj2‚à•2"
EX,0.8978240302743614,"‚à•w[p]
j2 ‚à•2
) = 1"
EX,0.8987701040681173,"œÄ cot(arccos
‚à•w[p]
j2 ‚àíwj2‚à•2"
EX,0.8997161778618732,"‚à•w[p]
j2 ‚à•2
) ‚â§2"
EX,0.9006622516556292,"œÄ
‚à•w[p]
j2 ‚àíwj2‚à•2"
EX,0.9016083254493851,"‚à•w[p]
j2 ‚à•2
. (110)"
EX,0.902554399243141,Published as a conference paper at ICLR 2022
EX,0.9035004730368968,"Hence, (104) and (110) suggest that"
EX,0.9044465468306528,I ‚â§6Œ¥2
EX,0.9053926206244087,"œÄ
‚à•wj2 ‚àíw[p]
j2 ‚à•2
œÉK
¬∑ ‚à•a‚à•2
2.
(111)"
EX,0.9063386944181646,The same bound that shown in (111) holds for P2 as well.
EX,0.9072847682119205,P3 and P4 satisfy (111) except for changing Œ¥2 to ÀúŒ¥2.
EX,0.9082308420056765,"Therefore, we have"
EX,0.9091769157994324,‚à•‚àá2f(W [p]; p) ‚àí‚àá2f(W ; p)‚à•2
EX,0.9101229895931883,"= max
‚à•Œ±‚à•2‚â§1"
EX,0.9110690633869442,"Œ±T (‚àá2f(W [p]; p) ‚àí‚àá2f(W ; p))Œ± ‚â§ K
X j1=1 K
X j2=1 Œ±T
j1"
EX,0.9120151371807,"
‚àÇ2f
‚àÇwj1‚àÇwj2
(W [p]; p) ‚àí
‚àÇ2f
‚àÇwj1‚àÇwj2
(W ; p)

Œ±j2  ‚â§1 K2 K
X j1=1 K
X j2=1"
EX,0.912961210974456,"
Œª‚à•P1 + P2‚à•2 + (1 ‚àíŒª)‚à•P3 + P4‚à•2

‚à•Œ±j1‚à•2‚à•Œ±j2‚à•2 ‚â§1 K2 K
X j1=1 K
X"
EX,0.9139072847682119,"j2=1
4(ŒªŒ¥2 + (1 ‚àíŒª)ÀúŒ¥2)
‚à•w[p]
j2 ‚àíwj2‚à•2"
EX,0.9148533585619678,"œÉK
‚à•Œ±j1‚à•2‚à•Œ±j2‚à•2 ‚â§4"
EX,0.9157994323557237,"K
 
ŒªŒ¥2 + (1 ‚àíŒª)ÀúŒ¥2
¬∑ ‚à•W [p] ‚àíW ‚à•2 œÉK
, (112)"
EX,0.9167455061494797,"where Œ± ‚ààRKd and Œ±j ‚ààRd with Œ± = [Œ±T
1 , Œ±T
2 , ¬∑ ¬∑ ¬∑ , Œ±T
K]T ."
EX,0.9176915799432356,"I
INITIALIZATION VIA TENSOR METHOD"
EX,0.9186376537369915,"In this section, we brieÔ¨Çy summarize the tensor initialization in (Zhong et al., 2017) by studying the
target function class as y = 1 K K
X"
EX,0.9195837275307474,"j=1
v‚àó
j œÜ(w‚àóT
j x),
(113)"
EX,0.9205298013245033,"where v‚àó
j ‚ààR. Note that for ReLU function, we have v‚àó
j œÜ(w‚àóT
j x) = sign(v‚àó
j )œÜ(|v‚àó
j |w‚àóT
j x).
Without loss of generalization, we can assume v‚àó
j ‚àà{+1, ‚àí1}. Additionally, it is clear that the
function studied in (2) is the special case of (113) when v‚àó
j = 1 for all j. In addition, Theorem 5.6
in (Zhong et al., 2017) show that the sign of v‚àó
j can be directly recovered using tensor initialization,
which indicates the the equivalence of (2) and (113) when using tensor initialization."
EX,0.9214758751182592,We Ô¨Årst deÔ¨Åne some high order momenta in the following way:
EX,0.9224219489120151,"M1 = Ex{yx} ‚ààRd,
(114)"
EX,0.923368022705771,"M2 = Ex
h
y
 
x ‚äóx ‚àíŒ¥2I
i
‚ààRd√ód,
(115)"
EX,0.924314096499527,"M3 = Ex
h
y
 
x‚äó3 ‚àíxe‚äóŒ¥2I
i
‚ààRd√ód√ód,
(116)"
EX,0.9252601702932829,where Ex is the expectation over x and z‚äó3 := z ‚äóz ‚äóz. The operator e‚äóis deÔ¨Åned as
EX,0.9262062440870388,"ve‚äóZ = d2
X"
EX,0.9271523178807947,"i=1
(v ‚äózi ‚äózi + zi ‚äóv ‚äózi + zi ‚äózi ‚äóv),
(117)"
EX,0.9280983916745507,for any vector v ‚ààRd1 and Z ‚ààRd1√ód2.
EX,0.9290444654683065,Published as a conference paper at ICLR 2022
EX,0.9299905392620624,"Following the same calculation formulas in the Claim 5.2 (Zhong et al., 2017), there exist some
known constants œài, i = 1, 2, 3, such that M1 = K
X"
EX,0.9309366130558183,"j=1
œà1 ¬∑ ‚à•w‚àó
j ‚à•2 ¬∑ w‚àó
j,
(118) M2 = K
X"
EX,0.9318826868495743,"j=1
œà2 ¬∑ ‚à•w‚àó
j ‚à•2 ¬∑ w‚àó
jw‚àóT
j ,
(119) M3 = K
X"
EX,0.9328287606433302,"j=1
œà3 ¬∑ ‚à•w‚àó
j ‚à•2 ¬∑ w‚àó‚äó3
j
,
(120)"
EX,0.9337748344370861,"where w‚àó
j = w‚àó
j /‚à•w‚àó
j ‚à•2 in (114)-(116) is the normalization of w‚àó
j . Therefore, we can see that the
information of {w‚àó
j }K
j=1 are separated as the direction of wj and the magnitude of wj in M1, M2
and M3."
EX,0.934720908230842,"M1, M2 and M3 can be estimated through the samples

(xn, yn)
	N
n=1, and let c
M1, c
M2, c
M3
denote the corresponding estimates. First, we will decompose the rank-K tensor M3 and obtain the
{w‚àó
j}K
j=1. By applying the tensor decomposition method (Kuleshov et al., 2015) to c
M3, the outputs,"
EX,0.935666982024598,"denoted by bw
‚àó
j, are the estimations of {sjw‚àó
j}K
j=1, where sj is an unknown sign. Second, we will
estimate sj, v‚àó
j and ‚à•w‚àó
j ‚à•2 through M1 and M2. Note that M2 does not contain the information of
sj because s2
j is always 1. Then, through solving the following two optimization problem:"
EX,0.9366130558183539,"bŒ±1 = arg min
Œ±1‚ààRK :
 c
M1 ‚àí K
X"
EX,0.9375591296121097,"j=1
œà1Œ±1,j bw
‚àó
j
,"
EX,0.9385052034058656,"bŒ±2 = arg min
Œ±2‚ààRK :
 c
M2 ‚àí K
X"
EX,0.9394512771996215,"j=1
œà2Œ±2,j bw
‚àó
j bw
‚àóT
j
, (121)"
EX,0.9403973509933775,The estimation of sj can be given as
EX,0.9413434247871334,"ÀÜsj = sign(bŒ±1,j/bŒ±2,j)."
EX,0.9422894985808893,"Also, we know that |bŒ±1,j| is the estimation of ‚à•w‚àó
j ‚à•and"
EX,0.9432355723746452,"ÀÜvj = sign(bŒ±1,j/sj) = sign(bŒ±2,j)."
EX,0.9441816461684012,"Thus, W (0) is given as
h
sign(bŒ±2,1)bŒ±1,1 bw
‚àó
1,
¬∑ ¬∑ ¬∑ ,
sign(bŒ±2,K)bŒ±1,K bw
‚àó
K
i
."
EX,0.945127719962157,Subroutine 1 Tensor Initialization Method
EX,0.9460737937559129,"1: Input: labeled data D = {(xn, yn)}N
n=1;
2: Partition D into three disjoint subsets D1, D2, D3;
3: Calculate c
M1, c
M2 following (114), (115) using D1, D2, respectively;
4: Obtain the estimate subspace bV of c
M2;
5: Calculate c
M3( bV , bV , bV ) through D3;"
EX,0.9470198675496688,"6: Obtain {bsj}K
j=1 via tensor decomposition method (Kuleshov et al., 2015) on c
M3( bV , bV , bV );
7: Obtain bŒ±1, bŒ±2 by solving optimization problem (121);"
EX,0.9479659413434248,"8: Return: w(0)
j
= sign(bŒ±2,j)bŒ±1,j bV buj and v(0)
j
= sign(bŒ±2,j), j = 1, ..., K."
EX,0.9489120151371807,"To reduce the computational complexity of tensor decomposition, one can project c
M3 to a lower-
dimensional tensor (Zhong et al., 2017). The idea is to Ô¨Årst estimate the subspace spanned by
{w‚àó
j }K
j=1, and let bV denote the estimated subspace. Moreover, we have"
EX,0.9498580889309366,"M3( bV , bV , bV ) = Ex
h
y
 
( bV T x)‚äó3 ‚àí( bV T x)e‚äóEx( bV T x)( bV T x)T i
‚ààRK√óK√óK,
(122)"
EX,0.9508041627246925,Published as a conference paper at ICLR 2022
EX,0.9517502365184485,"Then, one can decompose the estimate c
M3( bV , bV , bV ) to obtain unit vectors {ÀÜsj}K
j=1 ‚ààRK. Since
w‚àólies in the subspace V , we have V V T w‚àó
j = w‚àó
j. Then, bV ÀÜsj is an estimate of w‚àó
j. The
initialization process is summarized in Subroutine 1."
EX,0.9526963103122044,"J
CLASSIFICATION PROBLEMS"
EX,0.9536423841059603,"The framework in this paper is extendable to binary classiÔ¨Åcation problem. For binary classiÔ¨Åcation
problem, the output y given input x is deÔ¨Åned as"
EX,0.9545884578997161,"Prob{y = 1} = g(W ‚àó; x)
(123)"
EX,0.9555345316934721,"with some ground truth parameter W ‚àó. To guarantee the output is within [0, 1], the activation
function is often used as sigmoid. For classiÔ¨Åcation, the loss function is cross-entropy, and the
objective function over labeled data D is deÔ¨Åned as"
EX,0.956480605487228,fD(W ) = 1 N X
EX,0.9574266792809839,"(xn,yn)‚ààD
‚àíyn log g(W ; xn) ‚àí(1 ‚àíyn) log(1 ‚àíg(W ; xn)).
(124)"
EX,0.9583727530747398,The expectation of objective function can be written as
EX,0.9593188268684958,"EDfD(W ) =E(x,y) ‚àíy log(g(W ; xn)) ‚àí(1 ‚àíy) log(1 ‚àíg(W ; x))"
EX,0.9602649006622517,=ExE(y|x) ‚àíy log(g(W ; xn)) ‚àí(1 ‚àíy) log(1 ‚àíg(W ; x))
EX,0.9612109744560076,"=Ex
h
‚àíg(W ‚àó; x) log(g(W ; xn)) ‚àí(1 ‚àíg(W ‚àó; x)) log(1 ‚àíg(W ; xn))
i
(125)"
EX,0.9621570482497634,Please note that (125) is exactly the same as (32) with Œª = 1 when the loss function is squared loss.
EX,0.9631031220435194,"For cross entropy loss function, the second order derivative of (125) is calculated as"
EX,0.9640491958372753,"‚àÇfD(W )
‚àÇwj‚àÇwk
= 1"
EX,0.9649952696310312,"N [
yn
g2(W ; x) +
1 ‚àíyn
(1 ‚àíg(W ; x))2 ] ¬∑ œÜ‚Ä≤(wT
j x)œÜ‚Ä≤(wT
k x)xxT .
(126)"
EX,0.9659413434247871,"when j Ã∏= k. Refer to (88) in (Fu et al., 2020) or (132) in (Zhang et al., 2020b), we have

yn(œÜ‚Ä≤(wT
j x)œÜ‚Ä≤(wT
k x))
g2(W ; x)"
EX,0.9668874172185431,"2 ‚â§

œÜ‚Ä≤(wT
j x)œÜ‚Ä≤(wT
k x)
g2(W ; x)"
EX,0.967833491012299,"2 ‚â§K2.
(127)"
EX,0.9687795648060549,"Following similar steps in (90), from DeÔ¨Åntion 2, we know that Œ±T
j
‚àÇfD(W )
‚àÇwj‚àÇwk Œ±k belongs to the sub-
exponential distribution. Therefore, similiar results for objective function with cross-entropy loss
can be established as well. One can check (Fu et al., 2020) or (Zhang et al., 2020b) for details."
EX,0.9697256385998108,"K
ONE-HIDDEN LAYER NEURAL NETWORK WITH TOP LAYER WEIGHTS"
EX,0.9706717123935666,"For a general one-hidden layer neural network, the output of the neural network is deÔ¨Åned as"
EX,0.9716177861873226,"g(W , v; x) = 1 K K
X"
EX,0.9725638599810785,"j=1
vjœÜ(wT
j x),
(128)"
EX,0.9735099337748344,"where v = [v1, v2, ¬∑ ¬∑ ¬∑ , vK] ‚ààRK. Then, the target function can be deÔ¨Åned as"
EX,0.9744560075685903,"y = g(W ‚àó, v‚àó; x) = 1 K K
X"
EX,0.9754020813623463,"j=1
v‚àó
j œÜ(w‚àóT
j x)
(129)"
EX,0.9763481551561022,for some unknown weights W ‚àóand v‚àó.
EX,0.9772942289498581,"In the following paragraphs, we will provide a short description for the equivalence of (129) and (2)
in theoretical analysis. Note that for ReLU functions, we have vjœÜ(wT
j x) = sign(vj)œÜ(|vj|wT
j x)."
EX,0.978240302743614,Published as a conference paper at ICLR 2022
EX,0.97918637653737,"Without loss of generalization, we can assume vj, v‚àó
j ‚àà{+1, ‚àí1} for all j ‚àà[K]5. From Appendix
I, we know that the sign of v‚àó
j can exactly estimated through tensor initialization. There, we can
focus on analysis the neural network in the form as"
EX,0.9801324503311258,"g(W ; x) = 1 K K
X"
EX,0.9810785241248817,"j=1
v‚àó
j œÜ(wT
j x).
(130)"
EX,0.9820245979186376,"Considering the objective function in (1) and population risk function in (17), we have ‚àÇÀÜf"
EX,0.9829706717123936,"‚àÇwk
(W ) ‚àí‚àÇf"
EX,0.9839167455061495,"‚àÇwk
(W ; p)

2"
EX,0.9848628192999054,"=

Œª
K2N K
X"
EX,0.9858088930936613,"j=1
v‚àó
j
h
N
X n=1"
EX,0.9867549668874173," 
œÜ(wT
j xn) ‚àíœÜ(w‚àóT
j xn)

xn ‚àíEx
 
œÜ(wT
j x) ‚àíœÜ(w[p]T
j
x)

x
i"
EX,0.9877010406811731,+ 1 ‚àíŒª
EX,0.988647114474929,"K2M v‚àó
j K
X j=1 h
M
X m=1"
EX,0.9895931882686849," 
œÜ(wT
j exm) ‚àíœÜ( e
wT
j exm)
exm ‚àíEex
 
œÜ(wT
j ex) ‚àíœÜ(w[p]T
j
ex)
ex
i
2 ‚â§ K
X"
EX,0.9905392620624409,"j=1
¬∑|v‚àó
j | ¬∑

Œª
K2N h
N
X n=1"
EX,0.9914853358561968," 
œÜ(wT
j xn) ‚àíœÜ(w‚àóT
j xn)

xn ‚àíEx
 
œÜ(wT
j x) ‚àíœÜ(w[p]T
j
x)

x
i"
EX,0.9924314096499527,"+ 1 ‚àíŒª K2M h
M
X m=1"
EX,0.9933774834437086," 
œÜ(wT
j exm) ‚àíœÜ( e
wT
j exm)
exm ‚àíEex
 
œÜ(wT
j ex) ‚àíœÜ(w[p]T
j
ex)
ex
i
2 = K
X j=1 Œª
K2N h
N
X n=1"
EX,0.9943235572374646," 
œÜ(wT
j xn) ‚àíœÜ(w‚àóT
j xn)

xn ‚àíEx
 
œÜ(wT
j x) ‚àíœÜ(w[p]T
j
x)

x
i"
EX,0.9952696310312205,"+ 1 ‚àíŒª K2M h
M
X m=1"
EX,0.9962157048249763," 
œÜ(wT
j exm) ‚àíœÜ( e
wT
j exm)
exm ‚àíEex
 
œÜ(wT
j ex) ‚àíœÜ(w[p]T
j
ex)
ex
i
2, (131)"
EX,0.9971617786187322,"which is exact the same as (89). Similar results can be derived for Lemma 12. Therefore, the
conclusions and proofs of Lemma 1 and Lemma 2 does not change at all."
EX,0.9981078524124882,"Additionally, Ô¨Åxing the second-layer weights and only training the hidden layer is the state-of-the-
art practice in analyzing two-layer neural networks (Arora et al., 2019b;a; Allen-Zhu et al., 2019;
Safran & Shamir, 2018; Li & Liang, 2018; Brutzkus & Globerson, 2017; Oymak & Soltanolkotabi,
2018; Zhang et al., 2019). Additionally, as indicated in (Safran & Shamir, 2018), training a one-
hidden-layer neural network with all vj Ô¨Åxed as 1 has intractable many spurious local minima, which
indicates that training problem is not trivial."
EX,0.9990539262062441,"5To see this, one can view |v‚àó
j |w‚àó
j as the new ground truth weights, and the goal for this paper is to recover
the new ground truth weights."
