Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0016233766233766235,"The secondary structure of ribonucleic acid (RNA) is more stable and accessible
1"
ABSTRACT,0.003246753246753247,"in the cell than its tertiary structure, making it essential for functional prediction.
2"
ABSTRACT,0.00487012987012987,"Although deep learning has shown promising results in this ﬁeld, current methods
3"
ABSTRACT,0.006493506493506494,"suffer from poor generalization and high complexity. In this work, we present
4"
ABSTRACT,0.008116883116883116,"RFold, a simple yet effective RNA secondary structure prediction in an end-to-end
5"
ABSTRACT,0.00974025974025974,"manner. RFold introduces a decoupled optimization process that decomposes the
6"
ABSTRACT,0.011363636363636364,"vanilla constraint satisfaction problem into row-wise and column-wise optimization,
7"
ABSTRACT,0.012987012987012988,"simplifying the solving process while guaranteeing the validity of the output.
8"
ABSTRACT,0.01461038961038961,"Moreover, RFold adopts attention maps as informative representations instead of
9"
ABSTRACT,0.016233766233766232,"designing hand-crafted features. Extensive experiments demonstrate that RFold
10"
ABSTRACT,0.017857142857142856,"achieves competitive performance and about eight times faster inference efﬁciency
11"
ABSTRACT,0.01948051948051948,"than the state-of-the-art method.
12"
INTRODUCTION,0.021103896103896104,"1
Introduction
13"
INTRODUCTION,0.022727272727272728,"Ribonucleic acid is essential in structural biology for its diverse functional classes [8, 45, 49, 18]. The
14"
INTRODUCTION,0.024350649350649352,"functions of RNA molecules are determined by their structure [57]. The secondary structure, which
15"
INTRODUCTION,0.025974025974025976,"contains the nucleotide base pairing information, as shown in Fig. 1, is crucial for the correct functions
16"
INTRODUCTION,0.027597402597402596,"of RNA molecules [13, 11, 68]. Although experimental assays such as X-ray crystallography [6],
17"
INTRODUCTION,0.02922077922077922,"nuclear magnetic resonance (NMR) [15], and cryogenic electron microscopy [12] can be implemented
18"
INTRODUCTION,0.030844155844155844,"to determine RNA secondary structure, they suffer from low throughput and expensive cost.
19"
INTRODUCTION,0.032467532467532464,A A C C U G G U C A G G C C C G G A A G G G A G C A G C C A
INTRODUCTION,0.03409090909090909,A A C C U G G U C A G G C C C G G A A G G G A G C A G C C A
INTRODUCTION,0.03571428571428571,"graph representation
matrix representation (contact map)"
INTRODUCTION,0.037337662337662336,"Figure 1: The graph and matrix representation
of an RNA secondary structure example."
INTRODUCTION,0.03896103896103896,"Computational RNA secondary structure predic-
20"
INTRODUCTION,0.040584415584415584,"tion methods have become increasingly popular
21"
INTRODUCTION,0.04220779220779221,"due to their high efﬁciency [31]. Currently, these
22"
INTRODUCTION,0.04383116883116883,"methods can be broadly classiﬁed into two cate-
23"
INTRODUCTION,0.045454545454545456,"gories [50, 14, 55, 60]: (i) comparative sequence
24"
INTRODUCTION,0.04707792207792208,"analysis and (ii) single sequence folding algorithm.
25"
INTRODUCTION,0.048701298701298704,"Comparative sequence analysis determines the sec-
26"
INTRODUCTION,0.05032467532467533,"ondary structure conserved among homologous se-
27"
INTRODUCTION,0.05194805194805195,"quences but the limited known RNA families hin-
28"
INTRODUCTION,0.05357142857142857,"der its development [35, 36, 28, 22, 21, 16, 43].
29"
INTRODUCTION,0.05519480519480519,"Researchers thus resort to single RNA sequence
30"
INTRODUCTION,0.056818181818181816,"folding algorithms that do not need multiple se-
31"
INTRODUCTION,0.05844155844155844,"quence alignment information. A classical cate-
32"
INTRODUCTION,0.060064935064935064,"gory of computational RNA folding algorithms is
33"
INTRODUCTION,0.06168831168831169,"to use dynamic programming (DP) that assumes the
34"
INTRODUCTION,0.0633116883116883,"secondary structure is a result of energy minimiza-
35"
INTRODUCTION,0.06493506493506493,"tion [3, 44, 39, 73, 42, 10]. However, energy-based
36"
INTRODUCTION,0.06655844155844155,"approaches usually require a nested structure, which ignores some biologically essential structures
37"
INTRODUCTION,0.06818181818181818,"such as pseudoknots, i.e., non-nested base pairs [5, 54, 70], as shown in Fig. 2. Since predicting
38"
INTRODUCTION,0.0698051948051948,"secondary structures with pseudoknots under the energy minimization framework has shown to be
39"
INTRODUCTION,0.07142857142857142,"hard and NP-complete [66, 14], deep learning techniques are introduced as an alternative approach.
40"
INTRODUCTION,0.07305194805194805,"A
A
C
U
G
U
A
A
C
U
G
U"
INTRODUCTION,0.07467532467532467,"nested structure
non-nested structure"
INTRODUCTION,0.0762987012987013,"Figure 2: Examples of nested and non-nested
secondary structures."
INTRODUCTION,0.07792207792207792,"Attempts to overcome the limitations of energy-
41"
INTRODUCTION,0.07954545454545454,"based methods have motivated deep learning meth-
42"
INTRODUCTION,0.08116883116883117,"ods in the absence of DP. SPOT-RNA [55] is a
43"
INTRODUCTION,0.08279220779220779,"seminal work that ensembles ResNet [24] and
44"
INTRODUCTION,0.08441558441558442,"LSTM [25] to identify molecular features. SPOT-
45"
INTRODUCTION,0.08603896103896104,"RNA does not constrain the output space into valid
46"
INTRODUCTION,0.08766233766233766,"RNA secondary structures, which degrades its gen-
47"
INTRODUCTION,0.08928571428571429,"eralization ability [32]. E2Efold [5] employs an
48"
INTRODUCTION,0.09090909090909091,"unrolled algorithm for constrained programming
49"
INTRODUCTION,0.09253246753246754,"that post-processes the network output to satisfy
50"
INTRODUCTION,0.09415584415584416,"the constraints. E2Efold introduces a convex relax-
51"
INTRODUCTION,0.09577922077922078,"ation to make the optimization tractable, leading
52"
INTRODUCTION,0.09740259740259741,"to possible constraint violations and poor general-
53"
INTRODUCTION,0.09902597402597403,"ization ability [53, 14]. Developing an appropriate
54"
INTRODUCTION,0.10064935064935066,"optimization that forces the output to be valid be-
55"
INTRODUCTION,0.10227272727272728,"comes an important issue. Apart from the optimization problem, state-of-the-art approaches require
56"
INTRODUCTION,0.1038961038961039,"hand-crafted features and introduce the pre-processing step for such features, which is inefﬁcient and
57"
INTRODUCTION,0.10551948051948051,"needs expert knowledge. CDPfold [72] develops a matrix representation based on sequence pairing
58"
INTRODUCTION,0.10714285714285714,"that reﬂects the implicit matching between bases. UFold [14] follows the exact post-process mecha-
59"
INTRODUCTION,0.10876623376623376,"nism as E2Efold and uses hand-crafted features from CDPfold with U-Net [51] model architecture to
60"
INTRODUCTION,0.11038961038961038,"improve the performance.
61"
INTRODUCTION,0.11201298701298701,"Although promising, current deep learning methods on RNA secondary structure prediction have
62"
INTRODUCTION,0.11363636363636363,"been distressed by: (1) the optimization process that is complicated and poor in generalization and
63"
INTRODUCTION,0.11525974025974026,"(2) the data pre-processing that requires expensive complexity and expert knowledge. In this paper,
64"
INTRODUCTION,0.11688311688311688,"we present RFold, a simple yet effective RNA secondary structure prediction method in an end-to-end
65"
INTRODUCTION,0.1185064935064935,"manner. Speciﬁcally, we introduce a decoupled optimization process that decomposes the vanilla
66"
INTRODUCTION,0.12012987012987013,"constraint satisfaction problem into row-wise and column-wise optimization, simplifying the solving
67"
INTRODUCTION,0.12175324675324675,"process while guaranteeing the validity of the output. Besides, we adopt attention maps as informative
68"
INTRODUCTION,0.12337662337662338,"representations to automatically learn the pair-wise interactions of the nucleotide bases instead of
69"
INTRODUCTION,0.125,"using hand-crafted features to perform data pre-processing. We conduct extensive experiments to
70"
INTRODUCTION,0.1266233766233766,"compare RFold with state-of-the-art methods on several benchmark datasets and show the superior
71"
INTRODUCTION,0.12824675324675325,"performance of our proposed method. Moreover, RFold has faster inference efﬁciency than those
72"
INTRODUCTION,0.12987012987012986,"methods due to its simplicity.
73"
RELATED WORK,0.1314935064935065,"2
Related work
74"
COMPARATIVE SEQUENCE ANALYSIS,0.1331168831168831,"2.1
Comparative Sequence Analysis
75"
COMPARATIVE SEQUENCE ANALYSIS,0.13474025974025974,"Comparative sequence analysis determines base pairs conserved among homologous sequences [55,
76"
COMPARATIVE SEQUENCE ANALYSIS,0.13636363636363635,"17, 28, 36, 35, 19, 20]. ILM [52] combines thermodynamic and mutual information content scores.
77"
COMPARATIVE SEQUENCE ANALYSIS,0.137987012987013,"Sankoff [27] merges the sequence alignment and maximal-pairing folding methods [46]. Dy-
78"
COMPARATIVE SEQUENCE ANALYSIS,0.1396103896103896,"nalign [41] and Carnac [62, 47] are the subsequent variants of Sankoff algorithms. RNA forester [26]
79"
COMPARATIVE SEQUENCE ANALYSIS,0.14123376623376624,"introduces a tree alignment model for global and local alignments. However, the limited number of
80"
COMPARATIVE SEQUENCE ANALYSIS,0.14285714285714285,"known RNA families [21, 16, 43] impedes the development of comparative methods.
81"
ENERGY-BASED FOLDING ALGORITHMS,0.1444805194805195,"2.2
Energy-based Folding Algorithms
82"
ENERGY-BASED FOLDING ALGORITHMS,0.1461038961038961,"When the secondary structure consists only of nested base pairing, dynamic programming can
83"
ENERGY-BASED FOLDING ALGORITHMS,0.14772727272727273,"efﬁciently predict the structure by minimizing energy. Early works in this category include Vienna
84"
ENERGY-BASED FOLDING ALGORITHMS,0.14935064935064934,"RNAfold [39], Mfold [73], RNAstructure [42], and CONTRAfold [10]. Faster implementations that
85"
ENERGY-BASED FOLDING ALGORITHMS,0.15097402597402598,"speed up dynamic programming have been proposed, such as Vienna RNAplfold [4], LocalFold [37],
86"
ENERGY-BASED FOLDING ALGORITHMS,0.1525974025974026,"and LinearFold [30]. However, these methods cannot accurately predict secondary structures with
87"
ENERGY-BASED FOLDING ALGORITHMS,0.15422077922077923,"pseudoknots, as predicting the lowest free energy structures with pseudoknots is NP-complete [40],
88"
ENERGY-BASED FOLDING ALGORITHMS,0.15584415584415584,"making it difﬁcult to improve performance.
89"
LEARNING-BASED FOLDING ALGORITHMS,0.15746753246753248,"2.3
Learning-based Folding Algorithms
90"
LEARNING-BASED FOLDING ALGORITHMS,0.1590909090909091,"SPOT-RNA [55] is a seminal work that employs deep learning for RNA secondary structure predic-
91"
LEARNING-BASED FOLDING ALGORITHMS,0.16071428571428573,"tion. SPOT-RNA2 [56] improves its predecessor by using evolution-derived sequence proﬁles and
92"
LEARNING-BASED FOLDING ALGORITHMS,0.16233766233766234,"mutational coupling. Inspired by Raptor-X [65] and SPOT-Contact [23], SPOT-RNA uses ResNet
93"
LEARNING-BASED FOLDING ALGORITHMS,0.16396103896103897,"and bidirectional LSTM with a sigmoid function to output the secondary structures. MXfold [1] is
94"
LEARNING-BASED FOLDING ALGORITHMS,0.16558441558441558,"also an early work that combines support vector machines and thermodynamic models. CDPfold [72],
95"
LEARNING-BASED FOLDING ALGORITHMS,0.1672077922077922,"DMFold [64], and MXFold2 [53] integrate deep learning techniques with energy-based methods.
96"
LEARNING-BASED FOLDING ALGORITHMS,0.16883116883116883,"E2Efold [5] takes a remarkable step in constraining the output to be valid by learning unrolled
97"
LEARNING-BASED FOLDING ALGORITHMS,0.17045454545454544,"algorithms. However, its relaxation for making the optimization tractable may violate the structural
98"
LEARNING-BASED FOLDING ALGORITHMS,0.17207792207792208,"constraints. UFold [14] further introduces U-Net model architecture to improve performance.
99"
PRELIMINARIES AND BACKGROUNDS,0.1737012987012987,"3
Preliminaries and Backgrounds
100"
PRELIMINARIES,0.17532467532467533,"3.1
Preliminaries
101"
PRELIMINARIES,0.17694805194805194,"The primary structure of RNA is the ordered linear sequence of bases, which is typically represented
102"
PRELIMINARIES,0.17857142857142858,"as a string of letters. Formally, an RNA sequence can be represented as X “ px1, ..., xLq, where xi P
103"
PRELIMINARIES,0.18019480519480519,"tA, U, C, Gu denotes one of the four bases, i.e., Adenine (A), Uracil (U), Cytosine (C), and Guanine
104"
PRELIMINARIES,0.18181818181818182,"(G). The secondary structure of RNA is a contact map represented as a matrix M P t0, 1uLˆL, where
105"
PRELIMINARIES,0.18344155844155843,"Mij “ 1 if the i-th and j-th bases are paired. In the RNA secondary structure prediction problem, we
106"
PRELIMINARIES,0.18506493506493507,"aim to obtain a model with learnable parameters Θ that learns a mapping FΘ : X ÞÑ M by exploring
107"
PRELIMINARIES,0.18668831168831168,"the interactions between bases. Here, we decompose the mapping FΘ into two sub-mappings as:
108"
PRELIMINARIES,0.18831168831168832,"FΘ :“ Hθh ˝ Gθg,
(1)"
PRELIMINARIES,0.18993506493506493,"where Hθh : X ÞÑ H, Gθg : H ÞÑ M are mappings parameterized by θh and θg, respectively.
109"
PRELIMINARIES,0.19155844155844157,"H P RLˆL is regarded as the unconstrained output of neural networks.
110"
BACKGROUNDS,0.19318181818181818,"3.2
Backgrounds
111"
BACKGROUNDS,0.19480519480519481,"It is worth noting that there are hard constraints on the formation of RNA secondary structure,
112"
BACKGROUNDS,0.19642857142857142,"meaning that certain types of pairing are not available [59]. Such constraints [5] can be formally
113"
BACKGROUNDS,0.19805194805194806,"described as follows:
114"
BACKGROUNDS,0.19967532467532467,"• (a) Only three types of nucleotide combinations can form base pairs: B :“ tAU, UAu Y
115"
BACKGROUNDS,0.2012987012987013,"tGC, CGu Y tGU, UGu. For any base pair xixj where xixj R B, Mij “ 0.
116"
BACKGROUNDS,0.20292207792207792,"• (b) No sharp loops within three bases. For any adjacent bases, there can be no pairing between
117"
BACKGROUNDS,0.20454545454545456,"them, i.e., @|i ´ j| ď 3, Mij “ 0.
118"
BACKGROUNDS,0.20616883116883117,"• (c) There can be at most one pair for each base, i.e., @i, řL
j“1 Mij ď 1.
119"
BACKGROUNDS,0.2077922077922078,"The available space of valid secondary structures is all symmetric matrices P t0, 1uLˆL that satisfy
120"
BACKGROUNDS,0.20941558441558442,"the above three constraints. The ﬁrst two constraints can be satisﬁed easily. We deﬁne a constraint
121"
BACKGROUNDS,0.21103896103896103,"matrix Ď
M as: Ď
Mij :“ 1 if xixj P B and |i ´ j| ě 4, and Ď
Mij :“ 0 otherwise. By element-wise
122"
BACKGROUNDS,0.21266233766233766,"multiplication of the network output and the constraint matrix Ď
M, invalid pairs are masked.
123"
BACKGROUNDS,0.21428571428571427,"The critical issue in obtaining a valid RNA secondary structure is the third constraint, i.e., processing
124"
BACKGROUNDS,0.2159090909090909,"the network output to create a symmetric binary matrix that only allows a single ""1"" to exist in each
125"
BACKGROUNDS,0.21753246753246752,"row and column. There are different strategies for dealing with this issue.
126"
BACKGROUNDS,0.21915584415584416,"SPOT-RNA
is a typical kind of method that imposes minor constraints. It takes the original output
127"
BACKGROUNDS,0.22077922077922077,"of neural networks H and directly applies the Sigmoid function, assigning a value of 1 to those
128"
BACKGROUNDS,0.2224025974025974,"greater than 0.5 and 0 to those less than 0.5. This process can be represented as:
129"
BACKGROUNDS,0.22402597402597402,"GpHq “ 1rSigmoidpHqą0.5s d H.
(2)"
BACKGROUNDS,0.22564935064935066,"Here, the offset term s has been set to 0.5. No explicit constraints are imposed, and no additional
130"
BACKGROUNDS,0.22727272727272727,"parameters θg are required.
131"
BACKGROUNDS,0.2288961038961039,"E2Efold
formulates the problem with constrained optimization and introduces an intermediate
132"
BACKGROUNDS,0.2305194805194805,"variable x
M P RLˆL. It aims to maximize the predeﬁned score function:
133"
BACKGROUNDS,0.23214285714285715,"Sp x
M, Hq “ 1 2"
BACKGROUNDS,0.23376623376623376,"A
H ´ s, T p x
Mq
E
´ ρ} x
M}1,
(3)"
BACKGROUNDS,0.2353896103896104,"where T p x
Mq “ 1"
"P X
M D X",0.237012987012987,"2p x
M d x
M ` p x
M d x
MqT q d Ď
M ensures the output is a symmetric matrix that
134"
"P X
M D X",0.23863636363636365,"satisﬁes the constraints (a-b), s is an offset term that is set as logp9.0q here, x¨, ¨y denotes matrix inner
135"
"P X
M D X",0.24025974025974026,"product and ρ} x
M}1 is a ℓ1 penalty term to make the matrix to be sparse.
136"
"P X
M D X",0.2418831168831169,"The constraint (c) is imposed by requiring Eq. 3 to satisfy T p x
Mq1 ď 1. Thus, Eq. 3 is rewritten as:
137"
"P X
M D X",0.2435064935064935,"Sp x
M, Hq “ min
λě0
1
2"
"P X
M D X",0.24512987012987014,"A
H ´ s, T p x
Mq
E
´ ρ} x
M}1
´
A
λ, ReLUpT p x
Mq1 ´ 1q
E
,
(4)"
"P X
M D X",0.24675324675324675,"where λ P RL
` is a Lagrange multiplier.
138"
"P X
M D X",0.2483766233766234,"Formally, this process can be represented as:
139"
"P X
M D X",0.25,"GθgpHq “ T parg max x
MPRLˆLSp x
M, Hqq.
(5)"
"P X
M D X",0.25162337662337664,"Though three constraints are explicitly imposed in E2Efold, this method requires iterative steps to
140"
"P X
M D X",0.2532467532467532,"approximate the valid solutions and cannot guarantee that the results are entirely valid. Moreover, it
141"
"P X
M D X",0.25487012987012986,"needs a set of parameters θg in this processing, making tuning the model complex.
142"
RFOLD,0.2564935064935065,"4
RFold
143"
DECOUPLED OPTIMIZATION,0.25811688311688313,"4.1
Decoupled Optimization
144"
DECOUPLED OPTIMIZATION,0.2597402597402597,"We propose the following formulation for the constrained optimization problem in RNA secondary
145"
DECOUPLED OPTIMIZATION,0.26136363636363635,"structure problem:
146"
DECOUPLED OPTIMIZATION,0.262987012987013,"min
M ´ trpM T x
Hq s.t. L
ÿ"
DECOUPLED OPTIMIZATION,0.26461038961038963,"j“1
Mij ď 1, @i; L
ÿ"
DECOUPLED OPTIMIZATION,0.2662337662337662,"i“1
Mij ď 1, @j,
(6)"
DECOUPLED OPTIMIZATION,0.26785714285714285,"where trpM T x
Hq “ řL
i“1
řL
j“1 Mij x
Hij represents the trace operation. The matrix x
H is sym-
147"
DECOUPLED OPTIMIZATION,0.2694805194805195,"metrized based on the original network output H while satisfying the constraints (a-b) in Sec. 3.2 by
148"
DECOUPLED OPTIMIZATION,0.2711038961038961,"multiplying the constraint matrix Ď
M, i.e., x
H “ pH d HT q d Ď
M.
149"
DECOUPLED OPTIMIZATION,0.2727272727272727,"We then propose to decouple the optimization process into row-wise and column-wise optimizations,
150"
DECOUPLED OPTIMIZATION,0.27435064935064934,"and deﬁne the corresponding selection schemes as Sr and Sc respectively:
151"
DECOUPLED OPTIMIZATION,0.275974025974026,"Sr “ tS1
r, S2
r, ..., SL
r u, Sc “ tS1
c, S2
c, ..., SL
c u,
(7)"
DECOUPLED OPTIMIZATION,0.2775974025974026,"where Si
r P t0, 1uL signiﬁes the selection scheme on the ith row, and Sj
c P t0, 1uL represents the
152"
DECOUPLED OPTIMIZATION,0.2792207792207792,"selection scheme on the jth column. The score function is deﬁned as:
153"
DECOUPLED OPTIMIZATION,0.28084415584415584,"SpSr, Sc, x
Hq “ ´trpM T x
Hq,
(8)"
DECOUPLED OPTIMIZATION,0.2824675324675325,"where Sr, Sc constitute the decomposition of M. The goal of the score function is to maximize
154"
DECOUPLED OPTIMIZATION,0.2840909090909091,"the dot product of M and x
H in order to select the maximum value in x
H. Our proposed decoupled
155"
DECOUPLED OPTIMIZATION,0.2857142857142857,"optimization reformulates the original constrained optimization problem in Equation 6 as follows:
156"
DECOUPLED OPTIMIZATION,0.28733766233766234,"min
Sr,Sc SpSr, Scq s.t. L
ÿ"
DECOUPLED OPTIMIZATION,0.288961038961039,"i“1
Si
r ď 1, @i; L
ÿ"
DECOUPLED OPTIMIZATION,0.2905844155844156,"j“1
Sj
c ď 1, @j.
(9)"
DECOUPLED OPTIMIZATION,0.2922077922077922,"If the corresponding x
Hij have the highest score in its row tx
HikuL
k“1 and its column tx
HkjuL
k“1, then
157"
DECOUPLED OPTIMIZATION,0.29383116883116883,"Mij “ 1. By exploring the optimal Sr and Sc, the chosen base pairs can be obtained by the optimal
158"
DECOUPLED OPTIMIZATION,0.29545454545454547,"scheme S “ Sr b Sc.
159"
ROW-COL ARGMAX,0.29707792207792205,"4.2
Row-Col Argmax
160"
ROW-COL ARGMAX,0.2987012987012987,"With the proposed decoupled optimization, the optimal matrix can be easily obtained using the variant
161"
ROW-COL ARGMAX,0.3003246753246753,"Argmax function:
162"
ROW-COL ARGMAX,0.30194805194805197,"Row-Col-Argmaxpx
Hq “ Row-Argmaxpx
Hq d Col-Argmaxpx
Hq
(10)"
ROW-COL ARGMAX,0.30357142857142855,"where Row-Argmax and Col-Argmax are row-wise and column-wise Argmax functions respectively:
163 164"
ROW-COL ARGMAX,0.3051948051948052,"Row-Argmaxijpx
Hq “"
ROW-COL ARGMAX,0.3068181818181818,"#
1, if maxtx
HikuL
k“1 “ x
Hij,
0, otherwise."
ROW-COL ARGMAX,0.30844155844155846,"Col-Argmaxijpx
Hq “"
ROW-COL ARGMAX,0.31006493506493504,"#
1, if maxtx
HkjuL
k“1 “ x
Hij,
0, otherwise. (11)"
ROW-COL ARGMAX,0.3116883116883117,"Theorem 1. Given a symmetric matrix x
H P RLˆL, the matrix Row-Col-Argmaxpx
Hq is also a
165"
ROW-COL ARGMAX,0.3133116883116883,"symmetric matrix.
166"
ROW-COL ARGMAX,0.31493506493506496,"Proof: See Appendix C.1.
167"
ROW-COL ARGMAX,0.31655844155844154,"As shown in Fig. 3, taking a random symmetric 6 ˆ 6 matrix as an example, we show the output
168"
ROW-COL ARGMAX,0.3181818181818182,"matrics of Row-Argmax, Col-Argmax, and Row-Col-Argmax functions, respectively. The Row-Col
169"
ROW-COL ARGMAX,0.3198051948051948,"Argmax selects the value that has the maximum value on both its row and column while keeping the
170"
ROW-COL ARGMAX,0.32142857142857145,"output matrix symmetric.
171"
ROW-COL ARGMAX,0.32305194805194803,"symmetric matrix
Row-Argmax
Col-Argmax
Row-Col-Argmax"
ROW-COL ARGMAX,0.3246753246753247,Figure 3: The visualization of the Row-Col-Argmax function.
ROW-COL ARGMAX,0.3262987012987013,"From Theorem 1, we can observe that Row-Col-Argmaxpx
Hq is a symmetric matrix that satisﬁes the
172"
ROW-COL ARGMAX,0.32792207792207795,"constraint (c). Since x
H already satisﬁes constraints (a-b), the optimized output is:
173"
ROW-COL ARGMAX,0.32954545454545453,"GpHq “ Sr b Sc “ Row-Col-Argmaxpx
Hq,
(12)"
ROW-COL ARGMAX,0.33116883116883117,"where Sr, Sc “ arg minSr,Sc ´trpSr, Scq.
174"
ROW-COL SOFTMAX,0.3327922077922078,"4.3
Row-Col Softmax
175"
ROW-COL SOFTMAX,0.3344155844155844,"Though the Row-Col Argmax function can obtain the optimal matrix GpHq, it is not differentiable
176"
ROW-COL SOFTMAX,0.336038961038961,"and thus cannot be directly used in the training process. In the training phase, we need to use a
177"
ROW-COL SOFTMAX,0.33766233766233766,"differentiable function to approximate the optimal results. Therefore, we propose using a Row-Col
178"
ROW-COL SOFTMAX,0.3392857142857143,"Softmax function to approximate the Row-Col Argmax function for training. To achieve this, we
179"
ROW-COL SOFTMAX,0.3409090909090909,"perform row-wise Softmax and column-wise Softmax on the symmetric matrix x
H separately, as
180"
ROW-COL SOFTMAX,0.3425324675324675,"shown below:
181"
ROW-COL SOFTMAX,0.34415584415584416,"Row-Softmaxijpx
Hq “
exppx
Hijq
řL
k“1 exppx
Hikq
,"
ROW-COL SOFTMAX,0.3457792207792208,"Col-Softmaxijpx
Hq “
exppx
Hijq
řL
k“1 exppx
Hkjq
. (13)"
ROW-COL SOFTMAX,0.3474025974025974,"The Row-Col Softmax function is then deﬁned as follows:
182"
ROW-COL SOFTMAX,0.349025974025974,"Row-Col-Softmaxpx
Hq “ 1"
PROW-SOFTMAXPX,0.35064935064935066,"2pRow-Softmaxpx
Hq ` Col-Softmaxpx
Hqq,
(14)"
PROW-SOFTMAXPX,0.3522727272727273,"Note that we use the average of Row-Softmaxpx
Hq and Col-Softmaxpx
Hq instead of the element
183"
PROW-SOFTMAXPX,0.3538961038961039,"product as shown in Equ. 10 for the convenience of optimization.
184"
PROW-SOFTMAXPX,0.3555194805194805,"Theorem 2. Given a symmetric matrix x
H P RLˆL, the matrix Row-Col-Softmaxpx
Hq is also a
185"
PROW-SOFTMAXPX,0.35714285714285715,"symmetric matrix.
186"
PROW-SOFTMAXPX,0.3587662337662338,"Proof: See Appendix C.2.
187"
PROW-SOFTMAXPX,0.36038961038961037,"As shown in Fig. 4, taking a random symmetric 6 ˆ 6 matrix as an example, we show the output
188"
PROW-SOFTMAXPX,0.362012987012987,"matrics of Row-Softmax, Col-Softmax, and Row-Col-Softmax functions, respectively. It can be
189"
PROW-SOFTMAXPX,0.36363636363636365,"seen that the output matrix of Row-Col-Softmax is still symmetric. Leveraging the differentiable
190"
PROW-SOFTMAXPX,0.3652597402597403,"property of Row-Col-Softmax, the model can be easily optimized.
191"
PROW-SOFTMAXPX,0.36688311688311687,"symmetric matrix
Row-Softmax
Col-Softmax
Row-Col-Softmax"
PROW-SOFTMAXPX,0.3685064935064935,Figure 4: The visualization of the Row-Col-Softmax function.
PROW-SOFTMAXPX,0.37012987012987014,"In the training phase, we apply the differentiable Row-Col Softmax activation and optimize the mean
192"
PROW-SOFTMAXPX,0.3717532467532468,"square error (MSE) loss function between GpHq and M:
193"
PROW-SOFTMAXPX,0.37337662337662336,"LpGpHq, Mq “ 1"
PROW-SOFTMAXPX,0.375,"L2 }Row-Col-Softmaxpx
Hq ´ M}2.
(15)"
PROW-SOFTMAXPX,0.37662337662337664,"4.4
Seq2map Attention
194"
PROW-SOFTMAXPX,0.3782467532467532,sequence one-hot
PROW-SOFTMAXPX,0.37987012987012986,𝑿:  𝐿×4
PROW-SOFTMAXPX,0.3814935064935065,Token embedding 𝐿×𝐷
PROW-SOFTMAXPX,0.38311688311688313,Seq2map Attention 𝐿×𝐿×1 +
PROW-SOFTMAXPX,0.3847402597402597,"Positional 
embedding 𝐿×𝐷"
PROW-SOFTMAXPX,0.38636363636363635,"1 32
32
64 128 64"
PROW-SOFTMAXPX,0.387987012987013,"256
512 256 128 𝐿×𝐿"
PROW-SOFTMAXPX,0.38961038961038963,(𝐿/2)×(𝐿/2)
PROW-SOFTMAXPX,0.3912337662337662,(𝐿/4)×(𝐿/4)
PROW-SOFTMAXPX,0.39285714285714285,(𝐿/8)×(𝐿/8)
PROW-SOFTMAXPX,0.3944805194805195,(𝐿/16)×(𝐿/16) 1 𝐿×𝐿 𝑯 𝒁+ 𝒁
PROW-SOFTMAXPX,0.3961038961038961,Figure 5: The overview model of RFold.
PROW-SOFTMAXPX,0.3977272727272727,"To simplify the pre-processing step that con-
195"
PROW-SOFTMAXPX,0.39935064935064934,"structs hand-crafted features based on RNA se-
196"
PROW-SOFTMAXPX,0.400974025974026,"quences, we propose a Seq2map attention mod-
197"
PROW-SOFTMAXPX,0.4025974025974026,"ule that can automatically produce informative
198"
PROW-SOFTMAXPX,0.4042207792207792,"representations. We start with a sequence in the
199"
PROW-SOFTMAXPX,0.40584415584415584,"one-hot form X P RLˆ4 and obtain the sum of
200"
PROW-SOFTMAXPX,0.4074675324675325,"the token embedding and positional embedding
201"
PROW-SOFTMAXPX,0.4090909090909091,"as the input for the Seq2map attention. For con-
202"
PROW-SOFTMAXPX,0.4107142857142857,"venience, we denote the input as Z P RLˆD,
203"
PROW-SOFTMAXPX,0.41233766233766234,"where D is the hidden layer size of the token
204"
PROW-SOFTMAXPX,0.413961038961039,"and positional embeddings.
205"
PROW-SOFTMAXPX,0.4155844155844156,"Motivated by the recent progress in attention
206"
PROW-SOFTMAXPX,0.4172077922077922,"mechanisms [63, 9, 34, 7, 33, 48, 29, 69, 38], we
207"
PROW-SOFTMAXPX,0.41883116883116883,"aim to develop a highly effective sequence-to-
208"
PROW-SOFTMAXPX,0.42045454545454547,"map transformation based on pair-wise attention.
209"
PROW-SOFTMAXPX,0.42207792207792205,"We obtain the query Q P RLˆD and key K P
210"
PROW-SOFTMAXPX,0.4237012987012987,"RLˆD by applying per-dim scalars and offsets to Z:
211"
PROW-SOFTMAXPX,0.4253246753246753,"Q “ γQZ ` βQ, K “ γKZ ` βK,
(16)"
PROW-SOFTMAXPX,0.42694805194805197,"where γQ, γK, βQ, βK P RLˆD are learnable parameters.
212"
PROW-SOFTMAXPX,0.42857142857142855,"Then, the pair-wise attention map is obtained by:
213"
PROW-SOFTMAXPX,0.4301948051948052,"sZ “ ReLU2pQKT {Lq,
(17)"
PROW-SOFTMAXPX,0.4318181818181818,"where ReLU2 is an activation function that can be recognized as a simpliﬁed Softmax function in
214"
PROW-SOFTMAXPX,0.43344155844155846,"vanilla Transformers [58]. The output of Seq2map is the gated representation of sZ:
215"
PROW-SOFTMAXPX,0.43506493506493504,"pZ “ sZ d σp sZq,
(18)"
PROW-SOFTMAXPX,0.4366883116883117,"where σp¨q is the Sigmoid function that performs as a gate operation.
216"
PROW-SOFTMAXPX,0.4383116883116883,"As shown in Fig. 5, we identify the problem of predicting H P RLˆL from the given sequence
217"
PROW-SOFTMAXPX,0.43993506493506496,"attention map pZ P RLˆL as an image-to-image segmentation problem and apply the U-Net model
218"
PROW-SOFTMAXPX,0.44155844155844154,"architecture to extract pair-wise information.
219"
EXPERIMENTS,0.4431818181818182,"5
Experiments
220"
EXPERIMENTS,0.4448051948051948,"We conduct experiments to compare our proposed RFold with state-of-the-art and commonly used
221"
EXPERIMENTS,0.44642857142857145,"methods in the ﬁeld of RNA secondary structure prediction. Multiple experimental settings are
222"
EXPERIMENTS,0.44805194805194803,"taken into account, including standard RNA secondary structure prediction, generalization evaluation,
223"
EXPERIMENTS,0.4496753246753247,"large-scale benchmark evaluation, and inference time comparison. Ablation studies are also presented.
224"
EXPERIMENTS,0.4512987012987013,"Datasets
We use three benchmark datasets: (i) RNAStralign [61], one of the most comprehensive
225"
EXPERIMENTS,0.45292207792207795,"collections of RNA structures, is composed of 37,149 structures from 8 RNA types; (ii) ArchiveII [57],
226"
EXPERIMENTS,0.45454545454545453,"a widely used benchmark dataset in classical RNA folding methods, containing 3,975 RNA structures
227"
EXPERIMENTS,0.45616883116883117,"from 10 RNA types; (iii) bpRNA [55], is a large scale benchmark dataset, containing 102,318
228"
EXPERIMENTS,0.4577922077922078,"structures from 2,588 RNA types.
229"
EXPERIMENTS,0.4594155844155844,"Baselines
We compare our proposed RFold with baselines including energy-based folding methods
230"
EXPERIMENTS,0.461038961038961,"such as Mfold [73], RNAsoft [2], RNAfold [39], RNAstructure [42], CONTRAfold [10], Con-
231"
EXPERIMENTS,0.46266233766233766,"textfold [71], and LinearFold [30]; learning-based folding methods such as SPOT-RNA [55], Exter-
232"
EXPERIMENTS,0.4642857142857143,"nafold [67], E2Efold [5], MXfold2 [53], and UFold [14].
233"
EXPERIMENTS,0.4659090909090909,"Metrics
We evaluate the performance by precision, recall, and F1 score, which are deﬁned as:
234"
EXPERIMENTS,0.4675324675324675,"Precision “
TP
TP ` FP, Recall “
TP
TP ` FN, F1 “ 2 Precision ¨ Recall"
EXPERIMENTS,0.46915584415584416,"Precision ` Recall,
(19)"
EXPERIMENTS,0.4707792207792208,"where TP, FP, and FN denote true positive, false positive and false negative, respectively.
235"
EXPERIMENTS,0.4724025974025974,"Implementation details
Following [14], we train the model for 100 epochs with the Adam opti-
236"
EXPERIMENTS,0.474025974025974,"mizer. The learning rate is 0.001, and the batch size is 1 for sequences with different lengths.
237"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.47564935064935066,"5.1
Standard RNA Secondary Structure Prediction
238"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.4772727272727273,"Table 1: Results on RNAStralign test set. Results
in bold and underlined are the top-1 and top-2
performances, respectively."
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.4788961038961039,"Method
Precision
Recall
F1"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.4805194805194805,"Mfold
0.450
0.398
0.420
RNAfold
0.516
0.568
0.540
RNAstructure
0.537
0.568
0.550
CONTRAfold
0.608
0.663
0.633
LinearFold
0.620
0.606
0.609
CDPfold
0.633
0.597
0.614
E2Efold
0.866
0.788
0.821
UFold
0.905
0.927
0.915
RFold
0.981
0.973
0.977"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.48214285714285715,"Following [5], we split the RNAStralign dataset
239"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.4837662337662338,"into training, validation, and testing sets by strat-
240"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.48538961038961037,"iﬁed sampling to ensure every set has all RNA
241"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.487012987012987,"types. We report the experimental results in Ta-
242"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.48863636363636365,"ble 1. It can be seen that energy-based methods
243"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.4902597402597403,"achieve relatively weak F1 scores ranging from
244"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.49188311688311687,"0.420 to 0.633. Learning-based folding algo-
245"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.4935064935064935,"rithms like E2Efold and UFold can signiﬁcantly
246"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.49512987012987014,"improve performance by large margins, while
247"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.4967532467532468,"RFold obtain even better performance among all
248"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.49837662337662336,"the metrics. Moreover, RFold obtains about 8%
249"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.5,"higher precision than the state-of-the-art method.
250"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.5016233766233766,"This phenomenon suggests that our proposed de-
251"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.5032467532467533,"coupled optimization is strict to satisfy all the
252"
STANDARD RNA SECONDARY STRUCTURE PREDICTION,0.5048701298701299,"hard constraints for predicting valid structures.
253"
GENERALIZATION EVALUATION,0.5064935064935064,"5.2
Generalization Evaluation
254"
GENERALIZATION EVALUATION,0.5081168831168831,"To verify the generalization ability of our proposed RFold, we directly evaluate the performance
255"
GENERALIZATION EVALUATION,0.5097402597402597,"on another benchmark dataset ArchiveII using the pre-trained model on the RNAStralign training
256"
GENERALIZATION EVALUATION,0.5113636363636364,"dataset. Following [5], we exclude RNA sequences in ArchiveII that have overlapping RNA types
257"
GENERALIZATION EVALUATION,0.512987012987013,"with the RNAStralign dataset for a fair comparison. The results are reported in Table 2.
258"
GENERALIZATION EVALUATION,0.5146103896103896,"It can be seen that traditional methods achieve F1 scores in the range of 0.545 to 0.842. Among
259"
GENERALIZATION EVALUATION,0.5162337662337663,"the state-of-the-art methods, RFold attains the highest F1 score. It is noteworthy that RFold has a
260"
GENERALIZATION EVALUATION,0.5178571428571429,"relatively lower recall metric and signiﬁcantly higher precision metric. This phenomenon may be
261"
GENERALIZATION EVALUATION,0.5194805194805194,"due to the strict constraints imposed by RFold. Although none of the current learning-based methods
262"
GENERALIZATION EVALUATION,0.5211038961038961,"can meet all the constraints presented in Sec. 3.2, the predictions made by RFold are guaranteed to
263"
GENERALIZATION EVALUATION,0.5227272727272727,"be valid. Therefore, RFold may cover fewer pairwise interactions, resulting in a lower recall metric.
264"
GENERALIZATION EVALUATION,0.5243506493506493,"Nonetheless, the highest F1 score indicates the excellent generalization ability of RFold.
265"
GENERALIZATION EVALUATION,0.525974025974026,Table 2: Results on ArchiveII dataset.
GENERALIZATION EVALUATION,0.5275974025974026,"Method
Precision
Recall
F1"
GENERALIZATION EVALUATION,0.5292207792207793,"Mfold
0.668
0.590
0.621
RNAfold
0.663
0.613
0.631
RNAstructure
0.664
0.606
0.628
CONTRAfold
0.696
0.651
0.665
LinearFold
0.724
0.605
0.647
RNAsoft
0.665
0.594
0.622
Eternafold
0.667
0.622
0.636
E2Efold
0.734
0.660
0.686
SPOT-RNA
0.743
0.726
0.711
MXfold2
0.788
0.760
0.768
Contextfold
0.873
0.821
0.842
UFold
0.887
0.928
0.905
RFold
0.938
0.910
0.921"
GENERALIZATION EVALUATION,0.5308441558441559,Table 3: Results on bpRNA-TS0 set.
GENERALIZATION EVALUATION,0.5324675324675324,"Method
Precision
Recall
F1"
GENERALIZATION EVALUATION,0.5340909090909091,"Mfold
0.501
0.627
0.538
E2Efold
0.140
0.129
0.130
RNAstructure
0.494
0.622
0.533
RNAsoft
0.497
0.626
0.535
RNAfold
0.494
0.631
0.536
Contextfold
0.529
0.607
0.546
LinearFold
0.561
0.581
0.550
MXfold2
0.519
0.646
0.558
Externafold
0.516
0.666
0.563
CONTRAfold
0.528
0.655
0.567
SPOT-RNA
0.594
0.693
0.619
UFold
0.521
0.588
0.553
RFold
0.692
0.635
0.644"
LARGE-SCALE BENCHMARK EVALUATION,0.5357142857142857,"5.3
Large-scale Benchmark Evaluation
266"
LARGE-SCALE BENCHMARK EVALUATION,0.5373376623376623,"The large-scale benchmark dataset bpRNA has a ﬁxed training set (TR0), evaluation set (VL0),
267"
LARGE-SCALE BENCHMARK EVALUATION,0.538961038961039,"and testing set (TS0). Following [55, 53, 14], we train the model in bpRNA-TR0 and evaluate the
268"
LARGE-SCALE BENCHMARK EVALUATION,0.5405844155844156,"performance on bpRNA-TS0 by using the best model learned from bpRNA-VL0. We summarize
269"
LARGE-SCALE BENCHMARK EVALUATION,0.5422077922077922,"the evaluation results in Table 3. It can be seen that RFold signiﬁcantly improves the previous
270"
LARGE-SCALE BENCHMARK EVALUATION,0.5438311688311688,"state-of-the-art method SPOT-RNA by 4.0% in the F1 score.
271"
LARGE-SCALE BENCHMARK EVALUATION,0.5454545454545454,Table 4: Results on long-range bpRNA-TS0 set.
LARGE-SCALE BENCHMARK EVALUATION,0.547077922077922,"Method
Precision
Recall
F1"
LARGE-SCALE BENCHMARK EVALUATION,0.5487012987012987,"Mfold
0.315
0.450
0.356
RNAfold
0.304
0.448
0.350
RNAstructure
0.299
0.428
0.339
CONTRAfold
0.306
0.439
0.349
LinearFold
0.281
0.355
0.305
RNAsoft
0.310
0.448
0.353
Externafold
0.308
0.458
0.355
SPOT-RNA
0.361
0.492
0.403
MXfold2
0.318
0.450
0.360
Contextfold
0.332
0.432
0.363
UFold
0.543
0.631
0.584
RFold
0.803
0.765
0.701"
LARGE-SCALE BENCHMARK EVALUATION,0.5503246753246753,"Following [14], we conduct an experiment
272"
LARGE-SCALE BENCHMARK EVALUATION,0.551948051948052,"on long-range interactions. The bpRNA-TS0
273"
LARGE-SCALE BENCHMARK EVALUATION,0.5535714285714286,"dataset contains more versatile RNA sequences
274"
LARGE-SCALE BENCHMARK EVALUATION,0.5551948051948052,"of different lengths and various types, which can
275"
LARGE-SCALE BENCHMARK EVALUATION,0.5568181818181818,"be a reliable evaluation. Given a sequence of
276"
LARGE-SCALE BENCHMARK EVALUATION,0.5584415584415584,"length L, the long-range base pairing is deﬁned
277"
LARGE-SCALE BENCHMARK EVALUATION,0.560064935064935,"as the paired and unpaired bases with intervals
278"
LARGE-SCALE BENCHMARK EVALUATION,0.5616883116883117,"longer than L{2. As shown in Table 4, RFold
279"
LARGE-SCALE BENCHMARK EVALUATION,0.5633116883116883,"performs unexpectedly well on these long-range
280"
LARGE-SCALE BENCHMARK EVALUATION,0.564935064935065,"base pairing predictions. We can also ﬁnd that
281"
LARGE-SCALE BENCHMARK EVALUATION,0.5665584415584416,"UFold performs better in long-range cases than
282"
LARGE-SCALE BENCHMARK EVALUATION,0.5681818181818182,"the complete cases. The possible reason may
283"
LARGE-SCALE BENCHMARK EVALUATION,0.5698051948051948,"come from the U-Net model architecture that
284"
LARGE-SCALE BENCHMARK EVALUATION,0.5714285714285714,"learns multi-scale features. RFold signiﬁcantly
285"
LARGE-SCALE BENCHMARK EVALUATION,0.573051948051948,"improves UFold in all the metrics by large mar-
286"
LARGE-SCALE BENCHMARK EVALUATION,0.5746753246753247,"gins, demonstrating its strong predictive ability.
287"
INFERENCE TIME COMPARISON,0.5762987012987013,"5.4
Inference Time Comparison
288
Table 5: Inference time on the RNAStralign."
INFERENCE TIME COMPARISON,0.577922077922078,"Method
Time"
INFERENCE TIME COMPARISON,0.5795454545454546,"CDPfold (Tensorﬂow)
300.11 s
RNAstructure (C)
142.02 s
CONTRAfold (C++)
30.58 s
Mfold (C)
7.65 s
Eternafold (C++)
6.42 s
RNAsoft (C++)
4.58 s
RNAfold (C)
0.55 s
LinearFold (C++)
0.43 s
SPOT-RNA(Pytorch)
77.80 s (GPU)
E2Efold (Pytorch)
0.40 s (GPU)
MXfold2 (Pytorch)
0.31 s (GPU)
UFold (Pytorch)
0.16 s (GPU)
RFold (Pytorch)
0.02 s (GPU)"
INFERENCE TIME COMPARISON,0.5811688311688312,"We compared the running time of various methods
289"
INFERENCE TIME COMPARISON,0.5827922077922078,"for predicting RNA secondary structures using the
290"
INFERENCE TIME COMPARISON,0.5844155844155844,"RNAStralign testing set with the same experimen-
291"
INFERENCE TIME COMPARISON,0.586038961038961,"tal setting as in [14]. The results are presented in
292"
INFERENCE TIME COMPARISON,0.5876623376623377,"Table 5, which shows the average inference time
293"
INFERENCE TIME COMPARISON,0.5892857142857143,"per sequence. The fastest energy-based method is
294"
INFERENCE TIME COMPARISON,0.5909090909090909,"LinearFold, which takes an average of about 0.43s
295"
INFERENCE TIME COMPARISON,0.5925324675324676,"for each sequence. The previous learning-based
296"
INFERENCE TIME COMPARISON,0.5941558441558441,"baseline, UFold, takes about 0.16s. RFold has the
297"
INFERENCE TIME COMPARISON,0.5957792207792207,"highest inference speed, costing only about 0.02s
298"
INFERENCE TIME COMPARISON,0.5974025974025974,"per sequence. In particular, RFold is about eight
299"
INFERENCE TIME COMPARISON,0.599025974025974,"times faster than UFold and sixteen times faster than
300"
INFERENCE TIME COMPARISON,0.6006493506493507,"MXfold2. The fast inference time of RFold is due
301"
INFERENCE TIME COMPARISON,0.6022727272727273,"to its simple sequence-to-map transformation.
302"
ABLATION STUDY,0.6038961038961039,"5.5
Ablation Study
303"
ABLATION STUDY,0.6055194805194806,"Decoupled Optimization
To validate the effectiveness of our proposed decoupled optimization,
304"
ABLATION STUDY,0.6071428571428571,"we conduct an experiment that replaces them with other strategies. The results are summarized in
305"
ABLATION STUDY,0.6087662337662337,"Table 6, where RFold-E and RFold-S denote our model with the strategies of E2Efold and SPOT-RNA,
306"
ABLATION STUDY,0.6103896103896104,"respectively. We ignore the recent UFold because it follows exactly the same strategy as E2Efold.
307"
ABLATION STUDY,0.612012987012987,"We also report the validity which is a sample-level metric evaluating whether all the constraints are
308"
ABLATION STUDY,0.6136363636363636,"satisﬁed. Though RFold-E has comparable performance in the ﬁrst three metrics with ours, many
309"
ABLATION STUDY,0.6152597402597403,"of its predicted structures are invalid. The strategy of SPOT-RNA has incorporated no constraint
310"
ABLATION STUDY,0.6168831168831169,"that results in its low validity. Moreover, its strategy seems to not ﬁt our model well, which may be
311"
ABLATION STUDY,0.6185064935064936,"caused by the simplicity of our RFold model.
312"
ABLATION STUDY,0.6201298701298701,"Table 6: Ablation study on optimzation
strategies (RNAStralign testing set)."
ABLATION STUDY,0.6217532467532467,"Method
Precision
Recall
F1
Validity"
ABLATION STUDY,0.6233766233766234,"RFold
0.981
0.973
0.977
100.00%
RFold-E
0.888
0.906
0.896
50.31%
RFold-S
0.223
0.988
0.353
0.00%"
ABLATION STUDY,0.625,"Table 7: Ablation study on pre-processing
strategies (RNAStralign testing set)."
ABLATION STUDY,0.6266233766233766,"Method
Precision
Recall
F1
Time"
ABLATION STUDY,0.6282467532467533,"RFold
0.981
0.973
0.977
0.0167
RFold-U
0.875
0.941
0.906
0.0507
RFold-SS
0.886
0.945
0.913
0.0158"
ABLATION STUDY,0.6298701298701299,"Seq2map Attention
We also conduct an experiment to evaluate the proposed Seq2map attention.
313"
ABLATION STUDY,0.6314935064935064,"We replace the Seq2map attention with the hand-crafted features from UFold and the outer concate-
314"
ABLATION STUDY,0.6331168831168831,"nation from SPOT-RNA, which are denoted as RFold-U and RFold-SS, respectively. In addition to
315"
ABLATION STUDY,0.6347402597402597,"performance metrics, we also report the average inference time for each RNA sequence to evaluate
316"
ABLATION STUDY,0.6363636363636364,"the model complexity. We summarize the result in Table 7. It can be seen that RFold-U takes much
317"
ABLATION STUDY,0.637987012987013,"more inference time than our RFold and RFold-SS due to the heavy computational cost when loading
318"
ABLATION STUDY,0.6396103896103896,"and learning from hand-crafted features. Moreover, it is surprising to ﬁnd that RFold-SS has a little
319"
ABLATION STUDY,0.6412337662337663,"better performance than RFold-U, with the least inference time for its simple outer concatenation
320"
ABLATION STUDY,0.6428571428571429,"operation. However, neither RFold-U nor RFold-SS can provide informative representations.
321"
VISUALIZATION,0.6444805194805194,"5.6
Visualization
322"
VISUALIZATION,0.6461038961038961,"We visualize two examples predicted by RFold and UFold in Fig. 6. The corresponding F1 scores are
323"
VISUALIZATION,0.6477272727272727,"denoted at the bottom of each plot. The ﬁrst secondary structures is a simple example of a nested
324"
VISUALIZATION,0.6493506493506493,"structure. It can be seen that UFold may fail in such a case. The second secondary structures is much
325"
VISUALIZATION,0.650974025974026,"more difﬁcult that contains over 300 bases of the non-nested structure. While UFold fails in such a
326"
VISUALIZATION,0.6525974025974026,"complex case, RFold can predict the structure accurately. Due to the limited space, we provide more
327"
VISUALIZATION,0.6542207792207793,"visualization comparisons in Appendix D.
328"
VISUALIZATION,0.6558441558441559,"RFold
True
UFold A A C C A U U A A G G
A A U A G A
C C A A G C
U C U A G G U G G U"
VISUALIZATION,0.6574675324675324,"U
G
A
G A A A C C C C
U U U G U A U U
A
G U C C U G G A
A A C A G G G"
VISUALIZATION,0.6590909090909091,"C
G
A
C A U U G U"
VISUALIZATION,0.6607142857142857,"C
A
A
A U"
VISUALIZATION,0.6623376623376623,"U
G
U
U C G G G
G
A C C A C C C
G
C U A A A U
U A C A U G C U A C C
G C A G C A G U
G C U G
A A A G G C C U G U G A G C A C U A G A G G U A A
C G C C U C U A G
G
G A U G G U A
A U A A C
G C G U G U A U A G G G U
A U A U C C G C
A G C G
A A G U U C
U
A A G G C
C U U
C U G C U A C G A A U
C G C G U"
VISUALIZATION,0.663961038961039,"U
C
A
C A G A C U A G A
C
G G C A A U G
G G C U C C U U
G C G G G G C"
VISUALIZATION,0.6655844155844156,"U
U
A
A
G
A
U
A
U
A
G
U
C
G
A A"
VISUALIZATION,0.6672077922077922,"C
C
C
C
U
C
A
G
A G A
U G A G G A
U G G A
A U C A A U
G 1 10 20 30 40 50 60 70 80 90 100 110 120 130 140"
VISUALIZATION,0.6688311688311688,"150
160 170 180 190 200 210 220 230 240 250 260"
VISUALIZATION,0.6704545454545454,"270
280
290 300 310 A A C C A U U A A G G
A A U A G A
C C A A G C
U C U A G G U G G U"
VISUALIZATION,0.672077922077922,"U
G
A
G A A A C C C C
U U U G U A U U
A
G U C C U G G A
A A C A G G G"
VISUALIZATION,0.6737012987012987,"C
G
A
C A U U G U"
VISUALIZATION,0.6753246753246753,"C
A
A
A U"
VISUALIZATION,0.676948051948052,"U
G
U
U C G G G
G
A C C A C C C
G
C U A A A U
U A C A U G C U A C C
G C A G C A G U
G C U G
A A A G G C C U G U G A G C A C U A G A G G U A A
C G C C U C U A G
G
G A U G G U A
A U A A C
G C G U G U A U A G G G U
A U A U C C G C
A G C G
A A G U U C
U
A A G G C
C U U
C U G C U A C G A A U
C G C G U"
VISUALIZATION,0.6785714285714286,"U
C
A
C A G A C U A G A
C
G G C A A U G
G G C U C C U U
G C G G G G C"
VISUALIZATION,0.6801948051948052,"U
U
A
A
G
A
U
A
U
A
G
U
C
G
A A"
VISUALIZATION,0.6818181818181818,"C
C
C
C
U
C
A
G
A G A
U G A G G A
U G G A
A U C A A U
G 1 10 20 30 40 50 60 70 80 90 100 110 120 130 140"
VISUALIZATION,0.6834415584415584,"150
160 170 180 190 200 210 220 230 240 250 260"
VISUALIZATION,0.685064935064935,"270
280
290 300 310 A
A C C A U
U
A A G G A A U A"
VISUALIZATION,0.6866883116883117,"G
A
C
C A A G C U C U A
G
G U G G U
U G A
G A"
VISUALIZATION,0.6883116883116883,"A
A
C
C
C
C
U
U
U
G
U
A
U
U
A
G U C C U G G A
A A C A G G G"
VISUALIZATION,0.689935064935065,"C
G
A
C A U U G U"
VISUALIZATION,0.6915584415584416,"C
A
A
A U U G U U C"
VISUALIZATION,0.6931818181818182,"G
G
G
G
A C C"
VISUALIZATION,0.6948051948051948,"A
C
C
C
G C U
A A A U U A C A U G C U A C C"
VISUALIZATION,0.6964285714285714,"G
C
A
G
C"
VISUALIZATION,0.698051948051948,"A
G
U
G
C
U
G
A A
A
G G C C U
G U G"
VISUALIZATION,0.6996753246753247,"A
G
C
A
C
U A G A G G U A A
C G C C U C U
A G G G A U G G U
A A U A A C
G C G
U G U A U A G G G U"
VISUALIZATION,0.7012987012987013,"A
U
A
U C C G C A G C G A A G U U C U A A G"
VISUALIZATION,0.702922077922078,"G
C
C
U U C U G C U"
VISUALIZATION,0.7045454545454546,"A
C
G
A A U C
G
C G U U C A C A G A C U A"
VISUALIZATION,0.7061688311688312,"G
A
C
G G C A A U G
G G C U C C U U
G C G G G G C"
VISUALIZATION,0.7077922077922078,"U
U
A
A
G
A
U
A
U 1 10 20 30 40
50 60 70 80 90 100 110 120 130 140 150 160 170 180"
VISUALIZATION,0.7094155844155844,"190
200 210 220 230 240 250 260 270"
VISUALIZATION,0.711038961038961,"RFold
True
UFold"
VISUALIZATION,0.7126623376623377,"1.000
0.995
0.558
0.823"
VISUALIZATION,0.7142857142857143,Figure 6: Visualization of the true and predicted structures.
CONCLUSION,0.7159090909090909,"6
Conclusion
329"
CONCLUSION,0.7175324675324676,"In this study, we present RFold, a simple yet effective learning-based model for RNA secondary
330"
CONCLUSION,0.7191558441558441,"structure prediction. We propose decoupled optimization to replace the complicated post-processing
331"
CONCLUSION,0.7207792207792207,"strategies while incorporating constraints for the output. Seq2map attention is proposed for sequence-
332"
CONCLUSION,0.7224025974025974,"to-map transformation, which can automatically learn informative representations from a single
333"
CONCLUSION,0.724025974025974,"sequence without extensive pre-processing operations. Comprehensive experiments demonstrate that
334"
CONCLUSION,0.7256493506493507,"RFold achieves competitive performance with faster inference speed. We hope RFold can provide a
335"
CONCLUSION,0.7272727272727273,"new perspective for efﬁcient RNA secondary structure prediction.
336"
REFERENCES,0.7288961038961039,"References
337"
REFERENCES,0.7305194805194806,"[1] M. Akiyama, K. Sato, and Y. Sakakibara. A max-margin training of rna secondary structure pre-
338"
REFERENCES,0.7321428571428571,"diction integrated with the thermodynamic model. Journal of bioinformatics and computational
339"
REFERENCES,0.7337662337662337,"biology, 16(06):1840025, 2018.
340"
REFERENCES,0.7353896103896104,"[2] M. Andronescu, R. Aguirre-Hernandez, A. Condon, and H. H. Hoos. Rnasoft: a suite of rna
341"
REFERENCES,0.737012987012987,"secondary structure prediction and design software tools. Nucleic acids research, 31(13):3416–
342"
REFERENCES,0.7386363636363636,"3422, 2003.
343"
REFERENCES,0.7402597402597403,"[3] S. Bellaousov, J. S. Reuter, M. G. Seetin, and D. H. Mathews. Rnastructure: web servers for
344"
REFERENCES,0.7418831168831169,"rna secondary structure prediction and analysis. Nucleic acids research, 41(W1):W471–W474,
345"
REFERENCES,0.7435064935064936,"2013.
346"
REFERENCES,0.7451298701298701,"[4] S. H. Bernhart, I. L. Hofacker, and P. F. Stadler. Local rna base pairing probabilities in large
347"
REFERENCES,0.7467532467532467,"sequences. Bioinformatics, 22(5):614–615, 2006.
348"
REFERENCES,0.7483766233766234,"[5] X. Chen, Y. Li, R. Umarov, X. Gao, and L. Song. Rna secondary structure prediction by learning
349"
REFERENCES,0.75,"unrolled algorithms. In International Conference on Learning Representations, 2019.
350"
REFERENCES,0.7516233766233766,"[6] H.-K. Cheong, E. Hwang, C. Lee, B.-S. Choi, and C. Cheong. Rapid preparation of rna samples
351"
REFERENCES,0.7532467532467533,"for nmr spectroscopy and x-ray crystallography. Nucleic acids research, 32(10):e84–e84, 2004.
352"
REFERENCES,0.7548701298701299,"[7] K. M. Choromanski, V. Likhosherstov, D. Dohan, X. Song, A. Gane, T. Sarlos, P. Hawkins, J. Q.
353"
REFERENCES,0.7564935064935064,"Davis, A. Mohiuddin, L. Kaiser, et al. Rethinking attention with performers. In International
354"
REFERENCES,0.7581168831168831,"Conference on Learning Representations, 2020.
355"
REFERENCES,0.7597402597402597,"[8] F. Crick. Central dogma of molecular biology. Nature, 227(5258):561–563, 1970.
356"
REFERENCES,0.7613636363636364,"[9] Y. N. Dauphin, A. Fan, M. Auli, and D. Grangier. Language modeling with gated convolutional
357"
REFERENCES,0.762987012987013,"networks. In International conference on machine learning, pages 933–941. PMLR, 2017.
358"
REFERENCES,0.7646103896103896,"[10] C. B. Do, D. A. Woods, and S. Batzoglou. Contrafold: Rna secondary structure prediction
359"
REFERENCES,0.7662337662337663,"without physics-based models. Bioinformatics, 22(14):e90–e98, 2006.
360"
REFERENCES,0.7678571428571429,"[11] J. Fallmann, S. Will, J. Engelhardt, B. Grüning, R. Backofen, and P. F. Stadler. Recent advances
361"
REFERENCES,0.7694805194805194,"in rna folding. Journal of biotechnology, 261:97–104, 2017.
362"
REFERENCES,0.7711038961038961,"[12] S. M. Fica and K. Nagai. Cryo-electron microscopy snapshots of the spliceosome: structural
363"
REFERENCES,0.7727272727272727,"insights into a dynamic ribonucleoprotein machine. Nature structural & molecular biology,
364"
REFERENCES,0.7743506493506493,"24(10):791–799, 2017.
365"
REFERENCES,0.775974025974026,"[13] G. E. Fox and C. R. Woese. 5s rna secondary structure. Nature, 256(5517):505–507, 1975.
366"
REFERENCES,0.7775974025974026,"[14] L. Fu, Y. Cao, J. Wu, Q. Peng, Q. Nie, and X. Xie. Ufold: fast and accurate rna secondary
367"
REFERENCES,0.7792207792207793,"structure prediction with deep learning. Nucleic acids research, 50(3):e14–e14, 2022.
368"
REFERENCES,0.7808441558441559,"[15] B. Fürtig, C. Richter, J. Wöhnert, and H. Schwalbe. Nmr spectroscopy of rna. ChemBioChem,
369"
REFERENCES,0.7824675324675324,"4(10):936–962, 2003.
370"
REFERENCES,0.7840909090909091,"[16] P. P. Gardner, J. Daub, J. G. Tate, E. P. Nawrocki, D. L. Kolbe, S. Lindgreen, A. C. Wilkinson,
371"
REFERENCES,0.7857142857142857,"R. D. Finn, S. Grifﬁths-Jones, S. R. Eddy, et al. Rfam: updates to the rna families database.
372"
REFERENCES,0.7873376623376623,"Nucleic acids research, 37(suppl_1):D136–D140, 2009.
373"
REFERENCES,0.788961038961039,"[17] P. P. Gardner and R. Giegerich. A comprehensive comparison of comparative rna structure
374"
REFERENCES,0.7905844155844156,"prediction approaches. BMC bioinformatics, 5(1):1–18, 2004.
375"
REFERENCES,0.7922077922077922,"[18] S. Geisler and J. Coller. Rna in unexpected places: long non-coding rna functions in diverse
376"
REFERENCES,0.7938311688311688,"cellular contexts. Nature reviews Molecular cell biology, 14(11):699–712, 2013.
377"
REFERENCES,0.7954545454545454,"[19] J. Gorodkin, L. J. Heyer, and G. D. Stormo. Finding the most signiﬁcant common sequence and
378"
REFERENCES,0.797077922077922,"structure motifs in a set of rna sequences. Nucleic acids research, 25(18):3724–3732, 1997.
379"
REFERENCES,0.7987012987012987,"[20] J. Gorodkin, S. L. Stricklin, and G. D. Stormo. Discovering common stem–loop motifs in
380"
REFERENCES,0.8003246753246753,"unaligned rna sequences. Nucleic Acids Research, 29(10):2135–2144, 2001.
381"
REFERENCES,0.801948051948052,"[21] S. Grifﬁths-Jones, A. Bateman, M. Marshall, A. Khanna, and S. R. Eddy. Rfam: an rna family
382"
REFERENCES,0.8035714285714286,"database. Nucleic acids research, 31(1):439–441, 2003.
383"
REFERENCES,0.8051948051948052,"[22] R. R. Gutell, J. C. Lee, and J. J. Cannone. The accuracy of ribosomal rna comparative structure
384"
REFERENCES,0.8068181818181818,"models. Current opinion in structural biology, 12(3):301–310, 2002.
385"
REFERENCES,0.8084415584415584,"[23] J. Hanson, K. Paliwal, T. Litﬁn, Y. Yang, and Y. Zhou. Accurate prediction of protein con-
386"
REFERENCES,0.810064935064935,"tact maps by coupling residual two-dimensional bidirectional long short-term memory with
387"
REFERENCES,0.8116883116883117,"convolutional neural networks. Bioinformatics, 34(23):4039–4045, 2018.
388"
REFERENCES,0.8133116883116883,"[24] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In
389"
REFERENCES,0.814935064935065,"Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–
390"
REFERENCES,0.8165584415584416,"778, 2016.
391"
REFERENCES,0.8181818181818182,"[25] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–
392"
REFERENCES,0.8198051948051948,"1780, 1997.
393"
REFERENCES,0.8214285714285714,"[26] M. Hochsmann, T. Toller, R. Giegerich, and S. Kurtz. Local similarity in rna secondary
394"
REFERENCES,0.823051948051948,"structures. In Computational Systems Bioinformatics. CSB2003. Proceedings of the 2003 IEEE
395"
REFERENCES,0.8246753246753247,"Bioinformatics Conference. CSB2003, pages 159–168. IEEE, 2003.
396"
REFERENCES,0.8262987012987013,"[27] I. L. Hofacker, S. H. Bernhart, and P. F. Stadler. Alignment of rna base pairing probability
397"
REFERENCES,0.827922077922078,"matrices. Bioinformatics, 20(14):2222–2227, 2004.
398"
REFERENCES,0.8295454545454546,"[28] I. L. Hofacker, M. Fekete, and P. F. Stadler. Secondary structure prediction for aligned rna
399"
REFERENCES,0.8311688311688312,"sequences. Journal of molecular biology, 319(5):1059–1066, 2002.
400"
REFERENCES,0.8327922077922078,"[29] W. Hua, Z. Dai, H. Liu, and Q. Le. Transformer quality in linear time. In International
401"
REFERENCES,0.8344155844155844,"Conference on Machine Learning, pages 9099–9117. PMLR, 2022.
402"
REFERENCES,0.836038961038961,"[30] L. Huang, H. Zhang, D. Deng, K. Zhao, K. Liu, D. A. Hendrix, and D. H. Mathews. Linear-
403"
REFERENCES,0.8376623376623377,"fold: linear-time approximate rna folding by 5’-to-3’dynamic programming and beam search.
404"
REFERENCES,0.8392857142857143,"Bioinformatics, 35(14):i295–i304, 2019.
405"
REFERENCES,0.8409090909090909,"[31] E. Iorns, C. J. Lord, N. Turner, and A. Ashworth. Utilizing rna interference to enhance cancer
406"
REFERENCES,0.8425324675324676,"drug discovery. Nature reviews Drug discovery, 6(7):556–568, 2007.
407"
REFERENCES,0.8441558441558441,"[32] A. J. Jung, L. J. Lee, A. J. Gao, and B. J. Frey. Rtfold: Rna secondary structure prediction using
408"
REFERENCES,0.8457792207792207,"deep learning with domain inductive bias.
409"
REFERENCES,0.8474025974025974,"[33] A. Katharopoulos, A. Vyas, N. Pappas, and F. Fleuret. Transformers are rnns: Fast autoregressive
410"
REFERENCES,0.849025974025974,"transformers with linear attention. In International Conference on Machine Learning, pages
411"
REFERENCES,0.8506493506493507,"5156–5165. PMLR, 2020.
412"
REFERENCES,0.8522727272727273,"[34] N. Kitaev, L. Kaiser, and A. Levskaya. Reformer: The efﬁcient transformer. In International
413"
REFERENCES,0.8538961038961039,"Conference on Learning Representations, 2019.
414"
REFERENCES,0.8555194805194806,"[35] B. Knudsen and J. Hein. Rna secondary structure prediction using stochastic context-free
415"
REFERENCES,0.8571428571428571,"grammars and evolutionary history. Bioinformatics (Oxford, England), 15(6):446–454, 1999.
416"
REFERENCES,0.8587662337662337,"[36] B. Knudsen and J. Hein. Pfold: Rna secondary structure prediction using stochastic context-free
417"
REFERENCES,0.8603896103896104,"grammars. Nucleic acids research, 31(13):3423–3428, 2003.
418"
REFERENCES,0.862012987012987,"[37] S. J. Lange, D. Maticzka, M. Möhl, J. N. Gagnon, C. M. Brown, and R. Backofen. Global
419"
REFERENCES,0.8636363636363636,"or local? predicting secondary structure and accessibility in mrnas. Nucleic acids research,
420"
REFERENCES,0.8652597402597403,"40(12):5215–5226, 2012.
421"
REFERENCES,0.8668831168831169,"[38] S. Li, Z. Wang, Z. Liu, C. Tan, H. Lin, D. Wu, Z. Chen, J. Zheng, and S. Z. Li. Efﬁcient
422"
REFERENCES,0.8685064935064936,"multi-order gated aggregation network. arXiv preprint arXiv:2211.03295, 2022.
423"
REFERENCES,0.8701298701298701,"[39] R. Lorenz, S. H. Bernhart, C. Höner zu Siederdissen, H. Tafer, C. Flamm, P. F. Stadler, and I. L.
424"
REFERENCES,0.8717532467532467,"Hofacker. Viennarna package 2.0. Algorithms for molecular biology, 6(1):1–14, 2011.
425"
REFERENCES,0.8733766233766234,"[40] R. B. Lyngsø and C. N. Pedersen. Rna pseudoknot prediction in energy-based models. Journal
426"
REFERENCES,0.875,"of computational biology, 7(3-4):409–427, 2000.
427"
REFERENCES,0.8766233766233766,"[41] D. H. Mathews and D. H. Turner. Dynalign: an algorithm for ﬁnding the secondary structure
428"
REFERENCES,0.8782467532467533,"common to two rna sequences. Journal of molecular biology, 317(2):191–203, 2002.
429"
REFERENCES,0.8798701298701299,"[42] D. H. Mathews and D. H. Turner. Prediction of rna secondary structure by free energy mini-
430"
REFERENCES,0.8814935064935064,"mization. Current opinion in structural biology, 16(3):270–278, 2006.
431"
REFERENCES,0.8831168831168831,"[43] E. P. Nawrocki, S. W. Burge, A. Bateman, J. Daub, R. Y. Eberhardt, S. R. Eddy, E. W. Floden,
432"
REFERENCES,0.8847402597402597,"P. P. Gardner, T. A. Jones, J. Tate, et al. Rfam 12.0: updates to the rna families database. Nucleic
433"
REFERENCES,0.8863636363636364,"acids research, 43(D1):D130–D137, 2015.
434"
REFERENCES,0.887987012987013,"[44] R. Nicholas and M. Zuker. Unafold: Software for nucleic acid folding and hybridization.
435"
REFERENCES,0.8896103896103896,"Bioinformatics, 453:3–31, 2008.
436"
REFERENCES,0.8912337662337663,"[45] H. F. Noller. Structure of ribosomal rna. Annual review of biochemistry, 53(1):119–162, 1984.
437"
REFERENCES,0.8928571428571429,"[46] R. Nussinov, G. Pieczenik, J. R. Griggs, and D. J. Kleitman. Algorithms for loop matchings.
438"
REFERENCES,0.8944805194805194,"SIAM Journal on Applied mathematics, 35(1):68–82, 1978.
439"
REFERENCES,0.8961038961038961,"[47] O. Perriquet, H. Touzet, and M. Dauchet. Finding the common structure shared by two
440"
REFERENCES,0.8977272727272727,"homologous rnas. Bioinformatics, 19(1):108–116, 2003.
441"
REFERENCES,0.8993506493506493,"[48] Z. Qin, W. Sun, H. Deng, D. Li, Y. Wei, B. Lv, J. Yan, L. Kong, and Y. Zhong. cosformer:
442"
REFERENCES,0.900974025974026,"Rethinking softmax in attention. In International Conference on Learning Representations,
443"
REFERENCES,0.9025974025974026,"2021.
444"
REFERENCES,0.9042207792207793,"[49] A. Rich and U. RajBhandary. Transfer rna: molecular structure, sequence, and properties.
445"
REFERENCES,0.9058441558441559,"Annual review of biochemistry, 45(1):805–860, 1976.
446"
REFERENCES,0.9074675324675324,"[50] E. Rivas. The four ingredients of single-sequence rna secondary structure prediction. a unifying
447"
REFERENCES,0.9090909090909091,"perspective. RNA biology, 10(7):1185–1196, 2013.
448"
REFERENCES,0.9107142857142857,"[51] O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical image
449"
REFERENCES,0.9123376623376623,"segmentation. In International Conference on Medical image computing and computer-assisted
450"
REFERENCES,0.913961038961039,"intervention, pages 234–241. Springer, 2015.
451"
REFERENCES,0.9155844155844156,"[52] J. Ruan, G. D. Stormo, and W. Zhang. An iterated loop matching approach to the prediction of
452"
REFERENCES,0.9172077922077922,"rna secondary structures with pseudoknots. Bioinformatics, 20(1):58–66, 2004.
453"
REFERENCES,0.9188311688311688,"[53] K. Sato, M. Akiyama, and Y. Sakakibara. Rna secondary structure prediction using deep
454"
REFERENCES,0.9204545454545454,"learning with thermodynamic integration. Nature communications, 12(1):1–9, 2021.
455"
REFERENCES,0.922077922077922,"[54] M. G. Seetin and D. H. Mathews. Rna structure prediction: an overview of methods. Bacterial
456"
REFERENCES,0.9237012987012987,"regulatory RNA, pages 99–122, 2012.
457"
REFERENCES,0.9253246753246753,"[55] J. Singh, J. Hanson, K. Paliwal, and Y. Zhou. Rna secondary structure prediction using an en-
458"
REFERENCES,0.926948051948052,"semble of two-dimensional deep neural networks and transfer learning. Nature communications,
459"
REFERENCES,0.9285714285714286,"10(1):1–13, 2019.
460"
REFERENCES,0.9301948051948052,"[56] J. Singh, K. Paliwal, T. Zhang, J. Singh, T. Litﬁn, and Y. Zhou. Improved rna secondary
461"
REFERENCES,0.9318181818181818,"structure and tertiary base-pairing prediction using evolutionary proﬁle, mutational coupling
462"
REFERENCES,0.9334415584415584,"and two-dimensional transfer learning. Bioinformatics, 37(17):2589–2600, 2021.
463"
REFERENCES,0.935064935064935,"[57] M. F. Sloma and D. H. Mathews. Exact calculation of loop formation probability identiﬁes
464"
REFERENCES,0.9366883116883117,"folding motifs in rna secondary structures. RNA, 22(12):1808–1818, 2016.
465"
REFERENCES,0.9383116883116883,"[58] D. So, W. Ma´nke, H. Liu, Z. Dai, N. Shazeer, and Q. V. Le. Searching for efﬁcient transformers
466"
REFERENCES,0.939935064935065,"for language modeling. Advances in Neural Information Processing Systems, 34:6010–6022,
467"
REFERENCES,0.9415584415584416,"2021.
468"
REFERENCES,0.9431818181818182,"[59] E. W. Steeg. Neural networks, adaptive optimization, and rna secondary structure prediction.
469"
REFERENCES,0.9448051948051948,"Artiﬁcial intelligence and molecular biology, pages 121–160, 1993.
470"
REFERENCES,0.9464285714285714,"[60] M. Szikszai, M. J. Wise, A. Datta, M. Ward, and D. Mathews. Deep learning models for rna
471"
REFERENCES,0.948051948051948,"secondary structure prediction (probably) do not generalise across families. bioRxiv, 2022.
472"
REFERENCES,0.9496753246753247,"[61] Z. Tan, Y. Fu, G. Sharma, and D. H. Mathews.
Turbofold ii: Rna structural alignment
473"
REFERENCES,0.9512987012987013,"and secondary structure prediction informed by multiple homologs. Nucleic acids research,
474"
REFERENCES,0.952922077922078,"45(20):11570–11581, 2017.
475"
REFERENCES,0.9545454545454546,"[62] H. Touzet and O. Perriquet. Carnac: folding families of related rnas. Nucleic acids research,
476"
REFERENCES,0.9561688311688312,"32(suppl_2):W142–W145, 2004.
477"
REFERENCES,0.9577922077922078,"[63] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and
478"
REFERENCES,0.9594155844155844,"I. Polosukhin. Attention is all you need. Advances in neural information processing systems,
479"
REFERENCES,0.961038961038961,"30, 2017.
480"
REFERENCES,0.9626623376623377,"[64] L. Wang, Y. Liu, X. Zhong, H. Liu, C. Lu, C. Li, and H. Zhang. Dmfold: A novel method to
481"
REFERENCES,0.9642857142857143,"predict rna secondary structure with pseudoknots based on deep learning and improved base
482"
REFERENCES,0.9659090909090909,"pair maximization principle. Frontiers in genetics, 10:143, 2019.
483"
REFERENCES,0.9675324675324676,"[65] S. Wang, S. Sun, Z. Li, R. Zhang, and J. Xu. Accurate de novo prediction of protein contact
484"
REFERENCES,0.9691558441558441,"map by ultra-deep learning model. PLoS computational biology, 13(1):e1005324, 2017.
485"
REFERENCES,0.9707792207792207,"[66] X. Wang and J. Tian. Dynamic programming for np-hard problems. Procedia Engineering,
486"
REFERENCES,0.9724025974025974,"15:3396–3400, 2011.
487"
REFERENCES,0.974025974025974,"[67] H. K. Wayment-Steele, W. Kladwang, A. I. Strom, J. Lee, A. Treuille, E. Participants, and R. Das.
488"
REFERENCES,0.9756493506493507,"Rna secondary structure packages evaluated and improved by high-throughput experiments.
489"
REFERENCES,0.9772727272727273,"BioRxiv, pages 2020–05, 2021.
490"
REFERENCES,0.9788961038961039,"[68] E. Westhof and V. Fritsch. Rna folding: beyond watson–crick pairs. Structure, 8(3):R55–R65,
491"
REFERENCES,0.9805194805194806,"2000.
492"
REFERENCES,0.9821428571428571,"[69] H. Wu, J. Wu, J. Xu, J. Wang, and M. Long. Flowformer: Linearizing transformers with
493"
REFERENCES,0.9837662337662337,"conservation ﬂows. arXiv preprint arXiv:2202.06258, 2022.
494"
REFERENCES,0.9853896103896104,"[70] X. Xu and S.-J. Chen. Physics-based rna structure prediction. Biophysics reports, 1(1):2–13,
495"
REFERENCES,0.987012987012987,"2015.
496"
REFERENCES,0.9886363636363636,"[71] S. Zakov, Y. Goldberg, M. Elhadad, and M. Ziv-Ukelson. Rich parameterization improves rna
497"
REFERENCES,0.9902597402597403,"structure prediction. Journal of Computational Biology, 18(11):1525–1542, 2011.
498"
REFERENCES,0.9918831168831169,"[72] H. Zhang, C. Zhang, Z. Li, C. Li, X. Wei, B. Zhang, and Y. Liu. A new method of rna secondary
499"
REFERENCES,0.9935064935064936,"structure prediction based on convolutional neural network and dynamic programming. Frontiers
500"
REFERENCES,0.9951298701298701,"in genetics, 10:467, 2019.
501"
REFERENCES,0.9967532467532467,"[73] M. Zuker. Mfold web server for nucleic acid folding and hybridization prediction. Nucleic
502"
REFERENCES,0.9983766233766234,"acids research, 31(13):3406–3415, 2003.
503"
