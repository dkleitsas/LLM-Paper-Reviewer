Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0016366612111292963,"The right to be forgotten has been legislated in many countries, but its enforce-
ment in the AI industry would cause unbearable costs. When single data dele-
tion requests come, companies may need to delete the whole models learned
with massive resources. Existing works propose methods to remove knowledge
learned from data for explicitly parameterized models, which however are not
appliable to the sampling-based Bayesian inference, i.e., Markov chain Monte
Carlo (MCMC), as MCMC can only infer implicit distributions.
In this pa-
per, we propose the ﬁrst machine unlearning algorithm for MCMC. We ﬁrst
convert the MCMC unlearning problem into an explicit optimization problem.
Based on this problem conversion, an MCMC inﬂuence function is designed
to provably characterize the learned knowledge from data, which then delivers
the MCMC unlearning algorithm. Theoretical analysis shows that MCMC un-
learning would not compromise the generalizability of the MCMC models. Ex-
periments on Gaussian mixture models and Bayesian neural networks conﬁrm
the effectiveness of the proposed algorithm. The code is available at https:
//github.com/fshp971/mcmc-unlearning."
INTRODUCTION,0.0032733224222585926,"1
INTRODUCTION"
INTRODUCTION,0.004909983633387889,"“The right to be forgotten” refers to the right of individuals to request data controllers such as tech
giants to delete the data collected from them. It has been recognized in many countries through
legislation, including the European Union’s General Data Protection Regulation (2016) and the Cal-
ifornia Consumer Privacy Act (2018). In the ﬁeld of machine learning, legal experts suggest that
companies may need to delete and re-train the machine learning models to meet the legal require-
ments of the right to be forgotten (Li et al., 2018; Garg et al., 2020). However, training a machine
learning model would usually cost massive amounts of resources, including data, energy, and time.
Thus, the enforcement of the right to be forgotten in the AI industry may result in unbearable costs."
INTRODUCTION,0.006546644844517185,"Toward this end, recent works (Cao & Yang, 2015; Guo et al., 2020) propose machine unlearning
algorithms to efﬁciently characterize and remove the knowledge learned from speciﬁc data. To
enable knowledge removal analysis, existing unlearning approaches usually require the machine
learning models to be explicitly parameterized, which however do not cover an important family of
machine learning algorithm, the Markov chain Monte Carlo (MCMC). MCMC is a sampling-based
Bayesian inference method that aims to draw samples along a Markov chain to approximate a target
posterior distribution (Hastings, 1970; Geman & Geman, 1984; Welling & Teh, 2011). Distributions
inferred by MCMC are usually implicitly parameterized, which makes it difﬁcult to directly apply
existing unlearning algorithms to the MCMC unlearning problem."
INTRODUCTION,0.008183306055646482,"In this paper, we propose an MCMC unlearning algorithm to realize the right to be forgotten in the
sampling-based Bayesian inference for the ﬁrst time. The key of tackling the MCMC unlearning
problem is to design methods to directly analyze the implicit parameter of the learned distribution.
To this end, we propose to employ the learned implicit distribution to approximate the target poste-
rior under the measure of KL-divergence, which then converts the MCMC unlearning problem to an"
INTRODUCTION,0.009819967266775777,*The authors contributed equally.
INTRODUCTION,0.011456628477905073,Published as a conference paper at ICLR 2022
INTRODUCTION,0.01309328968903437,"optimization problem with an explicit distribution parameter for knowledge removal analysis. Based
on this conversion, an MCMC inﬂuence function is designed (Huber, 2004; Koh & Liang, 2017) to
characterize the knowledge learned from single data samples. The new inﬂuence function then de-
livers the MCMC unlearning algorithm, which removes data knowledge by directly subtracting the
corresponding inﬂuence from the learned distribution."
INTRODUCTION,0.014729950900163666,"Theoretical analyses are conducted for the proposed MCMC unlearning algorithm. For the knowl-
edge removal analysis, we prove that the proposed algorithm can provably realize a ε-knowledge
removal, which is a new notation deﬁned for evaluating the machine unlearning performance in
Bayesian inference. For the generalization analysis, a PAC-Bayesian generalization upper bound
(McAllester, 1998; 1999; 2003; He et al., 2019) is established for the distribution processed by the
MCMC unlearning algorithm. The upper bound shows that the difference introduced by MCMC
unlearning in the generalization upper bound is no larger than the order of O(
p"
INTRODUCTION,0.016366612111292964,"|S′|/N). This result
demonstrates that the proposed algorithm would not compromise the generalization ability of the
learned distribution."
INTRODUCTION,0.01800327332242226,"In summary, our work has four main contributions: (1) We enable the knowledge removal analysis in
MCMC by converting the MCMC unlearning problem to an optimization problem. (2) Based on this
problem conversion, we design an MCMC inﬂuence function to characterize the knowledge learned
from data, which then delivers the MCMC unlearning algorithm. (3) We conduct theoretical analyses
and prove that the MCMC unlearning can realize an ε-knowledge removal and has little impact on
the generalization ability of the learned distribution. (4) We conduct comprehensive experiments
to verify the effectiveness of the proposed algorithm, which include Gaussian mixture models for
clustering on synthetic data, and Bayesian neural networks for classiﬁcation on real-world dataset.
The results suggest that the MCMC unlearning can effectively remove the knowledge learned from
the requested data while retaining the information learned from other data intact."
RELATED WORKS,0.019639934533551555,"2
RELATED WORKS"
RELATED WORKS,0.02127659574468085,"Markov chain Monte Carlo. MCMC is a Bayesian inference method that would draw samples
along a Markov chain, in which the drawn samples are proved to converge to that from a targeted
distribution (Hastings, 1970). Although many improvements have been made such as Hamiltonian
Monte Carlo (HMC) (Duane et al., 1987; Neal et al., 2011), Gibbs sampling (Geman & Geman,
1984; George & McCulloch, 1993) and slice sampling (Neal, 2003; Walker, 2007), MCMC still
suffers from huge computational cost when inferring on large-scale dataset, e.g. in computer vision
and image processing tasks (Zhang et al., 2020b; Wang et al., 2020), since each sampling step in
MCMC requires computation over the whole dataset."
RELATED WORKS,0.022913256955810146,"To tackle this issue, Welling & Teh (2011) introduce a scalable MCMC sampler named stochastic
gradient Langevin dynamics (SGLD) that by adding a proper noise to a standard stochastic gradient
optimization algorithm (Robbins & Monro, 1951), which can help the update iterations converge
to samples from the true posterior distribution. Since that, a variety of stochastic gradient MCMC
samplers (SG-MCMC) have been proposed, including stochastic gradient HMC (SGHMC) (Chen
et al., 2014), Patterson & Teh (2013), Ahn et al. (2012), Ding et al. (2014), and Zhang et al. (2020a).
Ma et al. (2015) further design a complete framework for constructing SG-MCMC."
RELATED WORKS,0.024549918166939442,"Machine unlearning. Machine unlearning aims to remove the knowledge learned from speciﬁc data
in efﬁcient manners (Cao & Yang, 2015). Existing approaches can be roughly divided into exact
methods and approximate methods. Exact methods aim to recover the model trained without the
removed data exactly and are usually realized via reducing the retraining cost. For example, Ginart
et al. (2019) design an efﬁcient unlearning method for k-means clustering via model quantization.
Bourtoule et al. (2021) propose a SISA framework that would only retrain the affected part of the
model during data deletion. Other advances include Ullah et al. (2021) and Brophy & Lowd (2021)."
RELATED WORKS,0.02618657937806874,"On the other hand, approximate methods aim to modify the trained model to approximate that trained
only on the remaining data. A series of works (Guo et al., 2020; Golatkar et al., 2020; 2021) are de-
signed via characterizing the inﬂuence of data on the trained model with inﬂuence functions (Cook
& Weisberg, 1982; Huber, 2004; Koh & Liang, 2017). Other approaches include Baumhauer et al.
(2020) and Izzo et al. (2021). Some works have studied machine unlearning in Bayesian infer-
ence (Nguyen et al., 2020; Gong et al., 2021). However, these works only focus on variational"
RELATED WORKS,0.027823240589198037,Published as a conference paper at ICLR 2022
RELATED WORKS,0.029459901800327332,"inference, an optimization-based Bayesian inference method, and could not be applied to sampling-
based Bayesian inference, MCMC. In contrast, our approach is the ﬁrst machine unlearning method
for MCMC, with a theoretical knowledge removal guarantee."
PRELIMINARIES,0.031096563011456628,"3
PRELIMINARIES"
PRELIMINARIES,0.03273322422258593,"Suppose p(z|θ) is a parameterized distribution over the sample space Z, where θ ∈Θ ⊂Rd is
the parameter with a prior distribution p(θ). Suppose S = {z1, z2, · · · , zN} is a dataset consists
of N samples, where each sample zi ∈Z is drawn from the parameterized distribution p(z|θ), i.e.,
zi ∼p(z|θ). Bayesian inference aims to infer the posterior distribution p(θ|S) of the parameter θ,"
PRELIMINARIES,0.03436988543371522,"p(θ|S) =
p(θ) QN
i=1 p(zi|θ)
R
p(θ) QN
i=1 p(zi|θ)dθ
."
PRELIMINARIES,0.03600654664484452,"For simplicity, for the given dataset S, we let pS denotes the true posterior distribution p(θ|S), and
ˆpS denotes the posterior distribution that inferred by Bayesian inference."
PRELIMINARIES,0.03764320785597381,"Usually, the denominator of the posterior pS has no closed-form solution, which barriers directly cal-
culating the posterior distribution. Thereby, researchers have designed methods to approximate the
target posterior. A canonical approach is the sampling-based Bayesian inference method, Markov
chain Monte Carlo (MCMC) (Hastings, 1970)."
PRELIMINARIES,0.03927986906710311,"MCMC infers a posterior distribution via ﬁrst constructs a Markov chain and then draws samples
according to the state of the chain. When the target posterior is the stationary distribution of the
Markov chain, it is proved that the drawn samples will converge to that from the target posterior.
However, MCMC methods usually suffer from scalable issues on large-scale datasets."
PRELIMINARIES,0.04091653027823241,"To this end, stochastic gradient MCMC (SG-MCMC) (Ma et al., 2015) leverage mini-batch estima-
tion (Robbins & Monro, 1951) to enable scalable sampling. In SG-MCMC, the posterior distribution
p(θ|S) can be rewritten as p(θ|S) ∝exp(−U(θ)), where U(θ) is the potential function deﬁned as
U(θ) = −P"
PRELIMINARIES,0.0425531914893617,"zi∈S log p(zi|θ) −log p(θ). In each sampling step, drawing samples with SG-MCMC
requires one to estimate the potential function U(θ) with mini-batch data ˜S ⊂S as follows,"
PRELIMINARIES,0.044189852700491,˜U(θ) = −|S| | ˜S| X
PRELIMINARIES,0.04582651391162029,"zi∈˜S
log p(zi|θ) −log p(θ)."
PRELIMINARIES,0.04746317512274959,"Typical SG-MCMC methods include SGLD and SGHMC. Stochastic gradient Langevin dynamics
(SGLD) (Welling & Teh, 2011) inserts Gaussian noise to stochastic gradients. In each sampling
step, SGLD updates the posterior sample θt as follows,"
PRELIMINARIES,0.049099836333878884,"θt+1 = θt −ηt∇θ ˜U(θt) + 2√ηtW,
where W is drawn from the standard Gaussian distribution N(0, I) and ηt > 0 is the step size."
PRELIMINARIES,0.05073649754500818,"To improve the sampling efﬁciency of SGLD, stochastic gradient Hamiltonian Monte Carlo
(SGHMC) (Chen et al., 2014) inserts a momentum vt into the posterior sample update as below,
θt+1 = θt + vt,"
PRELIMINARIES,0.05237315875613748,"vt+1 = (1 −α)vt −ηt∇θ ˜U(θt) +
p"
PRELIMINARIES,0.054009819967266774,"2αηtW,
where W is also drawn from the Gaussian distribution N(0, I), ηt > 0 is the step size, and
α ∈(0, 1) is the momentum factor. The initial momentum term v0 is drawn from the Gaussian
distribution N(0, η0I)."
PRELIMINARIES,0.05564648117839607,"To ensure the drawn samples converge to the targeted posterior, the step size ηt for both SGLD and
SGHMC needs to satisfy (Welling & Teh, 2011): (1) P∞
t=1 ηt = ∞; and (2) P∞
t=1 η2
t < ∞. A
typical step size schedule is ηt = a(b + t)−r, where a, b > 0 and r ∈(0.5, 1]."
MCMC UNLEARNING ALGORITHM,0.057283142389525366,"4
MCMC UNLEARNING ALGORITHM"
MCMC UNLEARNING ALGORITHM,0.058919803600654665,"This section presents the main results of this paper. We ﬁrst deﬁne a new notion, ε-knowledge
removal, to assess the machine unlearning performance in Bayesian inference. Then, an MCMC
unlearning algorithm is designed with knowledge removal and generalizability guarantees."
MCMC UNLEARNING ALGORITHM,0.060556464811783964,Published as a conference paper at ICLR 2022
MCMC UNLEARNING ALGORITHM,0.062193126022913256,"4.1
ε-KNOWLEDGE REMOVAL FOR BAYESIAN INFERENCE"
MCMC UNLEARNING ALGORITHM,0.06382978723404255,"Suppose a client requests to remove her/his data S′ ⊂S from the whole training dataset S. An
unlearning algorithm A for Bayesian inference aims to remove the knowledge learned from the
requested data S′ from the inferred distribution ˆpS as follows,"
MCMC UNLEARNING ALGORITHM,0.06546644844517185,"ˆp−S′
S
= A(ˆpS, S′),"
MCMC UNLEARNING ALGORITHM,0.06710310965630115,"where ˆp−S′
S
is named as the processed distribution."
MCMC UNLEARNING ALGORITHM,0.06873977086743044,"In order to meet the regulation requirements, the following notion is deﬁned to quantify the machine
unlearning performance in Bayesian inference.
Deﬁnition 1 (ε-knowledge removal). For the distribution ˆpS that inferred on dataset S via Bayesian
inference and any subset S′ ⊂S, we call algorithm A performs ε-knowledge removal, if"
MCMC UNLEARNING ALGORITHM,0.07037643207855974,"KL(ˆp−S′
S
∥ˆpS−S′) ≤ε,"
MCMC UNLEARNING ALGORITHM,0.07201309328968904,"where ˆp−S′
S
= A(ˆpS, S′) is the processed distribution.
Remark 1. Intuitively, a smaller ε indicates the algorithm A has better unlearning performance."
MCMC UNLEARNING ALGORITHM,0.07364975450081833,"In practice, one usually can only obtain an inferred distribution ˆpS(·|ω), subjects to a random seed
ω. In this case, the overall inferred distribution is ˆpS =
R
ˆpS(·|ω)p(ω)dω, which suggests that the
KL-divergence in Deﬁnition 1 can then be upper-bounded as below,"
MCMC UNLEARNING ALGORITHM,0.07528641571194762,"KL(ˆp−S′
S
∥ˆpS−S′) = KL(Eω ˆp−S′
S
(·|ω)∥Eω ˆpS−S′(·|ω)) =
Z"
MCMC UNLEARNING ALGORITHM,0.07692307692307693,"θ
Eω ˆp−S′
S
(θ|ω) log Eω ˆp−S′
S
(θ|ω)
Eω ˆpS−S′(θ|ω)dθ"
MCMC UNLEARNING ALGORITHM,0.07855973813420622,"≤
Z
Eω """
MCMC UNLEARNING ALGORITHM,0.08019639934533551,"ˆp−S′
S
(θ|ω) log ˆp−S′
S
(θ|ω)
ˆpS−S′(θ|ω) #"
MCMC UNLEARNING ALGORITHM,0.08183306055646482,"dθ = EωKL(ˆp−S′
S
∥ˆpS−S′|ω)."
MCMC UNLEARNING ALGORITHM,0.08346972176759411,"Motivated by the above inequality, the following knowledge removal estimator is further deﬁned to
efﬁciently estimate the knowledge removal performance in practice.
Deﬁnition 2 (knowledge removal estimator). Suppose ω1, · · · , ωM is M i.i.d. random seed in
Bayesian inference. Then, the knowledge removal estimator ˆεM is deﬁned as below,"
MCMC UNLEARNING ALGORITHM,0.0851063829787234,"ˆεM = 1 M M
X"
MCMC UNLEARNING ALGORITHM,0.0867430441898527,"m=1
KL(ˆp−S′
S
∥ˆpS−S′|ωm),"
MCMC UNLEARNING ALGORITHM,0.088379705400982,"where ˆp−S′
S
(·|ωm) = A(ˆpS(·|ωm), S′) is the processed distribution for the m-th random seed ωm.
Remark 2. Our experiments have employed this knowledge removal estimator ˆεM to estimate the
ε value in the ε-knowledge removal guarantee. See Section 5.2 for details.
Remark 3. This estimator is similar to the “Local Forgetting Bound” deﬁned in Golatkar et al.
(2020). The difference is that the bound in Golatkar et al. (2020) aims to estimate the random-
ness introduced by some “readout functions”, while ˆεM aims to quantify the ε-knowledge removal
guarantee by estimating the difference between the original and processed distributions."
METHODOLOGY,0.09001636661211129,"4.2
METHODOLOGY"
METHODOLOGY,0.09165302782324058,"This section presents the MCMC unlearning algorithm. To make the analysis easier, we assume that
one can obtain the exact targeted posterior distribution via MCMC. In other words, for a posterior
ˆpS that is inferred by MCMC, we assume that ˆpS = pS."
METHODOLOGY,0.09328968903436989,"Developing unlearning algorithm for MCMC is challenging, since there is no explicitly parame-
terized distribution for knowledge removal analysis. To tackle this challenge, we re-formulate the
MCMC unlearning problem as minimizing the following KL-divergence,"
METHODOLOGY,0.09492635024549918,"min
δ
KL(pS(· −δ)∥pS−S′),
(1)"
METHODOLOGY,0.09656301145662848,"where pS is the distribution already learned via MCMC, δ is the distribution shifting scale, S′ is the
dataset that is requested to be deleted, and pS−S′ is the targeted posterior that one aims to obtain. The"
METHODOLOGY,0.09819967266775777,Published as a conference paper at ICLR 2022
METHODOLOGY,0.09983633387888707,"idea behinds Eq. (1) is to approximate the targeted posterior pS−S′ via directly shifting the currently
learned distribution pS. In this case, one no longer needs to know the exact implicit distribution
parameter to perform machine unlearning, but only the explicit shifting scale δ is enough."
METHODOLOGY,0.10147299509001637,"So far, the MCMC unlearning problem has been converted to an optimization problem deﬁned as
Eq. (1). We then design MCMC unlearning algorithm based on this problem conversion. Let δ−S′
S
denotes any local minimizer of Eq. (1), and the goal of MCMC unlearning is to calculate the optimal
shifting scale δ−S′
S
. To achieve that goal, we ﬁrst expand the KL-divergence in Eq. (1) as follows,
KL(pS(· −δ)∥pS−S′) = KL(pS∥pS−S′(· + δ))"
METHODOLOGY,0.10310965630114566,"= Eθ∼pS [log p(θ|S)] + log p(S −S′) + Eθ∼pS [−log p(S, θ + δ) + log p(S′|θ + δ)] .
(2)
Through Eq. (2), one can ﬁnd that when removing dataset S′ via optimizing Eq. (1), an additional
term Eθ∼pS log p(S′|θ + δ) is introduced to force the distribution pS(· −δ) approaching the target
posterior pS−S′. This motivate us to follow existing works (Koh & Liang, 2017; Guo et al., 2020)
to conduct inﬂuence analysis on Eq. (1) based on the introduced term Eθ∼pS log p(S′|θ + δ)."
METHODOLOGY,0.10474631751227496,"Speciﬁcally, we deﬁne a new function F−S′,τ(δ, S) = Eθ∼pS[−log p(S, θ+δ)−τ ·log p(S′|θ+δ)],
where τ ∈[−1, 0]. Suppose there exists a function ˆδ(τ) with domain [−1, 0] such that ˆδ(0) = 0,
and ˆδ(τ) is a local minimizer of F−S′,τ(δ, S). Then, one can let the target shifting scale δ−S′
S
be
ˆδ(−1), and approximate it by the ﬁrst-order approximation: ˆδ(−1) ≈ˆδ(0) −∂ˆδ(0)/∂τ, which
means δ−S′
S
≈−∂ˆδ(0)/∂τ. Following a standard derivation, one can calculate the ﬁrst derivative
∂ˆδ(0)/∂τ as the following deﬁned MCMC inﬂuence function I(S′). Thus, the optimal δ−S′
S
is then
approximated as δ−S′
S
≈−I(S′). For the detailed inﬂuence analysis, see Appendix A.1.
Deﬁnition 3 (MCMC inﬂuence function). The MCMC inﬂuence function of dataset S′ ⊂S is
deﬁned to be"
METHODOLOGY,0.10638297872340426,"I(S′) = −
 
Eθ∼pS∇2
θ log p(θ, S)
−1 X"
METHODOLOGY,0.10801963993453355,"z∈S′
(Eθ∼pS∇θ log p(z|θ))T ."
METHODOLOGY,0.10965630114566285,"The MCMC inﬂuence function is deﬁned to estimate the inﬂuence of data S′ on the learned distri-
bution pS, as δ−S′
S
≈−I(S′). The computational cost of the MCMC inﬂuence function would be
high. An efﬁcient calculation method is given in Appendix B."
METHODOLOGY,0.11129296235679215,"Finally, based on Deﬁnition 3, the MCMC unlearning algorithm is designed as follows.
Algorithm 1 (MCMC unlearning). Suppose one have drawn a series of samples {θ1, · · · , θT } from
the posterior pS via MCMC. Then, MCMC unlearning algorithm removes the learned knowledge of
dataset S′ from each drawn sample θi as follows,
θ′
i ←θi −I(S′),
where I(S′) is the MCMC inﬂuence function for dataset S′ ⊂S.
Remark 4. Algorithm 1 is equivalent to the following unlearning process,"
METHODOLOGY,0.11292962356792144,"p−S′
S
(·) = A(pS, S′) = pS(· + I(S′)) ≈pS(· −δ−S′
S
).
Remark 5. Due to the inherent geometric difference between the distribution functions pS and
pS−S′, it is impossible for Algorithm 1 to directly shift pS to exactly recover pS−S′. However, the
experiments (see Section 5) show that the designed algorithm is good enough for removing learned
knowledge from MCMC distributions."
KNOWLEDGE REMOVAL ANALYSIS,0.11456628477905073,"4.3
KNOWLEDGE REMOVAL ANALYSIS"
KNOWLEDGE REMOVAL ANALYSIS,0.11620294599018004,"This section studies the ε-knowledge removal for the proposed MCMC unlearning algorithm. We
ﬁrst introduces several assumptions (Assumptions 1-4) for the knowledge removal analysis.
Assumption 1. Function −Eθ∼pS log p(θ + δ) and −Eθ∼pS log p(z|θ + δ) are L1-Lipschitz con-
tinuous on the support set supp(δ)."
KNOWLEDGE REMOVAL ANALYSIS,0.11783960720130933,"The Lipschitzness of −Eθ∼pS log p(θ + δ) can be realized by choosing appropriate prior dis-
tribution for θ, for example, let p(θ) be a Laplace distribution.
Besides, the Lipschitzness of
−Eθ∼pS log p(z|θ + δ) can usually be achieved by setting p(z|θ + δ) to be a neural network with
bounded domain in practice."
KNOWLEDGE REMOVAL ANALYSIS,0.11947626841243862,Published as a conference paper at ICLR 2022
KNOWLEDGE REMOVAL ANALYSIS,0.12111292962356793,"Assumption 2. There exists a neighborhood V2 ⊂supp(δ) of the origin point such that for any
dataset S and any sample point z ∈Z, the followings hold:"
KNOWLEDGE REMOVAL ANALYSIS,0.12274959083469722,"• (Smoothness). ∇δ[−Eθ∼pS log p(θ + δ)] and ∇δ[−Eθ∼pS log p(z|θ + δ)] are L2-Lipschitz
continuous on the space V2."
KNOWLEDGE REMOVAL ANALYSIS,0.12438625204582651,"• (Lipschitz Hessian). ∇2
δ[−Eθ∼pS log p(θ + δ)] and ∇2
δ[−Eθ∼pS log p(z|θ + δ)] are L3-
Lipschitz continuous on the space V2."
KNOWLEDGE REMOVAL ANALYSIS,0.1260229132569558,"Assumption 2 assumes the local smoothness and Hessian Lipschitzness for the involved functions,
which are common in literature for analyzing Newton methods (Nesterov & Polyak, 2006; Carmon
et al., 2018; Zhou et al., 2018).
Assumption 3 (strong convexity). There exists a neighborhood V3 ⊂supp(δ) of the origin
point such that for any dataset S and any sample point z ∈Z, −Eθ∼pS log p(θ + δ) and
−Eθ∼pS log p(z|θ + δ) are µ-strongly convex on V3."
KNOWLEDGE REMOVAL ANALYSIS,0.1276595744680851,"The inﬂuence analysis and the deﬁned MCMC inﬂuence function require the Hessian matrices of
−Eθ∼pS log p(θ + δ) and −Eθ∼pS log p(z|θ + δ) to be invertible. Assumption 3 ensures the invert-
ibilities of these Hessian matrices.
Assumption 4. Suppose Assumptions 1-3 hold.
Then there exists a sub-neighborhood V
∈
V2 ∩V3 of the origin point such that for any dataset S and any real τ ∈[−1, 0], the function
−Eθ∼pS log p(θ + δ|S) −τ · Eθ∼pS log p(S′|θ + δ) has at least one local minimizer falls in V ."
KNOWLEDGE REMOVAL ANALYSIS,0.12929623567921442,"Assumption 4 assumes the target optimal solution δ−S′
S
of Eq. (1) exists in the subspace that we are
interested in, which would make the inﬂuence analysis being meaningful."
KNOWLEDGE REMOVAL ANALYSIS,0.1309328968903437,"Under Assumptions 1-4, we prove that the MCMC inﬂuence function deﬁned in Deﬁnition 3 can
rigorously estimate the inﬂuence of data on the shifting scale δ.
Theorem 1. Under Assumptions 1-4, we have that"
KNOWLEDGE REMOVAL ANALYSIS,0.132569558101473,"δ−S′
S
= −I(S′) + O
|S′|2 N 2 
."
KNOWLEDGE REMOVAL ANALYSIS,0.1342062193126023,The proof of Theorem 1 is presented in Appendix A.1.
KNOWLEDGE REMOVAL ANALYSIS,0.13584288052373159,"Based on Theorem 1, a knowledge removal guarantee is proved for the MCMC unlearning algorithm.
Theorem 2. Suppose Assumptions 1-4 hold. Then, the MCMC unlearning algorithm A(pS, S′) =
pS(· + I(S′)) performs ε−S′
S
-knowledge removal, where"
KNOWLEDGE REMOVAL ANALYSIS,0.13747954173486088,"ε−S′
S
= KL(pS(· −δ−S′
S
)∥pS−S′) + O
|S′|4 N 3 
,"
KNOWLEDGE REMOVAL ANALYSIS,0.13911620294599017,"and δ−S′
S
is a local minimizer of the KL-divergence KL(pS(· −δ)∥pS−S′)."
KNOWLEDGE REMOVAL ANALYSIS,0.1407528641571195,"Proof sketch. We expand KL(pS(· + I(S′))∥pS−S′) into Taylor series up to 2-th order around the
point δ = δ−S′
S
. By applying the ﬁrst-order optimality condition, the ﬁrst-order term in the Taylor
series becomes 0. By leveraging the approximation error given in Theorem 1, the second-order term
is proved to be no larger than the order of O(|S′|4/N 3). The proof is presented in Appendix A.2.
Remark 6. As explained in the previous section, Algorithm 1 could not completely remove the
learned knowledge from the inferred distribution due to the inherent geometric difference between
the distribution pS and pS−S′. Nevertheless, Theorem 2 demonstrates that the Algorithm 1 can help
the KL-divergence in Eq. (1) approach its local minimum."
GENERALIZATION ANALYSIS,0.14238952536824878,"4.4
GENERALIZATION ANALYSIS"
GENERALIZATION ANALYSIS,0.14402618657937807,"This section studies the impact of the proposed MCMC unlearning algorithm on the generaliza-
tion ability of the inferred distribution. The analysis is conducted based on the PAC-Bayes theory
(McAllester, 1999; 2003; He et al., 2019), a framework for analyzing the generalization ability of
stochastic machine learning models (Mohri et al., 2012; He & Tao, 2020)."
GENERALIZATION ANALYSIS,0.14566284779050737,Published as a conference paper at ICLR 2022
GENERALIZATION ANALYSIS,0.14729950900163666,"6
4
2
0
2
4
4 2 0 2 4 6"
GENERALIZATION ANALYSIS,0.14893617021276595,Original Data
GENERALIZATION ANALYSIS,0.15057283142389524,"6
4
2
0
2
4
4 2 0 2 4 6 SGLD"
GENERALIZATION ANALYSIS,0.15220949263502456,"Origin
Target
Processed"
GENERALIZATION ANALYSIS,0.15384615384615385,"6
4
2
0
2
4
4 2 0 2 4 6 SGHMC"
GENERALIZATION ANALYSIS,0.15548281505728315,"Origin
Target
Processed"
GENERALIZATION ANALYSIS,0.15711947626841244,"(a) Visualized results of the GMMs experiments. There are four groups of
points in the synthetic dataset, where different groups are in different colors.
The samples that were generated from the original, processed, and target
model via MCMC sampling are colored in black, blue, and red, respectively."
GENERALIZATION ANALYSIS,0.15875613747954173,"SGLD
SGHMC
0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5"
GENERALIZATION ANALYSIS,0.16039279869067102,Unlearning Time (s)
GENERALIZATION ANALYSIS,0.16202945990180032,Time Cost
GENERALIZATION ANALYSIS,0.16366612111292964,"Retrain
Ours"
GENERALIZATION ANALYSIS,0.16530278232405893,"(b) Time costs for pro-
cessing
single
deletion
requests
via
retraining
and MCMC unlearning."
GENERALIZATION ANALYSIS,0.16693944353518822,Figure 1: Experiment results for GMMs.
GENERALIZATION ANALYSIS,0.1685761047463175,"Speciﬁcally, suppose Q is the parameter distribution of a stochastic model. Suppose S is the training
dataset. Then, the expected risk R(Q) and empirical risk ˆRS(Q) of Q are deﬁned to be"
GENERALIZATION ANALYSIS,0.1702127659574468,"R(Q) = E
θ∼Q E
z ℓ(θ, z),
ˆRS(Q) = E
θ∼Q
1
N N
X"
GENERALIZATION ANALYSIS,0.1718494271685761,"i=1
ℓ(θ, zi),"
GENERALIZATION ANALYSIS,0.1734860883797054,"where θ is the model parameter drawn from the distribution Q and ℓis a loss function ranging in
[0, 1]. The difference of the expected risk and the empirical risk is the generalization error. Its
magnitude characterizes the generalization ability of the stochastic model."
GENERALIZATION ANALYSIS,0.1751227495908347,"Then, a generalization bound for the distribution processed by Algorithm 1 is proved as below."
GENERALIZATION ANALYSIS,0.176759410801964,"Theorem 3. Suppose Assumptions 1-4 hold. Let p−S′
S
denotes the distribution processed by Algo-
rithm 1. Then, for any δ ∈(0, 1), with probability at least 1 −δ, the following inequality holds,"
GENERALIZATION ANALYSIS,0.1783960720130933,"R(p−S′
S
) ≤ˆRS(p−S′
S
) + s"
GENERALIZATION ANALYSIS,0.18003273322422259,Eθ∼pS[log pS(θ) + ∥θ∥1] + ∥I(S′)∥1 + log 2 + log 1
GENERALIZATION ANALYSIS,0.18166939443535188,"δ + log N + 2
2N −1
,"
GENERALIZATION ANALYSIS,0.18330605564648117,where ∥I(S′)∥1 ≤O(|S′|/N).
GENERALIZATION ANALYSIS,0.18494271685761046,The proof is given in Appendix A.3.
GENERALIZATION ANALYSIS,0.18657937806873978,"Corollary 1. Algorithm 1 increases the generalization upper bound in Theorem 3 no larger than
the order of O(
p"
GENERALIZATION ANALYSIS,0.18821603927986907,|S′|/N).
GENERALIZATION ANALYSIS,0.18985270049099837,"Proof. According to Theorem 3, the difference of the generalization upper bound introduced by"
GENERALIZATION ANALYSIS,0.19148936170212766,"Algorithm 1 is O(
q"
GENERALIZATION ANALYSIS,0.19312602291325695,∥I(S′)∥1
GENERALIZATION ANALYSIS,0.19476268412438624,"2N−1 ) ≤O(
q"
GENERALIZATION ANALYSIS,0.19639934533551553,O(|S′|/N)
GENERALIZATION ANALYSIS,0.19803600654664485,"2N−1
) = O(
√"
GENERALIZATION ANALYSIS,0.19967266775777415,"|S′|
N
). This completes the proof."
GENERALIZATION ANALYSIS,0.20130932896890344,"Remark 7. Corollary 1 indicates that the proposed MCMC unlearning algorithm would not com-
promise the generalization ability of the inferred distribution."
EXPERIMENTS,0.20294599018003273,"5
EXPERIMENTS"
EXPERIMENTS,0.20458265139116202,"In this section, we empirically verify the effectiveness and efﬁciency of the proposed MCMC un-
learning algorithm on the Gaussian mixture models and Bayesian neural networks."
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.20621931260229132,"5.1
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.2078559738134206,"We ﬁrst visualize the effect of the MCMC unlearning algorithm on a synthetic clustering dataset
that consists of 2, 000 examples, where each examples is two-dimensional and is possibly from 4
clusters. The Gaussian mixture models (GMMs) are employed to infer the cluster centers. For the
details of the GMMs used in our experiments, see Appendix C.1."
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.20949263502454993,"Experiment design. We employ SGLD and SGHMC to infer the GMMs on the clustering dataset.
Then, 400 points are removed from each of the grey parts and yellow parts, around 40% of the whole"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.21112929623567922,Published as a conference paper at ICLR 2022
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.2127659574468085,"Table 1: Experiment results on CIFAR-10. Different metrics are used to evaluate the machine
unlearning performance, including the classiﬁcation errors on the remaining set Sr, removed set
Sf, and test set Stest, the knowledge removal estimators ˆεM, and the membership inference attack
(MIA) accuracy on Sf. Every experiment is repeated 5 times. The results show that the proposed
MCMC unlearning algorithm beats baseline methods in almost every experiments settings."
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.2144026186579378,"Remove
Method
Err. on Sr (%)
Err. on Sf (%)
Err. on Stest (%)
ˆεM (×103)
MIA Acc. (%)"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.2160392798690671,"CIFAR-10
+
SGLD"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.2176759410801964,"3,000
Examples"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.2193126022913257,"Retrain
20.45±0.95
46.69±1.05
31.80±0.71
0.00±0.00
51.85±1.39"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.220949263502455,"Origin
21.71±0.94
18.91±1.13
31.22±0.53
4079.51±2.07
80.11±3.87
IS
21.81±0.80
28.71±1.06
31.77±0.82
4228.11±1.60
72.29±2.07
Ours
21.56±0.96
31.14±1.75
31.76±0.66
4070.59±1.99
69.21±5.22"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.2225859247135843,"5,000
Examples"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.22422258592471359,"Retrain
18.61±0.90
100.00±0.00
36.25±0.63
0.00±0.00
0.00±0.00"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.22585924713584288,"Origin
21.82±0.91
19.07±1.26
31.23±0.53
4173.23±1.90
80.62±4.58
IS
21.17±0.87
54.05±1.86
33.25±0.77
4342.04±1.64
46.49±4.90
Ours
20.73±0.86
73.96±4.25
34.81±0.31
4151.34±1.94
26.64±7.68"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.22749590834697217,"CIFAR-10
+
SGHMC"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.22913256955810146,"3,000
Examples"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.23076923076923078,"Retrain
20.24±0.37
45.83±1.61
31.80±0.48
0.00±0.00
55.34±3.00"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.23240589198036007,"Origin
21.50±0.40
18.83±1.46
31.47±0.54
0.00±0.00
82.85±1.49
IS
21.61±0.40
28.64±1.23
31.90±0.53
4296.82±2.02
70.79±3.52
Ours
21.31±0.37
30.33±2.44
31.75±0.55
4137.04±2.42
69.83±2.78"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.23404255319148937,"5,000
Examples"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.23567921440261866,"Retrain
18.56±0.38
100.00±0.00
36.21±0.34
0.00±0.00
0.00±0.00"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.23731587561374795,"Origin
21.61±0.39
18.91±1.13
31.47±0.52
4233.95±1.73
82.70±1.35
IS
21.03±0.44
54.20±1.48
33.55±0.36
4408.05±1.21
44.20±1.63
Ours
20.54±0.36
69.56±4.45
34.67±0.78
4212.63±1.72
29.12±3.94"
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.23895253682487724,"dataset at all, by our forgetting algorithms. We also trained models on only the remaining set with
the same MCMC inference settings to show the targets of the forgetting tasks. For the details of the
experiments, see Appendix C."
EXPERIMENTS FOR GAUSSIAN MIXTURE MODELS,0.24058919803600654,"Results analysis. The visualization results are presented in Fig. 1a, which show that after unlearn-
ing, the processed models are close to the target models. Besides, the time costs for processing single
data deletion requests are presented in Fig. 1b, which shows that the proposed MCMC unlearning
algorithm is signiﬁcantly faster than retraining the whole model. These results demonstrates that the
proposed algorithm can effectively and efﬁciently remove the learned knowledge of speciﬁed data."
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.24222585924713586,"5.2
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS"
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.24386252045826515,"SGLD
SGHMC
0 50 100"
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.24549918166939444,Unlearning Time (s)
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.24713584288052373,CIFAR-10
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.24877250409165302,"Retrain
IS
Ours"
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.25040916530278234,"Figure 2: Time costs for process-
ing single data deletion requests on
BNNs. A smaller time cost implies
a higher efﬁciency of the unlearn-
ing method."
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2520458265139116,"We then apply the MCMC unlearning algorithm to the
Bayesian neural networks on the CIFAR-10 (Krizhevsky et al.,
2009) dataset for classiﬁcation. Analogous experiments are
also conducted on the Fashion-MNIST (Xiao et al., 2017)
dataset, please see Appendix D for more details."
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.25368248772504093,"Dataset & BNN. We divide the training set S of CIFAR-10
into two parts, the removed part Sf and the remained part Sr.
A certain number of examples are randomly chosen from a
single class in the dataset to form the removed training set Sf.
The test set is denoted by Stest. A BNN consists of two con-
volutional layers and two fully-connected layers is adopted in
the experiments. For more details about the dataset and model
architecture, see Appendix D."
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2553191489361702,"Baseline method. We compare the proposed MCMC unlearning algorithm with the importance
sampling method (IS). Speciﬁcally, when a data deletion request comes, the importance sampling
method will process the request via performing MCMC sampling on the remaining data."
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2569558101472995,"Evaluation metrics. Four kinds of metrics are used to evaluate the performance of machine un-
learning: (1) Classiﬁcation errors. We calculate classiﬁcation errors the remaining set Sr, removed
set Sf, and test set Stest for different models. Ideally, after removing data, the three errors of the
processed model would approach that of the retrained model. (2) ε-Knowledge removal guaran-
tee. We use the knowledge removal estimator ˆεM deﬁned in Deﬁnition 2 to estimate the ε value
in the ε-knowledge removal guarantee. A smaller estimation result would imply a better knowl-"
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.25859247135842883,Published as a conference paper at ICLR 2022 plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2602291325695581,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2618657937806874,Removed 0 samples plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2635024549918167,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.265139116202946,Removed 2048 samples plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.26677577741407527,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2684124386252046,Removed 4096 samples plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2700490998363339,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.27168576104746317,Removed 5000 samples
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2733224222585925,"(a) The prediction conﬁdences changes for a “plane”
image. “Plane” is also the removed class. plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0"
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.27495908346972175,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2765957446808511,Removed 0 samples plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.27823240589198034,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.27986906710310966,Removed 2048 samples plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.281505728314239,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.28314238952536824,Removed 4096 samples plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.28477905073649756,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2864157119476268,Removed 5000 samples
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.28805237315875615,"(b) The prediction conﬁdences changes for a “plane”
image. “Plane” is also the removed class. plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0"
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2896890343698854,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.29132569558101473,Removed 0 samples plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.29296235679214405,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2945990180032733,Removed 2048 samples plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.29623567921440264,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2978723404255319,Removed 4096 samples plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.2995090016366612,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.3011456628477905,Removed 5000 samples
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.3027823240589198,"(c) The prediction conﬁdences changes for a “cat”
image. “Cat” is not the removed class. plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0"
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.3044189852700491,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.3060556464811784,Removed 0 samples plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.3076923076923077,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.309328968903437,Removed 2048 samples plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.3109656301145663,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.31260229132569556,Removed 4096 samples plane car bird cat deer dog frog horse ship truck 0.0 0.2 0.4 0.6 0.8 1.0
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.3142389525368249,Confidence
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.3158756137479542,Removed 5000 samples
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.31751227495908346,"(d) The prediction conﬁdences changes for a “ship”
image. “Ship” is not the removed class."
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.3191489361702128,"Figure 3: The changes of the prediction conﬁdences for the test set examples of CIFAR-10 along
with data removing. The BNN is trained with SGLD and the knowledge removal is conducted with
the proposed MCMC unlearning algorithm. The predictions for the true labels are colored in red."
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.32078559738134205,"edge removal performance. Calculating ˆεM requires to ﬁx a series of random seeds ω1, · · · , ωM.
To this end, we use a series of pre-trained models as the random seeds. See Appendix D.3 for the
detailed calculation procedures. (3) Membership inference attack (MIA) accuracy. We employ a
white-box MIA (Yeom et al., 2018) to infer whether the examples from the removed subset Sf come
from the training set of the model. Intuitively, the attack accuracy would decline after unlearning.
Thereby, a small attack accuracy implies a strong knowledge removal performance. See Appendix
D.4 for more details about the MIA and its calculation procedures. (4) Time costs for unlearning.
For different unlearning methods, we estimate the average time usages for processing single data
deletion requests. A smaller time cost corresponds to high unlearning efﬁciency."
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.32242225859247137,"Experiment designs.
We ﬁrst train the BNN on the complete training set S with SGLD and
SGHMC, respectively. Then, the subset Sf is removed iteratively, where a ﬁxed number of data
points are removed in each iteration. We also trained models on only the remaining set Sr to show
the targets of the machine unlearning task. For the details of the experiments, see Appendix D.5."
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.32405891980360063,"Results analysis. The experiment results are presented in Table 1. In all experiments, we observe
that the proposed MCMC unlearning algorithm can signiﬁcantly increase the model error on sample
set Sf while making the error on sample sets Sr and Stest close to that of the retrained one. Besides,
our algorithm can also reduce the ε value in the knowledge removal guarantee and the MIA accuracy
on Sf, which further indicates it can indeed remove speciﬁed knowledge from the MCMC models.
In contrast, the importance sampling method could neither effectively make the classiﬁcation errors
approach the targets, nor achieve stronger ε-knowledge removal. We also present the time costs
for different unlearning methods in Fig. 2. One can found that the MCMC unlearning algorithm is
signiﬁcantly faster than other methods. All these experiment results demonstrate the effectiveness
and efﬁciency of the proposed algorithm."
EXPERIMENTS FOR BAYESIAN NEURAL NETWORKS,0.32569558101472995,"Finally, we give a case study about the prediction changes on the test set examples to illustrate the
effect of the proposed MCMC unlearning algorithm. The results are presented in Fig. 3, where
one can observe that as the data removing continues, the prediction conﬁdence of the model on the
removed class signiﬁcantly decreases, while those on other classes remain the same or increase."
CONCLUSION,0.32733224222585927,"6
CONCLUSION"
CONCLUSION,0.32896890343698854,"The right to be forgotten imposes a considerable compliance burden on AI companies. A company
may need to delete the whole model learned from massive resources due to a request to delete a
single sample point. Existing works only appliable to explicit parameterized optimization problem,
which however not work for sampling-based Bayesian inference method, i.e., MCMC. In this work,
we convert the MCMC unlearning problem to an optimization problem. Then, an MCMC inﬂuence
function is designed to characterize the inﬂuence of data on the distribution inferred by MCMC. It
then delivers the ﬁrst MCMC unlearning algorithm. Theoretical analyses show that the proposed
algorithm can indeed reduce the learned knowledge, and would not compromise the generalization
ability of the inferred distribution. Experiments show that the proposed algorithm can remove the
inﬂuence of speciﬁed samples without compromising the knowledge learned on the remained data."
CONCLUSION,0.33060556464811786,Published as a conference paper at ICLR 2022
CONCLUSION,0.3322422258592471,ACKNOWLEDGMENTS
CONCLUSION,0.33387888707037644,"FH is supported in part by the Major Science and Technology Innovation 2030 “New Generation
Artiﬁcial Intelligence” key project (No. 2021ZD0111700). SF and DT are supported by Australian
Research Council Projects FL-170100117, IH-180100002, IC-190100031, and LE-200100049. The
authors sincerely appreciate Yue Xu and the anonymous ICLR reviewers for their helpful comments."
REFERENCES,0.3355155482815057,REFERENCES
REFERENCES,0.337152209492635,"Mart´ın Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S.
Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew
Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath
Kudlur, Josh Levenberg, Dandelion Man´e, Rajat Monga, Sherry Moore, Derek Murray, Chris
Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker,
Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi´egas, Oriol Vinyals, Pete Warden, Martin Wat-
tenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learn-
ing on heterogeneous systems, 2015."
REFERENCES,0.33878887070376434,"Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and
Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC
conference on computer and communications security, pp. 308–318, 2016."
REFERENCES,0.3404255319148936,"Naman Agarwal, Brian Bullins, and Elad Hazan. Second-order stochastic optimization for machine
learning in linear time. The Journal of Machine Learning Research, 18(1):4148–4187, 2017."
REFERENCES,0.34206219312602293,"Sungjin Ahn, Anoop Korattikara, and Max Welling. Bayesian posterior sampling via stochastic
gradient Fisher scoring. In International Conference on Machine Learning, pp. 1771–1778, 2012."
REFERENCES,0.3436988543371522,"Thomas Baumhauer, Pascal Sch¨ottle, and Matthias Zeppelzauer. Machine unlearning: Linear ﬁltra-
tion for logit-based classiﬁers. arXiv preprint arXiv:2002.02730, 2020."
REFERENCES,0.3453355155482815,"Lucas Bourtoule, Varun Chandrasekaran, Christopher A Choquette-Choo, Hengrui Jia, Adelin
Travers, Baiwu Zhang, David Lie, and Nicolas Papernot. Machine unlearning. In 2021 IEEE
Symposium on Security and Privacy (SP), pp. 141–159. IEEE, 2021."
REFERENCES,0.3469721767594108,"Jonathan Brophy and Daniel Lowd. Machine unlearning for random forests. In International Con-
ference on Machine Learning, pp. 1092–1104. PMLR, 2021."
REFERENCES,0.3486088379705401,"Yinzhi Cao and Junfeng Yang. Towards making systems forget with machine unlearning. In 2015
IEEE Symposium on Security and Privacy, pp. 463–480. IEEE, 2015."
REFERENCES,0.3502454991816694,"Yair Carmon, John C Duchi, Oliver Hinder, and Aaron Sidford. Accelerated methods for nonconvex
optimization. SIAM Journal on Optimization, 28(2):1751–1772, 2018."
REFERENCES,0.3518821603927987,"Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic gradient Hamiltonian Monte Carlo. In
International Conference on Machine Learning, volume 32 of Proceedings of Machine Learning
Research, pp. 1683–1691. PMLR, 2014."
REFERENCES,0.353518821603928,"R Dennis Cook and Sanford Weisberg. Residuals and Inﬂuence in Regression. New York: Chapman
and Hall, 1982."
REFERENCES,0.35515548281505727,"Nan Ding, Youhan Fang, Ryan Babbush, Changyou Chen, Robert D Skeel, and Hartmut Neven.
Bayesian sampling using stochastic gradient Thermostats. In Advances in Neural Information
Processing Systems, volume 27. Curran Associates, Inc., 2014."
REFERENCES,0.3567921440261866,"Simon Duane, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth. Hybrid Monte Carlo.
Physics letters B, 195(2):216–222, 1987."
REFERENCES,0.35842880523731585,"Sanjam Garg, ShaﬁGoldwasser, and Prashant Nalini Vasudevan. Formalizing data deletion in the
context of the right to be forgotten. Advances in Cryptology–EUROCRYPT 2020, 12106:373,
2020."
REFERENCES,0.36006546644844517,Published as a conference paper at ICLR 2022
REFERENCES,0.3617021276595745,"Stuart Geman and Donald Geman. Stochastic relaxation, Gibbs distributions, and the Bayesian
restoration of images. IEEE Transactions on Pattern Analysis and Machine Intelligence, (6):
721–741, 1984."
REFERENCES,0.36333878887070375,"Edward I George and Robert E McCulloch. Variable selection via Gibbs sampling. Journal of the
American Statistical Association, 88(423):881–889, 1993."
REFERENCES,0.3649754500818331,"Antonio Ginart, Melody Guan, Gregory Valiant, and James Y Zou. Making AI forget you: Data
deletion in machine learning. In Advances in Neural Information Processing Systems, volume 32.
Curran Associates, Inc., 2019."
REFERENCES,0.36661211129296234,"Aditya Golatkar, Alessandro Achille, and Stefano Soatto.
Eternal sunshine of the spotless net:
Selective forgetting in deep networks. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pp. 9304–9312, 2020."
REFERENCES,0.36824877250409166,"Aditya Golatkar, Alessandro Achille, Avinash Ravichandran, Marzia Polito, and Stefano Soatto.
Mixed-privacy forgetting in deep networks.
In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 792–801, 2021."
REFERENCES,0.3698854337152209,"Jinu Gong, Osvaldo Simeone, and Joonhyuk Kang. Bayesian variational federated learning and
unlearning in decentralized networks. arXiv preprint arXiv:2104.03834, 2021."
REFERENCES,0.37152209492635024,"Chuan Guo, Tom Goldstein, Awni Hannun, and Laurens Van Der Maaten. Certiﬁed data removal
from machine learning models. In International Conference on Machine Learning, pp. 3832–
3842. PMLR, 2020."
REFERENCES,0.37315875613747956,"W Keith Hastings. Monte Carlo Sampling Methods Using Markov Chains and Their Applications.
1970."
REFERENCES,0.37479541734860883,"Fengxiang He and Dacheng Tao.
Recent advances in deep learning theory.
arXiv preprint
arXiv:2012.10931, 2020."
REFERENCES,0.37643207855973815,"Fengxiang He, Tongliang Liu, and Dacheng Tao. Control batch size and learning rate to generalize
well: Theoretical and empirical evidence. In Advances in Neural Information Processing Systems,
pp. 1143–1152, 2019."
REFERENCES,0.3780687397708674,"Peter J Huber. Robust Statistics, volume 523. John Wiley & Sons, 2004."
REFERENCES,0.37970540098199673,"Zachary Izzo, Mary Anne Smart, Kamalika Chaudhuri, and James Zou. Approximate data dele-
tion from machine learning models. In International Conference on Artiﬁcial Intelligence and
Statistics, pp. 2008–2016. PMLR, 2021."
REFERENCES,0.381342062193126,"Pang Wei Koh and Percy Liang. Understanding black-box predictions via inﬂuence functions. In
International Conference on Machine Learning, pp. 1885–1894, 2017."
REFERENCES,0.3829787234042553,"Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
2009."
REFERENCES,0.38461538461538464,"Yann LeCun, L´eon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998."
REFERENCES,0.3862520458265139,"Tiffany Li, Eduard Fosch Villaronga, and Peter Kieseberg. Humans forget, machines remember:
Artiﬁcial intelligence and the right to be forgotten. Computer Law & Security Review, 34(2):304,
2018."
REFERENCES,0.3878887070376432,"Yi-An Ma, Tianqi Chen, and Emily Fox. A complete recipe for stochastic gradient MCMC. In
Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc., 2015."
REFERENCES,0.3895253682487725,"David A McAllester. Some PAC-Bayesian theorems. In Proceedings of the Annual Conference on
Computational Learning Theory, pp. 230–234, 1998."
REFERENCES,0.3911620294599018,"David A McAllester. PAC-Bayesian model averaging. In Proceedings of the Annual Conference on
Computational Learning Theory, pp. 164–170, 1999."
REFERENCES,0.39279869067103107,Published as a conference paper at ICLR 2022
REFERENCES,0.3944353518821604,"David A McAllester. PAC-Bayesian stochastic model selection. Machine Learning, 51(1):5–21,
2003."
REFERENCES,0.3960720130932897,"Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of machine learning.
MIT press, 2012."
REFERENCES,0.397708674304419,"Radford M Neal. Slice sampling. The Annals of Statistics, 31(3):705–767, 2003."
REFERENCES,0.3993453355155483,"Radford M Neal et al. MCMC using Hamiltonian dynamics. Handbook of Markov Chain Monte
Carlo, 2(11):2, 2011."
REFERENCES,0.40098199672667756,"Yurii Nesterov and Boris T Polyak. Cubic regularization of Newton method and its global perfor-
mance. Mathematical Programming, 108(1):177–205, 2006."
REFERENCES,0.4026186579378069,"Quoc Phong Nguyen, Bryan Kian Hsiang Low, and Patrick Jaillet. Variational Bayesian unlearning.
Advances in Neural Information Processing Systems, 33, 2020."
REFERENCES,0.40425531914893614,"Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
Automatic differentiation in
PyTorch. In NIPS-W, 2017."
REFERENCES,0.40589198036006546,"Sam Patterson and Yee Whye Teh. Stochastic gradient Riemannian Langevin Dynamics on the
probability simplex. In Advances in Neural Information Processing Systems, volume 26. Curran
Associates, Inc., 2013."
REFERENCES,0.4075286415711948,"Herbert Robbins and Sutton Monro. A stochastic approximation method. The Annals of Mathemat-
ical Statistics, pp. 400–407, 1951."
REFERENCES,0.40916530278232405,"Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. Membership inference at-
tacks against machine learning models. In 2017 IEEE Symposium on Security and Privacy (SP),
pp. 3–18. IEEE, 2017."
REFERENCES,0.41080196399345337,"Enayat Ullah, Tung Mai, Anup Rao, Ryan A. Rossi, and Raman Arora. Machine unlearning via
algorithmic stability. In Proceedings of Thirty Fourth Conference on Learning Theory, volume
134 of Proceedings of Machine Learning Research, pp. 4126–4142. PMLR, 2021."
REFERENCES,0.41243862520458263,"Stephen G Walker. Sampling the dirichlet mixture model with slices. Communications in Statis-
tics—Simulation and Computation®, 36(1):45–54, 2007."
REFERENCES,0.41407528641571195,"Chaoyue Wang, Chang Xu, and Dacheng Tao. Self-supervised pose adaptation for cross-domain
image animation. IEEE Transactions on Artiﬁcial Intelligence, 1(1):34–46, 2020. doi: 10.1109/
TAI.2020.3031581."
REFERENCES,0.4157119476268412,"Qing Wang, Sanjeev R Kulkarni, and Sergio Verd´u. Divergence estimation for multidimensional
densities via k-nearest-neighbor distances. IEEE Transactions on Information Theory, 55(5):
2392–2405, 2009."
REFERENCES,0.41734860883797054,"Max Welling and Yee W Teh. Bayesian learning via stochastic gradient Langevin dynamics. In
International Conference on Machine Learning, pp. 681–688, 2011."
REFERENCES,0.41898527004909986,"Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-MNIST: a novel image dataset for bench-
marking machine learning algorithms, 2017."
REFERENCES,0.4206219312602291,"Samuel Yeom, Irene Giacomelli, Matt Fredrikson, and Somesh Jha. Privacy risk in machine learn-
ing: Analyzing the connection to overﬁtting. In 2018 IEEE 31st Computer Security Foundations
Symposium (CSF), pp. 268–282. IEEE, 2018."
REFERENCES,0.42225859247135844,"Ruqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Chen, and Andrew Gordon Wilson. Cyclical
stochastic gradient MCMC for Bayesian deep learning. In International Conference on Learning
Representations, 2020a."
REFERENCES,0.4238952536824877,"Youjian Zhang, Chaoyue Wang, and Dacheng Tao. Video frame interpolation without temporal
priors. In Advances in Neural Information Processing Systems, volume 33, pp. 13308–13318,
2020b."
REFERENCES,0.425531914893617,"Dongruo Zhou, Pan Xu, and Quanquan Gu. Stochastic variance-reduced cubic regularized newton
methods. In International Conference on Machine Learning, pp. 5990–5999. PMLR, 2018."
REFERENCES,0.42716857610474634,Published as a conference paper at ICLR 2022
REFERENCES,0.4288052373158756,"A
PROOFS"
REFERENCES,0.43044189852700493,"This section collects all the proofs in this paper. To avoid technicalities, we assume that all functions
are differentiable throughout this paper. Furthermore, the order of differentiation and integration is
assumed to be interchangeable."
REFERENCES,0.4320785597381342,"For simplicity, we denote that"
REFERENCES,0.4337152209492635,"• h(δ, z) := −Eθ∼pS log p(z|θ + δ),"
REFERENCES,0.4353518821603928,"• f(δ) := −Eθ∼pS log p(θ + δ),"
REFERENCES,0.4369885433715221,"• F(δ, S) := P"
REFERENCES,0.4386252045826514,"z∈S h(δ, z) + f(δ) = P"
REFERENCES,0.4402618657937807,z∈S −Eθ∼pS log p(z|θ + δ) −Eθ∼pS log p(θ + δ).
REFERENCES,0.44189852700491,"A.1
PROOF OF THEOREM 1"
REFERENCES,0.44353518821603927,"To prove Theorem 1, we ﬁrst deﬁne the following function,"
REFERENCES,0.4451718494271686,"F−S′,τ(δ, S) = F(δ, S) + τ
X"
REFERENCES,0.44680851063829785,"z∈S′
h(δ, z),"
REFERENCES,0.44844517184942717,"where τ ∈[−1, 0]."
REFERENCES,0.4500818330605565,"Under Assumption 3, it can be shown that F−S′,τ(δ, S) is strongly convex on the space V3 deﬁned
in Assumption 3."
REFERENCES,0.45171849427168576,"Lemma 1. Suppose Assumption 3 holds. Then, for any τ ∈[−1, 0], F−S′,τ(δ, S) is strongly convex
on the space V3."
REFERENCES,0.4533551554828151,"Proof of Lemma 1. We rearrange the function F−S′,τ as follows,"
REFERENCES,0.45499181669394434,"F−S′,τ(δ, S) = F(δ, S −S′) + (1 + τ)
X"
REFERENCES,0.45662847790507366,"z∈S′
h(δ, z)."
REFERENCES,0.4582651391162029,"Apparently, F(δ, S −S′) is strongly convex on V3. Since τ ∈[−1, 0], we have that 1+τ ≥0. Thus,
(1 + τ) P
z∈S′ h(δ, z) is either strongly convex on V3 or equal to zero. Therefore, F−S′,τ(δ, S) is
strongly convex on V3."
REFERENCES,0.45990180032733224,The proof is completed.
REFERENCES,0.46153846153846156,"We then prove that when Assumption 4 holds, there exists a continuous mapping that “connects” the
origin point 0 ∈Rd and the target shifting scale δ−S′
S
."
REFERENCES,0.46317512274959083,"Lemma 2. Suppose Assumption 4 holds. Then, there exists a continuous function ˆδ : [−1, 0] →V
such that for any τ ∈[−1, 0], ˆδ(τ) is the global minimizer of the function F−S′,τ(δ, S) on space V ."
REFERENCES,0.46481178396072015,"Proof of Lemma 2. By applying Lemma 1 and Assumption 4, we have that the global minimizer of
the function F−S′,τ(γ, S) uniquely exists in V . Therefore, one can deﬁne the mapping ˆδ as below,"
REFERENCES,0.4664484451718494,"ˆδ(τ) = arg min
δ∈V F−S′,τ(δ, S),"
REFERENCES,0.46808510638297873,"where τ ∈[−1, 0]."
REFERENCES,0.469721767594108,"We then prove the continuity of ˆδ. Notice that ˆδ(τ) is the solution of the following equation,"
REFERENCES,0.4713584288052373,"∇δF(δ, S) + τ
X"
REFERENCES,0.47299509001636664,"z∈S′
∇δh(δ, z) = 0.
(3)"
REFERENCES,0.4746317512274959,"Since F−S′,τ(δ, S) is strongly convex, thus its Hessian matrix ∇2
δF−S′,τ(ˆδ(τ), S) is invertible.
Combining with the implicit function theorem, we have that ˆδ is continuous on the interval [−1, 0]."
REFERENCES,0.4762684124386252,The proof is completed.
REFERENCES,0.4779050736497545,Published as a conference paper at ICLR 2022
REFERENCES,0.4795417348608838,"When τ takes 0 and −1, the function ˆδ(τ) becomes 0 ∈Rd and δ−S′
S
, respectively. Therefore, δ−S′
S
can be expanded into Taylor series as follows,"
REFERENCES,0.48117839607201307,"δ−S′
S
= ˆδ(−1) = −∂ˆδ(0)"
REFERENCES,0.4828150572831424,"∂τ
+ 1"
REFERENCES,0.4844517184942717,2 · ∂2ˆδ(ξ)
REFERENCES,0.486088379705401,"∂τ 2 ,
(4)"
REFERENCES,0.4877250409165303,"where ξ ∈[−1, 0], 1"
REFERENCES,0.48936170212765956,"2
∂2ˆδ(ξ)"
REFERENCES,0.4909983633387889,"∂τ 2
is the Lagrange form of the remainder."
REFERENCES,0.49263502454991814,"We prove that the Lagrange remainder term becomes negligible as the training set size N goes to
inﬁnity. To do this, we ﬁrst prove the following Lemma."
REFERENCES,0.49427168576104746,"Lemma 3. Suppose Assumptions 1-4 hold. The mapping ˆδ is as deﬁned in Lemma 2. Then, we have
that"
REFERENCES,0.4959083469721768,∂ˆδ(τ)
REFERENCES,0.49754500818330605,"∂τ
= −∇−2
δ F(ˆδ(τ), S)
X"
REFERENCES,0.49918166939443537,"z∈S′
∇δh(ˆδ(τ), z)T ,"
REFERENCES,0.5008183306055647,"and for any τ ∈[−1, 0], ∥∂ˆδ(τ)"
REFERENCES,0.502454991816694,∂τ ∥2 ≤O(|S′|/N).
REFERENCES,0.5040916530278232,Proof. We ﬁrst calculate ∂ˆδ(τ)
REFERENCES,0.5057283142389526,"∂τ
based on Eq. (3) in the proof of Lemma 2. Calculate the derivatives
of the both sides of Eq. (3) with respect to τ, we have that"
REFERENCES,0.5073649754500819,"∇2
δF(ˆδ(τ), S) · ∂ˆδ(τ)"
REFERENCES,0.5090016366612111,"∂τ
+
X"
REFERENCES,0.5106382978723404,"z∈S′
∇δh(ˆδ(τ), z)T + τ ·
X"
REFERENCES,0.5122749590834698,"z∈S′
∇2
δh(ˆδ(τ), z) · ∂ˆδ(τ)"
REFERENCES,0.513911620294599,"∂τ
= 0.
(5)"
REFERENCES,0.5155482815057283,"According to Lemma 1, F−S′,τ(δ, S) is strongly convex on V . Thus, the following Hessian matrix"
REFERENCES,0.5171849427168577,"∇2
δF−S′,τ(ˆδ(τ), S) = ∇2
δF(ˆδ(τ), S) + τ
X"
REFERENCES,0.5188216039279869,"z∈S′
∇2
δh(ˆδ(τ), z)"
REFERENCES,0.5204582651391162,"is positive deﬁnite, hence invertible. Combining with Eq. (5), we have that"
REFERENCES,0.5220949263502455,∂ˆδ(τ)
REFERENCES,0.5237315875613748,"∂τ
= − "
REFERENCES,0.5253682487725041,"∇2
δF(ˆδ(τ), S) + τ
X"
REFERENCES,0.5270049099836334,"z∈S′
∇2
δh(ˆδ(τ), z) !−1 ·
X"
REFERENCES,0.5286415711947627,"z∈S′
∇δh(ˆδ(τ), z)T .
(6)"
REFERENCES,0.530278232405892,We then upper bound the norm of ∂ˆδ(τ)
REFERENCES,0.5319148936170213,"∂τ . Based on Eq. (6), we have that

∂ˆδ(τ) ∂τ 2
≤ "
REFERENCES,0.5335515548281505,"1
N ∇2
δF(ˆδ(τ), S) + τ N X"
REFERENCES,0.5351882160392799,"z∈S′
∇2
δh(ˆδ(τ), z)"
REFERENCES,0.5368248772504092,"!−1
2 ·"
N,0.5384615384615384,"1
N X"
N,0.5400981996726678,"z∈S′
∇δh(ˆδ(τ), z) 2
. (7)"
N,0.5417348608837971,"We ﬁrst consider the ﬁrst term of the right-hand side of Eq. (7). By Assumption 3, both f(δ) and
h(δ, z) are µ-strongly convex on the space V ⊂supp(δ). Thus, we have that
1
N ∇2
δF(ˆδ(τ), S) + τ N X"
N,0.5433715220949263,"z∈S′
∇2
δh(ˆδ(τ), z) = 1 N N
X"
N,0.5450081833060556,"i=1
∇2
δh(ˆδ(τ), zi) + 1"
N,0.546644844517185,"N ∇2
δf(ˆδ(τ)) + τ N X"
N,0.5482815057283142,"z∈S′
∇2
δh(ˆδ(τ), z) ⪰"
N,0.5499181669394435,"1
N X"
N,0.5515548281505729,"z∈S−S′
µ + µ"
N,0.5531914893617021,N + 1 + τ N X
N,0.5548281505728314,"z∈S′
µ ! I"
N,0.5564648117839607,⪰N −|S′|
N,0.55810147299509,"N
µ · I.
(8)"
N,0.5597381342062193,"Let λmin denotes the smallest eigenvalue of the following matrix
 
1
N ∇2
δF(ˆδ(τ), S) + τ N X"
N,0.5613747954173486,"z∈S′
∇2
δh(ˆδ(τ), z) ! ."
N,0.563011456628478,Published as a conference paper at ICLR 2022
N,0.5646481178396072,"Then, the Eq. (8) implies that λmin ≥N−|S′|"
N,0.5662847790507365,"N
µ. Hence, we have the following,"
N,0.5679214402618658,"1
N ∇2
δF(ˆδ(τ), S) + τ N X"
N,0.5695581014729951,"z∈S′
∇2
δh(ˆδ(τ), z)"
N,0.5711947626841244,"!−1
2"
N,0.5728314238952537,"=
1
λmin
≤
N
(N −|S′|)µ = O(1).
(9)"
N,0.574468085106383,"We then upper bound the second term of the right-hand side of Eq. (7). By applying Assumption 1,
we have that

1
N X"
N,0.5761047463175123,"z∈S′
∇δh(ˆδ(τ), z)"
N,0.5777414075286416,"2
≤L1 · |S′|"
N,0.5793780687397708,"N
= O
|S′| N"
N,0.5810147299509002,"
(10)"
N,0.5826513911620295,"Finally, inserting eqs. (9) (10) into Eq. (7), we eventually have that

∂ˆδ(τ) ∂τ"
N,0.5842880523731587,"2
≤O(1) · O
|S′| N"
N,0.5859247135842881,"
= O
|S′| N 
."
N,0.5875613747954174,The proof is completed.
N,0.5891980360065466,"Then, the following Lemma is obtained based on Lemma 3, which demonstrates the strictness of the
approximation in Eq. (4)."
N,0.5908346972176759,"Lemma 4. Suppose Assumptions 1-4 hold. The induced mapping ˆδ is as deﬁned in Lemma 2. Then,
for any τ ∈[−1, 0], we have that ∥∂2ˆδ(τ)"
N,0.5924713584288053,∂τ 2 ∥2 ≤O(|S′|2/N 2).
N,0.5941080196399345,Proof. We ﬁrst calculate ∂2δ(τ)
N,0.5957446808510638,"∂τ 2
based on Eq. (3). Similar to the proof of Lemma 3, we calculate the
second-order derivatives of the both sides of Eq. (3) with respect to τ and have that N
X"
N,0.5973813420621932,"i=1
B(τ, zi) + A(τ) + N
X"
N,0.5990180032733224,"i=1
∇2
δh(ˆδ(τ), zi) + ∇2
δf(ˆδ(τ)) !"
N,0.6006546644844517,· ∂2ˆδ(τ) ∂τ 2
N,0.602291325695581,"+ 2 ·
X"
N,0.6039279869067103,"z∈S′
∇2
δh(ˆδ(τ), z) · ∂ˆδ(τ)"
N,0.6055646481178396,"∂τ
+ τ
X"
N,0.6072013093289689,"z∈S′
B(τ, z) + τ
X"
N,0.6088379705400983,"z∈S′
∇2
δh(ˆδ(τ), z) · ∂2ˆδ(τ)"
N,0.6104746317512275,"∂τ 2
= 0,"
N,0.6121112929623568,which means
N,0.613747954173486,∂2ˆδ(τ)
N,0.6153846153846154,"∂τ 2
= −"
N,0.6170212765957447,"1
N N
X"
N,0.618657937806874,"i=1
∇2
δF(ˆδ(τ), S) + τ"
N,0.6202945990180033,"N ∇2
δ
X"
N,0.6219312602291326,"z∈S′
h(ˆδ(τ), z) !−1 ·"
N,0.6235679214402619,"1
N N
X"
N,0.6252045826513911,"i=1
B(τ, zi) + τ N X"
N,0.6268412438625205,"z∈S′
B(τ, z) + 1"
N,0.6284779050736498,N A(τ) + 2 N X
N,0.630114566284779,"z∈S′
∇2
δh(ˆδ(τ), z) · ∂ˆδ(τ) ∂τ ! , (11)"
N,0.6317512274959084,"in which the invertibility of

1
N
PN
i=1 ∇2
δF(ˆδ(τ), S) + τ N
P"
N,0.6333878887070377,"z∈S′ ∇2
δh(ˆδ(τ), z)

is guaranteed by"
N,0.6350245499181669,"Eq. (8), A(τ), B(τ, z) ∈RK×1, and for i = 1, · · · , K, we have the following,"
N,0.6366612111292962,A(τ)i = ∂ˆδ(τ) ∂τ
N,0.6382978723404256,"T
· ∇2
δ"
N,0.6399345335515548,∂f(ˆδ(τ)) ∂δi !
N,0.6415711947626841,· ∂ˆδ(τ)
N,0.6432078559738135,"∂τ
,
(12)"
N,0.6448445171849427,"B(τ, z)i = ∂ˆδ(τ) ∂τ"
N,0.646481178396072,"T
· ∇2
δ"
N,0.6481178396072013,"∂h(ˆδ(τ), z) ∂δi !"
N,0.6497545008183306,· ∂ˆδ(τ)
N,0.6513911620294599,"∂τ
.
(13)"
N,0.6530278232405892,Published as a conference paper at ICLR 2022
N,0.6546644844517185,We then upper bound the norm of ∂2ˆδ(τ)
N,0.6563011456628478,"∂τ 2 . Based on Eq. (11), we have that

∂2ˆδ(τ) ∂τ 2 2 ≤ "
N,0.6579378068739771,"1
N N
X"
N,0.6595744680851063,"i=1
∇2
δF(ˆγ(τ), S) + τ N X"
N,0.6612111292962357,"z∈S′
∇2
δh(ˆδ(τ), z)"
N,0.662847790507365,"!−1
2 · 1 N N
X"
N,0.6644844517184942,"i=1
∥B(τ, zi)∥2 + τ
X"
N,0.6661211129296236,"z∈S′
∥B(τ, z)∥2 + ∥A(τ)∥2 + 2  X"
N,0.6677577741407529,"z∈S′
∇2
δh(ˆδ(τ), z) · ∂ˆδ(τ) ∂τ 2 ! (14) ≤O"
N,0.6693944353518821,"1
N N
X"
N,0.6710310965630114,"i=1
∥B(τ, zi)∥2 + τ
X"
N,0.6726677577741408,"z∈S′
∥B(τ, z)∥2 + ∥A(τ)∥2 + 2  X"
N,0.67430441898527,"z∈S′
∇2
δh(ˆδ(τ), z) · ∂ˆδ(τ) ∂τ 2 !! , (15)"
N,0.6759410801963993,"where Eq. (15) is obtained by inserting Eq. (9) (in the proof of Lemma 3) into Eq. (14). Thus, the
remaining task is to upper bound the norms of A(τ), B(τ, z) and ∇2
δ
P"
N,0.6775777414075287,"z∈S′ h(ˆδ(τ), z) · ∂ˆδ(τ) ∂τ ."
N,0.679214402618658,"We ﬁrst upper bound ∥A(τ)∥2. Applying Lemma 3, we have that ∥∂ˆδ(τ)"
N,0.6808510638297872,∂τ ∥2 ≤O(|S′|/N). Applying
N,0.6824877250409165,"the Lipschitz Hessian condition in Assumption 2, we have that ∥∇2
δ( ∂f(ˆδ(τ))"
N,0.6841243862520459,"∂δi
∥2 is also bounded by
a real constant. Therefore, we have that"
N,0.6857610474631751,"∥A(τ)∥2 ≤ K
X i=1 ∇2
δ"
N,0.6873977086743044,∂f(ˆδ(τ)) ∂δi
N,0.6890343698854338,"!
2
·"
N,0.690671031096563,"∂ˆδ(τ) ∂τ  2 2
≤ K
X"
N,0.6923076923076923,"i=1
O(1) · O
|S′|2 N 2"
N,0.6939443535188216,"
= O
|S′|2 N 2"
N,0.6955810147299509,"
. (16)"
N,0.6972176759410802,"For B(τ, z), we similarly have that"
N,0.6988543371522095,"∥B(τ, z)∥2 ≤O
|S′|2 N 2"
N,0.7004909983633388,"
.
(17)"
N,0.7021276595744681,"To upper bound the norm of P
z∈S′ ∇2
δh(ˆδ(τ), z) · ∂ˆδ(τ)"
N,0.7037643207855974,"∂τ , we apply Lemma 3, Assumption 2, and
have that X"
N,0.7054009819967266,"z∈S′
∇2
δh(ˆδ(τ), z) · ∂ˆδ(τ) ∂τ 2
≤
X z∈S′"
N,0.707037643207856,"∇2
δh(ˆδ(τ), z)

2"
N,0.7086743044189853,∂ˆδ(τ) ∂τ
N,0.7103109656301145,"2
≤O
|S′|2 N"
N,0.7119476268412439,"
.
(18)"
N,0.7135842880523732,"Inserting eqs. (16), (17) and (18), into Eq. (15), we eventually have that

∂2ˆδ(τ) ∂τ 2 2 ≤O"
N,0.7152209492635024,"1
N N
X"
N,0.7168576104746317,"i=1
O
|S′|2 N 2"
N,0.7184942716857611,"
+ τ · O
|S′|3 N 2"
N,0.7201309328968903,"
+ O
|S′|2 N 2"
N,0.7217675941080196,"
+ 2 · O
|S′|2 N !!"
N,0.723404255319149,"= O
|S′|2 N 2 
."
N,0.7250409165302782,The proof is completed.
N,0.7266775777414075,"Finally, combining all the results, we prove Theorem 1."
N,0.7283142389525368,Proof of Theorem 1. The proof is completed by applying Lemmas 3 and 4 into Eq. (4).
N,0.7299509001636661,Published as a conference paper at ICLR 2022
N,0.7315875613747954,"A.2
PROOF OF THEOREM 2"
N,0.7332242225859247,This section presents the proof of Theorem 2.
N,0.734860883797054,"Proof of Theorem 2. By expanding the KL-divergence KL(pS(·+I(S′))∥pS−S′) into Taylor series
around the local region of δ = δ−S′
S
, we have
KL(pS(· + I(S′))∥pS−S′)"
N,0.7364975450081833,"= KL(pS(· −δ−S′
S
∥pS−S′) + (I(S′) + δ−S′
S
)T · ∇2
δKL(pS(· −ξ)∥pS−S′) · (I(S′) + δ−S′
S
)"
N,0.7381342062193126,"= KL(pS(· −δ−S′
S
∥pS−S′) −(I(S′) + δ−S′
S
)T · ∇2
δ """
N,0.7397708674304418,"F(ξ, S) −
X"
N,0.7414075286415712,"z∈S′
h(ξ, z) #"
N,0.7430441898527005,"· (I(S′) + δ−S′
S
),"
N,0.7446808510638298,"(19)
where the ﬁrst-order term equals 0 according to the ﬁrst-order optimal condition. By applying
Theorem 1 and Assumption 2, we further have
(I(S′) + δ−S′
S
)T · ∇2
δ """
N,0.7463175122749591,"F(ξ, S) −
X"
N,0.7479541734860884,"z∈S′
h(ξ, z) #"
N,0.7495908346972177,"· (I(S′) + δ−S′
S
) 2 ≤ ∇2
δ """
N,0.7512274959083469,"F(ξ, S) −
X"
N,0.7528641571194763,"z∈S′
h(ξ, z)"
N,0.7545008183306056,"#
2
·
I(S′) + δ−S′
S

2 2"
N,0.7561374795417348,"≤O ((N −|S′| + 1)L2 · diam(V )) · O
|S′|2 N 2"
N,0.7577741407528642,"2
≤O
|S′|4 N 3"
N,0.7594108019639935,"
.
(20)"
N,0.7610474631751227,"By combining eqs. (19) and (20), the proof is completed."
N,0.762684124386252,"A.3
PROOF OF THEOREM 3"
N,0.7643207855973814,This section presents the proof of Theorem 3.
N,0.7659574468085106,"We derive generalization bound for the proposed algorithm under the PAC-Bayesian framework
(McAllester, 1998; 1999; 2003). The framework can provide guarantees for randomized predictors
(e.g., the Bayesian predictors)."
N,0.7675941080196399,"Speciﬁcally, let Q a distribution on the parameter space Θ, P denotes the prior distribution over
the parameter space Θ. Then, the expected risks R(Q) is bounded in terms of the empirical risk
ˆR(Q, S) and KL-divergence KL(Q∥P) by the following result from PAC-Bayes.
Lemma 5 (cf. McAllester (2003), Theorem 1). For any real δ ∈(0, 1), with probability at least
1 −δ, we have the following inequality for all distributions Q:"
N,0.7692307692307693,"R(Q) ≤ˆR(Q, S) + s"
N,0.7708674304418985,KL(Q∥P) + log 1
N,0.7725040916530278,"δ + log N + 2
2N −1
.
(21)"
N,0.7741407528641571,"Based on Lemma 5, we prove the generalization bounds in Theorem 3."
N,0.7757774140752864,"proof of Theorem 3. Let the prior distribution P be a Laplace distribution lap(0, 1), p−S′
S
= pS(· +
I(S′)) be the distribution processed by the MCMC unlearning algorithm. Then, one can calculate
the KL-divergence KL(p−S′
S
∥P) as follows (where we assume that Θ = Rd),"
N,0.7774140752864157,"KL(p−S′
S
∥P) =
Z Θ
log"
N,0.779050736497545,"p−S′
S
(θ)
p(θ) !"
N,0.7806873977086743,"p−S′
S
(θ)dθ =
Z"
N,0.7823240589198036,"Θ
log

pS(θ)
p(θ −I(S′))"
N,0.7839607201309329,"
pS(θ)dθ =
Z"
N,0.7855973813420621,"Θ
[log pS(θ) + ∥θ −I(S′)∥1 + log 2] pS(θ)dθ"
N,0.7872340425531915,"≤Eθ∼pS log pS(θ) + Eθ∼pS∥θ∥1 + ∥I(S′)∥1 + log 2.
(22)"
N,0.7888707037643208,Published as a conference paper at ICLR 2022
N,0.79050736497545,"Inserting Eq. (22) into Eq. (21) in Lemma 5, we then obtain the PAC-Bayesian generalization
bound."
N,0.7921440261865794,"Eventually, by applying Lemma 3, we have that ∥I(S′)∥1 ≤O(|S′|/N)."
N,0.7937806873977087,The proof is completed.
N,0.795417348608838,"B
EFFICIENT CALCULATION OF MCMC INFLUENCE FUNCTION"
N,0.7970540098199672,"A major computing burden in the MCMC unlearning algorithm is calculating the product of H−1v,
where H is the Hessian matrix of some vector-valued function f(x) and v is a constant vector. When
the function f(x) is of high dimension, the calculation would have a considerably high computa-
tional cost. We follow Agarwal et al. (2017) and Koh & Liang (2017) to apply a divide-and-conquer
strategy to address the issue. This strategy relies on calculating the Hessian-vector product Hv."
N,0.7986906710310966,"Hessian-vector product (HVP). We ﬁrst discuss how to efﬁciently calculate Hv. The calculation
of Hv can be decomposed into two steps: (1) calculate ∂f(x)"
N,0.8003273322422259,"∂x
and then (2) calculate
∂
∂x

∂f(x)"
N,0.8019639934533551,"∂x
· v

."
N,0.8036006546644845,It is worth noting that ∂f(x)
N,0.8052373158756138,"∂x
∈R1×d and v ∈Rd×1, where d > 0 is the dimension of data. Thus,

∂f(x)"
N,0.806873977086743,"∂x
· v

is a scalar value. Calculating its gradient
∂
∂x

∂f(x)"
N,0.8085106382978723,"∂x
· v

has a very low computational
cost on platform PyTorch (Paszke et al., 2017) or TensorFlow (Abadi et al., 2015)."
N,0.8101472995090017,"Calculating H−1v. When the norm ∥H∥≤1, the matrix H−1 can be expanded by the Taylor’s
series as H−1 = P∞
i=0(I −H)i. Deﬁne that H−1
j
= Pj
i=0(I −H)i. Then, we have the following
recursive equation,
H−1
j
v = v + (I −H)H−1
j−1v."
N,0.8117839607201309,"Agarwal et al. (2017) prove that when j →∞, we have E[H−1
j
] →H−1. Therefore, we employ
H−1
j
v to approximate H−1v."
N,0.8134206219312602,"Moreover, to secure the condition ∥H∥≤1 stands, we scale H to cH by a scale c ∈R+, such that
∥cH∥≤1. Then, we approximate (cH)−1. Eventually, we have that H−1 = c(cH)−1. We can
plug it to the applicable equations above."
N,0.8150572831423896,"C
EXPERIMENTS DETAILS FOR GAUSSIAN MIXTURE MODELS"
N,0.8166939443535188,This section provides the additional experiments details for the Gaussian mixture models.
N,0.8183306055646481,"C.1
GAUSSIAN MIXTURE MODELS"
N,0.8199672667757774,"We employ Gaussian mixture models (GMMs) to infer the cluster centers on the synthetic dataset. A
GMM assumes that each example is drawn from K Gaussian distributions centered at µ1, · · · , µK,
respectively. Then, the hierarchical structure of GMM is as follows: (1) draw a clustering center
from the uniform distribution over {µc1, . . . , µcK}; and (2) sample zi from a Gaussian distribution
centering at µci. That is,"
N,0.8216039279869067,"µk ∼N(0, σ2I),"
N,0.823240589198036,"ci ∼categorical
 1"
N,0.8248772504091653,"K , · · · , 1 K 
,"
N,0.8265139116202946,"Zi ∼N(µci, I),"
N,0.8281505728314239,"where 1 ≤k ≤K, 1 ≤i ≤n, µk ∈Rd, ci ∈{1, · · · , K}, Zi ∈Rd, and the hyperparameter σ ∈R
is the prior standard deviation. In our experiments, the factor K is set as 4, and the prior standard
deviation σ is set as 1."
N,0.8297872340425532,"C.2
EXPERIMENTS DETAILS"
N,0.8314238952536824,The experiments for GMM have two main phases:
N,0.8330605564648118,Published as a conference paper at ICLR 2022
N,0.8346972176759411,"Training phase. Every GMM is trained for 4, 000 iterations. The batch size is set as 64. For
both SGLD and SGHMC, the learning rate schedule is set as 4 · t−0.5005/N, where t is the training
iteration step and N is the number of the training set size. Besides, the momentum factor α of
SGHMC is set as 0.9."
N,0.8363338788870703,"Unlearning phase. We remove a batch of 4 datums each time. When calculating the inversed-
Hessian-vector product H−1v in the inﬂuence functions (see Section B), the recursive calculation
number j is set as 32, and the scaling factor c is set as 1/N ′, where N ′ is the number of the current
remained training examples. Notice that N ′ will gradually decrease as the forgetting process con-
tinues. Moreover, we employ the Monte Carlo method to calculate the expectations in the MCMC
inﬂuence function. Speciﬁcally, we repeatedly draw sample θ for 5 times, calculate the matrix or
vector in the MCMC inﬂuence function, and average the results to approach the expectations."
N,0.8379705400981997,"D
EXPERIMENTS DETAILS FOR BAYESIAN NEURAL NETWORKS"
N,0.839607201309329,This section provides the additional experiments details for Bayesian neural networks.
N,0.8412438625204582,"D.1
DATASETS"
N,0.8428805237315876,"We employ two image datasets, Fashion-MNIST (Xiao et al., 2017) and CIFAR-10 (Krizhevsky
et al., 2009), in our experiments. Fashion-MNIST consists of grey-scale images from 10 classes,
where each class contains 6, 000 training examples and 1, 000 test examples. Besides, CIFAR-10
consists of color images from 10 classes, where each class contains 5, 000 training examples and
1, 000 test examples. No data augmentation is used in the experiments."
N,0.8445171849427169,"Furthermore, it is worth noting that the models used for Fashion-MNIST and CIFAR-10 are ﬁrst
pretrained on MNIST (LeCun et al., 1998) and CIFAR-100 (Krizhevsky et al., 2009), respectively.
Please see Appendices D.3 and D.5 for more details."
N,0.8461538461538461,"D.2
BAYESIAN NEURAL NETWORKS"
N,0.8477905073649754,"This section introduces the model architectures used in our experiments and the implementation
details for training BNNs."
N,0.8494271685761048,"D.2.1
MODEL ARCHITECTURES"
N,0.851063829787234,"For Fashion-MNIST, we use a LeNet (LeCun et al., 1998) architecture that consists of two convo-
lutional layers followed by three fully-connected layers. The convolutional layers use 5 × 5 convo-
lutions, each followed by a 2 × 2 max-pooling layer and a ReLU activation function. The channel
numbers of the two convolutional layers are 6 and 16, respectively. Besides, each fully-connected
layer is also followed by a ReLU activation function, while the hidden layer channels are 120 and
84, respectively."
N,0.8527004909983633,"for CIFAR-10, we follow Abadi et al. (2016) to use a network architecture that consists of two
convolutional layers followed by two fully-connected layers. Each convolutional layer uses 5 × 5
convolution, with a channel number of 64, followed by a 2 × 2 max-pooling layer and a ReLU acti-
vation function. Besides, each fully-connected layer is also followed by a ReLU activation function,
while the hidden layer channels are 384."
N,0.8543371522094927,"D.2.2
MODEL TRAINING"
N,0.855973813420622,"In all the experiments, we use an isotropic Gaussian distribution N(0, σ2
0I) as the prior of the BNNs,
in which the hyperparameter σ0 is set as 0.1."
N,0.8576104746317512,"Traditional SG-MCMC methods would inject random noise to BNNs during training. However,
it is found that the noise injection in the early training iterations hurts the convergence of BNNs
(Zhang et al., 2020a). To alleviate such a problem, we follow Zhang et al. (2020a) to ﬁrst avoid the
noise injection in the early training iterations and then resume SG-MCMC as usual in the rest of the
training."
N,0.8592471358428805,Published as a conference paper at ICLR 2022
N,0.8608837970540099,"D.3
ESTIMATING THE ε-KNOWLEDGE REMOVAL GUARANTEE"
N,0.8625204582651391,"We use the knowledge removal estimator ˆεM deﬁned in Deﬁnition 2 to estimate the ε value in the ε-
knowledge removal guarantee. According to the deﬁnition of ˆεM, calculating it requires ﬁrst ﬁxing
a series of random seeds, and then calculating the KL-divergence between two MCMC distributions."
N,0.8641571194762684,"For the random seeds, we employ the pretraining technique (Golatkar et al., 2020) to ﬁx them.
Speciﬁcally, for the experiments on Fashion-MNIST, all the models used are ﬁrst pre-trained on
MNIST; for the experiments on CIFAR-10, all the models used are ﬁrst pre-trained on CIFAR-100."
N,0.8657937806873978,"Besides, for the KL-divergence calculation, we follow Wang et al. (2009) to estimate the KL-
divergence in a k-NN manner, in which 100 samples are drawn from each of the processed and
retrained distributions for the estimation."
N,0.867430441898527,"D.4
MEMBERSHIP INFERENCE ATTACK"
N,0.8690671031096563,"Membership inference attack (MIA) (Shokri et al., 2017; Yeom et al., 2018) is a privacy attack
that aims to infer whether a given example is in the training set based on the output of the model.
In our experiments, we adopt a white-box threshold-based MIA (Yeom et al., 2018) to assess the
unlearning performance. The calculation consists of two steps: (1) learn an optimal MIA threshold
on the remained training set Sr and the test set Stest, and (2) calculate MIA accuracy with the
learned threshold on the removed training set Sf."
N,0.8707037643207856,"Learn the optimal threshold. Suppose the “to-be-inferred” example (x, y) comes from Sr and
Stest with equal probabilities. Then, the attack accuracy of MIA with a threshold ρ ∈[0, 1] on the
model fθ is calculated as follows,"
N,0.8723404255319149,"Acc(ρ, Sr, Stest) = 0.5 × P"
N,0.8739770867430442,"(x,y)∈Sr 1[fθ(x)y ≥ρ]"
N,0.8756137479541735,"|Sr|
+ P"
N,0.8772504091653028,"(x,y)∈Stest 1[fθ(x)y < ρ]"
N,0.8788870703764321,"|Stest| ! ,"
N,0.8805237315875614,"where fθ(x)y is the output conﬁdence for label y and 1[·] is the indicator function. Then, the optimal
threshold ρoptim is obtained via calculating the maximizer of the above attack accuracy, i.e.,"
N,0.8821603927986906,"ρoptim = arg max
ρ
Acc(ρ, Sr, Stest)."
N,0.88379705400982,"Calculate MIA accuracy on Sf. With the optimal threshold ρoptim that learned on Sr and Stest,
the MIA accuracy on the removed set Sf is calculated as follows,"
N,0.8854337152209493,"Acc(ρoptim, Sf) = P"
N,0.8870703764320785,"(x,y)∈Sf 1[fθ(x)y ≥ρoptim]"
N,0.8887070376432079,"|Sf|
."
N,0.8903436988543372,"Intuitively, after removing the knowledge learned from the removed subset Sf, the MIA accuracy
Acc(ρoptim, Sf) would decline. As a result, a low MIA accuracy on the removed subset Sf would
imply a strong knowledge removal performance."
N,0.8919803600654664,"D.5
EXPERIMENTS DETAILS"
N,0.8936170212765957,"This section provides the omitted experiment details, including the settings of the hyperparameters
and the procedures of the experiments."
N,0.8952536824877251,"D.5.1
EXPERIMENTS ON FASHION-MNIST"
N,0.8968903436988543,"Pretraining phase. In every experiment, we pretrain a non-Bayesian model on MNIST via SGD
for 2, 000 iterations, with a batch size of 128, a learning rate of 0.1/N, where N is the training set
size, and a momentum factor of 0.9."
N,0.8985270049099836,"Training phase. Every BNN is trained for 10, 000 iterations. The batch size is set as 128. For both
SGLD and SGHMC, we ﬁrst train the model without noise injection in the ﬁrst 1, 000 iterations. In
this stage, the learning rate is ﬁxed to 0.01/N. Then, we resume the traditional SGLD and SGHMC
in the rest of the training. In this stage, the learning rate schedule is set as 0.01 · t−0.5005/N, where
t is the training iteration step. Besides, the momentum factor α of SGHMC is set as 0.9."
N,0.900163666121113,Published as a conference paper at ICLR 2022
N,0.9018003273322422,Unlearning phase. We remove a batch of 64 datums each time.
N,0.9034369885433715,"For the MCMC unlearning algorithm, when calculating the inversed-Hessian-vector product H−1v
in the MCMC inﬂuence function (see Appendix B), the recursive calculation number j is set as 64,
the scaling factor c is set as 0.05/N ′, in which N ′ is the number of the current remained training
examples. Notice that N ′ will gradually decrease as the forgetting process continues. Besides, we
employ the Monte Carlo method to calculate the expectations in the MCMC inﬂuence function.
Speciﬁcally, each time we draw a sample θ via the MCMC sampler and calculate the matrix and
vector in the MCMC inﬂuence function based on θ to estimate the desired expectation."
N,0.9050736497545008,"Besides, for the importance sampling method, we process each data deletion request by performing
MCMC sampling for 1, 000 times on the remaining data."
N,0.9067103109656302,"D.5.2
EXPERIMENTS ON CIFAR-10"
N,0.9083469721767594,"Pretraining phase. In every experiment, we pretrain a non-Bayesian model on CIFAR-100 via SGD
for 10, 000 iterations, with a batch size of 128, a learning rate of 0.1/N, where N is the training set
size, and a momentum factor of 0.9."
N,0.9099836333878887,"Training phase. Every BNN is trained for 20, 000 iterations. The batch size is set as 128. For both
SGLD and SGHMC, we ﬁrst train the model without noise injection in the ﬁrst 5, 000 iterations. In
this stage, the learning rate is ﬁxed to 0.01/N. Then, we resume the traditional SGLD and SGHMC
in the rest of the training. In this stage, the learning rate schedule is set as 0.01 · t−0.5005/N, where
t is the training iteration step. Besides, the momentum factor α of SGHMC is set as 0.9."
N,0.911620294599018,Unlearning phase. We remove a batch of 64 datums each time.
N,0.9132569558101473,"For the MCMC unlearning algorithm, When calculating the inversed-Hessian-vector product H−1v
in the MCMC inﬂuence functions (see Appendix B), the recursive calculation number j is set as
64, the scaling factors c is set as 0.08/N ′, where N ′ is the number of the current remained training
examples. Notice that N ′ will gradually decrease as the forgetting process continues. Besides, we
employ the Monte Carlo method to calculate the expectations in the MCMC inﬂuence function.
Speciﬁcally, each time we draw a sample θ via the MCMC sampler and calculate the matrix and
vector in the MCMC inﬂuence function based on θ to estimate the desired expectation."
N,0.9148936170212766,"Besides, for the importance sampling method, we process each data deletion request by performing
MCMC sampling for 1, 000 times on the remaining data."
N,0.9165302782324058,"D.6
EXPERIMENT RESULTS ON FASHION-MNIST"
N,0.9181669394435352,"This section presents all the experiment results of BNNs on the Fashion-MNIST dataset. The evalu-
ations of unlearning performance are shown as Table 2, while the time costs for unlearning is shown
in Fig. 4 The results further justify the effectiveness of the proposed algorithm."
N,0.9198036006546645,"SGLD
SGHMC
0 20 40"
N,0.9214402618657938,Unlearning Time (s)
N,0.9230769230769231,Fashion-MNIST
N,0.9247135842880524,"Retrain
IS
Ours"
N,0.9263502454991817,Figure 4: Time costs for processing single data deletion requests on BNNs.
N,0.9279869067103109,"D.7
EVALUATION ON PREDICTION DIFFERENCES"
N,0.9296235679214403,"In this section, we adopt the metric named prediction differences to better quantify the difference
between the retrained and processed models. For two BNNs p1(·) and p2(·) learned by MCMC, their
prediction difference on a given dataset S is deﬁned as Eθ1∼p1Eθ2∼p2
1
|S|
P"
N,0.9312602291325696,"(xi,yi)∈S ∥fθ1(xi) −"
N,0.9328968903436988,Published as a conference paper at ICLR 2022
N,0.9345335515548282,"Table 2: Experiment results on Fashion-MNIST. Different metrics are used to evaluate the machine
unlearning performance, including the classiﬁcation errors on the remaining set Sr, removed set
Sf, and test set Stest, the knowledge removal estimators ˆεM, and the membership inference attack
(MIA) accuracy on Sf. Every experiment is repeated 5 times."
N,0.9361702127659575,"Remove
Method
Err. on Sr (%)
Err. on Sf (%)
Err. on Stest (%)
ˆεM (×103)
MIA Acc. (%)"
N,0.9378068739770867,"Fashion
MNIST
+
SGLD"
N,0.939443535188216,"4,000
Examples"
N,0.9410801963993454,"Retrain
12.81±0.49
37.62±0.76
15.63±0.59
0.00±0.00
16.12±5.79"
N,0.9427168576104746,"Origin
13.49±0.81
17.39±0.41
14.73±0.80
351.00±4.98
10.86±8.02
IS
12.67±0.70
34.93±2.16
15.30±0.77
365.97±3.04
13.97±11.37
Ours
12.93±0.72
35.84±1.85
15.57±0.77
350.30±4.82
10.36±2.31"
N,0.9443535188216039,"6,000
Examples"
N,0.9459901800327333,"Retrain
11.21±0.57
100.00±0.00
21.05±0.49
0.00±0.00
0.00±0.00"
N,0.9476268412438625,"Origin
13.38±0.85
17.08±0.51
14.73±0.80
364.63±2.45
7.20±5.93
IS
11.10±0.66
87.30±5.82
19.90±0.87
378.11±1.45
4.52±2.31
Ours
11.39±0.68
98.13±1.61
20.59±0.99
362.55±2.47
1.25±0.67"
N,0.9492635024549918,"Fashion
MNIST
+
SGHMC"
N,0.9509001636661211,"4,000
Examples"
N,0.9525368248772504,"Retrain
14.57±1.11
38.90±3.42
17.34±1.11
0.00±0.00
5.58±5.81"
N,0.9541734860883797,"Origin
15.21±1.30
17.58±1.68
16.40±1.17
362.60±8.24
12.03±12.61
IS
14.27±1.22
36.54±1.73
16.97±1.16
375.62±5.10
13.76±13.12
Ours
14.56±1.24
37.48±2.02
17.29±1.08
361.72±7.87
11.28±13.25"
N,0.955810147299509,"6,000
Examples"
N,0.9574468085106383,"Retrain
12.99±0.94
100.00±0.00
22.61±0.69
0.00±0.00
0.00±0.00"
N,0.9590834697217676,"Origin
15.16±1.31
17.27±1.80
16.40±1.17
366.98±6.24
8.32±12.07
IS
12.52±1.04
87.48±7.22
20.94±1.44
382.34±3.48
4.20±1.84
Ours
12.93±1.16
98.23±1.04
22.39±0.85
364.99±6.00
1.59±0.51"
N,0.9607201309328969,"Table 3: The results of prediction differences on CIFAR-10 and Fashion-MNIST. The prediction
differences between the retrained model and the processed model are calculated on the remaining
set Sr, removed set Sf, and test set Stest, respectively."
N,0.9623567921440261,"Remove
Method
Pred. diff. on Sr
Pred. diff. on Sf
Pred. diff. on Stest"
N,0.9639934533551555,"CIFAR-10
+
SGLD"
N,0.9656301145662848,"3,000
Examples"
N,0.967266775777414,"Origin
0.18±0.00
0.50±0.02
0.21±0.01
IS
0.18±0.00
0.37±0.01
0.20±0.01
Ours
0.17±0.00
0.35±0.02
0.19±0.01"
N,0.9689034369885434,"5,000
Examples"
N,0.9705400981996727,"Origin
0.23±0.00
1.42±0.02
0.37±0.01
IS
0.21±0.00
0.92±0.03
0.29±0.01
Ours
0.19±0.00
0.67±0.05
0.25±0.01"
N,0.972176759410802,"CIFAR-10
+
SGHMC"
N,0.9738134206219312,"3,000
Examples"
N,0.9754500818330606,"Origin
0.19±0.00
0.50±0.01
0.22±0.00
IS
0.19±0.00
0.38±0.01
0.21±0.00
Ours
0.18±0.00
0.35±0.01
0.20±0.01"
N,0.9770867430441899,"5,000
Examples"
N,0.9787234042553191,"Origin
0.23±0.00
1.44±0.02
0.37±0.00
IS
0.22±0.00
0.94±0.02
0.31±0.00
Ours
0.20±0.00
0.73±0.05
0.27±0.00"
N,0.9803600654664485,"Fashion
MNIST
+
SGLD"
N,0.9819967266775778,"4,000
Examples"
N,0.983633387888707,"Origin
0.13±0.02
0.37±0.02
0.15±0.02
IS
0.11±0.02
0.22±0.01
0.12±0.02
Ours
0.11±0.02
0.21±0.02
0.12±0.02"
N,0.9852700490998363,"6,000
Examples"
N,0.9869067103109657,"Origin
0.17±0.01
1.45±0.02
0.30±0.01
IS
0.13±0.01
0.56±0.05
0.18±0.01
Ours
0.13±0.01
0.33±0.07
0.15±0.01"
N,0.9885433715220949,"Fashion
MNIST
+
SGHMC"
N,0.9901800327332242,"4,000
Examples"
N,0.9918166939443536,"Origin
0.15±0.03
0.43±0.03
0.18±0.03
IS
0.14±0.03
0.26±0.05
0.15±0.03
Ours
0.14±0.03
0.26±0.05
0.15±0.03"
N,0.9934533551554828,"6,000
Examples"
N,0.9950900163666121,"Origin
0.18±0.02
1.44±0.02
0.30±0.02
IS
0.14±0.02
0.55±0.07
0.18±0.02
Ours
0.13±0.02
0.35±0.05
0.16±0.02"
N,0.9967266775777414,"fθ2(xi)∥1, where fθ1(xi) and fθ2(xi) are two prediction conﬁdence vectors for the example xi.
Intuitively, a smaller prediction difference indicates a smaller deviation between the retrained and
processed models."
N,0.9983633387888707,"We calculate the prediction difference between the retrained model and the processed model on three
different datasets, Sr, Sf, and Stest. The experiment results on CIFAR-10 and Fashion-MNIST are
shown in Table 3. The results show that the proposed MCMC unlearning algorithm can effectively
reduce the prediction difference, which further justify the effectiveness of the proposed method."
