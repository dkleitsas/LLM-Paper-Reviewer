Section,Section Appearance Order,Paragraph
ZHEJIANG UNIVERSITY,0.0,"1Zhejiang University
2Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security
3Siebel School of Computing and Data Science
University of Illinois Urbana-Champaign
{qiheng_sun,jinfeiliu}@zju.edu.cn, hxia7@illinois.edu"
ABSTRACT,0.0020491803278688526,Abstract
ABSTRACT,0.004098360655737705,"The state-of-the-art feature attribution methods often neglect the influence of
unobservable confounders, posing a risk of misinterpretation, especially when
it is crucial for the interpretation to remain faithful to the data. To counteract
this, we propose a new approach, data-faithful feature attribution, which trains
a confounder-free model using instrumental variables. The cluttered effects of
unobservable confounders in a model trained as such are decoupled from input
features, thereby aligning the output of the model with the contribution of input
features to the target feature in the data generation. Furthermore, feature attribution
results produced by our method are more robust when focusing on attributions
from the perspective of data generation. Our experiments on both synthetic and
real-world datasets demonstrate the effectiveness of our approaches."
INTRODUCTION,0.006147540983606557,"1
Introduction"
INTRODUCTION,0.00819672131147541,"The increasing complexity and opacity of machine learning (ML) models in real-world applications
boost the demand for feature attribution [8]. The feature attribution methods have been developed to
help users understand why a model produces certain outputs from specific inputs. For instance, a
loan applicant rejected by a bank’s decision-making model might seek reasons behind the denial and
what changes could potentially reverse the model’s decision. Some recent studies [19, 9] have shifted
the focus of feature attribution from a traditional model-centric perspective to a new perspective that
is data-centric. Specifically, users may wish to assign importance values to features according to the
data generation process, referring to the causal relationships through which features influence the
target feature. For example, consider a medical application setting where a patient seeks to understand
which personal features aggravated the illness and the cooperative impact of all features on the illness.
What the patient really wants to know is how all features collaboratively contribute to the illness,
rather than one diagnostic model’s prediction output. These two aspects of feature attribution align
with the concepts of model fidelity and data fidelity, respectively. Here, model fidelity refers to the
attribution being consistent with the output of the explained model, while data fidelity pertains to the
attribution being consistent with the data generation process."
INTRODUCTION,0.010245901639344262,"SHapley Additive exPlanations (SHAP) [27] and Integrated Gradients (IG) [38] are prevalent rep-
resentatives of two distinct series of feature attribution methods, each uniquely satisfying critical
axioms including sensitivity, implementation invariance, completeness, and symmetry [28]. These
properties are essential for ensuring reasonability and fairness in feature attribution. The SHAP-based
methods, grounded in game theory and particularly the Shapley value [32], offer interpretations by
evaluating all possible combinations of feature contributions in a discrete feature space. In contrast,"
INTRODUCTION,0.012295081967213115,∗Jinfei Liu is the corresponding author.
INTRODUCTION,0.014344262295081968,Ability
INTRODUCTION,0.01639344262295082,"Education
Income
Parental
Education"
INTRODUCTION,0.018442622950819672,Unobservable Confounder
INTRODUCTION,0.020491803278688523,Instrumental Variable 1 2
INTRODUCTION,0.022540983606557378,"Other
Features"
INTRODUCTION,0.02459016393442623,"Figure 1: Arrows indicate direct effects. Since Ability s not directly observed and is correlated with
education, the influence that should be attributed to Ability (arrow 1) is erroneously attributed to
Education (arrow 2) in feature attribution. To fix this issue, Parental Education can be used as an
instrumental variable for investigating the true impact of Education on Income."
INTRODUCTION,0.02663934426229508,"the IG-based methods, which are an analog of the Aumann-Shapley method [39] from cost-sharing,
focus on continuous feature spaces by using path integration over gradients. It is worth noting that
even when we aim for interpretations that are faithful to the data, we still rely on a model to predict
the target feature values when certain features are selected or excluded in the attribution process.
However, when unobservable confounders exist, both SHAP-based and IG-based methods may
lead to misunderstandings if applied directly to the widely used predictive model. This is because
unobservable confounders, although impacting the output, are entirely overlooked from the process
of attribution. Consequently, their influence is instead attributed to other correlated features."
INTRODUCTION,0.028688524590163935,"Motivation example. As shown in Figure 1, suppose a model predicting personal income includes
Education as an input feature, and Ability serves as a confounder if the model does not incorporate
it as an input feature. Because Ability has an indirect impact on Income through its influence on
Education and a direct impact on Income simultaneously, the existing feature attribution methods
tend to incorrectly attach the direct impact of Ability on Income to the impact of Education on Income
due to their correlation. This concealed correlation may lead to incorrect attribution on the role
of educational level in personal income, resulting in an overestimation of the education returns, as
demonstrated in our experiments using real datasets (§ 5)."
INTRODUCTION,0.030737704918032786,"In this paper, we develop a method to eliminate unobservable confounder effects in feature attribution
in order to achieve a deeper understanding from the perspective of data fidelity. The instrumental
variable method is widely used for causal analysis [24]. It lies in identifying features that directly
affect those influenced by confounders, while not having a direct impact on the outcome themselves.
By using the instrumental variable to control confounders that influence specific features, any resulting
changes in the outcome variable are driven solely by how the instrumental variable alters that feature.
For example, in Figure 1, when examining the impact of Education on Income, a suitable instrumental
variable could be the variable Parental Education as analyzed in appendix Section F.2. By observing
the changes in Education resulting from variations in Parental Education, we can then discern the
true effect of Education on Income, effectively isolating it from other confounders. Intuitively, the
instrumental variable approach can help to mitigate the impact of unobservable confounders in feature
attribution. However, the instrumental variable approach mainly focuses on evaluating the isolated
impact of individual features influenced by unobservable confounders on the outcome variable, while
feature attribution lies in considering the cooperative attribution of features. This means evaluating
the combined contribution of Education and Other Features on Income."
INTRODUCTION,0.03278688524590164,"To bridge this gap, we propose using a two-stage model training with the instrumental variable that
disrupts the association between confounders and other features. Specifically, the model is trained
using features re-estimated through instrumental variables and collaborative variables. This ensures
that the influence of confounders remains consistent despite variations in feature coalitions. Therefore,
the marginal contribution of each feature, which is determined by assessing the impact on the model’s
output with and without the feature, is not affected by any confounders. Furthermore, the attribution
value of each feature, calculated as the average of its marginal contributions across different feature
coalitions, remains influenced by confounders. This alignment allows the contribution of input
features to the model output to mirror their contribution in data generation to the target feature,
thereby facilitating the attribution to be faithful to the data. Feature attribution involves explaining
a model output by assigning attribution scores to the input instance. However, our focus is on
data-faithful feature attribution, i.e., we are not trying to explain the output of a specific model but
trying to explain the target feature through a model."
INTRODUCTION,0.03483606557377049,"Contributions. To the best of our knowledge, we are the first to identify a crucial issue: unobservable
confounders compromise feature attribution, especially when data fidelity is essential. To tackle this
challenge, we propose training models free of confounders using instrumental variables, ensuring
the feature attribution will remain faithful to the data. We validate the effectiveness of our proposed
methods using both real and synthetic datasets, observing that our method achieves up to a 67%
relative improvement over the baseline methods in terms of the error of attribution ratio metric in the
real dataset."
PRELIMINARIES,0.036885245901639344,"2
Preliminaries"
PROBLEM SETUP,0.0389344262295082,"2.1
Problem Setup"
PROBLEM SETUP,0.040983606557377046,"We aim to quantitatively assess the influence of each input feature on the target feature. This
assessment can be viewed as a contribution assignment problem in the context of cooperative game
theory [41]. Formally, given an explained input vector of d features x∗= {x∗
1, . . . , x∗
d}, a baseline
input x′, and a model f : Rd →R which approximates the data generation equation for the target
feature, our objective is to explain the difference in target feature, i.e., y∗−y′, conducting data-faithful
attribution for the input features. We assume x∗and x′ are of the same dimensionality d, and each
entry can be either discrete or continuous. We denote by X the set of input features and Y the target
feature, partitioning X into two subsets: ˜X, which is influenced by unobserved confounders (denoted
as E), and X, the set of other observable features. For clarity and convenience, we use x, y, ˜x,
x, ϵ to denote possible values within feature sets X, Y , ˜X, X, E, respectively. For a given subset
of features S, we denote the subset of the original vector of values by using S as a subscript, e.g.,
xS := {xi}i:i∈S."
SHAP-BASED ATTRIBUTION,0.0430327868852459,"2.2
SHAP-based Attribution"
SHAP-BASED ATTRIBUTION,0.045081967213114756,"Shapley Value. Consider a set of players N = {1, . . . , d}. A coalition S is a subset of N that
cooperates to complete a task. A utility function U(S) (S ⊆N) is the utility of a coalition S for a
task. The marginal contribution of player i with respect to a coalition S is U(S∪{i})−U(S). Shapley
value is the unique metric that satisfies the properties of fair reward allocation, including balance,
symmetry, additivity, and zero element [41]. It measures the expectation of marginal contribution by
i in all possible coalitions. That is,"
SHAP-BASED ATTRIBUTION,0.0471311475409836,"SVi =
1
|N| X"
SHAP-BASED ATTRIBUTION,0.04918032786885246,S⊆N \{i}
SHAP-BASED ATTRIBUTION,0.05122950819672131,"U(S ∪{i}) −U(S)
 |N |−1
|S|

."
SHAP-BASED ATTRIBUTION,0.05327868852459016,"Computing the exact Shapley value requires enumerating all utilities for all player subsets. Therefore,
the computational complexity of exactly calculating the Shapley value is exponential [46]."
SHAP-BASED ATTRIBUTION,0.055327868852459015,"SHAP [27] utilizes the concept of Shapley values to attribute the contribution of each feature in a
model. In the existing SHAP-based methods [27, 19], the definition of utility functions for interpreting
an input x can be divided into two categories [5], condition expectation Shapley and intervention
Shapley. In condition expectation Shapley, following the assumption that the features are generated
according to a distribution D, the utility function is defined by UC(S) = ED[f(x)|xS = x∗
S] [37]
based on the condition expectation of the model prediction under feature set S. In intervention
Shapley, the utility function is defined by UI(S) = ED[f(x)|do(xS = x∗
S)] [44] where the
operation do(xS = x∗
S) means we intervene on the features S in variable x to be the same as the
features in x∗, while the features outside of S in x are influenced following the causal relationships
of the features [30]. For conciseness, we omit the subscript D in the expectation term in the rest of
the paper."
IG-BASED ATTRIBUTION,0.05737704918032787,"2.3
IG-based Attribution"
IG-BASED ATTRIBUTION,0.05942622950819672,"IG is a pivotal method for model attribution [38], particularly well-suited for deep neural networks
due to its prerequisite that the model be continuously differentiable. This approach calculates the
cumulative gradients along a straight-line path extending from a baseline input x′ to the explained
input x∗. Mathematically, the attribution IGi assigned to a particular feature x∗
i for a given input x∗"
IG-BASED ATTRIBUTION,0.06147540983606557,and baseline x′ is defined as:
IG-BASED ATTRIBUTION,0.06352459016393443,"IGi (x∗, x′, f) = (x∗
i −x′
i)
Z 1 α=0"
IG-BASED ATTRIBUTION,0.06557377049180328,∂f (x′ + α (x∗−x′))
IG-BASED ATTRIBUTION,0.06762295081967214,"∂x∗
i
dα.
(1)"
IG-BASED ATTRIBUTION,0.06967213114754098,"Remarkably, IG shares similarities with the Aumann-Shapley approach [39] and satisfies several
essential properties, including linearity, dummy attribution, Affine Scale Invariance (ASI), propor-
tionality, and symmetry [37]. Recent research has enhanced IG through its application to complex
models and the refinement of the integrated path [1, 28]."
MISATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.07172131147540983,"3
Misattribution with Unobservable Confounders"
MISATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.07377049180327869,"In this section, we carry out a theoretical analysis to demonstrate how unobservable confounders
mislead the feature attribution of both SHAP-based and IG-based methods. To show the influence
of unobservable confounders in feature attribution, we first employ a simple structural equation to
characterize the data-generating process, expressed as"
MISATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.07581967213114754,"y = g(˜x, x) + ϵ,"
MISATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.0778688524590164,"where g(˜x, x) can represent any linear or nonlinear continuous relationship involving both ˜x and
x. The equation allows us to clearly recognize the individual contributions of ˜x and x to y, while
also considering the unobserved effects encapsulated in the error term ϵ. Given that ˜X is the set of
features influenced by unobservable confounders E, it generally follows that given two data instances
x1 and x2, E[ϵ|˜x1] ̸= E[ϵ|˜x2] when ˜x1 ̸= ˜x2 since ˜X is influenced by E while E[ϵ|x1] = E[ϵ|x2] is
valid as the feature set X is not affected by E."
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.07991803278688525,"3.1
Example of Errors for Data-Faithful Feature Attribution"
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.08196721311475409,"We discuss how unobservable confounders introduce errors in data-faithful feature attribution with
a toy example of Figure 1 in condition expectation Shapley. We can assume ϵ as ability, ˜x as the
measurement of education level, x the work time in a week (i.e., the other variable), and y the weekly
income. ˜x, x, and ϵ each represents a single numerical variable. The data generation equations are
defined as follows:"
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.08401639344262295,"ϵ ∼Uniform(0, 1),
˜x ∼Uniform(0, 1) + ϵ,
x ∼Uniform(0, 1),
y = ˜x · x + ϵ."
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.0860655737704918,"In this case, ability influences education, and the three features all have a direct influence on income.
Consider a specific data instance x∗= [˜x∗, x∗] = [1.5, 1] we are curious about the contributions of
the individual’s education level and work hours to their income compared to the features distribution.
In this example, it means assigning a value to the individual’s education level ˜x∗= 1.5 and work
time x∗= 1 to evaluate their contribution to weekly income in comparison to the distribution of
education levels and work hours of the population."
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.08811475409836066,"First, we conduct feature attribution with a model f that is trained to fit E[y|x] = E[y|˜x, x] =
g(˜x, x) + E[ϵ|˜x, x] which simulates the widely used supervised machine learning model train-
ing paradigm in reality. The utility derived from the model is UC(S) = E[f(x)|xS = x∗
S] =
E[g(˜x, x)|xS = x∗
S] + E[ϵ|xS = x∗
S].
The condition expectation Shapley value of ˜x∗is
SVC
˜x∗= 1"
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.09016393442622951,"2{[UC({˜x∗}) −UC(∅)] + [UC({˜x∗, x∗}) −UC({x∗})]}. Replacing the according util-
ities, we have SVC
˜x∗=
1
2{E[g(˜x∗, x)] + E[ϵ|˜x∗, x] −E[g(˜x, x)] −E[ϵ|˜x, x] + E[g(˜x∗, x∗)] +
E[ϵ|˜x∗, x∗] −E[g(˜x, x∗)] −E[ϵ|˜x, x∗]}."
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.09221311475409837,"Then, we conduct feature attribution for ˜x∗with the term which it really contribute to y, i.e., g(˜x, x).
The utility derived is U
C(S) = E[g(˜x, x)|xS = x∗
S]. According to the definition of condition
expectation Shapley, SV
C
˜x∗= 1"
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.0942622950819672,"2{[U
C({˜x∗}) −U
C(∅)] + [U
C({˜x∗, x∗}) −U
C({x∗})]}. Replacing"
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.09631147540983606,"the accrrording utilities, we have SV
C
˜x∗= 1"
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.09836065573770492,"2{E[g(˜x∗, x)]−E[g(˜x, x)]+E[g(˜x∗, x∗)]−E[g(˜x, x∗)]}."
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.10040983606557377,"Errors in Feature Attribution Values. The values of each expectation term computed according
to the data generation equations are shown in Table 1. Since x is independent from ϵ, we have
E[ϵ|˜x, x∗] = E[ϵ|˜x, x] and E[ϵ|˜x∗, x∗] = E[ϵ|˜x∗, x]. By substituting the values for each expected
term, we can obtain that SVC
˜x∗= 0.875, SV
C
˜x∗= 0.625, SVC"
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.10245901639344263,"x∗= 0.325, and SV
C
x∗= 0.325. It’s"
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.10450819672131148,"Table 1: Value of each expectation term in SVC
˜x∗."
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.10655737704918032,"E[g(˜x, x)]
E[g(˜x∗, x)]
E[g(˜x, x∗)]
E[g(˜x∗, x∗)]
E[ϵ|˜x, x]
E[ϵ|˜x∗, x]
0.5
0.75
0.5
1.5
0.5
0.75"
EXAMPLE OF ERRORS FOR DATA-FAITHFUL FEATURE ATTRIBUTION,0.10860655737704918,"clear that attribution based on the model trained to fit E[y|x], which is a common training paradigm in
supervised learning, tends to give a wrong attribution value of ˜x∗, which is the excessive attribution
value of education level in this example. The intuitive reason is that the model associates the direct
effect of ability on income with the education level, i.e., the influence of ϵ is attached to ˜x. However,
E[ϵ|˜x∗, x] −E[ϵ|˜x, x] is not actually in the effect of ˜x∗on y because ˜x does not influence ϵ during
the data generation process."
ERRORS IN FEATURE ATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.11065573770491803,"3.2
Errors in Feature Attribution with Unobservable Confounders"
ERRORS IN FEATURE ATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.11270491803278689,"We analyze the attribution errors when the feature attribution is conducted on a model f trained to fit
E[y|x] = E[y|˜x, x] in supervised learning for SHAP-based method (Propositions 1 and 2) and IG
(Proposition 3), respectively.
Proposition 1. The expected error for marginal contribution of feature i in condition expectation
Shapley with model f trained to fit E[y|x] is E[ϵ|xS∪{i} = x∗
S∪{i}] −E[ϵ|xS = x∗
S], resulting"
ERRORS IN FEATURE ATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.11475409836065574,"an expected deviation of attribution value by ∆SVi =
1
N
P"
ERRORS IN FEATURE ATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.1168032786885246,"S⊆N \{i}
 |N |−1
|S|
−1{E[ϵ|xS∪{i} =
x∗
S∪{i}] −E[ϵ|xS = x∗
S]}."
ERRORS IN FEATURE ATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.11885245901639344,"Proof. Due to the limited space, please see the appendix for detailed proof. The same to the following
propositions."
ERRORS IN FEATURE ATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.12090163934426229,"Proposition 2. The expected error for marginal contribution of feature i in intervention Shapley
with mode f trained to fit E[y|x] is ED[ϵ|do(xS∪{i} = x∗
S∪{i})] −E[ϵ|do(xS = x∗
S)], resulting"
ERRORS IN FEATURE ATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.12295081967213115,"an expected deviation of attribution value by ∆SVi =
1
N
P"
ERRORS IN FEATURE ATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.125,"S⊆N \{i}
 |N |−1
|S|
−1{E[ϵ|do(xS∪{i} =
x∗
S∪{i})] −E[ϵ|do(xS = x∗
S)]}."
ERRORS IN FEATURE ATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.12704918032786885,Proposition 3. The expected error for attribution value of feature i using IG with model f trained to
ERRORS IN FEATURE ATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.1290983606557377,"fit E[y|x] is ∆IGi = (x∗
i −x′
i)
R 1
α=0
∂f(x′+α(x∗−x′))"
ERRORS IN FEATURE ATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.13114754098360656,"∂xi
−
∂g(x′+α(x∗−x′))"
ERRORS IN FEATURE ATTRIBUTION WITH UNOBSERVABLE CONFOUNDERS,0.13319672131147542,"∂xi
dα."
MITIGATING UNOBSERVABLE CONFOUNDERS VIA INSTRUMENTAL VARIABLES,0.13524590163934427,"4
Mitigating Unobservable Confounders via Instrumental Variables"
MITIGATING UNOBSERVABLE CONFOUNDERS VIA INSTRUMENTAL VARIABLES,0.13729508196721313,"As demonstrated in Section 3, when it pertains to unobservable confounders, the prevalent feature
attribution methods including SHAP and IG inevitably lead to misunderstandings that are not faithful
to the data, since they rely on predictive model f trained to fit E[y|x]. This is fundamental because the
trained predictive model has already associated the unobservable confounders with the input features.
Therefore, it is tempting to ask: how can we decouple the confounders from their correlations with
other features in the used model f?"
MOTIVATION OF USING CONFOUNDER-FREE MODEL,0.13934426229508196,"4.1
Motivation of Using Confounder-free Model"
MOTIVATION OF USING CONFOUNDER-FREE MODEL,0.1413934426229508,"One may think a straightforward solution is directly training a model f to fit g(˜x, x). Unfortunately,
it is nearly impossible since we cannot remove the influence of unobservable confounders in the target
feature y. To bridge the gap, we provide an alternative solution to train a model that gives the same
attribution results for the input features as it is trained to fit g(˜x, x). Denote by ˆy = g(˜x, x) + E[ϵ],
and f is trained to fit E[ˆy|˜x, x]. The influence of ˜x and x on ˆy is identical to their impact on y, as
both are encompassed within g(˜x, x)."
MOTIVATION OF USING CONFOUNDER-FREE MODEL,0.14344262295081966,"Example. For the toy example in Section 3, the utility calculated with f trained to fit E[ˆy|˜x, x] =
g(˜x, x) + E[ϵ] is ˆUC(S) = E[g(˜x, x)|xS = x∗
S] + E[ϵ]. The condition expectation Shapley value"
MOTIVATION OF USING CONFOUNDER-FREE MODEL,0.14549180327868852,"of ˜x∗is ˆ
SV
C
˜x∗= 1"
MOTIVATION OF USING CONFOUNDER-FREE MODEL,0.14754098360655737,"2{[ ˆU({˜x∗}) −ˆU(∅)] + [ ˆU({˜x∗, x∗}) −ˆU({x∗})]}. By replacing the according
utilities, we have ˆ
SV ˜x∗=
1
2{E[g(˜x∗, x)] + E[ϵ] −E[g(˜x, x)] −E[ϵ] + E[g(˜x∗, x∗)] + E[ϵ] −"
MOTIVATION OF USING CONFOUNDER-FREE MODEL,0.14959016393442623,"E[g(˜x, x∗)] −E[ϵ]} = 1"
MOTIVATION OF USING CONFOUNDER-FREE MODEL,0.15163934426229508,"2{E[g(˜x∗, x)] −E[g(˜x, x)] + E[g(˜x∗, x∗)] −E[g(˜x, x∗)]} = SV
C
˜x∗."
MOTIVATION OF USING CONFOUNDER-FREE MODEL,0.15368852459016394,"The advantage of attribution based on ˆy lies in the term E[ϵ] being constant, thereby breaking the
association between ϵ and the input features."
MOTIVATION OF USING CONFOUNDER-FREE MODEL,0.1557377049180328,"Proposition 4. From the perspective of data generation, the contributions of features in ˜x and x to y
are equivalent to their contributions to ˆy. When using the condition expectation Shapley, intervention
Shapley, and Integrated Gradients (IG) methods, the attribution values of each feature in ˜x and x are
identical for both models f = g(˜x, x) and f = g(˜x, x) + E[ϵ]."
CONFOUNDER-FREE MODEL BUILDING,0.15778688524590165,"4.2
Confounder-free Model Building"
CONFOUNDER-FREE MODEL BUILDING,0.1598360655737705,"With Proposition 4, the problem becomes how to train the model f to fit E[ˆy|˜x, x] now. To achieve
this, we introduce the instrumental variables."
CONFOUNDER-FREE MODEL BUILDING,0.16188524590163936,"Instrumental Variable. The features that are used as instrumental variables, denoted as Ψ, can
be effectively utilized in our model if they satisfy the following three key properties. 1) relevance:
Ψ should correlate with ˜X, ensuring that Ψ can serve as a reliable proxy for these features. 2)
exogeneity: Ψ should be uncorrelated with the latent confounders E, ensuring that it is not influenced
by these unobserved factors. 3) exclusion restriction: Ψ should influence the outcome Y solely
through its effect on ˜X. In other words, apart from its interaction with ˜X, Ψ should not have any other
direct or indirect pathways affecting Y . This ensures that the effect of Ψ on Y can be unambiguously
attributed to its relationship with ˜X. The effectiveness of IV-SHAP and IV-IG may be reduced when
the three assumptions of instrumental variables are violated. However, the extent of this reduction
depends on how severely the assumptions are violated."
CONFOUNDER-FREE MODEL BUILDING,0.16393442622950818,"With the help of instrumental variables, we can establish the following equation by taking the
expectation of y given x and ψ,"
CONFOUNDER-FREE MODEL BUILDING,0.16598360655737704,"E[y|x, ψ] = E[g(˜x, x)|x, ψ] + E[ϵ] =
Z
g(˜x, x) + E[ϵ]dM(˜x|x, ψ),"
CONFOUNDER-FREE MODEL BUILDING,0.1680327868852459,"where ψ is a possible value of Ψ and dM(˜x|x, ψ) is the conditional distribution of ˜X. Given the T
training data instances, the optimal parameters of model f trained to fit g(˜x, x) + E[ϵ] within the
function space H are identified by minimizing the following objective:"
CONFOUNDER-FREE MODEL BUILDING,0.17008196721311475,"min
f∈H T
X"
CONFOUNDER-FREE MODEL BUILDING,0.1721311475409836,"t=1
L

yt −
Z
f (˜x, xt) dM (˜x|xt, ψt)

(2)"
CONFOUNDER-FREE MODEL BUILDING,0.17418032786885246,"where L represents the loss metric we used to evaluate model performance and t is the index of
specific data instance. We provide the training methods for supervised neural network models which
are extensively employed in the real world in Section 4.3. Specifically, we discuss their loss functions
and gradient computations when the objectives are regression and classification problems. The
training steps are inspired by the two-stage training in causal effect estimation [2] and counterfactual
prediction [18]. The re-estimated unconfounded values are sampled from the first-stage trained
model, the sampling has little influence on the implementation and computation complexity of the
second-stage model training. Therefore, the two-stage training process does not limit the method’s
practical usability. Due to the limited space, we provide details of model training with discrete input
features and non-gradient model training in appendix Section D."
CONFOUNDER-FREE MODEL TRAINING,0.1762295081967213,"4.3
Confounder-free Model Training"
CONFOUNDER-FREE MODEL TRAINING,0.17827868852459017,"Model Training for Continuous Feature Attribution. In the regression task, where the model f
is a neural network trained for forecasting continuous value, it is also denoted as fθ(˜x, x), where θ
represents the model parameters. As our objective, we adopt a l2 loss function. With the unknown
conditional distribution of ˜X given X and Ψ, we initially utilize a neural network model, denoted
ˆ
Mϕ, where ϕ is the model parameters, to approximate this distribution. The l2 loss function for
determining the optimal model parameters θ subsequently approximates as per the following equation"
CONFOUNDER-FREE MODEL TRAINING,0.18032786885245902,L(T; θ) = |T|−1 X t
CONFOUNDER-FREE MODEL TRAINING,0.18237704918032788,"
yt −
Z
fθ (˜x, xt) d ˆ
Mϕ (˜x | xt, ψt)
2
,
(3)"
CONFOUNDER-FREE MODEL TRAINING,0.18442622950819673,"where the integral term estimates the expected output of fθ under the distribution approximated by
ˆ
Mϕ. By employing the relevant calculations, we ascertain that the gradient of the loss function with
respect to the tth training data point is"
CONFOUNDER-FREE MODEL TRAINING,0.1864754098360656,"∇θLt = −2E ˆ
Mϕ(˜x|xt,ψt) [yt −fθ (˜x, xt)] · E ˆ
Mϕ(˜x|xt,ψt). [f ′
θ (˜x, xt)] .
(4)"
CONFOUNDER-FREE MODEL TRAINING,0.1885245901639344,"In short, our training process comprises two fundamental steps: 1) an instrumental variable method is
applied to re-estimate ˜x, mitigating the impact of unobservable confounders, and 2) this refined ˜x is
utilized to calculate the gradients for f."
CONFOUNDER-FREE MODEL TRAINING,0.19057377049180327,"Model Training for Discrete Feature Attribution. In the classification task, where y is a discrete
variable representing classes, we adapt the loss function to the multi-class cross-entropy"
CONFOUNDER-FREE MODEL TRAINING,0.19262295081967212,"L(T; θ) = |T|−1 X t R
X r=1"
CONFOUNDER-FREE MODEL TRAINING,0.19467213114754098,"Z
yt,r · ln fθ,r (˜x, xt)d ˆ
Mϕ (˜x | xt, ψt)

.
(5)"
CONFOUNDER-FREE MODEL TRAINING,0.19672131147540983,"In this formulation, yt,r represents the true label of the tth data point in the rth category. R denotes
the total number of distinct classes into which the target variable y can be classified. The probability
of the model classifying a data point into the rth category is given by fθ,r (˜x, xt). The gradient
calculation for the tth training data point, considering this loss function, is then"
CONFOUNDER-FREE MODEL TRAINING,0.1987704918032787,"∇θLt =E ˆ
Mϕ(˜x|xt,zt) "" R
X r=1"
CONFOUNDER-FREE MODEL TRAINING,0.20081967213114754,"yt,r
fθ,r (˜x, xt) · f ′
θ,r (˜x, xt) # .
(6)"
CONFOUNDER-FREE MODEL TRAINING,0.2028688524590164,"This adaptation of the loss function for discrete target variables ensures that our model can handle
classification tasks, effectively optimizing its performance across multiple categories."
CONFOUNDER-FREE MODEL TRAINING,0.20491803278688525,"Feature Attribution Computation. The exact computation of Shapley value and integrated gradients
needs huge cost while approximation methods are widely used. Towards practical applications, we
further propose a Shapley value approximation method and an integrated gradients approximation
method for saving computation costs in Sections E.1 and E.2, respectively. The correlation of input
features may affect the data-faithfulness of IV-SHAP and IV-IG. We can combine methods which
deal with the correlated input features to the two-stage model to better capture these correlations.
For example, on-manifold Shapley [26] can be used to account for feature correlations, while causal
Shapley [19] can be applied if the causal structure of the input features is known."
EXPERIMENTS,0.2069672131147541,"5
Experiments"
EXPERIMENTS,0.20901639344262296,"In this section, we present our empirical evaluation in detail. We employ synthetic and real-world
datasets to evaluate the faithfulness and robustness against unobservable confounders of feature
attributions given by our proposed data-faithful feature attribution methods to prevalent SHAP-based
and IG methods. Comparisons of feature attribution for classification problems, feature attribution
on non-gradient training models, and the approximation methods of SHAP and IG are given in
appendix Sections F.3, F.4, and F.5, respectively. Our code can be found in the repository at
https://github.com/ZJU-DIVER/IV-SHAP."
EXPERIMENTS ON SYNTHETIC DATASETS,0.21106557377049182,"5.1
Experiments on Synthetic Datasets"
EXPERIMENTS ON SYNTHETIC DATASETS,0.21311475409836064,"We first conducted a data simulation experiment to validate our proposed methods’ effectiveness.
Synthetic datasets offer an advantage in studying feature attribution, as we can obtain the ground
truth of attribution values according to the data generation equation which is unobtainable in most
real datasets."
EXPERIMENTS ON SYNTHETIC DATASETS,0.2151639344262295,"Dataset Generation Process. We generated two synthetic datasets, each containing four parts:
an unobserved confounder ϵ, a variable ˜x influenced by the unobserved confounder, collaborative
variables x = {xi} (1 ≤i ≤6), and the target feature y. Notably, dataset A and dataset B share the
same x and ψ. ϵ is formulated by a uniform variable v and a parameter ρ which controls the noise
level. The generation of these features adhered to specific functional relationships, as illustrated in"
EXPERIMENTS ON SYNTHETIC DATASETS,0.21721311475409835,"0.125
0.25
0.375
0.5"
EXPERIMENTS ON SYNTHETIC DATASETS,0.2192622950819672,"Feature
Deviation 0.0 0.1 0.2 0.3 0.4 0.5 Error ρ=0.2"
EXPERIMENTS ON SYNTHETIC DATASETS,0.22131147540983606,IV-BSHAP SHAP IV-IG IG
EXPERIMENTS ON SYNTHETIC DATASETS,0.22336065573770492,"0.125
0.25
0.375
0.5"
EXPERIMENTS ON SYNTHETIC DATASETS,0.22540983606557377,"Feature
Deviation 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 Error ρ=0.4"
EXPERIMENTS ON SYNTHETIC DATASETS,0.22745901639344263,IV-BSHAP SHAP IV-IG IG
EXPERIMENTS ON SYNTHETIC DATASETS,0.22950819672131148,"0.125
0.25
0.375
0.5"
EXPERIMENTS ON SYNTHETIC DATASETS,0.23155737704918034,"Feature
Deviation 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 Error ρ=0.6"
EXPERIMENTS ON SYNTHETIC DATASETS,0.2336065573770492,IV-BSHAP SHAP IV-IG IG
EXPERIMENTS ON SYNTHETIC DATASETS,0.23565573770491804,"0.125
0.25
0.375
0.5"
EXPERIMENTS ON SYNTHETIC DATASETS,0.23770491803278687,"Feature
Deviation 0.0 0.2 0.4 0.6 0.8 1.0 Error ρ=0.8"
EXPERIMENTS ON SYNTHETIC DATASETS,0.23975409836065573,IV-BSHAP SHAP IV-IG IG
EXPERIMENTS ON SYNTHETIC DATASETS,0.24180327868852458,"0.125
0.25
0.375
0.5"
EXPERIMENTS ON SYNTHETIC DATASETS,0.24385245901639344,"Feature
Deviation 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 Error ρ=1.0"
EXPERIMENTS ON SYNTHETIC DATASETS,0.2459016393442623,IV-BSHAP SHAP IV-IG IG
EXPERIMENTS ON SYNTHETIC DATASETS,0.24795081967213115,Figure 2: Evaluation results on synthetic Dataset A.
EXPERIMENTS ON SYNTHETIC DATASETS,0.25,"0.125
0.25
0.375
0.5"
EXPERIMENTS ON SYNTHETIC DATASETS,0.2520491803278688,"Feature
Deviation 0.00 0.05 0.10 0.15 0.20 Error ρ=0.2"
EXPERIMENTS ON SYNTHETIC DATASETS,0.2540983606557377,IV-BSHAP SHAP IV-IG IG
EXPERIMENTS ON SYNTHETIC DATASETS,0.25614754098360654,"0.125
0.25
0.375
0.5"
EXPERIMENTS ON SYNTHETIC DATASETS,0.2581967213114754,"Feature
Deviation 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 Error ρ=0.4"
EXPERIMENTS ON SYNTHETIC DATASETS,0.26024590163934425,IV-BSHAP SHAP IV-IG IG
EXPERIMENTS ON SYNTHETIC DATASETS,0.26229508196721313,"0.125
0.25
0.375
0.5"
EXPERIMENTS ON SYNTHETIC DATASETS,0.26434426229508196,"Feature
Deviation 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 Error ρ=0.6"
EXPERIMENTS ON SYNTHETIC DATASETS,0.26639344262295084,IV-BSHAP SHAP IV-IG IG
EXPERIMENTS ON SYNTHETIC DATASETS,0.26844262295081966,"0.125
0.25
0.375
0.5"
EXPERIMENTS ON SYNTHETIC DATASETS,0.27049180327868855,"Feature
Deviation 0.0 0.1 0.2 0.3 0.4 0.5 Error ρ=0.8"
EXPERIMENTS ON SYNTHETIC DATASETS,0.2725409836065574,IV-BSHAP SHAP IV-IG IG
EXPERIMENTS ON SYNTHETIC DATASETS,0.27459016393442626,"0.125
0.25
0.375
0.5"
EXPERIMENTS ON SYNTHETIC DATASETS,0.2766393442622951,"Feature
Deviation 0.0 0.1 0.2 0.3 0.4 0.5 Error ρ=1.0"
EXPERIMENTS ON SYNTHETIC DATASETS,0.2786885245901639,IV-BSHAP SHAP IV-IG IG
EXPERIMENTS ON SYNTHETIC DATASETS,0.2807377049180328,Figure 3: Evaluation results on synthetic Dataset B.
EXPERIMENTS ON SYNTHETIC DATASETS,0.2827868852459016,the equations below.
EXPERIMENTS ON SYNTHETIC DATASETS,0.2848360655737705,"v ∼Uniform(0, 1),
xi ∼Uniform(0, 1) (1 ≤i ≤6),
ψ ∼Uniform(0, 1),"
EXPERIMENTS ON SYNTHETIC DATASETS,0.28688524590163933,Dataset A
EXPERIMENTS ON SYNTHETIC DATASETS,0.2889344262295082,"




"
EXPERIMENTS ON SYNTHETIC DATASETS,0.29098360655737704,"



"
EXPERIMENTS ON SYNTHETIC DATASETS,0.2930327868852459,"ϵA = v · ρ,"
EXPERIMENTS ON SYNTHETIC DATASETS,0.29508196721311475,"˜xA =
p"
EXPERIMENTS ON SYNTHETIC DATASETS,0.29713114754098363,"ϵa · ψ + ϵA + ψ2
/3,"
EXPERIMENTS ON SYNTHETIC DATASETS,0.29918032786885246,"yA = ˜xA + x2
1 + x2 + √x3 + x2
4+x5+√x6"
EXPERIMENTS ON SYNTHETIC DATASETS,0.3012295081967213,"2
6
+ ϵA,"
EXPERIMENTS ON SYNTHETIC DATASETS,0.30327868852459017,Dataset B
EXPERIMENTS ON SYNTHETIC DATASETS,0.305327868852459,"






"
EXPERIMENTS ON SYNTHETIC DATASETS,0.3073770491803279,"





"
EXPERIMENTS ON SYNTHETIC DATASETS,0.3094262295081967,"ϵB = exp(v · ρ −1) ρ
,"
EXPERIMENTS ON SYNTHETIC DATASETS,0.3114754098360656,"˜xB =
p"
EXPERIMENTS ON SYNTHETIC DATASETS,0.3135245901639344,"ϵB · ψ + ϵB + ψ2
/3,"
EXPERIMENTS ON SYNTHETIC DATASETS,0.3155737704918033,yB = ˜xB · exp(x1) + x2 + √x3 + exp(x4)+x5+√x6
EXPERIMENTS ON SYNTHETIC DATASETS,0.3176229508196721,"2
6
+ ϵB."
EXPERIMENTS ON SYNTHETIC DATASETS,0.319672131147541,"Compared Methods. We utilized two representative feature attribution algorithms, SHAP [27]
and IG [38], as the baseline methods. Specifically, we trained a neural network model on synthetic
datasets to fit E[y|x] as the baseline model. Then we applied the two feature attribution methods to
attribute contributions for input features. For our proposed approach, we employed the same neural
network architecture but trained the model to fit E[ˆy|x] with instrumental variables. Our attribution
approaches, applied to the model trained with the instrumental variable, are referred to as IV-SHAP
and IV-IG, corresponding to SHAP and IG, respectively. It is worth noting that for the model, the
explicitly input data features have no causal relationships among them. Therefore, Causal SHAP [19],
Asymmetric SHAP [14], BSHAP [37] and SHAP are equivalent in this context."
EXPERIMENTS ON SYNTHETIC DATASETS,0.32172131147540983,"Experimental Results. We randomly generated 1000 data points based on the data generation
equations. We then adjusted features ˜x and x of each data point by subtracting a certain value as a
baseline input. We conducted experiments with varied subtracted values set at 0.125, 0.25, 0.375, and
0.5. For each data point, we applied IV-SHAP, IV-IG, SHAP, and IG to attribute the contributions of
the features. Subsequently, we compared the attribution values of feature ˜x against the ground truth
obtained directly from the data generation equations. We observe that the errors in attribution results
provided by IV-SHAP and IV-IG are significantly smaller than those of SHAP and IG. The absolute
errors in the attribution values of each algorithm for every data point, as compared to the benchmark,
are illustrated in Figures 2 and 3."
EXPERIMENTS ON REAL-WORLD DATASETS,0.3237704918032787,"5.2
Experiments on Real-world Datasets"
EXPERIMENTS ON REAL-WORLD DATASETS,0.32581967213114754,"We conducted experiments on two real-world datasets to demonstrate the efficacy of IV-SHAP and
IV-IG in practical scenarios where data generation processes are black-box. Initially, we excluded
specific features to simulate unobservable confounders. Subsequently, we trained a model using the
complete set of features to establish ground-truth attribution values, thereby assessing the robustness
and reliability of the compared methods under realistic conditions."
EXPERIMENTS ON REAL-WORLD DATASETS,0.32786885245901637,"Real-world Datasets. The first real dataset we used is the Griliches76 dataset [17, 36], consisting of
758 entries with 20 variables each, gathered from the U.S. labour market. This dataset is extensively
used in research to explore the impact of education on income. In the study examining the relationship
between the logarithm of weekly earnings (lw) and other features such as educational years (edu),
years of work experience (expr), tenure at the current organization (tenure), marital status (mr),
residence in the South (rns), and urban residence (smsa), there exists a significant challenge. Ability,
as an unobservable confounder, not only directly influences an individual’s education level but
also their income. Using feature attribution methods like SHAP and IG without accounting for the
confounder might incorrectly attribute the effect of ability on income to correlated educational levels.
To address this issue, we incorporated the educational years of the mother (medu) as an instrumental
variable to affect an individual’s education. Additionally, IQ scores (iq) and knowledge in the world
of work test (kww) in the dataset, serving as crucial indicators of ability, offer a unique opportunity
to approximate the ground truth of the real contribution of each feature."
EXPERIMENTS ON REAL-WORLD DATASETS,0.32991803278688525,"Compared Methods. We assume a decrease in educational years for each individual as baseline
inputs and execute a two-phase experiment. Initially, we omit IQ and the world of work test scores,
calculating attribution values for IV-SHAP, IV-IG, SHAP, and IG. Note that the process of computing
these attribution values using IV-SHAP, IV-IG, SHAP, and IG is consistent with the synthetic
dataset experiments. These methods are employed to evaluate the impact of reduced education
years. Subsequently, we incorporate IQ and the world of work test scores to train a new model and
recalculate attribution values using SHAP and IG. Due to the absence of a real-world benchmark
in the reality dataset, we adopt the attribution results from the model, which includes unobservable
confounders in its training process, as our benchmark for comparison."
EXPERIMENTS ON REAL-WORLD DATASETS,0.3319672131147541,"Evaluation Metric.
Denote the average attribution ratio of IV-SHAP by EARIVSHAP
=
1
n
Pn
i=1 | IVSHAPi"
EXPERIMENTS ON REAL-WORLD DATASETS,0.33401639344262296,"lwi
| where IVSHAPi refers to the educational attribution value for the ith data point,
calculated by the IV-SHAP method. IVSHAPi represents the extent to which changes in educational
years influence the income in the ith data point. lwi is the income for the ith data point. EARIVSHAP
is the average of the absolute values of the ratios between the educational attribution values and
income across all data points. This measure provides a comprehensive quantification of the impact
of educational years on income. The average attribution ratio for reduced educational years, cal-
culated by SHAP in the model trained with IQ and the world of work test scores, is denoted as
EARBMSHAP = 1"
EXPERIMENTS ON REAL-WORLD DATASETS,0.3360655737704918,"n
Pn
i=1 | BMSHAPi"
EXPERIMENTS ON REAL-WORLD DATASETS,0.33811475409836067,"lwi
| where BMSHAPi represents the benchmark attribution of educa-
tion on income, incorporating IQ and the world of work test. We then compute the absolute relative
error between the attributions of IV-SHAP and the benchmark using the formula | EARIVSHAP−EARBMSHAP"
EXPERIMENTS ON REAL-WORLD DATASETS,0.3401639344262295,"EARBMSHAP
|.
For the SHAP algorithm, EARBMSHAP still serve as a benchmark for EARSHAP. For the attribution
values calculated by IV-IG and IG, we use the average attribution ratio obtained by the IG algorithm
on the model that includes IQ and kww as inputs as the benchmark."
EXPERIMENTS ON REAL-WORLD DATASETS,0.3422131147540984,"Experimental Results. The experimental results are shown in Table 2, which demonstrates that our
methods can significantly reduce the attribution error. The values in the table represent the mean of
five independent runs, with the standard deviation following each mean."
EXPERIMENTS ON REAL-WORLD DATASETS,0.3442622950819672,Table 2: Relative error of each attribution algorithm.
EXPERIMENTS ON REAL-WORLD DATASETS,0.3463114754098361,"YEAR
1
2
3
4
5
SHAP
0.566 ± 0.041
0.569 ± 0.053
0.569 ± 0.040
0.548 ± 0.047
0.552 ± 0.038
IV-SHAP
0.184 ± 0.032
0.162 ± 0.026
0.172 ± 0.025
0.157 ± 0.019
0.146 ± 0.021
IG
0.554 ± 0.044
0.582 ± 0.052
0.583 ± 0.044
0.467 ± 0.047
0.538 ± 0.043
IV-IG
0.178 ± 0.025
0.152 ± 0.020
0.165 ± 0.028
0.149 ± 0.023
0.135 ± 0.017"
EXPERIMENTS ON REAL-WORLD DATASETS,0.3483606557377049,"Empirical Analysis. The second real dataset we use is the Angrist and Krueger dataset [3], which is
an American census dataset consisting of statistical data on people born in specific years, including
variables such as age (AGE), an education level (EDUC), weekly wage (LWKLYWGE), marital
status (MARRIED), and race (RACE). We employed this dataset to examine the confounder effects
of the ability on the attribution of education for income. In this dataset, we used the quarter of birth as
an instrumental variable for years of education. The rationale behind this is the compulsory education
laws in various states, which typically mandate schooling until the age of 16. Students born early
in the year often start school later, leading to systematic differences in educational duration based
on birth quarter. However, this dataset lacks measures of intelligence or work capability to assess
the factor of ability, so we cannot conduct the experiment like the previous one. Nevertheless, the
average attribution ratio of one additional year, calculated by SHAP, IV-SHAP, IG, and IV-IG, are
0.0218, 0.0206, 0.0218, and 0.0207, respectively. This aligns with the observation that people may
overestimate educational returns because of neglecting the confounder ability in [6]."
LIMITATIONS,0.35040983606557374,"6
Limitations"
LIMITATIONS,0.3524590163934426,"Despite the strengths of our approach, there are several limitations to consider which are shown as
follows:"
LIMITATIONS,0.35450819672131145,"• Dependence on the Availability of Instrumental Variables: Our approach assumes the
presence of suitable instrumental variables for features affected by unobserved confounders.
However, in practical scenarios, finding appropriate instrumental variables can be challeng-
ing sometimes. For further information on identifying instrumental variables, refer to works
such as [4], [10], and [23]."
LIMITATIONS,0.35655737704918034,"• Linearity Assumption in Theoretical Derivations: Our theoretical derivations are based
on the assumption that the influence of unobserved confounders on the target features is
linear. This assumption does not hold in all real-world situations. Nevertheless, in our
experiments with real datasets in Section 5.2, our attribution method showed significant
improvements over existing methods, even when the influence of unobservable confounders
on features was non-linear."
LIMITATIONS,0.35860655737704916,"These limitations highlight areas for future research, particularly in developing methods that do
not rely on the availability of instrumental variables and that can give theoretical analysis of non-
linear effects of unobserved confounders. Addressing these aspects can enhance the practicality and
applicability of our methods."
CONCLUSION,0.36065573770491804,"7
Conclusion"
CONCLUSION,0.36270491803278687,"In this paper, we focus on addressing the effects of unobservable confounders in feature attribution,
emphasizing feature attribution being faithful to data. The proposed method improves the under-
standing of the causal factors driving an outcome variable, going beyond standard attribution scores
that simply describe predictive models. Our approach of training confounder-free models using
instrumental variables effectively isolates the impact of confounders, enhancing the robustness of
data-faithful feature attribution results. Our validations using real and synthetic datasets confirm
the effectiveness of the proposed methods. For future work, we intend to develop methods that do
not rely on the availability of instrumental variables and that can provide a theoretical analysis of
the non-linear effects of unobserved confounders. For the broader impacts of the paper, please see
Section A in the appendix due to the limited space."
CONCLUSION,0.36475409836065575,Acknowledgment
CONCLUSION,0.3668032786885246,"The authors would like to thank the anonymous reviewers for their helpful comments. This work
was supported in part by the National Key RD Program of China (2021YFB3101100), NSFC
grants (62102352, U23A20306), The Zhejiang Province Pioneer Plan (2024C01074), and NSF grant
(CNS-2125530)."
REFERENCES,0.36885245901639346,References
REFERENCES,0.3709016393442623,"[1] N. Akhtar and M. A. Jalwana. Towards credible visual model interpretation with path attribution.
In International Conference on Machine Learning, pages 439–457. PMLR, 2023."
REFERENCES,0.3729508196721312,"[2] J. D. Angrist and G. W. Imbens. Two-stage least squares estimation of average causal effects
in models with variable treatment intensity. Journal of the American statistical Association,
90(430):431–442, 1995."
REFERENCES,0.375,"[3] J. D. Angrist and A. B. Krueger. The effect of age at school entry on educational attainment: an
application of instrumental variables with moments from two samples. Journal of the American
statistical Association, 87(418):328–336, 1992."
REFERENCES,0.3770491803278688,"[4] M. Baiocchi, J. Cheng, and D. S. Small. Instrumental variable methods for causal inference.
Statistics in medicine, 33(13):2297–2340, 2014."
REFERENCES,0.3790983606557377,"[5] S. Bordt and U. von Luxburg. From shapley values to generalized additive models and back. In
International Conference on Artificial Intelligence and Statistics, pages 709–745. PMLR, 2023."
REFERENCES,0.38114754098360654,"[6] D. Card. The causal effect of education on earnings. Handbook of labor economics, 3:1801–
1863, 1999."
REFERENCES,0.3831967213114754,"[7] J. Castro, D. Gómez, and J. Tejada. Polynomial calculation of the shapley value based on
sampling. Computers & Operations Research, 36(5):1726–1730, 2009."
REFERENCES,0.38524590163934425,"[8] H. Chen, I. C. Covert, S. M. Lundberg, and S.-I. Lee. Algorithms to estimate shapley value
feature attributions. Nature Machine Intelligence, 5(6):590–601, 2023."
REFERENCES,0.38729508196721313,"[9] H. Chen, J. D. Janizek, S. Lundberg, and S.-I. Lee. True to the model or true to the data? arXiv
preprint arXiv:2006.16234, 2020."
REFERENCES,0.38934426229508196,"[10] N. M. Davies, G. D. Smith, F. Windmeijer, and R. M. Martin. Issues in the reporting and
conduct of instrumental variable studies: a systematic review. Epidemiology, 24(3):363–369,
2013."
REFERENCES,0.39139344262295084,"[11] X. Deng and C. H. Papadimitriou. On the complexity of cooperative solution concepts. Math.
Oper. Res., 19(2):257–266, 1994."
REFERENCES,0.39344262295081966,"[12] R. Dwivedi, D. Dave, H. Naik, S. Singhal, R. Omer, P. Patel, B. Qian, Z. Wen, T. Shah,
G. Morgan, et al. Explainable ai (xai): Core ideas, techniques, and solutions. ACM Computing
Surveys, 55(9):1–33, 2023."
REFERENCES,0.39549180327868855,"[13] J. Enguehard. Sequential integrated gradients: a simple but effective method for explaining
language models. In Findings of the Association for Computational Linguistics: ACL 2023,
Toronto, Canada, July 9-14, 2023, pages 7555–7565. Association for Computational Linguistics,
2023."
REFERENCES,0.3975409836065574,"[14] C. Frye, C. Rowat, and I. Feige. Asymmetric shapley values: incorporating causal knowl-
edge into model-agnostic explainability. Advances in Neural Information Processing Systems,
33:1229–1239, 2020."
REFERENCES,0.39959016393442626,"[15] H. Gao, J. Li, W. Qiang, L. Si, B. Xu, C. Zheng, and F. Sun. Robust causal graph representation
learning against confounding effects. In Proceedings of the AAAI Conference on Artificial
Intelligence, volume 37, pages 7624–7632, 2023."
REFERENCES,0.4016393442622951,"[16] A. Ghorbani and J. Zou. Data shapley: Equitable valuation of data for machine learning. In
International conference on machine learning, pages 2242–2251. PMLR, 2019."
REFERENCES,0.4036885245901639,"[17] Z. Griliches. Wages of very young men. Journal of Political Economy, 84(4, Part 2):S69–S85,
1976."
REFERENCES,0.4057377049180328,"[18] J. Hartford, G. Lewis, K. Leyton-Brown, and M. Taddy. Deep iv: A flexible approach for
counterfactual prediction. In International Conference on Machine Learning, pages 1414–1423.
PMLR, 2017."
REFERENCES,0.4077868852459016,"[19] T. Heskes, E. Sijben, I. G. Bucur, and T. Claassen. Causal shapley values: Exploiting causal
knowledge to explain individual predictions of complex models. Advances in neural information
processing systems, 33:4778–4789, 2020."
REFERENCES,0.4098360655737705,"[20] N. Jethani, M. Sudarshan, I. Covert, S.-I. Lee, and R. Ranganath. Fastshap: Real-time shapley
value estimation. ICLR 2022, 2022."
REFERENCES,0.41188524590163933,"[21] Y. Jung, S. Kasiviswanathan, J. Tian, D. Janzing, P. Blöbaum, and E. Bareinboim. On measuring
causal contributions via do-interventions. In International Conference on Machine Learning,
pages 10476–10501. PMLR, 2022."
REFERENCES,0.4139344262295082,"[22] D. Kaltenpoth and J. Vreeken. Nonlinear causal discovery with latent confounders. In Interna-
tional Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA,
volume 202 of Proceedings of Machine Learning Research, pages 15639–15654. PMLR, 2023."
REFERENCES,0.41598360655737704,"[23] Y. Kawakami. Instrumental variable-based identification for causal effects using covariate
information. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-
Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh
Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event,
February 2-9, 2021, pages 12131–12138. AAAI Press, 2021."
REFERENCES,0.4180327868852459,"[24] Y. Kawakami, M. Kuroki, and J. Tian. Instrumental variable estimation of average partial
causal effects. In International Conference on Machine Learning, ICML 2023, 23-29 July 2023,
Honolulu, Hawaii, USA, volume 202 of Proceedings of Machine Learning Research, pages
16097–16130. PMLR, 2023."
REFERENCES,0.42008196721311475,"[25] R. Liu, C. Yin, and P. Zhang. Estimating individual treatment effects with time-varying
confounders. In 2020 IEEE International Conference on Data Mining (ICDM), pages 382–391.
IEEE, 2020."
REFERENCES,0.42213114754098363,"[26] S. M. Lundberg and S.-I. Lee. Consistent feature attribution for tree ensembles. arXiv preprint
arXiv:1706.06060, 2017."
REFERENCES,0.42418032786885246,"[27] S. M. Lundberg and S.-I. Lee. A unified approach to interpreting model predictions. Advances
in neural information processing systems, 30, 2017."
REFERENCES,0.4262295081967213,"[28] D. D. Lundstrom, T. Huang, and M. Razaviyayn. A rigorous study of integrated gradients
method and extensions to internal neuron attributions. In International Conference on Machine
Learning, pages 14485–14508. PMLR, 2022."
REFERENCES,0.42827868852459017,"[29] S. Maleki, L. Tran-Thanh, G. Hines, T. Rahwan, and A. Rogers. Bounding the estimation error
of sampling-based shapley value approximation with/without stratifying. CoRR, abs/1306.4265,
2013."
REFERENCES,0.430327868852459,"[30] J. Pearl. Causality. Cambridge university press, 2009."
REFERENCES,0.4323770491803279,"[31] M. T. Ribeiro, S. Singh, and C. Guestrin. "" why should i trust you?"" explaining the predictions of
any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge
discovery and data mining, pages 1135–1144, 2016."
REFERENCES,0.4344262295081967,"[32] L. S. Shapley. A value for n-person games. Contributions to the Theory of Games, 2(28):307–
317, 1953."
REFERENCES,0.4364754098360656,"[33] A. Shrikumar, P. Greenside, and A. Kundaje. Learning important features through propagating
activation differences. In International conference on machine learning, pages 3145–3153.
PMLR, 2017."
REFERENCES,0.4385245901639344,"[34] R. Singal, G. Michailidis, and H. Ng. Flow-based attribution in graphical models: A recursive
shapley approach. In International Conference on Machine Learning, pages 9733–9743. PMLR,
2021."
REFERENCES,0.4405737704918033,"[35] D. Smilkov, N. Thorat, B. Kim, F. Viégas, and M. Wattenberg. Smoothgrad: removing noise by
adding noise. arXiv preprint arXiv:1706.03825, 2017."
REFERENCES,0.4426229508196721,"[36] H. Stock and W. Watson.
Instructional stata datasets for econometrics.
Boston College
Department of Economics, 2003."
REFERENCES,0.444672131147541,"[37] M. Sundararajan and A. Najmi. The many shapley values for model explanation. In International
conference on machine learning, pages 9269–9278. PMLR, 2020."
REFERENCES,0.44672131147540983,"[38] M. Sundararajan, A. Taly, and Q. Yan. Axiomatic attribution for deep networks. In International
conference on machine learning, pages 3319–3328. PMLR, 2017."
REFERENCES,0.4487704918032787,"[39] Y. Tauman. The aumann-shapley prices: a survey. The shapley value, page 279, 1988."
REFERENCES,0.45081967213114754,"[40] J. Wang, J. Wiens, and S. Lundberg. Shapley flow: A graph-based approach to interpreting
model predictions. In International Conference on Artificial Intelligence and Statistics, pages
721–729. PMLR, 2021."
REFERENCES,0.45286885245901637,"[41] E. Winter. The shapley value. Handbook of game theory with economic applications, 3:2025–
2054, 2002."
REFERENCES,0.45491803278688525,"[42] A. Wu, K. Kuang, B. Li, and F. Wu. Instrumental variable regression with confounder balancing.
In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore,
Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 24056–
24075. PMLR, 2022."
REFERENCES,0.4569672131147541,"[43] Y. Xu, J. Zhu, C. Shi, S. Luo, and R. Song. An instrumental variable approach to confounded
off-policy evaluation. In Proceedings of the 40th International Conference on Machine Learning,
volume 202 of Proceedings of Machine Learning Research, pages 38848–38880. PMLR, 23–29
Jul 2023."
REFERENCES,0.45901639344262296,"[44] A. Zern, K. Broelemann, and G. Kasneci. Interventional shap values and interaction values
for piecewise linear regression trees. In Proceedings of the AAAI Conference on Artificial
Intelligence, volume 37, pages 11164–11173, 2023."
REFERENCES,0.4610655737704918,"[45] J. Zhang, D. Kumor, and E. Bareinboim. Causal imitation learning with unobserved confounders.
Advances in neural information processing systems, 33:12263–12274, 2020."
REFERENCES,0.46311475409836067,"[46] J. Zhang, Q. Sun, J. Liu, L. Xiong, J. Pei, and K. Ren. Efficient sampling approaches to shapley
value approximation. Proceedings of the ACM on Management of Data, 1(1):1–24, 2023."
REFERENCES,0.4651639344262295,"[47] J. Zhang, H. Xia, Q. Sun, J. Liu, L. Xiong, J. Pei, and K. Ren. Dynamic shapley value
computation.
In 39th IEEE International Conference on Data Engineering, ICDE 2023,
Anaheim, CA, USA, April 3-7, 2023, pages 639–652. IEEE, 2023."
REFERENCES,0.4672131147540984,Appendix
REFERENCES,0.4692622950819672,"In the appendix of our paper, we provide comprehensive additional content. We discuss the lbroader
impacts of the paper in Section A, respectively. Section B reviews the related works. In Section
D, we delve into the computation of gradients when dealing with discrete features and discuss
training methods for non-neural network models. Following this, Section E presents the algorithm
for computing Shapley values optimized using confidence intervals, along with an error analysis for
unbiased sampling in integrated gradients. Subsequently, Section F offers supplementary material
related to our experimental procedures. This includes a detailed analysis of the characteristics of
our experimental dataset, justifying our experimental design. Additional results from classification
experiments and non-neural network models are also provided."
REFERENCES,0.4713114754098361,"A
Broader Impacts"
REFERENCES,0.4733606557377049,"While we believe our paper has many positive social impacts, we think it can particularly affect:"
REFERENCES,0.47540983606557374,"• Fairness and Equity in Automated Systems: Reduces biases caused by unobservable
confounders in feature attribution, promoting fairness in systems like credit scoring and
hiring. This helps to build trust in these systems and supports fair decision-making in various
areas."
REFERENCES,0.4774590163934426,"• Improved Decision-Making in Healthcare: Our method enables more accurate identifica-
tion of factors affecting patient outcomes, leading to better diagnosis, treatment plans, and
personalized medicine. Healthcare professionals can make better decisions, which improves
patient care and outcomes."
REFERENCES,0.47950819672131145,We do not think our paper has any negative social impacts.
REFERENCES,0.48155737704918034,"B
Related Work"
REFERENCES,0.48360655737704916,"In this section, we first introduce seminal works that have a significant influence on the feature
attribution domain. This is followed by an exploration of works integrating causal knowledge into
feature attribution. Additionally, we introduce the widespread presence of confounders in machine
learning. Finally, we discuss advancements in computational optimization for SHAP-based methods.
For a more detailed survey of feature attribution, please see [12]."
REFERENCES,0.48565573770491804,"B.1
Classic Feature Attribution Techniques"
REFERENCES,0.48770491803278687,"LIME (Local Interpretable Model-agnostic Explanations) facilitates the understanding of individual
predictions of complex models by creating explanatory models [31]. It reveals the impact of features
on predictions by perturbing the input and observing the resultant changes in output. DeepLIFT
(Deep Learning Important FeaTures) offers a method for assessing feature importance in deep neural
networks by comparing the activation of each feature against a reference activation, proving particu-
larly effective in interpreting deep learning models [33]. SmoothGrad enhances visual interpretations
of gradient-based methods by applying multiple small random perturbations to the input data and aver-
aging the gradients of these perturbations [35]. Meanwhile, researchers have increasingly recognized
that for interpretability methods to be effective and credible, they need to satisfy axiomatic properties.
SHAP (SHapley Additive exPlanations) employs Shapley values from cooperative game theory to
measure feature contributions, offering a model-agnostic approach with broad applicability [27]. It
adheres to desirable allocation properties, ensuring both consistency and equity in attributing feature
influence on predictions. Meanwhile, Integrated Gradients (IG) calculates feature importance through
the integration of gradients along a straight path from a baseline to the input, making it ideal for
scenarios with continuous features and differentiable models [38]."
REFERENCES,0.48975409836065575,"B.2
Causal Feature Attribution Techniques"
REFERENCES,0.4918032786885246,"In the evolving field of feature attribution, the significance of causal relationships for data-faithful
interpretations is increasingly recognized [21]. Asymmetric Shapley values (ASVs) are developed"
REFERENCES,0.49385245901639346,"to infuse causal understanding into model explanations [14]. They achieve this by modifying the
symmetry axiom in the Shapley value framework, allowing for the inclusion of causal relationships.
Notably, ASVs can provide insights even without a complete causal graph. Causal Shapley values
stand out in their capacity to distinguish between direct and indirect feature impacts on model
predictions, offering a profound understanding of data generation [19]. Shapley Flow distinguishes
itself by evaluating the entire causal graph, attributing influence across its edges rather than focusing
solely on nodes [40]. Recursive Shapley Value (RSV) presents a specialized approach for graphical
models, quantifying the propagation of changes from source nodes throughout the graph [34].
However, despite the advancements made by these methods in considering the causal relationships
between model input features, these methods overlook the impact of unobservable confounders on
feature attribution."
REFERENCES,0.4959016393442623,"B.3
Confounders in Machine Learning"
REFERENCES,0.4979508196721312,"Researchers have recently begun exploring methods to identify and adjust for confounders in algo-
rithmic models to enhance decision-making quality [22, 42]. Gao et al. [15] identify that pre-trained
graph neural networks perform better on pruned graphs than on full graphs due to confounders and
introduce Robust Causal Graph Representation Learning (RCGRL) to effectively address this issue
by eliminating confounders. Zhang et al. [45] introduce a method for causal imitation learning in the
presence of unobservable confounders, featuring a graphical criterion to evaluate its feasibility despite
partially observed decision variables behind expert actions. Deep Sequential Weighting (DSW) is
proposed for estimating individual treatment effects in healthcare, accounting for time-varying hidden
confounders using deep learning [25]. In confounded sequential decision-making, Xu et al. [43]
study introduces an instrumental variable (IV) method for off-policy evaluation (OPE) to estimate
policy returns accurately in infinite horizon settings."
REFERENCES,0.5,"B.4
Approximation of SHAP-based Methods"
REFERENCES,0.5020491803278688,"TreeSHAP [26], for tree-based models, enhances SHAP value calculation efficiency by utilizing
tree structures to skip redundant feature combination evaluations. Dynamic Shapley, as discussed
in the paper by [47], focuses on dealing with scenarios where the players may change. Kernel
SHAP [27], suitable for various models, approximates SHAP values by sampling in the feature
space and assessing the impact of different feature combinations. Among the recent advancements in
optimizing SHAP computation are TMC (Truncated Monte Carlo) [16] and FastSHAP [20], each
offering unique approaches to enhance efficiency. TMC employs a truncation technique for rapid,
biased sampling approximations. FastSHAP is biased too, employing a pre-trained auxiliary model,
speeds up SHAP value prediction. Moreover, unlike methods that approximate Shapley values
through sampling, its ability to accurately estimate Shapley values does not improve with more
samples, as the precision of the auxiliary model is predetermined upon training. Recently, researchers
have proposed one Shapley value approximation method based on the complementary contribution
which can be adapted to the general class of feature attribution scenarios [46]."
REFERENCES,0.5040983606557377,"C
Proofs"
REFERENCES,0.5061475409836066,"C.1
Proof of Proposition 1"
REFERENCES,0.5081967213114754,"Proof. From the perspective of the data generation process for y, the marginal contribution of feature
i is exclusively linked to the function g. Thus, the marginal contribution of feature i in condition
expectation Shapley for the target feature generation is U
C(S ∪{i})−U
C(S) = E[g(˜x, x)|xS∪{i} =
xS∪{i}] −E[g(˜x, x)|xS = xS]. For the model trained to fit E[y|˜x, x], we have E[y|˜x, x] =
E[g(˜x, x)|˜x, x] + E[ϵ|˜x, x] = g(˜x, x) + E[ϵ|˜x]. Therefore, given explained input x, the marginal
contribution of a particular feature i with S in condition expectation Shapley derived with model f can
be represented as follows UC(S∪{i})−UC(S) = E[f(x)|xS∪{i} = xS∪{i}]−E[f(x)|xS = xS] =
E[g(˜x, x)|xS∪{i} = xS∪{i}] + E[e|xS∪{i} = xS∪{i}] −E[g(˜x, x)|xS = xS] −E[e|xS = xS].
Thus, the marginal contribution calculated by the model f which is trained to fit E[y|˜x, x] includes
an error term ED[ϵ|xS∪{i} = xS∪{i}] −E[ϵ|xS∪{i} = xS∪{i}], arises from the model’s reliance on
the correlations within features ˜X and E. By averaging the errors in the marginal contributions of"
REFERENCES,0.5102459016393442,"feature i with all possible cooperate coalitions, we can get the expected deviation of attribution value"
REFERENCES,0.5122950819672131,"by ∆SVi =
1
N
P"
REFERENCES,0.514344262295082,"S⊆N\{i}
 |N|−1
|S|
−1{ED[ϵ|xS∪{i} = x∗
S∪{i}] −E[ϵ|xS = x∗
S]}."
REFERENCES,0.5163934426229508,"C.2
Proof of Proposition 2"
REFERENCES,0.5184426229508197,"Proof. From the data generation perspective, the marginal contribution of feature i in intervention
Shapley for the target feature generation should be U
I(S ∪{i}) −U
I(S) = E[g(˜x, x)|do(xS∪{i} =
xS∪{i})] −E[g(˜x, x)|do(xS = xS)]. However, for the intervention Shapley, the marginal contribu-
tion derived with a model trained to fit E[y|˜x, x] is UI(S ∪{i}) −UI(S) = E[f(x)|do(xS∪{i} =
xS∪{i})] −E[f(x)|do(xS = xS)] = E[g(˜x, x)|do(xS∪{i} = xS∪{i})] + E[ϵ|do(xS∪{i} =
xS∪{i})] −E[g(˜x, x)|do(xS = xS)] −ED[ϵ|do(xS = xS)]. Thus, we have the expected error
for marginal contribution of feature i in intervention Shapley with mode f trained to fit E[y|x] is
ED[ϵ|do(xS∪{i} = x∗
S∪{i})] −ED[ϵ|do(xS = x∗
S)]. By averaging the errors in all the marginal con-
tributions of feature i with all possible cooperative coalitions, we can get the expected deviation of attri-"
REFERENCES,0.5204918032786885,"bution value by ∆SVi =
1
N
P"
REFERENCES,0.5225409836065574,"S⊆N\{i}
 |N |−1
|S|
−1{ED[ϵ|do(xS∪{i} = x∗
S∪{i})] −ED[ϵ|do(xS =
x∗
S)]}."
REFERENCES,0.5245901639344263,"C.3
Proof of Proposition 3"
REFERENCES,0.5266393442622951,"Proof. For IG, where ϵ is the unobservable confounder correlated with x, the derivative ∂f"
REFERENCES,0.5286885245901639,"∂x is likely
to incorporate the effect of ϵ on x, as it is trained to fit g(x) + ϵ. Consequently, the following
inequality typically holds ∂f"
REFERENCES,0.5307377049180327,"∂x ̸=
∂g
∂x. Therefore, the attribution IGi(x, x′, f) derived from the
predictive model f generally differs from the attribution IGi(x, x′, g) that should be obtained based
on the actual data generation process. When we accumulate the difference of ∂f"
REFERENCES,0.5327868852459017,∂x and ∂g
REFERENCES,0.5348360655737705,"∂x in the path,
we can get the error for attribution value of feature i using IG with model f trained to fit E[y|x] is"
REFERENCES,0.5368852459016393,"∆IGi = (x∗
i −x′
i)
R 1
α=0
∂f(x′+α(x∗−x′))"
REFERENCES,0.5389344262295082,"∂xi
−
∂g(x′+α(x∗−x′))"
REFERENCES,0.5409836065573771,"∂xi
dα."
REFERENCES,0.5430327868852459,"C.4
Proof of Proposition 4"
REFERENCES,0.5450819672131147,"Proof. The marginal contribution of a particular feature i with S in condition expectation Shapley de-
rived with model f = g(˜x, x) + E[ϵ] can be represented as follows UC(S ∪{i}) −UC(S) =
E[f(x)|xS∪{i} = xS∪{i}] −E[f(x)|xS = xS] = E[g(˜x, x)|xS∪{i} = xS∪{i}] + E[e] −
E[g(˜x, x)|xS = xS] −E[e] = E[g(˜x, x)|xS∪{i} = xS∪{i}] −E[g(˜x, x)|xS = xS]. Thus, the
attribution are identical for models f = g(˜x, x) and f = g(˜x, x) + E[ϵ] in condition expectation
Shapley."
REFERENCES,0.5471311475409836,"The marginal contribution derived with a model trained to fit f = g(˜x, x) + E[ϵ] is UI(S ∪{i}) −
UI(S) = E[f(x)|do(xS∪{i} = xS∪{i})] −E[f(x)|do(xS = xS)] = E[g(˜x, x)|do(xS∪{i} =
xS∪{i})] + E[ϵ] −E[g(˜x, x)|do(xS = xS)] −E[ϵ] = E[g(˜x, x)|do(xS∪{i} = xS∪{i})] −
E[g(˜x, x)|do(xS
= xS)]. Thus, the attribution are identical for models f
= g(˜x, x) and
f = g(˜x, x) + E[ϵ] in intervention Shapley."
REFERENCES,0.5491803278688525,The derivative ∂f
REFERENCES,0.5512295081967213,∂x = ∂g
REFERENCES,0.5532786885245902,"∂x holds when model f = g(x)+E[ϵ] as E[ϵ] is a constant. Thus, the attribution
are identical for models f = g(˜x, x) and f = g(˜x, x) + E[ϵ] in Integrated Gradients(IG)."
REFERENCES,0.555327868852459,"D
Discrete Confounded features and Gradient-Free Model Training"
REFERENCES,0.5573770491803278,"D.1
Training with Discrete Features"
REFERENCES,0.5594262295081968,"We extend our discussion to scenarios where the targets predicted by ˆ
Mϕ (˜x | xt, ψt) are discrete. In
cases where the prediction features P of ˆ
Mϕ are discrete, the fundamental approach to optimizing the
loss function L(T; θ) remains similar. The primary modification involves substituting the integral
over the probability distribution of P with a summation across discrete points. Assuming P has K"
REFERENCES,0.5614754098360656,"categories, and denoting the probability of the tth data point being classified into the kth category by
ˆ
Mϕ
 ˜xk | xt, zt

, the loss function when y is continuous is reformulated as:"
REFERENCES,0.5635245901639344,"L(T; θ) = |T|−1 X t  yt − K
X"
REFERENCES,0.5655737704918032,"k=1
ˆ
Mϕ
 ˜xk | xt, ψt

fθ
 ˜xk, xt

!2 .
(7)"
REFERENCES,0.5676229508196722,"For the tth training data point, the gradient of this loss function is:"
REFERENCES,0.569672131147541,"∇θLt = −2 "" yt − K
X"
REFERENCES,0.5717213114754098,"k=1
ˆ
Mϕ
 ˜xk | xt, ψt

fθ
 ˜xk, xt

# · "" K
X"
REFERENCES,0.5737704918032787,"k=1
ˆ
Mϕ
 ˜xk | xt, ψt

f ′
θ
 ˜xkxt

# . (8)"
REFERENCES,0.5758196721311475,"Furthermore, the gradients of a mini-batch comprising m training data tuples are computed as:"
REFERENCES,0.5778688524590164,"∇m
θ Lt ≡m−1 X t
−2 "" yt − K
X"
REFERENCES,0.5799180327868853,"k=1
ˆ
Mϕ

˜xk | xt, ψt

fθ

˜xk, xt
!# · "" K
X"
REFERENCES,0.5819672131147541,"k=1
ˆ
Mϕ

˜xk | xt, ψt

f ′
θ

˜xk, xt
# .
(9)"
REFERENCES,0.5840163934426229,"In situations where y is a discrete variable, representing categories or classes, the multi-class cross-
entropy can be formulated as:"
REFERENCES,0.5860655737704918,"L(T; θ) = |T|−1 X t R
X r K
X"
REFERENCES,0.5881147540983607,"k=1
ˆ
Mϕ
 ˜xk | xt, ψt

yt,r · ln fθ,r
 ˜xk, xt

(10)"
REFERENCES,0.5901639344262295,"In this formulation, yt,r represents the true label of the tth data point in the rth category. R denotes
the total number of distinct categories or classes into which the target variable y can be classified.
The model’s prediction for this category is given by fθ,r (˜x, xt). The gradient calculation for the tth
training data point, considering this loss function, is then:"
REFERENCES,0.5922131147540983,"∇θLt = R
X r=1 K
X"
REFERENCES,0.5942622950819673,"k=1
ˆ
Mϕ
 ˜xk | xt, ψt

yt,r
fθ,r (˜xk, xt) · f ′
θ,r
 ˜xk, xt

.
(11)"
REFERENCES,0.5963114754098361,"Furthermore, the gradients of a mini-batch comprising m training data tuples are computed as:"
REFERENCES,0.5983606557377049,"∇m
θ Lt ≡m−1 X t R
X r=1 K
X"
REFERENCES,0.6004098360655737,"k=1
ˆ
Mϕ
 ˜xk | xt, ψt

yt,r
fθ,r (˜xk, xt) · f ′
θ,r
 ˜xk, xt

.
(12)"
REFERENCES,0.6024590163934426,"This adaptation of the loss function for discrete target variables ensures that our model can handle
classification tasks, effectively optimizing its performance across multiple categories."
REFERENCES,0.6045081967213115,"D.2
Gradient-Free Model Training"
REFERENCES,0.6065573770491803,"When training models to fit ˆy in scenarios where gradient-based optimization is not feasible, we
introduce an alternative approach that effectively addresses the influence of confounding factors. The
essence of this approach lies in the generation of synthetic data, which is derived from the predicted
distribution of p. By sampling each original data point B times, we create B synthetic data points for
every original point. This process results in a synthetic dataset that embodies the controlled effects
of the confounders. The creation of this dataset is a vital step towards ensuring that the subsequent
model training is less influenced by confounding variables."
REFERENCES,0.6086065573770492,"A key advantage of this method is its independence from any specific model type. The generated
synthetic dataset can be utilized to train a variety of machine learning models, not limited to those that
rely on gradient-based optimization. This model-agnostic nature significantly widens the applicability
of our approach, making it suitable for various scenarios and models. Through this method, we ensure
that the training of models occurs in an environment where the impact of confounders is mitigated,
thereby enhancing the reliability of the feature attribution."
REFERENCES,0.610655737704918,"E
Supplement to SHAP and IG approximation"
REFERENCES,0.6127049180327869,"SHAP-based methods and IG-based methods can be applied to the proposed confounder-free models.
However, the computational complexity poses a significant barrier to real-world applications. The
exact computation of the Shapley value is proved to be an #P-hard problem [11], and the exact
computation of integrated gradients requires the antiderivative of the gradient, which is infeasible due
to their complexity, necessitating the use of approximation methods. The approximation cost of the
Shapley value is higher than the straightforward sampling in the path of integrated gradients due to
extensive feature subset evaluations. To further enhance the applicability, we develop optimizations
for the approximation of SHAP-based methods. Research has shown that Shapley values can be
represented not only based on marginal contributions but also complementary contributions, which
allows for reusing samples in estimations, offering an advantage [46]. We propose an enhanced
approach for SHAP-based methods, optimizing complementary contribution-based sampling using
confidence intervals. This optimization is designed to minimize estimation errors in all utility
functions within SHAP-based methods."
REFERENCES,0.6147540983606558,"E.1
Estimation Techniques for SHAP"
REFERENCES,0.6168032786885246,"Recent work [46] suggests that the Shapley value formula can be equivalently transformed into a
form expressed based on complementary contributions. Here, the complementary contribution refers
to the difference in utility between complementary subsets. The Shapley expression is given by"
REFERENCES,0.6188524590163934,"SVi =
1
|N| X"
REFERENCES,0.6209016393442623,S⊆N \{i}
REFERENCES,0.6229508196721312,"U(S ∪{i}) −U(S)
 |N |−1
|S|

(13) = 1 n X"
REFERENCES,0.625,S⊆N\{zi}
REFERENCES,0.6270491803278688,"U(S ∪{zi}) −U(N \ (S ∪{zi}))
 n−1
|S|

.
(14)"
REFERENCES,0.6290983606557377,"The formulas based on complementary contributions offer advantages in terms of sample reusability
during approximate computation. Building on this foundation, we propose a dynamic sampling
adjustment based on the confidence intervals of Shapley value estimates in stratified sampling."
REFERENCES,0.6311475409836066,"Denote by Si,j
N = {S ∪{zi}|S ⊆N \ {zi}, |S| = j −1} (1 ≤j ≤n) the set of (zi, j)-coalitions,
and by SVi,j the expected complementary contributions of (zi, j)-coalitions. That is,"
REFERENCES,0.6331967213114754,"SVi,j =
X"
REFERENCES,0.6352459016393442,"S∈Si,j
N"
REFERENCES,0.6372950819672131,"U(S) −U(N \ S)
 n−1
j−1

.
(15)"
REFERENCES,0.639344262295082,"Complementary contributions CC(S) = U(S ∪{zi}) −U(N \ (S ∪{zi})) are naturally stratified
into n strata Si,1
N , . . . , Si,n
N according to the coalition size. We start by deriving the confidence
interval of the estimator of SVi,j using t-test.
Lemma 5. According to the Central Limit Theorem, the sample mean approximates a normal
distribution when the sample size is sufficiently large. Assuming a confidence level of α, the confidence
interval for SVi,j based on the t-test is SVi,j ± Aα
Si,j
√mi,j , which can also be represented as"
REFERENCES,0.6413934426229508,"P(SVi,j −Aα
Si,j
√mi,j
< SVi,j < SVi,j + Aα
Si,j
√mi,j
) = α,
(16)"
REFERENCES,0.6434426229508197,"where Aα is the t-score corresponding to α, mi,j is the sample size of Si,j
N and Si,j is the sampling
variance of SVi,j."
REFERENCES,0.6454918032786885,"Denote by Sj
N = {S|S ⊆N, |S| = j} the set of j-coalitions (1 ≤j ≤n). After drawing a coalition
S from Sj
N , we can estimate the complementary contribution CCN (S), which can be used in SVi,j
for zi in S and SVi,n−j for zi in N \ S. In light of the fact that each sample can influence multiple
strata, how should we allocate the number of samples to optimize the precision of the estimated
values? We denote Ij
N as the sum of the confidence intervals for strata which can be influenced by a
random sample of Sj
N , that is"
REFERENCES,0.6475409836065574,"Ij
N = 2 ∗( N
X"
REFERENCES,0.6495901639344263,"i=1
Aα
Si,j
√mi,j
+ N
X"
REFERENCES,0.6516393442622951,"i=1
Aα
Si,n−j
√mi,n−j
).
(17)"
REFERENCES,0.6536885245901639,"For each sampling iteration, we select the stratum that maximizes the sum of the corresponding
confidence intervals."
REFERENCES,0.6557377049180327,"Next, we will outline the algorithmic procedure, which is divided into two primary stages. Due to
page limitations, the pseudo-code of the algorithm is presented in Algorithm 1 in the appendix. In
the first stage, we sample at least minit samples for SVi,j. We then compute unbiased estimations
of σ2
i,j using Bessel’s correction based on samples collected in the first stage. In the second stage,
the stratum for each individual sampling is determined based on the sum of confidence intervals
Ij
N (1 ≤j ≤n/2). Furthermore, this sum is updated upon the completion of each sampling.
Specifically, let CCN (S1 ∪{zi}), . . . , CCN (Smi,j ∪{zi}) be mi,j samples for computing SVi,j,"
REFERENCES,0.6577868852459017,"then d
σ2
i,j =
1
mi,j−1
Pmi,j
k=1 (CCN (Sk ∪{zi}) −
1
mi,j
Pmi,j
k=1 CCN (Sk ∪{zi})). Let mfirst be the
number of samples used in the first stage, and the number of remaining samples is m −mfirst. We
calculate Ij
N (1 ≤j ≤n/2) according to Equation (17) using the unbiased sample variance d
σ2
i,j.
We randomly sample from the stratum with the largest sum of confidence intervals. Following this
sampling, the sum of confidence intervals will be updated. We will continue to repeat this process
until all samples have been utilized. The final estimation of Shapley value is the average of all
complementary contribution means in each stratum."
REFERENCES,0.6598360655737705,"SHAP experiences an exponential increase in computational complexity with the addition of more
features. However, for IG, the increase in features does not significantly escalate the complexity
of the integral path. Therefore, in terms of efficiency in approximate computations, IG generally
outperforms SHAP. This makes IG a preferable choice in situations where computational complexity
for interpretability is a critical concern. However, it is important to note that SHAP, as a model-
agnostic method, is applicable for interpreting models that are not based on gradient optimization."
REFERENCES,0.6618852459016393,"Algorithm of SHAP Computation Based on the Confidence Interval. For the algorithm process
we propose, which utilizes confidence intervals to optimize the calculation of Shapley values, refer to
Algorithm 1. It is important to note that our algorithm is utility function-agnostic [29], meaning it can
be applied across various SHAP-based algorithm variants. This is achieved by simply substituting the
utility function defined by each method into our calculation. Furthermore, we provide an unbiased
proof of our method in Theorem 6.
Theorem 6. Given a set of players N = {z1, . . . , zn}, Algorithm 1 gives an unbiased estimation of
Shapley value for every player, that is, E[SVi] = SVi (1 ≤i ≤n)."
REFERENCES,0.6639344262295082,"Proof. Denote by CCN (S1), . . . , CCN (Smi,j) a sample of Si,j
N (1 ≤i, j ≤n) drawn by Algo-
rithm 1. The expectation of the sample SVi,j =
1
mi,j
Pmi,j
k=1 CCN (Sk). We can compute the"
REFERENCES,0.6659836065573771,"expectation of SVi,j with"
REFERENCES,0.6680327868852459,"E[SVi,j] = E[ 1 mi,j"
REFERENCES,0.6700819672131147,"mi,j
X"
REFERENCES,0.6721311475409836,"k=1
CCN (Sk)] =
1
mi,j"
REFERENCES,0.6741803278688525,"mi,j
X"
REFERENCES,0.6762295081967213,"k=1
E[CCN (Sk)]
(18)"
REFERENCES,0.6782786885245902,"According to Equation 15, E[CCN (Sk)] = SVi,j. Thus, E[SVi,j] = SVi,j that means SVi,j is an
unbiased estimation of SVi,j."
REFERENCES,0.680327868852459,"Then, we can compute the expectation of SVi produced by Algorithm 1. We have"
REFERENCES,0.6823770491803278,"E[SVi] = E[ 1 n n
X j=1"
REFERENCES,0.6844262295081968,"SVi,j] = 1 n n
X"
REFERENCES,0.6864754098360656,"j=1
E[SVi,j] = 1 n n
X"
REFERENCES,0.6885245901639344,"j=1
SVi,j = SVi.
(19)"
REFERENCES,0.6905737704918032,"That is, SVi is an unbiased estimation of SVi."
REFERENCES,0.6926229508196722,"E.2
Unbiased Integrated Gradients Approximation"
REFERENCES,0.694672131147541,"In existing literature related to Integrated Gradients (IG), interpolation methods are commonly used
for approximation [13], which already exhibit high efficiency compared to SHAP-like approximation
methods. In contrast, our paper introduces the use of Monte Carlo methods for the integration of
gradients. It’s important to clarify that the aim of proposing an unbiased estimate for IG is not"
REFERENCES,0.6967213114754098,Algorithm 1 Shapley value computation based on the confidence interval.
REFERENCES,0.6987704918032787,"Input: players N = {z1, . . . , zn}, minit > 1 , and m > 0
Output: approximate Shapley value SVi for each player zi (1 ≤i ≤n)
SVi, SVi,j, mi,j ←0 (1 ≤i ≤n);
c ←−1;
while c ̸= Pn
j=1 m1,j do
c = Pn
j=1 m1,j;
for i=1 to n, j = 1 to n do"
REFERENCES,0.7008196721311475,"if mi,j < minit then"
REFERENCES,0.7028688524590164,"let S be a sample drawn from Sj
N ;
u ←U(S) −U(N \ S);
for zi ∈S do"
REFERENCES,0.7049180327868853,"SVi,|S|+ = u; mi,|S|+ = 1;
end for
for zi ∈N \ S do"
REFERENCES,0.7069672131147541,"SVi,|N\S|−= u; mi,|N\S|+ = 1;
end for
end if
end for
end while
compute d
S2
i,j (1 ≤i, j ≤n);
mfirst ←Pn
j=1 m1,j;
for k = 0 to m −mfirst do"
REFERENCES,0.7090163934426229,for j=1 to n do
REFERENCES,0.7110655737704918,"Ij
N = 2 ∗(PN
i=1 Aα
Si,j
√mi,j + PN
i=1 Aα
Si,n−j
√mi,n−j );
end for
let S be a sample drawn from Sj
N where j corresponding to the stratum with the maximum Ij
N ;
u ←U(S) −U(N \ S);
for zi ∈S do"
REFERENCES,0.7131147540983607,"SVi,|S|+ = u; mi,|S|+ = 1;
end for
for zi ∈N \ S do"
REFERENCES,0.7151639344262295,"SVi,|N\S|−= u; mi,|N\S|+ = 1;
end for
update d
S2
i,j (1 ≤i, j ≤n);
end for
for i=1 to n do"
REFERENCES,0.7172131147540983,SVi = 1
REFERENCES,0.7192622950819673,"n
Pn
j=1 SVi,j/mi,j;
end for
return SV1, . . . , SVn."
REFERENCES,0.7213114754098361,"to optimize sampling efficiency but rather to provide an error analysis for the sampling process.
Our proposed approach not only provides an unbiased estimate of the integrated gradients but also
includes this crucial error analysis."
REFERENCES,0.7233606557377049,"Let u be a uniformly distributed random variable over the interval [0, 1], where"
REFERENCES,0.7254098360655737,"h(u) = (xi −x′
i)∂f (x′ + u (x −x′)) ∂xi
."
REFERENCES,0.7274590163934426,"Then, h(u) is an unbiased estimator of IGi(x, x′, f) due to"
REFERENCES,0.7295081967213115,"E[h(u)] = (xi −x′
i)
Z 1 u=0"
REFERENCES,0.7315573770491803,∂f (x′ + u (x −x′))
REFERENCES,0.7336065573770492,"∂xi
du = (xi −x′
i)
Z 1 α=0"
REFERENCES,0.735655737704918,∂f (x′ + α (x −x′))
REFERENCES,0.7377049180327869,"∂xi
dα. (20)"
REFERENCES,0.7397540983606558,"Next, we can obtain a more accurate unbiased estimate through the following steps: First, we generate
mi random samples u1, · · · , umi of u. Then, we sample h(u) based on these random numbers
to get an independent and identically distributed sample h(u1), · · · , h(umi). Finally, we use the
observed values of IGi(x, x′, f) =
1
mi
Pmi
i=1 h(ui) as the estimate for IGi(x, x′, f). The proof
that
1
mi
Pmi
i=1 h(ui) is an unbiased estimator of IGi(x, x′, f) is straightforward, due to the fact that
E[ 1"
REFERENCES,0.7418032786885246,"mi
Pmi
i=1 h(ui)] =
1
mi
Pmi
i=1 E[h(ui)] = IGi(x, x′, f)."
REFERENCES,0.7438524590163934,"Lemma 7. The probability that IGi(x, x′, f)(1 ≤i ≤n) deviates from IGi(x, x′, f) be equal to or
greater than any fixed ϵ ≥0 given the sample size mi is bounded by"
REFERENCES,0.7459016393442623,"P(|IGi(x, x′, f) −IGi(x, x′, f)| ≥ϵ|mi) ≤2 exp(−2miϵ2"
REFERENCES,0.7479508196721312,"r2
i,j
)
(21)"
REFERENCES,0.75,"where ri,j = maxu∈[0,1] h(u) −minu∈[0,1] h(u)."
REFERENCES,0.7520491803278688,"Proof. According to Hoeffding’s inequality, we have"
REFERENCES,0.7540983606557377,"P(|IGi(x, x′, f) −IGi(x, x′, f)| ≥ϵ|mi)
(22)"
REFERENCES,0.7561475409836066,"=P(|IGi(x, x′, f) −E[IGi(x, x′, f)]| ≥ϵ|mi)
(23) =P(| mi
X"
REFERENCES,0.7581967213114754,"i=1
h(ui) −E[ mi
X"
REFERENCES,0.7602459016393442,"i=1
h(ui)]| ≥miϵ|mi) ≤2 exp(−2miϵ2"
REFERENCES,0.7622950819672131,"r2
i,j
).
(24)"
REFERENCES,0.764344262295082,"F
Supplement to Experiments"
REFERENCES,0.7663934426229508,"F.1
Experiments Compute Resources"
REFERENCES,0.7684426229508197,"We conduct experiments on a machine with 2 Montage(R) Jintide(R) C6226R @ 2.90GHz and
256GB memory. Our experiments do not require high-end hardware, and our algorithm is not
time-consuming. For feature attribution experiments on synthetic datasets, each attribution algorithm
takes about 10 seconds to attribute one data point. Thus, an attribution algorithm takes several hours
to attribute an entire dataset. The time consumption on our real dataset is similar. Also, since our
algorithm uses very little memory, it is easy to run multiple processes and algorithms in parallel on a
machine, so the time cost for reproduction is friendly."
REFERENCES,0.7704918032786885,"F.2
Analysis of Experiment Design"
REFERENCES,0.7725409836065574,"Statistical Characteristics of the Synthetic Datasets. We present the mean and variance of each
feature in our synthetic datasets to provide crucial insights into their characteristics, as shown in Table
3. The mean offers an understanding of the average behaviour of features, while the variance indicates
their variability. This information is vital for assessing the data’s overall distribution and quality,
and it plays a key role in interpreting the results of our proposed methods and baseline algorithms."
REFERENCES,0.7745901639344263,Table 3: Mean and Std.Dev. of Features as a Function of ρ.
REFERENCES,0.7766393442622951,"ρ
0.2
0.4
0.6
0.8
1.0
ea
0.10 ± 0.05
0.20 ± 0.11
0.30 ± 0.17
0.40 ± 0.23
0.50 ± 0.28
ta
0.21 ± 0.12
0.27 ± 0.14
0.32 ± 0.17
0.37 ± 0.18
0.42 ± 0.21
ya
0.68 ± 0.18
0.87 ± 0.24
1.0 ± 0.31
1.15 ± 0.39
1.30 ± 0.47
eb
2.03 ± 0.12
1.12 ± 0.13
0.83 ± 0.15
0.69 ± 0.16
0.61 ± 0.18
tb
1.11 ± 0.21
0.72 ± 0.19
0.60 ± 0.18
0.53 ± 0.18
0.50 ± 0.18
yb
2.83 ± 0.25
1.65 ± 0.23
1.27 ± 0.24
1.09 ± 0.25
0.99 ± 0.27"
REFERENCES,0.7786885245901639,"These statistics help validate the synthetic data’s consistency and reliability, which is essential for the
credibility of our experimental findings."
REFERENCES,0.7807377049180327,"Statistical Characteristics of the Real Datasets. In the analysis of the Griliches76 dataset [36], we
observe various degrees of correlation between the mother’s years of education (denoted as med) and
several key variables. Firstly, the correlation coefficient between the mother’s education and marital
status (variables mrt and mrt80) is close to 0, indicating almost no correlation between the mother’s
level of education and her marital status. The correlation coefficients with urban residence status
(variables smsa and smsa80) are 0.098 and 0.031, respectively, suggesting a slight positive correlation.
This implies that there is a weak but positive association between the mother’s educational attainment
and living in an urban area. A moderate positive correlation is observed with IQ, as indicated by
a correlation coefficient of 0.226 with the mother’s education. This suggests that higher maternal
education is somewhat associated with higher IQ scores. Similarly, the correlation between the
mother’s education and scores in the world of work test is 0.195, which also reflects a moderate
positive correlation. This indicates that higher maternal education levels might be linked to better
performance in job-related knowledge. Most notably, the correlation coefficients with personal
education years (variables s and s80) are 0.340 and 0.341, respectively, indicating a relatively strong
positive correlation. This suggests that the mother’s level of education is considerably associated
with the individual’s own educational attainment. While there is a certain degree of correlation
between maternal education and both IQ and job knowledge test scores, factors like regression to the
mean in intelligence suggest that the correlation between a mother’s education and her child’s IQ is
weaker than the correlation between a mother’s education and the child’s own educational attainment.
Therefore, we posit that selecting maternal education as an instrumental variable, although not
perfectly ideal, still holds validity and can be utilized to verify our methodology."
REFERENCES,0.7827868852459017,"In the Angrist dataset, a child must be six years old within the current year to enroll in school under
the U.S. Compulsory Education Law. In the U.S., the school year typically starts in August, meaning
a child turning six in December can still commence their education in the same year. Consequently, a
child born in the fourth quarter, such as December, can start school before reaching six. Conversely, a
child born in the first quarter, like January, must wait until the autumn term after their sixth birthday
to begin school. U.S. law mandates students must be at least 16 years old to legally drop out of school.
Therefore, students dropping out at 16 may have varying years of education based on their birth
month. For instance, those born between 1920-1929 have average educational years of 11.39, 11.44,
11.55, and 11.57 for each quarter, respectively. Parents, when deciding to have children, seldom
consider such subtle differences in birth months. Thus, the month of a child’s birth, independent
of other factors affecting educational levels like intelligence, family background, and environment,
can be seen as a random assignment. This inadvertently creates variations in education duration
based on birth month – akin to a randomized controlled trial where children born in the fourth quarter
represent the ""experimental group"" with longer education, while those in the first quarter are the
""control group"" with shorter education. Hence, the birth quarter serves as an instrumental variable in
this context."
REFERENCES,0.7848360655737705,"F.3
Classification Task with DNN Model"
REFERENCES,0.7868852459016393,"In this experiment, we continued to utilize synthetic datasets a and b for a classification study. This
time, the labels were processed for binary classification. Specifically, we computed the probabilities
for data points being classified into category 1 by applying a sigmoid function to the y values in
the datasets; otherwise, the labels were assigned to category 0. Due to the inherent randomness in"
REFERENCES,0.7889344262295082,"generating labels, it was not feasible to directly determine a benchmark for each feature’s contribution
to the data classification."
REFERENCES,0.7909836065573771,"To validate the efficacy of our proposed method, we designed a comparative experiment based on
the symmetric properties of SHAP and IG. In this experiment, we set baseline inputs by reducing
the values of feature t and the collaborative variables c in each data point. The reduction followed a
specific rule: the decrease in t and the decrease in c should result in equivalent Shapley/IG values for
the change in y. Under this setup, the SHAP/IG values attributed to the classification into category 1
should be identical for both t and c. We assessed the effectiveness of our approach by comparing
the difference in SHAP/IG values for t and c between our method and baseline algorithms. The
results indicated that our approach significantly reduced errors compared to baseline algorithms.
This outcome suggests that even though t and c might have similar Shapley values in altering y,
the baseline training method may inaccurately estimate changes in latent confounders, leading to
different impacts of t and c on the final classification."
REFERENCES,0.7930327868852459,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.2 0.4 0.6 0.8 1.0 1.2 Error ρ=0.2"
REFERENCES,0.7950819672131147,"IV-BSHAP
SHAP
IV-IG
IG"
REFERENCES,0.7971311475409836,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 Error ρ=0.4"
REFERENCES,0.7991803278688525,"IV-BSHAP
SHAP
IV-IG
IG"
REFERENCES,0.8012295081967213,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.2 0.4 0.6 0.8 Error ρ=0.6"
REFERENCES,0.8032786885245902,"IV-BSHAP
SHAP
IV-IG
IG"
REFERENCES,0.805327868852459,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.2 0.4 0.6 0.8 1.0 Error ρ=0.8"
REFERENCES,0.8073770491803278,"IV-BSHAP
SHAP
IV-IG
IG"
REFERENCES,0.8094262295081968,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.2 0.4 0.6 0.8 1.0 1.2 Error ρ=1.0"
REFERENCES,0.8114754098360656,"IV-BSHAP
SHAP
IV-IG
IG"
REFERENCES,0.8135245901639344,Figure 4: Evaluation results on synthetic Dataset A with DNN Classifier.
REFERENCES,0.8155737704918032,"0.125
0.25
0.375
0.5
Feature Deviation 0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 Error ρ=0.2"
REFERENCES,0.8176229508196722,"IV-BSHAP
SHAP
IV-IG
IG"
REFERENCES,0.819672131147541,"0.125
0.25
0.375
0.5
Feature Deviation 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 Error ρ=0.4"
REFERENCES,0.8217213114754098,"IV-BSHAP
SHAP
IV-IG
IG"
REFERENCES,0.8237704918032787,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.2 0.4 0.6 0.8 Error ρ=0.6"
REFERENCES,0.8258196721311475,"IV-BSHAP
SHAP
IV-IG
IG"
REFERENCES,0.8278688524590164,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.1 0.2 0.3 0.4 0.5 Error ρ=0.8"
REFERENCES,0.8299180327868853,"IV-BSHAP
SHAP
IV-IG
IG"
REFERENCES,0.8319672131147541,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.2 0.4 0.6 0.8 1.0 1.2 Error ρ=1.0"
REFERENCES,0.8340163934426229,"IV-BSHAP
SHAP
IV-IG
IG"
REFERENCES,0.8360655737704918,Figure 5: Evaluation results on synthetic Dataset B with DNN Classifier.
REFERENCES,0.8381147540983607,"F.4
Regression Task with XGBoost Model"
REFERENCES,0.8401639344262295,"We opted for XGBoost as the representative of non-deep learning models for our experiments. As
gradient accumulation is not feasible on XGBoost, the Integrated Gradients (IG) algorithm cannot
be applied. Hence, our comparisons were primarily focused on SHAP-based algorithms. The
experimental results indicate that our method outperforms the baseline in most scenarios. When
the impact of the unobservable confounder is minimal, our method is less effective compared to
the baseline. This is considered reasonable, as there are inherent errors in training the model with
features re-estimated using instrumental variables. In such scenarios, the influence of these errors on
the model surpasses that of the unobservable confounder."
REFERENCES,0.8422131147540983,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.1 0.2 0.3 0.4 0.5 Error ρ=0.2"
REFERENCES,0.8442622950819673,"IV-BSHAP
SHAP"
REFERENCES,0.8463114754098361,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.1 0.2 0.3 0.4 0.5 Error ρ=0.4"
REFERENCES,0.8483606557377049,"IV-BSHAP
SHAP"
REFERENCES,0.8504098360655737,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.1 0.2 0.3 0.4 0.5 Error ρ=0.6"
REFERENCES,0.8524590163934426,"IV-BSHAP
SHAP"
REFERENCES,0.8545081967213115,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.1 0.2 0.3 0.4 0.5 0.6 Error ρ=0.8"
REFERENCES,0.8565573770491803,"IV-BSHAP
SHAP"
REFERENCES,0.8586065573770492,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Error ρ=1.0"
REFERENCES,0.860655737704918,"IV-BSHAP
SHAP"
REFERENCES,0.8627049180327869,Figure 6: Evaluation results on synthetic dataset a with XGBoost.
REFERENCES,0.8647540983606558,"F.5
Efficiency of Our Approximation Methods"
REFERENCES,0.8668032786885246,"We utilized widely-used algorithms MC (Monte Carlo, referring to the Monte Carlo sampling
method based on marginal contributions) [7], CC (Complementary Contribution, referring to the
stratified sampling method based on complementary contribution), and the state-of-the-art CCN"
REFERENCES,0.8688524590163934,"0.125
0.25
0.375
0.5
Feature Deviation 0.00 0.05 0.10 0.15 0.20 0.25 0.30 Error ρ=0.2"
REFERENCES,0.8709016393442623,"IV-BSHAP
SHAP"
REFERENCES,0.8729508196721312,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.1 0.2 0.3 0.4 Error ρ=0.4"
REFERENCES,0.875,"IV-BSHAP
SHAP"
REFERENCES,0.8770491803278688,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.1 0.2 0.3 0.4 Error ρ=0.6"
REFERENCES,0.8790983606557377,"IV-BSHAP
SHAP"
REFERENCES,0.8811475409836066,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.1 0.2 0.3 0.4 Error ρ=0.8"
REFERENCES,0.8831967213114754,"IV-BSHAP
SHAP"
REFERENCES,0.8852459016393442,"0.125
0.25
0.375
0.5
Feature Deviation 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 Error ρ=1.0"
REFERENCES,0.8872950819672131,"IV-BSHAP
SHAP"
REFERENCES,0.889344262295082,Figure 7: Evaluation results on synthetic dataset b with XGBoost.
REFERENCES,0.8913934426229508,Table 4: MSE of the SHAP values estimation.
REFERENCES,0.8934426229508197,"SAMPLES
56*100
56*200
56*300
56*400
56*500
MC
3.20E-5
1.74E-5
1.28E-5
9.81E-6
8.37E-6
CC
1.78E-5
9.45E-6
6.89E-6
5.37E-6
4.58E-6
CCN
1.76E-5
9.62E-6
6.71E-6
5.45E-6
4.96E-6
OURS
1.48E-5
8.66E-6
6.15E-6
4.92E-6
4.25E-6"
REFERENCES,0.8954918032786885,"(Complementary Contribution Neyman, referring to the sampling based on Neyman allocation with
complementary contribution) [46] as baseline methods for our experiment on the real-world Spambase
dataset. We chose the Spambase dataset for its larger number of features (56), compared to the
two other real datasets we previously used. This higher feature count offers a better testbed to
evaluate our proposed methods. It is worth noting that both our proposed method and these baseline
methods are unbiased sampling estimation approaches. We trained a regression neural network
model on a random selection of 1000 data points from this dataset. The efficiency of each method
was assessed by comparing the Mean Squared Error (MSE) of SHAP values against a benchmark
for the same number of samples. For this, we denoted the SHAP value of the jth feature for the
ith data point as SVi,j in the benchmark, and SVi,j in the estimation algorithm, with the MSE"
REFERENCES,0.8975409836065574,calculated using
REFERENCES,0.8995901639344263,"Pn
i=1
Pm
j=1(SVi,j−SVi,j)2"
REFERENCES,0.9016393442622951,"n∗m
, where n=1000 and m=56. Given that the computation of
exact SHAP values requires exponential time complexity, we used the results obtained from extensive
sampling via the CC method as our benchmark, involving 10,000×56 samples. These results served
as a specific benchmark, separate from the baseline CC method used earlier in the experiment for
comparative analysis. We then analyzed errors for sampling algorithms at various sample sizes,
ranging from 100×56 to 500×56. Our findings revealed a decrease in error for all algorithms as
sample size increased, with our method exhibiting the lowest error as shown in Table 4. This superior
performance is attributed to our method’s unique ability to estimate each stratum’s confidence interval
from sample variance during sampling."
REFERENCES,0.9036885245901639,NeurIPS Paper Checklist
CLAIMS,0.9057377049180327,1. Claims
CLAIMS,0.9077868852459017,"Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: The introduction of our paper clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations.
Guidelines:"
CLAIMS,0.9098360655737705,"• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2. Limitations"
CLAIMS,0.9118852459016393,"Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: Please see Section 6.
Guidelines:"
CLAIMS,0.9139344262295082,"• The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ""Limitations"" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3. Theory Assumptions and Proofs"
CLAIMS,0.9159836065573771,"Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: We provide the full set of assumptions and a complete (and correct) proof.
Guidelines:"
CLAIMS,0.9180327868852459,"• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4. Experimental Result Reproducibility"
CLAIMS,0.9200819672131147,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: The experiments sections (Section 5 and F in the appendix) provided in the
paper disclose all the information needed to reproduce the main experimental results."
CLAIMS,0.9221311475409836,Guidelines:
CLAIMS,0.9241803278688525,"• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5. Open access to data and code"
CLAIMS,0.9262295081967213,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification:
Our code can be found in the repository at https://github.com/
ZJU-DIVER/IV-SHAP.
Guidelines:"
CLAIMS,0.9282786885245902,"• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why."
CLAIMS,0.930327868852459,"• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted."
CLAIMS,0.9323770491803278,6. Experimental Setting/Details
CLAIMS,0.9344262295081968,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?"
CLAIMS,0.9364754098360656,Answer: [Yes]
CLAIMS,0.9385245901639344,Justification: The full details are provided with the code.
CLAIMS,0.9405737704918032,Guidelines:
CLAIMS,0.9426229508196722,"• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.944672131147541,7. Experiment Statistical Significance
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9467213114754098,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9487704918032787,Answer: [Yes]
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9508196721311475,"Justification: For the results on synthetic datasets, we used bar charts, which effectively
demonstrate the stability of the experimental results. For the experimental results presented
in tabular format, we included the standard deviation to show statistical significance."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9528688524590164,Guidelines:
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9549180327868853,"• The answer NA means that the paper does not include experiments.
• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text."
EXPERIMENTS COMPUTE RESOURCES,0.9569672131147541,8. Experiments Compute Resources
EXPERIMENTS COMPUTE RESOURCES,0.9590163934426229,"Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?"
EXPERIMENTS COMPUTE RESOURCES,0.9610655737704918,Answer: [Yes]
EXPERIMENTS COMPUTE RESOURCES,0.9631147540983607,"Justification: Please see Section F.1 in the appendix for the information of computer re-
sources."
EXPERIMENTS COMPUTE RESOURCES,0.9651639344262295,Guidelines:
EXPERIMENTS COMPUTE RESOURCES,0.9672131147540983,"• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9. Code Of Ethics"
EXPERIMENTS COMPUTE RESOURCES,0.9692622950819673,"Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
Answer: [Yes]
Justification: We have thoroughly reviewed the NeurIPS Code of Ethics and confirm that
our research conforms to it in every respect.
Guidelines:"
EXPERIMENTS COMPUTE RESOURCES,0.9713114754098361,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10. Broader Impacts"
EXPERIMENTS COMPUTE RESOURCES,0.9733606557377049,"Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: Please see Section A in the appendix for societal impacts.
Guidelines:"
EXPERIMENTS COMPUTE RESOURCES,0.9754098360655737,"• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11. Safeguards"
EXPERIMENTS COMPUTE RESOURCES,0.9774590163934426,"Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?"
EXPERIMENTS COMPUTE RESOURCES,0.9795081967213115,"Answer: [NA]
Justification: The paper does not pose such risks.
Guidelines:"
EXPERIMENTS COMPUTE RESOURCES,0.9815573770491803,"• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12. Licenses for existing assets"
EXPERIMENTS COMPUTE RESOURCES,0.9836065573770492,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We have properly cited the original papers that produced the real datasets used
in the paper.
Guidelines:"
EXPERIMENTS COMPUTE RESOURCES,0.985655737704918,"• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
• If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13. New Assets"
EXPERIMENTS COMPUTE RESOURCES,0.9877049180327869,"Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [Yes]
Justification: The paper introduces new code assets, which are well documented. The
documentation includes details about the usage, the limitations, and the corresponding
license.
Guidelines:"
EXPERIMENTS COMPUTE RESOURCES,0.9897540983606558,"• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used.
• At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9918032786885246,14. Crowdsourcing and Research with Human Subjects
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9938524590163934,"Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer:[NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
We used two real-world datasets that contain information about education and income
collected from the market, which are anonymized and do not involve direct human sub-
jects research. Therefore, the requirements for providing instructions, screenshots, and
compensation details do not apply.
Guidelines:"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9959016393442623,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: The paper uses two real-world datasets that contain information about edu-
cation and income collected from the market. These datasets are anonymized and do not
involve direct human subjects research. Therefore, IRB approval is not required.
Guidelines:"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9979508196721312,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review."
