Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0007930214115781126,"Deep neural networks (DNNs) have revealed severe vulnerability to adversarial
perturbations, besides empirical adversarial training for robustness, the design of
provably robust classiﬁers attracts more and more attention. Randomized smooth-
ing method provides the certiﬁed robustness with agnostic architecture, which is
further extended to a provable robustness framework using f-divergence. While
these methods cannot be applied to smoothing measures with bounded support
sets such as uniform probability measures due to the use of likelihood ratio in
their certiﬁcation methods. In this paper, we introduce a framework that is able to
deal with robustness properties of arbitrary smoothing measures including those
with bounded support set, by using Wasserstein distance as well as total vari-
ation distance. By applying our methodology to uniform probability measures
with support set B2(O, r), we obtain certiﬁed robustness properties concerning
lp-perturbations. And by applying to uniform probability measures with support
set B∞(O, r), we obtain certiﬁed robustness properties with respect to l1, l2, l∞-
perturbations. We present experimental results on CIFAR-10 dataset with ResNet
to validate our theory. It is worth mentioning that our certiﬁcation procedure only
costs constant computation time, which is an improvement upon the state-of-the-
art methods in terms of the computation time."
INTRODUCTION,0.0015860428231562252,"1
INTRODUCTION"
INTRODUCTION,0.0023790642347343376,"Vulnerability to adversarial samples is a major obstacle that various classiﬁers obtained by machine
learning algorithms, especially deep neural networks (DNNs), need to overcome (Szegedy et al.,
2013; Nguyen et al., 2015). For instance, in computer vision applications, deliberately adding some
subtle perturbation δ that humans cannot perceive to the input image x will cause DNNs to give a
wrong classiﬁcation output with high probability. Many empirical adversarial defenses have been
proposed, among which adversarial training (Madry et al., 2018) is the most effective one (Athalye
et al., 2018), however, it still faces stronger or adaptive attacks to decrease its effectiveness to a
certain degree (Croce & Hein, 2020). This motivates research on certiﬁed robustness: algorithms
that are provably robust to the worst-case attacks."
INTRODUCTION,0.0031720856463124504,"Some works propose algorithms to learn DNNs that are provably robust against norm-bounded ad-
versarial perturbations by using some convex relaxation methods (Wong & Kolter, 2018; Weng et al.,
2018; Xiao et al., 2018; Zhang et al., 2019). However, these approaches are usually computationally
expensive and require extensive knowledge of classiﬁer architecture. Besides, randomized smooth-
ing (ﬁrst introduced in Cohen et al. (2019)) has received signiﬁcant attention in recent years for
verifying the robustness of classiﬁers. Based on this method, several papers have studied which
smoothing strategies perform better for speciﬁc lp perturbations. Cohen et al. (2019) concludes that
randomized smoothing can be well understood for the l2 case by using Gaussian probability measure
for smoothing. It follows that several special cases of the conjecture have been proven for p < 2. Li
et al. (2018) show that l1 robustness can be achieved with the Laplacian distribution, and Lee et al.
(2019) show that l0 robustness can be achieved with a discrete distribution. Other papers start from
the opposite perspective and focus on studying under speciﬁc assumptions which perturbation is
provably difﬁcult to handle and which smoothing methods are ineffective for particular disturbance.
As for the existence of a noise distribution that works for the case of p > 2, Blum et al. (2020)
and Kumar et al. (2020) show hardness results for random smoothing to achieve certiﬁed adversarial
robustness against attacks in the lp ball of radius ϵ. Nevertheless, since these works provide hard-
ness results for every possible base classiﬁer f : Rd →Y including those unusual and even bizarre
ones, hardness results given by these papers might be attributed to taking into account classiﬁers that"
INTRODUCTION,0.003965107057890563,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.004758128469468675,"will never appear in real-world applications. From this perspective, the order of difﬁculty restricted
within the common classiﬁers subset still remains unresolved."
INTRODUCTION,0.0055511498810467885,"Notably, based on randomized smoothing strategy, Dvijotham et al. (2020) introduce a provable ro-
bustness framework using f-divergence as their convex relaxation technique. However, due to the
use of likelihood ratio in their certiﬁcation methods, the framework cannot be applied to smoothing
measures with bounded support sets such as uniform probability measures. In this paper, we intro-
duce a framework that is able to deal with robustness properties of arbitrary smoothing measures,
including those with bounded support set, by using Wasserstein distance as well as total variation
distance. Our contributions are summarized as follows:"
INTRODUCTION,0.006344171292624901,"• By applying our methodology to uniform probability measures with support set B2(O, r),
we obtain certiﬁed robustness properties with respect to lp-perturbations. By applying
our methodology to uniform probability measures with support set B∞(O, r), we obtain
certiﬁed robustness properties with respect to l1, l2, l∞-perturbations.
• Furthermore, we analyze the cases when smoothing measure is taken as uniform proba-
bility measure with more general support set Bp(O, r) and show the unavoidable curse of
dimension for the usage of bounded support set smoothing measures.
• We present experimental results on CIFAR-10 dataset with ResNet to validate our theory. It
is worth mentioning that our certiﬁcation procedure only costs constant computation time,
which is an improvement upon the state-of-the-art methods in terms of the computation
time."
PROBLEM SETTING,0.007137192704203013,"2
PROBLEM SETTING"
PROBLEM SETTING,0.007930214115781126,"Given a binary base classiﬁer h : Rd →Y = {±1} and smoothing probability measure µ, the
randomly smoothed classiﬁer hµ(x) is deﬁned as follows.
Deﬁnition 1 (smoothed classiﬁer, smoothing measure). The smoothed version of a base binary
classiﬁer h producing labels in set Y = {±1} is deﬁned as"
PROBLEM SETTING,0.008723235527359239,"hµ(x) = arg max
y∈Y PX∼x+µ[h(X) = y],
(1)"
PROBLEM SETTING,0.00951625693893735,where µ ∈P(X) is called smoothing measure.
PROBLEM SETTING,0.010309278350515464,"Another way to understand this deﬁnition is to say that the smoothed classiﬁer ﬁrst scores point x
as hµ,y(x) = PX∼x+µ[h(X) = y] for each speciﬁc class y ∈Y and then outputs the class y∗with
the highest score. We want to study the robustness of the smoothed classiﬁer hµ against adversarial
perturbations of size at most ϵ with respect to a given norm || · ||p. The question that whether a
bounded lp norm adversarial attack on a ﬁxed input x satisfying hµ(x) = +1 is successful or not
can be formulated as solving the optimization problem below:"
PROBLEM SETTING,0.011102299762093577,"min
||x′−x||p≤ϵ PX∼x′+µ[h(X) = +1].
(2)"
PROBLEM SETTING,0.011895321173671689,The attack is successful if and only if the minimum value is smaller than 1
SINCE WE KNOW LITTLE,0.012688342585249802,"2. Since we know little
about the information of the black-box classiﬁer h, we follow the approach introduced in Dvijotham
et al. (2020): rather than studying the adversarial attack in the input space X, we study it in the space
of probability measures deﬁned on input space P(X),"
SINCE WE KNOW LITTLE,0.013481363996827915,"min
||x′−x||≤ϵ PX∼x′+µ[h(X) = +1] =
min
ν∈Dx,ϵ,q PX∼ν[h(X) = +1],
(3)"
SINCE WE KNOW LITTLE,0.014274385408406027,"where Dx,ϵ,q := {x′ + µ : ||x −x′||q ≤ϵ} represents an lq-norm-based constraint set of radius ϵ for
smoothing measure µ centered at a particular sample point x. Then, we follow the full-information
robust certiﬁcation framework established in Dvijotham et al. (2020) and analyze the generalization
of binary classiﬁer h, which they called speciﬁcation and denote it as φ : X ⊆Rd →Z ⊆R.
Besides, deﬁne reference measure ρ as x + µ and a collection of perturbed probability measures
D ⊆P(X). Checking whether a given speciﬁcation φ is robustly certiﬁed at ρ with respect to D or
not is equivalent to estimating the optimal value of following optimization problem is non-negative
or not:
OPT(φ, ρ, D) := min
ν∈D EX∼ν[φ(X)].
(4)"
SINCE WE KNOW LITTLE,0.01506740681998414,"And certifying lp robustness on input x with output of smoothed classiﬁer hµ(x) = +1 is equivalent
to verify whether OPT(h, x + µ, Dx,ϵ,q) ≥0 or not."
SINCE WE KNOW LITTLE,0.01586042823156225,Under review as a conference paper at ICLR 2022
OUR CERTIFICATION PROCEDURES,0.016653449643140365,"3
OUR CERTIFICATION PROCEDURES"
OUR CERTIFICATION PROCEDURES,0.017446471054718478,Notice that the certiﬁcation in Dvijotham et al. (2020) uses the likelihood ratio r(X) = ν(X)
OUR CERTIFICATION PROCEDURES,0.01823949246629659,"ρ(X), while
r(X) is well-deﬁned only when the support set of ρ contains the support set of ν. Thus, when the
support set of reference measure ρ is bounded, and ν takes even a small translation of ρ, the support
set of ν will cross over the boundary of support set of ρ. Their certiﬁcation is invalid in this case.
In this paper, by using Wasserstein distance as well as total variance distance, we provide analytical
techniques able to analyze bounded support set which is not covered by Dvijotham et al. (2020)."
OUR CERTIFICATION PROCEDURES,0.0190325138778747,"Since the set of measures Dx,ϵ,q constraint in optimization problem OPT(h, x + µ, Dx,ϵ,q) is in-
tractable to deal with, we consider relaxations of this by using Wasserstein distance as well as total
variance distance constraints between ν and x + µ, i.e. Dx,ϵ,q ⊆{ν : Wp(x + µ, ν) ≤δ} := Dx,δ,p
which represents Wp-distance-based constraint set of radius δ for smoothing measure µ centered at
sample point x and D ⊆{ν : TV (x + µ, ν) ≤ξ} := Dx,ξ which represents TV-distance-based
constraint set of radius ξ for smoothing measure µ centered at sample point x. Combining the two
relaxations, we know Dx,ϵ,q ⊆Dx,δ,p ∩Dx,ξ and therefore"
OUR CERTIFICATION PROCEDURES,0.019825535289452814,"OPT(h, x + µ, Dx,ϵ,q) ≥OPT(h, x + µ, Dx,δ,p ∩Dx,ξ).
(5)"
OUR CERTIFICATION PROCEDURES,0.020618556701030927,"And we can obtain tighter relaxation by combining multiple Wasserstein distance relaxation with
different p, i.e. Dx,ϵ,q ⊆
  T"
OUR CERTIFICATION PROCEDURES,0.02141157811260904,"i∈I Dx,δi,pi

∩Dx,ξ where I ⊆R+ and therefore"
OUR CERTIFICATION PROCEDURES,0.022204599524187154,"OPT(h, x + µ, Dx,ϵ,q) ≥OPT

h, x + µ,
  \"
OUR CERTIFICATION PROCEDURES,0.022997620935765267,"i∈I
Dx,δi,pi

∩Dx,ξ

.
(6)"
OUR CERTIFICATION PROCEDURES,0.023790642347343377,"Thus, for a ﬁxed input x, it sufﬁces to consider the Wasserstein distance and total variance distance
relaxed problem and verify whether OPT(h, x + µ, Dx,δ,p ∩Dx,ξ) ≥0 or not. The analysis of this
problem can be divided into three parts: computing the Wasserstein distance relaxation measure set,
computing the total variance distance relaxation measure set, and computing the Lagrange function
as well as dual problem of the relaxed optimization problem OPT(h, x + µ, Dx,δ,p ∩Dx,ξ). The
details are discussed in the following three sections."
RELAXATION USING WASSERSTEIN DISTANCE,0.02458366375892149,"3.1
RELAXATION USING WASSERSTEIN DISTANCE"
RELAXATION USING WASSERSTEIN DISTANCE,0.025376685170499604,"In this section, we show the following relaxation from norm-based constraint sets into W-distance-
based constraint sets for general smoothing measures as well as Gaussian smoothing measure."
RELAXATION USING WASSERSTEIN DISTANCE,0.026169706582077717,"Dx,ϵ,q = {x′ + µ : ||x −x′||q ≤ϵ} ⊆{ν : Wp(x + µ, ν) ≤δ} = Dx,δ,p.
(7)"
GENERAL PROBABILITY MEASURE,0.02696272799365583,"3.1.1
GENERAL PROBABILITY MEASURE"
GENERAL PROBABILITY MEASURE,0.02775574940523394,"Here, we want to ﬁnd a δq(ϵ) such that"
GENERAL PROBABILITY MEASURE,0.028548770816812053,"Dx,ϵ,q = {x′ + µ : ||x −x′||q ≤ϵ} ⊆{ν : Wp(x + µ, ν) ≤δq(ϵ)} = Dx,δq(ϵ),p for all µ ∈P(X).
(8)
Theorem 3.1. For all x ∈Rd, ϵ > 0, q > 0, norm-based constraint set Dx,ϵ,q can be relaxed
into W-distance-based constraint set Dx,δq(ϵ),p with radius δq(ϵ) = max{ϵ, ϵd
1
2 −1"
GENERAL PROBABILITY MEASURE,0.029341792228390166,"q } which can be
formulated as"
GENERAL PROBABILITY MEASURE,0.03013481363996828,"Dx,ϵ,q ⊆

ν : Wp(x + µ, ν) ≤max{ϵ, ϵd
1
2 −1"
GENERAL PROBABILITY MEASURE,0.030927835051546393,"q }
	
:= D
x,max{ϵ,ϵd
1
2 −1"
GENERAL PROBABILITY MEASURE,0.0317208564631245,"q },p
(9)"
GENERAL PROBABILITY MEASURE,0.03251387787470262,"And this relaxation radius max{ϵ, ϵd
1
2 −1"
GENERAL PROBABILITY MEASURE,0.03330689928628073,"q } works for any Wasserstein distance parameter p > 0 as
well as any smoothing measure µ."
GENERAL PROBABILITY MEASURE,0.03409992069785884,"Note that for lq(q ≤2) adversarial perturbations, the relaxed radius avoids the inﬂuence of dimen-
sion d, whereas for lq(q > 2) adversarial perturbations, as q increases, 1 2 −1"
GENERAL PROBABILITY MEASURE,0.034892942109436956,q increases from 0 to 1
GENERAL PROBABILITY MEASURE,0.035685963521015066,"2
correspondingly. The fact that the radius of Wq-distance constraint set grows with order Θ(d
1
2 −1"
GENERAL PROBABILITY MEASURE,0.03647898493259318,"q )
provides us with an intuition that it is increasingly harder to bound Dx,ϵ,q with larger q, therefore,
W-distance-relaxation works better for lq(q ≤2) norm perturbation. And this relaxation radius is
tight for W2 distance and Gaussian smoothing measures which is proved in the appendix D and
therefore shows that W2-distance-relaxation works well for Gaussian smoothing measure."
GENERAL PROBABILITY MEASURE,0.03727200634417129,Under review as a conference paper at ICLR 2022
RELAXATION USING TOTAL VARIANCE DISTANCE,0.0380650277557494,"3.2
RELAXATION USING TOTAL VARIANCE DISTANCE"
RELAXATION USING TOTAL VARIANCE DISTANCE,0.03885804916732752,"In this section, we show the following relaxation from norm-based constraint sets into TV-distance-
based constraint sets for Gaussian and uniform smoothing measures.
Dx,ϵ,q = {x′ + µ : ||x −x′||q ≤ϵ} ⊆{ν : TV (x + µ, ν) ≤ξ} = Dx,ξ
(10)"
GAUSSIAN PROBABILITY MEASURE,0.03965107057890563,"3.2.1
GAUSSIAN PROBABILITY MEASURE"
GAUSSIAN PROBABILITY MEASURE,0.040444091990483745,"Here, we want to ﬁnd a ξ(ϵ) for Gaussian measure µ = N(0, σ2I) such that"
GAUSSIAN PROBABILITY MEASURE,0.041237113402061855,"Dx,ϵ,q = {x′ + µ : ||x −x′||q ≤ϵ} ⊆{ν : TV (x + µ, ν) ≤ξ(ϵ)} = Dx,ξ(ϵ).
(11)"
GAUSSIAN PROBABILITY MEASURE,0.04203013481363997,"The magnitude of ξ(ϵ) is given by the following theorem.
Theorem 3.2. For Gaussian probability measure µ = N(0, σ2I) on Euclidean space Rd and for all
x ∈R, ϵ > 0, q > 0, norm-based constraint set Dx,ϵ,q can be relaxed into TV-distance-based con-"
GAUSSIAN PROBABILITY MEASURE,0.04282315622521808,"straint set Dx,ξ(ϵ) with radius ξ(ϵ) = 2G
  max{ϵ,ϵd
1
2 −1"
GAUSSIAN PROBABILITY MEASURE,0.04361617763679619,"q }
2σ

−1 where G is the cumulative distribution
function for standard normal distribution N(0, 1) which can be formulated as"
GAUSSIAN PROBABILITY MEASURE,0.04440919904837431,"Dx,ϵ,q ⊆

ν : TV (x + µ, ν) ≤2G

max
n ϵ"
GAUSSIAN PROBABILITY MEASURE,0.04520222045995242,"2σ , ϵd
1
2 −1 q 2σ"
GAUSSIAN PROBABILITY MEASURE,0.045995241871530534,"o
−1

.
(12)"
GAUSSIAN PROBABILITY MEASURE,0.046788263283108644,"This theorem theoretically shows that TV distance relaxation works effectively for lq(q ≤2) per-
turbation due to the irrelevance of the radius to dimension d and increasingly bad for lq(q > 2)
perturbation because of the dependence of the radius to dimension d as order Θ(d
1
2 −1 q )."
UNIFORM PROBABILITY MEASURE,0.047581284694686754,"3.2.2
UNIFORM PROBABILITY MEASURE"
UNIFORM PROBABILITY MEASURE,0.04837430610626487,"Here, we want to ﬁnd a ξ(ϵ) for uniform measure µ = U(K), where K is a speciﬁc convex compact
set, with density function fK(x) =
1
Vol(K)Ix∈K such that"
UNIFORM PROBABILITY MEASURE,0.04916732751784298,"Dx,ϵ,q = {x′ + µ : ||x −x′||q ≤ϵ} ⊆{ν : TV (x + µ, ν) ≤ξ(ϵ)} = Dx,ξ(ϵ).
(13)"
UNIFORM PROBABILITY MEASURE,0.0499603489294211,"In this paper, we mainly focus on the case when K is lp-norm ball centered at original point O with
radius r, i.e., K = Bp(O, r). We give following theorems about special cases when p = 1, 2, ∞.
Theorem 3.3. When K is an l1 norm ball centered at O with radius r, for uniform probability
measure U(K) on Euclidean space Rd, we have"
UNIFORM PROBABILITY MEASURE,0.05075337034099921,"Dx,ϵ,q \

ν : TV (x + µ, ν) ≤1 −δ
	
̸= ∅for all q > 1 and arbitrarily small δ > 0,
(14)"
UNIFORM PROBABILITY MEASURE,0.05154639175257732,"when ϵ ≥2rd
1
q −1. Note that ϵ ≥2r
√"
UNIFORM PROBABILITY MEASURE,0.052339413164155434,d which decays with order Θ(d−1
UNIFORM PROBABILITY MEASURE,0.05313243457573354,2 ) for q = 2 and ϵ ≥2r
UNIFORM PROBABILITY MEASURE,0.05392545598731166,"d which
decays with order Θ(d−1) for q = ∞."
UNIFORM PROBABILITY MEASURE,0.05471847739888977,"This theorem theoretically shows that for uniform smoothing measures with l1 ball support set, and
total variance distance failed to relax measure set Dx,ϵ,q effectively when q = 2, ∞. And this will
consequently lead to bad performance for l2 and l∞robustness certiﬁcation task, which can be seen
from the following section discussing the importance of TV-distance-based relaxation radius.
Theorem 3.4. When K is an l2 (Euclidean) ball centered at O with radius r, for uniform
probability measure U(K) on Euclidean space Rd and for all x ∈R, ϵ > 0, q > 0, when
ϵ > min{2r, 2rd
1
q −1"
UNIFORM PROBABILITY MEASURE,0.05551149881046788,"2 }, norm-based constraint set Dx,ϵ,q failed to be relaxed into TV-distance-
based constraint set which can be formulated as"
UNIFORM PROBABILITY MEASURE,0.056304520222045996,"Dx,ϵ,q \

ν : TV (x + µ, ν) ≤1 −δ
	
̸= ∅for all q > 1 and arbitrarily small δ > 0.
(15)"
UNIFORM PROBABILITY MEASURE,0.057097541633624106,"And when ϵ ≤min{2r, 2rd
1
q −1"
UNIFORM PROBABILITY MEASURE,0.05789056304520222,"2 }, norm-based constraint set Dx,ϵ,q can be relaxed into valid TV-"
UNIFORM PROBABILITY MEASURE,0.05868358445678033,"distance-based constraint set Dx,ξ(ϵ) with radius ξ(ϵ) = 1 −"
UNIFORM PROBABILITY MEASURE,0.05947660586835844,"R arccos( max{ϵ,ϵd
1
2 −1"
UNIFORM PROBABILITY MEASURE,0.06026962727993656,"q }
2r
)
0
sinn(t)dt
R π"
UNIFORM PROBABILITY MEASURE,0.06106264869151467,"2
0
sinn(t)dt
which can"
UNIFORM PROBABILITY MEASURE,0.061855670103092786,be formulated as
UNIFORM PROBABILITY MEASURE,0.0626486915146709,"Dx,ϵ,q ⊆

ν : TV (x + µ, ν) ≤1 −"
UNIFORM PROBABILITY MEASURE,0.063441712926249,"R arccos( max{ϵ,ϵd
1
2 −1"
UNIFORM PROBABILITY MEASURE,0.06423473433782712,"q }
2r
)
0
sinn(t)dt
R π"
UNIFORM PROBABILITY MEASURE,0.06502775574940524,"2
0 sinn(t)dt"
UNIFORM PROBABILITY MEASURE,0.06582077716098335,"
.
(16)"
UNIFORM PROBABILITY MEASURE,0.06661379857256146,Under review as a conference paper at ICLR 2022
UNIFORM PROBABILITY MEASURE,0.06740681998413957,"This theorem shows that for uniform smoothing measures with l2 ball support set, when q ≤2,
relaxation radius is independent of dimension d, whereas when q > 2 relaxation radius starts to be
bound up with dimension d and the impact of d grows as q increases. To put it another way, total
variance distance relaxation performs well for uniform smoothing measures with l2 ball support set
when q ≤2 and increasingly poor when q > 2."
UNIFORM PROBABILITY MEASURE,0.06819984139571768,"Theorem 3.5. When K is an l∞cube centered at O with radius r, for uniform probability measure
U(K) on Euclidean space Rd and for all x ∈R, ϵ > 0, q > 0, when ϵ > 2r, norm-based constraint
set Dx,ϵ,q failed to be relaxed into TV-distance-based constraint set which can be formulated as"
UNIFORM PROBABILITY MEASURE,0.0689928628072958,"Dx,ϵ,q \

ν : TV (x + µ, ν) ≤1 −δ
	
̸= ∅for all q > 0 and arbitrarily small δ > 0.
(17)"
UNIFORM PROBABILITY MEASURE,0.06978588421887391,"And when ϵ ≤2r, norm-based constraint set Dx,ϵ,q can be relaxed into valid TV-distance-based
constraint set Dx,ξ(ϵ). When q = 1, ξ(ϵ) can be taken as
ϵ
2r, which can be formulated as"
UNIFORM PROBABILITY MEASURE,0.07057890563045202,"Dx,ϵ,1 ⊆
n
ν : TV (x + µ, ν) ≤ϵ"
R,0.07137192704203013,2r
R,0.07216494845360824,"o
.
(18)"
R,0.07295796986518636,"When q = 2, ξ(ϵ) can be taken as 1 −
 
1 −
ϵ"
D,0.07375099127676447,"2d
1
2 r
d when 0 < ϵ ≤2tnr where
q n−1"
D,0.07454401268834258,"n
≤tn < 1 and
tn approaches 1 at an exponential rate, which can be formulated as"
D,0.0753370340999207,"Dx,ϵ,2 ⊆
n
ν : TV (x + µ, ν) ≤1 −
 
1 −
ϵ"
D,0.0761300555114988,"2d
1
2 r"
D,0.07692307692307693,"do
≈
n
ν : TV (x + µ, ν) ≤1 −e−ϵ"
R D,0.07771609833465504,"2r d
1
2 o
, (19)"
R D,0.07850911974623315,"ξ(ϵ) can be taken as 1 −
 d−1+√ d( ϵ"
R D,0.07930214115781126,"2r )2−d+1
d
d−1 1−√ d( ϵ"
R D,0.08009516256938938,2r )2−d+1
R D,0.08088818398096749,"d

when 2tnr < ϵ < 2r, which
can be formulated as"
R D,0.0816812053925456,"Dx,ϵ,2 ⊆

ν : TV (x + µ, ν) ≤1 −
d −1 +
p d( ϵ"
R D,0.08247422680412371,"2r)2 −d + 1
d"
R D,0.08326724821570182,"d−11 −
p d( ϵ"
R D,0.08406026962727994,"2r)2 −d + 1 d 
."
R D,0.08485329103885805,"(20)
When q = ∞, ξ(ϵ) can be taken as 1 −
 
1 −
ϵ
2r
d, which can be formulated as"
R D,0.08564631245043616,"Dx,ϵ,∞⊆

ν : TV (x + µ, ν) ≤1 −
 
1 −ϵ"
R,0.08643933386201427,"2r
d

.
(21)"
R,0.08723235527359238,"As for uniform smoothing measures with l∞cube support set, this theorem shows that the perfor-
mance towards l1 perturbation turns out to be ﬁne since TV distance relaxation radius ϵ"
R HAS NOTHING,0.0880253766851705,"2r has nothing
to do with dimension d and the dimensional curse is avoided. However, in this case, TV distance
relaxation shows incapability to cope with l2 and l∞perturbation in some extent due to the rate of"
R HAS NOTHING,0.08881839809674862,"increasing radius tending to 1 as Θ(ed
1
2 ) and Θ(ed)."
R HAS NOTHING,0.08961141950832673,"After discussing the special cases when K is an l∞cube or an l2 Euclidean ball, we then consider
the general case when K is an lp ball centered at the original point with radius r and give a lower
bound for TV distance relaxation radius in the following theorem."
R HAS NOTHING,0.09040444091990484,"Theorem 3.6. When K is an lp ball centered at O with radius r, for uniform probability measure
U(K) on Euclidean space Rd and assume norm-based constraint set Dx,ϵ,q can be relaxed into
TV-distance-based constraint set Dx,ξ(ϵ), then"
R HAS NOTHING,0.09119746233148295,"ξ(ϵ) ≥2
Z
ϵd
1
p"
R HAS NOTHING,0.09199048374306107,"4r(pe)
1
p Γ(1+ 1 p )"
EXP,0.09278350515463918,"0
exp
1"
EXP,0.09357652656621729,p −e(2xΓ(1 + 1
EXP,0.0943695479777954,"p))p
dx"
EXP,0.09516256938937351,"for all perturbation norm parameter q > 0 with high probability when d is sufﬁciently large, which
can be formulated as"
EXP,0.09595559080095163,"Dx,ϵ,q \

ν : TV (x + µ, ν) ≤2
Z
ϵd
1
p"
EXP,0.09674861221252974,"4r(pe)
1
p Γ(1+ 1 p )"
EXP,0.09754163362410785,"0
exp
1"
EXP,0.09833465503568596,p −e(2xΓ(1 + 1
EXP,0.09912767644726407,"p))p
dx −δ

̸= ∅(22)"
EXP,0.0999206978588422,for arbitrarily small δ > 0.
EXP,0.1007137192704203,Under review as a conference paper at ICLR 2022
EXP,0.10150674068199841,"Figure 1: Graph of density function f(x) = exp
  1"
EXP,0.10229976209357652,p −e( 2 pΓ( 1
EXP,0.10309278350515463,"p))pxp
when p = 2, 4, 6 from left to
right"
EXP,0.10388580491673276,A way to interpret this theorem is that as p increases and K correspondingly translates from l1
EXP,0.10467882632831087,"norm cross-polytope into l∞norm cube, the dependence of integral upper limit
ϵd
1
p"
EXP,0.10547184773988898,"4r(pe)
1
p Γ(1+ 1"
EXP,0.10626486915146709,p ) on
EXP,0.1070578905630452,"dimension d is gradually reduced, which theoretically shows by taking all kinds of lq perturbations
into consideration, in average scale U
 
Bp(O, r)

tends to perform better than U
 
Bq(O, r)

where
p > q. Nevertheless, note that the curse of dimension is unavoidable when we use uniform smooth-
ing measure U(K) with bounded support set. Note the graphs of density function shown in Figure
1 when p = 2, 4, 6, we know that as p increases, the density curve is increasingly short, fat, and
light-tailed. From another perspective, we consider a ball with a ﬁxed radius r. As the dimension d
of the base Euclidean space increases, ﬁxed proportion of mass concentrates within a slab of width
Θ(d−1"
EXP,0.10785091197462332,"p ). Thus, intuitively, it is increasingly difﬁcult to bound the perturbed measure set Dx,ϵ,q by
using TV distance and certify as dimension d enlarge due to the existence of TV-relaxation upper
bound in the dual optimization problem."
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.10864393338620143,"3.3
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.10943695479777954,"Based on the above analysis, in this section, we are now prepared to compute the Lagrange function
and dual problem of the relaxed optimization problem OPT(φ, x + µ, Dx,δ,p ∩Dx,ξ). Here we
mainly focus on the case when reference measure ρ = x+µ and perturbed probability measure ν are
absolutely continuous w.r.t. Lebesgue measure λ on Rd, i.e., ρ, ν ≪λ and discard uncommon cases
when ρ, ν are discrete, single or mixed w.r.t. λ. Since ρ, ν ≪λ, assume the density function of ρ
and ν w.r.t. Lebesgue measure λ are f(x) and g(x), x ∈Rd respectively. Instead of using likelihood
ratio r(x), we consider the difference between g(x) and f(x) and deﬁne it as q(x) := g(x) −f(x).
The objective function EX∼ν[φ(X)] of optimization problem OPT(φ, ρ, D) can be rewritten in
terms of difference function q(x). And we give the theorems below.
Theorem 3.7 (Wp distance relaxation with 0 < p ≤1). The relaxed optimization problem
OPT(φ, x + µ, Dx,δ,p ∩Dx,ξ) is equivalent to the convex optimization problem with only one func-
tional variable as below"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.11022997620935765,"inf
q∈L1(X) Z"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.11102299762093576,"X
φ(x)q(x)dx + EX∼x+µ[φ(X)], s.t.
sup
||f||L,p≤1"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.11181601903251388,"Z
f(x)q(x)dx ≤δ,
Z
|q(x)|dx ≤2ξ"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.11260904044409199,"(23)
where ||f||L,p := supx,y∈Rd,x̸=y
|f(x)−f(y)|"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.1134020618556701,"||x−y||p
2
."
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.11419508326724821,"Theorem 3.8 (Wp distance relaxation with p > 1). When smoothing measure µ possesses a convex
compact support set K and R := supy∈K ||y||2, R∗:= ||x||2+R+max{ϵ, ϵd
1
2 −1"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.11498810467882632,"q }, the relaxed op-
timization problem OPT(φ, x+µ, Dx,δ,p∩Dx,ξ) can be further relaxed into the convex optimization
problem with only one functional variable below"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.11578112609040445,"inf
q∈L1(X) Z"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.11657414750198256,"X
φ(x)q(x)dx + EX∼x+µ[φ(X)],
(24)"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.11736716891356067,"s.t.
sup
||f||L≤p(2R∗)p−1"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.11816019032513878,"Z
f(x)q(x)dx ≤δp + (p −1)(2R∗)p−1,
Z
|q(x)|dx ≤2ξ,"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.11895321173671689,"where ||f||L := supx,y∈Rd,x̸=y
|f(x)−f(y)|"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.11974623314829501,"||x−y||2
."
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.12053925455987312,"Theorem 3.9. The Lagrange function of optimization problem in (23) and (24) is
L(λ) = EX∼x+µ[φ(X)] −2ξ −λC,
(25)"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.12133227597145123,Under review as a conference paper at ICLR 2022
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.12212529738302934,"Smoothing
Measure
Perturbation
Certiﬁcation Objective
Prerequisite"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.12291831879460745,"U(B2(O, r))
lq(q ≤2)
EX∼x+µ[φ(X)] −2

1 −"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.12371134020618557,R arccos( ϵ
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.12450436161776368,"2r )
0
sinn(t)dt
R π"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.1252973830293418,"2
0
sinn(t)dt"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.1260904044409199,"
ϵ ≤2r"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.126883425852498,"lq(q > 2)
EX∼x+µ[φ(X)] −2

1 −"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.12767644726407612,"R arccos( ϵd
1
2 −1"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.12846946867565423,"q
2r
)
0
sinn(t)dt
R π"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.12926249008723237,"2
0
sinn(t)dt"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.13005551149881048,"
ϵ ≤2rd
1
q −1 2"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.1308485329103886,"U(B∞(O, r))
l1
EX∼x+µ[φ(X)] −ϵ"
VERIFYING FULL-INFORMATION ROBUST CERTIFICATION,0.1316415543219667,"r
ϵ ≤2r
l2
EX∼x+µ[φ(X)] −2

1 −
 
1 −
ϵ"
D,0.1324345757335448,"2d
1
2 r
d
ϵ ≤2tnr"
D,0.13322759714512292,"l∞
EX∼x+µ[φ(X)] −2

1 −
 
1 −
ϵ
2r
d
ϵ ≤2r"
D,0.13402061855670103,"N(0, σ2I)
lq(q ≤2)
EX∼x+µ[φ(X)] −2
 
2G( ϵ"
D,0.13481363996827914,"2σ) −1

-"
D,0.13560666137985725,"lq(q > 2)
EX∼x+µ[φ(X)] −2
 
2G( ϵd
1
2 −1"
D,0.13639968279143536,"q
2σ
) −1

-"
D,0.1371927042030135,Table 1: Certiﬁcation objectives and prerequisites.
D,0.1379857256145916,"where λ ≥0 is the dual variable w.r.t. constraint sup||f||L≤1
R
f(x)q(x)dx ≤δ or constraint
sup||f||L≤p(2R∗)p−1
R
f(x)q(x)dx ≤δp + (p −1)(2R∗)p−1 and C := δ when 0 < p ≤1 whereas
C := δp + (p −1)(2R∗)p−1 when p > 1."
D,0.1387787470261697,"Using the duality result, we know the optimal value in (23) can be obtained by computing"
D,0.13957176843774782,"max
λ≥0 EX∼x+µ[φ(X)] −ξ −λC = EX∼x+µ[φ(X)] −ξ,
(26)"
D,0.14036478984932593,"which is only related to the radius ξ of TV distance relaxation set. We can see from this formula the
signiﬁcance of TV distance relaxation radius. By plugging the TV distance relaxation radius given
in theorem 3.4, 3.5 and 3.2 in dual optimization problem, we obtain the certiﬁcation objective in
Table 1 and we return certiﬁed for lp norm perturbation with magnitude ϵ if the objective function
has non-negative value."
RELATIONSHIP WITH PREVIOUS WORK,0.14115781126090404,"3.4
RELATIONSHIP WITH PREVIOUS WORK"
RELATIONSHIP WITH PREVIOUS WORK,0.14195083267248215,"By applying our methodology to Gaussian probability measure, we miraculously obtain the same
certiﬁed robustness properties provided in Dvijotham et al. (2020) using as Hockey-stick divergence
with β = 1.
Theorem 3.10. When smoothing measure is taken as Gaussian probability measure, the certiﬁcate
EX∼x+µ[φ(X)]−2
 
2G( ϵ"
RELATIONSHIP WITH PREVIOUS WORK,0.14274385408406026,"2σ)−1

given in our paper is equivalent to the certiﬁcate ϵHS,1 ≤[ θa−θb"
RELATIONSHIP WITH PREVIOUS WORK,0.14353687549563837,"2
]+
given in paper Dvijotham et al. (2020)."
RELATIONSHIP WITH PREVIOUS WORK,0.14432989690721648,"Therefore, when applying both methodologies to Gaussian measure, the formulas obtained are the-
oretically equivalent. Despite the similarity in analyzing Gaussian measure, our work covers cases
with bounded support sets, which is our main contribution."
EXPERIMENTS,0.14512291831879462,"4
EXPERIMENTS"
EXPERIMENTS,0.14591593973037273,"For adversarial robustness certiﬁcation, we choose the test set certiﬁed accuracy as our metric of
interest, which is deﬁned as the percentage of data points in the test set that can be correctly classiﬁed
and can also pass the robustness certiﬁcation within an l2 ball of an assigned radius r. To pass the
robustness certiﬁcation at data point x, the classiﬁcation results of all points within an l2 distance to
the original point x must be consistent. For a model using the smoothing method, the classiﬁcation
result of a data point is the class with the highest score in the smoothed data distribution, not to be
confused with the direct output of the base classiﬁer at that data point."
EXPERIMENTS,0.14670896114195084,"In all experiments, the certiﬁcation process on the test set with assigned perturbation l2 radius is
shown in the following Algorithm 1. Note that the cert(scorea, 1 −scorea, r) function returns true
if the certiﬁcation objective is non-negative, otherwise it returns false. Such objective is calculated"
EXPERIMENTS,0.14750198255352895,Under review as a conference paper at ICLR 2022
EXPERIMENTS,0.14829500396510706,"using formulas in Table 1 with l2 perturbation and corresponding smoothing distribution. Since our
method using Wasserstein distance does not involve iterations, our certiﬁcation procedure only costs
constant computation time, which is much faster than Dvijotham et al. (2020)."
EXPERIMENTS,0.14908802537668517,"Algorithm 1 Certiﬁcation process
Input: T: test set, gt(x): true class of image x, f(x): base classiﬁer, D(x): smoothing distribution,
n: sample amount, r: perturbation radius
Output: acc: test set certiﬁed accuracy"
EXPERIMENTS,0.14988104678826328,"1: certCount ←0, allCount ←0
2: for all x ∈T do
3:
S ←{n samples from D(x)}
4:
countc ←0 for every class c
5:
for all x′ ∈S do
6:
countf(x′) ←countf(x′) + 1
7:
end for
8:
scorec ←
countc
card(S) for every class c"
EXPERIMENTS,0.1506740681998414,"9:
a ←arg maxc{scorec}
10:
if a = gt(x) ∧cert(scorea, 1 −scorea, r) then
11:
certCount ←certCount + 1
12:
end if
13:
allCount ←allCount + 1
14: end for
15: return acc ←certCount"
EXPERIMENTS,0.1514670896114195,allCount
EXPERIMENTS,0.1522601110229976,"We achieve identical results when comparing our W-distance method with the F-divergence method
in Dvijotham et al. (2020) using Gaussian distribution and with speciﬁc metric parameter settings,
which is proved possible in Section 3.4. However, there is no previous work done yet to examine
the usage of uniform distribution when smoothing, so we mainly focus on comparing Gaussian, l2
and l∞uniform distribution all using our W-distance method."
SETUPS,0.15305313243457574,"4.1
SETUPS"
SETUPS,0.15384615384615385,"We choose CIFAR-10 as our dataset and ResNet-110 as our base classiﬁer. We ﬁrstly train the base
classiﬁer on the 50000 image training set without smoothing and achieve 89.6% prediction accuracy
on the 10000 image test set. Then we run the certiﬁcation process on the test set with incremental
perturbation radius r. We test out different smoothing distributions as mentioned above, and we
change the parameters of such distributions to illustrate the effect of different distributions further.
We also try increasing the smoothing sample amount to examine the trade-off between performance
and accuracy improvement. All training, testing, and certiﬁcation are run on an NVIDIA RTX 3090."
W-DISTANCE METHOD WITH DIFFERENT SMOOTHING DISTRIBUTIONS,0.15463917525773196,"4.2
W-DISTANCE METHOD WITH DIFFERENT SMOOTHING DISTRIBUTIONS"
W-DISTANCE METHOD WITH DIFFERENT SMOOTHING DISTRIBUTIONS,0.15543219666931007,"We ﬁrstly implement our W-distance method with N(x, 0.05) as smoothing distribution and sample
amount n=100, and then we change the variance of the Gaussian distribution to 0.025 and 0.1. As
shown in Figure 2, there is a neat cut-off for each setting where the perturbation gets too big, and no
data point can pass the certiﬁcation at this point. By changing the variance of the smoothing distri-
bution, we observe a clear trend that the increase of variance leads to a drop of initial certiﬁcation"
W-DISTANCE METHOD WITH DIFFERENT SMOOTHING DISTRIBUTIONS,0.15622521808088818,"Figure 2: Results of different smoothing distributions using our W-distance method. Sigma stands
for variance for Gaussian distribution and the norm range for uniform distribution."
W-DISTANCE METHOD WITH DIFFERENT SMOOTHING DISTRIBUTIONS,0.1570182394924663,Under review as a conference paper at ICLR 2022
W-DISTANCE METHOD WITH DIFFERENT SMOOTHING DISTRIBUTIONS,0.1578112609040444,"accuracy but also stronger robustness that can endure more signiﬁcant perturbation, and the decrease
of the variance leads to the opposite change accordingly."
W-DISTANCE METHOD WITH DIFFERENT SMOOTHING DISTRIBUTIONS,0.1586042823156225,"Next, for smoothing process, we substitute Gaussian distribution with l2 or l∞uniform distribution,
with the norm range set to 0.025, 0.05 and 0.1. In Figure 2, both experiment results show identical
characteristics as with Gaussian distribution, but they bring along a critical issue, the mismatch of the
perturbation radius’s magnitude. Comparing the perturbation radius at the cut-off point, we ﬁnd that
the radius of Gaussian distribution is about 50 times larger than that of two uniform distributions."
W-DISTANCE METHOD WITH DIFFERENT SMOOTHING DISTRIBUTIONS,0.15939730372720062,"We assume that this phenomenon is caused by the lack of intersection of the smoothing distributions
before and after perturbation. For Gaussian distribution, there is always an intersection no matter
how big the perturbation radius gets, but two uniform distributions will separate quickly and become
disjoint under perturbation. Furthermore, the dimension of a 32 × 32 × 3 image is 3072, the square
root of which is around 55.4, very close to the cut-off radius’s 50 times ratio difference. Such
correlation may trace to the involvement of dimension when calculating the ﬁnite support set volume
of l2 and l∞uniform distribution, while the support set volume of Gaussian distribution is inﬁnitely
large. We conjecture that such deﬁciency is inherent when using the uniform distribution, which can
hardly be further improved."
W-DISTANCE METHOD WITH DIFFERENT SAMPLING AMOUNTS,0.16019032513877876,"4.3
W-DISTANCE METHOD WITH DIFFERENT SAMPLING AMOUNTS"
W-DISTANCE METHOD WITH DIFFERENT SAMPLING AMOUNTS,0.16098334655035687,"When calculating scores for each class in the smoothing process, as we cannot classify all possible
data points, we shall only acquire approximate scores by sampling from the smoothed data distri-
bution. Thus such scores may differ in multiple runs due to the randomness of sampling. However,
through our experiments, we ﬁnd that with a certain amount of samples, we can already obtain suf-
ﬁciently accurate scores, which cannot be signiﬁcantly improved by increasing the sample amount."
W-DISTANCE METHOD WITH DIFFERENT SAMPLING AMOUNTS,0.16177636796193498,Figure 3: Results on sample amounts with different smoothing distributions using W-distance.
W-DISTANCE METHOD WITH DIFFERENT SAMPLING AMOUNTS,0.1625693893735131,"We set the sample amount n to 100, 1000, and 10000 with three different smoothing distributions,
and they all obtain similar results: it takes only 10 minutes to run through the 10000 images test set
with 100 samples for each image, 30 minutes with 1000 samples and 3 hours with excessive 10000
samples. It is ten times faster than the 2 hours running time with the iteration-based method in
Dvijotham et al. (2020) using just 100 samples. It is also worth noting in Figure 3 that by increasing
the sample amount, no signiﬁcant improvement is observed with Gaussian distribution. However,
there is minor progress made with both uniform distributions when the samples are getting overly
abundant. We assume that the extra samples make up for the lack of intersections of smoothing
uniform distributions before and after the perturbation, while Gaussian distribution has no such
issues."
CONCLUSION,0.1633624107850912,"5
CONCLUSION"
CONCLUSION,0.1641554321966693,"We have introduced a framework based on Wasserstein distance and total variance distance relax-
ation as well as Lagrange duality. This methodology is able to deal with the analysis of bounded
support set smoothing measures, which is not covered by previous work. Moreover, we have ana-
lyzed the performance of speciﬁc smoothing measures, including Gaussian probability measure and
uniform probability measures with support set B2(O, r), B∞(O, r) theoretically and experimen-
tally, which shows the relative incapability of bounded support set smoothing measures compared
with Gaussian smoothing measure."
CONCLUSION,0.16494845360824742,Under review as a conference paper at ICLR 2022
REFERENCES,0.16574147501982553,REFERENCES
REFERENCES,0.16653449643140364,"Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of
security: Circumventing defenses to adversarial examples. In ICML, 2018."
REFERENCES,0.16732751784298175,"Avrim Blum, Travis Dick, Naren Manoj, and Hongyang Zhang. Random smoothing might be unable
to certify l∞robustness for high-dimensional images. Journal Of Machine Learning Research,
2020."
REFERENCES,0.1681205392545599,"Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certiﬁed adversarial robustness via randomized
smoothing. In ICML, 2019."
REFERENCES,0.168913560666138,"Francesco Croce and Matthias Hein. Reliable evaluation of adversarial robustness with an ensemble
of diverse parameter-free attacks. In ICML, 2020."
REFERENCES,0.1697065820777161,"D.C Dowson and B.V Landau.
The fr´echet distance between multivariate normal distributions.
Journal of Multivariate Analysis, 1982."
REFERENCES,0.17049960348929422,"Krishnamurthy Dj Dvijotham, Jamie Hayes, Borja Balle, Zico Kolter, Chongli Qin, Andras Gy-
orgy, Kai Xiao, Sven Gowal, and Pushmeet Kohli. A framework for robustness certiﬁcation of
smoothed classiﬁers using f-divergences. In ICLR, 2020."
REFERENCES,0.17129262490087233,"Aounon Kumar, Alexander Levine, Tom Goldstein, and Soheil Feizi. Curse of dimensionality on
randomized smoothing for certiﬁable robustness. In ICML, 2020."
REFERENCES,0.17208564631245044,"Guang-He Lee, Yang Yuan, Shiyu Chang, and Tommi S Jaakkola. Tight certiﬁcates of adversarial
robustness for randomly smoothed classiﬁers. arXiv preprint arXiv:1906.04948, 2019."
REFERENCES,0.17287866772402855,"Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Certiﬁed adversarial robustness with
additive noise. arXiv preprint arXiv:1809.03113, 2018."
REFERENCES,0.17367168913560665,"Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. In ICLR, 2018."
REFERENCES,0.17446471054718476,"Anh Nguyen, Jason Yosinski, and Jeff Clune. Deep neural networks are easily fooled: High conﬁ-
dence predictions for unrecognizable images. In Proceedings of the IEEE conference on computer
vision and pattern recognition, 2015."
REFERENCES,0.17525773195876287,"Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013."
REFERENCES,0.176050753370341,"Matthew Thorpe. Introduction to optimal transport, 2018."
REFERENCES,0.17684377478191912,"Lily Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel, Duane Boning,
and Inderjit Dhillon. Towards fast computation of certiﬁed robustness for relu networks. In ICML,
2018."
REFERENCES,0.17763679619349723,"Eric Wong and Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. In ICML, 2018."
REFERENCES,0.17842981760507534,"Kai Y Xiao, Vincent Tjeng, Nur Muhammad Shaﬁullah, and Aleksander Madry. Training for faster
adversarial robustness veriﬁcation via inducing relu stability. arXiv preprint arXiv:1809.03008,
2018."
REFERENCES,0.17922283901665345,"Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth, Bo Li, Duane Boning,
and Cho-Jui Hsieh. Towards stable and efﬁcient training of veriﬁably robust neural networks.
arXiv preprint arXiv:1906.06316, 2019."
REFERENCES,0.18001586042823156,Under review as a conference paper at ICLR 2022
REFERENCES,0.18080888183980967,"A
OPTIMAL TRANSPORT THEORY"
REFERENCES,0.18160190325138778,"Assume µ, ν ∈P(Rd). Besides, assume µ, ν are absolutely continuous w.r.t. Lebesgue measure λ
and let density functions be f and g.
Deﬁnition 2 (Push Forward). If T : Rd →Rd, then the distribution of T(X) is called the push-
forward of P, denoted by T#P. In other words,"
REFERENCES,0.1823949246629659,"T#P(A) = P(T(x) ∈A) = P(T −1(A))
Deﬁnition 3 (Optimal Distance, Optimal Transport Map). The Monge version of the optimal trans-
port distance is"
REFERENCES,0.183187946074544,"inf
T :T #P =Q"
REFERENCES,0.18398096748612214,"Z
||x −T(x)||pdP(x)
(27)"
REFERENCES,0.18477398889770025,"A minimizer T ∗, if one exists, is called the optimal transport map.
Deﬁnition 4 (Wasserstein Distance, Earth Mover Distance, Optimal Transport Plan). Let Γ(µ, ν)
denote all joint distributions γ for (X, Y ) that have marginals µ and ν. Then the Wasserstein
distance is"
REFERENCES,0.18556701030927836,"Wp(µ, ν) =

inf
γ∈Γ(µ,ν)"
REFERENCES,0.18636003172085647,"Z
||x −y||p
2dγ(x, y)
 1"
REFERENCES,0.18715305313243458,"p
where p ≥1
(28)"
REFERENCES,0.1879460745440127,"When p = 1, this is also called the Earth Mover distance. The minimizer γ∗(which does exist) is
called the optimal transport plan.
Lemma A.1 (Dual Formulation of Wasserstein Distance When p ≤1). It can be shown that"
REFERENCES,0.1887390959555908,"W p
p (µ, ν) = sup
ψ,φ"
REFERENCES,0.1895321173671689,"Z
ψ(y)dν(y) −
Z
φ(x)dµ(x)
(29)"
REFERENCES,0.19032513877874702,"where ψ(y) −φ(x) ≤||x −y||p. In the special case when p = 1, we have the very simple represen-
tation"
REFERENCES,0.19111816019032513,"W1(µ, ν) = sup
ϕ∈F1"
REFERENCES,0.19191118160190326,"Z
ϕ(x)dµ(x)−
Z
ϕ(x)dν(x) = sup
ϕ∈F1"
REFERENCES,0.19270420301348137,"Z
ϕ(x)d(µ−ν)(x) = sup
ϕ∈F1"
REFERENCES,0.19349722442505948,"Z
ϕ(x)(f−g)(x)dx"
REFERENCES,0.1942902458366376,"(30)
where F1 denotes all maps from Rd to R such that |f(x) −f(y)| ≤||x −y|| for all x, y. In the case
when 0 < p < 1, we have similar simple representation"
REFERENCES,0.1950832672482157,"Wp(µ, ν) = sup
ϕ∈Fp"
REFERENCES,0.1958762886597938,"Z
ϕ(x)dµ(x)−
Z
ϕ(x)dν(x) = sup
ϕ∈Fp"
REFERENCES,0.19666931007137192,"Z
ϕ(x)d(µ−ν)(x) = sup
ϕ∈Fp"
REFERENCES,0.19746233148295003,"Z
ϕ(x)(f−g)(x)dx"
REFERENCES,0.19825535289452814,"(31)
where Fp denotes all maps from Rd to R such that |f(x) −f(y)| ≤||x −y||p for all x, y.
Lemma A.2 (Dual Formulation of Wasserstein Distance When 1 < p < ∞). In the case when
1 < p < ∞and the support sets of measure µ and ν are included in a convex compact set K.
Deﬁne R = supx∈K ||x||2, then we have slightly different dual formulation"
REFERENCES,0.19904837430610625,"Wp(µ, ν) ≥

sup
ϕ∈Lip(p(2R)p−1)"
REFERENCES,0.1998413957176844,"Z
ϕ(y)d(ν −µ)(y) −(p −1)(2R)p−1
 1 p"
REFERENCES,0.2006344171292625,"=

sup
ϕ∈Lip(p(2R)p−1)"
REFERENCES,0.2014274385408406,"Z
ϕ(y)(g −f)(y)dy −(p −1)(2R)p−1
 1"
REFERENCES,0.20222045995241872,"p
(32)"
REFERENCES,0.20301348136399683,"where Lip(p(2R)p−1) denotes all maps f from Rd to R such that |f(x)−f(y)| ≤p(2R)p−1||x−y||
for all x, y ∈K.
Deﬁnition 5 (Total Variation Distance). The total variation distance between two probability distri-
bution µ and ν on Rd is deﬁned by"
REFERENCES,0.20380650277557494,"||µ −ν||T V = max

|µ(A) −ν(A)| : A ⊆Rd	
(33)"
REFERENCES,0.20459952418715305,"where Rd is the set of all Borel subsets.
Lemma A.3. Let µ and ν be two probability distributions on Rd and absolutely continuous w.r.t.
Lebesgue measure λ. Assume the density function of measure µ and ν w.r.t. λ are f(x) and g(x).
Then,"
REFERENCES,0.20539254559873116,||µ −ν||T V = 1 2 Z Rd
REFERENCES,0.20618556701030927,"f(x) −g(x)
dx
(34)"
REFERENCES,0.20697858842188738,Under review as a conference paper at ICLR 2022
REFERENCES,0.20777160983346551,"B
PROOF OF LEMMA A.2"
REFERENCES,0.20856463124504362,Recall the dual form of Wasserstein distance
REFERENCES,0.20935765265662173,"W p
p (µ, ν) =
sup
ψ,φ∈C(Rd)"
REFERENCES,0.21015067406819984,"Z
ψ(y)dν(y) −
Z
φ(x)dµ(x)
(35)"
REFERENCES,0.21094369547977795,where ψ(y) −φ(x) ≤||x −y||p.
REFERENCES,0.21173671689135606,"For simplicity of the proof, consider equivalent form"
REFERENCES,0.21252973830293417,"W p
p (µ, ν) =
sup
ψ,φ∈C(Rd)"
REFERENCES,0.21332275971451228,"Z
ψ(y)dν(y) +
Z
φ(x)dµ(x)
(36)"
REFERENCES,0.2141157811260904,"where ψ(y) −φ(x) ≤||x −y||p. First, we introduce a theorem in Thorpe (2018)
Theorem B.1 (Existence of a Maximiser to the Dual Problem). Let µ ∈P(X), ν ∈P(Y ), where
X and Y are polish, and c : X × Y →[0, +∞). Assume that there exists cX ∈L1(µ), cY ∈L1(ν)
such that c(x, y) ≤cX(x) + cY (y) for µ-almost every x ∈X and ν-almost every y ∈Y . In
addition, assume that"
REFERENCES,0.21490880253766853,"M :=
Z"
REFERENCES,0.21570182394924664,"X
cX(x)dµ(x) +
Z"
REFERENCES,0.21649484536082475,"Y
cY (y)dν(y) < ∞
(37)"
REFERENCES,0.21728786677240286,"Then there exists (ϕ, ψ) ∈Φc = {(ϕ, ψ) ∈L1(µ) × L1(ν) : ϕ(x) + ψ(y) ≤c(x, y)} where the
inequality is understood to hold for µ-almost every x ∈X and ν-almost every y ∈Y such that"
REFERENCES,0.21808088818398097,"sup
Φc
J = J(ϕ, ψ)
(38)"
REFERENCES,0.21887390959555908,"where J is deﬁned by J : L1(µ) × L1(ν) →R, J(ϕ, ψ) =
R"
REFERENCES,0.2196669310071372,"X ϕdµ +
R"
REFERENCES,0.2204599524187153,"Y ψdν. Futhermore we can
choose (ϕ, ψ) = (ηcc, ηc) for some η ∈L1(µ). For η : X →¯R, the c-transforms ηc, ηcc are deﬁned
by
ηc : Y →¯R,
ηc(y) = inf
x∈X(c(x, y) −η(x))
(39)"
REFERENCES,0.2212529738302934,"ηcc : Y →¯R,
ηcc(y) = inf
x∈X(c(x, y) −ηc(x))
(40)"
REFERENCES,0.22204599524187152,"Lemma B.1. For a, b ∈R and 1 ≤p < ∞,"
REFERENCES,0.22283901665344966,"|a + b|p ≤2p−1(|a|p + |b|p)
(41)"
REFERENCES,0.22363203806502777,"Proof. First, it’s easy to verify the cases when either of a = 0, b = 0, p = 1 holds. Then, Wlog,
assume a, b ∈R+"
REFERENCES,0.22442505947660588,|a + b|p ≤2p−1(|a|p + |b|p)
REFERENCES,0.22521808088818399,⇐⇒(a + b)p ≤2p−1(ap + bp)
REFERENCES,0.2260111022997621,"⇐⇒2p−1

a
a + b"
REFERENCES,0.2268041237113402,"p
+

b
a + b"
REFERENCES,0.22759714512291832,"p
≥1"
REFERENCES,0.22839016653449642,"⇐⇒2p−1[xp + (1 −x)p] ≥1, ∀x ∈(0, 1)"
REFERENCES,0.22918318794607453,where the last inequality is easy to verify.
REFERENCES,0.22997620935765264,"In our case, c(x, y) = ||x −y||p ≤(||x|| + ||y||)p ≤2p−1(||x||p + ||y||p) and the requirement that
M < ∞is exactly the condition that µ and ν have ﬁnite pth moments which is easy to verify by
noting that supp(µ) = supp(ν) = K is compact set in Rd. Then, according to the theorem, there
exists η ∈L1(µ) such that"
REFERENCES,0.23076923076923078,"W p
p (µ, ν) =
sup
η∈L1(µ)"
REFERENCES,0.2315622521808089,"Z
ηc(y)dν(y) +
Z
ηcc(x)dµ(x)
(42)"
REFERENCES,0.232355273592387,Note that ηc possesses Lipschitz continuous property stated below
REFERENCES,0.2331482950039651,Under review as a conference paper at ICLR 2022
REFERENCES,0.23394131641554322,"Lemma B.2. For η ∈L1(K) where K ⊆Rd is a convex compact set, then ηcp is a p(2R)p−1-
Lipschitz function where R := supx∈K ||x|| and cp(x, y) = ||x −y||p, i.e.,"
REFERENCES,0.23473433782712133,"||ηcp(x) −ηcp(y)|| ≤p(2R)p−1||x −y||,
x, y ∈K
(43)"
REFERENCES,0.23552735923869944,Proof.
REFERENCES,0.23632038065027755,"|ηcp(x) −ηcp(y)| =
 inf
z1∈K
 
||x −z1||p −η(z1)

−inf
z2∈K
 
||y −z2||p −η(z2)

(44)"
REFERENCES,0.23711340206185566,"=
 inf
z1∈K sup
z2∈K"
REFERENCES,0.23790642347343377," 
||x −z1||p −||y −z2||p
−
 
η(z1) −η(z2)
"
REFERENCES,0.2386994448850119,"≤sup
z∈K"
REFERENCES,0.23949246629659002," 
||x −z||p −η(z)

−
 
||y −z||p −η(z)

(45)"
REFERENCES,0.24028548770816813,"= sup
z∈K"
REFERENCES,0.24107850911974624,||x −z||p −||y −z||p
REFERENCES,0.24187153053132435,"where 44 is due to the deﬁnition of c-transform; 45 is obtained by taking a speciﬁc value of z1 as z2.
Note that K is a compact set and
||x −z||p −||y −z||p is a continuous function w.r.t. z, then there
exists a point z∗such that
||x −z∗||p −||y −z∗||p = supz∈K
||x −z||p −||y −z||p. According
to the ﬁrst order condition, z∗satisﬁes the equation below"
REFERENCES,0.24266455194290246,∇z(||x −z||p −||y −z||p) = ∇z||x −z||p −∇z||y −z||p = ∇z||z −x||p −∇z||z −x||p
REFERENCES,0.24345757335448057,"= p||z −x||
p
2 −1(z −x)⊤−p||z −y||
p
2 −1(z −y)⊤= 0
(46)"
REFERENCES,0.24425059476605868,"=⇒||z −x||
p
2 −1(z −x)⊤= ||z −y||
p
2 −1(z −y)⊤"
REFERENCES,0.24504361617763679,"=⇒(||z −x||
p
2 −1 −||z −y||
p
2 −1)z⊤= ||z −x||
p
2 −1x⊤−||z −y||
p
2 −1y⊤"
REFERENCES,0.2458366375892149,"=⇒z =
||z −x||
p
2 −1"
REFERENCES,0.24662965900079303,"||z −x||
p
2 −1 −||z −y||
p
2 −1 x −
||z −y||
p
2 −1"
REFERENCES,0.24742268041237114,"||z −x||
p
2 −1 −||z −y||
p
2 −1 y"
REFERENCES,0.24821570182394925,"where 46 is due to ∇x||x||p = ∇x(x⊤x)
p
2 = p(x⊤x)
p
2 −1x⊤= p||x||
p
2 −1x⊤. And this equation
shows that z∗lie on the line determined by x and y but does not lies on the part between x and y,
which can be formulated as z∗= λx + (1 −λ)y, λ ∈R \ (0, 1). Note that"
REFERENCES,0.24900872323552736,"sup
λ∈R\(0,1)"
REFERENCES,0.24980174464710547,"||x −
 
λx + (1 −λ)y

||p −||y −
 
λx + (1 −λ)y

||p"
REFERENCES,0.2505947660586836,"=
sup
λ∈R\(0,1)"
REFERENCES,0.2513877874702617,||(1 −λ)(x −y)||p −||λ(y −x)||p
REFERENCES,0.2521808088818398,"=
sup
λ∈R\(0,1)"
REFERENCES,0.2529738302934179,"|1 −λ|p −|λ|p · ||x −y||p =

sup
λ∈R\(0,1)"
REFERENCES,0.253766851704996,"|1 −λ||p −|λ|p

· ||x −y||p"
REFERENCES,0.25455987311657413,"Then, we just need to optimize"
REFERENCES,0.25535289452815224,"sup
λ∈R\(0,1)"
REFERENCES,0.25614591593973035,|1 −λ|p −|λ|p
REFERENCES,0.25693893735130846,"s.t.
λx + (1 −λ)y ∈K"
REFERENCES,0.25773195876288657,Note that we can relax the constraint as below
REFERENCES,0.25852498017446474,"λx + (1 −λ)y ∈K
⇐⇒λ(x −y) + y = (1 −λ)(y −x) + x ∈K
=⇒||λ(x −y) + y|| = ||(1 −λ)(y −x) + x|| ≤R
(47)
=⇒||λ(x −y)|| ≤R + ||y||,
||(1 −λ)(y −x)|| ≤R + ||x||
(48)
=⇒|λ| · ||x −y|| ≤2R,
|1 −λ| · ||x −y|| ≤2R
(49)"
REFERENCES,0.25931800158604285,"=⇒1 −
2R
||x −y|| ≤λ ≤
2R
||x −y||"
REFERENCES,0.26011102299762096,where 47 and 49 is due to the deﬁnition of R as supx∈K ||x||; 48 is due to triangular inequality.
REFERENCES,0.26090404440919907,Under review as a conference paper at ICLR 2022
REFERENCES,0.2616970658207772,"Using the relaxed constraint, we can show that when λ ≥1,
|1 −λ|p −|λ|p = λp −(λ −1)p is an
increasing function w.r.t. λ as p ≥1, then
|1 −λ|p −|λ|p = λp −(λ −1)p ≤

2R
||x −y||"
REFERENCES,0.2624900872323553,"p
−

2R
||x −y|| −1
p
(50)"
REFERENCES,0.2632831086439334,"And when λ ≤0,
|1 −λ|p −|λ|p = (1 −λ)p −(−λ)p is a decreasing function w.r.t λ as p ≥1,
then
|1 −λ|p −|λ|p = (1 −λ)p −(−λ)p ≤

2R
||x −y||"
REFERENCES,0.2640761300555115,"p
−

2R
||x −y|| −1
p
(51)"
REFERENCES,0.2648691514670896,"Note that

2R
||x −y||"
REFERENCES,0.2656621728786677,"p
−

2R
||x −y|| −1
p
= p

k ·

2R
||x −y||"
REFERENCES,0.26645519429024583,"
+ (1 −k) ·

2R
||x −y|| −1
p−1
(52)"
REFERENCES,0.26724821570182394,"= p

2R
||x −y|| + (k −1)
p−1
≤p

2R
||x −y|| p−1"
REFERENCES,0.26804123711340205,"where 52 is due to the Differential Mean Value Theorem where k ∈(0, 1)."
REFERENCES,0.26883425852498016,"Thus, we have"
REFERENCES,0.2696272799365583,"|ηcp(x) −ηcp(y)| ≤p

2R
||x −y||"
REFERENCES,0.2704203013481364,"p−1
· ||x −y||p = p(2R)p−1||x −y||
(53)"
REFERENCES,0.2712133227597145,i.e. ηcp(x) is a p(2R)p−1-Lipschitz function.
REFERENCES,0.2720063441712926,"Using Lipschitz continuous property of ηc, we get"
REFERENCES,0.2727993655828707,"W p
p (µ, ν) =
sup
η∈L1(µ)"
REFERENCES,0.2735923869944489,"Z
ηc(y)dν(y) +
Z
ηcc(x)dµ(x) ≤
sup
ϕ∈Lip(p(2R)p−1)"
REFERENCES,0.274385408406027,"Z
ϕ(y)dν(y) +
Z
ϕc(x)dµ(x)"
REFERENCES,0.2751784298176051,"=
sup
ϕ∈Lip(p(2R)p−1)"
REFERENCES,0.2759714512291832,"Z
ϕ(y)dν(y) +
Z
ϕc(y)dµ(y) (54)"
REFERENCES,0.2767644726407613,"where Lip(p(2R)p−1) denotes the set of p(2R)p−1-Lipschitz functions. On the other hand, recall
that
W p
p (µ, ν) =
sup
ψ,φ∈C(Rd)"
REFERENCES,0.2775574940523394,"Z
ψ(y)dν(y) +
Z
φ(x)dµ(x)
(55)"
REFERENCES,0.27835051546391754,"where ψ(y) + φ(x) ≤||x −y||p. Keeping ψ(x) ﬁxed and optimizing w.r.t. φ(y), then we just
need to optimize
R
φ(y)dµ(y) under constraint φ(y) ≤||x −y||p −ψ(x). Then obviously we
have φ∗(y) = infx∈K
 
||x −y||p −ψ(x)

= ψcp(y) where cp(x, y) = ||x −y||p. The map
(φ, ψ) ∈C(K)2 7→(ψcp, ψ) ∈C(K)2 replaces dual potentials by ”better” ones improving the dual
objective W p
p (µ, ν)."
REFERENCES,0.27914353687549565,"Using c-transform, we can reformulate constrained problem into unconstrained convex problem over
a single potential"
REFERENCES,0.27993655828707376,"W p
p (µ, ν) =
sup
ψ∈C(Rd)"
REFERENCES,0.28072957969865187,"Z
ψ(y)dν(y) +
Z
ψcp(x)dµ(x) =
sup
ψ∈C(Rd)"
REFERENCES,0.28152260111023,"Z
ψ(y)dν(y) +
Z
ψcp(y)dµ(y)"
REFERENCES,0.2823156225218081,"(56)
Combining 54 and 56, we know that when the support set of measure µ and ν supp(µ) = supp(ν) =
K where K is a convex compact set, we have"
REFERENCES,0.2831086439333862,"sup
ψ∈C(K)"
REFERENCES,0.2839016653449643,"Z
ψ(y)dν(y)+
Z
ψcp(y)dµ(y) = W p
p (µ, ν) ≤
sup
ϕ∈Lip(p(2R)p−1)"
REFERENCES,0.2846946867565424,"Z
ϕ(y)dν(y)+
Z
ϕc(y)dµ(y)"
REFERENCES,0.2854877081681205,"(57)
Note that Lipschitz function must be continuous and therefore Lip(p(2R)p−1) ⊆C(K). Then, we
have"
REFERENCES,0.28628072957969863,"sup
ϕ∈Lip(p(2R)p−1)"
REFERENCES,0.28707375099127674,"Z
ϕ(y)dν(y) +
Z
ϕc(y)dµ(y) ≤
sup
φ∈C(K)"
REFERENCES,0.28786677240285485,"Z
ψ(y)dν(y) +
Z
ψcp(y)dµ(y)
(58)"
REFERENCES,0.28865979381443296,Under review as a conference paper at ICLR 2022
REFERENCES,0.28945281522601113,"Combining 57 and 58, we know the inequality in 57 changes into equality"
REFERENCES,0.29024583663758924,"W p
p (µ, ν) =
sup
ϕ∈Lip(p(2R)p−1)"
REFERENCES,0.29103885804916735,"Z
ϕ(y)dν(y) +
Z
ϕc(y)dµ(y)
(59)"
REFERENCES,0.29183187946074546,"Note that for f(x) = xp −p(2R)p−1x, x ∈R+ achieves its minimum when f ′(x) = pxp−1 −
p(2R)p−1 = 0, i.e. x = 2R and the minimum is f(2R) = −(p −1)(2R)p−1. Then,"
REFERENCES,0.29262490087232357,"ϕcp(y) = inf
x∈K"
REFERENCES,0.2934179222839017,"
||x−y||p−ϕ(x)

≥inf
x∈K"
REFERENCES,0.2942109436954798,"
||x−y||p−ϕ(y)−p(2R)p−1||x−y||

= −ϕ(y)−(p−1)(2R)p−1"
REFERENCES,0.2950039651070579,"(60)
Thus, we attain a lower bound of W p
p (µ, ν)"
REFERENCES,0.295796986518636,"W p
p (µ, ν) =
sup
ϕ∈Lip(p(2R)p−1)"
REFERENCES,0.2965900079302141,"Z
ϕ(y)dν(y) +
Z
ϕc(y)dµ(y)
(61)"
REFERENCES,0.2973830293417922,"≥
sup
ϕ∈Lip(p(2R)p−1)"
REFERENCES,0.29817605075337034,"Z
ϕ(y)dν(y) −
Z 
ϕ(y) + (p −1)(2R)p−1
dµ(y)
(62)"
REFERENCES,0.29896907216494845,"=
sup
ϕ∈Lip(p(2R)p−1)"
REFERENCES,0.29976209357652656,"Z
ϕ(y)dν(y) −
Z
ϕ(y)dµ(y) −(p −1)(2R)p−1"
REFERENCES,0.30055511498810467,"=
sup
ϕ∈Lip(p(2R)p−1)"
REFERENCES,0.3013481363996828,"Z
ϕ(y)d(ν −µ)(y) −(p −1)(2R)p−1"
REFERENCES,0.3021411578112609,where 61 is due to 59 and 62 is due to 60.
REFERENCES,0.302934179222839,"C
PROOF OF THEOREM 3.1"
REFERENCES,0.3037272006344171,Proof.
REFERENCES,0.3045202220459952,"Dx,ϵ,q = {x′ + µ : ||x −x′||q ≤ϵ}
(63)
Note that"
REFERENCES,0.3053132434575734,"sup
ν∈Dx,ϵ,q
Wp(µ, ν) =
sup
||x−x′||q≤ϵ
Wp(x + µ, x′ + µ) =
sup
||z||q≤ϵ
Wp(µ, z + µ)
(64)"
REFERENCES,0.3061062648691515,"where the ﬁrst equality is due to the deﬁnition of Dx,ϵ,q and the second equality is due to the trans-
lation invariance property of Wasserstein distance."
REFERENCES,0.3068992862807296,Then recall the Monge version of Wasserstein distance
REFERENCES,0.3076923076923077,"Wp(µ, ν) ≤

inf
T :T #µ=ν"
REFERENCES,0.3084853291038858,"Z
||x −T(x)||pdµ(x)
 1"
REFERENCES,0.30927835051546393,"p
(65)"
REFERENCES,0.31007137192704204,"Noticing the inf operator in the Monge version deﬁnition of Wp, we can get an upper bound for
Wp(µ, ν) by specializing a transport map ˜T satisfying ˜Tµ = ν. In our case, we take ˜T : Rd →
Rd, ˜T : x 7→x + z, and it’s easy to verify that ˜T #µ = z + µ. Then we get the upper bound below"
REFERENCES,0.31086439333862015,"Wp(µ, z + µ) ≤

inf
T :T #µ=z+µ"
REFERENCES,0.31165741475019826,"Z
||x −T(x)||pdµ(x)
 1"
REFERENCES,0.31245043616177637,"p
≤
 Z
||x −˜T(x)||pdµ(x)
 1"
REFERENCES,0.3132434575733545,"p
= ||z||"
REFERENCES,0.3140364789849326,"(66)
where the last equality is due to µ is a probability measure. This provides us with an intuition that
the upper bound of Wp(µ, z + µ) is determined by the Euclidean norm of displacement z. Using
this upper bound,
sup
||z||q≤ϵ
Wp(µ, z + µ) ≤
sup
||z||q≤ϵ
||z||2
(67)"
REFERENCES,0.3148295003965107,"When 0 < q ≤2, using the lemma that when 0 < p < q < ∞, ||z||q ≤||z||p, ∀z ∈Rd holds, we
have sup||z||q≤ϵ ||z||2 ≤sup||z||q≤ϵ ||z||q = ϵ. On the other hand, note that ||ϵe1||2 = ||ϵe1||q = ϵ,
we have sup||z||q≤ϵ ||z||2 = ϵ. And when q > 2, recall Holder’s Inequality below"
REFERENCES,0.3156225218080888,"Lemma C.1 (Holder’s Inequality for Rn). For {ai}1≤i≤n, {bi}1≤i≤n ⊆R, r > 1, we have n
X"
REFERENCES,0.3164155432196669,"i=1
|ai||bi| ≤

n
X"
REFERENCES,0.317208564631245,"i=1
|ai|r 1"
REFERENCES,0.31800158604282314,"r 
n
X"
REFERENCES,0.31879460745440125,"i=1
|ai|
r
r−1
 r−1"
REFERENCES,0.31958762886597936,"r
(68)"
REFERENCES,0.3203806502775575,Under review as a conference paper at ICLR 2022
REFERENCES,0.32117367168913563,"Apply it to the case n = d, |ai| = |xi|2, |bi| = 1 and r = q"
REFERENCES,0.32196669310071374,"2 > 1, d
X"
REFERENCES,0.32275971451229185,"i=1
|xi|2 = d
X"
REFERENCES,0.32355273592386996,"i=1
|xi|2 · 1 ≤

d
X"
REFERENCES,0.32434575733544807,"i=1
(|xi|2)
q
2
 2"
REFERENCES,0.3251387787470262,"q 
d
X i=1
1"
REFERENCES,0.3259318001586043,"q
q−2
 q−2"
REFERENCES,0.3267248215701824,"q
=

d
X"
REFERENCES,0.3275178429817605,"i=1
|xi|q
 2"
REFERENCES,0.3283108643933386,"q
d1−2"
REFERENCES,0.32910388580491673,"q
(69)"
REFERENCES,0.32989690721649484,"||x||2 =

d
X"
REFERENCES,0.33068992862807295,"i=1
|xi|2
 1"
REFERENCES,0.33148295003965106,"2
≤

d
X"
REFERENCES,0.33227597145122917,"i=1
|xi|q
 1"
REFERENCES,0.3330689928628073,"q
d
1
2 −1"
REFERENCES,0.3338620142743854,"q = ||x||qd
1
2 −1"
REFERENCES,0.3346550356859635,"q
(70)"
REFERENCES,0.3354480570975416,"Thus, sup||z||q≤ϵ ||z||2
≤sup||z||q≤ϵ ||x||qd
1
2 −1"
REFERENCES,0.3362410785091198,"q
= ϵd
1
2 −1"
REFERENCES,0.3370340999206979,"q .
On the other hand, note that || ϵ"
REFERENCES,0.337827121332276,"n
1
q
Pd
i=1 ei||q = ϵ, || ϵ"
REFERENCES,0.3386201427438541,"n
1
q
Pd
i=1 ei||2 = ϵd
1
2 −1"
REFERENCES,0.3394131641554322,"q , we have sup||z||q≤ϵ ||z||2 = ϵd
1
2 −1"
REFERENCES,0.3402061855670103,q . Combin-
REFERENCES,0.34099920697858843,"ing the case when 0 < q ≤2 and q > 2, we have"
REFERENCES,0.34179222839016654,"sup
||x−x′||q≤ϵ
Wp(x + µ, x′ + µ) =
sup
||z||q≤ϵ
Wp(µ, z + µ) ≤"
REFERENCES,0.34258524980174465,(ϵ when 0 < q ≤2
REFERENCES,0.34337827121332276,"ϵd
1
2 −1"
REFERENCES,0.34417129262490087,"q when q > 2
= max{ϵ, ϵd
1
2 −1 q } (71)"
REFERENCES,0.344964314036479,"D
W2 DISTANCE RELAXATION IS TIGHT FOR GAUSSIAN PROBABILITY
MEASURE"
REFERENCES,0.3457573354480571,"Here, we show that W2 distance relaxation for Gaussian probability measure is tight.
Theorem D.1. When µ = N(0, σ2I) and p = 2, the relaxation in 9 is tight. In other words,"
REFERENCES,0.3465503568596352,"Dx,ϵ,q ⊆D
x,max{ϵ,ϵd
1
2 −1"
REFERENCES,0.3473433782712133,"q },2 but Dx,ϵ,q \ D
x,max{ϵ,ϵd
1
2 −1"
REFERENCES,0.3481363996827914,"q }−δ,2 ̸= ∅for any sufﬁciently small δ > 0. (72)"
REFERENCES,0.34892942109436953,"Proof. Note that Dowson & Landau (1982) established the formula of Wasserstein distance between
two Gaussian measures."
REFERENCES,0.34972244250594764,"Theorem D.2. For Gaussian probability measures µ = N(µ1, Σ1) and ν = N(µ2, Σ2), W2-
distance between µ and ν have closed form formula"
REFERENCES,0.35051546391752575,"W2(µ, ν)2 = ||µ1 −µ2||2 + tr
 
Σ1 + Σ2 −2(Σ1Σ2)
1
2 
(73)"
REFERENCES,0.35130848532910386,"Using above theorem, we yield following tight relaxation between norm-based constraint set Dx,ϵ,q
and W2-distance based constraint sets Dx,δ,2 for Gaussian smoothing measures centered at origin,
i.e. µ = N(0, σ2I)"
REFERENCES,0.352101506740682,"sup
ν∈Dx,ϵ,q
W2(µ, ν) =
sup
||x−x′||q≤ϵ
W2(x + µ, x′ + µ) =
sup
||z||q≤ϵ
W2(µ, z + µ)"
REFERENCES,0.35289452815226013,"=
sup
||z||q≤ϵ
||z||2 = max{ϵ, ϵd
1
2 −1"
REFERENCES,0.35368754956383824,"q }
(74)"
REFERENCES,0.35448057097541635,"where 74 is due to theorem D.2 and equality 71. And generalization of above theorem when µ =
N(0, Σ) can be proved in the same way."
REFERENCES,0.35527359238699446,"E
PROOF OF THEOREM 3.2"
REFERENCES,0.3560666137985726,"Proof. First, we introduce the lemma below."
REFERENCES,0.3568596352101507,"Lemma E.1. Let X be a random variable that follows d-dimensional Gaussian distribution with
density function"
REFERENCES,0.3576526566217288,"f(x; µ, Σ) =
1"
REFERENCES,0.3584456780333069,"(2π)
d
2 |Σ|
1
2 e−1"
REFERENCES,0.359238699444885,"2 (x−µ)T Σ−1(x−µ)
(75)"
REFERENCES,0.3600317208564631,"where x, µ ∈Rd and Σ ∈Sd
++. Let H : xT w + b = 0 be a hyperplane in the d-dimensional
Euclidean space Rd, where w ∈Rd and b ∈R. The hyperplane H deﬁnes two half-spaces:"
REFERENCES,0.36082474226804123,"Ω+ = {x ∈Rd|xT w + b ≥0},
Ω−= {x ∈Rd|xT w + b < 0}
(76)"
REFERENCES,0.36161776367961934,Under review as a conference paper at ICLR 2022
REFERENCES,0.36241078509119745,"Deﬁne the integral over half-space Ω+ as P =
Z"
REFERENCES,0.36320380650277556,"Ω+
f(x; µ, Σ)dx =
Z Ω+ 1"
REFERENCES,0.36399682791435367,"(2π)
d
2 |Σ|
1
2 e−1"
REFERENCES,0.3647898493259318,2 (x−µ)T Σ−1(x−µ)dx
REFERENCES,0.3655828707375099,"Since Σ is positive deﬁnite symmetric, there exist an orthogonal matrix U and a diagonal matrix
D with positive diagonal elements such that Σ = U T DU. Let x0 = −
µ⊤w+b
||
√"
REFERENCES,0.366375892149088,"DUw||2 and hence P =
R ∞
x0
1
√ 2πe−1"
REFERENCES,0.3671689135606661,2 x2dx.
REFERENCES,0.3679619349722443,"(The proof of this lemma is credit to https://math.stackexchange.com/questions/
556977/gaussian-integrals-over-a-half-space.)"
REFERENCES,0.3687549563838224,Recall the deﬁnition of lp-norm constraint set of probability measures
REFERENCES,0.3695479777954005,"Dx,ϵ,q = {x′ + µ : ||x −x′||q ≤ϵ}
(77)
Note that
sup
ν∈Dx,ϵ,q
TV (µ, ν) =
sup
||x−x′||q≤ϵ
TV (x + µ, x′ + µ) =
sup
||z||q≤ϵ
TV (µ, z + µ)
(78)"
REFERENCES,0.3703409992069786,"where the ﬁrst equality is due to the deﬁnition of Dx,ϵ,q and the second equality is due to the trans-
lation invariance property of total variance distance."
REFERENCES,0.3711340206185567,"Deﬁne hyperplane H1 : xT z −||z||2
2
2
= 0 and H2 : xT z + ||z||2
2
2
= 0. The hyperplane H1 deﬁnes"
REFERENCES,0.3719270420301348,"two half-spaces: Ω1
+ = {x ∈Rd|xT z −||z||2
2
2
≥0} and Ω1
−= {x ∈Rd|xT z −||z||2
2
2
< 0}. And"
REFERENCES,0.37272006344171293,"the hyperplane H2 deﬁnes two half-spaces: Ω2
+ = {x ∈Rd|xT z + ||z||2
2
2
≥0} and Ω2
−= {x ∈"
REFERENCES,0.37351308485329104,"Rd|xT z + ||z||2
2
2
< 0}. Applying lemma E.1 and lemma A.3, we know that"
REFERENCES,0.37430610626486915,"sup
||z||q≤ϵ
TV (µ, z + µ)"
REFERENCES,0.37509912767644726,"=
sup
||z||q≤ϵ 1
2"
REFERENCES,0.3758921490880254,"Z 
1"
REFERENCES,0.3766851704996035,"(2π)
d
2 σd e−xT x"
REFERENCES,0.3774781919111816,"2σ2 −
1"
REFERENCES,0.3782712133227597,"(2π)
d
2 σd e−(x−z)T (x−z)"
REFERENCES,0.3790642347343378,"2σ2
dx
(79) = 1"
SUP,0.3798572561459159,"2
sup
||z||q≤ϵ Z Ω1
+ 1"
SUP,0.38065027755749403,"(2π)
d
2 σd"
SUP,0.38144329896907214,e−xT x
SUP,0.38223632038065025,2σ2 −e−(x−z)T (x−z)
SUP,0.3830293417922284,"2σ2
dx +
Z Ω1
− 1"
SUP,0.3838223632038065,"(2π)
d
2 σd"
SUP,0.38461538461538464,e−xT x
SUP,0.38540840602696275,2σ2 −e−(x−z)T (x−z)
SUP,0.38620142743854086,"2σ2
dx = 1"
SUP,0.38699444885011897,"2
sup
||z||q≤ϵ Z Ω1
+ 1"
SUP,0.3877874702616971,"(2π)
d
2 σd"
SUP,0.3885804916732752,"
e−(x−z)T (x−z)"
SUP,0.3893735130848533,"2σ2
−e−xT x"
SUP,0.3901665344964314,"2σ2

dx +
Z Ω1
− 1"
SUP,0.3909595559080095,"(2π)
d
2 σd"
SUP,0.3917525773195876,"
e−xT x"
SUP,0.39254559873116573,2σ2 −e−(x−z)T (x−z)
SUP,0.39333862014274384,"2σ2

dx (80) = 1"
SUP,0.39413164155432195,"2
sup
||z||q≤ϵ Z"
SUP,0.39492466296590006,"Ω1
+
d(z + µ) −
Z"
SUP,0.3957176843774782,"Ω1
+
dµ +
Z"
SUP,0.3965107057890563,"Ω1
−
dµ −
Z"
SUP,0.3973037272006344,"Ω1
−
d(z + µ) = 1"
SUP,0.3980967486122125,"2
sup
||z||q≤ϵ Z"
SUP,0.39888977002379067,"Ω2
+
dµ −
Z"
SUP,0.3996827914353688,"Ω1
+
dµ +
Z"
SUP,0.4004758128469469,"Ω1
−
dµ −
Z"
SUP,0.401268834258525,"Ω2
−
dµ
(81) = 1"
SUP,0.4020618556701031,"2
sup
||z||q≤ϵ Z ∞"
SUP,0.4028548770816812,"−||z||2 2σ 1
√"
SUP,0.4036478984932593,2π e−1
SUP,0.40444091990483744,"2 x2dx −
Z ∞"
SUP,0.40523394131641555,"||z||2 2σ 1
√"
SUP,0.40602696272799366,2π e−1
SUP,0.40681998413957177,"2 x2dx +
Z
||z||2 2σ −∞ 1
√"
SUP,0.4076130055511499,2π e−1
SUP,0.408406026962728,"2 x2dx −
Z −||z||2 2σ −∞ 1
√"
SUP,0.4091990483743061,2π e−1
SUP,0.4099920697858842,2 x2dx (82) = 1
SUP,0.4107850911974623,"2
sup
||z||q≤ϵ"
SUP,0.4115781126090404,"
G
||z||2 2σ"
SUP,0.41237113402061853,"
−G

−||z||2 2σ"
SUP,0.41316415543219664,"
+ G
||z||2 2σ"
SUP,0.41395717684377475,"
−G

−||z||2 2σ"
SUP,0.4147501982553529,"
(83) = 1"
SUP,0.41554321966693103,"2
sup
||z||q≤ϵ
2

2G
||z||2 2σ"
SUP,0.41633624107850914,"
−1

(84)"
SUP,0.41712926249008725,"= 2G
 max{ϵ, ϵd
1
2 −1"
SUP,0.41792228390166536,"q }
2σ

−1
(85)"
SUP,0.41871530531324347,"where 79 is due to lemma A.3; 80 is due to the consistency of sign of integrand function on Ω1
+ and
Ω1
−; 81 is due to the transformation formula of space coordinates; 82 is due to lemma E.1; 83 and
85 is due to the deﬁnition and central symmetry property of G as the cumulative density function of
standard normal distribution; 85 is due to 71."
SUP,0.4195083267248216,Under review as a conference paper at ICLR 2022
SUP,0.4203013481363997,"F
PROOF OF THEOREM 3.3"
SUP,0.4210943695479778,Proof. Recall the deﬁnition of lp-norm constraint set of probability measures
SUP,0.4218873909595559,"Dx,ϵ,q = {x′ + µ : ||x −x′||q ≤ϵ}
(86)
Note that
sup
ν∈Dx,ϵ,q
TV (µ, ν) =
sup
||x−x′||q≤ϵ
TV (x + µ, x′ + µ) =
sup
||z||q≤ϵ
TV (µ, z + µ)
(87)"
SUP,0.422680412371134,"where the ﬁrst equality is due to the deﬁnition of Dx,ϵ,q and the second equality is due to the trans-
lation invariance property of total variance distance. Next, compute the value of TV (µ, z + µ)."
SUP,0.4234734337827121,"Lemma F.1. K is a l1 norm ball centered at original point of radius r, then K ∩(z + K) = ∅if
and only if ||z||1 > 2r."
SUP,0.42426645519429024,"Proof. First, we prove the if part and assume ||z||1 > 2r. Consider arbitrarily taken x ∈(z + K),
i.e. ||x −z||1 ≤r. According to the triangular inequality with respect to l1 norm, we have
||x||1 = ||z −(x −z)||1 ≥||z||1 −||x −z||1 > 2r −r = r
(88)
which shows that x /∈K and therefore K ∩(z + K) = ∅.
Then we prove the only if part by using reduction to absurdity and assume ||z||1 ≤2r. Take y = 1"
SUP,0.42505947660586835,"2z,
then ||y||1 = 1"
SUP,0.42585249801744646,2||z||1 ≤r and ||y −z||1 = 1
SUP,0.42664551942902457,"2||z||1 ≤r which shows that y ∈K ∩(z + K) and
therefore K ∩(z + K) ̸= ∅which leads to a contradiction."
SUP,0.4274385408406027,"According to lemma F.1, we know that when

z
||z||q ≤ϵ, ||z||1 ≥2r
	
̸= ∅, we have"
SUP,0.4282315622521808,"sup
ν∈Dx,ϵ,q
TV (µ, ν) =
sup
||z||q≤ϵ
TV (µ, z + µ) = 1
(89)"
SUP,0.4290245836637589,Deﬁne ¯z = 2r
SUP,0.42981760507533706,"d
Pd
i=1 ei, and it’s easy to verify that ||¯z||1 = 2r and ||¯z||q = 2rd
1
q −1 for q > 1. Thus,
when ϵ > 2rd
1
q −1, we have
sup
ν∈Dx,ϵ,q
TV (µ, ν) =
sup
||z||q≤ϵ
TV (µ, z + µ) = 1
(90)"
SUP,0.43061062648691517,"G
PROOF OF THEOREM 3.4"
SUP,0.4314036478984933,"Proof. First, we introduce the lemmas below for the convenience of later proof."
SUP,0.4321966693100714,"Lemma G.1 (Volume Formula of d-dimensional spherical cap). The volume of a d-dimensional
hyperspherical cap of height h and radius r is given by:"
SUP,0.4329896907216495,"V = π
d−1"
RD,0.4337827121332276,2 rd
RD,0.4345757335448057,Γ( d+1 2 )
RD,0.43536875495638383,"Z arccos( r−h r
)"
RD,0.43616177636796194,"0
sind(t)dt
(91)"
RD,0.43695479777954005,"where we deﬁne h as the value shown in ﬁgure 4 and Γ (the gamma function) is given by Γ(z) =
R ∞
0
tz−1e−tdt."
RD,0.43774781919111816,"Lemma G.2 (Volume formula of d-dimensional Euclidean ball). The volume of d-dimensional Eu-
clidean ball of radius r is given by"
RD,0.43854084060269627,"V =
π
d
2 rd Γ( d"
RD,0.4393338620142744,"2 + 1)
(92)"
RD,0.4401268834258525,Recall the deﬁnition of lp-norm constraint set of probability measures
RD,0.4409199048374306,"Dx,ϵ,q = {x′ + µ : ||x −x′||q ≤ϵ}
(93)
Note that
sup
ν∈Dx,ϵ,q
TV (µ, ν) =
sup
||x−x′||q≤ϵ
TV (x + µ, x′ + µ) =
sup
||z||q≤ϵ
TV (µ, z + µ)
(94)"
RD,0.4417129262490087,"where the ﬁrst equality is due to the deﬁnition of Dx,ϵ,q and the second equality is due to the trans-
lation invariance property of total variance distance."
RD,0.4425059476605868,Under review as a conference paper at ICLR 2022
RD,0.44329896907216493,Figure 4: An example of a spherical cap in blue
RD,0.44409199048374304,"Lemma G.3. K is a l2 norm ball centered at original point of radius r, then K ∩(z + K) = ∅if
and only if ||z||2 > 2r."
RD,0.44488501189532115,"According to this lemma, we know that when q ≤2 and ϵ > 2r, we have"
RD,0.4456780333068993,"1 ≥
sup
||z||q≤ϵ
TV (µ, z + µ) ≥TV (µ, ϵe1 + µ) = Vol(K∆(ϵe1 + K))"
RD,0.4464710547184774,"2Vol(K)
= 1
(95)"
RD,0.44726407613005553,"where the last equality is due to ||ϵe1||2 = ϵ > 2r and applying lemma G.3. And when q > 2 and
ϵ > 2rd
1
q −1"
RD,0.44805709754163364,"2 , we have"
RD,0.44885011895321175,"1 ≥
sup
||z||q≤ϵ
TV (µ, z + µ) ≥TV (µ, ϵ d
1
q d
X"
RD,0.44964314036478986,"i=1
ei + µ) =
Vol(K∆( ϵ"
RD,0.45043616177636797,"d
1
q
Pd
i=1 ei + K))"
RD,0.4512291831879461,"2Vol(K)
= 1
(96)"
RD,0.4520222045995242,where the last equality is due to || ϵ
RD,0.4528152260111023,"d
1
q
Pd
i=1 ei||2 = ϵd
1
2 −1"
RD,0.4536082474226804,q > 2r and applying lemma G.3. Combin-
RD,0.4544012688342585,"ing the results for q ≤2 and q > 2, we have"
RD,0.45519429024583663,"sup
||z||q≤ϵ
TV (µ, z + µ) = 1 when ϵ > min{2r, 2rd
1
q −1"
RD,0.45598731165741474,"2 }
(97)"
RD,0.45678033306899285,"Next, consider the case when ϵ ≤min{2r, 2rd
1
q −1"
RD,0.45757335448057096,"2 }. Applying G.1, lemma G.2 and lemma A.3,
we have"
RD,0.45836637589214907,"sup
||z||q≤ϵ
TV (µ, z + µ)"
RD,0.4591593973037272,"=
sup
||z||q≤ϵ 1
2"
RD,0.4599524187153053,"Z 
1
Vol(K)Ix∈K −
1
Vol(K)Ix∈z+K
dx
(98)"
RD,0.4607454401268834,"=
sup
||z||q≤ϵ"
RD,0.46153846153846156,"1
2Vol(K)"
RD,0.4623314829500397,"Z
Ix∈K∆(z+K)dx =
sup
||z||q≤ϵ"
RD,0.4631245043616178,Vol(K∆(z + K))
RD,0.4639175257731959,2Vol(K)
RD,0.464710547184774,"=
sup
||z||q≤ϵ"
RD,0.4655035685963521,"Vol(K) −2π
d−1"
RD,0.4662965900079302,"2
rd"
RD,0.46708961141950833,Γ( d+1
RD,0.46788263283108644,"2
)
R arccos( ||z||2"
R,0.46867565424266455,"2r
)
0
sind(t)dt"
R,0.46946867565424266,"Vol(K)
=
sup
||z||q≤ϵ
1 −"
R,0.47026169706582077,"2π
d−1"
RD,0.4710547184773989,"2
rd"
RD,0.471847739888977,Γ( d+1
RD,0.4726407613005551,"2
)
R arccos( ||z||2"
R,0.4734337827121332,"2r
)
0
sind(t)dt"
R,0.4742268041237113,"Vol(K)
(99)"
R,0.47501982553528943,"=
sup
||z||q≤ϵ
1 −"
R,0.47581284694686754,"2π
d−1"
RD,0.4766058683584457,"2
rd"
RD,0.4773988897700238,Γ( d+1
RD,0.4781919111816019,"2
)
R arccos( ||z||2"
R,0.47898493259318004,"2r
)
0
sind(t)dt"
R,0.47977795400475814,"π
d
2
Γ( d"
R,0.48057097541633625,"2 +1)rd
=
sup
||z||q≤ϵ
1 −2Γ( d"
R,0.48136399682791436,2 + 1)
R,0.4821570182394925,"π
1
2 Γ( d+1 2 )"
R,0.4829500396510706,Z arccos( ||z||2
R,0.4837430610626487,"2r
)"
R,0.4845360824742268,"0
sind(t)dt (100)"
R,0.4853291038858049,= 1 −2Γ( d
R,0.486122125297383,2 + 1)
R,0.48691514670896113,"π
1
2 Γ( d+1 2 )"
R,0.48770816812053924,"Z arccos( max{ϵ,ϵd
1
2 −1"
R,0.48850118953211735,"q }
2r
)"
R,0.48929421094369546,"0
sind(t)dt
(101)"
R,0.49008723235527357,"where 114 is due to lemma A.3; 99 is due to lemma G.1; 100 is due to lemma G.2; 101 is due to 71.
Because of the computation difﬁculty (overﬂow), we have to simplify the term Γ( d"
R,0.4908802537668517,"2 +1)
Γ( d+1 2
) ."
R,0.4916732751784298,Under review as a conference paper at ICLR 2022
R,0.49246629659000796,"When d is even, assume d = 2k, k ∈N and note that Γ(1) = 1, Γ( 1"
R,0.49325931800158607,"2) = π
1
2 , then Γ( d"
R,0.4940523394131642,2 + 1)
R,0.4948453608247423,Γ( d+1
R,0.4956383822363204,2 ) = Γ(k + 1)
R,0.4964314036478985,Γ(k + 1
R,0.4972244250594766,"2) =
k!Γ(1)
Πk
i=1(i −1"
R,0.4980174464710547,2)Γ( 1
R,0.49881046788263284,"2) =
k!"
R,0.49960348929421095,"π
1
2 Πk
i=1(i −1"
R,0.500396510705789,"2)
=
(2k)!!"
R,0.5011895321173672,"π
1
2 (2k −1)!!
(102)"
R,0.5019825535289453,"Recall the Wallis integral lemma that when d is even
Z
π
2"
R,0.5027755749405234,"0
sind(t)dt =
Z
π
2"
R,0.5035685963521015,"0
cosd(t)dt = π"
R,0.5043616177636796,2 · (d −1)!!
R,0.5051546391752577,"d!!
,
d = 2k ∈N
(103) Thus, Γ( d"
R,0.5059476605868358,2 + 1)
R,0.5067406819984139,Γ( d+1
R,0.507533703409992,"2 ) =
(2k)!!"
R,0.5083267248215702,"π
1
2 (2k −1)!!
=
1 2π−1"
R,0.5091197462331483,2 · ( π
R,0.5099127676447264,2 · (2k−1)!!
R,0.5107057890563045,"(2k)!! )
=
1 2π−1 2 R π"
R,0.5114988104678826,"2
0 sin2k(t)dt
=
1 2π−1 2 R π"
R,0.5122918318794607,"2
0 sind(t)dt
(104)
When d is odd, assume d = 2k + 1, k ∈N and note that Γ(1) = 1, Γ( 1"
R,0.5130848532910388,"2) = π
1
2 , then Γ( d"
R,0.5138778747026169,2 + 1)
R,0.514670896114195,Γ( d+1
R,0.5154639175257731,2 ) = Γ(k + 3
R,0.5162569389373514,"2)
Γ(k + 1) = Πk
i=0(i + 1"
R,0.5170499603489295,2)Γ( 1
R,0.5178429817605076,"2)
k!Γ(1)
= π
1
2 Πk
i=0(i + 1"
R,0.5186360031720857,"2)
k!
= π
1
2 (2k + 1)!!"
R,0.5194290245836638,"2 · (2k)!!
(105)"
R,0.5202220459952419,"Recall the Wallis integral lemma that when d is odd
Z
π
2"
R,0.52101506740682,"0
sind(t)dt =
Z
π
2"
R,0.5218080888183981,"0
cosd(t)dt = (d −1)!!"
R,0.5226011102299762,"d!!
,
d = 2k + 1 ∈N
(106) Thus, Γ( d"
R,0.5233941316415543,2 + 1)
R,0.5241871530531325,Γ( d+1
R,0.5249801744647106,"2 ) = π
1
2 (2k + 1)!!"
R,0.5257731958762887,"2 · (2k)!!
=
1 2π−1"
R,0.5265662172878668,"2 · (
(2k)!!
(2k+1)!!)
=
1 2π−1 2 R π"
R,0.5273592386994449,"2
0 sin2k+1(t)dt
=
1 2π−1 2 R π"
R,0.528152260111023,"2
0 sind(t)dt
(107)
To sum up, for all d ∈N, we have Γ( d"
R,0.5289452815226011,2 + 1)
R,0.5297383029341792,Γ( d+1
R,0.5305313243457573,"2 ) =
1 2π−1 2 R π"
R,0.5313243457573354,"2
0 sind(t)dt
(108)"
R,0.5321173671689136,Then we avoid the computation of Γ( d
R,0.5329103885804917,"2 + 1), Γ( d+1"
R,0.5337034099920698,"2 ) and transfer it into the computation of an
integral. Applying formula 108, we have"
R,0.5344964314036479,"sup
||z||q≤ϵ
TV (µ, z + µ) = 1 −
1
R π"
R,0.535289452815226,"2
0 sind(t)dt"
R,0.5360824742268041,"Z arccos( max{ϵ,ϵd
1
2 −1"
R,0.5368754956383822,"q }
2r
)"
R,0.5376685170499603,"0
sind(t)dt
(109)"
R,0.5384615384615384,"H
PROOF OF THEOREM 3.5"
R,0.5392545598731165,Proof. Recall the deﬁnition of lp-norm constraint set of probability measures
R,0.5400475812846947,"Dx,ϵ,q = {x′ + µ : ||x −x′||q ≤ϵ}
(110)"
R,0.5408406026962728,Note that
R,0.5416336241078509,"sup
ν∈Dx,ϵ,q
TV (µ, ν) =
sup
||x−x′||q≤ϵ
TV (x + µ, x′ + µ) =
sup
||z||q≤ϵ
TV (µ, z + µ)
(111)"
R,0.542426645519429,"where the ﬁrst equality is due to the deﬁnition of Dx,ϵ,q and the second equality is due to the trans-
lation invariance property of total variance distance."
R,0.5432196669310071,"When ϵ ≥2r,
1 ≥
sup
||z||q≤ϵ
TV (µ, z + µ) ≥TV (µ, ϵe1 + µ) = 1
(112)"
R,0.5440126883425852,Under review as a conference paper at ICLR 2022
R,0.5448057097541633,"where the ﬁrst inequality is due to the fact that µ and z + µ are probability measures; the second
inequality is due to supp(µ) ∩supp(ϵe1 + µ) = ∅. Thus, in this case,"
R,0.5455987311657414,"sup
||z||q≤ϵ
TV (µ, z + µ) = 1
(113)"
R,0.5463917525773195,"When ϵ < 2r,"
R,0.5471847739888978,"sup
||z||q≤ϵ
TV (µ, z + µ)"
R,0.5479777954004759,"=
sup
||z||q≤ϵ 1
2"
R,0.548770816812054,"Z 
1
Vol(K)Ix∈K −
1
2Vol(K)Ix∈z+K
dx
(114)"
R,0.5495638382236321,"=
sup
||z||q≤ϵ"
R,0.5503568596352102,"1
2Vol(K)"
R,0.5511498810467883,"Z
Ix∈K∆(z+K)dx =
sup
||z||q≤ϵ"
R,0.5519429024583664,Vol(K∆(z + K))
R,0.5527359238699445,"2Vol(K)
=
sup
||z||q≤ϵ
1 −Vol(K ∩(z + K))"
R,0.5535289452815226,Vol(K)
R,0.5543219666931007,"=
sup
||z||q≤ϵ
1 −Πd
i=1(2r −|zi|)"
R,0.5551149881046789,"(2r)d
=
sup
||z||q≤ϵ
1 −Πd
i=1

1 −|zi|"
R,0.555908009516257,2r
R,0.5567010309278351,"
(115)"
R,0.5574940523394132,"First, we study typical cases when q = 1, 2, ∞. When q = 1, we need to solve the following
optimization problem
inf
||z||1≤ϵ Πd
i=1(2r −|zi|)
(116)"
R,0.5582870737509913,Here we use mathematical induction to prove that
R,0.5590800951625694,"inf
||z||1≤ϵ Πd
i=1(2r −|zi|) = (2r)d−1(2r −ϵ)
(117)"
R,0.5598731165741475,"When d = 2,"
R,0.5606661379857256,"inf
||z||1≤ϵ Πd
i=1(2r −|zi|) =
inf
|z1|+|z2|≤ϵ(2r −|z1|)(2r −|z2|) = inf
|z2|≤ϵ(2r −ϵ + |z2|)(2r −|z2|)"
R,0.5614591593973037,"=
inf
0≤z2≤ϵ(2r −ϵ + z2)(2r −z2) =
inf
0≤z2≤ϵ z2(ϵ −z2) + 2r(2r −ϵ) = 2r(2r −ϵ)"
R,0.5622521808088818,"Thus, induction hypothesis holds for d = 2. Then, assume induction hypothesis holds for d = n.
When d = n + 1,"
R,0.56304520222046,"inf
||z||1≤ϵ Πn+1
i=1 (2r −|zi|) =
inf
Pn+1
i=1 |zi|≤ϵ
Πn+1
i=1 (2r −|zi|) =
inf
Pn
i=1 |zi|≤ϵ−|zn+1|"
R,0.5638382236320381," 
Πn
i=1(2r −|zi|)

(2r −|zn+1|)"
R,0.5646312450436162,"=
inf
|zn+1|≤ϵ(2r)n−1(2r −ϵ + |zn+1|)(2r −|zn+1|)
(118)"
R,0.5654242664551943,"= (2r)n(2r −ϵ) = (2r)d−1(2r −ϵ)
(119)"
R,0.5662172878667724,"where 118 is due to the induction hypothesis when d = n; 119 is due to the induction hypothesis
when d = 2. Therefore, we have already proved that"
R,0.5670103092783505,"inf
||z||1≤ϵ Πd
i=1(2r −|zi|) = (2r)d−1(2r −ϵ), ∀d ∈N
(120)"
R,0.5678033306899286,"Plugging in this result, it follows that"
R,0.5685963521015067,"sup
||z||1≤ϵ
TV (µ, z + µ) =
sup
||z||1≤ϵ
1 −Πd
i=1(2r −|zi|)"
R,0.5693893735130848,"(2r)d
= 1 −(2r)d−1(2r −ϵ)"
R,0.5701823949246629,"(2r)d
= ϵ"
R,0.570975416336241,"2r
(121)"
R,0.5717684377478192,"When q = 2, we need to solve the following optimization problem"
R,0.5725614591593973,"inf
||z||2≤ϵ Πd
i=1(2r −|zi|)
(122)"
R,0.5733544805709754,"When d = 2,"
R,0.5741475019825535,"inf
||z||2≤ϵ Πd
i=1(2r −|zi|) =
inf
|z1|2+|z2|2≤ϵ2(2r −|z1|)(2r −|z2|) = inf
|z2|≤ϵ"
R,0.5749405233941316,"
2r −(ϵ2 −z2
2)
1
2

(2r −|z2|)"
R,0.5757335448057097,"=
inf
0≤z2≤ϵ"
R,0.5765265662172878,"
2r −(ϵ2 −z2
2)
1
2

(2r −z2)"
R,0.5773195876288659,Under review as a conference paper at ICLR 2022
R,0.578112609040444,"Deﬁne f(z2) = ln

2r −(ϵ2 −z2
2)
1
2

+ ln (2r −z2), then"
R,0.5789056304520223,"f ′(z2) = z2(ϵ2 −z2
2)−1 2"
R,0.5796986518636004,"2r −(ϵ2 −z2
2)
1
2 −
1
2r −z2
= 2rz2(ϵ2 −z2
2)−1"
R,0.5804916732751785,"2 −z2
2(ϵ2 −z2
2)−1"
R,0.5812846946867566,"2 −2r + (ϵ2 −z2
2)
1
2

2r −(ϵ2 −z2
2)
1
2

(2r −z2)
(123)
Deﬁne g(z2) = 2rz2(ϵ2 −z2
2)−1"
R,0.5820777160983347,"2 −z2
2(ϵ2 −z2
2)−1"
R,0.5828707375099128,"2 −2r + (ϵ2 −z2
2)
1
2 , then"
R,0.5836637589214909,"g′(z2) = (2z3
2 −3ϵ2z2 + 2rϵ2)(ϵ2 −z2
2)−3"
R,0.584456780333069,"2
(124)"
R,0.5852498017446471,"Deﬁne h(z2) = 2z3
2 −3ϵ2z2 + 2rϵ2, then h′(z2) = 6z2
2 −3ϵ2 = 6(z2 −
ϵ
√"
R,0.5860428231562252,"2)(z2 +
ϵ
√"
R,0.5868358445678034,"2). Thus,
when 0 ≤z2 ≤
ϵ
√"
R,0.5876288659793815,"2, h′(x) ≤0; when
ϵ
√"
R,0.5884218873909596,"2 < z2 ≤ϵ, h′(x) > 0. Thus, the minimum value of h(x)"
R,0.5892149088025377,"on interval [0, ϵ] is h( ϵ
√"
R,0.5900079302141158,"2) =
√"
R,0.5908009516256939,"2ϵ2(
√"
R,0.591593973037272,"2r −ϵ). Therefore, function f(z2) behaves differently when"
R,0.5923869944488501,"0 < ϵ ≤
√"
R AND WHEN,0.5931800158604282,"2r and when
√"
R AND WHEN,0.5939730372720063,2r < ϵ < 2r.
R AND WHEN,0.5947660586835845,"When 0 < ϵ ≤
√"
R AND WHEN,0.5955590800951626,"2r, h(z2) ≥h( ϵ
√"
R AND WHEN,0.5963521015067407,"2) =
√"
R AND WHEN,0.5971451229183188,"2ϵ2(
√"
R AND WHEN,0.5979381443298969,"2r −ϵ) ≥0 on interval [0, ϵ] and therefore"
R AND WHEN,0.598731165741475,"g′(z2) = h(z2)(ϵ2 −z2
2)−3"
R AND WHEN,0.5995241871530531,"2 ≥0. Note that g(0) = ϵ −2r < 0, g( ϵ
√"
R AND WHEN,0.6003172085646312,"2) = 0, g(ϵ−) = ∞and
therefore f ′(z2) ≤0 when 0 ≤z2 ≤
ϵ
√"
R AND WHEN,0.6011102299762093,"2 while f ′(z2) > 0 when
ϵ
√"
R AND WHEN,0.6019032513877874,"2 < z2 ≤ϵ. Thus, f(z2) takes
its minimum when z2 =
ϵ
√"
R AND WHEN,0.6026962727993656,"2. In this case,"
R AND WHEN,0.6034892942109437,"inf
0≤z2≤ϵ"
R AND WHEN,0.6042823156225218,"
2r −(ϵ2 −z2
2)
1
2

(2r −z2) = (2r −
ϵ
√"
R AND WHEN,0.6050753370340999,"2)2
(125)"
R AND WHEN,0.605868358445678,"When
√"
R AND WHEN,0.6066613798572561,"2r < ϵ < 2r, we have h(0) = 2rϵ2 > 0, h( ϵ
√"
R AND WHEN,0.6074544012688342,"2) =
√"
R AND WHEN,0.6082474226804123,"2ϵ2(
√"
R AND WHEN,0.6090404440919904,"2r −ϵ) < 0, h(ϵ) =
ϵ2(2r −ϵ) > 0. Assume h(t1) = h(t2) = 0, 0 < t1 <
ϵ
√"
R AND WHEN,0.6098334655035687,"2 < t2 < ϵ, then when 0 ≤z2 ≤t1
or t2 ≤z2 ≤ϵ, h(z2) ≥0 and when t1 < z2 < t2, h(z2) < 0. Therefore, g′(z2) ≥0 when
0 ≤z2 ≤t1 or t2 ≤z2 ≤ϵ; g′(z2) < 0 when t1 < z2 < t2. Note that g(z2) = 0 ⇐⇒(2z2
2 −"
R AND WHEN,0.6106264869151468,"ϵ2)
 
2(z2−r)2+2r2−ϵ2
= 0, therefore when 0 ≤z2 ≤r−
q ϵ2"
R AND WHEN,0.6114195083267249,"2 −r2 or
ϵ
√"
R AND WHEN,0.612212529738303,"2 ≤z2 ≤r+
q ϵ2"
R AND WHEN,0.6130055511498811,"2 −r2,"
R AND WHEN,0.6137985725614592,"g(z2) ≤0; when r −
q ϵ2"
R AND WHEN,0.6145915939730373,"2 −r2 < z2 <
ϵ
√"
R AND WHEN,0.6153846153846154,"2 or r +
q ϵ2"
R AND WHEN,0.6161776367961935,"2 −r2 < z2 < ϵ, g(z2) > 0. Thus, when"
R AND WHEN,0.6169706582077716,"0 ≤z2 ≤r −
q ϵ2"
R AND WHEN,0.6177636796193497,"2 −r2 or
ϵ
√"
R AND WHEN,0.6185567010309279,"2 ≤z2 ≤r +
q ϵ2"
R AND WHEN,0.619349722442506,"2 −r2, f ′(x) ≤0; when r −
q ϵ2"
R AND WHEN,0.6201427438540841,"2 −r2 < z2 <
ϵ
√"
R AND WHEN,0.6209357652656622,"2
or r +
q ϵ2"
R AND WHEN,0.6217287866772403,"2 −r2 < z2 < ϵ, f ′(x) > 0. Thus, f(z2) takes its minimum when z2 = r −
q ϵ2 2 −r2"
R AND WHEN,0.6225218080888184,"or z2 = r +
q ϵ2"
R AND WHEN,0.6233148295003965,"2 −r2. In this case,"
R AND WHEN,0.6241078509119746,"inf
0≤z2≤ϵ"
R AND WHEN,0.6249008723235527,"
2r −(ϵ2 −z2
2)
1
2

(2r −z2) =

r − r ϵ2"
R AND WHEN,0.6256938937351308,"2 −r2

r + r ϵ2"
R AND WHEN,0.626486915146709,"2 −r2

= 2r2 −ϵ2"
R AND WHEN,0.6272799365582871,"2
(126)"
R AND WHEN,0.6280729579698652,"inf
||z||2≤ϵ Πd
i=1(2r−|zi|) =
inf
Pn+1
i=1 z2
i ≤ϵ2 Πn+1
i=1 (2r−|zi|) =
inf
Pn
i=1 z2
i ≤ϵ2−z2
n+1"
R AND WHEN,0.6288659793814433,"
Πn
i=1(2r−|zi|)

(2r−|zn+1|)"
R AND WHEN,0.6296590007930214,"(127)
By then, we have understand clearly the optimization problem when d = 2."
R AND WHEN,0.6304520222045995,"Then, consider the case when d = 3. When d = 3,"
R AND WHEN,0.6312450436161776,"inf
||z||2≤ϵ Πd
i=1(2r −|zi|) =
inf
z2
1+z2
2+z2
3≤ϵ2(2r −|z1|)(2r −|z2|)(2r −|z3|)
(128)"
R AND WHEN,0.6320380650277557,"When 0 < ϵ ≤
√"
R AND WHEN,0.6328310864393338,"2r, assume the optimal point is z∗. We will prove that each coordinate of z∗has
the same value. Here we use reduction to absurdity, and wlog assume z∗
1 ̸= z∗
2. By ﬁxing the value
of z∗
3, the optimization problem 122 is equivalent to"
R AND WHEN,0.6336241078509119,"inf
z2
1+z2
2≤ϵ2−(z∗
3 )2(2r −|z1|)(2r −|z2|)
(129)"
R AND WHEN,0.63441712926249,"And (z∗
1, z∗
2) should be an optimal point of above problem. Note that ϵ2 −(z∗
3)2 ≤ϵ2 ≤2r2 and
applying 125, we know that z∗
1 = z∗
2 which is a contradiction. Thus, z∗
1 = z∗
2 = z∗
3 = c. And"
R AND WHEN,0.6352101506740682,"inf
||z||2≤ϵ Πn
i=1(2r −|zi|) = inf
c≤
ϵ
√"
R AND WHEN,0.6360031720856463,"3
(2r −c)3 =

2r −
ϵ
√ 3"
R AND WHEN,0.6367961934972244,"3
(130)"
R AND WHEN,0.6375892149088025,Under review as a conference paper at ICLR 2022
R AND WHEN,0.6383822363203806,"When
√"
R AND WHEN,0.6391752577319587,"2r < ϵ ≤
√"
R AND WHEN,0.6399682791435368,"3r, it’s obvious that the optimal point z∗of optimization problem 128 must lie
on the boundary of feasible region, i.e. (z∗
1)3 + (z∗
2)3 + (z∗
3)3 = ϵ2. Wlog, assume (z∗
3)3 ≥ϵ2"
AND,0.640761300555115,"3 and
(z∗
1)2 + (z∗
2)2 ≤2ϵ2"
AND,0.6415543219666932,"3 ≤2r3. By ﬁxing the value of z∗
3 and following similar deduction procedure as
above we know that z∗
1 = z∗
2 = c∗, where c∗is the optimal point of following optimization problem."
AND,0.6423473433782713,"inf
0≤c≤
ϵ
√"
AND,0.6431403647898494,"3
(2r −c)2(2r −
p"
AND,0.6439333862014275,"ϵ2 −2c2)
(131)"
AND,0.6447264076130056,"Deﬁne f(x) = 2 ln (2r −x) + ln (2r −
√"
AND,0.6455194290245837,"ϵ2 −2x2) where 0 ≤x ≤
ϵ
√"
AND,0.6463124504361618,"3, then"
AND,0.6471054718477399,"f ′(x) =
2(3x2 −2rx −ϵ2 + 2r
√"
AND,0.647898493259318,"ϵ2 −2x2)
(x −2r)(2r −
√"
AND,0.6486915146708961,"ϵ2 −2x2)
√"
AND,0.6494845360824743,"ϵ2 −2x2
(132)"
AND,0.6502775574940524,"It’s obvious that the denominator of f ′(x) is negative. As for the numerator, deﬁne g(x) = 3x2 −
2rx −ϵ2 where 0 ≤x ≤
ϵ
√"
NOTE THAT,0.6510705789056305,3. Note that
NOTE THAT,0.6518636003172086,"g(x) ≤max
n
g(0), g
 ϵ
√ 3"
NOTE THAT,0.6526566217287867,"o
= max
n
−ϵ2, −2rϵ
√ 3"
NOTE THAT,0.6534496431403648,"o
≤0
(133)"
NOTE THAT,0.6542426645519429,"Thus, we have the following equivalent relationship"
NOTE THAT,0.655035685963521,"3x2 −2rx −ϵ2 + 2r
p"
NOTE THAT,0.6558287073750991,ϵ2 −2x2 ≤0
NOTE THAT,0.6566217287866772,"⇐⇒3x2 −2rx −ϵ2 ≤−2r
p"
NOTE THAT,0.6574147501982553,ϵ2 −2x2 ≤0
NOTE THAT,0.6582077716098335,"⇐⇒(3x2 −2rx −ϵ2)2 ≥
 
−2r
p"
NOTE THAT,0.6590007930214116,ϵ2 −2x22 ≥0
NOTE THAT,0.6597938144329897,⇐⇒(3x2 −ϵ2)(3x2 −4rx + 4r2 −ϵ2) ≥0
NOTE THAT,0.6605868358445678,⇐⇒3x2 −4rx + 4r2 −ϵ2 ≤0 ⇐⇒
NOTE THAT,0.6613798572561459,"


 

"
NOTE THAT,0.662172878667724,"∅
when
√"
NOTE THAT,0.6629659000793021,"2r < ϵ ≤2 r 2
3r"
NOTE THAT,0.6637589214908802,"2r −
√"
NOTE THAT,0.6645519429024583,3ϵ2 −8r2
NOTE THAT,0.6653449643140364,"3
≤x ≤2r +
√"
NOTE THAT,0.6661379857256146,3ϵ2 −8r2
NOTE THAT,0.6669310071371927,"3
when 2 r"
NOTE THAT,0.6677240285487708,"2
3r < ϵ ≤
√"
R,0.6685170499603489,3r
R,0.669310071371927,where the last equivalent relationship is due to the discriminant of the quadratic equation 3x2 −
R,0.6701030927835051,"4rx+4r2 −ϵ2 is ∆= 4(3ϵ2 −8r2). Therefore, when
√"
R,0.6708961141950832,"2r < ϵ ≤2
q"
R,0.6716891356066613,"2
3r, f ′(x) ≤0, ∀0 ≤x ≤
ϵ
√"
R,0.6724821570182395,"3
and hence the optimal point c∗in the optimization problem 131 takes value
ϵ
√"
R,0.6732751784298177,"3, whereas when"
Q,0.6740681998413958,"2
q"
Q,0.6748612212529739,"2
3r < ϵ ≤
√"
Q,0.675654242664552,"3r, f ′(x) ≤0 for 0 ≤x ≤2r−
√"
Q,0.6764472640761301,3ϵ2−8r2
Q,0.6772402854877082,"3
, 2r+
√"
Q,0.6780333068992863,3ϵ2−8r2
Q,0.6788263283108644,"3
≤x ≤
ϵ
√"
Q,0.6796193497224425,3 and f ′(x) > 0
Q,0.6804123711340206,"for 2r−
√"
Q,0.6812053925455988,3ϵ2−8r2
Q,0.6819984139571769,"3
≤x ≤2r+
√"
Q,0.682791435368755,3ϵ2−8r2
Q,0.6835844567803331,"3
and note that f( 2r−
√"
Q,0.6843774781919112,3ϵ2−8r2
Q,0.6851704996034893,"3
) < f( ϵ
√"
Q,0.6859635210150674,3) hence the optimal
Q,0.6867565424266455,"point c∗in the optimization problem takes value 2r−
√"
Q,0.6875495638382236,3ϵ2−8r2
Q,0.6883425852498017,"3
. To sum up, when
√"
Q,0.6891356066613799,"2r < ϵ ≤2
q 2
3r,"
Q,0.689928628072958,"the optimal point z∗of optimization problem 128 satisﬁes z∗
1 = z∗
2 = z∗
3 =
ϵ
√"
Q,0.6907216494845361,"3. And when 2
q"
Q,0.6915146708961142,"2
3r < ϵ ≤
√"
Q,0.6923076923076923,"3r, the optimal point z∗of optimization problem 128 satisﬁes z∗
1 = z∗
2 = 2r−
√"
Q,0.6931007137192704,3ϵ2−8r2
Q,0.6938937351308485,"3
, z∗
3 = 4r+
√"
Q,0.6946867565424266,3ϵ2−8r2
Q,0.6954797779540047,"3
or one of its permutations."
Q,0.6962727993655828,"When
√"
Q,0.697065820777161,"3r < ϵ < 2r, similarly we have (z∗
1)3 + (z∗
2)3 + (z∗
3)3 = ϵ2. If there exists 1 ≤i ≤3 such
that (z∗
i )2 ≥ϵ2 −2r2, wlog assume (z∗
3)2 ≥ϵ2 −2r2. By substituting the value range of x from
[0,
ϵ
√"
Q,0.6978588421887391,"3] into [0, r], following similar deduction procedure and noticing that f( 2r−
√"
Q,0.6986518636003172,3ϵ2−8r2
Q,0.6994448850118953,"3
) < f(r),"
Q,0.7002379064234734,"we know that the optimal point z∗in this case satisﬁes z∗
1 = z∗
2 = 2r−
√"
Q,0.7010309278350515,3ϵ2−8r2
Q,0.7018239492466296,"3
, z∗
3 = 4r+
√"
Q,0.7026169706582077,3ϵ2−8r2
Q,0.7034099920697859,"3
or one of its permutations. On the other hand, if (z∗
i )2 < ϵ2 −2r2 for all 1 ≤i ≤3, then"
Q,0.704203013481364,"(z∗
1)2 + (z∗
2)2 = ϵ2 −(z∗
3)2 > 2r2. Applying 126 and taking z∗
1 = r −
q"
Q,0.7049960348929422,"ϵ2−(z∗
3 )2"
Q,0.7057890563045203,"2
−r2, z∗
2 = r +
q"
Q,0.7065820777160984,"ϵ2−(z∗
3 )2"
Q,0.7073750991276765,"2
−r2, we know the optimization problem is equivalent to"
Q,0.7081681205392546,"inf
0≤z3<
√"
Q,0.7089611419508327,ϵ2−2r2
Q,0.7097541633624108,"
2r2 −ϵ2 −z2
3
2"
Q,0.7105471847739889,"
(2r −z3)
(134)"
Q,0.711340206185567,Under review as a conference paper at ICLR 2022
Q,0.7121332275971451,"According to monotonicity analysis of the cubic function above, the optimal point z∗
3 is either
2r−
√"
Q,0.7129262490087233,3ϵ2−8r2
OR,0.7137192704203014,"3
or
√"
OR,0.7145122918318795,"ϵ2 −2r2. And it’s easy to verify that f( 2r−
√"
OR,0.7153053132434576,3ϵ2−8r2
OR,0.7160983346550357,"3
) < f(
√"
OR,0.7168913560666138,"ϵ2 −2r2) and
therefore z∗
3 = 2r−
√"
OR,0.7176843774781919,3ϵ2−8r2
OR,0.71847739888977,"3
. However, (z∗
2)2 > ϵ2 −2r2 which leads to a contradiction."
OR,0.7192704203013481,"In summary, considering the case d = 3, when 0 < ϵ ≤2
q"
OR,0.7200634417129262,"2
3r, the optimal point z∗of original"
OR,0.7208564631245044,"optimization problem satisﬁes z∗
1 = z∗
2 = z∗
3 =
ϵ
√"
OR,0.7216494845360825,"3 and the optimal value is (2r −
ϵ
√"
OR,0.7224425059476606,"3)3 and when
√"
OR,0.7232355273592387,"3r < ϵ < 2r, the optimal point z∗, the optimal point z∗of original optimization problem satisﬁes
z∗
1 = z∗
2 = 2r−
√"
OR,0.7240285487708168,3ϵ2−8r2
OR,0.7248215701823949,"3
, z∗
3 = 4r+
√"
OR,0.725614591593973,3ϵ2−8r2
OR,0.7264076130055511,"3
or one of its permutations."
OR,0.7272006344171292,"Next, consider the general case when d = n ≥4. In the ﬁrst place, we point out and prove two
useful properties of the optimal point z∗which help simplify our later discussion a lot."
OR,0.7279936558287073,• All coordinates of optimal point z∗takes at most two different values.
OR,0.7287866772402855,"• If the coordinates of an optimal point z∗takes exactly two different values c1 and c2, then
the number of coordinates equal to c1 must be n −1 or 1."
OR,0.7295796986518636,"Proof. On one hand, by using reduction to absurdity, wlog assume z∗
1, z∗
2, z∗
3 take three different
values. Fixing the value of the other n −3 coordinates, we know that (z∗
1, z∗
2, z∗
3) is the optimal
point of a special case of original problem when d = 3. And note that for all the optimal points of
d = 3, there must exist two coordinates taking the same value, which leads to a contradiction. Thus,
the ﬁrst property is satisﬁed.
On the other hand, similarly, by applying reduction to absurdity, wlog assume z∗
1 = z∗
2 = c1 and
z∗
3 = z∗
4 = c2 where c1 ̸= c2. Fixing z∗
2, z∗
4 and the value of the other n−4 coordinates and aware of
the fact that (z∗
1)2 + (z∗
3)2 ≤ϵ2"
OR,0.7303727200634417,"2 < 2r2, we know that (z∗
1, z∗
3) is the optimal point of a special case
of original problem when d = 2, ϵ <
√"
OR,0.7311657414750198,"2r and therefore z∗
1 = z∗
3, which leads to a contradiction.
Thus, the second property is satisﬁed."
OR,0.7319587628865979,"Using the two properties above, we know that the optimal point z∗has only two possible forms:
z∗=
  ϵ
√n, · · · ,
ϵ
√n

and z∗=
 
c, · · · , c,
p"
OR,0.732751784298176,"ϵ2 −(n −1)c2
or one of its permutations where"
OR,0.7335448057097541,"0 ≤c ≤
ϵ
√n−1, c ̸=
ϵ
√n, which can be uniﬁed into one form: z∗=
 
c, · · · , c,
p"
OR,0.7343378271213322,ϵ2 −(n −1)c2
OR,0.7351308485329104,"or one of its permutations where 0 ≤c ≤
ϵ
√n−1. Thus, the original problem can be simpliﬁed into
following optimization problem with one degree of freedom:"
OR,0.7359238699444886,"inf
0≤c≤
ϵ
√n−1
(2r −c)n−1 
2r −
p"
OR,0.7367168913560667,"ϵ2 −(n −1)c2
(135)"
OR,0.7375099127676448,"Deﬁne f(x) = (n −1) ln (2r −x) + ln (2r −
p"
OR,0.7383029341792229,"ϵ2 −(n −1)x2) where 0 ≤x ≤
ϵ
√n−1, then"
OR,0.739095955590801,"f ′(x) =
(n −1)
 
nx2 −2rx −ϵ2 + 2r
p"
OR,0.7398889770023791,ϵ2 −(n −1)x2
OR,0.7406819984139572,"(x −2r)
 
2r −
p"
OR,0.7414750198255353,ϵ2 −(n −1)x2p
OR,0.7422680412371134,"ϵ2 −(n −1)x2 , where 0 ≤x <
ϵ
√n −1
(136)"
OR,0.7430610626486915,"It’s obvious that the denominator of f ′(x) is negative. As for the numerator, deﬁne g(x) = nx2 −
2rx −ϵ2 where 0 ≤x ≤
ϵ
√n−1. Note that"
OR,0.7438540840602696,"g(x) ≤min

g(0), g

ϵ
√n −1"
OR,0.7446471054718478,"
= max

0, ϵ(ϵ −2√n −1r) n −1"
OR,0.7454401268834259,"
≤0
(137)"
OR,0.746233148295004,Under review as a conference paper at ICLR 2022
OR,0.7470261697065821,"where the last inequality is due to ϵ < 2r < 2√n −1r. Thus, when 0 ≤x ≤
ϵ
√n−1,"
OR,0.7478191911181602,"nx2 −2rx −ϵ2 + 2r
p"
OR,0.7486122125297383,ϵ2 −(n −1)x2 ≤0
OR,0.7494052339413164,"⇐⇒nx2 −2rx −ϵ2 ≤−2r
p"
OR,0.7501982553528945,ϵ2 −(n −1)x2 ≤0
OR,0.7509912767644726,"⇐⇒(nx2 −2rx −ϵ2)2 ≥
 
−2r
p"
OR,0.7517842981760507,ϵ2 −(n −1)x22
OR,0.7525773195876289,⇐⇒(nx2 −ϵ2)(nx2 −4rx + 4r2 −ϵ2) ≥0
OR,0.753370340999207,"⇐⇒

x −
ϵ
√n"
OR,0.7541633624107851,"
(nx2 −4rx + 4r2 −ϵ2) ≥0 ⇐⇒"
OR,0.7549563838223632,"



"
OR,0.7557494052339413,"


"
OR,0.7565424266455194,"x ≥
ϵ
√n
when 0 < ϵ < 2 r n −1 n
r"
OR,0.7573354480570975,"x ≥
ϵ
√n or 2r −
p"
OR,0.7581284694686756,nϵ2 −4(n −1)r2
OR,0.7589214908802537,"n
≤x ≤2r +
p"
OR,0.7597145122918318,nϵ2 −4(n −1)r2
OR,0.76050753370341,"n
when 2 r n −1"
OR,0.7613005551149881,"n
r ≤ϵ < 2r"
OR,0.7620935765265662,"where the last equivalence relationship is due to the discriminant of the quadratic equation nx2 −
4rx + 4r2 −ϵ2 = 0 is"
OR,0.7628865979381443,"∆= 4

nϵ2 −4(n −1)r2
< 0 ⇐⇒0 < ϵ < 2 r n −1"
OR,0.7636796193497224,"n
r
(138)"
OR,0.7644726407613005,"Thus, if 0 < ϵ < 2
q n−1"
OR,0.7652656621728786,"n r, then f ′(x) ≥0 when
ϵ
√n ≤x ≤
ϵ
√n−1 and f ′(x) < 0 when
0 ≤x <
ϵ
√n. Thus, f(x) takes its minimum when x =
ϵ
√n and therefore c∗=
ϵ
√n."
OR,0.7660586835844568,"If 2
q n−1"
OR,0.7668517049960349,"n r ≤ϵ < 2r, then f ′(x) ≥0 when
2r−√"
OR,0.767644726407613,nϵ2−4(n−1)r2
OR,0.7684377478191912,"n
≤x ≤
2r+√"
OR,0.7692307692307693,"nϵ2−4(n−1)r2 n
or"
OR,0.7700237906423474,"ϵ
√n ≤x ≤
ϵ
√n−1 and f ′(x) < 0 when 0 ≤x <
2r−√"
OR,0.7708168120539255,nϵ2−4(n−1)r2
OR,0.7716098334655036,"n
or
2r+√"
OR,0.7724028548770817,"nϵ2−4(n−1)r2 n
<"
OR,0.7731958762886598,"x <
ϵ
√n. In this case, f(x) takes its minimum when x =
2r−√"
OR,0.7739888977002379,nϵ2−4(n−1)r2
OR,0.774781919111816,"n
or x =
ϵ
√n. For the"
OR,0.7755749405233942,"convenience of analysis, assume t =
ϵ
2r,
q n−1"
OR,0.7763679619349723,"n
≤t < 1 and it follows that"
OR,0.7771609833465504,"ef(
ϵ
√n ) = (2r)n
1 −
t
√n"
OR,0.7779540047581285,"n
(139)"
OR,0.7787470261697066,"ef
 
2r−√"
OR,0.7795400475812847,nϵ2−4(n−1)r2
OR,0.7803330689928628,"n

= (2r)n
(n −1) +
p"
OR,0.7811260904044409,"nt2 −(n −1)
n"
OR,0.781919111816019,"n−11 −
p"
OR,0.7827121332275971,nt2 −(n −1) n  (140)
OR,0.7835051546391752,"We can prove that there exists tn ∈
hq n−1"
OR,0.7842981760507534,"n , 1

such that c∗=
ϵ
√n when 2
q n−1"
OR,0.7850911974623315,n r ≤ϵ ≤2tnr
OR,0.7858842188739096,"and c∗=
2r−√"
OR,0.7866772402854877,nϵ2−4(n−1)r2
OR,0.7874702616970658,"n
when 2tnr < ϵ < 2r while tn converge to 1 at an exponential rate as
shown in ﬁgure 5."
OR,0.7882632831086439,"In conclusion, for the case d = n ≥4, when 0 < ϵ ≤2tnr, c∗=
ϵ
√n and therefore"
OR,0.789056304520222,"inf
||z||2≤ϵ Πn
i=1(2r−|zi|) = (2r−c∗)n−1 
2r−
p"
OR,0.7898493259318001,"ϵ2 −(n −1)(c∗)2
=

2r−ϵ n
1
2"
OR,0.7906423473433782,"n
=

2r−ϵ d
1
2 d"
OR,0.7914353687549563,"(141)
Plugging in this result, it follows that"
OR,0.7922283901665345,"sup
||z||2≤ϵ
TV (µ, z+µ) =
sup
||z||2≤ϵ
1−Πd
i=1(2r −|zi|)"
OR,0.7930214115781126,"(2r)d
= 1−"
OR,0.7938144329896907," 
2r −
ϵ"
OR,0.7946074544012688,"d
1
2
d"
OR,0.7954004758128469,"(2r)d
= 1−

1−
ϵ"
D,0.796193497224425,"2d
1
2 r"
D,0.7969865186360032,"d
(142)"
D,0.7977795400475813,Under review as a conference paper at ICLR 2022
D,0.7985725614591594,"Figure
5:
Graphs
of
functions
f1(t)
=
 
1
−
t
√n
n, f2(t)
=
 (n−1)+√"
D,0.7993655828707376,"nt2−(n−1)
n
n−1 1−√"
D,0.8001586042823157,nt2−(n−1)
D,0.8009516256938938,"n

when n = 4, 16, 64 from left to right.
Accord-"
D,0.8017446471054719,"ing to the ﬁgure, on interval
hq n−1"
D,0.80253766851705,"n , 1
i
, f2(t) is greater than f1(t) at ﬁrst and then f2(t) exceeds"
D,0.8033306899286281,"f1(t). Furthermore, as n increases, the horizontal coordinate of the intersection point converge to 1,
which can be seen intuitively from the ﬁgure above."
D,0.8041237113402062,"and when 2tnr < ϵ < 2r, c∗=
2r−√"
D,0.8049167327517843,nϵ2−4(n−1)r2
D,0.8057097541633624,"n
and therefore"
D,0.8065027755749405,"inf
||z||2≤ϵ Πn
i=1(2r −|zi|) = (2r −c∗)n−1 
2r −
p"
D,0.8072957969865187,ϵ2 −(n −1)(c∗)2
D,0.8080888183980968,"=
2(n −1)r +
p"
D,0.8088818398096749,nϵ2 −4(n −1)r2 n
D,0.809674861221253,"n−12r −
p"
D,0.8104678826328311,nϵ2 −4(n −1)r2 n 
D,0.8112609040444092,"=
2(d −1)r +
p"
D,0.8120539254559873,dϵ2 −4(d −1)r2 n
D,0.8128469468675654,"n−12r −
p"
D,0.8136399682791435,dϵ2 −4(d −1)r2 d 
D,0.8144329896907216,"Plugging in this result, it follows that"
D,0.8152260111022998,"sup
||z||2≤ϵ
TV (µ, z + µ) =
sup
||z||2≤ϵ
1 −Πd
i=1(2r −|zi|) (2r)d = 1 −"
D,0.8160190325138779, 2(d−1)r+√
D,0.816812053925456,dϵ2−4(d−1)r2
D,0.8176050753370341,"d
d−1 2r−√"
D,0.8183980967486122,"dϵ2−4(d−1)r2 d
 (2r)d"
D,0.8191911181601903,"= 1 −
d −1 +
p d( ϵ"
D,0.8199841395717684,"2r)2 −d + 1
d"
D,0.8207771609833465,"d−11 −
p d( ϵ"
D,0.8215701823949246,2r)2 −d + 1 d 
D,0.8223632038065027,"When q = ∞, it’s easy to verify that"
D,0.8231562252180809,"inf
||z||∞≤ϵ Πd
i=1(2r −|zi|) = (2r −ϵ)d
(143)"
D,0.823949246629659,"Plugging in the formula above, it follows"
D,0.8247422680412371,"sup
||z||∞≤ϵ
TV (µ, z + µ) =
sup
||z||∞≤ϵ
1 −Πd
i=1(2r −|zi|)"
D,0.8255352894528152,"(2r)d
= 1 −(2r −ϵ)d"
D,0.8263283108643933,"(2r)d
= 1 −

1 −ϵ"
R,0.8271213322759714,2r
R,0.8279143536875495,"d
(144)"
R,0.8287073750991277,"I
PROOF OF THEOREM 3.6"
R,0.8295003965107058,Proof. Recall the deﬁnition of lp-norm constraint set of probability measures
R,0.830293417922284,"Dx,ϵ,q = {x′ + µ : ||x −x′||q ≤ϵ}
(145)"
R,0.8310864393338621,"Assume Dx,ϵ,q ⊆Dx,ξ(ϵ), then"
R,0.8318794607454402,"ξ(ϵ) ≥
sup
ν∈Dx,ϵ,q
TV (µ, ν) =
sup
||x−x′||q≤ϵ
TV (x+µ, x′+µ) =
sup
||z||q≤ϵ
TV (µ, z+µ) ≥TV (µ, ϵe1+µ) (146)"
R,0.8326724821570183,Under review as a conference paper at ICLR 2022
R,0.8334655035685964,"which indicates that TV (µ, ϵe1+µ) provides a lower bound for ξ(ϵ). Thus, we only need to estimate
the value of TV (µ, ϵe1 + µ). According to lemma A.3, we have"
R,0.8342585249801745,"TV (µ, ϵe1 + µ) = Vol(K∆(ϵe1 + K))"
R,0.8350515463917526,"2Vol(K)
= 1 −Vol(K ∩(ϵe1 + K))"
R,0.8358445678033307,"Vol(K)
Note that
K ∩(ϵe1 + K)"
R,0.8366375892149088,"=
n
x ∈Rd|x1|p + · · · + |xd|p ≤rp, |x1 −ϵ|p + |x2|p + · · · + |xd|p ≤rpo"
R,0.8374306106264869,"=
n
x ∈Rdϵ −(rp −(|x2|p + · · · + |xd|p|))
1
p ≤x1 ≤(rp −(|x2|p + · · · + |xd|p|))
1
p
o"
R,0.838223632038065,"=
n
x ∈Rdϵ −(rp −(|x2|p + · · · + |xd|p))
1
p ≤x1 ≤ϵ 2"
R,0.8390166534496432,"o
∪
n
x
 ϵ"
R,0.8398096748612213,"2 ≤x1 ≤(rp −(|x2|p + · · · + |xd|p|))
1
p
o"
R,0.8406026962727994,":= Ω1 ∪Ω2 where Ω1 ∩Ω2 = ∅
It’s easy to verify that Vol(Ω1) = Vol(Ω2) according to integration by substitution and therefore
Vol(K ∩(ϵe1 + K)) = 2Vol(Ω2). To estimate the volume of Ω2, we ﬁrst introduce several lemmas
below for the convenience of later discussion."
R,0.8413957176843775,"Lemma I.1 (Volume formula of d-dimensional lp norm ball). The volume of d-dimensional lp ball
of radius r is given by"
R,0.8421887390959556,"V (d)
p
= (2r)d Γ(1 + 1 p)d"
R,0.8429817605075337,Γ(1 + d
R,0.8437747819191118,"p)
(147)"
R,0.8445678033306899,"Lemma I.2. The d-dimensional lp ball of volume 1 has radius about
d
1
p"
R,0.845360824742268,"2(pe)
1
p Γ(1+ 1 p )."
R,0.8461538461538461,"Proof. When dimension d is big enough, we can obtain an asymptotic volume estimation of lp norm
ball with radius r."
R,0.8469468675654243,"V (d)
p
= (2r)d Γ(1 + 1 p)d"
R,0.8477398889770024,Γ(1 + d
R,0.8485329103885805,"p) ≈(2r)d
Γ(1 + 1 p)d q 2π d"
R,0.8493259318001586,"p

d
pe
 d"
R,0.8501189532117367,"p =
r p 2πd"
R,0.8509119746233148,"2r(pe)
1
p Γ(1 + 1 p) d
1
p"
R,0.8517049960348929,"d
(148)"
R,0.852498017446471,where the ﬁrst equality is due to lemma I.1 and the approximate equality is due to Stirling’s formula
R,0.8532910388580491,"about the estimation of gamma function that Γ(z + 1) ≈
√"
R,0.8540840602696272,"2πz

z
e
z
. Thus, when V (d)
p
= 1, we
have"
R,0.8548770816812054,"r ≈
d
1
p"
R,0.8556701030927835,"2(pe)
1
p Γ(1 + 1"
R,0.8564631245043616,"p)
(149)"
R,0.8572561459159397,"Then we estimate the volume of lp norm ball cap by studying the asymptotic property of the mass
distribution of lp norm ball. To begin with, let’s estimate the (d −1)-dimensional volume of a slice
through the center of the lp ball of volume 1. Note that the ball has radius r = (V (d)
p
)−1"
R,0.8580491673275178,"d . The slice
is an (d −1)-dimensional ball of this radius, so its volume is"
R,0.8588421887390959,"V (d−1)
p
rd−1 = V (d−1)
p
(V (d)
p
)−d−1"
R,0.8596352101506741,"d
= 2d−1 Γ(1 + 1 p)d−1"
R,0.8604282315622522,Γ(1 + d−1 p )
R,0.8612212529738303,"
2d Γ(1 + 1 p)d"
R,0.8620142743854085,Γ(1 + d p) −d−1
R,0.8628072957969866,"d
(150)"
R,0.8636003172085647,"Using Stirling’s formula again, when d is sufﬁciently large, we have"
R,0.8643933386201428,"V (d−1)
p
rd−1"
R,0.8651863600317209,= 2d−1 Γ(1 + 1 p)d−1
R,0.865979381443299,Γ(1 + d−1 p )
R,0.8667724028548771,"
2d Γ(1 + 1 p)d"
R,0.8675654242664552,Γ(1 + d p) −d−1
R,0.8683584456780333,"d
= 2d−1
Γ(1 + 1 p)d−1 q"
R,0.8691514670896114,2π d−1
R,0.8699444885011896,"p

d−1"
R,0.8707375099127677,"pe
 d−1 p"
R,0.8715305313243458,"
2d
Γ(1 + 1 p)d q 2π d"
R,0.8723235527359239,"p

d
pe
 d p −d−1 d =
1
q"
R,0.873116574147502,2π d−1
R,0.8739095955590801,"p

d−1"
R,0.8747026169706582,"pe
 d−1"
R,0.8754956383822363,"p
·
1
q 2π d"
R,0.8762886597938144,"p

d
pe
 d"
R,0.8770816812053925,"p −d−1 d
=
1 ( 2π"
R,0.8778747026169706,"p )
1
2d (d −1) d−1 p
+ 1"
R,0.8786677240285488,2 d−d−1
R,0.8794607454401269,"p
−d−1"
D,0.880253766851705,"2d
=
(1 +
1
d−1) d−1 p
+ 1 2 ( 2πd"
D,0.8810467882632831,"p )
1
2d
≈e
1
p"
D,0.8818398096748612,Under review as a conference paper at ICLR 2022
D,0.8826328310864393,Figure 6: Comparing the volume of a ball with that of its central slice
D,0.8834258524980174,where the second equality is due to Stirling’s formula for Γ(1+ d−1
D,0.8842188739095955,p ) and Γ(1+ d
D,0.8850118953211736,"p); the third equality
just eliminate the exponential of 2 and Γ(1 + 1"
D,0.8858049167327517,"p). Thus, we conclude that the slice has volume about"
D,0.8865979381443299,"e
1
p when d is large."
D,0.887390959555908,"Then, consider the (d −1)-dimensional volumes of parallel slices. The slice at distance x from the
center is an (d −1)-dimensional ball whose radius is (rp −xp)
1
p , so the volume of the smaller slice
is about"
D,0.8881839809674861,"e
1
p
(rp −xp)
1
p r"
D,0.8889770023790642,"d−1
= e
1
p

1 −
x r"
D,0.8897700237906423,p d−1 p
D,0.8905630452022204,"Since r is roughly
d
1
p"
D,0.8913560666137986,"2(pe)
1
p Γ(1+ 1"
D,0.8921490880253767,"p ), this is about"
D,0.8929421094369548,"e
1
p

1−
2x(pe)
1
p Γ(1 + 1 p) d
1
p"
D,0.893735130848533,p d−1
D,0.8945281522601111,"p
= e
1
p

1−
pe(2xΓ(1 + 1 p))p d  d−1"
D,0.8953211736716892,"p
≈exp
1"
D,0.8961141950832673,p−e(2xΓ(1+1 p))p
D,0.8969072164948454,"Thus, if we project the mass distribution of the lp ball of volume 1 onto a single coordinate
direction, we get a distribution with density function f(x) = exp( 1"
D,0.8977002379064235,p −e(2xΓ(1 + 1
D,0.8984932593180016,"p))p) =
exp
  1"
D,0.8992862807295797,p −e( 2 pΓ( 1
D,0.9000793021411578,"p))pxp
."
D,0.9008723235527359,"Thus, for an lp ball centered at original point O with volume 1 and approximate radius
d
1
p"
D,0.901665344964314,"2(pe)
1
p Γ(1+ 1 p ),"
D,0.9024583663758922,"then we can use the integral 2
R s
0 exp

1
p −e(2xΓ(1+ 1"
D,0.9032513877874703,"p))p
dx to estimate the volume between two
parallel slices at the same distance s from the center. Then the volume of lp ball cap corresponding to"
D,0.9040444091990484,the slice at distance s from the center can be approximated by 1
D,0.9048374306106265,"2 −
R s
0 exp

1
p −e(2xΓ(1+ 1"
D,0.9056304520222046,"p))p
dx."
D,0.9064234734337827,"Note that the ratio k of slice’s distance d from center to radius r is about s
.
d
1
p"
D,0.9072164948453608,"2(pe)
1
p Γ(1+ 1 p ) ="
D,0.9080095162569389,"2s(pe)
1
p Γ(1+ 1 p )"
D,0.908802537668517,"d
1
p
, i.e. s =
kd
1
p"
D,0.9095955590800952,"2(pe)
1
p Γ(1+ 1"
D,0.9103885804916733,"p ). Thus, the volume of cap can be represented as"
D,0.9111816019032514,"1
2 −
Z
kd
1
p"
D,0.9119746233148295,"2(pe)
1
p Γ(1+ 1 p )"
EXP,0.9127676447264076,"0
exp
1"
EXP,0.9135606661379857,p −e(2xΓ(1 + 1
EXP,0.9143536875495638,"p))p
dx"
EXP,0.9151467089611419,"which is only related to the ratio k. Then, we can conclude that for a lp ball with radius r, when
dimension d is large enough and its cap corresponding to the slice at distance h form the center, then
the volume ratio of cap to ball is approximately"
EXP,0.91593973037272,"1
2 −
Z
sd
1
p"
EXP,0.9167327517842981,"2r(pe)
1
p Γ(1+ 1 p )"
EXP,0.9175257731958762,"0
exp
1"
EXP,0.9183187946074544,p −e(2xΓ(1 + 1
EXP,0.9191118160190325,"p))p
dx
(151) Thus,"
EXP,0.9199048374306106,Vol(Ω2)
EXP,0.9206978588421887,Vol(K) = 1
EXP,0.9214908802537668,"2 −
Z
ϵd
1
p"
EXP,0.922283901665345,"4r(pe)
1
p Γ(1+ 1 p )"
EXP,0.9230769230769231,"0
exp
1"
EXP,0.9238699444885012,p −e(2xΓ(1 + 1
EXP,0.9246629659000793,"p))p
dx
(152)"
EXP,0.9254559873116575,Under review as a conference paper at ICLR 2022
EXP,0.9262490087232356,and therefore
EXP,0.9270420301348137,"TV (µ, ϵe1 + µ) = 1 −Vol(K ∩(ϵe1 + K))"
EXP,0.9278350515463918,"Vol(K)
= 1 −2Vol(Ω2)"
EXP,0.9286280729579699,Vol(K)
EXP,0.929421094369548,"= 2
Z
ϵd
1
p"
EXP,0.9302141157811261,"4r(pe)
1
p Γ(1+ 1 p )"
EXP,0.9310071371927042,"0
exp
1"
EXP,0.9318001586042823,p −e(2xΓ(1 + 1
EXP,0.9325931800158604,"p))p
dx"
EXP,0.9333862014274386,"J
PROOF OF THEOREM 3.7"
EXP,0.9341792228390167,"Proof. Note that f(x) and g(x) are respectively density functions of reference measure ρ = x + µ
and perturbed measure ν and q(x) is deﬁned as g(x) −f(x). Therefore"
EXP,0.9349722442505948,"EX∼ν[φ(X)] =
Z
φ(x)g(x)dx =
Z
φ(x)
 
g(x) −f(x)

dx +
Z
φ(x)f(x)dx =
Z
φ(x)q(x)dx +
Z
φ(x)f(x)dx"
EXP,0.9357652656621729,"=
Z
φ(x)q(x)dx + EX∼x+µ[φ(X)]"
EXP,0.936558287073751,"where the ﬁrst term contains all the uncertainty in one functional variable q(x) and the second term
is a constant when sample point x, smoothing measure µ and speciﬁcation φ are ﬁxed. And when
ν ∈Dx,δ,p or equivalently Wp(ν, x + µ) ≤δ, applying the dual form of Wp distance given in
formula 30 and 31, we have"
EXP,0.9373513084853291,"W1(ν, x + µ) = sup
ϕ∈F1"
EXP,0.9381443298969072,"Z
ϕ(x)(f −g)(x)dx = sup
ϕ∈F1"
EXP,0.9389373513084853,"Z
ϕ(x)(g −f)(x)dx = sup
ϕ∈F1"
EXP,0.9397303727200634,"Z
ϕ(x)q(x)dx"
EXP,0.9405233941316415,"=
sup
||f||L≤1"
EXP,0.9413164155432197,"Z
f(x)q(x)dx ≤δ
(153)"
EXP,0.9421094369547978,"And when ν ∈Dx,ξ or equivalently TV (ν, x + µ) ≤ξ, applying lemma A.3 for absolutely contin-
uous measure, we have"
EXP,0.9429024583663759,"TV (ν, x + µ) = 1 2"
EXP,0.943695479777954,"Z
|f(x) −g(x)|dx = 1 2"
EXP,0.9444885011895321,"Z
|q(x)|dx ≤ξ
(154)"
EXP,0.9452815226011102,"It follows that OPT(φ, x + µ, Dx,δ,p ∩Dx,ξ) is equivalent to minν∈Dx,δ,p∩Dx,ξ E[φ(X)] according
to the deﬁnition and therefore equivalent to optimization problem 23 which is obviously convex
according to 153 and 154."
EXP,0.9460745440126883,"K
PROOF OF THEOREM 3.8"
EXP,0.9468675654242664,Recall the following result proved in the section before
EXP,0.9476605868358445,"EX∼ν[φ(X)] =
Z
φ(x)q(x)dx + EX∼x+µ[φ(X)]
(155)"
EXP,0.9484536082474226,"When ν ∈Dx,δ,p or equivalently Wp(ν, x + µ) ≤δ, applying the dual form of Wp distance given
in formula 32 and noticing that supy∈spt(ν)∪spt(x+µ) ||y||2 = ||x||2 + R + max{ϵ, ϵd
1
2 −1"
EXP,0.9492466296590008,"q } := R∗,
we have

sup
ϕ∈Lip(p(2R∗)p−1)"
EXP,0.9500396510705789,"Z
ϕ(y)(g −f)(y)dy −(p −1)(2R∗)p−1
 1"
EXP,0.950832672482157,"p
≤Wp(ν, x + µ) ≤δ
(156)"
EXP,0.9516256938937351,or equivalently
EXP,0.9524187153053132,"sup
ϕ∈Lip(p(2R∗)p−1)"
EXP,0.9532117367168914,"Z
ϕ(y)(g −f)(y)dy =
sup
||f||L≤p(2R∗)p−1"
EXP,0.9540047581284695,"Z
f(x)q(x)dx ≤δp + (p −1)(2R∗)p−1"
EXP,0.9547977795400476,"(157)
where Lip
 
p(2R∗)p−1
denotes all maps f from Rd to R such that |f(x)−f(y)| ≤p(2R∗)p−1||x−
y|| for all x, y ∈K. Note OPT(φ, x+µ, Dx,δ,p ∩Dx,ξ) is equivalent to minν∈Dx,δ,p∩Dx,ξ E[φ(X)]
according to the deﬁnition and therefore can be relaxed into optimization problem which is obviously
convex according to 157 and 154."
EXP,0.9555908009516257,Under review as a conference paper at ICLR 2022
EXP,0.9563838223632039,"L
PROOF OF THEOREM 3.9"
EXP,0.957176843774782,"Proof. For 0 < p ≤1, the optimization over q can be solved using Lagrangian duality as follows:
we dualize the constraints on q and obtain"
EXP,0.9579698651863601,"L(λ) =
inf
||q||1≤2ξ"
EXP,0.9587628865979382," Z
φ(x)q(x)dx + EX∼x+µ[φ(X)] + λ

sup
||f||L,p≤1"
EXP,0.9595559080095163,"Z
f(x)q(x)dx −δ
"
EXP,0.9603489294210944,"= EX∼x+µ[φ(X)] +
inf
||q||1≤2ξ
sup
||f||L,p≤1"
EXP,0.9611419508326725," Z
φ(x)q(x)dx + λ

sup
||f||L≤1"
EXP,0.9619349722442506,"Z
f(x)q(x)dx −δ
"
EXP,0.9627279936558287,"= EX∼x+µ[φ(X)] +
inf
||q||1≤2ξ
sup
||f||L,p≤1"
EXP,0.9635210150674068,"Z  
φ(x) + f(x)

q(x)dx −λδ"
EXP,0.964314036478985,"= EX∼x+µ[φ(X)] +
sup
||f||L,p≤1
inf
||q||1≤2ξ"
EXP,0.9651070578905631,"Z  
φ(x) + f(x)

q(x)dx −λδ"
EXP,0.9659000793021412,"= EX∼x+µ[φ(X)] +
sup
||f||L,p≤1
inf
||q||1≤2ξ −
Z  
φ(x) + f(x)

q(x)
dx −λδ
(158)"
EXP,0.9666931007137193,"= EX∼x+µ[φ(X)] −
inf
||f||L,p≤1
sup
||q||1≤2ξ"
EXP,0.9674861221252974,"Z  
φ(x) + f(x)

q(x)
dx −λδ"
EXP,0.9682791435368755,"= EX∼x+µ[φ(X)] −2ξ
inf
||f||L,p≤1"
EXP,0.9690721649484536,"φ(x) + f(x)

∞−λδ
(159)"
EXP,0.9698651863600317,"= EX∼x+µ[φ(X)] −2ξ −λδ
(160)"
EXP,0.9706582077716098,"where 158 is due to the choice of q(x) such that sgn(q(x)) = sgn(φ(x) + f(x)); 159 is due to
Holder inequality when q = 1, p = ∞; 160 is due to the fact that inf||f||L≤1
φ(x) + f(x)

∞= 1
since the range of φ(x) is {±1} in applications and f cannot change suddenly when crossing the
decision region boundary of φ due to the Lipschitz constant constraint."
EXP,0.9714512291831879,"Similarly, for p > 1, we have L(λ)"
EXP,0.972244250594766,"=
inf
||q||1≤2ξ"
EXP,0.9730372720063442," Z
φ(x)q(x)dx + EX∼x+µ[φ(X)] + λ

sup
||f||L≤p(2R∗)p−1"
EXP,0.9738302934179223,"Z
f(x)q(x)dx −
 
δp + (p −1)(2R∗)p−1"
EXP,0.9746233148295004,= EX∼x+µ[φ(X)]
EXP,0.9754163362410785,"+
inf
||q||1≤2ξ
sup
||f||L≤p(2R∗)p−1"
EXP,0.9762093576526566," Z
φ(x)q(x)dx + λ

sup
||f||L≤p(2R∗)p−1"
EXP,0.9770023790642347,"Z
f(x)q(x)dx −
 
δp + (p −1)(2R∗)p−1"
EXP,0.9777954004758128,"= EX∼x+µ[φ(X)] +
inf
||q||1≤2ξ
sup
||f||L≤p(2R∗)p−1"
EXP,0.9785884218873909,"Z  
φ(x) + f(x)

q(x)dx −λ
 
δp + (p −1)(2R∗)p−1"
EXP,0.979381443298969,"= EX∼x+µ[φ(X)] +
sup
||f||L≤p(2R∗)p−1
inf
||q||1≤2ξ"
EXP,0.9801744647105471,"Z  
φ(x) + f(x)

q(x)dx −λ
 
δp + (p −1)(2R∗)p−1"
EXP,0.9809674861221253,"= EX∼x+µ[φ(X)] +
sup
||f||L≤p(2R∗)p−1
inf
||q||1≤2ξ −
Z  
φ(x) + f(x)

q(x)
dx −λ
 
δp + (p −1)(2R∗)p−1"
EXP,0.9817605075337034,"= EX∼x+µ[φ(X)] −
inf
||f||L≤p(2R∗)p−1
sup
||q||1≤2ξ"
EXP,0.9825535289452815,"Z  
φ(x) + f(x)

q(x)
dx −λ
 
δp + (p −1)(2R∗)p−1"
EXP,0.9833465503568596,"= EX∼x+µ[φ(X)] −2ξ
inf
||f||L≤p(2R∗)p−1
φ(x) + f(x)

∞−λ
 
δp + (p −1)(2R∗)p−1"
EXP,0.9841395717684377,"= EX∼x+µ[φ(X)] −2ξ −λ
 
δp + (p −1)(2R∗)p−1"
EXP,0.9849325931800159,Under review as a conference paper at ICLR 2022
EXP,0.985725614591594,"M
PROOF OF THEOREM 3.10"
EXP,0.9865186360031721,"Recall the certiﬁcate by using Hockey-stick divergence provided in table 4 in Dvijotham et al. (2020)
as below"
EXP,0.9873116574147502,"ϵHS,β ≤
hβ(θa −θb) −|β −1| 2 i"
EXP,0.9881046788263284,"+
When β = 1, it follows that"
EXP,0.9888977002379065,"ϵHS,1 ≤
hθa −θb 2 i"
EXP,0.9896907216494846,"+
Besides, recall the relaxation radius using Hockey-stick divergence as below"
EXP,0.9904837430610627,"ϵHS,1 = G
 ϵ 2σ"
EXP,0.9912767644726408,"
−G

−ϵ 2σ"
EXP,0.9920697858842189,"
= 2G
 ϵ 2σ 
−1"
EXP,0.992862807295797,"And plug it in above inequality, we have"
EXP,0.9936558287073751,"ϵHS,1 = 2G( ϵ"
EXP,0.9944488501189532,"2σ ) −1 ≤
hθa −θb 2 i +"
EXP,0.9952418715305313,"And recall the deﬁnition of θa and θb, we have"
EXP,0.9960348929421095,EX∼x+µ[φ(X)] = θa −θb
EXP,0.9968279143536876,"Thus, our certiﬁcate EX∼x+µ[φ(X)] −2
 
2G( ϵ"
EXP,0.9976209357652657,"2σ) −1

≥0 is equivalent to 2G( ϵ"
EXP,0.9984139571768438,2σ ) −1 ≤θa −θb
EXP,0.9992069785884219,"2
Thus, the equivalence relation holds."
