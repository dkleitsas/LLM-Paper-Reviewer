Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0013404825737265416,"Large language models (LLMs) have shown great promise at generating robot pro-
1"
ABSTRACT,0.002680965147453083,"grams from natural language given domain-specific robot application programming
2"
ABSTRACT,0.004021447721179625,"interfaces (APIs). However, the performance gap between proprietary LLMs and
3"
ABSTRACT,0.005361930294906166,"smaller open-weight LLMs remains wide. This raises a question: Can we fine-
4"
ABSTRACT,0.006702412868632708,"tune smaller open-weight LLMs for generating domain-specific robot programs to
5"
ABSTRACT,0.00804289544235925,"close the performance gap with proprietary LLMs? While SELF-INSTRUCT is a
6"
ABSTRACT,0.00938337801608579,"promising solution by generating a diverse set of training data, it cannot verify the
7"
ABSTRACT,0.010723860589812333,"correctness of these programs. In contrast, a robot simulator with a well-defined
8"
ABSTRACT,0.012064343163538873,"world can identify execution errors but limits the diversity of programs that it can
9"
ABSTRACT,0.013404825737265416,"verify. In this work, we introduce ROBO-INSTRUCT, which brings the best of
10"
ABSTRACT,0.014745308310991957,"both worlds — it promotes the diversity of SELF-INSTRUCT, while providing cor-
11"
ABSTRACT,0.0160857908847185,"rectness of simulator-based checking. ROBO-INSTRUCT introduces ROBOSIM to
12"
ABSTRACT,0.01742627345844504,"synthesize a consistent world state on the fly by inferring properties relevant to the
13"
ABSTRACT,0.01876675603217158,"program being checked, and simulating actions accordingly. Furthermore, the in-
14"
ABSTRACT,0.020107238605898123,"structions and programs generated by SELF-INSTRUCT may be subtly inconsistent
15"
ABSTRACT,0.021447721179624665,"— such as the program missing a step implied by the instruction. ROBO-INSTRUCT
16"
ABSTRACT,0.022788203753351208,"further addresses this with INSTALIGN, an instruction-program alignment pro-
17"
ABSTRACT,0.024128686327077747,"cedure that revises the task instruction to reflect actual results of the generated
18"
ABSTRACT,0.02546916890080429,"program. Given a few seed task descriptions and the robot APIs, ROBO-INSTRUCT
19"
ABSTRACT,0.02680965147453083,"is capable of generating a training dataset using only a small open-weight model.
20"
ABSTRACT,0.028150134048257374,"This dataset is then be used to fine-tune small open-weight language models, en-
21"
ABSTRACT,0.029490616621983913,"abling them to even exceed the performance of several proprietary LLMs including
22"
ABSTRACT,0.030831099195710455,"GPT-3.5-Turbo and Gemini-Pro.
23"
INTRODUCTION,0.032171581769437,"1
Introduction
24"
INTRODUCTION,0.03351206434316354,"Large language models (LLMs) have demonstrated great promise at generating robot programs from
25"
INTRODUCTION,0.03485254691689008,"natural language instructions [3, 10–12, 17, 18, 31, 39]. For example, consider an instruction for
26"
INTRODUCTION,0.036193029490616625,"a service mobile robot: ""Check how many conference rooms have no markers."" The robot may
27"
INTRODUCTION,0.03753351206434316,"be equipped with a domain-specific robot application programming interface (API) that includes
28"
INTRODUCTION,0.0388739946380697,"skills such as go_to(location) for navigation and is_in_room(object) for perception. Since
29"
INTRODUCTION,0.040214477211796246,"such domain-specific APIs do not exist in the training dataset of general-purpose LLMs, in-context
30"
INTRODUCTION,0.04155495978552279,"learning (ICL) via few-shot examples is often employed to describe and use such APIs for performing
31"
INTRODUCTION,0.04289544235924933,"few-shot inference. However, there is a significant performance gap [10] in the correctness of
32"
INTRODUCTION,0.04423592493297587,"programs generated by ICL for large proprietary models and smaller open-weight models that can be
33"
INTRODUCTION,0.045576407506702415,"deployed locally on robots. This raises a question: can we fine-tune small open-weight LLMs for
34"
INTRODUCTION,0.04691689008042895,"generating domain-specific robot programs to close the performance gap with proprietary LLMs?
35"
INTRODUCTION,0.04825737265415549,Instruction-Program Pair
INTRODUCTION,0.049597855227882036,"Check if there is a key here. If 
so, pick it up. 
1 def task_program():
2  if is_in_room(""key""):
3   pick(""key"")"
INTRODUCTION,0.05093833780160858,"Gen. 
Program"
INTRODUCTION,0.05227882037533512,InstAlign
INTRODUCTION,0.05361930294906166,Program
INTRODUCTION,0.054959785522788206,"1 def task_program():
2  if not is_in_room(""key""):
3   pick(""key"")"
INTRODUCTION,0.05630026809651475,"RobotPickError: 'key' does not 
exist in the current location"
INTRODUCTION,0.057640750670241284,Instruction
INTRODUCTION,0.058981233243967826,"Ask if there is a key here. If so, pick 
it up."
INTRODUCTION,0.06032171581769437,"Misalignment: The robot doesn't 
verbally ask but visually check 
if a key is present."
INTRODUCTION,0.06166219839142091,Input Prompt
INTRODUCTION,0.06300268096514745,"Aligned
Instruction"
INTRODUCTION,0.064343163538874,Instruction
INTRODUCTION,0.06568364611260054,Program
INTRODUCTION,0.06702412868632708,Examples
INTRODUCTION,0.06836461126005362,Success Fail
INTRODUCTION,0.06970509383378017,"Self-Instruct
Gen. 
Instruction"
INTRODUCTION,0.07104557640750671,Robo-Instruct
INTRODUCTION,0.07238605898123325,Input Prompt
INTRODUCTION,0.07372654155495978,"Here is a robot that has the following 
skills:
{RoboEval APIs} 
{Seed Examples}
Generate an interesting robot task that 
can be accomplished using above skills."
INTRODUCTION,0.07506702412868632,Pass@1
INTRODUCTION,0.07640750670241286,"RoboSim
Robot World State Init"
INTRODUCTION,0.0777479892761394,Program Translation
INTRODUCTION,0.07908847184986595,"Exec Program 
1 2 3"
INTRODUCTION,0.08042895442359249,Query & Update
INTRODUCTION,0.08176943699731903,Return Values w.r.t to
INTRODUCTION,0.08310991957104558,the Current State
INTRODUCTION,0.08445040214477212,"Robot APIs ×k +
→"
INTRODUCTION,0.08579088471849866,"→
Valid
Program ❓ ❓"
INTRODUCTION,0.0871313672922252,"Figure 1: High-Level Overview of ROBO-INSTRUCT. This figure also illustrates an example of an
invalid SELF-INSTRUCT-generated instruction and program, as well as pass@1 results of different
LLMs on ROBOEVAL."
INTRODUCTION,0.08847184986595175,"Since training datasets of the domain-specific robot programs are often unavailable, SELF-INSTRUCT
36"
INTRODUCTION,0.08981233243967829,"might seem like a promising solution [29, 36]. Consider the setting of generating programs for
37"
INTRODUCTION,0.09115281501340483,"service mobile robots that can perceive objects, navigate to various locations, manipulate items, and
38"
INTRODUCTION,0.09249329758713137,"communicate with humans. By formulating these robot skills into APIs, we can create a few seed
39"
INTRODUCTION,0.0938337801608579,"task examples demonstrating their use case and employ SELF-INSTRUCT to generate a diverse set of
40"
INTRODUCTION,0.09517426273458444,"instruction-program pairs as training data, as illustrated in Fig. 1. However, using SELF-INSTRUCT
41"
INTRODUCTION,0.09651474530831099,"naïvely may generate infeasible instructions—e.g., asking the robot to pick up multiple objects at once
42"
INTRODUCTION,0.09785522788203753,"when it cannot due to physical constraints. They can also violate domain-specific constraints. For
43"
INTRODUCTION,0.09919571045576407,"example, in Fig. 1, after line 2 confirms the absence of a key at the current location, line 3 erroneously
44"
INTRODUCTION,0.10053619302949061,"attempts to pick up a key. Further, these instructions may not align with the generated programs, even
45"
INTRODUCTION,0.10187667560321716,"if these programs are valid. For example, Fig. 1 shows an example instruction directing the robot to
46"
INTRODUCTION,0.1032171581769437,"verbally ask in each room if a key exists, whereas the program instructs the robot to visually check
47"
INTRODUCTION,0.10455764075067024,"in each room. Finally, the generated programs may have execution errors. These challenges may
48"
INTRODUCTION,0.10589812332439678,"appear to be solvable using a simulator, but a simulator needs an initial world state to check against
49"
INTRODUCTION,0.10723860589812333,"programs. A simulator using a hand-curated world state will end up rejecting the wide diversity of
50"
INTRODUCTION,0.10857908847184987,"programs generated by SELF-INSTRUCT, even if they are executable, just because the world state did
51"
INTRODUCTION,0.10991957104557641,"not capture some aspect relevant to them (e.g., the presence of a “key”).
52"
INTRODUCTION,0.11126005361930295,"This work introduces ROBO-INSTRUCT, a new framework based on SELF-INSTRUCT, to address these
53"
INTRODUCTION,0.1126005361930295,"issues and improve the performance of small open-weight language models for generating domain-
54"
INTRODUCTION,0.11394101876675604,"specific robot programs. As shown in Fig. 1, ROBO-INSTRUCT introduces two novel components:
55"
INTRODUCTION,0.11528150134048257,"(1) ROBOSIM, a task-agnostic simulator that encodes domain-specific constraints and validates
56"
INTRODUCTION,0.11662198391420911,"robot programs generated from SELF-INSTRUCT. Critically, ROBOSIM dynamically synthesizes
57"
INTRODUCTION,0.11796246648793565,"a consistent world state starting from arbitrary programs. (2) INSTALIGN, an instruction-program
58"
INTRODUCTION,0.1193029490616622,"alignment procedure that revises the generated instructions to better reflect the intent of the generated
59"
INTRODUCTION,0.12064343163538874,"programs. ROBO-INSTRUCT also employs a rejection-sampling mechanism that rejects invalid
60"
INTRODUCTION,0.12198391420911528,"programs detected by ROBOSIM and queries SELF-INSTRUCT for a new program corresponding to
61"
INTRODUCTION,0.12332439678284182,"the same generated instruction.
62"
INTRODUCTION,0.12466487935656836,"We validate ROBO-INSTRUCT by fine-tuning Codellama-Python-7B [30] and evaluate on ROBOEVAL,
63"
INTRODUCTION,0.1260053619302949,"a domain-specific code generation benchmark for service mobile robots. We show that ROBO-
64"
INTRODUCTION,0.12734584450402145,"INSTRUCT is capable of improving the performance of the Codellama model by using only a small
65"
INTRODUCTION,0.128686327077748,"open-weight model to generate the training dataset. Compared to the base Codellama-Python-
66"
INTRODUCTION,0.13002680965147453,"7B model without fine-tuning, our ROBO-INSTRUCT fine-tuned models outperform by 28.75% in
67"
INTRODUCTION,0.13136729222520108,"average pass@1 scores; and, compared to SELF-INSTRUCT fine-tuned model, our model outperform
68"
INTRODUCTION,0.13270777479892762,"by 13.75%.; and the best pass@1 of ROBO-INSTRUCT fine-tuned model achieves a 68.75% match,
69"
INTRODUCTION,0.13404825737265416,"surpassing the performance of the proprietary GPT-3.5-Turbo and Gemini-1.0-Pro.
70"
INTRODUCTION,0.1353887399463807,"Contributions
Our main contributions are as follows:
71"
INTRODUCTION,0.13672922252010725,"1. We introduce ROBO-INSTRUCT, a new framework for improving the code generation
72"
INTRODUCTION,0.1380697050938338,"performance of small open-weight language models for domain-specific robot programs.
73"
INTRODUCTION,0.13941018766756033,"This framework introduces two novel components, ROBOSIM and INSTALIGN.
74"
WE INTRODUCE A DYNAMIC WORLD SYNTHESIS AND EVALUATION PROCESS FOR GENERATING RELEVANT,0.14075067024128687,"2. We introduce a dynamic world synthesis and evaluation process for generating relevant
75"
WE INTRODUCE A DYNAMIC WORLD SYNTHESIS AND EVALUATION PROCESS FOR GENERATING RELEVANT,0.14209115281501342,"world states for automated code checking for diverse, arbitrary tasks in ROBOSIM.
76"
WE INTRODUCE A DYNAMIC WORLD SYNTHESIS AND EVALUATION PROCESS FOR GENERATING RELEVANT,0.14343163538873996,"3. We introduce INSTALIGN, an instruction alignment procedure to refine instruction-code
77"
WE INTRODUCE A DYNAMIC WORLD SYNTHESIS AND EVALUATION PROCESS FOR GENERATING RELEVANT,0.1447721179624665,"pairs to improve alignment between instructions and code generated by SELF-INSTRUCT.
78"
WE INTRODUCE A DYNAMIC WORLD SYNTHESIS AND EVALUATION PROCESS FOR GENERATING RELEVANT,0.14611260053619302,"4. We fine-tune a small open-weight model, Codellama-Python-7B [30], using ROBO-
79"
WE INTRODUCE A DYNAMIC WORLD SYNTHESIS AND EVALUATION PROCESS FOR GENERATING RELEVANT,0.14745308310991956,"INSTRUCT, and improve its performance to outperform several CodeLLMs, including
80"
WE INTRODUCE A DYNAMIC WORLD SYNTHESIS AND EVALUATION PROCESS FOR GENERATING RELEVANT,0.1487935656836461,"Deepseek-Coder-33B [8], and Starcoder2-15B [21] and two proprietary LLMs, GPT-3.5-
81"
WE INTRODUCE A DYNAMIC WORLD SYNTHESIS AND EVALUATION PROCESS FOR GENERATING RELEVANT,0.15013404825737264,"Turbo [27] and Gemini-1.0-Pro [33] on the ROBOEVAL benchmark.
82"
WE INTRODUCE A DYNAMIC WORLD SYNTHESIS AND EVALUATION PROCESS FOR GENERATING RELEVANT,0.15147453083109919,"Our code and data will be released at URL anonymized.
83"
ROBO-INSTRUCT,0.15281501340482573,"2
ROBO-INSTRUCT
84"
ROBO-INSTRUCT,0.15415549597855227,"In this section, we present how ROBO-INSTRUCT generates training datasets of domain-specific robot
85"
ROBO-INSTRUCT,0.1554959785522788,"programs. Alg. 1 shows a broad overview of the framework. To add an entry in the training dataset,
86"
ROBO-INSTRUCT,0.15683646112600536,"SELF-INSTRUCT first generates an instruction-program pair, (I, P), from the robot APIs and seed
87"
ROBO-INSTRUCT,0.1581769436997319,"tasks, shown in Appendix A.4. Then, ROBOSIM dynamically synthesizes a consistent world state on
88"
ROBO-INSTRUCT,0.15951742627345844,"the fly as it executes and validates P. If P is invalid, ROBO-INSTRUCT employs a rejection-sampling
89"
ROBO-INSTRUCT,0.16085790884718498,"method, which generates a new program P given the same I and evaluates the new P again. This
90"
ROBO-INSTRUCT,0.16219839142091153,"process repeats until P becomes valid or a predefined maximum resampling limit is reached. If the
91"
ROBO-INSTRUCT,0.16353887399463807,"limit is reached, the instruction might be invalid given the domain-specific APIs or too complex to
92"
ROBO-INSTRUCT,0.1648793565683646,"generate a program, so the instruction-program pair is discarded. Finally, if P is valid, INSTALIGN
93"
ROBO-INSTRUCT,0.16621983914209115,"takes in (I, P) to revise I to better reflect the intent of P and the aligned instruction and program is
94"
ROBO-INSTRUCT,0.1675603217158177,"saved to the training dataset. In the following subsections, we elaborate on the specific design of each
95"
ROBO-INSTRUCT,0.16890080428954424,"component.
96"
ROBO-INSTRUCT,0.17024128686327078,"Algorithm 1 ROBO-INSTRUCT: Instruction-Program Generation
Require: S,
▷Robot API and seed tasks,
Let P ←Program,
▷The program begin checked
Let I ←Instruction,
▷The instruction corresponding to P
Let ROBOSIM: P →bool,
▷Domain-specific task-agnostic simulator
Let INSTALIGN: S × I × P →I,
▷Instruction-program alignment model
Let SELF-INSTRUCTinst: S →I,
▷SELF-INSTRUCT instruction generation model
Let SELF-INSTRUCTcode: S × I →P,
▷SELF-INSTRUCT program generation model
1: Initialize: D = ∅
▷Training dataset
2: Initialize: N
▷Training dataset size
3: Initialize: m
▷Maximum resampling limit
4: while len(D) < N do
5:
I ←SELF-INSTRUCTinst(S)
6:
P ←SELF-INSTRUCTcode(S, I)
7:
for i = 1 to m do
8:
is_program_valid = ROBOSIM(P)
▷Validate the program
9:
if is_program_valid = FALSE then
10:
P ←SELF-INSTRUCTcode(S, I)
▷Rejection-sampling
11:
else
12:
Ialigned ←INSTALIGN(S, I, P)
▷Align instruction with the program
13:
D ←(Ialigned, P)
14:
break
15:
end if
16:
end for
17: end while
18: return D"
ROBO-INSTRUCT,0.17158176943699732,"2.1
ROBOSIM: A Task-Agnostic Simulator For Domain-Specific Programs
97"
ROBO-INSTRUCT,0.17292225201072386,"We present a principled approach to design ROBOSIM for validating domain-specific robot programs.
98"
ROBO-INSTRUCT,0.1742627345844504,"Alg. 2 illustrates the high-level algorithm used to assess the correctness of a robot program. ROBOSIM
99"
ROBO-INSTRUCT,0.17560321715817695,"employs the concept of world state to simulate the robot actions directed by a program, ensuring
100"
ROBO-INSTRUCT,0.1769436997319035,"consistent and reliable evaluation. A world state is a symbolic representation of the environment
101"
ROBO-INSTRUCT,0.17828418230563003,"in which the robot operates, and it keeps track of the high-level changes in the robot state and the
102"
ROBO-INSTRUCT,0.17962466487935658,"surrounding environment as the robot performs actions in order. For example, consider a program
103"
ROBO-INSTRUCT,0.18096514745308312,"instruction that commands a robot to check if an apple is nearby. The world state queries the stored
104"
ROBO-INSTRUCT,0.18230563002680966,"information about the surrounding environment, identifies all objects at the robot’s current location,
105"
ROBO-INSTRUCT,0.1836461126005362,"and informs the program whether an apple is present.
106"
ROBO-INSTRUCT,0.18498659517426275,"However, since SELF-INSTRUCT generates arbitrary programs based on the provided APIs, ROBOSIM
107"
ROBO-INSTRUCT,0.1863270777479893,"does not know what a plausible world state relevant to the program would be a priori — e.g., reasoning
108"
ROBO-INSTRUCT,0.1876675603217158,"about the existence of an apple in the example program. Thus, we equip ROBOSIM with the ability
109"
ROBO-INSTRUCT,0.18900804289544235,"to expand the world state as more robot actions are performed. Our approach is inspired by angelic
110"
ROBO-INSTRUCT,0.1903485254691689,"execution [4], which has previously been used for software verification of programs with partially
111"
ROBO-INSTRUCT,0.19168900804289543,"defined library functions. In our case, instead of partially defined library functions, we have unknown
112"
ROBO-INSTRUCT,0.19302949061662197,"plausible world states. ROBOSIM dynamically synthesizes and grows a world state based on domain-
113"
ROBO-INSTRUCT,0.19436997319034852,"specific constraints (e.g., object permanence, robot skills, etc.) and the execution trace of the program,
114"
ROBO-INSTRUCT,0.19571045576407506,"which allows it to infer a consistent and relevant world state.
115"
ROBO-INSTRUCT,0.1970509383378016,"Specifically, ROBOSIM modifies the program to replace all API calls with the DYNAMICEVAL
116"
ROBO-INSTRUCT,0.19839142091152814,"function (Alg. 2 line 4) — when an API function is called during execution, the DYNAMICEVAL
117"
ROBO-INSTRUCT,0.19973190348525469,"function is invoked instead.
118"
ROBO-INSTRUCT,0.20107238605898123,"DYNAMICEVAL makes an important extension to the formulation of STRIPS [7] to integrate with
119"
ROBO-INSTRUCT,0.20241286863270777,"API functions. DYNAMICEVAL equips each API function with specific pre-conditions, effects, and
120"
ROBO-INSTRUCT,0.2037533512064343,"return values. The pre-conditions are composed of literals tailored to the function’s requirements.
121"
ROBO-INSTRUCT,0.20509383378016086,"For instance, the API function is_in_room(‘apple’), which determines if an object ‘apple’ is in
122"
ROBO-INSTRUCT,0.2064343163538874,"the same room as the robot, uses two literals for its pre-condition: robot_at(X) and obj_at(X,
123"
ROBO-INSTRUCT,0.20777479892761394,"‘apple’). Generally, STRIPS assigns one of two possible values to each literal: True if the literal is
124"
ROBO-INSTRUCT,0.20911528150134048,"defined, otherwise False. However, prior to program execution, DYNAMICEVAL is unaware of the
125"
ROBO-INSTRUCT,0.21045576407506703,"program-relevant literals. Thus we assign a third value, undefined, to such unknown literals. Literals
126"
ROBO-INSTRUCT,0.21179624664879357,"must thus be explicitly defined as either True or False, or they remain undefined if not specified.
127"
ROBO-INSTRUCT,0.2131367292225201,"Alg. 3 demonstrates how DYNAMICEVAL executes an API function and updates the world state. First,
128"
ROBO-INSTRUCT,0.21447721179624665,"it calculates the precondition specified for the function. It then checks each literal in the precondition
129"
ROBO-INSTRUCT,0.2158176943699732,"to see if it is defined. If a literal is undefined, DYNAMICEVAL invokes GROWWORLD, a stochastic
130"
ROBO-INSTRUCT,0.21715817694369974,"function that assigns a random truth value to the literal and updates the world state accordingly.
131"
ROBO-INSTRUCT,0.21849865951742628,"Finally, DYNAMICEVAL proceeds to execute the API function using the current world state, retrieves
132"
ROBO-INSTRUCT,0.21983914209115282,"the return values, and applies the function’s effects to update the world state.
133"
ROBO-INSTRUCT,0.22117962466487937,"Fig. 2 illustrates an example of ROBOSIM executing a generated program. Initially, ROBOSIM’s
134"
ROBO-INSTRUCT,0.2225201072386059,"world state only specifies the robot’s current location, and whether a pie is in the same room
135"
ROBO-INSTRUCT,0.22386058981233245,"as the robot remains undefined (line 2). Therefore, DYNAMICEVAL invokes GROWWORLD to
136"
ROBO-INSTRUCT,0.225201072386059,"Algorithm 2 ROBOSIM(P)
Require: Program P
▷Generated program
1: Initialize: Set A
▷A set of domain-specific robot APIs
2: Initialize: k
▷Number of evaluation iterations
3: Initialize: Winit
▷An initial world state with or without predefined information
4: Ptrans ←TRANSLATE(P, A, DYNAMICEVAL)
▷Replace each API call with DYNAMICEVAL
5: for i = 1 to k do
▷Then, evaluate P k times to catch program errors
6:
try:
7:
W ←Winit
▷Initialize a new world state
8:
exec(Ptrans, W)
9:
catch:
10:
return False
11: end for
12: return True
▷Return True if all program executions are successful"
ROBO-INSTRUCT,0.22654155495978553,"Algorithm 3 DYNAMICEVAL(api_fn, params, W)"
ROBO-INSTRUCT,0.22788203753351208,"1: p ←GETPRECOND(api_fn, params)
▷Get the parameter-specific precondition for api_fn
2: for l ∈p do
▷Loop through every literal in the precondition
3:
if CHECKDEFINED(W, l) == undefined then
4:
W ←GROWWORLD(l, W)
▷Instantiate the literal and grow W to include it
5:
end if
6: end for
7: retval, W ←EXECUPDATE(api_fn, params, W)
▷Execute api_fn and update W
8: return retval, W"
ROBO-INSTRUCT,0.2292225201072386,"robot_at(start_loc): True
is_reachable(start_loc):True"
ROBO-INSTRUCT,0.23056300268096513,"1 def task_program():
2   if is_in_room(""pie"")
3     pick(""pie"")
4     go_to(""kitchen"")
5     place(""pie"")
6   else:
7     say(""there is no pie"")"
ROBO-INSTRUCT,0.23190348525469168,"robot_at(start_loc): 
is_reachable(start_loc)       
obj_at(start_loc, ""pie"")       True"
ROBO-INSTRUCT,0.23324396782841822,"robot_at(start_loc):          
is_reachable(start_loc):    
robot_holding(""pie""):                 e
obj_at(start_loc, ""pie"")               x"
ROBO-INSTRUCT,0.23458445040214476,"robot_at(start_loc)           
is_reachable(start_loc)  
obj_at(start_loc, ""pie"")      False"
ROBO-INSTRUCT,0.2359249329758713,"robot_at(start_loc)           
is_reachable(start_loc)   
obj_at(start_loc, ""pie"")"
ROBO-INSTRUCT,0.23726541554959785,"robot_at(start_loc)             False
is_reachable(start_loc)    
robot_holding(""pie"")  
is_reachable(""kitchen"")            d            
robot_at(""kitchen"")              True"
ROBO-INSTRUCT,0.2386058981233244,"def task_program():
  if is_in_room(""pie"")
    pick(""pie"")
    go_to(""kitchen"")
    place(""pie"")
  else:
    say(""there is no pie"")"
ROBO-INSTRUCT,0.23994638069705093,"def task_program():
  if is_in_room(""pie"")
    pick(""pie"")
    go_to(""kitchen"")
    place(""pie"")
  else:
    say(""there is no pie"")"
ROBO-INSTRUCT,0.24128686327077747,"def task_program():
  if is_in_room(""pie"")
    pick(""pie"")
    go_to(""kitchen"")
    place(""pie"")
  else:
    say(""there is no pie"")"
ROBO-INSTRUCT,0.24262734584450402,"def task_program():
  if is_in_room(""pie"")
    pick(""pie"")
    go_to(""kitchen"")
    place(""pie"")
  else:
    say(""there is no pie"")"
ROBO-INSTRUCT,0.24396782841823056,"def task_program():
  if is_in_room(""pie"")
    pick(""pie"")
    go_to(""kitchen"")
    place(""pie"")
  else:
    say(""there is no pie"")"
ROBO-INSTRUCT,0.2453083109919571,"def task_program():
  if is_in_room(""pie"")
    pick(""pie"")
    go_to(""kitchen"")
    place(""pie"")
  else:
    say(""there is no pie"")"
ROBO-INSTRUCT,0.24664879356568364,"robot_at(start_loc)         
is_reachable(start_loc)    
robot_holding(""pie"")              dd 
is_reachable(""kitchen"")   
robot_at(""kitchen"")          
obj_at(""kitchen"", ""pie"")            x"
ROBO-INSTRUCT,0.2479892761394102,World State
ROBO-INSTRUCT,0.24932975871313673,Program
ROBO-INSTRUCT,0.25067024128686327,RoboSim
ROBO-INSTRUCT,0.2520107238605898,No change
ROBO-INSTRUCT,0.25335120643431636,"True
True
True"
ROBO-INSTRUCT,0.2546916890080429,"False
True
False
True
True
True"
ROBO-INSTRUCT,0.25603217158176944,"True
True
True
Undef."
ROBO-INSTRUCT,0.257372654155496,"False
True
True
True
True"
ROBO-INSTRUCT,0.2587131367292225,"True
True
False"
ROBO-INSTRUCT,0.26005361930294907,"True
True
False 1
2
3 4
2
1"
ROBO-INSTRUCT,0.2613941018766756,API Deﬁnitions
ROBO-INSTRUCT,0.26273458445040215,"is_in_room(obj) -> Bool
pick(obj)       -> None
go_to(loc)      -> None
place(obj)      -> None
say(msg)        -> None"
ROBO-INSTRUCT,0.2640750670241287,"Figure 2: Example of ROBOSIM executing a generated program and updating the world state.
Initially, ROBOSIM begins with a world state that includes only the robot’s current location. As the
program executes, two distinct execution paths emerge, depicted in light purple and blue. This figure
demonstrates how the world state is updated along each execution path."
ROBO-INSTRUCT,0.26541554959785524,"randomly determine a truth value for the obj_at(start_loc, ""pie"") literal, leading to two
137"
ROBO-INSTRUCT,0.2667560321715818,"distinct execution paths depicted in light purple and blue. Subsequently, as additional API functions
138"
ROBO-INSTRUCT,0.2680965147453083,"are called, more literals are introduced or updated in the world state to ensure consistent evaluations.
139"
ROBO-INSTRUCT,0.26943699731903487,"Finally, due to the stochastic nature of DYNAMICEVAL, ROBOSIM must execute the generated
140"
ROBO-INSTRUCT,0.2707774798927614,"program multiple times to validate the program. If all executions are successful, the program is
141"
ROBO-INSTRUCT,0.27211796246648795,"deemed correct (Alg. 2 line 5-11).
142"
ROBO-INSTRUCT,0.2734584450402145,"2.2
INSTALIGN: Instruction-Program Alignment Procedure
143"
ROBO-INSTRUCT,0.27479892761394104,"Given that LLMs are extensively trained in code understanding [30], INSTALIGN is a procedure that
144"
ROBO-INSTRUCT,0.2761394101876676,"prompts an LLM to revise I to better reflect the intent of P. This procedure involves two steps: first,
145"
ROBO-INSTRUCT,0.2774798927613941,"given I and P, INSTALIGN leverages Chain-of-Thought reasoning [37] (CoT) to prompt an LLM
146"
ROBO-INSTRUCT,0.27882037533512066,"to generate a revised instruction, Irevised; second, INSTALIGN invokes the LLM again to determine
147"
ROBO-INSTRUCT,0.2801608579088472,"whether I or Irevised is more aligned with P’s intent and output the chosen instruction as Ialigned.
148"
ROBO-INSTRUCT,0.28150134048257375,"To generate Irevised, the prompt to the LLM comprises the robot API function definitions, I, P, and
149"
ROBO-INSTRUCT,0.2828418230563003,"CoT instructions. The CoT asks the LLM to perform the following three steps in order: 1. write down
150"
ROBO-INSTRUCT,0.28418230563002683,"all the robot APIs used in the program; 2. examine these APIs and write down step by step what
151"
ROBO-INSTRUCT,0.2855227882037534,"the program does; 3. combine all the information above to revise the robot instruction. Similarly,
152"
ROBO-INSTRUCT,0.2868632707774799,"to determine Ialigned, an LLM is prompted to think step by step about P, I and Irevised to arrive at a
153"
ROBO-INSTRUCT,0.28820375335120646,"conclusion. Detailed prompt is shown in Appendix A.6.
154"
ANALYSIS AND EXPERIMENTS,0.289544235924933,"3
Analysis and Experiments
155"
ANALYSIS AND EXPERIMENTS,0.29088471849865954,"In this section, we investigate the following two research questions:
156"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.29222520107238603,"1. Is ROBO-INSTRUCT effective at generating training data to fine-tune a small language model
157"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.2935656836461126,"for generating domain-specific robot programs?
158"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.2949061662198391,"2. How do ROBOSIM and InstAlign impact the effectiveness of ROBO-INSTRUCT?
159"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.29624664879356566,"We conduct our investigation by fine-tuning the Codellama-Python-7B model [30] on the synthetic
160"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.2975871313672922,"dataset generated by ROBO-INSTRUCT and evaluate the fine-tuned model using ROBOEVAL [10], a
161"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.29892761394101874,"domain-specific code generation benchmark for service mobile robots. In the following subsections,
162"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.3002680965147453,"we first provide a brief description of ROBOEVAL. Then we present our experimental results address-
163"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.30160857908847183,"ing the two main research questions. Finally, we offer more analysis of ROBOSIM, INSTALIGN, and
164"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.30294906166219837,"the synthetic dataset.
165"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.3042895442359249,"3.1
ROBOEVAL: A Domain-Specific Robot Code Generation Benchmark
166"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.30563002680965146,"Task Instruction
Go to the elevator. Wait until someone shows up and ask them if they are here for the tour. If 
yes, welcome them to the university, tell them to follow you, and take them to the main 
conference room. If not, wait for the next person. When you get to the conference room, say 
you have arrived at the conference room and also say enjoy your visit here!"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.306970509383378,"Canonical Solution
1  def task_program():
2   go_to(""elevator"")
3   while True:
4     if is_in_room(""person""):
5       response = ask("""", ""Are you here for the conference?"", [""Yes"", ""No""])
6       if response == ""Yes"":
7         say(""Welcome to the university. Please follow me."")
8         break
9     time.sleep(1)
10  go_to(""conference room”)
11  say(""We have arrived. Enjoy your time here"")"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.30831099195710454,"# Get the current location of the robot.
def get_current_location() -> str"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.3096514745308311,"# Get a list of all rooms.
def get_all_rooms() -> list[str]"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.3109919571045576,"# Check if an object is in the current room.
def is_in_room(object : str) -> bool"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.31233243967828417,"# Go to a specific named location.
def go_to(location : str) -> None"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.3136729222520107,"# Ask a person a question, and offer a set of specific 
options for the person to respond. Returns the response 
selected by the person.
def ask(person : str, question : str,"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.31501340482573725,options: list[str]) -> str
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.3163538873994638,"# Say the message out loud.
def say(message : str) -> None"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.31769436997319034,"# Pick up an object if you are not already holding one. You 
can only hold one object at a time.
def pick(obj: str) -> None"
IS ROBO-INSTRUCT EFFECTIVE AT GENERATING TRAINING DATA TO FINE-TUNE A SMALL LANGUAGE MODEL,0.3190348525469169,"# Place an object down if you are holding one.
def place(obj: str) -> None"
ROBOEVAL BENCHMARK TASKS,0.3203753351206434,"16 RoboEval Benchmark Tasks
RoboEval Domain-Speciﬁc API Deﬁnitions"
ROBOEVAL BENCHMARK TASKS,0.32171581769436997,"FindBackpack
ElevatorTour
…
GetDrink
WeatherPoll"
ROBOEVAL BENCHMARK TASKS,0.3230563002680965,Figure 3: ROBOEVAL APIs and benchmark task example.
ROBOEVAL BENCHMARK TASKS,0.32439678284182305,"ROBOEVAL is a domain-specific code generation benchmark, featuring a suite of 16 tasks designed
167"
ROBOEVAL BENCHMARK TASKS,0.3257372654155496,"to evaluate the ability of LLMs to understand custom APIs and generate programs for service robots.
168"
ROBOEVAL BENCHMARK TASKS,0.32707774798927614,"In this domain, a service robot can perceive objects, navigate to various locations, manipulate items,
169"
ROBOEVAL BENCHMARK TASKS,0.3284182305630027,"and communicate with humans. Furthermore, the robot should be capable of basic commonsense
170"
ROBOEVAL BENCHMARK TASKS,0.3297587131367292,"reasoning and executing complex tasks that involve conditional and repetitive actions. To facilitate
171"
ROBOEVAL BENCHMARK TASKS,0.33109919571045576,"these capabilities, ROBOEVAL defines a set of 8 API functions in Python as skill primitives. Fig. 3
172"
ROBOEVAL BENCHMARK TASKS,0.3324396782841823,"illustrates these function signatures and definitions, alongside an example task instruction and its
173"
ROBOEVAL BENCHMARK TASKS,0.33378016085790885,"canonical solution from the benchmark. In addition, unlike other popular code generation benchmark
174"
ROBOEVAL BENCHMARK TASKS,0.3351206434316354,"tasks [2, 6, 9, 14, 16, 19], the order of the robot’s actions is crucial for successfully completing the
175"
ROBOEVAL BENCHMARK TASKS,0.33646112600536193,"specified tasks. For instance, in the task ""bring me a marker from the classroom that does not have a
176"
ROBOEVAL BENCHMARK TASKS,0.3378016085790885,"whiteboard,"" the robot must check each classroom until it finds one without a whiteboard, whereas
177"
ROBOEVAL BENCHMARK TASKS,0.339142091152815,"simply bringing back a marker is insufficient. Hence, ROBOEVAL evaluates the generated program by
178"
ROBOEVAL BENCHMARK TASKS,0.34048257372654156,"executing it in a simulator to capture the action traces, which are subsequently validated for sequence
179"
ROBOEVAL BENCHMARK TASKS,0.3418230563002681,"correctness using temporal logic.
180"
ROBOEVAL BENCHMARK TASKS,0.34316353887399464,"3.2
RQ1: Is ROBO-INSTRUCT Effective at Generating Training Data to Fine-Tune a Small
181"
ROBOEVAL BENCHMARK TASKS,0.3445040214477212,"Language Model for Generating Domain-Specific Robot Programs?
182"
ROBOEVAL BENCHMARK TASKS,0.34584450402144773,"Experiment Setup. We use the open-weight LLM, Llama3-8B-Inst, for ROBO-INSTRUCT. To
183"
ROBOEVAL BENCHMARK TASKS,0.34718498659517427,"generate a diverse dataset, we employ nucleus sampling for creating instruction-program pairs,
184"
ROBOEVAL BENCHMARK TASKS,0.3485254691689008,"setting the temperature T = 1 and top p = 0.95. The maximum resampling limit is capped at 3 to
185"
ROBOEVAL BENCHMARK TASKS,0.34986595174262736,"accommodate instructions that initially produce invalid programs. For the LLM used in INSTALIGN,
186"
ROBOEVAL BENCHMARK TASKS,0.3512064343163539,"we empirically adjust the generation temperature to T = 0.3 to optimize performance. Furthermore,
187"
ROBOEVAL BENCHMARK TASKS,0.35254691689008044,"we assess the edit similarity between token sequences of each instruction pair in the dataset [15],
188"
ROBOEVAL BENCHMARK TASKS,0.353887399463807,"removing duplicates where the similarity score exceeds 0.6. We use the same setup to generate
189"
ROBOEVAL BENCHMARK TASKS,0.3552278820375335,"data via SELF-INSTRUCT. Instead of discarding invalid programs, SELF-INSTRUCT includes every
190"
ROBOEVAL BENCHMARK TASKS,0.35656836461126007,"generated instruction-program pair in the training dataset. Finally, we create two datasets with 5K
191"
ROBOEVAL BENCHMARK TASKS,0.3579088471849866,"instruction-program pairs each using SELF-INSTRUCT and ROBO-INSTRUCT respectively. These
192"
ROBOEVAL BENCHMARK TASKS,0.35924932975871315,"datasets are then used to fine-tune the Codellama-Python-7B model. The learning rate is set to be
193"
ROBOEVAL BENCHMARK TASKS,0.3605898123324397,"ROBOEVAL pass@1
Fine-tune
Model
# Param
T = 0
T = 0.2
Licensing"
ROBOEVAL BENCHMARK TASKS,0.36193029490616624,"-
GPT-4
-
83.75%
85.81%
Proprietary
-
GPT-3.5
-
67.5%
65.56%
Proprietary
-
Gemini-1.0-Pro
-
60.00%
59.88%
Proprietary"
ROBOEVAL BENCHMARK TASKS,0.3632707774798928,"-
Codellama-Python
7B
40.00%
39.31%
Open
-
Codellama-Python
34B
46.25%
48.25%
Open
-
Starcoder2
15B
62.5%
60.94%
Open
-
Deepseek-Coder
33B
53.75%
52.13%
Open
-
Llama3-Inst
8B
48.75%
48.38%
Open
Self-Instruct
Codellama-Python
7B
55.00%
52.69%
Open
Robo-Instruct (ours)
Codellama-Python
7B
68.75%
66.00%
Open"
ROBOEVAL BENCHMARK TASKS,0.3646112600536193,"Table 1: Pass@1 results of different LLMs on ROBOEVAL computed with greedy decoding T = 0
and nucleus sampling T = 0.2."
ROBOEVAL BENCHMARK TASKS,0.36595174262734587,"3e-5 with a warmup ratio of 3% and a constant lr scheduler. We employ the AdamW optimizer [20]
194"
ROBOEVAL BENCHMARK TASKS,0.3672922252010724,"with an effective batch size of 8, training each model for 5 epochs using a sequence length of 2048
195"
ROBOEVAL BENCHMARK TASKS,0.36863270777479895,"tokens. We train all our models on a single H-100 GPU using unsloth [35].
196"
ROBOEVAL BENCHMARK TASKS,0.3699731903485255,"Baselines. We divide our baseline models into 2 categories: 1) proprietary LLMs, including
197"
ROBOEVAL BENCHMARK TASKS,0.37131367292225204,"GPT4 [28], GPT3.5-Turbo [27], Gemino-Pro [33], and 2) open-weight LLMs, including Codellama-
198"
ROBOEVAL BENCHMARK TASKS,0.3726541554959786,"Python-7B [30], Codellama-Python-34B, Starcoder2-33B [21], Deepseek-Coder-33B [8], and
199"
ROBOEVAL BENCHMARK TASKS,0.3739946380697051,"Llama3-8B-Inst [1]. All the results are evaluated using ROBOEVAL and reported in Tab. 1.
200"
ROBOEVAL BENCHMARK TASKS,0.3753351206434316,"Tab. 1 presents the average pass@1 results for different LLMs on ROBOEVAL, using two different
201"
ROBOEVAL BENCHMARK TASKS,0.37667560321715815,"temperature settings for generation: greedy decoding at a temperatures of T = 0 and nucleus
202"
ROBOEVAL BENCHMARK TASKS,0.3780160857908847,"sampling at a temperature of T = 0.2. The results show that ROBO-INSTRUCT-fine-tuned Codellama
203"
ROBOEVAL BENCHMARK TASKS,0.37935656836461124,"significantly improves upon the base Codellama-Python-7B and outperforms the SELF-INSTRUCT-
204"
ROBOEVAL BENCHMARK TASKS,0.3806970509383378,"fine-tuned variant. Notably, it surpasses all open-weight models, including larger ones like Codellama-
205"
ROBOEVAL BENCHMARK TASKS,0.3820375335120643,"Python-34B and Deepseek-Coder-33B. Additionally, although the training dataset was generated
206"
ROBOEVAL BENCHMARK TASKS,0.38337801608579086,"using Llama3-8B-Inst, which scores less than 50% pass@1 on ROBOEVAL, our ROBO-INSTRUCT-
207"
ROBOEVAL BENCHMARK TASKS,0.3847184986595174,"fine-tuned model still achieves a significant improvement, scoring 68.75% under deterministic
208"
ROBOEVAL BENCHMARK TASKS,0.38605898123324395,"temperature settings for generation. Finally, compared to proprietary models, while our ROBO-
209"
ROBOEVAL BENCHMARK TASKS,0.3873994638069705,"INSTRUCT-fine-tuned model trails the more powerful GPT-4, it outperforms GPT-3.5-Turbo and
210"
ROBOEVAL BENCHMARK TASKS,0.38873994638069703,"Gemini-1.0-Pro in generating programs for service mobile robots. This result demonstrates the
211"
ROBOEVAL BENCHMARK TASKS,0.3900804289544236,"effectiveness of our approach in generating domain-specific robot program data for fine-tuning a
212"
ROBOEVAL BENCHMARK TASKS,0.3914209115281501,"small language model. It suggests that the fine-tuned model could potentially replace some proprietary
213"
ROBOEVAL BENCHMARK TASKS,0.39276139410187666,"models, providing a more cost-effective and private option for local deployment.
214"
ROBOEVAL BENCHMARK TASKS,0.3941018766756032,"3.3
RQ2: How Do ROBOSIM and InstAlign Impact the Effectiveness of ROBO-INSTRUCT?
215"
ROBOEVAL BENCHMARK TASKS,0.39544235924932974,"T=0
T=0.2
Invalid
Method
pass@1
Improv.
pass@1
Improv.
Programs"
ROBOEVAL BENCHMARK TASKS,0.3967828418230563,"Codellama-7B-Python
40.00%
+0%
39.31%
+0%
38.31%
SELF-INSTRUCT
55.00%
+15.00%
52.69%
+13.38%
20.94%
+Reject Unsolvable (RU)
60.00%
+20.00%
57.62%
+18.31%
23.38%
+ROBOSIM + RU
63.75%
+23.75%
63.88%
+24.57%
14.13%
+INSTALIGN + RU
58.75%
+18.75%
59.81%
+20.50%
23.44%
+Both (ROBO-INSTRUCT)
68.75%
+28.75%
66.00%
+26.69%
17.07%"
ROBOEVAL BENCHMARK TASKS,0.39812332439678283,"Table 2: Pass@1 results of different LLMs on ROBOEVAL computed with greedy decoding T = 0
and nucleus sampling T = 0.2."
ROBOEVAL BENCHMARK TASKS,0.39946380697050937,"Using the same setup as in the previous section, we investigate the effectiveness of ROBOSIM
216"
ROBOEVAL BENCHMARK TASKS,0.4008042895442359,"and INSTALIGN. Since SELF-INSTRUCT may generate invalid instructions that no corresponding
217"
ROBOEVAL BENCHMARK TASKS,0.40214477211796246,"valid program can pass in ROBOSIM, we propose rejecting these unsolvable instructions (we name
218"
ROBOEVAL BENCHMARK TASKS,0.403485254691689,"this process RU) to evaluate the upperbound performance of SELF-INSTRUCT. Tab. 2 shows the
219"
ROBOEVAL BENCHMARK TASKS,0.40482573726541554,"average pass@1 results from Codellama-7B-Python fine-tuned on different datasets generated by
220"
ROBOEVAL BENCHMARK TASKS,0.4061662198391421,"each method. First, findings from SELF-INSTRUCT + RU indicate that simply discarding invalid
221"
ROBOEVAL BENCHMARK TASKS,0.4075067024128686,"instructions could also improve model performance. Additionally, fine-tuning with a dataset created
222"
ROBOEVAL BENCHMARK TASKS,0.40884718498659517,"from SELF-INSTRUCT+RoboSim results in the smallest proportion of invalid program errors. Finally,
223"
ROBOEVAL BENCHMARK TASKS,0.4101876675603217,"while incorporating either ROBOSIM or INSTALIGN individually offers some improvement over the
224"
ROBOEVAL BENCHMARK TASKS,0.41152815013404825,"baseline SELF-INSTRUCT + RU results, ROBO-INSTRUCT still results in the best performance. This
225"
ROBOEVAL BENCHMARK TASKS,0.4128686327077748,"indicates that the integration of these two components is important to the framework’s effectiveness.
226"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.41420911528150134,"3.4
Qualitative analysis of the generated program errors
227"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4155495978552279,Syntax Error
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4168900804289544,"1 def task_program():
2   go_to(""David's office"")
3   response = ask(""David"", ""Where do you want to meet 
     tomorrow?"",["""") + get_all_rooms() + [""""])
4   go_to(response)
5   say(""Tomorrow's Meeting at 10am"")"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.41823056300268097,"SyntaxError: closing parenthesis ')' does not match opening 
parenthesis '['"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4195710455764075,Hallucination of New APIs
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.42091152815013405,"1 def task_program():
2   go_to(""main hall"")
3   say(""Everyone, stop what you're doing. I need your help
     with a quick survey."")
4   for person in get_people_in_room():
5     response = ask(person, ""How do you feel about the
       sofa?"",[""Good"", ""Bad"", ""Neutral""])
6     say(person + "" thinks the sofa is ""+ response)"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4222520107238606,NameError: name 'get_people_in_room' is not defined
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.42359249329758714,Incorrect Use of API
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4249329758713137,"1 def task_program():
2   current_location = get_current_location()
3   all_rooms_in_location =  
      get_all_rooms(current_location)
4   for room in all_rooms_in_location:
5     go_to(room)
6   go_to(current_location)
7   say(""I am now back at my initial location"")"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4262734584450402,"TypeError: get_all_rooms() takes 0 positional arguments but 1 
was given"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.42761394101876676,Incorrect Use of API Return Value
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4289544235924933,"1 def task_program():
2   list_of_rooms = get_all_rooms() 
3   rooms_with_robots = [] 
4   for room in list_of_rooms: 
5     if ""robot"" in is_in_room(""robot""): 
6       go_to(room)"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.43029490616621985,"TypeError: is_in_room(""robot"") returns a 'bool' type and it is 
not iterable"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4316353887399464,Logical Error
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.43297587131367293,"1 def task_program():
2   if not is_in_room(""watering can""): 
3       pick(""watering can"") 
4   go_to(""flower bed"") 
5   response = ask(""John"", ""Do you want the watering
      can?"",[""yes"", ""no"", ""ask Susan""]) 
6   say(""John said: "" + response)"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4343163538873995,"RobotPickError: 'watering can' does not exist in the current 
location"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.435656836461126,Logical Error
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.43699731903485256,"1 def task_program():
2   go_to(""game room"")
3   if is_in_room(""Jack""):
4     say(""Hello Jack"")        
5   response = ask(""Jack"",""Do you want to play a game?"", 
      [""Yes"", ""No""])"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4383378016085791,RobotAskError: 'Jack' is not at the 'game room' location
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.43967828418230565,Logical Error
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4410187667560322,"1 def task_program():
2   go_to(""item storage room"")
3   pick(""item storage room"")"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.44235924932975873,"RobotPickError: 'item storage room' is a location that cannot 
be picked"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4436997319034853,Logical Error
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4450402144772118,"1 def task_program():    
2   for room in get_all_rooms(): 
3     go_to(room) 
4     pick(""toy"")
5     go_to(""living room"")
6     if not is_in_room(""toy""):
7       place(""toy"")"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.44638069705093836,"RobotPickError: robot can only hold one thing at a time and is 
already holding 'toy' ×
× ×
× ×
× ×
×"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4477211796246649,"Figure 4: SELF-INSTRUCT-Generated Program Errors: Examples 1 to 4 illustrate errors specific to
the Python language, and Examples 5 to 8 highlight errors rooted in domain-specific constraints.2"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.44906166219839144,"We analyze invalid programs identified by ROBOSIM, categorizing the errors into two types: language-
228"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.450402144772118,"native errors and domain-specific constraint violations. Fig. 4 displays eight examples of these
229"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4517426273458445,"programs, with Examples 1 to 4 illustrating errors specific to the Python language, and Examples 5
230"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.45308310991957107,"to 8 highlighting errors rooted in domain-specific constraints. Language-native errors are generally
231"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4544235924932976,"straightforward, such as syntax errors, the use of undefined variables or functions, or improper use of
232"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.45576407506702415,"provided APIs.
233"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4571045576407507,"In contrast, errors related to domain-specific constraints tend to be more complex to detect. For
234"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4584450402144772,"instance, Example 5 illustrates the program incorrectly trying to pick up a watering can (line 3) after
235"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4597855227882037,"establishing that it is not present at the location (line 2). Similarly, Example 6 demonstrates an error
236"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.46112600536193027,"where the program inappropriately asks Jack (line 5) after confirming his absence from the room
237"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4624664879356568,2Programs have been adapted to succinctly demonstrate the types of errors and fit within the figure.
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.46380697050938335,"(line 3). Example 7 illustrates a scenario in which ROBOSIM updates the world state by labeling
238"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4651474530831099,"""item storage room"" as a location after executing the go_to command (line 2). Subsequently, the
239"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.46648793565683644,"robot attempts to pick up this location (line 3), resulting in an error. Example 9 is the most intricate
240"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.467828418230563,"scenario where the world state in the living room is updated to include a toy after the robot places it
241"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4691689008042895,"there (line 7). When the robot returns to the living room for the second time (line 5), it does not place
242"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.47050938337801607,"down what it holds (line 7). Hence, in the third room the robot visits (line 3), when it attempts to pick
243"
QUALITATIVE ANALYSIS OF THE GENERATED PROGRAM ERRORS,0.4718498659517426,"up a toy again (line 4), an error occurs because the robot can only carry one item at a time.
244"
RELATED WORK,0.47319034852546915,"4
Related Work
245"
LLMS FOR ROBOT CODE GENERATION,0.4745308310991957,"4.1
LLMs for Robot Code Generation
246"
LLMS FOR ROBOT CODE GENERATION,0.47587131367292224,"LLMs have shown impressive capabilities in generating robot programs from natural language
247"
LLMS FOR ROBOT CODE GENERATION,0.4772117962466488,"[11, 17, 31]. One popular approach uses LLMs to generate composable costmaps for robots to
248"
LLMS FOR ROBOT CODE GENERATION,0.4785522788203753,"plan their motion on. In this approach, Voxposer [12] focuses on the tabletop manipulation setting
249"
LLMS FOR ROBOT CODE GENERATION,0.47989276139410186,"and NavCon [3] focuses on creating composable maps for navigation. Using LLM to create reward
250"
LLMS FOR ROBOT CODE GENERATION,0.4812332439678284,"functions is also promising. Eureka [23, 24] and Language to Rewards for Robotic Skill Synthesis [41]
251"
LLMS FOR ROBOT CODE GENERATION,0.48257372654155495,"both show that LLM can generate good reward functions that allows robots to acquire complex skills.
252"
LLMS FOR ROBOT CODE GENERATION,0.4839142091152815,"Finally, LLM can also be used to generate programs for high-level planning. LLM+p [18] outputs a
253"
LLMS FOR ROBOT CODE GENERATION,0.48525469168900803,"robot plan in the form of the well-defined planning domain definition language (PDDL). Tidybot [39]
254"
LLMS FOR ROBOT CODE GENERATION,0.4865951742627346,"uses an LLM to generate a rule that captures user preferences from examples and executes a program
255"
LLMS FOR ROBOT CODE GENERATION,0.4879356568364611,"to sequentially complete the task in order. RoboEval [10] focuses on generating domain-specific
256"
LLMS FOR ROBOT CODE GENERATION,0.48927613941018766,"programs for service mobile robots. It generates a program that allows the service robot to carry out
257"
LLMS FOR ROBOT CODE GENERATION,0.4906166219839142,"long-horizon tasks and then validates the correctness of the program.
258"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.49195710455764075,"4.2
Generating Datasets For Fine-tuning LLMs
259"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.4932975871313673,"To enhance LLMs’ performance in code generation, numerous studies have explored the creation
260"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.49463806970509383,"of specialized datasets [13, 25, 26]. SELF-INSTRUCT [36] is one popular method for generating
261"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.4959785522788204,"synthetic datasets using an LLM. Following this methodology, Alpaca [32] generates 52K instruction-
262"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.4973190348525469,"following demonstrations and subsequently fine-tunes the LLaMA 7B model [34] to create Alpaca 7B,
263"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.49865951742627346,"which can behave qualitatively similarly to OpenAI’s text-davinci-003. Code Alpaca [5] extends this
264"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5,"approach to generate code instructions using 21 seed tasks, while Gorilla-LM [29] adapts the method
265"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5013404825737265,"to focus on ML domain-specific APIs from Huggingface, TensorFlow Hub, and Torch Hub. To create
266"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5026809651474531,"more complex instructions, Evol-Instruct [22, 40] proposes iteratively updating instructions to become
267"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5040214477211796,"more complex through different prompting strategies. In addition to Evol-Instruct, OSS-Instruct [38]
268"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5053619302949062,"uses open-source code snippets to generate 75K high-quality instruction data and fine-tunes the
269"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5067024128686327,"Codelllama-Python-7B model to create Magicoder, which can match the performance of GPT-3.5-
270"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5080428954423593,"Turbo [27] on HumanEval [6]. While these works focus on creating seed instruction sets to generate
271"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5093833780160858,"synthetic data for effectively fine-tuning an LLM, our research investigates post-processing methods
272"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5107238605898123,"in addition to SELF-INSTRUCT. Specifically, we concentrate on generating domain-specific programs
273"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5120643431635389,"in robotics [10], where we can effectively leverage constraints to filter out erroneous programs.
274"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5134048257372654,"5
Conclusion, Limitation and Future Works
275"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.514745308310992,"In this work, we introduce ROBO-INSTRUCT, a novel framework to generate synthetic training data
276"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5160857908847185,"to fine-tune small language models for domain-specific robot programs. ROBO-INSTRUCT comprises
277"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.517426273458445,"two novel components: 1) ROBOSIM, an angelic-execution-based algorithm to effectively validate
278"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5187667560321716,"SELF-INSTRUCT-generated programs, and 2) INSTALIGN, an instruction alignment procedure to
279"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5201072386058981,"revise instructions to better align with the generated programs. The experimental results demonstrate
280"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5214477211796247,"that the Codellama-Python-7B model fine-tuned on the ROBO-INSTRUCT-generated dataset can
281"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5227882037533512,"significantly outperform many popular open-weight LLMs for generating domain-specific robot
282"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5241286863270778,"programs. It also outperforms two proprietary LLMs, GPT-3.5-Turbo and Gemino-1.0-Pro, as well
283"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5254691689008043,"as the SELF-INSTRUCT-fine-tuned variant. A limitation of this study is that ROBO-INSTRUCT
284"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5268096514745308,"relies on SELF-INSTRUCT to filter invalid programs, making the dataset quality dependent on SELF-
285"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5281501340482574,"INSTRUCT’s performance. This can introduce biases if SELF-INSTRUCT consistently fails in certain
286"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5294906166219839,"areas. Future work will explore integrating ROBO-INSTRUCT with advanced methods like Evol-Inst
287"
GENERATING DATASETS FOR FINE-TUNING LLMS,0.5308310991957105,"and OSS-Inst to enhance dataset quality for domain-specific robot programs.
288"
REFERENCES,0.532171581769437,"References
289"
REFERENCES,0.5335120643431636,"[1] Meta AI. Introducing meta llama 3: The most capable openly available llm to date. https:
290"
REFERENCES,0.5348525469168901,"//ai.meta.com/blog/meta-llama-3/, 2024. Accessed: 2024-05-21.
291"
REFERENCES,0.5361930294906166,"[2] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David
292"
REFERENCES,0.5375335120643432,"Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. Program synthesis
293"
REFERENCES,0.5388739946380697,"with large language models, 2021.
294"
REFERENCES,0.5402144772117963,"[3] Harel Biggie, Ajay Narasimha Mopidevi, Dusty Woods, and Christoffer Heckman. Tell me
295"
REFERENCES,0.5415549597855228,"where to go: A composable framework for context-aware embodied robot navigation, 2023.
296"
REFERENCES,0.5428954423592494,"[4] Manfred Broy and Martin Wirsing. On the algebraic specification of nondeterministic program-
297"
REFERENCES,0.5442359249329759,"ming languages. In Proceedings of the 6th Colloquium on Trees in Algebra and Programming,
298"
REFERENCES,0.5455764075067024,"CAAP ’81, page 162–179, Berlin, Heidelberg, 1981. Springer-Verlag. ISBN 3540108289.
299"
REFERENCES,0.546916890080429,"[5] Sahil Chaudhary. Code alpaca: An instruction-following llama model for code generation.
300"
REFERENCES,0.5482573726541555,"https://github.com/sahil280114/codealpaca, 2023.
301"
REFERENCES,0.5495978552278821,"[6] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto,
302"
REFERENCES,0.5509383378016086,"Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul
303"
REFERENCES,0.5522788203753352,"Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke
304"
REFERENCES,0.5536193029490617,"Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad
305"
REFERENCES,0.5549597855227882,"Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias
306"
REFERENCES,0.5563002680965148,"Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex
307"
REFERENCES,0.5576407506702413,"Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,
308"
REFERENCES,0.5589812332439679,"William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra,
309"
REFERENCES,0.5603217158176944,"Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer,
310"
REFERENCES,0.561662198391421,"Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech
311"
REFERENCES,0.5630026809651475,"Zaremba. Evaluating large language models trained on code. 2021.
312"
REFERENCES,0.564343163538874,"[7] Richard E. Fikes and Nils J. Nilsson. Strips: a new approach to the application of theorem
313"
REFERENCES,0.5656836461126006,"proving to problem solving. In Proceedings of the 2nd International Joint Conference on
314"
REFERENCES,0.5670241286863271,"Artificial Intelligence, IJCAI’71, page 608–620, San Francisco, CA, USA, 1971. Morgan
315"
REFERENCES,0.5683646112600537,"Kaufmann Publishers Inc.
316"
REFERENCES,0.5697050938337802,"[8] Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen,
317"
REFERENCES,0.5710455764075067,"Xiao Bi, Y. Wu, Y. K. Li, Fuli Luo, Yingfei Xiong, and Wenfeng Liang. Deepseek-coder:
318"
REFERENCES,0.5723860589812333,"When the large language model meets programming – the rise of code intelligence, 2024. URL
319"
REFERENCES,0.5737265415549598,"https://arxiv.org/abs/2401.14196.
320"
REFERENCES,0.5750670241286864,"[9] Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora, Ethan Guo,
321"
REFERENCES,0.5764075067024129,"Collin Burns, Samir Puranik, Horace He, Dawn Song, and Jacob Steinhardt. Measuring coding
322"
REFERENCES,0.5777479892761395,"challenge competence with apps. NeurIPS, 2021.
323"
REFERENCES,0.579088471849866,"[10] Zichao Hu, Francesca Lucchetti, Claire Schlesinger, Yash Saxena, Anders Freeman, Sadanand
324"
REFERENCES,0.5804289544235925,"Modak, Arjun Guha, and Joydeep Biswas. Deploying and evaluating llms to program service
325"
REFERENCES,0.5817694369973191,"mobile robots. IEEE Robotics and Automation Letters, 9(3):2853–2860, 2024. doi: 10.1109/
326"
REFERENCES,0.5831099195710456,"LRA.2024.3360020.
327"
REFERENCES,0.5844504021447721,"[11] Chenguang Huang, Oier Mees, Andy Zeng, and Wolfram Burgard. Visual language maps
328"
REFERENCES,0.5857908847184986,"for robot navigation. In Proceedings of the IEEE International Conference on Robotics and
329"
REFERENCES,0.5871313672922251,"Automation (ICRA), London, UK, 2023.
330"
REFERENCES,0.5884718498659517,"[12] Wenlong Huang, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun Wu, and Li Fei-Fei. Vox-
331"
REFERENCES,0.5898123324396782,"poser: Composable 3d value maps for robotic manipulation with language models. In 7th
332"
REFERENCES,0.5911528150134048,"Annual Conference on Robot Learning, 2023. URL https://openreview.net/forum?id=
333"
REFERENCES,0.5924932975871313,"9_8LF30mOC.
334"
REFERENCES,0.5938337801608579,"[13] Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi Rui Tam, Keith
335"
REFERENCES,0.5951742627345844,"Stevens, Abdullah Barhoum, Duc Minh Nguyen, Oliver Stanley, Richárd Nagyfi, Shahul
336"
REFERENCES,0.596514745308311,"ES, Sameer Suri, David Alexandrovich Glushkov, Arnav Varma Dantuluri, Andrew Maguire,
337"
REFERENCES,0.5978552278820375,"Christoph Schuhmann, Huu Nguyen, and Alexander Julian Mattick. Openassistant conversations
338"
REFERENCES,0.599195710455764,"- democratizing large language model alignment. In Thirty-seventh Conference on Neural
339"
REFERENCES,0.6005361930294906,"Information Processing Systems Datasets and Benchmarks Track, 2023. URL https://
340"
REFERENCES,0.6018766756032171,"openreview.net/forum?id=VSJotgbPHF.
341"
REFERENCES,0.6032171581769437,"[14] Yuhang Lai, Chengxi Li, Yiming Wang, Tianyi Zhang, Ruiqi Zhong, Luke Zettlemoyer, Wen-
342"
REFERENCES,0.6045576407506702,"Tau Yih, Daniel Fried, Sida Wang, and Tao Yu. Ds-1000: A natural and reliable benchmark for
343"
REFERENCES,0.6058981233243967,"data science code generation. ArXiv, abs/2211.11501, 2022.
344"
REFERENCES,0.6072386058981233,"[15] Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris
345"
REFERENCES,0.6085790884718498,"Callison-Burch, and Nicholas Carlini. Deduplicating training data makes language models better.
346"
REFERENCES,0.6099195710455764,"In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, Proceedings of the 60th
347"
REFERENCES,0.6112600536193029,"Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),
348"
REFERENCES,0.6126005361930295,"pages 8424–8445, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi:
349"
REFERENCES,0.613941018766756,"10.18653/v1/2022.acl-long.577. URL https://aclanthology.org/2022.acl-long.577.
350"
REFERENCES,0.6152815013404825,"[16] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond,
351"
REFERENCES,0.6166219839142091,"Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy,
352"
REFERENCES,0.6179624664879356,"Cyprien de Masson d’Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl,
353"
REFERENCES,0.6193029490616622,"Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson,
354"
REFERENCES,0.6206434316353887,"Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. Competition-level
355"
REFERENCES,0.6219839142091153,"code generation with alphacode. Science, 378(6624):1092–1097, 2022. doi: 10.1126/science.
356"
REFERENCES,0.6233243967828418,"abq1158. URL https://www.science.org/doi/abs/10.1126/science.abq1158.
357"
REFERENCES,0.6246648793565683,"[17] Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian Ichter, Pete Florence,
358"
REFERENCES,0.6260053619302949,"and Andy Zeng. Code as policies: Language model programs for embodied control. In arXiv
359"
REFERENCES,0.6273458445040214,"preprint arXiv:2209.07753, 2022.
360"
REFERENCES,0.628686327077748,"[18] Bo Liu, Yuqian Jiang, et al. LLM+P: Empowering Large Language Models with Optimal
361"
REFERENCES,0.6300268096514745,"Planning Proficiency. arXiv:2304.11477, 2023.
362"
REFERENCES,0.631367292225201,"[19] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. Is your code generated
363"
REFERENCES,0.6327077747989276,"by chatGPT really correct? rigorous evaluation of large language models for code generation.
364"
REFERENCES,0.6340482573726541,"In Thirty-seventh Conference on Neural Information Processing Systems, 2023. URL https:
365"
REFERENCES,0.6353887399463807,"//openreview.net/forum?id=1qvx610Cu7.
366"
REFERENCES,0.6367292225201072,"[20] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In International
367"
REFERENCES,0.6380697050938338,"Conference on Learning Representations, 2019. URL https://openreview.net/forum?
368"
REFERENCES,0.6394101876675603,"id=Bkg6RiCqY7.
369"
REFERENCES,0.6407506702412868,"[21] Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico Cassano, Joel Lamy-Poirier, Noua-
370"
REFERENCES,0.6420911528150134,"mane Tazi, Ao Tang, Dmytro Pykhtar, Jiawei Liu, Yuxiang Wei, Tianyang Liu, Max Tian,
371"
REFERENCES,0.6434316353887399,"Denis Kocetkov, Arthur Zucker, Younes Belkada, Zijian Wang, Qian Liu, Dmitry Abulkhanov,
372"
REFERENCES,0.6447721179624665,"Indraneil Paul, Zhuang Li, Wen-Ding Li, Megan Risdal, Jia Li, Jian Zhu, Terry Yue Zhuo,
373"
REFERENCES,0.646112600536193,"Evgenii Zheltonozhskii, Nii Osae Osae Dade, Wenhao Yu, Lucas Krauß, Naman Jain, Yixuan
374"
REFERENCES,0.6474530831099196,"Su, Xuanli He, Manan Dey, Edoardo Abati, Yekun Chai, Niklas Muennighoff, Xiangru Tang,
375"
REFERENCES,0.6487935656836461,"Muhtasham Oblokulov, Christopher Akiki, Marc Marone, Chenghao Mou, Mayank Mishra,
376"
REFERENCES,0.6501340482573726,"Alex Gu, Binyuan Hui, Tri Dao, Armel Zebaze, Olivier Dehaene, Nicolas Patry, Canwen Xu,
377"
REFERENCES,0.6514745308310992,"Julian McAuley, Han Hu, Torsten Scholak, Sebastien Paquet, Jennifer Robinson, Carolyn Jane
378"
REFERENCES,0.6528150134048257,"Anderson, Nicolas Chapados, Mostofa Patwary, Nima Tajbakhsh, Yacine Jernite, Carlos Muñoz
379"
REFERENCES,0.6541554959785523,"Ferrandis, Lingming Zhang, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, and
380"
REFERENCES,0.6554959785522788,"Harm de Vries. Starcoder 2 and the stack v2: The next generation, 2024.
381"
REFERENCES,0.6568364611260054,"[22] Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing
382"
REFERENCES,0.6581769436997319,"Ma, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models
383"
REFERENCES,0.6595174262734584,"with evol-instruct. In The Twelfth International Conference on Learning Representations, 2024.
384"
REFERENCES,0.660857908847185,"URL https://openreview.net/forum?id=UnUwSIgK5W.
385"
REFERENCES,0.6621983914209115,"[23] Yecheng Jason Ma, William Liang, Guanzhi Wang, De-An Huang, Osbert Bastani, Dinesh
386"
REFERENCES,0.6635388739946381,"Jayaraman, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Eureka: Human-level reward design
387"
REFERENCES,0.6648793565683646,"via coding large language models. arXiv preprint arXiv: Arxiv-2310.12931, 2023.
388"
REFERENCES,0.6662198391420912,"[24] Yecheng Jason Ma, William Liang, Hungju Wang, Sam Wang, Yuke Zhu, Linxi Fan, Osbert
389"
REFERENCES,0.6675603217158177,"Bastani, and Dinesh Jayaraman. Dreureka: Language model guided sim-to-real transfer. 2024.
390"
REFERENCES,0.6689008042895442,"[25] Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman,
391"
REFERENCES,0.6702412868632708,"Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, et al. Crosslin-
392"
REFERENCES,0.6715817694369973,"gual generalization through multitask finetuning. arXiv preprint arXiv:2211.01786, 2022.
393"
REFERENCES,0.6729222520107239,"[26] Niklas Muennighoff, Qian Liu, Armel Randy Zebaze, Qinkai Zheng, Binyuan Hui, Terry Yue
394"
REFERENCES,0.6742627345844504,"Zhuo, Swayam Singh, Xiangru Tang, Leandro Von Werra, and Shayne Longpre. Octopack:
395"
REFERENCES,0.675603217158177,"Instruction tuning code large language models. In The Twelfth International Conference on
396"
REFERENCES,0.6769436997319035,"Learning Representations, 2024. URL https://openreview.net/forum?id=mw1PWNSWZP.
397"
REFERENCES,0.67828418230563,"[27] OpenAI. Chatgpt: Optimizing language models for dialogue. https://openai.com/blog/
398"
REFERENCES,0.6796246648793566,"chatgpt/, 2022.
399"
REFERENCES,0.6809651474530831,"[28] OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-
400"
REFERENCES,0.6823056300268097,"cia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red
401"
REFERENCES,0.6836461126005362,"Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Moham-
402"
REFERENCES,0.6849865951742627,"mad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher
403"
REFERENCES,0.6863270777479893,"Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brock-
404"
REFERENCES,0.6876675603217158,"man, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann,
405"
REFERENCES,0.6890080428954424,"Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis,
406"
REFERENCES,0.6903485254691689,"Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey
407"
REFERENCES,0.6916890080428955,"Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux,
408"
REFERENCES,0.693029490616622,"Thomas Degry, Noah Deutsch, Damien Deville, et al. Gpt-4 technical report, 2024.
409"
REFERENCES,0.6943699731903485,"[29] Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. Gorilla: Large language
410"
REFERENCES,0.6957104557640751,"model connected with massive apis. arXiv preprint arXiv:2305.15334, 2023.
411"
REFERENCES,0.6970509383378016,"[30] Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan,
412"
REFERENCES,0.6983914209115282,"Yossi Adi, Jingyu Liu, Romain Sauvestre, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov,
413"
REFERENCES,0.6997319034852547,"Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan
414"
REFERENCES,0.7010723860589813,"Xiong, Alexandre Défossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas
415"
REFERENCES,0.7024128686327078,"Usunier, Thomas Scialom, and Gabriel Synnaeve. Code llama: Open foundation models for
416"
REFERENCES,0.7037533512064343,"code, 2024.
417"
REFERENCES,0.7050938337801609,"[31] Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay,
418"
REFERENCES,0.7064343163538874,"Dieter Fox, Jesse Thomason, and Animesh Garg. Progprompt: Generating situated robot task
419"
REFERENCES,0.707774798927614,"plans using large language models. In 2023 IEEE International Conference on Robotics and
420"
REFERENCES,0.7091152815013405,"Automation (ICRA), pages 11523–11530, 2023. doi: 10.1109/ICRA48891.2023.10161317.
421"
REFERENCES,0.710455764075067,"[32] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy
422"
REFERENCES,0.7117962466487936,"Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model.
423"
REFERENCES,0.7131367292225201,"https://github.com/tatsu-lab/stanford_alpaca, 2023.
424"
REFERENCES,0.7144772117962467,"[33] Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut,
425"
REFERENCES,0.7158176943699732,"Johan Schalkwyk, Andrew M. Dai, Anja Hauth, Katie Millican, David Silver, Melvin Johnson,
426"
REFERENCES,0.7171581769436998,"Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, Timothy
427"
REFERENCES,0.7184986595174263,"Lillicrap, Angeliki Lazaridou, Orhan Firat, James Molloy, Michael Isard, Paul R. Barham, Tom
428"
REFERENCES,0.7198391420911529,"Hennigan, Benjamin Lee, Fabio Viola, et al. Gemini: A family of highly capable multimodal
429"
REFERENCES,0.7211796246648794,"models, 2024.
430"
REFERENCES,0.7225201072386059,"[34] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timo-
431"
REFERENCES,0.7238605898123325,"thée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez,
432"
REFERENCES,0.725201072386059,"Armand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation
433"
REFERENCES,0.7265415549597856,"language models, 2023.
434"
REFERENCES,0.7278820375335121,"[35] Unslothai.
Unsloth: Finetune llama 3, mistral & gemma llms 2-5x faster with 80 URL
435"
REFERENCES,0.7292225201072386,"https://github.com/unslothai/unsloth. Accessed: 2024-05-22.
436"
REFERENCES,0.7305630026809652,"[36] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi,
437"
REFERENCES,0.7319034852546917,"and Hannaneh Hajishirzi. Self-instruct: Aligning language model with self generated instruc-
438"
REFERENCES,0.7332439678284183,"tions, 2022.
439"
REFERENCES,0.7345844504021448,"[37] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi,
440"
REFERENCES,0.7359249329758714,"Quoc V Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language
441"
REFERENCES,0.7372654155495979,"models. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors,
442"
REFERENCES,0.7386058981233244,"Advances in Neural Information Processing Systems, 2022.
443"
REFERENCES,0.739946380697051,"[38] Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang. Magicoder: Source
444"
REFERENCES,0.7412868632707775,"code is all you need, 2023.
445"
REFERENCES,0.7426273458445041,"[39] Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song, Jeannette
446"
REFERENCES,0.7439678284182306,"Bohg, Szymon Rusinkiewicz, and Thomas Funkhouser. Tidybot: Personalized robot assistance
447"
REFERENCES,0.7453083109919572,"with large language models. Autonomous Robots, 2023.
448"
REFERENCES,0.7466487935656837,"[40] Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, Qing-
449"
REFERENCES,0.7479892761394102,"wei Lin, and Daxin Jiang. WizardLM: Empowering large pre-trained language models to follow
450"
REFERENCES,0.7493297587131368,"complex instructions. In The Twelfth International Conference on Learning Representations,
451"
REFERENCES,0.7506702412868632,"2024. URL https://openreview.net/forum?id=CfXh93NDgH.
452"
REFERENCES,0.7520107238605898,"[41] Wenhao Yu, Nimrod Gileadi, Chuyuan Fu, Sean Kirmani, Kuang-Huei Lee, Montse Gonza-
453"
REFERENCES,0.7533512064343163,"lez Arenas, Hao-Tien Lewis Chiang, Tom Erez, Leonard Hasenclever, Jan Humplik, Brian
454"
REFERENCES,0.7546916890080428,"Ichter, Ted Xiao, Peng Xu, Andy Zeng, Tingnan Zhang, Nicolas Heess, Dorsa Sadigh, Jie
455"
REFERENCES,0.7560321715817694,"Tan, Yuval Tassa, and Fei Xia. Language to rewards for robotic skill synthesis. Arxiv preprint
456"
REFERENCES,0.7573726541554959,"arXiv:2306.08647, 2023.
457"
REFERENCES,0.7587131367292225,"A
Appendix
458"
REFERENCES,0.760053619302949,"A.1
Overview
459"
REFERENCES,0.7613941018766756,"In this appendix, we first present ablation experiments to investigate the percentage of invalid
460"
REFERENCES,0.7627345844504021,"programs generated by SELF-INSTRUCT and examine how the generation temperature in INSTALIGN
461"
REFERENCES,0.7640750670241286,"affects final performance. Next, we analyze and compare the datasets generated by ROBO-INSTRUCT
462"
REFERENCES,0.7654155495978552,"and SELF-INSTRUCT. Finally, we list the seed tasks used in ROBOEVALand the CoT prompt.
463"
REFERENCES,0.7667560321715817,"A.2
Ablation Exmperiments
464"
REFERENCES,0.7680965147453083,Figure 5: Ablation Experiments
REFERENCES,0.7694369973190348,"A.2.1
effectivenss of the simulator
465"
REFERENCES,0.7707774798927614,"We analyze the percentage of instruction-program pairs discarded by ROBOSIM at various maximum
466"
REFERENCES,0.7721179624664879,"resampling limits, as shown in Fig. 5. Initially, with the maximum resampling limit set to 0, disabling
467"
REFERENCES,0.7734584450402144,"the rejection-sampling method, approximately 51% of the programs generated by SELF-INSTRUCT
468"
REFERENCES,0.774798927613941,"contain errors. As the limit increases, fewer programs are discarded. However, there is a diminishing
469"
REFERENCES,0.7761394101876675,"return; even with the maximum resampling limit set to 10, about 15% of the instructions still result in
470"
REFERENCES,0.7774798927613941,"invalid programs.
471"
REFERENCES,0.7788203753351206,"A.2.2
Instruction Alignment model temperature
472"
REFERENCES,0.7801608579088471,"We further investigate how varying LLM temperatures for generating Irevised in INSTALIGN impact
473"
REFERENCES,0.7815013404825737,"the performance of the fine-tuned model. Fig. 5 shows the bar chart of the pass@1 score of the
474"
REFERENCES,0.7828418230563002,"models fine-tuned over datasets generated using different LLM temperatures in INSTALIGN. The
475"
REFERENCES,0.7841823056300268,"model performs the best when fine-tuned on the dataset generated using LLM temperature T = 0.3.
476"
REFERENCES,0.7855227882037533,"As the temperature increases, we observe a decrease in performance.
477"
REFERENCES,0.7868632707774799,"A.3
Analysis of the Generated Datasets
478"
REFERENCES,0.7882037533512064,"(a) Token Length Distribution for SELF-INSTRUCT
vs.ROBO-INSTRUCT"
REFERENCES,0.789544235924933,"(b) Cosine Similarity with ROBOEVALfor SELF-
INSTRUCT vs.ROBO-INSTRUCT"
REFERENCES,0.7908847184986595,Figure 6: Dataset Analysis
REFERENCES,0.792225201072386,"Method
Size
Ngram=4 Score
# Synth. Loc.
# Synth. Obj.
ROBO-INSTRUCT
5K
0.587
1025
928
SELF-INSTRUCT
5K
0.581
956
1060
Table 3: Dataset Statistics"
REFERENCES,0.7935656836461126,"We first compute and plot the distribution of token lengths in the SELF-INSTRUCT-generated dataset
479"
REFERENCES,0.7949061662198391,"and the ROBO-INSTRUCT-generated dataset, as shown in Fig. 6(a). Next, we measure the cosine
480"
REFERENCES,0.7962466487935657,"similarity between each dataset and the ROBOEVALbenchmark tasks following the approach in
481"
REFERENCES,0.7975871313672922,"Magicoder [38], as depicted in Fig. 6(b). Finally, Tab. 3 presents the n-gram diversity score of each
482"
REFERENCES,0.7989276139410187,"dataset, along with the number of synthesized locations and objects. Our findings indicate that both
483"
REFERENCES,0.8002680965147453,"distributions and dataset statistics are very similar, suggesting that ROBO-INSTRUCT enhances the
484"
REFERENCES,0.8016085790884718,"quality of the generated data over SELF-INSTRUCT rather than merely aligning the dataset towards
485"
REFERENCES,0.8029490616621984,"the benchmark tasks.
486"
REFERENCES,0.8042895442359249,"A.4
ROBOEVALSeed Task Example
487"
REFERENCES,0.8056300268096515,"1
# Instruction: Go to Arjun ’s office ,
488"
REFERENCES,0.806970509383378,"2
# ask him if he is ready to head out ,
489"
REFERENCES,0.8083109919571045,"3
# and come back and tell me what he said
490"
DEF,0.8096514745308311,"4
def
task_program ():
491"
DEF,0.8109919571045576,"5
start_loc = get_current_location ()
492"
DEF,0.8123324396782842,"6
go_to(""Arjun ’s office"")
493"
DEF,0.8136729222520107,"7
response = ask(""Arjun"",
494"
DEF,0.8150134048257373,"8
""Are you ready to go?"",
495"
DEF,0.8163538873994638,"9
[""Yes"", ""No""])
496"
DEF,0.8176943699731903,"10
go_to(start_loc)
497"
DEF,0.8190348525469169,"11
say(""Arjun
said: "" + response)
498"
DEF,0.8203753351206434,Listing 1: Seed Task Example 1
DEF,0.82171581769437,"1
# Instruction: Ask Alice if she needs 1, 2, or 3 boxes.
499"
DEF,0.8230563002680965,"2
# Go to the
storage
room and ask if they have that many
boxes.
500"
DEF,0.824396782841823,"3
# If so , go place the boxes in Alice ’s office.
501"
DEF,0.8257372654155496,"4
# Otherwise , tell
Alice you could not get the boxes.
502"
DEF,0.8270777479892761,"5
def
task_program ():
503"
DEF,0.8284182305630027,"6
go_to(""Alice ’s office"")
504"
DEF,0.8297587131367292,"7
num_boxes = ask(""Alice"",
505"
DEF,0.8310991957104558,"8
""How many
boxes do you need?"",
506"
DEF,0.8324396782841823,"9
[""1"", ""2"", ""3""])
507"
DEF,0.8337801608579088,"10
go_to(""storage
room"")
508"
DEF,0.8351206434316354,"11
response = ask("""",
509"
DEF,0.8364611260053619,"12
""Do you have"" + num_boxes + "" boxes?"",
510"
DEF,0.8378016085790885,"13
[""Yes"", ""No""])
511"
DEF,0.839142091152815,"14
if response == ""Yes"":
512"
DEF,0.8404825737265416,"15
for _ in range(int(num_boxes)):
513"
DEF,0.8418230563002681,"16
pick(""box"")
514"
DEF,0.8431635388739946,"17
go_to(""Alice ’s office"")
515"
DEF,0.8445040214477212,"18
place(""box"")
516"
DEF,0.8458445040214477,"19
go_to(""storage
room"")
517"
DEF,0.8471849865951743,"20
else:
518"
DEF,0.8485254691689008,"21
go_to(""Alice ’s office"")
519"
DEF,0.8498659517426274,"22
say(""I could not get the boxes"")
520"
DEF,0.8512064343163539,Listing 2: Seed Task Example 2
DEF,0.8525469168900804,"1
# Instruction: Check if there is a red marker in the main
521"
DEF,0.853887399463807,"2
# office , and if so , tell Eve that
there is a marker
there.
522"
DEF,0.8552278820375335,"3
# If not , go to the supply
room and
523"
DEF,0.8565683646112601,"4
# bring a red marker to the main
office.
524"
DEF,0.8579088471849866,"5
def
task_program ():
525"
DEF,0.8592493297587132,"6
go_to(""main
office"")
526"
DEF,0.8605898123324397,"7
red_marker_found = is_in_room(""red marker"")
527"
DEF,0.8619302949061662,"8
if red_marker_found :
528"
DEF,0.8632707774798928,"9
go_to(""Eve’s office"")
529"
DEF,0.8646112600536193,"10
say(""There is a red marker in the main
office"")
530"
DEF,0.8659517426273459,"11
else:
531"
DEF,0.8672922252010724,"12
go_to(""supply
room"")
532"
DEF,0.868632707774799,"13
pick(""red marker"")
533"
DEF,0.8699731903485255,"14
go_to(""main
office"")
534"
DEF,0.871313672922252,"15
place(""red marker"")
535"
DEF,0.8726541554959786,Listing 3: Seed Task Example 3
DEF,0.8739946380697051,"1
# Instruction: Check
every
classroom if there is a whiteboard.
536"
DEF,0.8753351206434317,"2
# Go to Aiden ’s office to tell him which
room does not
537"
DEF,0.8766756032171582,"3
# have a whiteboard. Come back and tell me task is completed.
538"
DEF,0.8780160857908847,"4
def
task_program ():
539"
DEF,0.8793565683646113,"5
start_loc = get_current_location ()
540"
DEF,0.8806970509383378,"6
list_of_rooms = get_all_rooms ()
541"
DEF,0.8820375335120644,"7
room_without_whiteboard = []
542"
DEF,0.8833780160857909,"8
for room in list_of_rooms :
543"
DEF,0.8847184986595175,"9
if ""classroom"" not in room:
544"
CONTINUE,0.886058981233244,"10
continue
545"
CONTINUE,0.8873994638069705,"11
go_to(room)
546"
IF NOT,0.8887399463806971,"12
if not
is_in_room(""whiteboard""):
547"
IF NOT,0.8900804289544236,"13
room_without_whiteboard .append(room)
548"
IF NOT,0.8914209115281502,"14
go_to(""Aiden ’s office"")
549"
IF NOT,0.8927613941018767,"15
if len( room_without_whiteboard ) > 0:
550"
IF NOT,0.8941018766756033,"16
message = """"
551"
FOR ROOM IN,0.8954423592493298,"17
for room in
room_without_whiteboard :
552"
FOR ROOM IN,0.8967828418230563,"18
message += room + "", ""
553"
FOR ROOM IN,0.8981233243967829,"19
message += ""do not have a whiteboard""
554"
FOR ROOM IN,0.8994638069705094,"20
else:
555"
FOR ROOM IN,0.900804289544236,"21
message = ""all
classrooms
have a whiteboard""
556"
FOR ROOM IN,0.9021447721179625,"22
say(message)
557"
FOR ROOM IN,0.903485254691689,"23
go_to(start_loc)
558"
FOR ROOM IN,0.9048257372654156,"24
say(""task is completed"")
559"
FOR ROOM IN,0.9061662198391421,Listing 4: Seed Task Example 4
FOR ROOM IN,0.9075067024128687,"1
# Instruction: Go to the
kitchen
and wait for
someone
560"
FOR ROOM IN,0.9088471849865952,"2
# to show up. When
someone
shows up , ask them to open
561"
FOR ROOM IN,0.9101876675603218,"3
# the fridge , then pick up a diet coke.
562"
FOR ROOM IN,0.9115281501340483,"4
# Finally , put the diet coke in the living
room.
563"
DEF,0.9128686327077749,"5
def
task_program ():
564"
DEF,0.9142091152815014,"6
go_to(""kitchen"")
565"
WHILE,0.9155495978552279,"7
while
True:
566"
WHILE,0.9168900804289544,"8
if is_in_room(""person""):
567"
WHILE,0.9182305630026809,"9
response = ask("""",
568"
WHILE,0.9195710455764075,"10
""Please
open the fridge"",
569"
WHILE,0.920911528150134,"11
[""Yes"", ""No""])
570"
WHILE,0.9222520107238605,"12
if response == ""Yes"":
571"
WHILE,0.9235924932975871,"13
pick(""diet coke"")
572"
BREAK,0.9249329758713136,"14
break
573"
BREAK,0.9262734584450402,"15
time.sleep (1)
574"
BREAK,0.9276139410187667,"16
go_to(""living
room"")
575"
BREAK,0.9289544235924933,"17
place(""diet coke"")
576"
BREAK,0.9302949061662198,Listing 5: Seed Task Example 5
BREAK,0.9316353887399463,"1
# Instruction: Take a bed sheet
from the
laundry
room
577"
BREAK,0.9329758713136729,"2
# and put it in each of the
bedrooms.
578"
DEF,0.9343163538873994,"3
def
task_program ():
579"
DEF,0.935656836461126,"4
start_loc = get_current_location ()
580"
DEF,0.9369973190348525,"5
list_of_rooms = get_all_rooms ()
581"
DEF,0.938337801608579,"6
for room in list_of_rooms :
582"
DEF,0.9396782841823056,"7
if ""bedroom"" not in room:
583"
CONTINUE,0.9410187667560321,"8
continue
584"
CONTINUE,0.9423592493297587,"9
go_to(""laundry
room"")
585"
CONTINUE,0.9436997319034852,"10
pick(""bed sheet"")
586"
CONTINUE,0.9450402144772118,"11
go_to(room)
587"
CONTINUE,0.9463806970509383,"12
place(""bed sheet"")
588"
CONTINUE,0.9477211796246648,"13
go_to(start_loc)
589"
CONTINUE,0.9490616621983914,Listing 6: Seed Task Example 6
CONTINUE,0.9504021447721179,"A.5
Prompts to Generate Synthetic Dataset Using SELF-INSTRUCT
590"
CONTINUE,0.9517426273458445,"You are a helpful assistant. Here is a robot that has the following capabilities:
- def get_current_location() -> str:
- def get_all_rooms() -> list[str]:
- def is_in_room(object : str) -> bool:
- def go_to(location : str) -> None:
- def ask(person : str, question : str, options: list[str]) -> str:
- def say(message : str) -> None:
- def pick(obj: str) -> None:
- def place(obj: str) -> None:
Generate an interesting robot task that can be accomplished using the above capabilities.
{{SEED EXAMPLE}}"
CONTINUE,0.953083109919571,"Generate an interesting robot task that can be accomplished using the above capabilities.
..."
CONTINUE,0.9544235924932976,Table 4: Prompts to Generate Synthetic Dataset Using SELF-INSTRUCT.
CONTINUE,0.9557640750670241,"A.6
CoT Prompts for INSTALIGN
591"
CONTINUE,0.9571045576407506,"### Role: You are an expert at understanding robot programs. You will be given a task instruction
and robot program pair. However, the instruction may not align with the program well. You need
to correct the task instruction to match the given robot program."
CONTINUE,0.9584450402144772,"### Context: The robot only has access to the following 8 APIs and standard Python functions
- def get_current_location() -> str:
- def get_all_rooms() -> list[str]:
- def is_in_room(object : str) -> bool:
- def go_to(location : str) -> None:
- ask(person : str, question : str, options: list[str]) -> str:
- say(message : str) -> None:
- def pick(obj: str) -> None:
- def place(obj: str) -> None:"
CONTINUE,0.9597855227882037,"### Inputs
Original Instruction: This is a task instruction that may not align with the robot program Robot
Program: This is a python function starting with ‘def task_program():‘"
CONTINUE,0.9611260053619303,"### Task:
1. Write down all the provided APIs used in the program and explain the effect of each API in
this program
2. Examine these APIs and write down step by step what the program does
3. Combine all the results above and rewrite the instruction under # Final Corrected Instruction:
You need to be specific and clear in your final corrected instruction."
CONTINUE,0.9624664879356568,Table 5: CoT Prompts for INSTALIGN.
CONTINUE,0.9638069705093834,"B
CheckList
592"
CONTINUE,0.9651474530831099,"1. [Claims] Yes. The research questions listed in the evaluation section are formulated so as to
593"
CONTINUE,0.9664879356568364,"directly reflect the claims of the paper.
594"
CONTINUE,0.967828418230563,"2. [Limitations] Yes. This is discussed in Section 5.
595"
CONTINUE,0.9691689008042895,"3. [Theory, Assumptions and Proofs] N/A. We do not have any theoretical results.
596"
CONTINUE,0.9705093833780161,"4. [Experimental Result Reproducibility] Yes. We provide the training hyperparameters in
597"
CONTINUE,0.9718498659517426,"Section 4. We will also release our model upon acceptance.
598"
CONTINUE,0.9731903485254692,"5. [Open Access to Data and Code] Yes. We provide the prompts that are used to generate
599"
CONTINUE,0.9745308310991957,"the training dataset. We will also release our training dataset upon acceptance.
600"
CONTINUE,0.9758713136729222,"6. [Experimental Setting/ Details] Yes. We discuss the details of the training scheme in
601"
CONTINUE,0.9772117962466488,"Section 3.2, which follows the standard approach to fine-tuning an LLM.
602"
CONTINUE,0.9785522788203753,"7. [Experiment Statistical Significance] Yes. We performed ablation studies to validate our
603"
CONTINUE,0.9798927613941019,"methods in Section 3.3.
604"
CONTINUE,0.9812332439678284,"8. [Experiments Compute Resource] Yes. We mention that we train all our models on a
605"
CONTINUE,0.982573726541555,"single H-100 GPU using unsloth in Section 3.2.
606"
CONTINUE,0.9839142091152815,"9. [Code Of Ethics] Yes
607"
CONTINUE,0.985254691689008,"10. [Broader Impacts] N/A: This paper addresses an existing problem (using LLMs to synthe-
608"
CONTINUE,0.9865951742627346,"size robot programs [10, 12, 17]), and does not introduce any novel concerns beyond the
609"
CONTINUE,0.9879356568364611,"existing scope.
610"
CONTINUE,0.9892761394101877,"11. [Safeguards] N/A: the programs we will generate or release are domain-specific with
611"
CONTINUE,0.9906166219839142,"respect to RoboEval [10], which has existing safeguards in place.
612"
CONTINUE,0.9919571045576407,"12. [Licenses] Yes — we build on SELF-INSTRUCT, Llamav3 [30], and RoboEval [10] with
613"
CONTINUE,0.9932975871313673,"attribution, and Table 1 refers to the licenses of the models used in the evaluation.
614"
CONTINUE,0.9946380697050938,"13. [Assets] N/A. The code we will release will include details of documentation, training,
615"
CONTINUE,0.9959785522788204,"license, and limitations. The code will be released upon acceptance.
616"
CONTINUE,0.9973190348525469,"14. [Crowdsourcing and Research with Human Subjects] N/A
617"
CONTINUE,0.9986595174262735,"15. [IRB Approvals] N/A
618"
