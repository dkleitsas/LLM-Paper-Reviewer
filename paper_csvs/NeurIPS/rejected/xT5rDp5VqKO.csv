Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.00684931506849315,"This paper demonstrates that the performance of coincidence detection - a classic
1"
ABSTRACT,0.0136986301369863,"neuromorphic signal processing method found in Rosenblatt’s perceptrons with
2"
ABSTRACT,0.02054794520547945,"distributed transmission times, can be competitive to a state-of-the-art deep learning
3"
ABSTRACT,0.0273972602739726,"method for pattern recognition. Hence, we cannot remain comfortably numb to the
4"
ABSTRACT,0.03424657534246575,"prevailing dogma that efficient matrix-vector operations is all we need; but should
5"
ABSTRACT,0.0410958904109589,"enquire with greater vigour if more advanced continual learning methods (running
6"
ABSTRACT,0.04794520547945205,"on spiking neural network hardware with neuromodulatory mechanisms at multiple
7"
ABSTRACT,0.0547945205479452,"timescales) can beat the accuracy of task-specific deep learning methods.
8"
INTRODUCTION,0.06164383561643835,"1
Introduction
9"
INTRODUCTION,0.0684931506849315,"Frank Rosenblatt and his team (1957-1971) built and analyzed several kinds of perceptrons [1, 2, 3, 4]
10"
INTRODUCTION,0.07534246575342465,"- networks of sensory, association and receptor neurons; which in contemporary deep learning termi-
11"
INTRODUCTION,0.0821917808219178,"nology relates to the input, hidden and output layers. The propagating signals were binary (compatible
12"
INTRODUCTION,0.08904109589041095,"with a spike-based view), the synaptic delays (transmission times) and weights (memory states) could
13"
INTRODUCTION,0.0958904109589041,"be analog, the network could be recurrent and was often randomly interconnected, and learning
14"
INTRODUCTION,0.10273972602739725,"often meant tuning the weights of the association-receptor subnetwork by some error-corrective
15"
INTRODUCTION,0.1095890410958904,"reinforcement. The synaptic delays were not learnt but instead randomly distributed in Rosenblatt’s
16"
INTRODUCTION,0.11643835616438356,"Tobermory perceptrons [5], and this was rich enough to realize concentration-invariant and uniform
17"
INTRODUCTION,0.1232876712328767,"time-warp invariant spatiotemporal classification by logarithmic encoding and coincidence detection.
18"
INTRODUCTION,0.13013698630136986,"However, the processing speed of commercial Von Neumann computers advanced exponentially
19"
INTRODUCTION,0.136986301369863,"and outperformed neuromorphic hardware on yesterdecade’s benchmarks [6]. The Tobermory per-
20"
INTRODUCTION,0.14383561643835616,"ceptron was forgotten, nevertheless, the utility of logarithmic encoding and coincidence detection
21"
INTRODUCTION,0.1506849315068493,"was formalized by John Hopfield [7] as an efficient solution to the analog match problem in pattern
22"
INTRODUCTION,0.15753424657534246,"recognition.
23"
INTRODUCTION,0.1643835616438356,"Now, half a century after the accidental demise of Rosenblatt, neuromorphic signal processors are
24"
INTRODUCTION,0.17123287671232876,"making a comeback. For example, (1) Intel’s Loihi with spike-time dependent plasticity mechanisms
25"
INTRODUCTION,0.1780821917808219,"for learning olfactory pattern recognizers [8]; (2) Physical reservoir computing networks [9] where
26"
INTRODUCTION,0.18493150684931506,"the interconnectivity of the hidden layer is unchanged, closer to the spirit of Rosenblatt’s randomly
27"
INTRODUCTION,0.1917808219178082,"interconnected sensory-association subnetwork.
28"
INTRODUCTION,0.19863013698630136,"Here, to strengthen the case for revisiting classic methods on novel and modern hardware, we evaluate
29"
INTRODUCTION,0.2054794520547945,"the performance of coincidence detection in comparison to a deep learning method. Nothing more,
30"
INTRODUCTION,0.21232876712328766,"nothing less, although this work was triggered by a rabid interest in employing artificial intelligence
31"
INTRODUCTION,0.2191780821917808,"to sniff out infections and prevent future pandemics.
32"
INTRODUCTION,0.22602739726027396,Table 1: Test accuracy (%)
INTRODUCTION,0.2328767123287671,"ResNet-26
Coincidence detection"
INTRODUCTION,0.23972602739726026,"82.2± 0.3 (from [10])
82.7 (this work)"
METHODS,0.2465753424657534,"2
Methods
33"
METHODS,0.2534246575342466,"Here, we consider the work [10] of an interdisciplinary team, where a 26 layer convolutional neural
34"
METHODS,0.2602739726027397,"network with residual connections (ResNet-26) was successfully trained for classifying pathogenic
35"
METHODS,0.2671232876712329,"bacteria by Raman spectroscopy. In their work, there are N = 30 classes of bacterial isolates and
36"
METHODS,0.273972602739726,"they begin with a ResNet-26 pre-trained on N×2000 spectra, then for each class n = 1 : N there are
37"
METHODS,0.2808219178082192,"M = 100 training spectra, and similarly N ×M = 3000 test spectra. Each spectrum x contains 1000
38"
METHODS,0.2876712328767123,"floating-point numbers ranging between 0 and 1. Although compute intensive, their deep learning
39"
METHODS,0.2945205479452055,"method proved to be a tool of great convenience for pattern recognition in a challenging dataset,
40"
METHODS,0.3013698630136986,"where intra-isolate spectra were often more dissimilar than inter-isolate spectra.
41"
METHODS,0.3082191780821918,"Our method to tackle the above dataset, is inspired by the theory of how coincidence detection [7]
42"
METHODS,0.3150684931506849,"in animal brains is fundamental for odour classification in complex and turbulent mixtures. Each
43"
METHODS,0.3219178082191781,"class n has a vector representation wn that is learnt, and an input vector x results in an output
44"
METHODS,0.3287671232876712,"class y(x) = argn max(x V wn) where we introduce the operator V to represent the coincidence
45"
METHODS,0.3356164383561644,"between two signals. The analytical nature of coincidence detection depends on the specificities of the
46"
METHODS,0.3424657534246575,"ion-channels and the membranes involved [11], and may even incorporate nonlinear leaky-integrate
47"
METHODS,0.3493150684931507,"[12] multiple timescale mechanisms. We do not yet have a complete theory of neuromorphic signal
48"
METHODS,0.3561643835616438,"processing, so here we introduce an approximation for the translation and scale-invariant property of
49"
METHODS,0.363013698630137,"coincidence detection as
50"
METHODS,0.3698630136986301,"argn max(x
^
wn) ≈argn max(wn · ˆx),
(1)"
METHODS,0.3767123287671233,"where ˆx is the zero-mean unit-variance normalization of x.
51"
METHODS,0.3835616438356164,"Thus, the approximation in Eq. (1) allows y(x) to be learnt by a logistic regression on the normalized
52"
METHODS,0.3904109589041096,"dataset. We discard the pre-training data, pre-process the training and test spectra by a range-1 mean
53"
METHODS,0.3972602739726027,"filter, and use the default method for logistic regression in Wolfram Mathematica (L2-regularization
54"
METHODS,0.4041095890410959,"= 0.0001, optimization method = limited-memory BFGS). Code is provided in the supplemental
55"
METHODS,0.410958904109589,"material for reproducibility.
56"
RESULT AND OUTLOOK,0.4178082191780822,"3
Result and outlook
57"
RESULT AND OUTLOOK,0.4246575342465753,"The coincidence detection (via normalized logistic regression) method introduced here achieves a test
58"
RESULT AND OUTLOOK,0.4315068493150685,"accuracy greater than ResNet-26 (see Table 1), and it took less than 3 seconds to train the classifier
59"
RESULT AND OUTLOOK,0.4383561643835616,"on a modern desktop (without any special-purpose GPUs). Check the Appendix for a confusion
60"
RESULT AND OUTLOOK,0.4452054794520548,"matrix plot of the training and test data. Note that the training data was fit all at once to a 100%
61"
RESULT AND OUTLOOK,0.4520547945205479,"accuracy. With a more neuromorphic coincidence detection method and a learning method that adapts
62"
RESULT AND OUTLOOK,0.4589041095890411,"the synaptic delays w continually, to keep track under changing environmental conditions, we may
63"
RESULT AND OUTLOOK,0.4657534246575342,"achieve even greater accuracies.
64"
REFERENCES,0.4726027397260274,"References
65"
REFERENCES,0.4794520547945205,"[1] Frank Rosenblatt. The perceptron, a perceiving and recognizing automaton Project Para.
66"
REFERENCES,0.4863013698630137,"Cornell Aeronautical Laboratory, Inc. Report no. 85-460-1, 1957.
67"
REFERENCES,0.4931506849315068,"[2] Frank Rosenblatt. The perceptron: A theory of statistical separability in cognitive systems.
68"
REFERENCES,0.5,"Cornell Aeronautical Laboratory, Inc. Report no. VG-1196-G-1, 1958.
69"
REFERENCES,0.5068493150684932,"[3] Frank Rosenblatt. Principles of neurodynamics. perceptrons and the theory of brain mechanisms.
70"
REFERENCES,0.5136986301369864,"Cornell Aeronautical Laboratory, Inc. Report no. 1196-G-8, 1961.
71"
REFERENCES,0.5205479452054794,"[4] Frank Rosenblatt. Cognitive systems research program. Technical report, Cornell University,
72"
REFERENCES,0.5273972602739726,"Ithaca, New York, 1971.
73"
REFERENCES,0.5342465753424658,"[5] Frank Rosenblatt. A description of the tobermory perceptron. In Collected Technical Papers,
74"
REFERENCES,0.541095890410959,"volume 2. Cornell University, Ithaca, New York, 1963.
75"
REFERENCES,0.547945205479452,"[6] George Nagy. Neural networks-then and now. IEEE Transactions on Neural Networks, 2(2):316–
76"
REFERENCES,0.5547945205479452,"318, 1991.
77"
REFERENCES,0.5616438356164384,"[7] John J Hopfield. Pattern recognition computation using action potential timing for stimulus
78"
REFERENCES,0.5684931506849316,"representation. Nature, 376(6535):33–36, 1995.
79"
REFERENCES,0.5753424657534246,"[8] Nabil Imam and Thomas A Cleland. Rapid online learning and robust recall in a neuromorphic
80"
REFERENCES,0.5821917808219178,"olfactory circuit. Nature Machine Intelligence, 2(3):181–191, 2020.
81"
REFERENCES,0.589041095890411,"[9] G. Tanaka, T. Yamane, J.B. Héroux, R. Nakane, N. Kanazawa, S. Takeda, H. Numata, D. Nakano,
82"
REFERENCES,0.5958904109589042,"and A. Hirose. Recent advances in physical reservoir computing: A review. Neural Networks,
83"
REFERENCES,0.6027397260273972,"115:100–123, 2019.
84"
REFERENCES,0.6095890410958904,"[10] Chi-Sing Ho, Neal Jean, Catherine A Hogan, Lena Blackmon, Stefanie S Jeffrey, Mark Holodniy,
85"
REFERENCES,0.6164383561643836,"Niaz Banaei, Amr AE Saleh, Stefano Ermon, and Jennifer Dionne. Rapid identification of
86"
REFERENCES,0.6232876712328768,"pathogenic bacteria using raman spectroscopy and deep learning. Nature communications,
87"
REFERENCES,0.6301369863013698,"10(1):1–8, 2019.
88"
REFERENCES,0.636986301369863,"[11] Nelson Spruston. Pyramidal neurons: dendritic structure and synaptic integration. Nature
89"
REFERENCES,0.6438356164383562,"Reviews Neuroscience, 9(3):206–221, 2008.
90"
REFERENCES,0.6506849315068494,"[12] Wondimu Teka, Toma M Marinov, and Fidel Santamaria. Neuronal spike timing adapta-
91"
REFERENCES,0.6575342465753424,"tion described with a fractional leaky integrate-and-fire model. PLoS computational biology,
92"
REFERENCES,0.6643835616438356,"10(3):e1003526, 2014.
93"
REFERENCES,0.6712328767123288,"Checklist
94"
REFERENCES,0.678082191780822,"1. For all authors...
95"
REFERENCES,0.684931506849315,"(a) Do the main claims made in the abstract and introduction accurately reflect the paper’s
96"
REFERENCES,0.6917808219178082,"contributions and scope? [Yes] See Table 1.
97"
REFERENCES,0.6986301369863014,"(b) Did you describe the limitations of your work? [Yes] Equation (1) makes it clear that
98"
REFERENCES,0.7054794520547946,"we employ an approximation for coincidence detection.
99"
REFERENCES,0.7123287671232876,"(c) Did you discuss any potential negative societal impacts of your work? [N/A]
100"
REFERENCES,0.7191780821917808,"(d) Have you read the ethics review guidelines and ensured that your paper conforms to
101"
REFERENCES,0.726027397260274,"them? [Yes]
102"
REFERENCES,0.7328767123287672,"2. If you are including theoretical results...
103"
REFERENCES,0.7397260273972602,"(a) Did you state the full set of assumptions of all theoretical results? [N/A]
104"
REFERENCES,0.7465753424657534,"(b) Did you include complete proofs of all theoretical results? [N/A]
105"
REFERENCES,0.7534246575342466,"3. If you ran experiments...
106"
REFERENCES,0.7602739726027398,"(a) Did you include the code, data, and instructions needed to reproduce the main ex-
107"
REFERENCES,0.7671232876712328,"perimental results (either in the supplemental material or as a URL)? [Yes] Check
108"
REFERENCES,0.773972602739726,"supplemental material
109"
REFERENCES,0.7808219178082192,"(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they
110"
REFERENCES,0.7876712328767124,"were chosen)? [Yes]
111"
REFERENCES,0.7945205479452054,"(c) Did you report error bars (e.g., with respect to the random seed after running experi-
112"
REFERENCES,0.8013698630136986,"ments multiple times)? [N/A]
113"
REFERENCES,0.8082191780821918,"(d) Did you include the total amount of compute and the type of resources used (e.g., type
114"
REFERENCES,0.815068493150685,"of GPUs, internal cluster, or cloud provider)? [Yes] qualitatively, in the results section
115"
REFERENCES,0.821917808219178,"4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
116"
REFERENCES,0.8287671232876712,"(a) If your work uses existing assets, did you cite the creators? [Yes]
117"
REFERENCES,0.8356164383561644,"(b) Did you mention the license of the assets? [Yes] In the supplemental information
118"
REFERENCES,0.8424657534246576,"(c) Did you include any new assets either in the supplemental material or as a URL? [No]
119"
REFERENCES,0.8493150684931506,"(d) Did you discuss whether and how consent was obtained from people whose data you’re
120"
REFERENCES,0.8561643835616438,"using/curating? [N/A]
121"
REFERENCES,0.863013698630137,"(e) Did you discuss whether the data you are using/curating contains personally identifiable
122"
REFERENCES,0.8698630136986302,"information or offensive content? [N/A]
123"
REFERENCES,0.8767123287671232,"5. If you used crowdsourcing or conducted research with human subjects...
124"
REFERENCES,0.8835616438356164,"(a) Did you include the full text of instructions given to participants and screenshots, if
125"
REFERENCES,0.8904109589041096,"applicable? [N/A]
126"
REFERENCES,0.8972602739726028,"(b) Did you describe any potential participant risks, with links to Institutional Review
127"
REFERENCES,0.9041095890410958,"Board (IRB) approvals, if applicable? [N/A]
128"
REFERENCES,0.910958904109589,"(c) Did you include the estimated hourly wage paid to participants and the total amount
129"
REFERENCES,0.9178082191780822,"spent on participant compensation? [N/A]
130"
REFERENCES,0.9246575342465754,"A
Appendix
131"
REFERENCES,0.9315068493150684,"Confusion matrix of the training and test data. Wolfram Mathematica code to reproduce these results
132"
REFERENCES,0.9383561643835616,"is provided as supplemental material.
133 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100 100"
REFERENCES,0.9452054794520548,"1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30"
REFERENCES,0.952054794520548,"100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100"
REFERENCES,0.958904109589041,predicted class
REFERENCES,0.9657534246575342,actual class 97 103 113 113 76 103 33 130 101 100 90 82 105 85 114 66 144 36 100 104 100 143 134 86 110 118 98 100 103 113
REFERENCES,0.9726027397260274,"1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30"
REFERENCES,0.9794520547945206,"100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100
100"
REFERENCES,0.9863013698630136,predicted class
REFERENCES,0.9931506849315068,actual class 134
