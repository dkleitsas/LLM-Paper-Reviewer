Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0005417118093174431,"We consider a multi-task contextual bandit setting, where the learner is given a
1"
ABSTRACT,0.0010834236186348862,"graph encoding relations between the bandit tasks. The tasks’ preference vectors
2"
ABSTRACT,0.0016251354279523294,"are assumed to be piecewise constant over the graph, forming clusters. At every
3"
ABSTRACT,0.0021668472372697724,"round, we estimate the preference vectors by solving an online network lasso
4"
ABSTRACT,0.0027085590465872156,"problem with a suitably chosen, time-dependent regularization parameter. We
5"
ABSTRACT,0.0032502708559046588,"establish a novel oracle inequality relying on a convenient restricted eigenvalue
6"
ABSTRACT,0.003791982665222102,"assumption. Our theoretical findings highlight the importance of dense intra-cluster
7"
ABSTRACT,0.004333694474539545,"connections and sparse inter-cluster ones. That results in a sublinear regret bound
8"
ABSTRACT,0.004875406283856988,"significantly lower than its counterpart in the independent task learning setting.
9"
ABSTRACT,0.005417118093174431,"Finally, we support our theoretical findings by experimental evaluation against
10"
ABSTRACT,0.005958829902491874,"graph bandit multi-task learning and online clustering of bandits algorithms.
11"
INTRODUCTION,0.0065005417118093175,"1
Introduction
12"
INTRODUCTION,0.007042253521126761,"Online commercial websites aim to properly recommend their products to their customers, and the
13"
INTRODUCTION,0.007583965330444204,"performance of these recommendations depends on the knowledge of users’ preferences. Unlike
14"
INTRODUCTION,0.008125677139761646,"traditional collaborative-filtering-based methods [Su and Khoshgoftaar, 2009], such knowledge is
15"
INTRODUCTION,0.00866738894907909,"initially unavailable. Therefore, the online recommender systems need to recommend various items
16"
INTRODUCTION,0.009209100758396533,"to the users and observe their ratings to explore their preferences. At the same time, the recommender
17"
INTRODUCTION,0.009750812567713976,"system should be able to recommend items that attract users’ attention and receive high ratings by
18"
INTRODUCTION,0.010292524377031419,"exploiting the learned knowledge. The contextual bandits frameworks [Li et al., 2010] have been
19"
INTRODUCTION,0.010834236186348862,"popularly used to formalize and address this exploration-exploitation trade-off.
20"
INTRODUCTION,0.011375947995666305,"However, the classical form of contextual bandits [Li et al., 2010, Chu et al., 2011, Abbasi-Yadkori
21"
INTRODUCTION,0.011917659804983749,"et al., 2011] ignores the availability of social networks amongst users and solves the problem for
22"
INTRODUCTION,0.012459371614301192,"each user separately. Consequently, such algorithms have some drawbacks when applied to problems
23"
INTRODUCTION,0.013001083423618635,"with a large number of users. First, such a large number hinders the computational efficiency of
24"
INTRODUCTION,0.013542795232936078,"such algorithms. Second, the partial feedback of the bandit settings exposes the algorithms to have
25"
INTRODUCTION,0.014084507042253521,"weak estimations and impair their decision-making ability [Yang et al., 2020]. Consequently, to
26"
INTRODUCTION,0.014626218851570965,"improve bandit algorithms’ performance for large-scale applications, structural assumptions that link
27"
INTRODUCTION,0.015167930660888408,"the different users are usually integrated within bandit algorithms [Cesa-Bianchi et al., 2013, Gentile
28"
INTRODUCTION,0.01570964247020585,"et al., 2014, Li et al., 2019, Herbster et al., 2021].
29"
INTRODUCTION,0.016251354279523293,"The papers of Cesa-Bianchi et al. [2013], Yang et al. [2020] attempt to integrate the prior knowledge of
30"
INTRODUCTION,0.016793066088840736,"social networks into their contextual bandit algorithms. Both papers proposed UCB-style algorithms
31"
INTRODUCTION,0.01733477789815818,"and exhibited the importance of using the social network graph to achieve lower regrets using
32"
INTRODUCTION,0.017876489707475622,"Laplacian regularization. Consequently, both methods promote smoothness among the preference
33"
INTRODUCTION,0.018418201516793065,"vectors of users in order to transfer the collected information between them. However, the Laplacian
34"
INTRODUCTION,0.01895991332611051,"regularization does not account for the smoothness heterogeneity introduced by a piecewise constant
35"
INTRODUCTION,0.01950162513542795,"behavior over the graph [Wang et al., 2016]. On the other hand, algorithms of online clustering of
36"
INTRODUCTION,0.020043336944745395,"bandits [Gentile et al., 2014, Li et al., 2019] start from a graph and gradually add or remove edges to
37"
INTRODUCTION,0.020585048754062838,"form clusters as connected components. However, their clustering can cause overconfidence in the
38"
INTRODUCTION,0.02112676056338028,"constructed clusters, potentially leading to error accumulation.
39"
INTRODUCTION,0.021668472372697724,"In this paper, we assume access to a graph encoding relations between bandit tasks, and that the task
40"
INTRODUCTION,0.022210184182015168,"parameter vectors are piecewise constant over the graph. That means that tasks form clusters. We
41"
INTRODUCTION,0.02275189599133261,"propose an algorithm that integrates the prior knowledge of the piecewise constant structure to update
42"
INTRODUCTION,0.023293607800650054,"tasks rather than finding the clusters explicitly. That way, we mitigate the limitations mentioned
43"
INTRODUCTION,0.023835319609967497,"above: the piecewise constant smoothness is naturally integrated into our regularizer, and we do not
44"
INTRODUCTION,0.02437703141928494,"estimate the clusters so our algorithm does not suffer from overconfidence drawbacks.
45"
INTRODUCTION,0.024918743228602384,"More precisely, we provide the following contributions
46"
INTRODUCTION,0.025460455037919827,"• We analyze an instance of the Network Lasso problem [Hallac et al., 2015], where every vertex’s
47"
INTRODUCTION,0.02600216684723727,"preference vector is estimated using data generated during the interaction between users and the
48"
INTRODUCTION,0.026543878656554713,"bandit. We provide the first oracle inequality in this setting and link it to fundamental quantities
49"
INTRODUCTION,0.027085590465872156,"characterizing the relation between the graph and the true preference vectors of the users. Our
50"
INTRODUCTION,0.0276273022751896,"result relies on our novel restricted eigenvalue (RE) condition, which we assume for our setting.
51"
INTRODUCTION,0.028169014084507043,"This result is of independent interest and can be applied to independently generated data as a
52"
INTRODUCTION,0.028710725893824486,"special case.
53"
INTRODUCTION,0.02925243770314193,"• We prove how the empirical multi-task Gram matrix of the data inherits the RE condition from
54"
INTRODUCTION,0.029794149512459372,"its true counterpart. Both this result and the previous one depend on the sparsity of inter-cluster
55"
INTRODUCTION,0.030335861321776816,"connections and the density of intra-cluster ones.
56"
INTRODUCTION,0.03087757313109426,"• We provide a regret upper bound for our setting. Our bound highlights the advantage of our
57"
INTRODUCTION,0.0314192849404117,"algorithm in high dimensional settings, and for large graphs.
58"
INTRODUCTION,0.031960996749729145,"• We support our theoretical findings by extensive numerical experiments on simulated data that
59"
INTRODUCTION,0.032502708559046585,"prove the advantage of our algorithm compared to other approaches used for online clustering of
60"
INTRODUCTION,0.03304442036836403,"bandits.
61"
INTRODUCTION,0.03358613217768147,"The rest of the paper is organized as follows. Section 2 discusses the relation of our work to the
62"
INTRODUCTION,0.03412784398699892,"literature. We formulate our problem and state some of our assumptions in Section 3, then we present
63"
INTRODUCTION,0.03466955579631636,"our bandit algorithm in Section 4. We analyze the problem theoretically in Section 5, and finally, we
64"
INTRODUCTION,0.035211267605633804,"demonstrate its practical interest via numerical experiments in Section 6.
65"
RELATED WORK,0.035752979414951244,"2
Related work
66"
RELATED WORK,0.03629469122426869,"Lasso contextual bandits
To address the high dimensional setting for linear bandits, several multi-
67"
RELATED WORK,0.03683640303358613,"armed bandit papers solve a LASSO [Tibshirani, 1996] problem under different assumptions [Bastani
68"
RELATED WORK,0.03737811484290358,"and Bayati, 2019, Kim and Paik, 2019, Oh et al., 2021, Ariu et al., 2022]. They all rely on a previously
69"
RELATED WORK,0.03791982665222102,"established compatibility or RE condition [Bühlmann and van de Geer, 2011], that they adapt to the
70"
RELATED WORK,0.038461538461538464,"non-i.i.d case. Such assumptions were also used in the multi-task setting by Cella and Pontil [2021]
71"
RELATED WORK,0.0390032502708559,"with a Group Lasso regularization [Yuan and Lin, 2006], and to impose a low rank structure on the
72"
RELATED WORK,0.03954496208017335,"task preference vectors in Cella et al. [2023]. In our case, we provide a novel oracle inequality, rather
73"
RELATED WORK,0.04008667388949079,"than just generalize an existing one to the non-i.i.d setting, with a newly introduced RE assumption.
74"
RELATED WORK,0.040628385698808236,"Clustering of bandits
Sequentially clustering bandit tasks was introduced in Gentile et al. [2014]
75"
RELATED WORK,0.041170097508125676,"with CLUB algorithm. In CLUB, starting with a fully connected graph, an iterative graph learning pro-
76"
RELATED WORK,0.04171180931744312,"cess is performed, where edges between users are deleted if their preference vectors are significantly
77"
RELATED WORK,0.04225352112676056,"different. As a result, any connected component is seen as a cluster and only one recommendation per
78"
RELATED WORK,0.04279523293607801,"cluster is developed. In another work, Li et al. [2019] generalize the setting of Gentile et al. [2014]
79"
RELATED WORK,0.04333694474539545,"and address its limitations via including merging operations in addition to splitting. In contrast to
80"
RELATED WORK,0.043878656554712896,"these approaches, the algorithm in Nguyen and Lauw [2014] groups users via K-means clustering,
81"
RELATED WORK,0.044420368364030335,"and the algorithm in Cheng et al. [2023] relies on hedonic games for online clustering of bandits.
82"
RELATED WORK,0.04496208017334778,"Furthermore, Yang and Toni [2018] make use of community detection techniques on graphs to find
83"
RELATED WORK,0.04550379198266522,"user clusters. Gentile et al. [2017] study the clustering of the contextual bandit problem where their
84"
RELATED WORK,0.04604550379198267,"proposed algorithm, named CAB, adaptively matches user preferences in the face of constantly
85"
RELATED WORK,0.04658721560130011,"evolving items. Our work fundamentally differs from the previous ones on two aspects. First, we
86"
RELATED WORK,0.047128927410617555,"assume access to a graph encoding relations between users, which is more informative than a complete
87"
RELATED WORK,0.047670639219934995,"graph. Second, we do not keep track of a model for each cluster, but rather we integrate a prior over
88"
RELATED WORK,0.048212351029252434,"the graph via a graph total variation regularizer that enforces a piecewise constant behaviour for the
89"
RELATED WORK,0.04875406283856988,"estimated preference vectors.
90"
RELATED WORK,0.04929577464788732,"Multi-task learning
Several contributions assume some underlying structure that links the bandit
91"
RELATED WORK,0.04983748645720477,"tasks. In Cella and Pontil [2021], task preference vectors are assumed to be sparse and to share their
92"
RELATED WORK,0.05037919826652221,"sparsity support, implying that they lie in a low-dimensional subspace with dimensions aligning with
93"
RELATED WORK,0.050920910075839654,"the canonical basis vectors. This idea is further generalized in Cella et al. [2023], where the tasks
94"
RELATED WORK,0.051462621885157094,"are assumed to be confined to an arbitrary unknown low-dimensional subspace. That work improves
95"
RELATED WORK,0.05200433369447454,"upon Hu et al. [2021] by not requiring the knowledge of the small dimenson of the task space. The
96"
RELATED WORK,0.05254604550379198,"underlying structure linking tasks can also be a graph encoding relations between them [Cesa-Bianchi
97"
RELATED WORK,0.05308775731310943,"et al., 2013, Yang and Toni, 2018], which is our case. However, while they assume smoothness as a
98"
RELATED WORK,0.053629469122426866,"prior, we assume piecewise constant behavior.
99"
PROBLEM SETTING,0.05417118093174431,"3
Problem setting
100"
PROBLEM SETTING,0.05471289274106175,"We consider a linear bandit setting, with a finite number of tasks representing users in a recommenda-
101"
PROBLEM SETTING,0.0552546045503792,"tion system for example. For each task the agent has to choose among K arms, each associated to a
102"
PROBLEM SETTING,0.05579631635969664,"d-dimensional context vector. All interactions over a horizon of T time steps. We further assume
103"
PROBLEM SETTING,0.056338028169014086,"that we have access to an undirected graph G = (V, E), with vertex set V representing the tasks
104"
PROBLEM SETTING,0.056879739978331526,"and edge set E encoding the relationships between them. We identify the vertex set V with the set
105"
PROBLEM SETTING,0.05742145178764897,"of vertex indices [|V|]. Thus, we consider E to be a subset of V2, where every edge (m, n) ∈E
106"
PROBLEM SETTING,0.05796316359696641,"has weight wmn > 0, with m < n. The tasks’ preference vectors are denoted by {θm}m∈V ⊂Rd
107"
PROBLEM SETTING,0.05850487540628386,"verifying ∥θm∥≤1 ∀m ∈V, which we concatenate as row vectors into matrix Θ ∈R|V|×d. The
108"
PROBLEM SETTING,0.0590465872156013,"latter represents a graph vector signal, assumed to be piecewise constant over G.
109"
PROBLEM SETTING,0.059588299024918745,"At a round t ∈N⋆, a user m(t) ∈V is selected uniformly at random and served an arm with context
110"
PROBLEM SETTING,0.060130010834236185,"vector x(t) from a finite action set A(t) ⊂Rd with size K, depending on their estimated preference
111"
PROBLEM SETTING,0.06067172264355363,"vector ˆθm(t)(t) ∈Rd. We assume the expected reward to be linear, with an additive, σ-sub-Gaussian
112"
PROBLEM SETTING,0.06121343445287107,"noise conditionally on the past. Formally, denoting by F0 the trivial sigma-algebra, and for all t ≥1,
113"
PROBLEM SETTING,0.06175514626218852,"by Ft the sigma-algebra generated by history set {m(1), x(1), y(1), · · · , m(t), x(t), y(t), m(t+1)},
114"
PROBLEM SETTING,0.06229685807150596,"the received reward y(t) is given by y(t) =

θm(t)(t), x(t)

+ η(t), where η(t) is Ft−measurable
115"
PROBLEM SETTING,0.0628385698808234,"and
116"
PROBLEM SETTING,0.06338028169014084,"E [η(t)|Ft−1] = 0,
E [exp(sη(t))|Ft−1] ≤exp
1"
PROBLEM SETTING,0.06392199349945829,"2σ2s2

∀t ≥1, ∀s ∈R.
(1)"
PROBLEM SETTING,0.06446370530877574,"At the end of a round t, all preference vectors are updated into a new estimation ˆΘ(t) while leveraging
117"
PROBLEM SETTING,0.06500541711809317,"the structure of graph G, formally by solving the following optimization problem:
118"
PROBLEM SETTING,0.06554712892741062,"ˆΘ(t) = arg min
˜Θ∈R|V|×d
1
2t t
X τ=1"
PROBLEM SETTING,0.06608884073672806,"D
˜θm(τ), x(τ)
E
−y(τ)
2
+ α(t)
X"
PROBLEM SETTING,0.06663055254604551,"(m,n)∈E
wmn
˜θm −˜θn
,
(2)"
PROBLEM SETTING,0.06717226435536294,"where ∥·∥denotes the Euclidean norm for vectors. The performance of our policy is assessed by the
119"
PROBLEM SETTING,0.06771397616468039,"expected regret over the T interaction rounds for all tasks:
120"
PROBLEM SETTING,0.06825568797399784,"R(T) = E "" T
X t=1"
PROBLEM SETTING,0.06879739978331528,"θm(t), x⋆(t) −x(t)

# ,
(3)"
PROBLEM SETTING,0.06933911159263272,"where x⋆(t) ∈arg max˜x∈A(t)

θm(t), ˜x

.
121"
PROBLEM SETTING,0.06988082340195016,"The Optimization problem in (2) is an instance of the Network Lasso [Hallac et al., 2015]. Other
122"
PROBLEM SETTING,0.07042253521126761,"instances of the same type were studied by Jung et al. [2018], Jung and Vesselinova [2019], Jung
123"
PROBLEM SETTING,0.07096424702058506,"[2020]. The objective is characterized by its second term that, while being just the Laplacian
124"
PROBLEM SETTING,0.07150595882990249,"regularization without squaring the norms, promotes a piecewise constant behavior rather than
125"
PROBLEM SETTING,0.07204767063921994,"smoothness. For real-valued signals (d = 1), this regularization has been extensively studied for
126"
PROBLEM SETTING,0.07258938244853738,"image and graph signal denoising, for the problem of trend filtering on graphs [Wang et al., 2016].
127"
PROBLEM SETTING,0.07313109425785481,"According to Wang et al. [2016], that regularization better adapts to the heterogeneity of smoothness
128"
PROBLEM SETTING,0.07367280606717226,"of the signal and induces a cluster structure in the data: similar users will not only have similar
129"
PROBLEM SETTING,0.07421451787648971,"models but the same model, which offers a compression of the overall model over the graph. Note
130"
PROBLEM SETTING,0.07475622968580715,"that our setting is cluster agnostic; our algorithm does not aim to learn the cluster structure explicitly
131"
PROBLEM SETTING,0.07529794149512459,"but to exploit it implicitly using the total variation semi-norm as regularization. The latter’s strength
132"
PROBLEM SETTING,0.07583965330444203,"is controlled via a time-dependent regularization coefficient α(t), which we will express later in the
133"
PROBLEM SETTING,0.07638136511375948,"analysis.
134"
PROBLEM SETTING,0.07692307692307693,"We formalize our assumption on the context generation as follows.
135"
PROBLEM SETTING,0.07746478873239436,"Assumption 1 (i.i.d action sets). Context sets {A(t)}T
t=1 are generated i.i.d. from a distribution p
136"
PROBLEM SETTING,0.0780065005417118,"over RK×d, such that ∥x∥≤1∀x ∈A(t) ∀t ≥1.
137"
PROBLEM SETTING,0.07854821235102925,"In addition to the i.i.d assumption, we assume more regularity.
138"
PROBLEM SETTING,0.0790899241603467,"Assumption 2 (Relaxed symmetry and balanced covariance). There exists a constant ν ≥1 such
139"
PROBLEM SETTING,0.07963163596966413,"that for all X ∈RK×d, p(−X) ≤νp(X). Furthermore, there exists ω > 0, such that for any
140"
PROBLEM SETTING,0.08017334777898158,"permutation (a1, · · · , aK) of [K], for any i ∈{2, · · · , K −1}, and for any w ∈Rd, we have
141"
PROBLEM SETTING,0.08071505958829903,"E

xaix⊤
ai[w⊤xa1 < · · · < w⊤xaK]

≼ωE

(xa1x⊤
a1 + xaKx⊤
aK)[w⊤xa1 < · · · < w⊤xaK]

,"
PROBLEM SETTING,0.08125677139761647,"where M ≼N means that N −M is a PSD matrix.
142"
PROBLEM SETTING,0.0817984832069339,"This assumption was introduced in Oh et al. [2021], and has already been used in a multi-task setting
143"
PROBLEM SETTING,0.08234019501625135,"by Cella et al. [2023]. Parameter ν controls the skewness, as ν = 1 corresponds to a symmetric
144"
PROBLEM SETTING,0.0828819068255688,"distribution. ω decreases with increasing positive correlation between arms. It verifies ω = O(1)
145"
PROBLEM SETTING,0.08342361863488625,"for multi-variate Gaussians and uniform distributions over the unit sphere [Oh et al., 2021]. The
146"
PROBLEM SETTING,0.08396533044420368,"piecewise constant behaviour of the graph signal Θ is formalized in the next assumption.
147"
PROBLEM SETTING,0.08450704225352113,"Assumption 3 (Piecewise constant signal). There exists a partition P of V, such that for any cluster
148"
PROBLEM SETTING,0.08504875406283857,"C ∈P, signal Θ is constant on C, and the graph obtained by taking the vertices in C and the edges
149"
PROBLEM SETTING,0.08559046587215602,"linking them is connected.
150"
PROBLEM SETTING,0.08613217768147345,"Assumption 3 basically states that the true preference vectors are clustered and that the given graph
151"
PROBLEM SETTING,0.0866738894907909,"induces the cluster structure. It is required for our approach to be beneficial, as we will detail in the
152"
PROBLEM SETTING,0.08721560130010834,"analysis section. For the sake of clarity, we defer the statement of other technical assumptions to
153"
PROBLEM SETTING,0.08775731310942579,"Section 5.
154"
ALGORITHM,0.08829902491874322,"4
Algorithm
155"
ALGORITHM,0.08884073672806067,"Our policy in Algorithm 1 follows a greedy arm selection rule in a multi-task setting, in the same
156"
ALGORITHM,0.08938244853737812,"vein as those presented in Oh et al. [2021], Cella et al. [2023]. Indeed, as pointed out in Oh et al.
157"
ALGORITHM,0.08992416034669556,"[2021], exploration is implicitly incorporated into regularization parameter α(t)’s time dependence.
158"
ALGORITHM,0.090465872156013,"It has the following expression
159"
ALGORITHM,0.09100758396533044,α(t) := α0σ t
ALGORITHM,0.09154929577464789,"v
u
u
tt + s"
X,0.09209100758396534,"2
X"
X,0.09263271939328277,"m∈V
|Tm(t)|2 log
1
δ(t) + 2 max
m∈V |Tm(t)| log
1
δ(t),
(4)"
X,0.09317443120260022,"where the set of time steps a task m has been selected up to time t is denoted by Tm(t).
160"
ANALYSIS,0.09371614301191766,"5
Analysis
161"
ANALYSIS,0.09425785482123511,"This section provides the main steps of the analysis. One of the paper’s contribution lies in finding an
162"
ANALYSIS,0.09479956663055254,"oracle inequality of the network lasso problem given a restricted eigenvalue condition holding for the
163"
ANALYSIS,0.09534127843986999,"true multi-task Gram matrix. In this regard, the next major challenge and contribution is to show that
164"
ANALYSIS,0.09588299024918744,"the empirical multi-task Gram matrix, estimated in the algorithm, satisfies the restricted eigenvalue
165"
ANALYSIS,0.09642470205850487,"condition. We start by proving an oracle inequality for the estimation error of Θ, assuming that the
166"
ANALYSIS,0.09696641386782232,"condition given by Definition 2 is verified by the empirical data Gram matrix. Then, we prove that the
167"
ANALYSIS,0.09750812567713976,"latter assumption actually holds with high probability given that true multi-task Gram matrix satisfies
168"
ANALYSIS,0.09804983748645721,"it. Our final contribution in this work is the establishment of a regret bound for our algorithm.
169"
NOTATION AND TECHNICAL ASSUMPTIONS,0.09859154929577464,"5.1
Notation and technical assumptions
170"
NOTATION AND TECHNICAL ASSUMPTIONS,0.09913326110509209,"We provide additional notations required for the analysis. We denote by ∂P the set of all edges in
171"
NOTATION AND TECHNICAL ASSUMPTIONS,0.09967497291440953,"E connecting vertices from different clusters from partition P (Assumption 3), and we call it the
172"
NOTATION AND TECHNICAL ASSUMPTIONS,0.10021668472372698,"Algorithm 1: Network Lasso Policy
Input
: T, α0 > 0, G, function δ
Initialization : ˆΘ(0) = 0 ∈R|V|×d"
NOTATION AND TECHNICAL ASSUMPTIONS,0.10075839653304441,"for t ∈[1, T] do"
NOTATION AND TECHNICAL ASSUMPTIONS,0.10130010834236186,"1. Draw a user m(t) ∈V uniformly at random.
2. Observe context set A(t)."
NOTATION AND TECHNICAL ASSUMPTIONS,0.10184182015167931,"3. Select x(t) ∈arg max˜x∈A(t)
D
ˆθm(t−1), ˜x
E
, breaking ties arbitrarily."
NOTATION AND TECHNICAL ASSUMPTIONS,0.10238353196099675,"4. Receive payoff y(t)
5. Update α(t) via Equation (4)"
NOTATION AND TECHNICAL ASSUMPTIONS,0.10292524377031419,6. Update ˆΘ(t) via solving the network Lasso problem (2) end
NOTATION AND TECHNICAL ASSUMPTIONS,0.10346695557963163,"boundary of P. Thus, ∂Pc, the complementary set of ∂P, is formed by edges connecting vertices of
173"
NOTATION AND TECHNICAL ASSUMPTIONS,0.10400866738894908,"the same cluster. The total weight of the boundary, i.e.the sum of its edges’ weights, is referred to as
174"
NOTATION AND TECHNICAL ASSUMPTIONS,0.10455037919826653,"w(∂P). Given a signal Z ∈R|V|×d, we denote by ZP the signal obtained by setting row vectors of Z
175"
NOTATION AND TECHNICAL ASSUMPTIONS,0.10509209100758396,"to their mean-per-cluster value w.r.t. P. For any edge subset I ∈E, we denote the following norms:
176"
NOTATION AND TECHNICAL ASSUMPTIONS,0.1056338028169014,"∥·∥F as the Frobenius norm, ∥z∥M =
√"
NOTATION AND TECHNICAL ASSUMPTIONS,0.10617551462621885,"z⊤Mz as the weighted norm of vector z ∈Rd induced
177"
NOTATION AND TECHNICAL ASSUMPTIONS,0.1067172264355363,by matrix M ∈Rd×d and ∥Θ∥I := P
NOTATION AND TECHNICAL ASSUMPTIONS,0.10725893824485373,"(m,n)∈I wmn∥θm −θn∥as the total variation semi-norm
178"
NOTATION AND TECHNICAL ASSUMPTIONS,0.10780065005417118,"of Θ ∈R|V|×d over I. Thus, the regularization term of Problem (2) is equal to ∥Θ∥E. Also, we
179"
NOTATION AND TECHNICAL ASSUMPTIONS,0.10834236186348863,"define the incidence matrix BI ⊂R|E|×|V|restricted to I ⊆E to be null except at rows with index
180"
NOTATION AND TECHNICAL ASSUMPTIONS,0.10888407367280607,"i ∈I corresponding to edge (m, n), where it equals wmn(em −en), where em is the mth canonical
181"
NOTATION AND TECHNICAL ASSUMPTIONS,0.1094257854821235,"basis vector of R|V|. We define AV(t) := diag
 
X1(t)⊤X1(t), . . . , X|V|(t)⊤X|V|(t)

∈Rd|V|×d|V|,
182"
NOTATION AND TECHNICAL ASSUMPTIONS,0.10996749729144095,and subsequently the empirical multi-task Gram matrix up to time step t is given by 1
NOTATION AND TECHNICAL ASSUMPTIONS,0.1105092091007584,"t AV(t). The
183"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11105092091007585,"following definition introduces quantities related to the clusters defined by partition P, with crucial
184"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11159263271939328,"roles that we will elucidate throughout the analysis.
185"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11213434452871072,"Definition 1 (Cluster content constants). Let C ∈P be a cluster.
186"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11267605633802817,"• We denote by ∂vC the inner boundary of C, i.e.the vertices of C that are connected to its comple-
187"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11321776814734562,mentary. We define the inner isoperimetric ratio of C as ιG(C) := |∂vC|
NOTATION AND TECHNICAL ASSUMPTIONS,0.11375947995666305,"|C| .
188"
NOTATION AND TECHNICAL ASSUMPTIONS,0.1143011917659805,"• By abuse of notation, we denote as BC the incidence matrix restricted to edges linking vertices
189"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11484290357529794,"of C, its associated Laplacian matrix by LC := B⊤
C BC, and its pseudo-inverse by L†
C. The
190"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11538461538461539,"topological centrality index of node m ∈C w.r.t C is equal to (L†
C)−1
mm. We define the topological
191"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11592632719393282,"centrality index of C by cG(C) := minm∈C(L†
C)−1
mm.
192"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11646803900325027,"The inner isoperimetric ratio of a cluster measures how many “interior” nodes a cluster contains, in
193"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11700975081256772,"the sense that they are not connected to its complementary. It is at most equal to the isoperimetric ratio
194"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11755146262188516,"for weightless graphs as the size of the inner boundary is at most equal to that of the edge boundary,
195"
NOTATION AND TECHNICAL ASSUMPTIONS,0.1180931744312026,"the latter being connected to the algebraic connectivity via the Cheeger inequality [Cheeger, 1970].
196"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11863488624052004,"The topological centrality index measures the overall connectedness of a vertex in a network and
197"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11917659804983749,"indicates how robust a node is to edge failures [Ranjan and Zhang, 2013]. Also, it can be tied to
198"
NOTATION AND TECHNICAL ASSUMPTIONS,0.11971830985915492,"electricity spreading in a network according to Van Mieghem et al. [2017]. We refer the interested
199"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12026002166847237,"reader to the two previously mentioned works for a detailed account of the properties of the topological
200"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12080173347778982,"centrality index. In the appendix, we show that for binary weights graphs the minimum topological
201"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12134344528710726,"centrality index is at least equal to the algebraic connectivity theoretically and experimentally, where
202"
NOTATION AND TECHNICAL ASSUMPTIONS,0.1218851570964247,"we showcase that the difference between the two can be significant.
203"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12242686890574214,"To proceed, we will need the following definition that introduces several notations to reduce the
204"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12296858071505959,"clutter.
205"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12351029252437704,"Definition 2 (Restricted Eigenvalue (RE) condition and norm). Let {Mi}|V|
i=1 ⊂Rd×d be a set of
206"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12405200433369447,"positive semi-definite matrices. We say that the matrix MV := diag(M1, · · · , M|V|) verifies the
207"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12459371614301191,"restricted eigenvalue condition with constants κ ≥0 and ϕ > 0 if
208"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12513542795232935,"ϕ2∥Z∥2
RE ≤
X"
NOTATION AND TECHNICAL ASSUMPTIONS,0.1256771397616468,"i∈V
∥zi∥2
Mi
∀Z ∈S with rows {zi}i∈V,"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12621885157096424,"where S is the cone defined by:
209"
NOTATION AND TECHNICAL ASSUMPTIONS,0.1267605633802817,"S := {Z ∈R|V|×d; a1(G, Θ)∥Z∥∂Pc ≤a2(G, Θ)
ZP

F + (1 −κ)+∥Z∥∂P},"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12730227518959913,"a1(G, Θ) := 1 −"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12784398699891658,"1
α0 + 2κw(∂P)"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12838569880823403,"min
C∈P p"
NOTATION AND TECHNICAL ASSUMPTIONS,0.12892741061755147,"cG(C)
,
a2(G, Θ) := 1"
NOTATION AND TECHNICAL ASSUMPTIONS,0.1294691224268689,"α0
+
√"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13001083423618634,"2κw(∂P) max
C∈P p"
NOTATION AND TECHNICAL ASSUMPTIONS,0.1305525460455038,"ιG(C),"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13109425785482123,"and the RE semi-norm is defined by ∥Z∥RE :=
ZP

F ∨(1 −κ)+B†
∂PB∂PZ
.
210"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13163596966413868,"To interpret the previous definition, we point out that the sum on the right-hand side of Definition 2
211"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13217768147345613,"can be written as
vec(Z⊤)

MV, where vec denotes the operation of stacking a matrix’s columns
212"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13271939328277357,"vertically. As a result, the condition is analogous to requiring that MV is invertible with minimum
213"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13326110509209102,"eigenvalue ϕ2, but weaker since it holds only for signals Z ∈S and for the ∥·∥RE norm. This
214"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13380281690140844,"requirement has the same form as the compatibility assumption for the Lasso [Bühlmann and van de
215"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13434452871072589,"Geer, 2011, Oh et al., 2021] or the restricted strong convexity assumption [Cella et al., 2023].
216"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13488624052004333,"We further make the following assumption on the true multi-task Gram matrix:
217"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13542795232936078,"Assumption 4 (RE condition for the true multi-task Gram matrix). For k ∈[K], let Σk := E

xkx⊤
k

218"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13596966413867823,"be the Gram matrix of the kth context vector’s marginal distribution, let ΣV be the true multi-task
219"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13651137594799567,"Gram matrix of the context vector generating distribution, given by
220"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13705308775731312,"ΣV := I|V| ⊗Σ,
where
Σ = 1 K K
X"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13759479956663057,"k=1
Σk.
(5)"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13813651137594798,"We assume that ΣV verifies RE condition (Definition 2) with some problem dependent constants
221"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13867822318526543,"κ ∈

0,
1
2w(∂P) min
C∈P p"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13921993499458288,"cG(C)

and ϕ > 0.
222"
NOTATION AND TECHNICAL ASSUMPTIONS,0.13976164680390032,"This assumption is common to make for Lasso-like bandit problems [Oh et al., 2021, Ariu et al., 2022,
223"
NOTATION AND TECHNICAL ASSUMPTIONS,0.14030335861321777,"Cella et al., 2023]. We will later show that it can be transferred to empirical multi-task Gram matrix.
224"
ORACLE INEQUALITY,0.14084507042253522,"5.2
Oracle inequality
225"
ORACLE INEQUALITY,0.14138678223185266,"This section is dedicated to provide a bound on the estimation error of the Network Lasso problem
226"
ORACLE INEQUALITY,0.1419284940411701,"given in Equation (2) at a particular step t of Algorithm 1.We assume fixed design, meaning that
227"
ORACLE INEQUALITY,0.14247020585048753,"the context vectors are given and fixed, and we are not concerned by their randomness (due to the
228"
ORACLE INEQUALITY,0.14301191765980498,"context generating distribution), nor by the randomness of their number for each user (due to random
229"
ORACLE INEQUALITY,0.14355362946912242,"selection at each time step).
230"
ORACLE INEQUALITY,0.14409534127843987,"For a time step t, we deliver the oracle inequality controlling the deviation between the estimated
231"
ORACLE INEQUALITY,0.14463705308775732,"preference vectors ˆΘ(t) and the true ones Θ. For the sake of simplicity, we provisionally assume
232"
ORACLE INEQUALITY,0.14517876489707476,"that the RE condition holds for the empirical multi-task Gram matrix AV(t).
233"
ORACLE INEQUALITY,0.1457204767063922,"Theorem 1 (Oracle inequality). Assume that the RE assumption holds for the empirical multi-
234"
ORACLE INEQUALITY,0.14626218851570963,"task Gram matrix with constants κ ∈

0,
1
2w(∂P) min
C∈P p"
ORACLE INEQUALITY,0.14680390032502708,"cG(C)

and ϕ > 0.
Suppose that
235"
ORACLE INEQUALITY,0.14734561213434452,"maxm∈V |Tm(t)| ≤bt for some b > 0. Then, with a probability at least 1 −δ(t), we have
236"
ORACLE INEQUALITY,0.14788732394366197,"Θ −ˆΘ(t)

F ≤2
σ
ϕ2√"
ORACLE INEQUALITY,0.14842903575297942,"tf(G, Θ)"
ORACLE INEQUALITY,0.14897074756229686,"v
u
u
t1 + 2b s"
ORACLE INEQUALITY,0.1495124593716143,"|V| log
1
δ(t) + 2b log
1
δ(t),"
ORACLE INEQUALITY,0.15005417118093176,"where
237"
ORACLE INEQUALITY,0.15059588299024917,"f(G, Θ) := α0

a2(G, Θ) +
√"
ORACLE INEQUALITY,0.15113759479956662,"21≤1(κ)w(∂P)

"
ORACLE INEQUALITY,0.15167930660888407,"a2(G, Θ) +
√"
ORACLE INEQUALITY,0.15222101841820151,21≤1(κ)w(∂P)
ORACLE INEQUALITY,0.15276273022751896,"a1(G, Θ) min
C∈P p"
ORACLE INEQUALITY,0.1533044420368364,"cG(C)
+ 1  ."
ORACLE INEQUALITY,0.15384615384615385,"The proof of the previous theorem mainly relies on a decomposition of the estimation error signal
238"
ORACLE INEQUALITY,0.1543878656554713,"into two parts: one is the projection of the error onto its mean per cluster value, that is, every node
239"
ORACLE INEQUALITY,0.15492957746478872,"within the same cluster is mapped to the mean estimation error of its cluster. The second part of the
240"
ORACLE INEQUALITY,0.15547128927410617,"decomposition is simply the residual part i.e. the deviation from the mean per cluster value, which
241"
ORACLE INEQUALITY,0.1560130010834236,"is related to the incidence matrices of each cluster. The probabilistic statement comes from a high
242"
ORACLE INEQUALITY,0.15655471289274106,"probability bound on the Euclidean norm of an empirical vector process associated with our problem,
243"
ORACLE INEQUALITY,0.1570964247020585,"using a generalization of the Hanson-Wright inequality to the subgaussian case [Hsu et al., 2012,
244"
ORACLE INEQUALITY,0.15763813651137595,"Theorem 2.1]. Compared to the bound of Jung [2020, Theorem 1], we bound a norm of the estimation
245"
ORACLE INEQUALITY,0.1581798483206934,"error rather than just the total variation semi-norm. Additionally, the bound exhibits different behavior
246"
ORACLE INEQUALITY,0.15872156013001085,"depending on whether κ > 1. Indeed, due to the expressions of a1(Θ, G) and a2(Θ, G), in the
247"
ORACLE INEQUALITY,0.15926327193932827,"case where κ > 1, the bound significantly decreases with the products w(∂P) minC∈P
p"
ORACLE INEQUALITY,0.1598049837486457,"ι(C) and
248"
ORACLE INEQUALITY,0.16034669555796316,w(∂P) maxC∈P cG(C)−1
ORACLE INEQUALITY,0.1608884073672806,"2 , which are both small enough for dense intra-cluster edge links and sparse
249"
ORACLE INEQUALITY,0.16143011917659805,"inter-cluster ones. However, when κ < 1, the w(∂P) term might dominate if it is moderately large,
250"
ORACLE INEQUALITY,0.1619718309859155,"and its effect can only be mitigated via a small subgaussianity constant σ or a large enough RE
251"
ORACLE INEQUALITY,0.16251354279523295,"condition constant ϕ.
252"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1630552546045504,"5.3
RE condition for the empirical multi-task Gram matrix
253"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1635969664138678,"To establish the oracle inequality, we assumed that the RE condition holds for the empirical multi-task
254"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.16413867822318526,"Gram matrix. The goal of this section is to prove this holds with high probability. To this end, we use
255"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1646803900325027,"the same strategy as in Oh et al. [2021], Cella et al. [2023]. We prove that on the one hand, given
256"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.16522210184182015,"the empirical multi-task Gram matrix inherits the RE condition from its adapted counterpart since it
257"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1657638136511376,"concentrates around it. On the other hand, we prove that the adapted Gram matrix verifies the RE
258"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.16630552546045504,"condition due to Assumption 1, 2 and 4 made on the context generation distribution.
259"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1668472372697725,"Theorem 2 (RE condition holding for the empirical multi-task Gram matrix). Under assumptions 2
260"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1673889490790899,"and 4, let t ≥1, and let κ, ϕ be the constants from Assumption 4. Assume that maxm∈V |Tm(t)| ≤bt.
261"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.16793066088840736,"Then, for any γ ∈

0,

1 + a2(G,Θ)+(1−κ)+√"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1684723726977248,"2w(∂P)
a1(G,Θ)
−2
, the empirical multi-task Gram matrix
262"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.16901408450704225,"verifies the RE condition with constants κ and ˆϕ, with
263"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1695557963163597,ˆϕ = ˜ϕ
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.17009750812567714,"v
u
u
t1 −γ "
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1706392199349946,"1 + a2(G, Θ) + (1 −κ)+√"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.17118093174431204,"2w(∂P)
a1(G, Θ) !2 ,
(6)"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.17172264355362946,with a probability at least equal to 1 −6d|V| exp
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1722643553629469,−3γ2 ˜ϕ4(minC∈P(˜cG(C) ∧˜cG(C)2)t
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.17280606717226435,"6b + 2
√"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1733477789815818,2γ ˜ϕ2 !
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.17388949079089924,", where
264"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1744312026002167,"˜ϕ :=
ϕ
√"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.17497291440953414,"2νω and ˜cG(C) := cG(C) ∧|C|
∀C ∈P.
265"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.17551462621885158,"The proof follows the same approach as in Oh et al. [2021], Cella et al. [2023]; we prove that the RE
266"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.176056338028169,"condition transfers from the true multi-task Gram matrix to its adapted counterpart VV(t), defined as
267"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.17659804983748645,"follows:
268"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1771397616468039,"VV(t) = diag
 
V1(t), · · · , V|V|(t)

,
(7)"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.17768147345612134,"where
269"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1782231852654388,Vm(t) = 1 t X
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.17876489707475623,"τ∈Tm(t)
E

x(τ)x(τ)⊤|Fτ−1

.
(8)"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.17930660888407368,"This transfer relies on the work of Oh et al. [2021, lemma 10]. The other step of the proof is showing
270"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.17984832069339113,"that the empirical multi-task Gram matrix and VV(t) become close to each other with high probability
271"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.18039003250270855,"after sufficiently many time steps, the respective distance between the two is measured with a matrix
272"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.180931744312026,"norm induced by the RE semi-norm and the restriction to set S (Definition 2). The bound showcases
273"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.18147345612134344,"a dependence on minC∈P cG(C) ∧|C|, which is of the same order as |C| for a fully connected cluster
274"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.1820151679306609,"with vertices C. It is also clear that with a higher minimum centrality of a cluster, the probability of
275"
RE CONDITION FOR THE EMPIRICAL MULTI-TASK GRAM MATRIX,0.18255687973997833,"satisfying the RE condition increases.
276"
REGRET BOUND,0.18309859154929578,"5.4
Regret bound
277"
REGRET BOUND,0.18364030335861323,"To bound the regret, we bound the expected instantaneous regret for each round t ≥1. This bound
278"
REGRET BOUND,0.18418201516793067,"relies on the oracle inequality holding and on the RE condition being satisfied for the empirical Gram
279"
REGRET BOUND,0.1847237269772481,"matrix, both with high probability. These two conditions are ensured and Theorem 1 and Theorem 2.
280"
REGRET BOUND,0.18526543878656554,"Theorem 3 (Regret bound). Let the mean horizon per node be T =
T
|V|.
Let min
C∈P p"
REGRET BOUND,0.18580715059588299,"cG(C)
281"
REGRET BOUND,0.18634886240520043,"going asymptotically to infinity and maxC∈P
p"
REGRET BOUND,0.18689057421451788,"ιG(C) going asymptotically to zero as well as
282"
REGRET BOUND,0.18743228602383533,"maxC∈P
p"
REGRET BOUND,0.18797399783315277,"ιG(C)w(∂P) and
w(∂P)
min
C∈P p"
REGRET BOUND,0.18851570964247022,"cG(C) going asymptotically to zero. Under assumptions1 to 4
283"
REGRET BOUND,0.18905742145178764,"and κ < 1, the expected regret of the Network Lasso Bandit algorithm is upper bounded as follows:
284"
REGRET BOUND,0.18959913326110509,R(|V|T) = O  
REGRET BOUND,0.19014084507042253,"v
u
u
t
T
min
C∈P cG(C) p"
REGRET BOUND,0.19068255687973998,"|V| +
q log
 "
REGRET BOUND,0.19122426868905743,"T|V|

+
4qV log
 "
REGRET BOUND,0.19176598049837487,"T|V|


+ 1"
REGRET BOUND,0.19230769230769232,"A log(d|V|)  ,"
REGRET BOUND,0.19284940411700974,"with A = 3γ2 minC∈P(˜cG(C) ∧˜c2
G(C))"
REGRET BOUND,0.19339111592632718,"6 log(|V|)
√"
REGRET BOUND,0.19393282773564463,"|V| + 2
√"
REGRET BOUND,0.19447453954496208,"2γ
.
285"
REGRET BOUND,0.19501625135427952,"Our regret is mainly formed of two parts. The first one is the sublinear time-dependent term and
286"
REGRET BOUND,0.19555796316359697,"represents the bulk of horizon dependence. Interestingly, it does not depend on the dimension,
287"
REGRET BOUND,0.19609967497291442,"which is a consequence of using the concentration inequality from Hsu et al. [2012]. Interestingly, it
288"
REGRET BOUND,0.19664138678223186,"decreases as the topological centrality index grows with the graph size, which proves the importance
289"
REGRET BOUND,0.19718309859154928,"of intra-cluster high connectivity.
290"
REGRET BOUND,0.19772481040086673,"The second significant term comes from ensuring the RE condition for the empirical multi-task Gram
291"
REGRET BOUND,0.19826652221018418,"matrix, and can be interpreted as the number of time steps necessary for it to hold, as pointed out by
292"
REGRET BOUND,0.19880823401950162,"Oh et al. [2021]. It has a logarithmic dependence in the graph size and in the dimension, which is
293"
REGRET BOUND,0.19934994582881907,"a characteristic of regret bound of the ""lasso type"". Also noteworthy is that the regret grows with
294"
REGRET BOUND,0.19989165763813652,"log(d) only in the time-independent term, making our policy useful in high-dimensional settings.
295"
EXPERIMENTS,0.20043336944745396,"6
Experiments
296"
EXPERIMENTS,0.2009750812567714,"We provide experiments to showcase the effect on the problem’s parameters on our algorithm’s
297"
EXPERIMENTS,0.20151679306608883,"performance as well as highlighting its advantageous performance compared to other algorithms. At
298"
EXPERIMENTS,0.20205850487540628,"each time step, the algorithm solves the network lasso problem (2) via a primal-dual algorithm used
299"
EXPERIMENTS,0.20260021668472372,"in Jung [2020].
300"
EXPERIMENTS,0.20314192849404117,"We compare our algorithm to several baselines of the literature. On the one hand, baselines relying
301"
EXPERIMENTS,0.20368364030335862,"on a given graph, GOBLin [Cesa-Bianchi et al., 2013] and GraphUCB [Yang et al., 2020] that use
302"
EXPERIMENTS,0.20422535211267606,"the Laplacian to smooth the preference vectors. On the other hand, we consider online clustering
303"
EXPERIMENTS,0.2047670639219935,"of bandits baselines, namely CLUB [Gentile et al., 2014] and SCLUB [Li et al., 2019]. Since these
304"
EXPERIMENTS,0.20530877573131096,"latter approaches start with a fully connected graph, we provide them the known graph for a fair
305"
EXPERIMENTS,0.20585048754062837,"comparison. As a sanity check, we also compare the independent task learning case with LinUCB
306"
EXPERIMENTS,0.20639219934994582,"(LinUcbITL) where each task is solved independently, and to the case of a LinUCB agent for each
307"
EXPERIMENTS,0.20693391115926327,"cluster (LinUcbOracle). The graph used is generated using stochastic block models in order to ensure
308"
EXPERIMENTS,0.20747562296858071,"that the generated graph induces a cluster structure, where an edge is constructed with probability p
309"
EXPERIMENTS,0.20801733477789816,"within clusters and q between clusters.
310"
EXPERIMENTS,0.2085590465872156,"Experimentally, we found that normalizing the adjacency matrix, that is we utilize the following
311"
EXPERIMENTS,0.20910075839653305,"normalized edges: wmn =
1
p"
EXPERIMENTS,0.2096424702058505,"deg(m) deg(n)
, where deg(m) denotes the degree of node m, yields
312"
EXPERIMENTS,0.21018418201516792,"significantly better results. Indeed, such a normalization makes the algorithm focus more on edges
313"
EXPERIMENTS,0.21072589382448537,"between low-degree nodes, which improves the propagation of the collected information within the
314"
EXPERIMENTS,0.2112676056338028,"graph. In all experiments we have set α0 = 0.1.
315"
EXPERIMENTS,0.21180931744312026,"Our results clearly showcase an improvement compared to the other baselines. Apart from the oracle
316"
EXPERIMENTS,0.2123510292524377,"that has complete knowledge of all clusters from the beginning, our policy performs significantly
317"
EXPERIMENTS,0.21289274106175515,"better than the rest beyond the error margins, covering one standard deviation at ten repetitions. We
318"
EXPERIMENTS,0.2134344528710726,"0
500
1000
1500
2000
2500
3000 0 200 400 600 800 1000"
EXPERIMENTS,0.21397616468039005,"CLUB
GOBLin
GraphUCB
LinUcbITL
LinUcbOracle
NetLasso
SCLUB"
EXPERIMENTS,0.21451787648970747,"(a) |V| = 100, d = 20, p = 0.4, q = 0.1"
EXPERIMENTS,0.2150595882990249,"0
200
400
600
800
1000 0 100 200 300 400 500"
EXPERIMENTS,0.21560130010834236,"CLUB
GOBLin
GraphUCB
LinUcbITL
LinUcbOracle
NetLasso
SCLUB"
EXPERIMENTS,0.2161430119176598,"(b) |V| = 100, d = 10, p = 0.5, q = 0.1"
EXPERIMENTS,0.21668472372697725,"0
500
1000
1500
2000
2500
3000 0 100 200 300 400"
"CLUB
GOBLIN
GRAPHUCB
LINUCBITL
LINUCBORACLE
NETLASSO
SCLUB",0.2172264355362947,"500
CLUB
GOBLin
GraphUCB
LinUcbITL
LinUcbOracle
NetLasso
SCLUB"
"CLUB
GOBLIN
GRAPHUCB
LINUCBITL
LINUCBORACLE
NETLASSO
SCLUB",0.21776814734561215,"(c) |V| = 50, d = 80, p = 0.8, q = 0.2"
"CLUB
GOBLIN
GRAPHUCB
LINUCBITL
LINUCBORACLE
NETLASSO
SCLUB",0.21830985915492956,"0
1000
2000
3000
4000
5000 0 250 500 750 1000 1250 1500 1750 2000"
"CLUB
GOBLIN
GRAPHUCB
LINUCBITL
LINUCBORACLE
NETLASSO
SCLUB",0.218851570964247,"CLUB
GOBLin
GraphUCB
LinUcbITL
LinUcbOracle
NetLasso
SCLUB"
"CLUB
GOBLIN
GRAPHUCB
LINUCBITL
LINUCBORACLE
NETLASSO
SCLUB",0.21939328277356446,"(d) |V| = 200, d = 20, p = 0.5, q = 0.05"
"CLUB
GOBLIN
GRAPHUCB
LINUCBITL
LINUCBORACLE
NETLASSO
SCLUB",0.2199349945828819,"Figure 1: Synthetic data experiment showing the cumulative regret of Network Lasso Policy as a
function of time-steps compared to other baselines, for different choices of |V|, d, p and q."
"CLUB
GOBLIN
GRAPHUCB
LINUCBITL
LINUCBORACLE
NETLASSO
SCLUB",0.22047670639219935,"provide results for up to |V| = 500 nodes showing the effective transfer of knowledge within the
319"
"CLUB
GOBLIN
GRAPHUCB
LINUCBITL
LINUCBORACLE
NETLASSO
SCLUB",0.2210184182015168,"graph.
320"
CONCLUSION AND FUTURE PERSPECTIVES,0.22156013001083424,"7
Conclusion and future perspectives
321"
CONCLUSION AND FUTURE PERSPECTIVES,0.2221018418201517,"In this work, we proposed a multi-task bandit framework that solves the case where the task preference
322"
CONCLUSION AND FUTURE PERSPECTIVES,0.2226435536294691,"vectors are piecewise constant over a graph. To this end, we used the Network Lasso policy to estimate
323"
CONCLUSION AND FUTURE PERSPECTIVES,0.22318526543878656,"the task parameters, which bypasses explicit clustering procedures. We showed a sublinear regret
324"
CONCLUSION AND FUTURE PERSPECTIVES,0.223726977248104,"bound and as a byproduct, we proved a novel oracle inequality that relies on the small size of the
325"
CONCLUSION AND FUTURE PERSPECTIVES,0.22426868905742145,"boundary as well as on the high value of the topological centrality index of each node within its
326"
CONCLUSION AND FUTURE PERSPECTIVES,0.2248104008667389,"cluster. Our experimental evaluations highlight the advantage of our method, especially when either
327"
CONCLUSION AND FUTURE PERSPECTIVES,0.22535211267605634,"the number of dimensions or nodes increases.
328"
CONCLUSION AND FUTURE PERSPECTIVES,0.2258938244853738,"Due to the technical similarity of our problem with the Lasso, a natural extension would be to extend
329"
CONCLUSION AND FUTURE PERSPECTIVES,0.22643553629469124,"it to a thresholded approach, in the same vein as [Ariu et al., 2022]. Another possible extension would
330"
CONCLUSION AND FUTURE PERSPECTIVES,0.22697724810400866,"be to use regularization with higher order total variation terms that impose a piecewise polynomial
331"
CONCLUSION AND FUTURE PERSPECTIVES,0.2275189599133261,"signal on a graph, as explained for scalar signals in Wang et al. [2016], Ortelli and van de Geer
332"
CONCLUSION AND FUTURE PERSPECTIVES,0.22806067172264355,"[2019].
333"
REFERENCES,0.228602383531961,"References
334"
REFERENCES,0.22914409534127844,"Y. Abbasi-Yadkori, D. Pál, and C. Szepesvári. Improved algorithms for linear stochastic bandits.
335"
REFERENCES,0.2296858071505959,"Advances in neural information processing systems, 24, 2011.
336"
REFERENCES,0.23022751895991334,"K. Ariu, K. Abe, and A. Proutiere. Thresholded Lasso Bandit. In Proceedings of the 39th International
337"
REFERENCES,0.23076923076923078,"Conference on Machine Learning, pages 878–928. PMLR, 2022.
338"
REFERENCES,0.2313109425785482,"H. Bastani and M. Bayati. Online Decision Making with High-Dimensional Covariates. Operations
339"
REFERENCES,0.23185265438786565,"Research, 2019. doi: 10.1287/opre.2019.1902.
340"
REFERENCES,0.2323943661971831,"S. Basu, B. Kveton, M. Zaheer, and C. Szepesvari. No Regrets for Learning the Prior in Bandits. In
341"
REFERENCES,0.23293607800650054,"Advances in Neural Information Processing Systems, 2021.
342"
REFERENCES,0.233477789815818,"S. Bilaj, S. Dhouib, and S. Maghsudi. Meta learning in bandits within shared affine subspaces. In
343"
REFERENCES,0.23401950162513543,"Proceedings of The 27th International Conference on Artificial Intelligence and Statistics. PMLR,
344"
REFERENCES,0.23456121343445288,"2024.
345"
REFERENCES,0.23510292524377033,"J. Borge-Holthoefer, A. Rivero, I. García, E. Cauhé, A. Ferrer, D. Ferrer, D. Francos, D. Iniguez, M. P.
346"
REFERENCES,0.23564463705308775,"Pérez, G. Ruiz, et al. Structural and dynamical patterns on online social networks: the spanish may
347"
REFERENCES,0.2361863488624052,"15th movement as a case study. PloS one, 6(8), 2011.
348"
REFERENCES,0.23672806067172264,"P. Bühlmann and S. van de Geer. Statistics for high-dimensional data. Springer Series in Statistics.
349"
REFERENCES,0.2372697724810401,"Springer, Heidelberg, 2011. ISBN 978-3-642-20191-2.
350"
REFERENCES,0.23781148429035753,"L. Cella and M. Pontil. Multi-task and meta-learning with sparse linear bandits. In Uncertainty in
351"
REFERENCES,0.23835319609967498,"Artificial Intelligence. PMLR, 2021.
352"
REFERENCES,0.23889490790899243,"L. Cella, A. Lazaric, and M. Pontil. Meta-learning with stochastic linear bandits. In Proceedings of
353"
REFERENCES,0.23943661971830985,"the 37th International Conference on Machine Learning. PMLR, 2020.
354"
REFERENCES,0.2399783315276273,"L. Cella, K. Lounici, G. Pacreau, and M. Pontil. Multi-task representation learning with stochastic
355"
REFERENCES,0.24052004333694474,"linear bandits. In International Conference on Artificial Intelligence and Statistics, 2023.
356"
REFERENCES,0.24106175514626219,"N. Cesa-Bianchi, C. Gentile, and G. Zappella. A gang of bandits. Advances in neural information
357"
REFERENCES,0.24160346695557963,"processing systems, 26, 2013.
358"
REFERENCES,0.24214517876489708,"J. Cheeger. A lower bound for the smallest eigenvalue of the laplacian. Problems in analysis, 1970.
359"
REFERENCES,0.24268689057421453,"X. Cheng, C. Pan, and S. Maghsudi. Parallel online clustering of bandits via hedonic game. In
360"
REFERENCES,0.24322860238353197,"International Conference on Machine Learning, pages 5485–5503. PMLR, 2023.
361"
REFERENCES,0.2437703141928494,"W. Chu, L. Li, L. Reyzin, and R. Schapire. Contextual bandits with linear payoff functions. In
362"
REFERENCES,0.24431202600216684,"Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics.
363"
REFERENCES,0.24485373781148428,"JMLR Workshop and Conference Proceedings, 2011.
364"
REFERENCES,0.24539544962080173,"X. Dong, D. Thanou, M. Rabbat, and P. Frossard. Learning graphs from data: A signal representation
365"
REFERENCES,0.24593716143011918,"perspective. IEEE Signal Processing Magazine, 2019.
366"
REFERENCES,0.24647887323943662,"D. Easley, J. Kleinberg, et al. Networks, crowds, and markets: Reasoning about a highly connected
367"
REFERENCES,0.24702058504875407,"world, volume 1. Cambridge university press Cambridge, 2010.
368"
REFERENCES,0.24756229685807152,"A. Fontan and C. Altafini. On the properties of laplacian pseudoinverses. In 2021 60th IEEE
369"
REFERENCES,0.24810400866738894,"Conference on Decision and Control (CDC). IEEE, 2021.
370"
REFERENCES,0.24864572047670638,"C. Gentile, S. Li, and G. Zappella. Online clustering of bandits. In International Conference on
371"
REFERENCES,0.24918743228602383,"Machine Learning, pages 757–765. PMLR, 2014.
372"
REFERENCES,0.24972914409534128,"C. Gentile, S. Li, P. Kar, A. Karatzoglou, G. Zappella, and E. Etrue. On context-dependent clustering
373"
REFERENCES,0.2502708559046587,"of bandits. In International Conference on machine learning, pages 1253–1262. PMLR, 2017.
374"
REFERENCES,0.25081256771397614,"D. Hallac, J. Leskovec, and S. Boyd. Network lasso: Clustering and optimization in large graphs. In
375"
REFERENCES,0.2513542795232936,"Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data
376"
REFERENCES,0.25189599133261104,"mining, pages 387–396, 2015.
377"
REFERENCES,0.2524377031419285,"M. Herbster, S. Pasteris, F. Vitale, and M. Pontil. A gang of adversarial bandits. Advances in Neural
378"
REFERENCES,0.25297941495124593,"Information Processing Systems, 34, 2021.
379"
REFERENCES,0.2535211267605634,"D. Hsu, S. Kakade, and T. Zhang. A tail inequality for quadratic forms of subgaussian random vectors.
380"
REFERENCES,0.2540628385698808,"Electronic Communications in Probability, 17, 2012.
381"
REFERENCES,0.25460455037919827,"J. Hu, X. Chen, C. Jin, L. Li, and L. Wang. Near-optimal representation learning for linear bandits
382"
REFERENCES,0.2551462621885157,"and linear rl. In International Conference on Machine Learning. PMLR, 2021.
383"
REFERENCES,0.25568797399783316,"A. Jung. Networked Exponential Families for Big Data Over Networks. IEEE Access, 8, 2020. ISSN
384"
REFERENCES,0.2562296858071506,"2169-3536.
385"
REFERENCES,0.25677139761646806,"A. Jung and N. Vesselinova. Analysis of network lasso for semi-supervised regression. In The 22nd
386"
REFERENCES,0.2573131094257855,"International Conference on Artificial Intelligence and Statistics, pages 380–387. PMLR, 2019.
387"
REFERENCES,0.25785482123510295,"A. Jung, N. Tran, and A. Mara. When Is Network Lasso Accurate? Frontiers in Applied Mathematics
388"
REFERENCES,0.2583965330444204,"and Statistics, 3, 2018. ISSN 2297-4687.
389"
REFERENCES,0.2589382448537378,"G.-S. Kim and M. C. Paik. Doubly-robust lasso bandit. Advances in Neural Information Processing
390"
REFERENCES,0.25947995666305523,"Systems, 32, 2019.
391"
REFERENCES,0.2600216684723727,"B. Kveton, M. Konobeev, M. Zaheer, C.-w. Hsu, M. Mladenov, C. Boutilier, and C. Szepesvari.
392"
REFERENCES,0.2605633802816901,"Meta-thompson sampling. In International Conference on Machine Learning. PMLR, 2021.
393"
REFERENCES,0.2611050920910076,"L. Li, W. Chu, J. Langford, and R. E. Schapire. A contextual-bandit approach to personalized news
394"
REFERENCES,0.261646803900325,"article recommendation. In Proceedings of the 19th international conference on World wide web,
395"
REFERENCES,0.26218851570964247,"pages 661–670, 2010.
396"
REFERENCES,0.2627302275189599,"S. Li, W. Chen, and K.-S. Leung. Improved algorithm on online clustering of bandits. arXiv preprint
397"
REFERENCES,0.26327193932827736,"arXiv:1902.09162, 2019.
398"
REFERENCES,0.2638136511375948,"M. McPherson, L. Smith-Lovin, and J. M. Cook. Birds of a feather: Homophily in social networks.
399"
REFERENCES,0.26435536294691225,"Annual review of sociology, 27(1):415–444, 2001.
400"
REFERENCES,0.2648970747562297,"M. E. Newman. Modularity and community structure in networks. Proceedings of the national
401"
REFERENCES,0.26543878656554715,"academy of sciences, 103(23):8577–8582, 2006.
402"
REFERENCES,0.2659804983748646,"T. T. Nguyen and H. W. Lauw. Dynamic clustering of contextual multi-armed bandits. In Pro-
403"
REFERENCES,0.26652221018418204,"ceedings of the 23rd ACM international conference on conference on information and knowledge
404"
REFERENCES,0.26706392199349943,"management, pages 1959–1962, 2014.
405"
REFERENCES,0.2676056338028169,"B. Nourani-Koliji, S. Bilaj, A. R. Balef, and S. Maghsudi. Piecewise-stationary combinatorial
406"
REFERENCES,0.2681473456121343,"semi-bandit with causally related rewards. arXiv preprint arXiv:2307.14138, 2023.
407"
REFERENCES,0.26868905742145177,"M.-H. Oh, G. Iyengar, and A. Zeevi. Sparsity-Agnostic Lasso Bandit. In Proceedings of the 38th
408"
REFERENCES,0.2692307692307692,"International Conference on Machine Learning, pages 8271–8280. PMLR, 2021.
409"
REFERENCES,0.26977248104008666,"F. Ortelli and S. van de Geer. Synthesis and analysis in total variation regularization. arXiv preprint
410"
REFERENCES,0.2703141928494041,"arXiv:1901.06418, 2019.
411"
REFERENCES,0.27085590465872156,"A. Peleg, N. Pearl, and R. Meir. Metalearning linear bandits by prior update. In Proceedings of The
412"
REFERENCES,0.271397616468039,"25th International Conference on Artificial Intelligence and Statistics. PMLR, 2022.
413"
REFERENCES,0.27193932827735645,"G. Ranjan and Z.-L. Zhang. Geometry of complex networks and topological centrality. Physica A:
414"
REFERENCES,0.2724810400866739,"Statistical Mechanics and its Applications, 2013.
415"
REFERENCES,0.27302275189599134,"X. Su and T. M. Khoshgoftaar. A survey of collaborative filtering techniques. Advances in artificial
416"
REFERENCES,0.2735644637053088,"intelligence, 2009, 2009.
417"
REFERENCES,0.27410617551462624,"R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical
418"
REFERENCES,0.2746478873239437,"Society Series B: Statistical Methodology, 1996.
419"
REFERENCES,0.27518959913326113,"J. Tropp. Freedman’s inequality for matrix martingales. Electronic Communications in Probability,
420"
REFERENCES,0.2757313109425785,"16:262 – 270, 2011.
421"
REFERENCES,0.27627302275189597,"P. Van Mieghem, K. Devriendt, and H. Cetinay. Pseudoinverse of the laplacian and best spreader
422"
REFERENCES,0.2768147345612134,"node in a network. Physical Review E, 2017.
423"
REFERENCES,0.27735644637053086,"Y.-X. Wang, J. Sharpnack, A. J. Smola, and R. J. Tibshirani. Trend filtering on graphs. Journal
424"
REFERENCES,0.2778981581798483,"of Machine Learning Research, 17(105):1–41, 2016. URL http://jmlr.org/papers/v17/
425"
REFERENCES,0.27843986998916576,"15-147.html.
426"
REFERENCES,0.2789815817984832,"K. Yang and L. Toni. Graph-based recommendation system. In 2018 IEEE Global Conference on
427"
REFERENCES,0.27952329360780065,"Signal and Information Processing (GlobalSIP), pages 798–802. IEEE, 2018.
428"
REFERENCES,0.2800650054171181,"K. Yang, L. Toni, and X. Dong. Laplacian-regularized graph bandits: Algorithms and theoretical
429"
REFERENCES,0.28060671722643554,"analysis. In International Conference on Artificial Intelligence and Statistics, pages 3133–3143.
430"
REFERENCES,0.281148429035753,"PMLR, 2020.
431"
REFERENCES,0.28169014084507044,"M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. Journal of
432"
REFERENCES,0.2822318526543879,"the Royal Statistical Society Series B: Statistical Methodology, 2006.
433"
REFERENCES,0.28277356446370533,"A
Some helper results
434"
REFERENCES,0.2833152762730228,"Proposition 1 (Bounds on norms of matrix products). Let M ∈Rm×n and N ∈Rn×p. Then
435"
REFERENCES,0.2838569880823402,"∥MN∥q,1 ≤∥M∥∞,1∥N∥q,1
∀q ∈[1, ∞]"
REFERENCES,0.2843986998916576,∥MN∥F ≤∥M∥∥N∥F
REFERENCES,0.28494041170097506,"∥MN∥F ≤
q"
REFERENCES,0.2854821235102925,"∥M⊤M∥∞,∞∥N∥2,1"
REFERENCES,0.28602383531960995,"∥MN∥2,1 ≤∥M∥2,1∥N∥"
REFERENCES,0.2865655471289274,"Proof.
436"
REFERENCES,0.28710725893824485,"First inequality
For any q ∈[1, ∞], we have:
437"
REFERENCES,0.2876489707475623,"e⊤
i MN

q ="
REFERENCES,0.28819068255687974,"e⊤
i M n
X"
REFERENCES,0.2887323943661972,"j=1
eje⊤
j N q"
REFERENCES,0.28927410617551463,"≤max
1≤j≤n
e⊤
i Mej

n
X j=1"
REFERENCES,0.2898158179848321,"e⊤
j N

q = max
1≤j≤n |(M)ij|∥N∥q,1 438"
REFERENCES,0.2903575297941495,"Second inequality
We have
439"
REFERENCES,0.290899241603467,"∥MN∥2
F = p
X"
REFERENCES,0.2914409534127844,"j=1
∥MNej∥2 ≤ p
X"
REFERENCES,0.29198266522210187,"j=1
∥M∥∥Nej∥2 = ∥M∥∥N∥2
F 440"
REFERENCES,0.29252437703141926,"Third inequality
We have
441"
REFERENCES,0.2930660888407367,"∥MN∥2
F = Tr(MNN⊤M⊤) ≤
M⊤M

∞,∞
NN⊤
1,1"
REFERENCES,0.29360780065005415,"Elements of (i, j) entry of matrix NN⊤is the inner product

e⊤
i N, e⊤
j N

. Hence, we have
442"
REFERENCES,0.2941495124593716,"NN⊤
1,1 =
X i,j"
REFERENCES,0.29469122426868904,"e⊤
i N, e⊤
j N
 ≤
X i,j"
REFERENCES,0.2952329360780065,"e⊤
i N
e⊤
j N
 = ∥N∥2
2,1. 443"
REFERENCES,0.29577464788732394,"Fourth inequality
We have
444"
REFERENCES,0.2963163596966414,"∥MN∥2,1 = m
X"
REFERENCES,0.29685807150595883,"i=1
∥eiMN∥≤ m
X"
REFERENCES,0.2973997833152763,"i=1
∥eiM∥∥N∥= ∥M∥2,1∥N∥ 445"
REFERENCES,0.2979414951245937,"Proposition 2 (Decomposition of a signal over a graph). For any C ∈P
446"
REFERENCES,0.29848320693391117,"• Let Z ∈R|V|×d be a graph signal. Let us denote by ZC the signal obtained from Z by
447"
REFERENCES,0.2990249187432286,"setting rows of vertices outside of C to zeros, and let Z|C ∈R|C|×d be the signal obtained
448"
REFERENCES,0.29956663055254606,"from ZC by removing the rows of vertices outside of C. Also, let B|C ∈R|EC|×|C| be the
449"
REFERENCES,0.3001083423618635,"matrix obtained by taking BC, and removing rows of edges that link C to its outside, and the
450"
REFERENCES,0.30065005417118096,"resulting null columns. It is clear that
451"
REFERENCES,0.30119176598049835,"BCZ = BCZC = B|CZ|C
(9)"
REFERENCES,0.3017334777898158,"• Let QC := B†
CBC. Then
452"
REFERENCES,0.30227518959913324,"I|V| =
X"
REFERENCES,0.3028169014084507,"C∈P
JC + QC
(10)"
REFERENCES,0.30335861321776814,"Q∂Pc :== B†
∂PcB∂Pc =
X"
REFERENCES,0.3039003250270856,"C∈P
QC
(11)"
REFERENCES,0.30444203683640303,"where JC = 1C1⊤
C
|C| , QC = B†
CBC
∀C ∈P and Q∂Pc := B†
∂PcB∂Pc.
453"
REFERENCES,0.3049837486457205,While P
REFERENCES,0.3055254604550379,"C∈P JC projects each entry of a graph signal onto the mean vector value of its
454"
REFERENCES,0.30606717226435537,"respective cluster, its residual Q∂Pc can be interpreted as the projection onto the respective
455"
REFERENCES,0.3066088840736728,"entries deviation from its cluster mean value.
456"
REFERENCES,0.30715059588299026,"Proof. Since the proof of the first point is trivial, we directly treat the second point. Denoting B†
|C the
457"
REFERENCES,0.3076923076923077,"pseudo-inverse of B|C it is a well-known linear algebra result that the matrix Q|C := B†
|CB|C is the
458"
REFERENCES,0.30823401950162516,"projector onto the null space of B|C. Since C is connected, the null space of B|C is unidimensional,
459"
REFERENCES,0.3087757313109426,"and is generated by vector 1|C| ∈R|C| having only ones as coordinates. Since the projector into that
460"
REFERENCES,0.30931744312026005,"nullspace is J|C| :=
1|C|1|C|"
REFERENCES,0.30985915492957744,"|C|
, we deduce that
461"
REFERENCES,0.3104008667388949,"Z|C = J|C|Z|C + Q|CZ|C
=⇒ZC = JCZC + QCZC
= JCZ + QCZ"
REFERENCES,0.31094257854821233,"where in the last line, QC := B†
CBC. Consequently, we have
462 Z =
X"
REFERENCES,0.3114842903575298,"C∈P
ZC =
X"
REFERENCES,0.3120260021668472,"C∈P
JCZ + QCZ"
REFERENCES,0.3125677139761647,"To prove the second point, we recall that B∂Pc is the incidence matrix obtained by setting rows
463"
REFERENCES,0.3131094257854821,"corresponding to edges in ∂P to zero. In other words, B∂Pc is the incidence matrix of the graph
464"
REFERENCES,0.31365113759479957,"after removing the boundary edges, and having exactly |P| connected components. Hence, B∂Pc
465"
REFERENCES,0.314192849404117,"has a null space spanned by the set {1C}C∈P, and the orthogonal projector onto this null space is
466
P"
REFERENCES,0.31473456121343446,"C∈P JC. Combining this fact with the fact that Q∂Pc is the projector onto the orthogonal of the
467"
REFERENCES,0.3152762730227519,"null space of B∂Pc, we arrive at the second point.
468"
REFERENCES,0.31581798483206935,"Proposition 3 (On the minimum topological centrality index of a graph vertex). Let G be a connected
469"
REFERENCES,0.3163596966413868,"graph with incidence matrix B and vertex set size N, and let L := B⊤B. Let c(G) denote the
470"
REFERENCES,0.31690140845070425,"minimum value of inverses of diagonal element of L†, called its minimum topological centrality index.
471"
REFERENCES,0.3174431202600217,"Also let a(G) be its algebraic connectivity, defined as the minimum non null eigenvalue of L. Then
472"
REFERENCES,0.3179848320693391,"• c(G) = ∥L∥−1
∞,∞.
473"
REFERENCES,0.31852654387865653,"• c(G) ≥a(G).
474"
REFERENCES,0.319068255687974,"• If G is weightless, then c(G) ≤
N 2
N−1.
475"
REFERENCES,0.3196099674972914,"Proof. Since L is PSD, L† is PSD and hence
L†
∞,∞is equal to the maximum diagonal entry of
476"
REFERENCES,0.32015167930660887,"L†. Taking the inverse proves the first point. Also, this implies that
477"
REFERENCES,0.3206933911159263,"c(G) =
L†−1"
REFERENCES,0.32123510292524377,"∞,∞≥
L†−1 = a(G),
(12)"
REFERENCES,0.3217768147345612,"where we used the fact that ∥·∥∞,∞≤∥·∥for matrices. This proves the second point of the
478"
REFERENCES,0.32231852654387866,"proposition.
479"
REFERENCES,0.3228602383531961,"For the last point, assume G is weightless, let Lcomp be the Laplaciane of complete graph built on the
480"
REFERENCES,0.32340195016251355,"vertices of G. Then we have Lcomp = N(IN −JN), where J is the square matrix of dimension N
481"
REFERENCES,0.323943661971831,"having 1/N as entries. From Fontan and Altafini [2021, Lemma 4], we have
482"
REFERENCES,0.32448537378114845,"L†
comp = (Lcomp + NJN)−1 −1"
REFERENCES,0.3250270855904659,N JN = IN N −1
REFERENCES,0.32556879739978334,"N JN
(13)"
REFERENCES,0.3261105092091008,which has diagonal elements 1
REFERENCES,0.3266522210184182,"N −
1
N 2 .
483"
REFERENCES,0.3271939328277356,"On the other hand, L ≼Lcomp Hence, by Fontan and Altafini [2021, lemma 4] we have for any
484"
REFERENCES,0.32773564463705307,"u ̸= 0
485"
REFERENCES,0.3282773564463705,"L† = (L + aJN)−1 −JN/a ≽(Lcomp + aJN)−1 −JN/a = L†
comp"
REFERENCES,0.32881906825568796,"This implies that the maximum diagonal entry of L† is at least equal to that of L†
comp, i.e.to 1"
REFERENCES,0.3293607800650054,"N −
1
N2 .
486"
REFERENCES,0.32990249187432286,"Taking the inverse of that entry finishes the proof.
487 488"
REFERENCES,0.3304442036836403,"B
Proofs of the different claims
489"
REFERENCES,0.33098591549295775,"B.1
Additional notation
490"
REFERENCES,0.3315276273022752,"The regularization term can be written more compactly using the incidence matrix of the graph
491"
REFERENCES,0.33206933911159264,"B ∈R|E|×|V| corresponding to an arbitrary orientation under the following form
492 X"
REFERENCES,0.3326110509209101,"1≤m<n≤|V|
wmn∥θm −θn∥= ∥BΘ∥2,1 = ∥Θ∥E
(14)"
REFERENCES,0.33315276273022754,"where the ∥·∥2,1 norm denotes the sum of the L2 norms o the rows of a matrix.1 We provide notations
493"
REFERENCES,0.333694474539545,"that we use in the proofs of the different statements, in order to reduce the clutter. We define
494"
REFERENCES,0.33423618634886243,"E := ˆΘ −Θ as the error signal, and its rows by {ϵm}|V|
m=1.
495"
REFERENCES,0.3347778981581798,"While PC
k=1 JC projects each entry of a graph signal onto the mean vector value of its respective
496"
REFERENCES,0.33531960996749727,"cluster, its residual Q∂Pc can be interpreted as the projection onto the respective entries deviation
497"
REFERENCES,0.3358613217768147,"from its cluster mean value.
498"
REFERENCES,0.33640303358613216,"Let ηm be a vector, vertically concatenated by noise terms of rewards received by node m, then we
499"
REFERENCES,0.3369447453954496,"define K ∈R|V|×d as the matrix of vertically concatenated row vectors η⊤
mXm.
500"
REFERENCES,0.33748645720476705,"B.2
Oracle inequality
501"
REFERENCES,0.3380281690140845,"In this section, we present all intermediary theoretical results leading to Theorem 1 stating the oracle
502"
REFERENCES,0.33856988082340195,"inequality. To reduce the clutter, we omit the dependence on t of several quantities. For instance, we
503"
REFERENCES,0.3391115926327194,"write α and ˆΘ instead of α(t) and ˆΘ(t).
504"
REFERENCES,0.33965330444203684,"Lemma 1 (A first deterministic inequality). Let t be a time step. We have
505 1
2tα X"
REFERENCES,0.3401950162513543,"m∈V
∥Xmϵm∥2 + ∥E∥∂Pc ≤1"
REFERENCES,0.34073672806067173,"tα ⟨K, E⟩+ ∥E∥∂P
(15)"
REFERENCES,0.3412784398699892,"1It is possible that the notation ∥·∥2,1 denotes the sum of 2−norms of columns in the literature."
REFERENCES,0.3418201516793066,"Notation
Meaning"
REFERENCES,0.3423618634886241,Indpendent of time t
REFERENCES,0.3429035752979415,"V
set of graph vertices
E
set of graph edges
BI ∈R|E|×|V|, I ⊆E
Graph incidence Matrix obtained by setting rows of edges outside I to zeros
BC ∈R|E|×|V|
cf. Definition 1
L ∈R|V|×|V|
B⊤B
θm ∈Rd
true preference vector of user/bandit m
Θ ∈R|V|×d
matrix of true vertically concatenated row preferences vectors
∂P ⊆E
Boundary of P: set of edges connecting nodes from different clusters
cG(C)
Minimum topological centrality index of a node of C restricted to the graph having nodes C
w(∂P)
Total weight of ∂P, i.e. sum of weights of edges in P
∥·∥
Euclidean norm for vectors, largest singular value for matrices
∥·∥A
Semi-norm associated defined by PSD matrix A: ∥x∥2
A := x⊤Ax
∥·∥F
matrix Frobenius norm
∥·∥p,q
q-norm of the vector with coordinates equal to the p−norm of rows
∥·∥I, I ⊆E
Total variation norm of signal over edges of I
A†
Moore-Penrose pseudo-inverse of matrix A
vec
vectorization operator consisting in concatenating the columns vertically
⊗
Kronecker product
1C ∈R|V|
Vector having elements equal to 1 at coordinates corresponding to vertices in C and 0 elsewhere
JC ∈R|V|×|V|
equal to 1C1⊤
C
|C|
QC ∈R|V|×|V|
equal to B†
CBC
QI ∈R|V|×|V|, I ⊆E
equal to B†
IBI
ek
elementary vectors of dimension depending on the context
σ
Subgaussianity constant / variance proxy"
REFERENCES,0.3434452871072589,Dependent on time t
REFERENCES,0.34398699891657636,"Tm(t)
set of time steps user m has been encountered before time t
ˆθm ∈Rd
estimated preference vector of user/bandit m
ϵm ∈Rd
estimation error for user/bandit m : ˆθm −θm
E ∈R|V|×d
vertical concatenation of row vectors ϵm
ηm ∈R|Tm(t)|
vector of subgaussian noise of user m
x(t) ∈Rd
context vector received at time t
m(t) ∈N
user at time t
Xm ∈R|Tm(t)|×d
data matrix of user m
X ∈Rt×d
data matrix of context vectors of all users
Am ∈Rd×d
X⊤
mXm (potentially associated to time t)
AV ∈Rd|V|×d|V|
diag(A1, · · · , Am)
K ∈R|V|×d
matrix of vertically concatenated row vectors η⊤
mXm
Table 1: Notation table."
REFERENCES,0.3445287107258938,"Proof. By optimality of ˆΘ, we have
506 1
2t X m∈V"
REFERENCES,0.34507042253521125,"Xm ˆθm −ym

2
+ α∥Θ∥E ≤1"
T,0.3456121343445287,2t X
T,0.34615384615384615,"m∈V
∥Xmθm −ym∥2 + α∥Θ∥E
(16)"
T,0.3466955579631636,"where the second line holds by definition of the observed rewards.
507"
T,0.34723726977248104,"On the one hand, given a user index m ∈V, and since by definition of the observed rewards we have
508"
T,0.3477789815817985,"we have for the least squared terms
509"
T,0.34832069339111593,"Xm ˆθm −ym

2
=
Xm ˆθm −Xmθm −ηm

2"
T,0.3488624052004334,= ∥Xmϵm −ηm∥2
T,0.3494041170097508,"= ∥Xmϵm∥2 + ∥Xmθm −ym∥2 −η⊤
mXmϵm"
T,0.34994582881906827,"where we used the fact that ym = Xmθm + ηm, which holds by definition of the observed rewards.
510"
T,0.3504875406283857,"Summing over the users, and using the definition of K, we have
511 1
2t X m∈V"
T,0.35102925243770317,"Xm ˆθm −ym

2
−1"
T,0.3515709642470206,2t X
T,0.352112676056338,"m∈V
∥Xmθm −ym∥2 = 1"
T,0.35265438786565545,2t X
T,0.3531960996749729,"m∈V
∥Xmϵm∥2 −1"
T,0.35373781148429034,"t ⟨K, E⟩
(17)"
T,0.3542795232936078,"On the other hand, we have for the estimated preference vectors
512"
T,0.35482123510292524,"∥Θ∥E =
X"
T,0.3553629469122427,"(m,n)∈E
wmn
ˆθm −ˆθn =
X"
T,0.35590465872156013,"(m,n)∈∂P
wmn
ˆθm −ˆθn
 +
X"
T,0.3564463705308776,"(m,n)∈∂Pc
wmn
ˆθm −ˆθn"
T,0.356988082340195,"=
 ˆΘ

∂P +
 ˆΘ

∂Pc,"
T,0.35752979414951247,"For the true ones, and for any C ∈P, let EC denote the edges linking the nodes of set of nodes C. It is
513"
T,0.3580715059588299,clear that ∂Pc = S
T,0.35861321776814736,"C∈P EC as a disjoint union, hence
514"
T,0.3591549295774648,"∥Θ∥E =
X"
T,0.35969664138678226,"(m,n)∈E
wmn∥θm −θn∥ =
X"
T,0.36023835319609965,"(m,n)∈∂P
wmn∥θm −θn∥+
X"
T,0.3607800650054171,"(m,n)∈∂Pc
wmn∥θm −θn∥"
T,0.36132177681473454,"= ∥Θ∥∂P +
X C∈P X"
T,0.361863488624052,"(m,n)∈EC
wmn∥θm −θn∥"
T,0.36240520043336943,= ∥Θ∥∂P
T,0.3629469122426869,"where the last equality holds due to the cluster assumption.
515"
T,0.3634886240520043,"Hence, we have
516"
T,0.3640303358613218,"∥Θ∥E −∥Θ∥E = ∥Θ∥∂P −
 ˆΘ

∂P −
 ˆΘ

∂Pc"
T,0.3645720476706392,"≤∥E∥∂P −
 ˆΘ

∂Pc,
(18)"
T,0.36511375947995667,"where the first inequality holds due to the triangle inequality, and the last one since ∥Θ∥∂Pc = 0.
517"
T,0.3656554712892741,"Combining Equations (16) to (18), we obtain the result of the statement.
518"
T,0.36619718309859156,"In the proof for the oracle inequality, we utilize projection operators on the graph signal, that we
519"
T,0.366738894907909,"define as followed:
520"
T,0.36728060671722645,"While PC
k=1 JC projects each entry of a graph signal onto the mean vector value of its respective
521"
T,0.3678223185265439,"cluster, its residual Q∂Pc can be interpreted as the projection onto the respective entries deviation
522"
T,0.36836403033586135,"from its cluster mean value.
523"
T,0.36890574214517874,"Lemma 2 (Bounding the error restricted to the boundary). The total variation of E restricted to the
524"
T,0.3694474539544962,"boundary verifies
525"
T,0.36998916576381363,∥E∥∂P ≤w(∂P)  √
MAX,0.3705308775731311,"2 max
C∈P p"
MAX,0.3710725893824485,"ιG(C)
EP

F + 2
∥E∥∂Pc"
MAX,0.37161430119176597,"min
C∈P p cG(C) "
MAX,0.3721560130010834,"
(19)"
MAX,0.37269772481040087,"Proof. The proof relies on a decomposition of the ∥E∥∂P term from Proposition 2. We have
526"
MAX,0.3732394366197183,∥E∥∂P =  X
MAX,0.37378114842903576,"C∈P
JCE + QCE ∂P"
MAX,0.3743228602383532,"=
EP + B†
∂PcB∂PcE

∂P"
MAX,0.37486457204767065,"≤
EP

∂P +
B†
∂PcB∂PcE

∂P
(20)"
MAX,0.3754062838569881,"where EP is obtained by setting the error signal on every cluster to its mean.
527"
MAX,0.37594799566630555,"For the first term on the right-hand side, let us denote by ϵC the value of any row of EP belonging to
528"
MAX,0.376489707475623,"cluster C, which is equal to the mean of errors E over that cluster. Also, we denote by (EP)∂P the
529"
MAX,0.37703141928494044,"signal obtained from EP by setting its rows corresponding to nodes that are not adjacent to any edge
530"
MAX,0.37757313109425783,"in the boundary ∂P to zeros. Also, let ∂vC denote the inner boundary of set of nodes C,i.e. nodes of
531"
MAX,0.3781148429035753,"C that connect it to its complementary. Then it holds that:
532"
MAX,0.3786565547128927,"EP

∂P =
B∂PEP

2,1
=
B∂P(EP)∂P

2,1
≤∥B∂P∥2,1
(EP)∂P

(by Proposition 1)"
MAX,0.37919826652221017,"≤∥B∂P∥2,1
(EP)∂P

F"
MAX,0.3797399783315276,"= ∥B∂P∥2,1 sX"
MAX,0.38028169014084506,"C∈P
|∂vC|∥ϵC∥2"
MAX,0.3808234019501625,"= ∥B∂P∥2,1 sX C∈P |∂vC|"
MAX,0.38136511375947996,|C| |C|∥ϵC∥2
MAX,0.3819068255687974,"≤∥B∂P∥2,1 max
C∈P p"
MAX,0.38244853737811485,"ιG(C)
sX"
MAX,0.3829902491874323,"C∈P
|C|∥ϵC∥2 =
√"
MAX,0.38353196099674974,"2w(∂P) max
C∈P p"
MAX,0.3840736728060672,"ιGC
EP

F
(21)"
MAX,0.38461538461538464,"For the second term, we have
533"
MAX,0.3851570964247021,"B†
∂PcB∂PcE

∂P =
B∂PB†
∂PcB∂PcE

2,1"
MAX,0.3856988082340195,"≤
B∂PB†
∂Pc

∞,1∥E∥∂Pc"
MAX,0.3862405200433369,"≤
B∂PB†
∂Pc

F ∥E∥∂Pc"
MAX,0.38678223185265437,"≤
(B†
∂Pc)⊤B⊤
∂P

F ∥E∥∂Pc"
MAX,0.3873239436619718,"≤
B⊤
∂P

2,1"
MAX,0.38786565547128926,"rB†
∂Pc(B†
∂Pc)⊤

∞,∞∥E∥∂Pc
(by Proposition 1) ="
MAX,0.3884073672806067,"B⊤
∂P

1,1
min
C∈P p"
MAX,0.38894907908992415,"cG(C)
∥E∥∂Pc."
MAX,0.3894907908992416,"= 2
w(∂P)"
MAX,0.39003250270855905,"min
C∈P p"
MAX,0.3905742145178765,"cG(C)
∥E∥∂Pc.
(22)"
MAX,0.39111592632719394,"The result is obtained by combining Equations (20) to (22).
534"
MAX,0.3916576381365114,"Theorem 4 (Theorem 2.1 of Hsu et al. [2012]). At time step t, let A ∈Rb×t where b ∈N∗, and let
535"
MAX,0.39219934994582883,"v ∈Rt be a random vector such that for some σ ≥0, we have
536"
MAX,0.3927410617551463,"E [exp(⟨u, v⟩)] ≤exp

∥u∥2 σ2 2"
MAX,0.39328277356446373,"
∀u ∈Rt."
MAX,0.3938244853737812,"Then for any δ ∈(0, 1), we have with a probability at least 1 −δ:
537"
MAX,0.39436619718309857,∥Av∥2 ≤σ2
MAX,0.394907908992416,"∥A∥2
F + 2
A⊤A

F r log 1"
MAX,0.39544962080173346,δ + 2∥A∥2 log 1 δ ! .
MAX,0.3959913326110509,"Lemma 3 (Empirical process bound). Let Xm ∈R|Tm|×d denotes the matrix of collected context
538"
MAX,0.39653304442036835,"vectors for task m ∈V, then, given collected context matrices {Xm}m∈V, for any δ ∈(0, 1) we
539"
MAX,0.3970747562296858,"have with probability of at least 1 −δ:
540"
MAX,0.39761646803900325,"∥K∥F ≤αδ(t) α0
t,"
MAX,0.3981581798483207,"where
541"
MAX,0.39869989165763814,αδ(t) := α0σ t
MAX,0.3992416034669556,"v
u
u
tt + 2 s X"
MAX,0.39978331527627303,"m∈V
|Tm(t)|2 log 1"
MAX,0.4003250270855905,"δ + 2 max
m∈V |Tm(t)| log 1"
MAX,0.4008667388949079,"δ ,
(23)"
MAX,0.4014084507042254,"Proof. We recall that K ∈Rt×d is the matrix obtained by stacking the row vectors η⊤
mXm vertically.
542"
MAX,0.4019501625135428,"On the one hand, we have
543"
MAX,0.40249187432286027,"∥K∥2
F =
X m∈V"
MAX,0.40303358613217766,"X⊤
mηm
2 =
X⊤
V η
2,
(24)"
MAX,0.4035752979414951,"where XV := diag(X1, · · · , X|V|) ∈Rt×d|V| .
544"
MAX,0.40411700975081255,"On the other one, for any u = (u1, · · · , ut) ∈Rt, denoting P(t) := exp
Pt
τ=1 uτητ

, we have
545"
MAX,0.40465872156013,"E [P(t)] = E [E [exp{utηt}P(t −1)|Ft−1]]
(by the law of total expectation)"
MAX,0.40520043336944744,"= E [P(t −1)E [exp(utηt)|Ft−1]]
(because {ηs}t−1
s=1 are Ft−1 measurable.)"
MAX,0.4057421451787649,"≤exp
1"
MAX,0.40628385698808234,"2σ2u2
t"
MAX,0.4068255687973998,"
E [P(t −1)]
(by the conditional subgaussianity assumption) ≤ tY"
MAX,0.40736728060671723,"s=1
exp
1"
MAX,0.4079089924160347,"2σ2u2
s"
MAX,0.4084507042253521,"
(by induction)"
MAX,0.40899241603466957,"= exp
1"
MAX,0.409534127843987,"2σ2∥u∥2

.
(25)"
MAX,0.41007583965330446,"From Equations (24) and (25), we can apply Theorem 4 to matrix XV and random vector η, which
546"
MAX,0.4106175514626219,"implies that with a probability at least 1 −δ, we have
547"
MAX,0.4111592632719393,∥XVη∥≤σ
MAX,0.41170097508125675,"v
u
u
tTr X"
MAX,0.4122426868905742,"m∈V
Am ! + 2 s X"
MAX,0.41278439869989164,"m∈V
∥Am∥2
F log 1"
MAX,0.4133261105092091,"δ + 2 max
m∈V ∥Am∥log 1 δ ,"
MAX,0.41386782231852653,where we used the equalities ∥XV∥F = P
MAX,0.414409534127844,"m∈V Tr(Am), ∥XV∥2 = max
m∈V ∥Am∥and
XVX⊤
V
2
F =
548"
MAX,0.41495124593716143,"X⊤
V XV
2
F = P"
MAX,0.4154929577464789,"m∈V ∥Am∥2
F . To arrive the the statement of the theorem, we use the fact that the
549"
MAX,0.4160346695557963,"context vectors have Euclidean norms of at most 1.
550 551"
MAX,0.41657638136511377,"Proposition 4 (Probabilistic inequality). With a probabability at least 1 −δ, we have
552 1
2tα X"
MAX,0.4171180931744312,"m∈V
∥Xmϵm∥2 + a1(G, Θ)∥E∥∂Pc ≤a2(G, Θ)
EP

F + (1 −κ)∥E∥∂P,
(26)"
MAX,0.41765980498374866,"where 0 ≤κ <
min
C∈P p cG(C)"
MAX,0.4182015167930661,"2w(∂P)
,
1
α0 < min
C∈P p"
MAX,0.41874322860238355,"cG(C) −2κw(∂P) and
553"
MAX,0.419284940411701,"a1(G, Θ) = 1 −"
MAX,0.4198266522210184,"1
α0 + 2κw(∂P)"
MAX,0.42036836403033584,"min
C∈P p"
MAX,0.4209100758396533,"cG(C)
(27)"
MAX,0.42145178764897073,"a2(G, Θ) = 1"
MAX,0.4219934994582882,"α0
+
√"
MAX,0.4225352112676056,"2κw(∂P) max
C∈P p"
MAX,0.4230769230769231,"ιG(C).
(28)"
MAX,0.4236186348862405,"Proof. The proof is a combination of the results of Lemmas 1 to 3. We have
554"
MAX,0.42416034669555797,"1
2tαδ X"
MAX,0.4247020585048754,"m∈V
∥Xmϵm∥2 + ∥E∥∂Pc"
MAX,0.42524377031419286,"≤
1
tαδ
⟨K, E⟩+ ∥E∥∂P
(by Lemma 1) ≤1"
MAX,0.4257854821235103,"α0
∥E∥F + κ∥E∥∂P + (1 −κ)∥E∥∂P
(by Lemma 3) ≤"
MAX,0.42632719393282775,"EP

F
α0
+
∥E∥∂Pc"
MAX,0.4268689057421452,"α0 min
C∈P p"
MAX,0.42741061755146265,"cG(C)
+ κw(∂P)  √"
MAX,0.4279523293607801,"2 max
C∈P p"
MAX,0.4284940411700975,"ιG(C)
EP

F + 2
∥E∥∂Pc"
MAX,0.42903575297941493,"min
C∈P p cG(C) "
MAX,0.4295774647887324,"+ (1 −κ)∥E∥∂P,"
MAX,0.4301191765980498,"where the last line is an application of Lemma 2. Grouping the terms by the type of norm applied to
555"
MAX,0.43066088840736727,"E finishes the proof.
556"
MAX,0.4312026002166847,"Theorem 1 (Oracle inequality). Assume that the RE assumption holds for the empirical multi-
557"
MAX,0.43174431202600216,"task Gram matrix with constants κ ∈

0,
1
2w(∂P) min
C∈P p"
MAX,0.4322860238353196,"cG(C)

and ϕ > 0.
Suppose that
558"
MAX,0.43282773564463706,"maxm∈V |Tm(t)| ≤bt for some b > 0. Then, with a probability at least 1 −δ(t), we have
559"
MAX,0.4333694474539545,"Θ −ˆΘ(t)

F ≤2
σ
ϕ2√"
MAX,0.43391115926327195,"tf(G, Θ)"
MAX,0.4344528710725894,"v
u
u
t1 + 2b s"
MAX,0.43499458288190684,"|V| log
1
δ(t) + 2b log
1
δ(t),"
MAX,0.4355362946912243,"where
560"
MAX,0.43607800650054174,"f(G, Θ) := α0

a2(G, Θ) +
√"
MAX,0.43661971830985913,"21≤1(κ)w(∂P)

"
MAX,0.4371614301191766,"a2(G, Θ) +
√"
MAX,0.437703141928494,21≤1(κ)w(∂P)
MAX,0.43824485373781147,"a1(G, Θ) min
C∈P p"
MAX,0.4387865655471289,"cG(C)
+ 1  ."
MAX,0.43932827735644636,"Proof. Using the previously established results, we obtain
561 1
2t X"
MAX,0.4398699891657638,"m∈V
∥Xmϵm∥2 + α∥E∥∂Pc"
MAX,0.44041170097508126,"≤αδa2(Θ, G)∥EP∥F + αδ(1 −κ)+∥E∥∂P
(by Proposition 4)"
MAX,0.4409534127843987,"=αδa2(Θ, G)∥EP∥F + αδ(1 −κ)+B∂PB†
∂PB∂PE

2,1
(by properties of the pseudo-inverse)"
MAX,0.44149512459371615,"≤αδa2(Θ, G)∥EP∥F + αδ∥B∂P∥2,11≤1(κ)(1 −κ)+B†
∂PB∂PE

(by Proposition 1)"
MAX,0.4420368364030336,"≤αδ(a2(Θ, G) + 1≤1(κ)
√"
MAX,0.44257854821235104,"2w(∂P))∥E∥RE
(by definition of the ∥∥RE norm)"
MAX,0.4431202600216685,"≤αa2(Θ, G) + 1≤1(κ)
√"
MAX,0.44366197183098594,"2w(∂P)
ϕ
√ t s X"
MAX,0.4442036836403034,"m∈V
∥ϵm∥2
Am
(using the RE assumption)"
MAX,0.44474539544962083,"≤
βα2
δ(a2(Θ, G) + 1≤1(κ)∥B∂P∥2,1)2"
MAX,0.4452871072589382,"2ϕ2
+
1
2βt X"
MAX,0.44582881906825567,"m∈V
∥Xmϵm∥2,
(29)"
MAX,0.4463705308775731,"where the last inequality holds for any β > 0, and is a consequence of the property that uv ≤u2 + v2 2
562"
MAX,0.44691224268689056,"for any u, v ∈R.
563"
MAX,0.447453954496208,"As a result, we can bound the norm of Q∂PcE as follows:
564"
MAX,0.44799566630552545,"∥Q∂PcE∥F =
B†
∂PcB∂PcE

F"
MAX,0.4485373781148429,"≤
rL†
∂Pc

∞,∞∥E∥∂Pc"
MAX,0.44907908992416035,"≤
2αδ(a2(Θ, G) + 1≤1(κ)∥B∂P∥2,1)2"
MAX,0.4496208017334778,"ϕ2a1(Θ, G) min
C∈P p"
MAX,0.45016251354279524,"cG(C)
(Equation (29) with β = 1).
(30)"
MAX,0.4507042253521127,"We can also bound the norm of EP as follows:
565"
MAX,0.45124593716143013,"EP
2
F ≤
1
tϕ2
X"
MAX,0.4517876489707476,"m∈V
∥Xmϵm∥2
(by RE assumption on empirical multi-task Gram matrix)"
MAX,0.452329360780065,"≤
4α2
δ(a2(Θ, G) + 1≤1(κ)∥B∂P∥2,1)2"
MAX,0.4528710725893825,"ϕ4
(by Equation (29) with β = 2).
(31)"
MAX,0.45341278439869986,"The result is then obtained by combining Equations (30) and (31) along with using the fact that
566"
MAX,0.4539544962080173,"E = EP + Q∂PcE and the expressions of a1(Θ, G) and a2(Θ, G), and bounding αδ(t) as follows:
567"
MAX,0.45449620801733476,αδ(t)2
MAX,0.4550379198266522,"α2
0
= σ2 t2  X"
MAX,0.45557963163596965,"m∈V
∥Xm∥2
F + 2 s X"
MAX,0.4561213434452871,"m∈V
∥XmX⊤
m∥2
F log 1"
MAX,0.45666305525460454,"δ + 2 max
m∈V ∥Xm∥2 log 1 δ   ≤σ2 t2 "
MAX,0.457204767063922,t + 2 s X
MAX,0.45774647887323944,"m∈V
|Tm(t)|2 log 1"
MAX,0.4582881906825569,"δ + 2 max
m∈V |Tm(t)| log 1 δ   ≤σ2 t2 "
MAX,0.45882990249187433,t + 2t r log 1
MAX,0.4593716143011918,δ + 2t log 1 δ ! ≤2σ2 t  1 + r log 1 δ !2 568
MAX,0.4599133261105092,"B.3
Inheriting the RE condition from the true to the empirical data Gram matrix
569"
MAX,0.46045503791982667,"B.3.1
From the adapted to the empirical multi-task Gram matrix
570"
MAX,0.4609967497291441,"Lemma 4 (Bounding a quadratic form using projections). Let M1, · · · , Mp ∈Rd×d be symmetric
571"
MAX,0.46153846153846156,"matrices, and let J := 1"
MAX,0.46208017334777896,"p11⊤, and Q = I −J. Then, for any Z ∈Rp×d with rows {zi}p
i=1, we have:
572  p
X"
MAX,0.4626218851570964,"i=1
z⊤
i Mizi ≤1 p  p
X"
MAX,0.46316359696641385,"i=1
Mi"
MAX,0.4637053087757313,"∥Z∥2
J + 2"
MAX,0.46424702058504874,"v
u
u
t"
P,0.4647887323943662,"1
p p
X"
P,0.46533044420368364,"i=1
M2
i"
P,0.4658721560130011,"∥Z∥Q∥Z∥J + max
1≤i≤p ∥Mi∥∥Z∥2
Q"
P,0.46641386782231853,"Proof. We have
573  p
X"
P,0.466955579631636,"i=1
z⊤
i Mizi =  p
X"
P,0.4674972914409534,"i=1
¯z⊤Mi¯z + 2 p
X"
P,0.46803900325027087,"i=1
(zi −¯z)⊤Mi¯z + p
X"
P,0.4685807150595883,"i=1
(zi −¯z)⊤Mi(zi −¯z)  ≤"
P,0.46912242686890576,"¯z⊤
p
X"
P,0.4696641386782232,"i=1
Mi¯z + 2  p
X"
P,0.47020585048754066,"i=1
e⊤
i QZMi¯z +  p
X"
P,0.47074756229685805,"i=1
e⊤
i QZMiZ⊤Qei (32)"
P,0.4712892741061755,"where we used the fact that zi −¯z = Z⊤ei −Z⊤Jei = Z⊤Qei.
574"
P,0.47183098591549294,"Let us now examine every term on the right-hand side of Equation (32). For the first term, we have
575
¯z⊤
p
X"
P,0.4723726977248104,"i=1
Mi¯z ≤  p
X"
P,0.47291440953412783,"i=1
Mi"
P,0.4734561213434453,∥¯z∥2 =
P,0.4739978331527627,"1
p p
X"
P,0.4745395449620802,"i=1
Mi"
P,0.4750812567713976,"∥Z∥2
J.
(33)"
P,0.47562296858071507,"For the second term, we have
576 p
X"
P,0.4761646803900325,"i=1
e⊤
i QZMi¯z ≤  p
X"
P,0.47670639219934996,"i=1
MiZ⊤Qei ∥¯z∥ =  p
X"
P,0.4772481040086674,"i=1
(e⊤
i ⊗Mi) vec(Z⊤Q) ∥¯z∥ ≤  p
X"
P,0.47778981581798485,"i=1
(e⊤
i ⊗Mi) "
P,0.4783315276273023,"vec(Z⊤Q)
∥¯z∥ =  p
X"
P,0.4788732394366197,"i=1
(e⊤
i ⊗Mi)"
P,0.47941495124593714,∥QZ∥F ∥¯z∥ =
P,0.4799566630552546,"v
u
u
t ( p
X"
P,0.48049837486457203,"i=1
(e⊤
i ⊗Mi))⊤
p
X"
P,0.4810400866738895,"i=1
(e⊤
i ⊗Mi)"
P,0.4815817984832069,∥QZ∥F ∥¯z∥ =
P,0.48212351029252437,"v
u
u
u
t  p
X i=1 p
X"
P,0.4826652221018418,"j=1
(e⊤
i ⊗Mi))(ej ⊗Mj)"
P,0.48320693391115926,∥QZ∥F ∥¯z∥ =
P,0.4837486457204767,"v
u
u
u
t  p
X i=1 p
X"
P,0.48429035752979416,"j=1
(e⊤
i ej ⊗MiMj)"
P,0.4848320693391116,∥QZ∥F ∥¯z∥ =
P,0.48537378114842905,"v
u
u
t  p
X"
P,0.4859154929577465,"i=1
M2
i"
P,0.48645720476706394,"∥QZ∥F ∥¯z∥.
(34)"
P,0.4869989165763814,"Finally, for the last term, we have
577 p
X"
P,0.4875406283856988,"i=1
e⊤
i QZMiZ⊤Qei ≤ p
X"
P,0.48808234019501623,"i=1
∥Mi∥
Z⊤Qei
2"
P,0.4886240520043337,"≤max
1≤i≤p ∥Mi∥ p
X i=1"
P,0.4891657638136511,"Z⊤Qei
2"
P,0.48970747562296857,"= max
1≤i≤p ∥Mi∥∥QZ∥2
F .
(35)"
P,0.490249187432286,"Combining Equations (33) to (35) yields the result.
578"
P,0.49079089924160346,"We also define an operator norm that is induced by the ∥∥RE introduced in Definition 2.
579"
P,0.4913326110509209,"Definition 3 ((RE,S)-induced operator norm). Let {Mm}m∈V ⊆Rd×d be symmetric matrices
580"
P,0.49187432286023836,"associated to the graph nodes V, and let MV := diag
 
M1, · · · , M|V|

∈Rd|V|×d|V|. For any
581"
P,0.4924160346695558,"cluster C ∈P, let the cluster mean and mean of squares associated to those matrices be given by
582"
P,0.49295774647887325,MC := 1 |C| X
P,0.4934994582881907,"m∈C
Mm,
M2C := 1 |C| X"
P,0.49404117009750814,"m∈C
M2
m."
P,0.4945828819068256,"The RE-induced operator norm of MV is defined as
583"
P,0.49512459371614304,"∥M∥RE,S := max
C∈P
MC
 ∨
r"
P,0.4956663055254605,"min
C∈P cG(C)−1 max
C∈P"
P,0.4962080173347779,"M2C
 ∨min
C∈P cG(C)−1 max
m∈V ∥Mm∥.
(36)"
P,0.4967497291440953,"B.3.2
Linking the adapted to the empirical Gram
584"
P,0.49729144095341277,"We first start by establishing that given the closeness of two PSD matrices in a certain sense, the RE
585"
P,0.4978331527627302,"condition can be transferred between them.
586"
P,0.49837486457204766,"Proposition 5 (Restricted spectral norm). Let Z ∈R|V|×d verifying
587"
P,0.4989165763813651,"a1(G, Θ)∥Z∥∂Pc ≤a2(G, Θ)
ZP

F + (1 −κ)+∥Z∥∂P"
P,0.49945828819068255,"Let {Mm}m∈V ⊆Rd×d be symmetric matrices associated to the graph nodes V, and let MV :=
588"
P,0.5,"diag(M1, · · · , M|V|) ∈Rd|V|×d|V|. Then we have:
589  X"
P,0.5005417118093174,"m∈V
z⊤
mMmzm"
P,0.5010834236186349,"≤∥M∥2
RE,S "
P,0.5016251354279523,"1 +
a2(G, Θ) + (1 −κ)+∥B∂P∥2,1"
P,0.5021668472372698,"a1(G, Θ) !2"
P,0.5027085590465872,"∥Z∥2
RE.
(37)"
P,0.5032502708559047,"Proof. For any cluster C, we denote by BC the incidence matrix obtained by setting the rows of B
590"
P,0.5037919826652221,"outside the edges linking nodes in C to null vectors. The latter’s nullspace is the span of the vector 1C
591"
P,0.5043336944745396,"having coordinates 1 at nodes in C and zeros elsewhere. Hence, the projector onto the orthogonal of
592"
P,0.504875406283857,"1C is QC := B†
CBC.
593"
P,0.5054171180931745,"On the one hand, for any signal Z ∈R|V|×d we have
594"
P,0.5059588299024919,"∥Z∥∂Pc =
X"
P,0.5065005417118094,"C∈P
∥BCZ∥2,1 ≥
X C∈P"
P,0.5070422535211268,"B†
CBCZ

F
rL†
C

∞,∞"
P,0.5075839653304443,"≥min
C∈P p"
P,0.5081256771397616,"cG(C)
X"
P,0.508667388949079,"C∈P
∥Z∥QC"
P,0.5092091007583965,"Hence, by the proposition’s assumptions, Z verifies
595"
P,0.5097508125677139,"min
C∈P p"
P,0.5102925243770314,"cG(C)a1(G, Θ)
X"
P,0.5108342361863488,"C∈P
∥Z∥QC ≤(a2(G, Θ)
ZP

F + (1 −κ)∥Z∥∂P)"
P,0.5113759479956663,"≤a2(G, Θ)
ZP

F + (1 −κ)+∥B∂P∥2,1
B†
∂PB∂PZ"
P,0.5119176598049837,"≤(a2(G, Θ) + (1 −κ)+∥B∥2,1)∥Z∥RE"
P,0.5124593716143012,"From Lemma 4, we have
596  X"
P,0.5130010834236186,"m∈V
z⊤
mMmzm  ≤
X C∈P  X"
P,0.5135427952329361,"m∈C
z⊤
mMmzm  ≤
X C∈P"
P,0.5140845070422535,"MC
∥Z∥2
JC + 2
X C∈P"
P,0.514626218851571,"r M2C
∥Z∥QC∥Z∥JC +
X"
P,0.5151679306608884,"C∈P
max
m∈C ∥Mm∥∥Z∥2
QC,
(38)"
P,0.5157096424702059,"where we used Equation (9).
597"
P,0.5162513542795233,"This allows us to bound every term in Equation (38). For the second term on the right-hand side, we
598"
P,0.5167930660888408,"have
599 X C∈P"
P,0.5173347778981582,"rM2C
∥Z∥QC∥Z∥JC"
P,0.5178764897074756,"≤max
C∈P"
P,0.5184182015167931,"rM2C

ZP

F sX"
P,0.5189599133261105,"C∈P
∥Z∥2
QC"
P,0.519501625135428,"≤
min
C∈P cG(C)−1 2"
P,0.5200433369447454,"a1(G, Θ)
max
C∈P"
P,0.5205850487540629,"rM2C
(a2(G, Θ) + (1 −κ)+∥B∥2,1)∥Z∥2
RE
(39)"
P,0.5211267605633803,"As for the third term, we have
600 X"
P,0.5216684723726978,"C∈P
max
m∈C ∥Mm∥∥Z∥2
QC ≤max
m∈V ∥Mm∥ X"
P,0.5222101841820151,"C∈P
∥Z∥QC !2"
P,0.5227518959913326,"≤max
m∈V ∥Mm∥
min
C∈P cG(C)−1"
P,0.52329360780065,"a1(G, Θ)2 (a2(G, Θ) + (1 −κ)+∥B∥2,1)2∥Z∥2
RE (40)"
P,0.5238353196099675,"Consequently, denoting v =
a2(G, Θ) + (1 −κ)+∥B∥2,1"
P,0.5243770314192849,"a1(G, Θ)
, and combining Equations (38) to (40),
601"
P,0.5249187432286024,"we obtain
602 X"
P,0.5254604550379198,"m∈V
z⊤
mMmzm "
P,0.5260021668472372,"max
C∈P
MC
 + 2v max
C∈P"
P,0.5265438786565547,"rM2C
 + v2 max
i∈V ∥Mi∥ !"
P,0.5270855904658721,"∥Z∥2
RE"
P,0.5276273022751896,"≤

max
C∈P
MC
) ∨
r"
P,0.528169014084507,"min
C∈P cG(C)−1 max
C∈P"
P,0.5287107258938245,"M2C
 ∨min
C∈P cG(C)−1 max
i∈V ∥Mi∥

(1 + v)2∥Z∥2
RE,"
P,0.5292524377031419,"which finishes the proof.
603"
P,0.5297941495124594,"Proposition 6 (Inheritance of a RE condition from a close matrix). Assume that the matrix VV
604"
P,0.5303358613217768,"verifies the RE condition with constant ϕ > 0, and that

AV t −VV"
P,0.5308775731310943,"op,RE
≤γϕ2 for some
605"
P,0.5314192849404117,"γ ∈

0,

1 + a2(G,Θ)+(1−κ)+√"
P,0.5319609967497292,"2w(∂P)
a1(G,Θ)
−2
. Then AV"
P,0.5325027085590466,"t
verifies the RE condition with constant
606"
P,0.5330444203683641,ˆϕ = ϕ
P,0.5335861321776815,"v
u
u
t1 −γ "
P,0.5341278439869989,"1 + a2(G, Θ) + (1 −κ)+√"
P,0.5346695557963164,"2w(∂P)
a1(G, Θ) !2 (41)"
P,0.5352112676056338,"Proof. From Proposition 4, we know that
607 1"
P,0.5357529794149513,"t ϵ⊤
V AVϵV = 1"
P,0.5362946912242686,"|V|ϵ⊤
V VVϵV + ϵ⊤
V ∆VϵV ≥1"
P,0.5368364030335862,"|V|ϵ⊤
V VVϵV −
ϵ⊤
V ∆VϵV ≥ "
P,0.5373781148429035,"ϕ2 −max
m∈V ∥∆V∥op,RE "
P,0.537919826652221,"1 +
a2(G, Θ) + (1 −κ)+∥B∂P∥2,1"
P,0.5384615384615384,"a1(G, Θ) !2"
P,0.5390032502708559,"∥E∥2
RE ≥ "
P,0.5395449620801733,ϕ2 −γϕ2
P,0.5400866738894908,"1 +
a2(G, Θ) + (1 −κ)+∥B∂P∥2,1"
P,0.5406283856988082,"a1(G, Θ) !2"
P,0.5411700975081257,"∥E∥2
RE"
P,0.5417118093174431,"where the third inequality is an applicaiton of Proposition 5.
608"
P,0.5422535211267606,"Theorem 5 (Matrix Freedman Inequality, Tropp [2011]). Consider a matrix martingale {M(t)}t≥1
609"
P,0.542795232936078,"with dimension d1 × d2. Let {N(t)}t≥1 be the associated difference sequence. Assume that for some
610"
P,0.5433369447453954,"A > 0, we have ∥N(t)∥≤A
∀t ≥1 almost surely. Define for any t ≥1:
611"
P,0.5438786565547129,"Wcol(t) := t
X"
P,0.5444203683640303,"τ=1
E

N(τ)N(τ)⊤|Fτ−1
"
P,0.5449620801733478,"Wrow(t) := t
X"
P,0.5455037919826652,"τ=1
E

N(τ)⊤N(τ)|Fτ−1

."
P,0.5460455037919827,"Then, for any u, v > 0,
612"
P,0.5465872156013001,"P [∃t ≥1; ∥M(t)∥≥u and ∥Wcol∥(t) ∨∥Wrow(t)∥≤v] ≤(d1 + d2) exp

−
3u2"
P,0.5471289274106176,6v + 2Au 
P,0.547670639219935,"Corollary 1. Let {N(τ)}t
τ=1 by a sequence of matrices of dimension d1 × d2, adapted to filtration
613"
P,0.5482123510292525,"{Fτ}t
τ=1. Let {ti}N
i=1 an increasing sequence with elements in [t] for some N ≤t. Consider the
614"
P,0.5487540628385699,"sequence {M(n)}N
τ=1 of random matrices defined by
615"
P,0.5492957746478874,"M(n) = n
X"
P,0.5498374864572048,"i=1
N(ti) −E [N(ti)|Fti−1]
(42)"
P,0.5503791982665223,"Then {M(n)}N
n=1 is a martingale adapted to the filtration {Ftn}N
n=1.
616"
P,0.5509209100758397,"Moreover,if ∥N(τ)∥≤b
∀τ ∈[t] for some b > 0, then we have
617"
P,0.551462621885157,"P [∥M(N)∥≥u] ≤(d1 + d2) exp

−
3u2"
P,0.5520043336944745,"6Nb2 + 2
√"
BU,0.5525460455037919,2bu
BU,0.5530877573131094,"
.
(43)"
BU,0.5536294691224268,"Proof. We denote E [·|Fs] as Es [·] for any s ∈N. Also, let C(s) := Es−1 [N(s)], which is
618"
BU,0.5541711809317443,"Fs−1-measurable by construction. We have for any n ∈[N],
619"
BU,0.5547128927410617,"Etn−1 [C(tn)] = Etn−1 [Etn−1 [N(tn)]] = Etn−1 [N(tn)]
(44)
=⇒Etn−1 [N(tn) −C(tn)] = 0
(45)"
BU,0.5552546045503792,"where the first equality is due to the tower rule since Ftn−1 ⊂Ftn−1. Also, we have for any τ ≥1
620"
BU,0.5557963163596966,"∥N(τ) −C(τ)∥2 =
(N(τ) −C(τ))2
(46)"
BU,0.5563380281690141,"≤Tr
 
(N(τ) −C(τ))2
(47)"
BU,0.5568797399783315,"= Tr
 
(N(τ) −C(τ))2
(48)"
BU,0.557421451787649,"= ∥N(τ)∥2
F −2 Tr(C(τ)N(τ)) + Tr
 
C(τ)2
(49)"
BU,0.5579631635969664,"≤∥N(τ)∥2
F + Tr
 
C(τ)2
≤2b2
(50)"
BU,0.5585048754062839,"Hence N(τ) −C(τ) is integrable for any τ ≥1. This shows that M(n) is a sequence of partial sums
621"
BU,0.5590465872156013,"of matrix martingale differences, hence it is a matrix martingale.
622"
BU,0.5595882990249187,"The second part of the corollary statement is a consequence of Theorem 5. The boundedness of
623"
BU,0.5601300108342362,"the sequence of martingale differences has already been established above. To verify the second
624"
BU,0.5606717226435536,"requirement of the theorem, let us compute bounds on the norms of Wcol and Wrow from Theorem 5.
625"
BU,0.5612134344528711,"Notice that the two matrices are equal since the difference sequence matrices N(ts) are symmetric.
626"
BU,0.5617551462621885,"Hence, for any n ∈[N], we have
627"
BU,0.562296858071506,"∥Wcol(N)∥∨∥Wrow(N)∥≤Tr(Wcol(N)) ∨Tr(Wrow(N))
(51) = Tr N
X"
BU,0.5628385698808234,"n=1
Etn−1

(N(tn) −C(tn))2
! (52) = N
X"
BU,0.5633802816901409,"n=1
Etn−1
h
∥N(tn)∥2
F
i
−Etn−1 [2 Tr(C(tn)N(tn))] + Tr
 
C(tn)2 (53) = N
X"
BU,0.5639219934994583,"n=1
Etn−1
h
∥N(tn)∥2
F
i
−Tr
 
C(tn)2
(54) ≤ N
X"
BU,0.5644637053087758,"n=1
Etn−1
h
∥N(tn)∥2
F
i
≤Nb2.
(55)"
BU,0.5650054171180932,"By Theorem 5, we have for any u > 0
628"
D EXP,0.5655471289274107,"2d exp

−
3u2"
D EXP,0.566088840736728,"6Nb2 + 2
√"
BU,0.5666305525460456,2bu
BU,0.5671722643553629,"
≥P

∃n ≥1; ∥M(n)∥≥u and ∥Wcol(n)∥≤Nb2
(56)"
BU,0.5677139761646804,"≥P

∥M(N)∥≥u and ∥Wcol(N)∥≤Nb2
(57)"
BU,0.5682556879739978,"= P [∥M(N)∥≥u]
(58)"
BU,0.5687973997833152,"where the last line holds because we showed that the inequality ∥Wcol(N)∥≤Nb2 holds almost
629"
BU,0.5693391115926327,"surely.
630"
BU,0.5698808234019501,"Proposition 7 (Concentration of the empirical multi-task Gram matrix around the adapted one). Let
631"
BU,0.5704225352112676,"t ≥1, b > 0. Then we have:
632 P"
BU,0.570964247020585,"""
AV(t) t
−VV"
BU,0.5715059588299025,"op,RE
> γ
 max
m∈V |Tm(t)| ≤bt #"
BU,0.5720476706392199,"≤d(2|P|e−A1t+(|V|+|P|)e−A2t+2|V|e−A3t),"
BU,0.5725893824485374,"where
633"
BU,0.5731310942578548,"A1 :=
3γ2 min
C∈P |C|t"
BU,0.5736728060671723,"6b + 2
√ 2γ"
BU,0.5742145178764897,"A2 :=
3γ2 min
C∈P cG(C)t"
BU,0.5747562296858072,"6b + 2
√ 2γ"
BU,0.5752979414951246,"v
u
u
t"
BU,0.5758396533044421,"min
C∈P cG(C)"
BU,0.5763813651137595,"min
C∈P |C|"
BU,0.5769230769230769,"A3 :=
3γ2 min
C∈P cG(C)2t"
BU,0.5774647887323944,"6b + 2
√"
BU,0.5780065005417118,"2γ min
C∈P cG(C)"
BU,0.5785482123510293,"Proof. For γ > 0, let us define
634"
BU,0.5790899241603467,∆m := AV
BU,0.5796316359696642,"t
−VV
and GGram,γ :=
1"
BU,0.5801733477789816,"t ∥∆V∥RE,S ≤γ

,"
BU,0.580715059588299,"where ∆V is block diagonal matrix formed by {∆m}m∈V. We also define ∆C and ∆2C in the same
635"
BU,0.5812567713976164,"pattern of Definition 3. We can express the complementary of this event as the disjunction of a finite
636"
BU,0.581798483206934,"number of events as follows:
637"
BU,0.5823401950162513,"Gc
Gram,γ
(59)"
BU,0.5828819068255688,"=

max
C∈P
∆C
 ∨
r"
BU,0.5834236186348862,"min
C∈P cG(C)−1 max
C∈P"
BU,0.5839653304442037,"∆2C
 ∨min
C∈P cG(C)−1 max
m∈V ∥∆m∥> tγ

(60) =
[ C∈P"
BU,0.5845070422535211,"∆C
 > tγ
	
∪
[ C∈P"
BU,0.5850487540628385,"∆2C
 > t2γ2 min
C∈P cG(C)

∪
[ m∈V"
BU,0.585590465872156,"
∥∆m∥> tγ min
C∈P cG(C)
 (61)"
BU,0.5861321776814734,"The first and third event can be bounded by considering the sequence xx⊤(τ) adapted to the filtration
638"
BU,0.5866738894907909,"{Fτ}, verifying
xx⊤(τ)
 ≤.
639"
BU,0.5872156013001083,"Bounding the probability of the first event
Let C ∈P be a cluster. By definition, we have
640"
BU,0.5877573131094258,"|C|∆C(t) =
X m∈C X"
BU,0.5882990249187432,"τ∈Tm(t)
xx(τ) −E [xx(τ)|Fτ−1] =
X τ∈S"
BU,0.5888407367280607,"m∈C Tm(t)
xx(τ) −E [xx(τ)|Fτ−1]"
BU,0.5893824485373781,"We will apply Corollary 1 for the sequence of time indices in C, i.e. S"
BU,0.5899241603466956,"m∈V Tm(t). Hence |C|∆C is a
641"
BU,0.590465872156013,"martingale sequence, and we have
642"
BU,0.5910075839653305,"P
∆C(t)
 > γt
 max
m∈V |Tm(t)| ≤bt

≤2d exp"
BU,0.5915492957746479,−3γ2|C|2t2
P,0.5920910075839654,6 P
P,0.5926327193932828,"m∈C |Tm(t)| + 2
√"
P,0.5931744312026003,2γ|C|t !
P,0.5937161430119177,≤2d exp
P,0.594257854821235,−3γ2|C|2t2
P,0.5947995666305526,"6|C|bt + 2
√"
P,0.59534127843987,2γ|C|t !
P,0.5958829902491874,"= 2d exp
 −3γ2|C|t"
P,0.5964247020585048,"6b + 2
√ 2γ "
P,0.5969664138678223,≤2d exp 
P,0.5975081256771397,"
−3γ2 min
C∈P |C|t"
P,0.5980498374864572,"6b + 2
√ 2γ "
P,0.5985915492957746,"
(62)"
P,0.5991332611050921,"Bounding the probability of the third event
Let m ∈V be a task index. We apply Corollary 1 for
643"
P,0.5996749729144095,"the sequence of time steps in Tm(t). We have
644"
P,0.600216684723727,"∆m(t) =
X"
P,0.6007583965330444,"τ∈Tm(t)
xx(τ) −E [xx(τ)|Fτ−1]"
P,0.6013001083423619,"is a martingale sequence, hence
645"
P,0.6018418201516793,"P

∥∆m(t)∥> γ min
C∈P cG(C)t
 max
m∈V |Tm(t)| ≤bt

≤2d exp "
P,0.6023835319609967,"
−3γ2 min
C∈P cG(C)2t2"
P,0.6029252437703142,"6|Tm(t)| + 2
√"
P,0.6034669555796316,"2γ min
C∈P cG(C)t  "
P,0.6040086673889491,≤2d exp 
P,0.6045503791982665,"
−3γ2 min
C∈P cG(C)2t2"
P,0.605092091007584,"6bt + 2
√"
P,0.6056338028169014,"2γ min
C∈P cG(C)t  "
P,0.6061755146262189,= 2d exp 
P,0.6067172264355363,"
−3γ2 min
C∈P cG(C)2t"
P,0.6072589382448538,"6b + 2
√"
P,0.6078006500541712,"2γ min
C∈P cG(C) "
P,0.6083423618634887,".
(63)"
P,0.6088840736728061,"Bounding the probability of the second event
Let C ∈P be a cluster, and let us denote em the
646"
P,0.6094257854821236,"mth canonical vector of R|C|. We have
647"
P,0.609967497291441,"∆2C(t)
 = 1 |C|  X m∈C  X"
P,0.6105092091007583,"τ∈Tm(t)
xx(τ) −E [xx(τ)|Fτ−1]   2 = 1 |C|  X"
P,0.6110509209100758,"m∈C
e⊤
m ⊗  X"
P,0.6115926327193932,"τ∈Tm(t)
xx(τ) −E [xx(τ)|Fτ−1]    2 = 1 |C|  X τ∈S"
P,0.6121343445287107,"m∈C Tm(t)
e⊤
m(τ) ⊗(xx(τ) −E [xx(τ)|Fτ−1])  2 = 1 |C|  X τ∈S"
P,0.6126760563380281,"m∈C Tm(t)
e⊤
m(τ) ⊗xx(τ) −E

em(τ) ⊗xx(τ)|Fτ−1
 2 ,"
P,0.6132177681473456,"where the last equality holds since m(τ) is measurable w.r.t. Fτ−1. We will apply the Corollary 1 to
648"
P,0.613759479956663,the set of time steps S
P,0.6143011917659805,"m∈C Tm(t) and the adapted sequence e⊤
m(τ) ⊗xx(τ) of matrices in Rd×d|C|.
649"
P,0.6148429035752979,"Hence we have
650 P"
P,0.6153846153846154,"""r∆2C(t)
 > γt min
C∈P p"
P,0.6159263271939328,"cG(C)
 max
m∈V |Tm(t)| ≤bt #"
P,0.6164680390032503,≤d(1 + |C|) exp 
P,0.6170097508125677,"
−3γ2|C| min
C∈P cG(C)t2"
P,0.6175514626218852,6 P
P,0.6180931744312026,"m∈C |Tm(t)| + 2
√ 2γ
q"
P,0.6186348862405201,"|C| min
C∈P cG(C)t  "
P,0.6191765980498375,≤d(1 + |C|) exp 
P,0.6197183098591549,"
−3γ2|C| min
C∈P cG(C)t"
P,0.6202600216684724,"6|C|b + 2
√ 2γ
q"
P,0.6208017334777898,"|C| min
C∈P cG(C)  "
P,0.6213434452871073,= d(1 + |C|) exp 
P,0.6218851570964247,"



"
P,0.6224268689057422,"−3γ2 min
C∈P cG(C)t"
P,0.6229685807150596,"6b + 2
√ 2γ s"
P,0.6235102925243771,"min
C∈P cG(C) |C| "
P,0.6240520043336945,"



"
P,0.624593716143012,≤d(1 + |C|) exp 
P,0.6251354279523293,"





"
P,0.6256771397616468,"−3γ2 min
C∈P cG(C)t"
P,0.6262188515709642,"6b + 2
√ 2γ"
P,0.6267605633802817,"v
u
u
t"
P,0.6273022751895991,"min
C∈P cG(C)"
P,0.6278439869989165,"min
C∈P |C| "
P,0.628385698808234,"





 (64)"
P,0.6289274106175514,"Union bound
We conclude the result of the statement via a union bound using Equation (61).
651"
P,0.6294691224268689,"Proposition 8 (Concentration of the empirical multi-task Gram matrix around the adapted one,
652"
P,0.6300108342361863,"simplified). propEmpCovConcentrationSimplified Let t ≥1, b > 0. Assume that maxm∈V |Tm(t)| ≤
653"
P,0.6305525460455038,"bt. Then we have:
654 P"
P,0.6310942578548212,"""
AV t −VV"
P,0.6316359696641387,"op,RE
> γ #"
P,0.6321776814734561,"≤6d|V| exp
−3γ2(minC∈P(˜cG(C) ∧˜cG(C)2)t"
P,0.6327193932827736,"6b + 2
√ 2γ 
,"
P,0.633261105092091,"where ˜cG(C) := cG(C) ∧|C|
∀C ∈P.
655"
P,0.6338028169014085,"Proof. The proof will rely on simple calculus inequalities. Hence, let u = minC∈P cG(C), v =
656"
P,0.6343445287107259,"minC∈P |C|, f = 3γ2, g = 6b, h = 2
√"
P,0.6348862405200434,"2γ, which are all positive. Then, we have
657"
P,0.6354279523293608,"A1 =
fu
f + g ≥(u ∧v)f"
P,0.6359696641386782,"f + g
≥(u ∧v)
(1 ∧u ∧v)f
f + g(1 ∧u ∧v)"
P,0.6365113759479957,"A2 =
fv
f + g v"
P,0.6370530877573131,"u
≥(v ∧u)f"
P,0.6375947995666306,f + g v∧u
P,0.638136511375948,"u
≥(v ∧u)f"
P,0.6386782231852655,"f + g
≥(u ∧v)
(1 ∧u ∧v)f
f + (1 ∧u ∧v)g"
P,0.6392199349945829,"A3 =
fv2"
P,0.6397616468039004,"f + gv ≥
(v ∧u)2"
P,0.6403033586132177,"f + (v ∧u)g ≥(u ∧v)
(1 ∧u ∧v)f
f + (1 ∧u ∧v)g
where we used the fact that functions of the form x 7→
x
β1x+β2 for positive β1, β2 are increasing on
658"
P,0.6408450704225352,"R+.
659"
P,0.6413867822318526,"As a final step, we use the inequality
(1 ∧x)f
f + (1 ∧x)g ≥x ∧1"
P,0.6419284940411701,"f + g taken for x = u ∧v, we apply the
660"
P,0.6424702058504875,"exp(−· t) function and we use the result of Proposition 7, we deduce the result.
661"
P,0.643011917659805,"B.3.3
From the true to the adapted Gram matrix
662"
P,0.6435536294691224,"For all of the proofs in this subsection, we follow an approach similar to that of Oh et al. [2021]. In
663"
P,0.6440953412784398,"particular, we use their Lemma 10.
664"
P,0.6446370530877573,"Theorem 6 (Lemma 10 of Oh et al. [2021]). Under Assumption 2 on the context generating distribu-
665"
P,0.6451787648970747,"tion, let t ≥1. We have for any θ ∈Rd:
666 X"
P,0.6457204767063922,"x∈A(t)
E "" xx⊤1 ("
P,0.6462621885157096,"x ∈arg max
˜x∈A(t)
⟨θ, ˜x⟩ )#"
P,0.6468039003250271,"≽
1
2νω Σ
(65)"
P,0.6473456121343445,"Proposition 9 (RE condition from the true to the adapted Gram matrix). Under Assumption 2, for
667"
P,0.647887323943662,"any t ≥1, the adapted Gram matrix VV(t) verifies the compatibility condition with constants κ and
668 ϕ
√"
P,0.6484290357529794,"2νω.
669"
P,0.6489707475622969,"Proof. For t ≥1, we have
670"
P,0.6495124593716143,"E

x(t)x(t)⊤|Ft−1

= E  X"
P,0.6500541711809318,"x∈A(t)
x(t)x(t)⊤|Ft−1 "
P,0.6505958829902492,"
(66)"
P,0.6511375947995667,"Let m ∈V. We have
671"
P,0.6516793066088841,Vm(t) = 1 t X
P,0.6522210184182016,"τ∈Tm(t)
E

x(τ)x(τ)⊤|Fτ−1
 = 1 t X"
P,0.652762730227519,"τ∈Tm(t)
E

E

x(τ)x(τ)⊤|θm(τ −1), Fτ−1

|Fτ−1

(law of total expectation) = 1 t X"
P,0.6533044420368364,"τ∈Tm(t)
E

x(τ)x(τ)⊤|θm(τ −1)

(x(τ) is fully determined by θm(τ −1)) = 1 t X"
P,0.6538461538461539,"τ∈Tm(t)
E  X"
P,0.6543878656554712,"x∈A(τ)
xx⊤1 ("
P,0.6549295774647887,"x ∈arg max
˜x∈A(t)
⟨θ, ˜x⟩ )"
P,0.6554712892741061,|θm(τ −1)  
P,0.6560130010834236,"≽
1
2νω Σ
(by Theorem 6).
(67)"
P,0.656554712892741,"Now, let Z ∈S, where S is defined with constant κ of Assumption 4. Then
672 X"
P,0.6570964247020585,"m∈V
∥z∥Vm(t) ≥
1
2νω X"
P,0.6576381365113759,"m∈V
∥zm∥Σ
by Equation (67) ≥ϕ2"
P,0.6581798483206934,"2νω ∥Z∥2
RE
(by Assumption 4),"
P,0.6587215601300108,"which finishes the proof.
673"
P,0.6592632719393283,"Theorem 2 (RE condition holding for the empirical multi-task Gram matrix). Under assumptions 2
674"
P,0.6598049837486457,"and 4, let t ≥1, and let κ, ϕ be the constants from Assumption 4. Assume that maxm∈V |Tm(t)| ≤bt.
675"
P,0.6603466955579632,"Then, for any γ ∈

0,

1 + a2(G,Θ)+(1−κ)+√"
P,0.6608884073672806,"2w(∂P)
a1(G,Θ)
−2
, the empirical multi-task Gram matrix
676"
P,0.661430119176598,"verifies the RE condition with constants κ and ˆϕ, with
677"
P,0.6619718309859155,ˆϕ = ˜ϕ
P,0.6625135427952329,"v
u
u
t1 −γ "
P,0.6630552546045504,"1 + a2(G, Θ) + (1 −κ)+√"
P,0.6635969664138678,"2w(∂P)
a1(G, Θ) !2 ,
(6)"
P,0.6641386782231853,with a probability at least equal to 1 −6d|V| exp
P,0.6646803900325027,−3γ2 ˜ϕ4(minC∈P(˜cG(C) ∧˜cG(C)2)t
P,0.6652221018418202,"6b + 2
√"
P,0.6657638136511376,2γ ˜ϕ2 !
P,0.6663055254604551,", where
678"
P,0.6668472372697725,"˜ϕ :=
ϕ
√"
P,0.66738894907909,"2νω and ˜cG(C) := cG(C) ∧|C|
∀C ∈P.
679"
P,0.6679306608884074,"Proof. For the sake of readability, let ˜ϕ =
ϕ
√"
P,0.6684723726977249,"2νω the compatibility constant of the adapted Gram
680"
P,0.6690140845070423,"matrix, according to Proposition 9. Then:
681"
P,0.6695557963163596,1 −6d|V| exp
P,0.6700975081256771,−3γ2 ˜ϕ4(minC∈P(˜cG(C) ∧˜cG(C)2)t
P,0.6706392199349945,"6b + 2
√"
P,0.671180931744312,2γ ˜ϕ2 ! (68) ≤P
P,0.6717226435536294,"""
AV t −VV"
P,0.6722643553629469,"op,RE
≤γ ˜ϕ2
#"
P,0.6728060671722643,"(by Proposition 8)
(69)"
P,0.6733477789815818,"≤P
AV"
P,0.6738894907908992,"t
satisfies the RE condition with constant κ and ˆϕ

(by Proposition 6),
(70)"
P,0.6744312026002167,where ˆϕ = ˜ϕ r
P,0.6749729144095341,"1 −γ

1 + a2(G,Θ)+(1−κ)+√"
P,0.6755146262188516,"2w(∂P)
a1(G,Θ)
2
.
682"
P,0.676056338028169,"B.4
Regret bound
683"
P,0.6765980498374865,"Lemma 5 (Concentration of the fraction of observations per task). lemma Assume that |V| ≥2. Then
684"
P,0.6771397616468039,"for δ ∈(0, 1), we have with a probability at least 1 −δ:
685"
P,0.6776814734561214,"max
m∈V
|Tm(t)| t
≤1"
P,0.6782231852654388,|V| + 2 s
P,0.6787648970747562,"1
t|V| log |V| δ + 4"
P,0.6793066088840737,3t log |V|
P,0.6798483206933911,"δ .
(71)"
P,0.6803900325027086,"Proof. We have |Tm(t)| := Pt
τ=1[m(τ) = m], where ∀t, ∀m ∈V, P [m(t) = m] =
1
|V|, meaning
that the binary variable [m(t) = m] follows a Bernoulli distribution B( 1"
P,0.680931744312026,"V ). Then, the random variable
Xt := [m(t) = m] −
1
|V| has mean 0, variance
1
|V|(1 −
1
|V|), and verifies |Xt| ≤1 −
1
|V| since
|V| ≥2. As a result, via the Bernstein inequality, we have for any m ∈V, and for any w ≥0,"
P,0.6814734561213435,"P
|Tm(t)| t
≥1"
P,0.6820151679306609,"|V| + w

≤exp  −
tw2"
P,0.6825568797399784,"2(1 −
1
|V|)( 1"
P,0.6830985915492958,"|V| + w 3 ) ! ≤exp  −
tw2 2( 1"
P,0.6836403033586133,|V| + w 3 ) !
P,0.6841820151679306,"For the right-hand side to hold with a probability at most δ ∈(0, 1), it is sufficient to have
686 t
w2 2( 1"
P,0.6847237269772481,|V| + w
P,0.6852654387865655,3 ) ≥log 1 δ ⇐= w2
P,0.685807150595883,"2 ≥
2 1"
P,0.6863488624052004,|V| log 1
P,0.6868905742145178,"δ
t
and w2"
P,0.6874322860238353,"2 ≥2w log 1 δ
3t"
P,0.6879739978331527,⇐= w = 2 s
P,0.6885157096424702,"1
|V| log 1"
P,0.6890574214517876,"δ
t
+ 4 log 1 δ
3t"
P,0.6895991332611051,"Hence, and via a union bound, we get
687 P"
P,0.6901408450704225,"""
|Tm(t)| t
≥1"
P,0.69068255687974,|V| + 2 s
P,0.6912242686890574,"1
|V| log 1 δ + 4"
P,0.6917659804983749,3t log 1 δ # ≤δ =⇒P 
P,0.6923076923076923,"max
m∈V
|Tm(t)| t
≥1"
P,0.6928494041170098,|V| + 2 s
P,0.6933911159263272,"1
|V| log 1"
P,0.6939328277356447,"δ
t
+ 4 log 1 δ
3t "
P,0.6944745395449621,≤|V|δ
P,0.6950162513542795,"The result is obtained by adjusting the value of δ.
688"
P,0.695557963163597,"Theorem 3 (Regret bound). Let the mean horizon per node be T =
T
|V|.
Let min
C∈P p"
P,0.6960996749729144,"cG(C)
689"
P,0.6966413867822319,"going asymptotically to infinity and maxC∈P
p"
P,0.6971830985915493,"ιG(C) going asymptotically to zero as well as
690"
P,0.6977248104008668,"maxC∈P
p"
P,0.6982665222101841,"ιG(C)w(∂P) and
w(∂P)
min
C∈P p"
P,0.6988082340195017,"cG(C) going asymptotically to zero. Under assumptions1 to 4
691"
P,0.699349945828819,"and κ < 1, the expected regret of the Network Lasso Bandit algorithm is upper bounded as follows:
692"
P,0.6998916576381365,R(|V|T) = O  
P,0.7004333694474539,"v
u
u
t
T
min
C∈P cG(C) p"
P,0.7009750812567714,"|V| +
q log
 "
P,0.7015167930660888,"T|V|

+
4qV log
 "
P,0.7020585048754063,"T|V|


+ 1"
P,0.7026002166847237,"A log(d|V|)  ,"
P,0.7031419284940412,"with A = 3γ2 minC∈P(˜cG(C) ∧˜c2
G(C))"
P,0.7036836403033586,"6 log(|V|)
√"
P,0.704225352112676,"|V| + 2
√"
P,0.7047670639219935,"2γ
.
693"
P,0.7053087757313109,"Proof. For any time step t, we will define a list of good events under which the Oracle inequality and
694"
P,0.7058504875406284,"the RE condition for the empirical multi-task Gram matrix both hold with high probability. Then, we
695"
P,0.7063921993499458,"will use those bounds to sum up over time steps until horizon T.
696"
P,0.7069339111592633,"Good events
We formalize these requirements as three families of time-depending ""good"" events.
697"
P,0.7074756229685807,"• Gpro(t) is the event that the mean of the empirical process bounded by α(t) up to a constant c,
698"
P,0.7080173347778982,"which is equivalent to saying that it converges:
699"
P,0.7085590465872156,"Gpro(t) :=
1"
P,0.7091007583965331,t ∥K∥F ≤α(t) α0
P,0.7096424702058505,"
(72)"
P,0.710184182015168,"• Gsel(t) is the event that the number of selections of all tasks is bounded by its expected value up
700"
P,0.7107258938244854,"to a small constant ρ(t)
701"
P,0.7112676056338029,"Gsel(t) :=

max
m∈V
|Tm(t)| t
≤1"
P,0.7118093174431203,|V| + ρ(t) t
P,0.7123510292524377,"
(73)"
P,0.7128927410617552,• GRE(t) is the event that the empirical multi-task Gram matrix 1
P,0.7134344528710725,"t AV(t) satisfies the RE condition.
702"
P,0.71397616468039,"GRE(t) :=
1"
P,0.7145178764897074,"t AV(t) verifies the RE condition with constants κ, ˆϕ

(74)"
P,0.7150595882990249,"Event Gpro(t) is the most straightforward to cover since our bound on the empirical process given in
703"
P,0.7156013001083423,"Lemma 3 holds with a probability of at least 1 −δ(t), thus:
704"
P,0.7161430119176598,"P [Gpro(t)c|Gsel(t)] ≤δ(t),
(75)"
P,0.7166847237269772,"where we included the time dependency on δ(t) in contrast to the previous section. This way we
705"
P,0.7172264355362947,"emphasize to adjust δ(t) after each round, to guarantee a sub linear regret bound. The probability of
706"
P,0.7177681473456121,"event Gsel(t) can be determined using Bernstein’s inequality:
707"
P,0.7183098591549296,"From Lemma 5 we can select ρ(t) = 2
q"
P,0.718851570964247,"t
|V| log
|V|
δsel(t) + 4"
LOG,0.7193932827735645,"3 log
|V|
δsel(t) as well as P [Gsel(t)c] ≤δsel(t).
708"
LOG,0.7199349945828819,"B.4.1
Instantaneous regret decomposition
709"
LOG,0.7204767063921993,"Now, given the event probabilities, we condition the instantaneous regret r(t) on the good events at a
710"
LOG,0.7210184182015168,"time t > t0. We have for its expectation:
711"
LOG,0.7215601300108342,"E [r(t)] ≤E [r(t)|Gsel(t)] + 2P [Gsel(t)c]
≤E [r(t)|Gpro(t) ∩GRE(t) ∩Gsel(t)]
+ 2 (P [Gpro(t)c|Gsel(t)] + P [GRE(t)c|Gsel(t)] + P [Gsel(t)c]) ,
(76)"
LOG,0.7221018418201517,"where we used the worst case bound r(t) ≤2 if any one of the good events does not hold.
712"
LOG,0.7226435536294691,"Bounding the regret
Inserting our results of the event probabilities, the oracle inequality and the
713"
LOG,0.7231852654387866,"decomposition of the expected instantaneous regret in Equation (76) and bounding the sum over
714"
LOG,0.723726977248104,"rounds, yields the final result. Thus, we start by bounding the sum over the first term i.e. the expected
715"
LOG,0.7242686890574215,"regret in case all good events hold:
716 T
X"
LOG,0.7248104008667389,"t=1
E [r(t)|Gpro(t) ∩GRE(t) ∩Gsel(t)] ≤ T
X t=1"
LOG,0.7253521126760564,"Θ −ˆΘ(t)

F"
LOG,0.7258938244853738,"Taking the result of our oracle inequality in Theorem 1, we point out that only α(t) is time dependent
717"
LOG,0.7264355362946913,"such that the rest of the terms can be pulled outside the sum:
718 T
X t=1"
LOG,0.7269772481040087,"Θ −ˆΘ(t)

F ≤ T
X"
LOG,0.7275189599133262,"t=1
2
σ
ˆϕ2√"
LOG,0.7280606717226435,"t
f(G, Θ)"
LOG,0.728602383531961,"v
u
u
t1 + 2b s"
LOG,0.7291440953412784,"|V| log
1
δ(t) + 2b log
1
δ(t) = 2σ"
LOG,0.7296858071505958,"ˆϕ2 f(G, Θ) T
X t=1 r 1"
LOG,0.7302275189599133,t + 2b t p
LOG,0.7307692307692307,2|V| log(t) + 4b
LOG,0.7313109425785482,t log(t) ≤2σ
LOG,0.7318526543878656,"ˆϕ2 f(G, Θ)
Z T 0 1
√ t + r"
B,0.7323943661971831,2b t p
B,0.7329360780065005,"2|V| log(T) + 2 log(T)

dt ≤2σ"
B,0.733477789815818,"ˆϕ2 f(G, Θ)

2
√ T + √"
T,0.7340195016251354,"8T
|V| + 4
4
s"
T,0.7345612134344529,"32 log(|V|T)T |V|
+ r 16"
T,0.7351029252437703,"3 log(|V|T) log(T) ! 
4p"
T,0.7356446370530878,"2|V| log(T) +
p"
T,0.7361863488624052,"2 log(T)
 = O"
T,0.7367280606717227,"f(G, Θ)
√ T
ˆϕ2 p"
T,0.7372697724810401,"|V| +
q log
 "
T,0.7378114842903575,"T|V|

+
4qV log
 "
T,0.738353196099675,"T|V|

! ,"
T,0.7388949079089924,"where
719"
T,0.7394366197183099,"f(G, Θ) :=

a2(G, Θ) +
√"
T,0.7399783315276273,"21≤1(κ)w(∂P)

"
T,0.7405200433369448,"a2(G, Θ) +
√"
T,0.7410617551462622,21≤1(κ)w(∂P)
T,0.7416034669555797,"a1(G, Θ) min
C∈P p"
T,0.742145178764897,"cG(C)
+ 1  ."
T,0.7426868905742146,"We upper bounded the sum with an integral i.e. PT
t=1 f(t) ≤
R T
0 f(t)dt for monotonically decreasing
720"
T,0.7432286023835319,"functions f(t) in the last inequality. Also b is the bound on the concentration of the fraction of
721"
T,0.7437703141928494,"observation per task provided by Lemma 5. For t0 =
p"
T,0.7443120260021668,"|V| we find by inserting the result to Lemma 5
722"
T,0.7448537378114843,"for all t > t0:
723"
T,0.7453954496208017,"1
|V| + 2 s"
T,0.7459371614301191,"1
t|V| log |V| δ + 4"
T,0.7464788732394366,"3t log |V| δ
≤1"
T,0.747020585048754,|V| + 2
T,0.7475622968580715,"v
u
u
t2 log

|V|
p |V|
 p"
T,0.7481040086673889,"|V||V|
+
8 log

|V|
p |V|
"
P,0.7486457204767064,"3
p |V| = 1"
P,0.7491874322860238,"|V| +
2
p |V| ""s"
P,0.7497291440953413,"3
p"
P,0.7502708559046587,"|V|
log(|V|) + 2 log(|V|) # = O"
P,0.7508125677139762,"log(|V|)
p |V| ! = b."
P,0.7513542795232936,"Finally we bound the sum over the instantaneous regret term for the bad events:
724 T
X"
P,0.7518959913326111,"t=1
2 (P [Gpro(t)c|Gsel(t)] + P [GRE(t)c|Gsel(t)] + P [Gsel(t)c])"
P,0.7524377031419285,"By construction, we have max(P [Gpro(t)c|Gsel(t)] , P [Gsel(t)c]) ≤δ(t) = 1"
P,0.752979414951246,"t2 . Hence,
725 T
X"
P,0.7535211267605634,"t=1
P [Gpro(t)c|Gsel(t)] + P [Gsel(t)c] ≤2 T
X t=1"
P,0.7540628385698809,"1
t2 ≤2 "
P,0.7546045503791983,"1 +
Z T 1 dt
t2 !"
P,0.7551462621885157,"≤4
(77)"
P,0.7556879739978332,"As for the RE condition event, letting A := 3γ2 minC∈P(˜cG(C) ∧˜c2
G(C))"
P,0.7562296858071506,"6b + 2
√"
P,0.7567713976164681,"2γ
, we have for any t0 ≥1
726 T
X"
P,0.7573131094257854,"t=t0
P [GRE(t)c|Gsel(t)] ≤6d|V| T
X"
P,0.757854821235103,"t=t0
exp(−At)
(by Theorem 2)"
P,0.7583965330444203,≤6d|V| e−At0
P,0.7589382448537378,"1 −e−A ≤6d|V|e−At0

1 + 1 A "
P,0.7594799566630552,"≤6d|V|e−At0

1 + 1 A "
P,0.7600216684723727,"where in the last line, we used the inequality exp(A) ≥A + 1. Hence, for any u > 0, choosing
727"
P,0.7605633802816901,"t0 =
lp"
P,0.7611050920910076,"|V|
m
∨
 1"
P,0.761646803900325,"A log
6d|V|(1 + 1 A)
u "
P,0.7621885157096425,"implies that PT
t=t0 P [GRE(t)c|Gsel(t)] ≤u. Before we continue with the regret bound, we need to
728"
P,0.7627302275189599,"find an appropriate bound on f(G,Θ)"
P,0.7632719393282773,"ˆϕ2
. Given our result in Theorem 1 and assuming that κ > 1, we
729"
P,0.7638136511375948,"get:
730"
P,0.7643553629469122,"f(G, Θ)"
P,0.7648970747562297,"ˆϕ2
= α0a2(G, Θ) ˆϕ2 "
P,0.7654387865655471,"
a2(G, Θ)"
P,0.7659804983748646,"a1(G, Θ) min
C∈P p"
P,0.766522210184182,"cG(C)
+ 1   = √"
P,0.7670639219934995,"2κw(∂P) maxC∈P
p"
P,0.7676056338028169,"ιG(C)α0 + 1

 
√"
P,0.7681473456121344,2κw(∂P) maxC∈P √
P,0.7686890574214518,ιG(C)α0+1
P,0.7692307692307693,"α0(min
C∈P p"
P,0.7697724810400867,cG(C) −2κw(∂P)) −1 + 1   1 −γ 
P,0.7703141928494042,"





 1 + √"
P,0.7708559046587216,2κw(∂P) maxC∈P √
P,0.771397616468039,ιG(C)α0+1 α 
P,0.7719393282773565,"

1−
2κw(∂P)
min
C∈P p cG(C) "
P,0.7724810400866738,"

−
1
min
C∈P p cG(C) "
P,0.7730227518959913,"





 2 = O "
P,0.7735644637053087,"maxC∈P ιG(C) + maxC∈P
p"
P,0.7741061755146262,ιG(C) + 1
P,0.7746478873239436,"min
C∈P p"
P,0.7751895991332611,"cG(C)
+ max
C∈P ιG(C) + 1   = O  
1"
P,0.7757313109425785,"min
C∈P p cG(C)  ."
P,0.776273022751896,"The first big O notation is obtained due to the fact that for for large min
C∈P p"
P,0.7768147345612134,"cG(C) and small
731"
P,0.7773564463705309,"maxC∈P
p"
P,0.7778981581798483,"ιG(C) the denominator term i.e. ˆϕ2 behaves like 1 −γ, which leaves the numerator
732"
P,0.7784398699891658,"dominating the rest of the term. Now, we simply have to insert all our results into the sum of
733"
P,0.7789815817984832,"instantaneous regrets:
734"
P,0.7795232936078007,R(T) ≤t0 + 2u + 8 + O
P,0.7800650054171181,"f(G, Θ)
√ T
ˆϕ2 p"
P,0.7806067172264355,"|V| +
q log
 "
P,0.781148429035753,"T|V|

+
4qV log
 "
P,0.7816901408450704,"T|V|

! ≤
lp"
P,0.7822318526543879,"|V|
m
+
 1"
P,0.7827735644637053,"A log
6d|V|(1 + 1 A)
u"
P,0.7833152762730228,"
+ 2u + 8 + O"
P,0.7838569880823402,"f(G, Θ)
√ T
ˆϕ2 p"
P,0.7843986998916577,"|V| +
q log
 "
P,0.7849404117009751,"T|V|

+
4qV log
 "
P,0.7854821235102926,"T|V|

! ≤
lp"
P,0.78602383531961,"|V|
m
+
 1"
P,0.7865655471289275,"A log(12d|V|(1 + A))

+ 1 A + 8 + O"
P,0.7871072589382448,"f(G, Θ)
√ T
ˆϕ2 p"
P,0.7876489707475623,"|V| +
q log
 "
P,0.7881906825568797,"T|V|

+
4qV log
 "
P,0.7887323943661971,"T|V|

! ≤
lp"
P,0.7892741061755146,"|V|
m
+
 1"
P,0.789815817984832,"A log(12d|V|(1 + A))

+ 1 A + 8 + O"
P,0.7903575297941495,"f(G, Θ)
√ T
ˆϕ2 p"
P,0.7908992416034669,"|V| +
q log
 "
P,0.7914409534127844,"T|V|

+
4qV log
 "
P,0.7919826652221018,"T|V|

! = O  1"
P,0.7925243770314193,A log(d|V|) +
P,0.7930660888407367,"v
u
u
t
T
min
C∈P cG(C) p"
P,0.7936078006500542,"|V| +
q log
 "
P,0.7941495124593716,"T|V|

+
4qV log
 "
P,0.7946912242686891,"T|V|

 ,"
P,0.7952329360780065,"where we set u =
1
2A in the third inequality.
735 736"
P,0.795774647887324,"C
Additional related work
737"
P,0.7963163596966414,"Homophily and modularity in social networks
Given the large number of users on social networks,
738"
P,0.7968580715059588,"one may be able to learn their preferences more quickly by leveraging the similarities between them.
739"
P,0.7973997833152763,"This idea relies on the notion of homophily in social networks McPherson et al. [2001], Easley et al.
740"
P,0.7979414951245937,"[2010]. In modelling social networks, users’ preferences relationships are encoded in a graph, where
741"
P,0.7984832069339112,"neighboring nodes are users with similar preferences. This graph can be known a priori or it can
742"
P,0.7990249187432286,"be inferred from previously collected feedback Dong et al. [2019]. Exploiting this information and
743"
P,0.7995666305525461,"integrating them into bandit algorithms can lead to a significant increase in performance Yang et al.
744"
P,0.8001083423618635,"[2020]. Indeed, the knowledge of user relations allows the algorithm to tackle the data sparsity issue
745"
P,0.800650054171181,"that is inherent to bandit settings.
746"
P,0.8011917659804983,"Another fundamental point that can be used for integration of information from social networks is
747"
P,0.8017334777898159,"that, social networks show large modularity measures Newman [2006] Borge-Holthoefer et al. [2011].
748"
P,0.8022751895991332,"This implies that we have high density of edges within clusters and low density of edges between
749"
P,0.8028169014084507,"clusters. As a result, users can be clustered based on the graph topology and a preference vector
750"
P,0.8033586132177681,"can be learned for each cluster, substantially reducing the dimensionality of the problem. In other
751"
P,0.8039003250270856,"words, discovering the clustering structure of users can reduce the computational burden of large
752"
P,0.804442036836403,"social networks. Consequently, there have been attempts in exploiting the clustered structures of
753"
P,0.8049837486457205,"social networks in bandit algorithms Gentile et al. [2014], Nguyen and Lauw [2014], Yang and Toni
754"
P,0.8055254604550379,"[2018], Li et al. [2019], Nourani-Koliji et al. [2023], Cheng et al. [2023].
755"
P,0.8060671722643553,"Bandit meta-learning
In contrast to the multi-task setting, meta learning deals with sequentially
756"
P,0.8066088840736728,"arriving tasks that have to be learnt and generalizing the gained information to improve performance
757"
P,0.8071505958829902,"for future tasks. Here, as in the multi-task setting, it is assumed that the tasks share some common
758"
P,0.8076923076923077,"structure that is ought to be learnt and exploited. In the work of Bilaj et al. [2024] it is assumed that
759"
P,0.8082340195016251,"the tasks were sampled from a common distribution such that they are concentrated around an affine
760"
P,0.8087757313109426,"subspace, which is learnt through PCA algorithm. The resulting projection matrices could then be
761"
P,0.80931744312026,"exploited to improve learning for new tasks in an adapted UCB and Thompson sampling approach.
762"
P,0.8098591549295775,"Other lines of work are Cella et al. [2020], Kveton et al. [2021], Basu et al. [2021], which learns the
763"
P,0.8104008667388949,"mean of the distribution under the assumption that the covariance of the prior is known or Peleg et al.
764"
P,0.8109425785482124,"[2022] which generalizes this assumption and attempts to learn the covariance as well.
765"
P,0.8114842903575298,"D
Additional experimental details
766"
P,0.8120260021668473,"D.1
About experiments of the main paper
767"
P,0.8125677139761647,"The experiments have been conducted with an intel i7 CPU with 12 2.6 GHz cores and 32 GB of
768"
P,0.8131094257854822,"RAM. The two experiments with the highest number of tasks (200) and dimension (80) take about 8
769"
P,0.8136511375947996,"hours, parallelized over the 12 cores.
770"
P,0.814192849404117,"To generate clusters, we generate |P| variables vii∈P from the uniform distribution, then we use
771"
P,0.8147345612134345,"them to construct a categorical distribution with probabilities proportional to evi. These probabilities
772"
P,0.8152762730227519,"defines the cluster proportions.
773"
P,0.8158179848320694,"D.2
Solving the Network Lasso problem
774"
P,0.8163596966413867,"We implement the Primal-Dual algorithm proposed in Jung [2020] to solve the Network Lasso
775"
P,0.8169014084507042,"problem but we do not vectorize the matrices (in the sense of stacking their columns into a vector),
776"
P,0.8174431202600216,"which speeds up computation.
777"
P,0.8179848320693391,"D.3
Algebraic connectivity vs topological centrality index
778"
P,0.8185265438786565,"Given two fully connected graphs weightless G1 and G2 with size 100 each, we progressively link
779"
P,0.819068255687974,"them by edges, we construct the Laplcian L of the resulting graph G. We measure the minimum
780"
P,0.8196099674972914,"topological centrality index min1≤i∈200(L†
C)−1
ii , and the algebraic connectivity, i.e. the minimum
781"
P,0.8201516793066089,"non-null eigenvalue of L.
782"
P,0.8206933911159263,"0.0
0.2
0.4
0.6
0.8
1.0
fraction of all edges linking the two complete graphs 0 20 40 60 80 100 120 140"
P,0.8212351029252438,"algebraic connectivity
minimum topological centrality index"
P,0.8217768147345612,"Figure 2: Minimum Topological centrality index vs Algebraic Connectivity, for a graph formed by
connecting two fully connected initial graphs G1, G2 with size 100 each."
P,0.8223185265438786,"Clearly, the minimum topological centrality index grows faster than the algebraic connectivity in
783"
P,0.8228602383531961,"this case, and seems to saturate at some level that is reached in a linear progress by the algebraic
784"
P,0.8234019501625135,"connectivity.
785"
P,0.823943661971831,"D.4
Limitations
786"
P,0.8244853737811484,"The first limitation of the paper is the restriction to the setting of i.i.d generated action sets. This
787"
P,0.8250270855904659,"restriction is common to all papers relying on Lasso-type optimization objectives [Bastani and Bayati,
788"
P,0.8255687973997833,"2019, Oh et al., 2021, Cella and Pontil, 2021, Ariu et al., 2022, Cella et al., 2023]. Also, we do not
789"
P,0.8261105092091008,"provide a lower bound for the regret, a challenge that we let for future work. Besides, our optimization
790"
P,0.8266522210184182,"problem is not strongly convex, which can be mitigated by adding a squared L2 norm regularization.
791"
P,0.8271939328277357,"However, such an addition would probably drastically change the theoretical analysis.
792"
P,0.8277356446370531,"D.5
Broader Impacts
793"
P,0.8282773564463706,"As our method can be applied to transfer knowledge between users of a recommender system, it has
794"
P,0.828819068255688,"the potential to improve their overall experience by learning their preferences quickly. However, one
795"
P,0.8293607800650055,"must be careful with the strength of the integrated prior knowledge as it can lead to an adverse effect
796"
P,0.8299024918743229,"of slowing down the learning process.
797"
P,0.8304442036836404,"NeurIPS Paper Checklist
798"
CLAIMS,0.8309859154929577,"1. Claims
799"
CLAIMS,0.8315276273022751,"Question: Do the main claims made in the abstract and introduction accurately reflect the
800"
CLAIMS,0.8320693391115926,"paper’s contributions and scope?
801"
CLAIMS,0.83261105092091,"Answer: [Yes]
802"
CLAIMS,0.8331527627302275,"Justification: The piecewise stationarity on a graph assumption is mentioned in Section 3
803"
CLAIMS,0.8336944745395449,"and formalized in Assumption 3. Theorem 1 states the oracle inequality, and Theorem 3
804"
CLAIMS,0.8342361863488624,"provides the regret bound after using the result of Theorem 2. Experiments are carried out
805"
CLAIMS,0.8347778981581798,"at Section 6.
806"
CLAIMS,0.8353196099674973,"Guidelines:
807"
CLAIMS,0.8358613217768147,"• The answer NA means that the abstract and introduction do not include the claims made
808"
CLAIMS,0.8364030335861322,"in the paper.
809"
CLAIMS,0.8369447453954496,"• The abstract and/or introduction should clearly state the claims made, including the
810"
CLAIMS,0.8374864572047671,"contributions made in the paper and important assumptions and limitations. A No or NA
811"
CLAIMS,0.8380281690140845,"answer to this question will not be perceived well by the reviewers.
812"
CLAIMS,0.838569880823402,"• The claims made should match theoretical and experimental results, and reflect how
813"
CLAIMS,0.8391115926327194,"much the results can be expected to generalize to other settings.
814"
CLAIMS,0.8396533044420368,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
815"
CLAIMS,0.8401950162513543,"are not attained by the paper.
816"
LIMITATIONS,0.8407367280606717,"2. Limitations
817"
LIMITATIONS,0.8412784398699892,"Question: Does the paper discuss the limitations of the work performed by the authors?
818"
LIMITATIONS,0.8418201516793066,"Answer: [Yes]
819"
LIMITATIONS,0.8423618634886241,"Justification: Appendix D.4 is dedicated to such discussion.
820"
LIMITATIONS,0.8429035752979415,"Guidelines:
821"
LIMITATIONS,0.843445287107259,"• The answer NA means that the paper has no limitation while the answer No means that
822"
LIMITATIONS,0.8439869989165764,"the paper has limitations, but those are not discussed in the paper.
823"
LIMITATIONS,0.8445287107258939,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
824"
LIMITATIONS,0.8450704225352113,"• The paper should point out any strong assumptions and how robust the results are to
825"
LIMITATIONS,0.8456121343445288,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
826"
LIMITATIONS,0.8461538461538461,"model well-specification, asymptotic approximations only holding locally). The authors
827"
LIMITATIONS,0.8466955579631636,"should reflect on how these assumptions might be violated in practice and what the
828"
LIMITATIONS,0.847237269772481,"implications would be.
829"
LIMITATIONS,0.8477789815817984,"• The authors should reflect on the scope of the claims made, e.g., if the approach was only
830"
LIMITATIONS,0.8483206933911159,"tested on a few datasets or with a few runs. In general, empirical results often depend on
831"
LIMITATIONS,0.8488624052004333,"implicit assumptions, which should be articulated.
832"
LIMITATIONS,0.8494041170097508,"• The authors should reflect on the factors that influence the performance of the approach.
833"
LIMITATIONS,0.8499458288190682,"For example, a facial recognition algorithm may perform poorly when image resolution
834"
LIMITATIONS,0.8504875406283857,"is low or images are taken in low lighting. Or a speech-to-text system might not be used
835"
LIMITATIONS,0.8510292524377031,"reliably to provide closed captions for online lectures because it fails to handle technical
836"
LIMITATIONS,0.8515709642470206,"jargon.
837"
LIMITATIONS,0.852112676056338,"• The authors should discuss the computational efficiency of the proposed algorithms and
838"
LIMITATIONS,0.8526543878656555,"how they scale with dataset size.
839"
LIMITATIONS,0.8531960996749729,"• If applicable, the authors should discuss possible limitations of their approach to address
840"
LIMITATIONS,0.8537378114842904,"problems of privacy and fairness.
841"
LIMITATIONS,0.8542795232936078,"• While the authors might fear that complete honesty about limitations might be used by
842"
LIMITATIONS,0.8548212351029253,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
843"
LIMITATIONS,0.8553629469122427,"limitations that aren’t acknowledged in the paper. The authors should use their best
844"
LIMITATIONS,0.8559046587215602,"judgment and recognize that individual actions in favor of transparency play an important
845"
LIMITATIONS,0.8564463705308776,"role in developing norms that preserve the integrity of the community. Reviewers will be
846"
LIMITATIONS,0.856988082340195,"specifically instructed to not penalize honesty concerning limitations.
847"
THEORY ASSUMPTIONS AND PROOFS,0.8575297941495125,"3. Theory Assumptions and Proofs
848"
THEORY ASSUMPTIONS AND PROOFS,0.8580715059588299,"Question: For each theoretical result, does the paper provide the full set of assumptions and
849"
THEORY ASSUMPTIONS AND PROOFS,0.8586132177681474,"a complete (and correct) proof?
850"
THEORY ASSUMPTIONS AND PROOFS,0.8591549295774648,"Answer: [Yes]
851"
THEORY ASSUMPTIONS AND PROOFS,0.8596966413867823,"Justification: We state the main assumptions in an Assumption environment. Full proofs
852"
THEORY ASSUMPTIONS AND PROOFS,0.8602383531960996,"are available in the supplementary material and some proof ideas in the main material.
853"
THEORY ASSUMPTIONS AND PROOFS,0.8607800650054171,"Guidelines:
854"
THEORY ASSUMPTIONS AND PROOFS,0.8613217768147345,"• The answer NA means that the paper does not include theoretical results.
855"
THEORY ASSUMPTIONS AND PROOFS,0.861863488624052,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
856"
THEORY ASSUMPTIONS AND PROOFS,0.8624052004333694,"referenced.
857"
THEORY ASSUMPTIONS AND PROOFS,0.8629469122426869,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
858"
THEORY ASSUMPTIONS AND PROOFS,0.8634886240520043,"• The proofs can either appear in the main paper or the supplemental material, but if they
859"
THEORY ASSUMPTIONS AND PROOFS,0.8640303358613218,"appear in the supplemental material, the authors are encouraged to provide a short proof
860"
THEORY ASSUMPTIONS AND PROOFS,0.8645720476706392,"sketch to provide intuition.
861"
THEORY ASSUMPTIONS AND PROOFS,0.8651137594799566,"• Inversely, any informal proof provided in the core of the paper should be complemented
862"
THEORY ASSUMPTIONS AND PROOFS,0.8656554712892741,"by formal proofs provided in appendix or supplemental material.
863"
THEORY ASSUMPTIONS AND PROOFS,0.8661971830985915,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
864"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.866738894907909,"4. Experimental Result Reproducibility
865"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8672806067172264,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
866"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8678223185265439,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
867"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8683640303358613,"of the paper (regardless of whether the code and data are provided or not)?
868"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8689057421451788,"Answer: [Yes]
869"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8694474539544962,"Justification: The code is included as a zip-file and all results are reproducible.
870"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8699891657638137,"Guidelines:
871"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8705308775731311,"• The answer NA means that the paper does not include experiments.
872"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8710725893824486,"• If the paper includes experiments, a No answer to this question will not be perceived
873"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.871614301191766,"well by the reviewers: Making the paper reproducible is important, regardless of whether
874"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8721560130010835,"the code and data are provided or not.
875"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8726977248104009,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
876"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8732394366197183,"to make their results reproducible or verifiable.
877"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8737811484290358,"• Depending on the contribution, reproducibility can be accomplished in various ways.
878"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8743228602383532,"For example, if the contribution is a novel architecture, describing the architecture fully
879"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8748645720476707,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
880"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.875406283856988,"be necessary to either make it possible for others to replicate the model with the same
881"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8759479956663055,"dataset, or provide access to the model. In general. releasing code and data is often
882"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8764897074756229,"one good way to accomplish this, but reproducibility can also be provided via detailed
883"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8770314192849404,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
884"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8775731310942578,"of a large language model), releasing of a model checkpoint, or other means that are
885"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8781148429035753,"appropriate to the research performed.
886"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8786565547128927,"• While NeurIPS does not require releasing code, the conference does require all submis-
887"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8791982665222102,"sions to provide some reasonable avenue for reproducibility, which may depend on the
888"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8797399783315276,"nature of the contribution. For example
889"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8802816901408451,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
890"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8808234019501625,"to reproduce that algorithm.
891"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8813651137594799,"(b) If the contribution is primarily a new model architecture, the paper should describe
892"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8819068255687974,"the architecture clearly and fully.
893"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8824485373781148,"(c) If the contribution is a new model (e.g., a large language model), then there should
894"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8829902491874323,"either be a way to access this model for reproducing the results or a way to reproduce
895"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8835319609967497,"the model (e.g., with an open-source dataset or instructions for how to construct the
896"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8840736728060672,"dataset).
897"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8846153846153846,"(d) We recognize that reproducibility may be tricky in some cases, in which case authors
898"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8851570964247021,"are welcome to describe the particular way they provide for reproducibility. In the
899"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8856988082340195,"case of closed-source models, it may be that access to the model is limited in some
900"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.886240520043337,"way (e.g., to registered users), but it should be possible for other researchers to have
901"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8867822318526544,"some path to reproducing or verifying the results.
902"
OPEN ACCESS TO DATA AND CODE,0.8873239436619719,"5. Open access to data and code
903"
OPEN ACCESS TO DATA AND CODE,0.8878656554712893,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
904"
OPEN ACCESS TO DATA AND CODE,0.8884073672806068,"tions to faithfully reproduce the main experimental results, as described in supplemental
905"
OPEN ACCESS TO DATA AND CODE,0.8889490790899242,"material?
906"
OPEN ACCESS TO DATA AND CODE,0.8894907908992417,"Answer: [Yes]
907"
OPEN ACCESS TO DATA AND CODE,0.890032502708559,"Justification: We use only simulated data.
908"
OPEN ACCESS TO DATA AND CODE,0.8905742145178764,"Guidelines:
909"
OPEN ACCESS TO DATA AND CODE,0.8911159263271939,"• The answer NA means that paper does not include experiments requiring code.
910"
OPEN ACCESS TO DATA AND CODE,0.8916576381365113,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
911"
OPEN ACCESS TO DATA AND CODE,0.8921993499458288,"public/guides/CodeSubmissionPolicy) for more details.
912"
OPEN ACCESS TO DATA AND CODE,0.8927410617551462,"• While we encourage the release of code and data, we understand that this might not be
913"
OPEN ACCESS TO DATA AND CODE,0.8932827735644637,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
914"
OPEN ACCESS TO DATA AND CODE,0.8938244853737811,"including code, unless this is central to the contribution (e.g., for a new open-source
915"
OPEN ACCESS TO DATA AND CODE,0.8943661971830986,"benchmark).
916"
OPEN ACCESS TO DATA AND CODE,0.894907908992416,"• The instructions should contain the exact command and environment needed to run to
917"
OPEN ACCESS TO DATA AND CODE,0.8954496208017335,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
918"
OPEN ACCESS TO DATA AND CODE,0.8959913326110509,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
919"
OPEN ACCESS TO DATA AND CODE,0.8965330444203684,"• The authors should provide instructions on data access and preparation, including how
920"
OPEN ACCESS TO DATA AND CODE,0.8970747562296858,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
921"
OPEN ACCESS TO DATA AND CODE,0.8976164680390033,"• The authors should provide scripts to reproduce all experimental results for the new
922"
OPEN ACCESS TO DATA AND CODE,0.8981581798483207,"proposed method and baselines. If only a subset of experiments are reproducible, they
923"
OPEN ACCESS TO DATA AND CODE,0.8986998916576381,"should state which ones are omitted from the script and why.
924"
OPEN ACCESS TO DATA AND CODE,0.8992416034669556,"• At submission time, to preserve anonymity, the authors should release anonymized
925"
OPEN ACCESS TO DATA AND CODE,0.899783315276273,"versions (if applicable).
926"
OPEN ACCESS TO DATA AND CODE,0.9003250270855905,"• Providing as much information as possible in supplemental material (appended to the
927"
OPEN ACCESS TO DATA AND CODE,0.9008667388949079,"paper) is recommended, but including URLs to data and code is permitted.
928"
OPEN ACCESS TO DATA AND CODE,0.9014084507042254,"6. Experimental Setting/Details
929"
OPEN ACCESS TO DATA AND CODE,0.9019501625135428,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
930"
OPEN ACCESS TO DATA AND CODE,0.9024918743228603,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
931"
OPEN ACCESS TO DATA AND CODE,0.9030335861321777,"results?
932"
OPEN ACCESS TO DATA AND CODE,0.9035752979414952,"Answer: [Yes]
933"
OPEN ACCESS TO DATA AND CODE,0.9041170097508126,"Justification: While training and testing sets are not part of our paper as it is about bandit
934"
OPEN ACCESS TO DATA AND CODE,0.90465872156013,"algorithms, we provide the source of the optimization algorithm we use to solve Equation (2).
935"
OPEN ACCESS TO DATA AND CODE,0.9052004333694474,"Guidelines:
936"
OPEN ACCESS TO DATA AND CODE,0.905742145178765,"• The answer NA means that the paper does not include experiments.
937"
OPEN ACCESS TO DATA AND CODE,0.9062838569880823,"• The experimental setting should be presented in the core of the paper to a level of detail
938"
OPEN ACCESS TO DATA AND CODE,0.9068255687973997,"that is necessary to appreciate the results and make sense of them.
939"
OPEN ACCESS TO DATA AND CODE,0.9073672806067172,"• The full details can be provided either with the code, in appendix, or as supplemental
940"
OPEN ACCESS TO DATA AND CODE,0.9079089924160346,"material.
941"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9084507042253521,"7. Experiment Statistical Significance
942"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9089924160346695,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
943"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.909534127843987,"information about the statistical significance of the experiments?
944"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9100758396533044,"Answer: [Yes]
945"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9106175514626219,"Justification: Error bars are provided in the plots.
946"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9111592632719393,"Guidelines:
947"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9117009750812568,"• The answer NA means that the paper does not include experiments.
948"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9122426868905742,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confidence
949"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9127843986998917,"intervals, or statistical significance tests, at least for the experiments that support the
950"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9133261105092091,"main claims of the paper.
951"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9138678223185266,"• The factors of variability that the error bars are capturing should be clearly stated (for
952"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.914409534127844,"example, train/test split, initialization, random drawing of some parameter, or overall
953"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9149512459371615,"run with given experimental conditions).
954"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9154929577464789,"• The method for calculating the error bars should be explained (closed form formula, call
955"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9160346695557963,"to a library function, bootstrap, etc.)
956"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9165763813651138,"• The assumptions made should be given (e.g., Normally distributed errors).
957"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9171180931744312,"• It should be clear whether the error bar is the standard deviation or the standard error of
958"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9176598049837487,"the mean.
959"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.918201516793066,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
960"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9187432286023836,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
961"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.919284940411701,"of Normality of errors is not verified.
962"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9198266522210184,"• For asymmetric distributions, the authors should be careful not to show in tables or
963"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9203683640303358,"figures symmetric error bars that would yield results that are out of range (e.g. negative
964"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9209100758396533,"error rates).
965"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9214517876489707,"• If error bars are reported in tables or plots, The authors should explain in the text how
966"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9219934994582882,"they were calculated and reference the corresponding figures or tables in the text.
967"
EXPERIMENTS COMPUTE RESOURCES,0.9225352112676056,"8. Experiments Compute Resources
968"
EXPERIMENTS COMPUTE RESOURCES,0.9230769230769231,"Question: For each experiment, does the paper provide sufficient information on the com-
969"
EXPERIMENTS COMPUTE RESOURCES,0.9236186348862405,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
970"
EXPERIMENTS COMPUTE RESOURCES,0.9241603466955579,"the experiments?
971"
EXPERIMENTS COMPUTE RESOURCES,0.9247020585048754,"Answer: [Yes]
972"
EXPERIMENTS COMPUTE RESOURCES,0.9252437703141928,"Justification: Computation resources used are mentioned in Appendix D.1.
973"
EXPERIMENTS COMPUTE RESOURCES,0.9257854821235103,"Guidelines:
974"
EXPERIMENTS COMPUTE RESOURCES,0.9263271939328277,"• The answer NA means that the paper does not include experiments.
975"
EXPERIMENTS COMPUTE RESOURCES,0.9268689057421452,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster, or
976"
EXPERIMENTS COMPUTE RESOURCES,0.9274106175514626,"cloud provider, including relevant memory and storage.
977"
EXPERIMENTS COMPUTE RESOURCES,0.9279523293607801,"• The paper should provide the amount of compute required for each of the individual
978"
EXPERIMENTS COMPUTE RESOURCES,0.9284940411700975,"experimental runs as well as estimate the total compute.
979"
EXPERIMENTS COMPUTE RESOURCES,0.929035752979415,"• The paper should disclose whether the full research project required more compute than
980"
EXPERIMENTS COMPUTE RESOURCES,0.9295774647887324,"the experiments reported in the paper (e.g., preliminary or failed experiments that didn’t
981"
EXPERIMENTS COMPUTE RESOURCES,0.9301191765980499,"make it into the paper).
982"
CODE OF ETHICS,0.9306608884073673,"9. Code Of Ethics
983"
CODE OF ETHICS,0.9312026002166848,"Question: Does the research conducted in the paper conform, in every respect, with the
984"
CODE OF ETHICS,0.9317443120260022,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
985"
CODE OF ETHICS,0.9322860238353196,"Answer: [Yes]
986"
CODE OF ETHICS,0.9328277356446371,"Justification: Our results are theoretical, and their potential harm largely depends on their
987"
CODE OF ETHICS,0.9333694474539544,"application.
988"
CODE OF ETHICS,0.933911159263272,"Guidelines:
989"
CODE OF ETHICS,0.9344528710725893,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
990"
CODE OF ETHICS,0.9349945828819068,"• If the authors answer No, they should explain the special circumstances that require a
991"
CODE OF ETHICS,0.9355362946912242,"deviation from the Code of Ethics.
992"
CODE OF ETHICS,0.9360780065005417,"• The authors should make sure to preserve anonymity (e.g., if there is a special considera-
993"
CODE OF ETHICS,0.9366197183098591,"tion due to laws or regulations in their jurisdiction).
994"
BROADER IMPACTS,0.9371614301191766,"10. Broader Impacts
995"
BROADER IMPACTS,0.937703141928494,"Question: Does the paper discuss both potential positive societal impacts and negative
996"
BROADER IMPACTS,0.9382448537378115,"societal impacts of the work performed?
997"
BROADER IMPACTS,0.9387865655471289,"Answer: [Yes]
998"
BROADER IMPACTS,0.9393282773564464,"Justification: It is provided in Appendix D.5 in the appendix.
999"
BROADER IMPACTS,0.9398699891657638,"Guidelines:
1000"
BROADER IMPACTS,0.9404117009750813,"• The answer NA means that there is no societal impact of the work performed.
1001"
BROADER IMPACTS,0.9409534127843987,"• If the authors answer NA or No, they should explain why their work has no societal
1002"
BROADER IMPACTS,0.9414951245937161,"impact or why the paper does not address societal impact.
1003"
BROADER IMPACTS,0.9420368364030336,"• Examples of negative societal impacts include potential malicious or unintended uses
1004"
BROADER IMPACTS,0.942578548212351,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
1005"
BROADER IMPACTS,0.9431202600216685,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
1006"
BROADER IMPACTS,0.9436619718309859,"groups), privacy considerations, and security considerations.
1007"
BROADER IMPACTS,0.9442036836403034,"• The conference expects that many papers will be foundational research and not tied
1008"
BROADER IMPACTS,0.9447453954496208,"to particular applications, let alone deployments. However, if there is a direct path to
1009"
BROADER IMPACTS,0.9452871072589383,"any negative applications, the authors should point it out. For example, it is legitimate
1010"
BROADER IMPACTS,0.9458288190682557,"to point out that an improvement in the quality of generative models could be used to
1011"
BROADER IMPACTS,0.9463705308775732,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
1012"
BROADER IMPACTS,0.9469122426868906,"that a generic algorithm for optimizing neural networks could enable people to train
1013"
BROADER IMPACTS,0.9474539544962081,"models that generate Deepfakes faster.
1014"
BROADER IMPACTS,0.9479956663055255,"• The authors should consider possible harms that could arise when the technology is being
1015"
BROADER IMPACTS,0.948537378114843,"used as intended and functioning correctly, harms that could arise when the technology is
1016"
BROADER IMPACTS,0.9490790899241603,"being used as intended but gives incorrect results, and harms following from (intentional
1017"
BROADER IMPACTS,0.9496208017334777,"or unintentional) misuse of the technology.
1018"
BROADER IMPACTS,0.9501625135427952,"• If there are negative societal impacts, the authors could also discuss possible mitigation
1019"
BROADER IMPACTS,0.9507042253521126,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
1020"
BROADER IMPACTS,0.9512459371614301,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
1021"
BROADER IMPACTS,0.9517876489707475,"feedback over time, improving the efficiency and accessibility of ML).
1022"
SAFEGUARDS,0.952329360780065,"11. Safeguards
1023"
SAFEGUARDS,0.9528710725893824,"Question: Does the paper describe safeguards that have been put in place for responsible
1024"
SAFEGUARDS,0.9534127843986999,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
1025"
SAFEGUARDS,0.9539544962080173,"image generators, or scraped datasets)?
1026"
SAFEGUARDS,0.9544962080173348,"Answer: [NA]
1027"
SAFEGUARDS,0.9550379198266522,"Justification: Only simulated data are used.
1028"
SAFEGUARDS,0.9555796316359697,"Guidelines:
1029"
SAFEGUARDS,0.9561213434452871,"• The answer NA means that the paper poses no such risks.
1030"
SAFEGUARDS,0.9566630552546046,"• Released models that have a high risk for misuse or dual-use should be released with
1031"
SAFEGUARDS,0.957204767063922,"necessary safeguards to allow for controlled use of the model, for example by requiring
1032"
SAFEGUARDS,0.9577464788732394,"that users adhere to usage guidelines or restrictions to access the model or implementing
1033"
SAFEGUARDS,0.9582881906825569,"safety filters.
1034"
SAFEGUARDS,0.9588299024918743,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
1035"
SAFEGUARDS,0.9593716143011918,"should describe how they avoided releasing unsafe images.
1036"
SAFEGUARDS,0.9599133261105092,"• We recognize that providing effective safeguards is challenging, and many papers do not
1037"
SAFEGUARDS,0.9604550379198267,"require this, but we encourage authors to take this into account and make a best faith
1038"
SAFEGUARDS,0.9609967497291441,"effort.
1039"
LICENSES FOR EXISTING ASSETS,0.9615384615384616,"12. Licenses for existing assets
1040"
LICENSES FOR EXISTING ASSETS,0.962080173347779,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
1041"
LICENSES FOR EXISTING ASSETS,0.9626218851570965,"the paper, properly credited and are the license and terms of use explicitly mentioned and
1042"
LICENSES FOR EXISTING ASSETS,0.9631635969664138,"properly respected?
1043"
LICENSES FOR EXISTING ASSETS,0.9637053087757314,"Answer: [Yes]
1044"
LICENSES FOR EXISTING ASSETS,0.9642470205850487,"Justification: All relevant work is properly cited and code is provided to reproduce the
1045"
LICENSES FOR EXISTING ASSETS,0.9647887323943662,"results.
1046"
LICENSES FOR EXISTING ASSETS,0.9653304442036836,"Guidelines:
1047"
LICENSES FOR EXISTING ASSETS,0.9658721560130011,"• The answer NA means that the paper does not use existing assets.
1048"
LICENSES FOR EXISTING ASSETS,0.9664138678223185,"• The authors should cite the original paper that produced the code package or dataset.
1049"
LICENSES FOR EXISTING ASSETS,0.9669555796316359,"• The authors should state which version of the asset is used and, if possible, include a
1050"
LICENSES FOR EXISTING ASSETS,0.9674972914409534,"URL.
1051"
LICENSES FOR EXISTING ASSETS,0.9680390032502708,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
1052"
LICENSES FOR EXISTING ASSETS,0.9685807150595883,"• For scraped data from a particular source (e.g., website), the copyright and terms of
1053"
LICENSES FOR EXISTING ASSETS,0.9691224268689057,"service of that source should be provided.
1054"
LICENSES FOR EXISTING ASSETS,0.9696641386782232,"• If assets are released, the license, copyright information, and terms of use in the pack-
1055"
LICENSES FOR EXISTING ASSETS,0.9702058504875406,"age should be provided. For popular datasets, paperswithcode.com/datasets has
1056"
LICENSES FOR EXISTING ASSETS,0.9707475622968581,"curated licenses for some datasets. Their licensing guide can help determine the license
1057"
LICENSES FOR EXISTING ASSETS,0.9712892741061755,"of a dataset.
1058"
LICENSES FOR EXISTING ASSETS,0.971830985915493,"• For existing datasets that are re-packaged, both the original license and the license of the
1059"
LICENSES FOR EXISTING ASSETS,0.9723726977248104,"derived asset (if it has changed) should be provided.
1060"
LICENSES FOR EXISTING ASSETS,0.9729144095341279,"• If this information is not available online, the authors are encouraged to reach out to the
1061"
LICENSES FOR EXISTING ASSETS,0.9734561213434453,"asset’s creators.
1062"
NEW ASSETS,0.9739978331527628,"13. New Assets
1063"
NEW ASSETS,0.9745395449620802,"Question: Are new assets introduced in the paper well documented and is the documentation
1064"
NEW ASSETS,0.9750812567713976,"provided alongside the assets?
1065"
NEW ASSETS,0.9756229685807151,"Answer: [No]
1066"
NEW ASSETS,0.9761646803900325,"Justification: [NA]
1067"
NEW ASSETS,0.97670639219935,"Guidelines:
1068"
NEW ASSETS,0.9772481040086674,"• The answer NA means that the paper does not release new assets.
1069"
NEW ASSETS,0.9777898158179849,"• Researchers should communicate the details of the dataset/code/model as part of their
1070"
NEW ASSETS,0.9783315276273022,"submissions via structured templates. This includes details about training, license,
1071"
NEW ASSETS,0.9788732394366197,"limitations, etc.
1072"
NEW ASSETS,0.9794149512459371,"• The paper should discuss whether and how consent was obtained from people whose
1073"
NEW ASSETS,0.9799566630552546,"asset is used.
1074"
NEW ASSETS,0.980498374864572,"• At submission time, remember to anonymize your assets (if applicable). You can either
1075"
NEW ASSETS,0.9810400866738895,"create an anonymized URL or include an anonymized zip file.
1076"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9815817984832069,"14. Crowdsourcing and Research with Human Subjects
1077"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9821235102925244,"Question: For crowdsourcing experiments and research with human subjects, does the paper
1078"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9826652221018418,"include the full text of instructions given to participants and screenshots, if applicable, as
1079"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9832069339111592,"well as details about compensation (if any)?
1080"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9837486457204767,"Answer: [NA]
1081"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9842903575297941,"Justification: [NA]
1082"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9848320693391116,"Guidelines:
1083"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.985373781148429,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1084"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9859154929577465,"human subjects.
1085"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9864572047670639,"• Including this information in the supplemental material is fine, but if the main contri-
1086"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9869989165763814,"bution of the paper involves human subjects, then as much detail as possible should be
1087"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9875406283856988,"included in the main paper.
1088"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9880823401950163,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
1089"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9886240520043337,"or other labor should be paid at least the minimum wage in the country of the data
1090"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9891657638136512,"collector.
1091"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9897074756229686,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
1092"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9902491874322861,"Subjects
1093"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9907908992416035,"Question: Does the paper describe potential risks incurred by study participants, whether
1094"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.991332611050921,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
1095"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9918743228602384,"approvals (or an equivalent approval/review based on the requirements of your country or
1096"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9924160346695557,"institution) were obtained?
1097"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9929577464788732,"Answer: [NA]
1098"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9934994582881906,"Justification: [NA]
1099"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9940411700975081,"Guidelines:
1100"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9945828819068255,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1101"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.995124593716143,"human subjects.
1102"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9956663055254604,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
1103"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9962080173347779,"may be required for any human subjects research. If you obtained IRB approval, you
1104"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9967497291440953,"should clearly state this in the paper.
1105"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9972914409534128,"• We recognize that the procedures for this may vary significantly between institutions
1106"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9978331527627302,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
1107"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9983748645720477,"guidelines for their institution.
1108"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9989165763813651,"• For initial submissions, do not include any information that would break anonymity (if
1109"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9994582881906826,"applicable), such as the institution conducting the review.
1110"
