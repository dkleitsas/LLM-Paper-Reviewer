Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0010111223458038423,"Computational RNA design tasks are often posed as inverse problems, where
1"
ABSTRACT,0.0020222446916076846,"sequences are designed based on adopting a single desired secondary structure
2"
ABSTRACT,0.003033367037411527,"without considering 3D geometry and conformational diversity. We introduce
3"
ABSTRACT,0.004044489383215369,"gRNAde, a geometric RNA design pipeline operating on 3D RNA backbones to
4"
ABSTRACT,0.005055611729019211,"design sequences that explicitly account for structure and dynamics. Under the
5"
ABSTRACT,0.006066734074823054,"hood, gRNAde is a multi-state Graph Neural Network that generates candidate
6"
ABSTRACT,0.007077856420626896,"RNA sequences conditioned on one or more 3D backbone structures where the
7"
ABSTRACT,0.008088978766430738,"identities of the bases are unknown. On a single-state fixed backbone re-design
8"
ABSTRACT,0.00910010111223458,"benchmark of 14 RNA structures from the PDB identified by Das et al. [2010],
9"
ABSTRACT,0.010111223458038422,"gRNAde obtains higher native sequence recovery rates (56% on average) compared
10"
ABSTRACT,0.011122345803842264,"to Rosetta (45% on average), taking under a second to produce designs compared
11"
ABSTRACT,0.012133468149646108,"to the reported hours for Rosetta. We further demonstrate the utility of gRNAde on
12"
ABSTRACT,0.01314459049544995,"a new benchmark of multi-state design for structurally flexible RNAs, as well as
13"
ABSTRACT,0.014155712841253791,"zero-shot ranking of mutational fitness landscapes in a retrospective analysis of a
14"
ABSTRACT,0.015166835187057633,"recent RNA polymerase ribozyme structure. Open source code and tutorials are
15"
ABSTRACT,0.016177957532861477,"available at: anonymous.4open.science/r/geometric-rna-design
16"
INTRODUCTION,0.017189079878665317,"1
Introduction
17"
INTRODUCTION,0.01820020222446916,"Why RNA design? Historical efforts in computational drug discovery have focussed on designing
18"
INTRODUCTION,0.019211324570273004,"small molecule or protein-based medicines that either treat symptoms or counter the end stages
19"
INTRODUCTION,0.020222446916076844,"of disease processes. In recent years, there is a growing interest in designing new RNA-based
20"
INTRODUCTION,0.021233569261880688,"therapeutics that intervene earlier in disease processes to cut off disease-causing information flow
21"
INTRODUCTION,0.022244691607684528,"in the cell [Damase et al., 2021, Zhu et al., 2022]. Notable examples of RNA molecules at the
22"
INTRODUCTION,0.023255813953488372,"forefront of biotechnology today include mRNA vaccines [Metkar et al., 2024] and CRISPR-based
23"
INTRODUCTION,0.024266936299292215,"genomic medicine [Doudna and Charpentier, 2014]. Of particular interest for structure-based design
24"
INTRODUCTION,0.025278058645096056,"are ribozymes and riboswitches in the untranslated regions of mRNAs [Mandal and Breaker, 2004,
25"
INTRODUCTION,0.0262891809908999,"Leppek et al., 2018]. In addition to coding for proteins (such as the spike protein in the Covid vaccine),
26"
INTRODUCTION,0.027300303336703743,"naturally occurring mRNAs contain riboswitches that are responsible for cell-state dependent protein
27"
INTRODUCTION,0.028311425682507583,"expression of the mRNA. Riboswitches act by ‘switching’ their 3D structure from an unbound
28"
INTRODUCTION,0.029322548028311426,"conformation to a bound one in the presence of specific metabolites or small molecules. Rational
29"
INTRODUCTION,0.030333670374115267,"design of riboswitches will enable translation to be dependent on the presence or absence of partner
30"
INTRODUCTION,0.03134479271991911,"molecules, essentially acting as ‘on-off’ switches for highly targeted mRNA therapies in the future
31"
INTRODUCTION,0.032355915065722954,"[Felletti et al., 2016, Mustafina et al., 2019, Mohsen et al., 2023].
32"
INTRODUCTION,0.033367037411526794,"Challenges of RNA modelling. Despite the promises of RNA therapeutics, proteins have instead
33"
INTRODUCTION,0.034378159757330634,"been the primary focus in the 3D biomolecular modelling community. Availability of a large number
34"
INTRODUCTION,0.03538928210313448,"of protein structures from the PDB combined with advances in deep learning for structured data
35"
INTRODUCTION,0.03640040444893832,"[Bronstein et al., 2021, Duval et al., 2023] have revolutionized protein 3D structure prediction [Jumper
36"
INTRODUCTION,0.03741152679474216,"Multi-state
Graph Neural"
INTRODUCTION,0.03842264914054601,"Network
Encoder"
INTRODUCTION,0.03943377148634985,Sequence
INTRODUCTION,0.04044489383215369,Decoder
INTRODUCTION,0.041456016177957536,RNA Conformational
INTRODUCTION,0.042467138523761376,Ensemble
INTRODUCTION,0.043478260869565216,"Set of Backbone
Geometric Graphs"
INTRODUCTION,0.044489383215369056,"Extract
Backbones
GAGCGU..."
INTRODUCTION,0.0455005055611729,"RNA
Sequence"
INTRODUCTION,0.046511627906976744,Fixed backbone
INTRODUCTION,0.047522750252780584,re-design
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.04853387259858443,"3D roto-translations
node order
conformation order"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.04954499494438827,Equivariant to:
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.05055611729019211,"Figure 1: The gRNAde pipeline for 3D RNA inverse design. gRNAde is a generative model for
RNA sequence design conditioned on backbone 3D structure(s). gRNAde processes one or more RNA
backbone graphs (a conformational ensemble) via a multi-state GNN encoder which is equivariant to
3D roto-translation of coordinates as well as conformer order, followed by conformer order-invariant
pooling and autoregressive sequence decoding."
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.05156723963599596,"et al., 2021] and rational design [Dauparas et al., 2022, Watson et al., 2023]. Applications of deep
37"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.0525783619817998,"learning for computational RNA design are underexplored compared to proteins due to paucity of
38"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.05358948432760364,"3D structural data [Schneider et al., 2023]. Most tools for RNA design primarily focus on secondary
39"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.054600606673407485,"structure without considering 3D geometry [Churkin et al., 2018] and use non-learnt algorithms for
40"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.055611729019211326,"aligning 3D RNA fragments [Han et al., 2017, Yesselman et al., 2019], which can be restrictive due
41"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.056622851365015166,"to the hand-crafted nature of the heuristics used.
42"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.057633973710819006,"In addition to limited 3D data for training deep learning models, the key technical challenge is that
43"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.05864509605662285,"RNA is more dynamic than proteins. The same RNA can adopt multiple distinct conformational
44"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.05965621840242669,"states to create and regulate complex biological functions [Ganser et al., 2019, Hoetzel and Suess,
45"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.06066734074823053,"2022, Ken et al., 2023]. Computational RNA design pipelines must account for both the 3D geometric
46"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.06167846309403438,"structure and conformational flexibility of RNA to engineer new biological functions.
47"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.06268958543983821,"Our contributions. This paper introduces gRNAde, a geometric deep learning-based pipeline for
48"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.06370070778564206,"RNA inverse design conditioned on 3D structure, analogous to ProteinMPNN for proteins [Dauparas
49"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.06471183013144591,"et al., 2022]. As illustrated in Figure 1, gRNAde generates candidate RNA sequences conditioned
50"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.06572295247724974,"on one or more backbone 3D conformations, enabling both single- and multi-state fixed-backbone
51"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.06673407482305359,"sequence design.
52"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.06774519716885744,"We demonstrate the utility of gRNAde for the following design scenarios:
53"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.06875631951466127,"• Improved performance and speed over Rosetta. We compare gRNAde to Rosetta [Leman
54"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.06976744186046512,"et al., 2020], the state-of-the-art physically based tool for 3D RNA inverse design, for single-
55"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.07077856420626896,"state fixed backbone design of 14 RNA structures of interest from the PDB identified by Das
56"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.0717896865520728,"et al. [2010]. We obtain higher native sequence recovery rates with gRNAde (56% on average)
57"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.07280080889787664,"compared to Rosetta (45% on average). Additionally, gRNAde is significantly faster than Rosetta
58"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.07381193124368049,"for inference; e.g. sampling 100+ designs in 1 second for an RNA of 60 nucleotides on an A100
59"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.07482305358948432,"GPU, compared to the reported hours for Rosetta.
60"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.07583417593528817,"• Enables multi-state RNA design, which was previously not possible with Rosetta. gRNAde
61"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.07684529828109202,"with multi-state GNNs improves sequence recovery over an equivalent single-state model on
62"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.07785642062689585,"a benchmark of structurally flexible RNAs, especially for surface nucleotides which undergo
63"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.0788675429726997,"positional or secondary structural changes.
64"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.07987866531850354,"• Zero-shot learning of RNA fitness landscape. In a retrospective analysis of mutational fitness
65"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.08088978766430738,"landscape data for an RNA polymerase ribozyme [McRae et al., 2024], we show how gRNAde’s
66"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.08190091001011122,"perplexity, the likelihood of a sequence folding into a backbone structure, can be used to
67"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.08291203235591507,"rank mutants based on fitness in a zero-shot/unsupervised manner and outperforms random
68"
"D ROTO-TRANSLATIONS
NODE ORDER
CONFORMATION ORDER",0.0839231547017189,"mutagenesis for improving fitness over the wild type in low throughput scenarios.
69"
THE GRNADE PIPELINE,0.08493427704752275,"2
The gRNAde pipeline
70"
THE GRNADE PIPELINE,0.0859453993933266,"2.1
The 3D RNA inverse folding problem
71"
THE GRNADE PIPELINE,0.08695652173913043,"Figure 1 illustrates the RNA inverse folding problem: the task of designing new RNA sequences
72"
THE GRNADE PIPELINE,0.08796764408493428,"conditioned on a structural backbone. Given the 3D coordinates of a backbone structure, machine
73"
THE GRNADE PIPELINE,0.08897876643073811,"learning models must generate sequences that are likely to fold into that shape. The underlying
74"
THE GRNADE PIPELINE,0.08998988877654196,"assumption behind inverse folding (and rational biomolecule design) is that structure determines
75"
THE GRNADE PIPELINE,0.0910010111223458,"function [Huang et al., 2016]. To the best of our knowledge, gRNAde is the first explicitly multi-state
76"
THE GRNADE PIPELINE,0.09201213346814964,"inverse folding pipeline, allowing users to design sequences for backbone conformational ensembles
77"
THE GRNADE PIPELINE,0.09302325581395349,"(a set of 3D backbone structures) as opposed to a single structure.
78"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.09403437815975733,"2.2
RNA conformational ensembles as geometric multi-graphs
79"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.09504550050556117,"Featurization. The input to gRNAde is an RNA to be re-designed. For instance, this could be a
80"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.09605662285136501,"set of PDB files with 3D backbone structures for the given RNA (a conformational ensemble) and
81"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.09706774519716886,"the corresponding sequence of n nucleotides. As shown in Appendix Figure 11, gRNAde builds a
82"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.0980788675429727,"geometric graph representation for each input structure:
83"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.09908998988877654,"1. We start with a 3-bead coarse-grained representation of the RNA backbone, retaining the
84"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.10010111223458039,"coordinates for P, C4’, N1 (pyrimidine) or N9 (purine) for each nucleotide [Dawson et al., 2016].
85"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.10111223458038422,"This ‘pseudotorsional’ representation describes RNA backbones completely in most cases while
86"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.10212335692618807,"reducing the size of the torsional space to prevent overfitting [Wadley et al., 2007].
87"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.10313447927199192,"2. Each nucleotide i is assigned a node in the geometric graph with the 3D coordinate ⃗xi ∈R3
88"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.10414560161779575,"corresponding to the centroid of the 3 bead atoms. Random Gaussian noise with standard
89"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.1051567239635996,"deviation 0.1Å is added to coordinates during training to prevent overfitting on crystallisation
90"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.10616784630940344,"artifacts, following Dauparas et al. [2022]. Each node is connected by edges to its 32 nearest
91"
RNA CONFORMATIONAL ENSEMBLES AS GEOMETRIC MULTI-GRAPHS,0.10717896865520728,"neighbours as measured by the pairwise distance in 3D space, ∥⃗xi −⃗xj∥2.
92"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.10819009100101112,"3. Nodes are initialized with geometric features analogous to the featurization used in protein
93"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.10920121334681497,"inverse folding [Ingraham et al., 2019, Jing et al., 2020]: (a) forward and reverse unit vectors
94"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.1102123356926188,"along the backbone from the 5’ end to the 3’ end, (⃗xi+1 −⃗xi and ⃗xi −⃗xi−1); and (b) unit
95"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.11122345803842265,"vectors, distances, angles, and torsions from each C4’ to the corresponding P and N1/N9.
96"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.1122345803842265,"4. Edge features for each edge from node j to i are initialized as: (a) the unit vector from the
97"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.11324570273003033,"source to destination node, ⃗xj −⃗xi; (b) the distance in 3D space, ∥⃗xj −⃗xi∥2, encoded by 32
98"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.11425682507583418,"radial basis functions; and (c) the distance along the backbone, j −i, encoded by 32 sinusoidal
99"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.11526794742163801,"positional encodings.
100"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.11627906976744186,"Multi-graph representation. As described in the previous section, given a set of k (conformer)
101"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.1172901921132457,"structures in the input conformational ensemble, each RNA backbone is featurized as a separate
102"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.11830131445904954,"geometric graph G(k) = (A(k), S(k), ⃗V (k)) with the scalar features S(k) ∈Rn×f, vector features
103"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.11931243680485339,"⃗V (k) ∈Rn×f ′×3, and A(k), an n × n adjacency matrix. For clear presentation and without loss of
104"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.12032355915065723,"generality, we omit edge features and use f, f ′ to denote scalar/vector feature channels.
105"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.12133468149646107,"The input to gRNAde is thus a set of geometric graphs {G(1), . . . , G(k)} which is merged into what we
106"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.12234580384226491,"term a ‘multi-graph’ representation of the conformational ensemble, M = (A, S, ⃗V ), by stacking the
107"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.12335692618806876,"set of scalar features {S(1), . . . , S(k)} into one tensor S ∈Rn×k×f along a new axis for the set size
108"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.1243680485338726,"k. Similarly, the set of vector features {⃗V (1), . . . , ⃗V (k)} is stacked into one tensor ⃗V ∈Rn×k×f ′×3.
109"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.12537917087967643,"Lastly, the set of adjacency matrices {A(1), . . . , A(k)} are merged via a union ∪into one single joint
110"
NODES ARE INITIALIZED WITH GEOMETRIC FEATURES ANALOGOUS TO THE FEATURIZATION USED IN PROTEIN,0.1263902932254803,"adjacency matrix A.
111"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.12740141557128412,"2.3
Multi-state GNN for representation learning on conformational ensembles
112"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.12841253791708795,"The gRNAde model, illustrated in Appendix Figure 12, processes one or more RNA backbone graphs
113"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.12942366026289182,"via a multi-state GNN encoder which is equivariant to 3D roto-translation of coordinates as well as to
114"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.13043478260869565,"the ordering of conformers, followed by conformer order-invariant pooling and sequence decoding.
115"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.13144590495449948,"We describe each component in the following sections.
116"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.13245702730030334,"Multi-state GNN encoder. When representing conformational ensembles as a multi-graph, each
117"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.13346814964610718,"node feature tensor contains three axes: (#nodes, #conformations, feature channels). We perform
118"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.134479271991911,"message passing on the multi-graph adjacency to independently process each conformer, while
119"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.13549039433771487,"maintaining permutation equivariance of the updated feature tensors along both the first (#nodes)
120"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.1365015166835187,"and second (#conformations) axes. This works by operating on only the feature channels axis and
121"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.13751263902932254,"generalising the PyTorch Geometric [Fey and Lenssen, 2019] message passing class to account for
122"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.1385237613751264,"the extra conformations axis; see Appendix Figure 14 and the pseudocode for details.
123"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.13953488372093023,"We use multiple rotation-equivariant GVP-GNN [Jing et al., 2020] layers to update scalar features
124"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.14054600606673406,"si ∈Rk×f and vector features ⃗vi ∈Rk×f ′×3 for each node i:
125"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.14155712841253792,"mi, ⃗mi :=
X"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.14256825075834176,"j∈Ni
MSG
 
(si, ⃗vi) , (sj, ⃗vj) , eij

,
(1)"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.1435793731041456,"s′
i, ⃗v′
i := UPD
 
(si, ⃗vi) , (mi, ⃗mi)

,
(2)"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.14459049544994945,"where MSG, UPD are Geometric Vector Perceptrons, a generalization of MLPs to take tuples of
126"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.14560161779575329,"scalar and vector features as input and apply O(3)-equivariant non-linear updates. The overall GNN
127"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.14661274014155712,"encoder is SO(3)-equivariant due to the use of reflection-sensitive input features (dihedral angles)
128"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.14762386248736098,"combined with O(3)-equivariant GVP-GNN layers.
129"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.1486349848331648,"Our multi-state GNN encoder is easy to implement in any message passing framework and can be
130"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.14964610717896865,"used as a plug-and-play extension for any geometric GNN pipeline to incorporate the multi-state
131"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.1506572295247725,"inductive bias. It serves as an elegant alternative to batching all the conformations, which we found
132"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.15166835187057634,"required major alterations to message passing and pooling depending on downstream tasks.
133"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.15267947421638017,"Conformation order-invariant pooling. The final encoder representations in gRNAde account for
134"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.15369059656218403,"multi-state information while being invariant to the permutation of the conformational ensemble. To
135"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.15470171890798787,"achieve this, we perform a Deep Set pooling [Zaheer et al., 2017] over the conformations axis after the
136"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.1557128412537917,"final encoder layer to reduce S ∈Rn×k×f and ⃗V ∈Rn×k×f ′×3 to S′ ∈Rn×f and ⃗V ′ ∈Rn×f ′×3:
137"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.15672396359959556,"S′, ⃗V ′ := 1 k k
X i=1"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.1577350859453994,"
S[: , i], ⃗V [: , i]

.
(3)"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.15874620829120323,"A simple sum or average pooling does not introduce any new learnable parameters to the pipeline and
138"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.1597573306370071,"is flexible to handle a variable number of conformations, enabling both single-state and multi-state
139"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.16076845298281092,"design with the same model.
140"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.16177957532861476,"Sequence decoding and loss function.
We feed the final encoder representations after pooling,
141"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.16279069767441862,"S′, ⃗V ′, to autoregressive GVP-GNN decoder layers to predict the probability of the four possible base
142"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.16380182002022245,"identities (A, G, C, U) for each node/nucleotide. Decoding proceeds according to the RNA sequence
143"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.16481294236602628,"order from the 5’ end to 3’ end. gRNAde is trained in a self-supervised manner by minimising a
144"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.16582406471183014,"cross-entropy loss (with label smoothing value of 0.05) between the predicted probability distribution
145"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.16683518705763398,"and the ground truth identity for each base. During training, we use autoregressive teacher forcing
146"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.1678463094034378,"[Williams and Zipser, 1989] where the ground truth base identity is fed as input to the decoder at
147"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.16885743174924167,"each step, encouraging the model to stay close to the ground-truth sequence.
148"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.1698685540950455,"Sampling. When using gRNAde for inference and designing new sequences, we iteratively sample
149"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.17087967644084934,"the base identity for a given nucleotide from the predicted conditional probability distribution,
150"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.1718907987866532,"given the partially designed sequence up until that nucleotide/decoding step. We can modulate the
151"
MULTI-STATE GNN FOR REPRESENTATION LEARNING ON CONFORMATIONAL ENSEMBLES,0.17290192113245703,"smoothness or sharpness of the probability distribution by using a temperature parameter.
152"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.17391304347826086,"2.4
Evaluation metrics for designed sequences
153"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.17492416582406473,"In principle, inverse folding models can be sampled from to obtain a large number of designed
154"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.17593528816986856,"sequences for a given backbone structure. Thus, in-silico metrics to determine which sequences are
155"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.1769464105156724,"useful and which ones to prioritise in wet lab experiments are a critical part of the overall pipeline. We
156"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.17795753286147623,"currently use the following metrics to evaluate gRNAde’s designs, visualised in Appendix Figure 13:
157"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.1789686552072801,"• Native sequence recovery, which is the average percentage of native (ground truth) nucleotides
158"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.17997977755308392,"correctly recovered in the sampled sequences. Recovery is the most widely used metric for
159"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.18099089989888775,"biomolecule inverse design [Dauparas et al., 2022] but can be misleading in the case of RNAs
160"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.1820020222446916,"where alternative nucleotide base pairings can form the same structural patterns.
161"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.18301314459049545,"• Secondary structure self-consistency score, where we ‘forward fold’ the sampled sequences
162"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.18402426693629928,"using a secondary structure prediction tool (we used EternaFold [Wayment-Steele et al., 2022])
163"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.18503538928210314,"and measure the average Matthew’s Correlation Coefficient (MCC) to the groundtruth secondary
164"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.18604651162790697,"structure, represented as a binary adjacency matrix. MCC values range between -1 and +1,
165"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.1870576339737108,"where +1 represents a perfect prediction, 0 an average random prediction and -1 an inverse
166"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.18806875631951467,"prediction. This measures how well the designs recover base pairing patterns.
167"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.1890798786653185,"• Tertiary structure self-consistency scores, where we ‘forward fold’ the sampled sequences
168"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.19009100101112233,"using a 3D structure prediction tool (we used RhoFold [Shen et al., 2022]) and compute the
169"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.1911021233569262,"average RMSD, TM-score and GDT_TS to the groundtruth C4’ coordinates to measure how
170"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.19211324570273003,"well the designs recover global structural similarity and 3D conformations.
171"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.19312436804853386,"• Perplexity, which can be thought of as the average number of bases that the model is selecting
172"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.19413549039433772,"from for each nucleotide. Formally, perplexity is the average exponential of the negative
173"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.19514661274014156,"log-likelihood of the sampled sequences. A perfect model would have perplexity of 1, while
174"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.1961577350859454,"a perplexity of 4 means that the model is making random predictions (the model outputs a
175"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.19716885743174925,"uniform probability over 4 possible bases). Perplexity does not require a ground truth structure
176"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.19817997977755308,"to calculate, and can also be used for ranking sequences as it is the model’s estimate of the
177"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.19919110212335692,"compatibility of a sequence with the input backbone structure.
178"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.20020222446916078,"Significance and limitations. Self-consistency metrics, termed ‘designability’ (eg. scRMSD≤2Å),
179"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.2012133468149646,"as well as perplexity have been found to correlate with experimental success in protein design
180"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.20222446916076844,"[Watson et al., 2023]. While precise designability thresholds are yet to be established for RNA,
181"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.2032355915065723,"pairs of structures with TM-score≥0.45 or GDT_TS≥0.5 are known to correspond to roughly the
182"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.20424671385237614,"same fold [Zhang et al., 2022]. Another major limitation for in-silico evaluation of 3D RNA design
183"
EVALUATION METRICS FOR DESIGNED SEQUENCES,0.20525783619817997,"compared to proteins is the relatively worse state of structure prediction tools [Schneider et al., 2023].
184"
EXPERIMENTAL SETUP,0.20626895854398383,"3
Experimental Setup
185"
EXPERIMENTAL SETUP,0.20728008088978767,"3D RNA structure dataset. We create a machine learning-ready dataset for RNA inverse design
186"
EXPERIMENTAL SETUP,0.2082912032355915,"using RNASolo [Adamczyk et al., 2022], a novel repository of RNA 3D structures extracted from
187"
EXPERIMENTAL SETUP,0.20930232558139536,"solo RNAs, protein-RNA complexes, and DNA-RNA hybrids in the PDB. We used structures at
188"
EXPERIMENTAL SETUP,0.2103134479271992,"resolution ≤4.0Å resulting in 4,223 unique RNA sequences for which a total of 12,011 structures
189"
EXPERIMENTAL SETUP,0.21132457027300303,"are available (RNASolo date cutoff: 31 October 2023). Dataset statistics are available in Appendix
190"
EXPERIMENTAL SETUP,0.2123356926188069,"Figure 15, illustrating the diversity of our dataset in terms of sequence length, number of structures
191"
EXPERIMENTAL SETUP,0.21334681496461072,"per sequence, as well as structural variations among conformations per sequence.
192"
EXPERIMENTAL SETUP,0.21435793731041455,"Structural clustering. In order to ensure that we evaluate gRNAde’s generalization ability to novel
193"
EXPERIMENTAL SETUP,0.21536905965621841,"RNAs, we cluster the 4,223 unique RNAs into groups based on structural similarity. We use US-align
194"
EXPERIMENTAL SETUP,0.21638018200202225,"[Zhang et al., 2022] with a similarity threshold of TM-score >0.45 for clustering, and ensure that
195"
EXPERIMENTAL SETUP,0.21739130434782608,"we train, validate and test gRNAde on structurally dissimilar clusters (see next paragraph). We also
196"
EXPERIMENTAL SETUP,0.21840242669362994,"provide utilities for clustering based on sequence homology using CD-HIT [Fu et al., 2012], which
197"
EXPERIMENTAL SETUP,0.21941354903943378,"leads to splits containing biologically dissimilar clusters of RNAs.
198"
EXPERIMENTAL SETUP,0.2204246713852376,"Splits to evaluate generalization. After clustering, we split the RNAs into training (∼4000 samples),
199"
EXPERIMENTAL SETUP,0.22143579373104147,"validation and test sets (100 samples each) to evaluate two different design scenarios:
200"
EXPERIMENTAL SETUP,0.2224469160768453,"1. Single-state split.
This split is used to fairly evaluate gRNAde for single-state design on a
201"
EXPERIMENTAL SETUP,0.22345803842264914,"set of RNA structures of interest from the PDB identified by Das et al. [2010], which mainly
202"
EXPERIMENTAL SETUP,0.224469160768453,"includes riboswitches, aptamers, and ribozymes. We identify the structural clusters belonging to
203"
EXPERIMENTAL SETUP,0.22548028311425683,"the RNAs identified in Das et al. [2010] and add all the RNAs in these clusters to the test set
204"
EXPERIMENTAL SETUP,0.22649140546006066,"(100 samples). The remaining clusters are randomly added to the training and validation splits.
205"
EXPERIMENTAL SETUP,0.2275025278058645,"2. Multi-state split.
This split is used to test gRNAde’s ability to design RNA with multiple
206"
EXPERIMENTAL SETUP,0.22851365015166836,"distinct conformational states. We order the structural clusters based on median intra-sequence
207"
EXPERIMENTAL SETUP,0.2295247724974722,"RMSD among available structures within the cluster1. The top 100 samples from clusters with
208"
EXPERIMENTAL SETUP,0.23053589484327602,"the highest median intra-sequence RMSD are added to the test set. The next 100 samples are
209"
EXPERIMENTAL SETUP,0.23154701718907988,"added to the validation set and all remaining samples are used for training.
210"
EXPERIMENTAL SETUP,0.23255813953488372,"Validation and test samples come from clusters with at most 5 unique sequences, in order to ensure
211"
EXPERIMENTAL SETUP,0.23356926188068755,"diversity. Any samples that were not assigned clusters are directly appended to the training set. We
212"
EXPERIMENTAL SETUP,0.2345803842264914,"1For each RNA sequence, we compute the pairwise C4’ RMSD among all available structures. We then
compute the median RMSD across all sequences within each structural cluster."
EXPERIMENTAL SETUP,0.23559150657229525,ViennaRNA
EXPERIMENTAL SETUP,0.23660262891809908,(2D only)
EXPERIMENTAL SETUP,0.23761375126390294,"FARNA
Rosetta
gRNAde
0.00 0.25 0.50 0.75 1.00"
EXPERIMENTAL SETUP,0.23862487360970677,Native sequence recovery 0.269 0.321 0.450 0.568
EXPERIMENTAL SETUP,0.2396359959555106,(a) gRNAde outperforms Rosetta.
EXPERIMENTAL SETUP,0.24064711830131447,"0.00
0.25
0.50
0.75
1.00
Rosetta seq. recovery 0.00 0.25 0.50 0.75 1.00"
EXPERIMENTAL SETUP,0.2416582406471183,gRNAde seq. recovery 1.1 1.2 1.3 1.4 1.5 1.6
EXPERIMENTAL SETUP,0.24266936299292213,gRNAde perplexity
EXPERIMENTAL SETUP,0.243680485338726,(b) gRNAde’s perplexity correlates with recovery.
EXPERIMENTAL SETUP,0.24469160768452983,"Figure 2: gRNAde compared to Rosetta for single-state design. (a) We benchmark native sequence
recovery of gRNAde, Rosetta, FARNA and ViennaRNA on 14 RNA structures of interest identified by
Das et al. [2010]. gRNAde obtains higher native sequence recovery rates (56% on average) compared
to Rosetta (45%). (b) Sequence recovery per sample for Rosetta and gRNAde, shaded by gRNAde’s
perplexity for each sample. gRNAde’s perplexity is correlated with native sequence recovery for
designed sequences. Full results are available in Appendix Table 2."
EXPERIMENTAL SETUP,0.24570273003033366,"also directly add very large RNAs (> 1000 nts) to the training set, as it is unlikely that we want to
213"
EXPERIMENTAL SETUP,0.24671385237613752,"design very large RNAs. We exclude very short RNA strands (< 10 nts).
214"
EXPERIMENTAL SETUP,0.24772497472194135,"Evaluation metrics. For a given data split, we evaluate models on the held-out test set by designing
215"
EXPERIMENTAL SETUP,0.2487360970677452,"16 sequences (sampled at temperature 0.1) for each test data point and computing averages for each of
216"
EXPERIMENTAL SETUP,0.24974721941354905,"the metrics described in Section 2.4: native sequence recovery, structural self-consistency scores and
217"
EXPERIMENTAL SETUP,0.25075834175935285,"perplexity. We employ early stopping by reporting test set performance for the model checkpoint for
218"
EXPERIMENTAL SETUP,0.2517694641051567,"the epoch with the best validation set recovery. Standard deviations are reported across 3 consistent
219"
EXPERIMENTAL SETUP,0.2527805864509606,"random seeds for all models.
220"
EXPERIMENTAL SETUP,0.2537917087967644,"Hyperparameters. All models use 4 encoder and 4 decoder GVP-GNN layers, with 128 scalar/16
221"
EXPERIMENTAL SETUP,0.25480283114256824,"vector node features, 64 scalar/4 vector edge features, and drop out probability 0.5, resulting in
222"
EXPERIMENTAL SETUP,0.2558139534883721,"2,147,944 trainable parameters. All models are trained for a maximum of 50 epochs using the Adam
223"
EXPERIMENTAL SETUP,0.2568250758341759,"optimiser with an initial learning rate of 0.0001, which is reduced by a factor 0.9 when validation
224"
EXPERIMENTAL SETUP,0.25783619817997977,"performance plateaus with patience of 5 epochs. Ablation studies of key modelling decisions are
225"
EXPERIMENTAL SETUP,0.25884732052578363,"available in Appendix Table 1.
226"
RESULTS,0.25985844287158744,"4
Results
227"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2608695652173913,"4.1
Single-state RNA design benchmark
228"
SINGLE-STATE RNA DESIGN BENCHMARK,0.26188068756319516,"We set out to compare gRNAde to Rosetta, a state-of-the-art physically based toolkit for biomolecular
229"
SINGLE-STATE RNA DESIGN BENCHMARK,0.26289180990899896,"modelling and design [Leman et al., 2020]. We reproduced the benchmark setup from Das et al.
230"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2639029322548028,"[2010] for Rosetta’s fixed backbone RNA sequence design workflow on 14 RNA structures of
231"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2649140546006067,"interest from the PDB, which mainly includes riboswitches, aptamers, and ribozymes (full listing in
232"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2659251769464105,"Table 2). We trained gRNAde on the single-state split detailed in Section 3, explicitly excluding the
233"
SINGLE-STATE RNA DESIGN BENCHMARK,0.26693629929221435,"14 RNAs as well as any structurally similar RNAs in order to ensure that we fairly evaluate gRNAde’s
234"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2679474216380182,"generalization abilities vs. Rosetta.
235"
SINGLE-STATE RNA DESIGN BENCHMARK,0.268958543983822,"gRNAde improves sequence recovery over Rosetta. In Figure 2, we compare gRNAde’s native
236"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2699696663296259,"sequence recovery for single-state design with numbers taken from Das et al. [2010] for Rosetta,
237"
SINGLE-STATE RNA DESIGN BENCHMARK,0.27098078867542974,"FARNA (a predecessor of Rosetta), and ViennaRNA (the most popular 2D inverse folding method).
238"
SINGLE-STATE RNA DESIGN BENCHMARK,0.27199191102123355,"gRNAde has higher recovery of 56% on average compared to 45% for Rosetta, 32% for FARNA, and
239"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2730030333670374,"27% for ViennaRNA. See Appendix Table 2 for per-RNA results.
240"
SINGLE-STATE RNA DESIGN BENCHMARK,0.27401415571284127,"gRNAde is significantly faster than Rosetta. In addition to superior sequence recovery, gRNAde
241"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2750252780586451,"is significantly faster than Rosetta for high-throughout design pipelines. Training gRNAde from
242"
SINGLE-STATE RNA DESIGN BENCHMARK,0.27603640040444893,"scratch takes roughly 2–6 hours on a single A100 GPU, depending on the exact hyperparameters.
243"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2770475227502528,"Once trained, gRNAde can design hundreds of sequences for backbones with hundreds of nucleotides
244"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2780586450960566,"Design 1:
perplexity: 1.310
recovery: 0.591 (27 edits)
sc2D = 0.923, scRMSD = 1.384
scTM = 0.831, scGDT = 0.830"
SINGLE-STATE RNA DESIGN BENCHMARK,0.27906976744186046,"Design 2:
perplexity: 1.382
recovery: 0.409 (37 edits)
sc2D = 0.922, scRMSD = 2.125
scTM = 0.687, scGDT = 0.678"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2800808897876643,"Design 3:
perplexity: 1.425
recovery: 0.515 (30 edits)
sc2D = 0.923, scRMSD = 3.213
scTM = 0.512, scGDT = 0.526"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2810920121334681,"Figure 3: Cherry-picked designs for Guanine riboswitch aptamer (PDB: 4FE5). We show the
RhoFold-predicted 3D structure in colour overlaid on the groundtruth structure in grey. Designs
recover the base pairing patterns and tertiary structure of the RNA, as measured by high self-
consistency score. gRNAde’s perplexity is correlated well with 3D self-consistency scores and can
be useful for ranking designs. More design visualisations are available in Appendix C."
SINGLE-STATE RNA DESIGN BENCHMARK,0.282103134479272,"in ∼1 second with GPU acceleration. On the other hand, Rosetta takes order of hours to produce
245"
SINGLE-STATE RNA DESIGN BENCHMARK,0.28311425682507585,"a single design due to performing expensive Monte Carlo optimisations2. Deep learning methods
246"
SINGLE-STATE RNA DESIGN BENCHMARK,0.28412537917087965,"like gRNAde are arguably easier to use since no expert customization is required and setup is easier
247"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2851365015166835,"compared to Rosetta [Dauparas et al., 2022], potentially making RNA design more broadly accessible.
248"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2861476238624874,"gRNAde’s perplexity correlates with sequence and structural recovery. In Figure 2b, we plot
249"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2871587462082912,"native sequence recovery per sample for Rosetta vs. gRNAde, shaded by gRNAde’s average perplexity
250"
SINGLE-STATE RNA DESIGN BENCHMARK,0.28816986855409504,"for each sample. Perplexity is an indicator of the model’s confidence in its own prediction (lower
251"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2891809908998989,"perplexity implies higher confidence) and appears to be correlated with native sequence recovery.
252"
SINGLE-STATE RNA DESIGN BENCHMARK,0.2901921132457027,"Additionally, visualisations of gRNAde’s designs for a riboswitch in Figure 3 show that perplexity
253"
SINGLE-STATE RNA DESIGN BENCHMARK,0.29120323559150657,"is also correlated with structural self-consistency scores. In the subsequent Section 4.3, we further
254"
SINGLE-STATE RNA DESIGN BENCHMARK,0.29221435793731043,"demonstrate the utility of gRNAde’s perplexity for zero-shot ranking of RNA fitness landscapes.
255"
MULTI-STATE RNA DESIGN BENCHMARK,0.29322548028311424,"4.2
Multi-state RNA design benchmark
256"
MULTI-STATE RNA DESIGN BENCHMARK,0.2942366026289181,"Structured RNAs often adopt multiple distinct conformational states to perform biological functions
257"
MULTI-STATE RNA DESIGN BENCHMARK,0.29524772497472196,"[Ken et al., 2023]. For instance, riboswitches adopt at least two distinct functional conformations: a
258"
MULTI-STATE RNA DESIGN BENCHMARK,0.29625884732052576,"ligand bound (holo) and unbound (apo) state, which helps them regulate and control gene expression
259"
MULTI-STATE RNA DESIGN BENCHMARK,0.2972699696663296,"[Stagno et al., 2017]. If we were to attempt single-state inverse design for such RNAs, each backbone
260"
MULTI-STATE RNA DESIGN BENCHMARK,0.2982810920121335,"structure may lead to a different set of sampled sequences. It is not obvious how to select the
261"
MULTI-STATE RNA DESIGN BENCHMARK,0.2992922143579373,"input backbone as well as designed sequence when using single-state models for multi-state design.
262"
MULTI-STATE RNA DESIGN BENCHMARK,0.30030333670374115,"gRNAde’s multi-state GNN, descibed in Section 2.3, directly ‘bakes in’ the multi-state nature of
263"
MULTI-STATE RNA DESIGN BENCHMARK,0.301314459049545,"RNA into the architecture and designs sequences explicitly conditioned on multiple states.
264"
MULTI-STATE RNA DESIGN BENCHMARK,0.3023255813953488,"In order to evaluate gRNAde’s multi-state design capabilities, we trained equivalent single-state and
265"
MULTI-STATE RNA DESIGN BENCHMARK,0.3033367037411527,"multi-state gRNAde models on the multi-state split detailed in Section 3, where the validation and
266"
MULTI-STATE RNA DESIGN BENCHMARK,0.30434782608695654,"test sets contain progressively more structurally flexible RNAs as measured by median RMSD among
267"
MULTI-STATE RNA DESIGN BENCHMARK,0.30535894843276035,"multiple available states for an RNA.
268"
MULTI-STATE RNA DESIGN BENCHMARK,0.3063700707785642,"Multi-state gRNAde boosts sequence recovery. In Figure 4a, we compared a single-state variant
269"
MULTI-STATE RNA DESIGN BENCHMARK,0.30738119312436807,"of gRNAde with otherwise equivalent multi-state models (with up to 3 and 5 states, respectively) in
270"
MULTI-STATE RNA DESIGN BENCHMARK,0.3083923154701719,"terms of native sequence recovery. Multi-state variants show marginal improvements, overall. As a
271"
MULTI-STATE RNA DESIGN BENCHMARK,0.30940343781597573,"caveat, it is worth noting that multi-state models consume more GPU memory than an equivalent
272"
MULTI-STATE RNA DESIGN BENCHMARK,0.3104145601617796,"single-state model during mini-batch training (approximate peak GPU usage for max. number of
273"
MULTI-STATE RNA DESIGN BENCHMARK,0.3114256825075834,"states = 1: 12GB, 3: 28GB, 5: 50GB on a single A100 with at most 3000 total nodes in a mini-batch).
274"
MULTI-STATE RNA DESIGN BENCHMARK,0.31243680485338726,"2While we have not run Rosetta ourselves, we note that its documentation states that “runs on RNA backbones
longer than ∼ten nucleotides take many minutes or hours”."
STATE,0.3134479271991911,1 state
STATES,0.31445904954499493,3 states
STATES,0.3154701718907988,5 states 0.00 0.25 0.50 0.75 1.00
STATES,0.31648129423660265,Native sequence recovery
STATES,0.31749241658240646,"0.455
0.469
0.484"
STATES,0.3185035389282103,(a) Per-sample sequence recovery
STATES,0.3195146612740142,"0.0
0.5
1.0"
STATES,0.320525783619818,Nucleotide Paired Probability 0.00 0.25 0.50 0.75 1.00
STATES,0.32153690596562184,Native sequence recovery
STATES,0.3225480283114257,"0
200
400"
STATES,0.3235591506572295,Nucleotide SASA
STATES,0.32457027300303337,"0
10
20
Nucleotide RMSD (A)"
STATES,0.32558139534883723,gRNAde model
STATE,0.32659251769464104,"1 state
3 states
5 states"
STATE,0.3276036400404449,(b) Per-nucleotide recovery vs. structural flexibility measures
STATE,0.32861476238624876,"Figure 4: Multi-state design benchmark. (a) Multi-state gRNAde show marginal improvement
over an equivalent single-state model in terms of average per-sample sequence recovery over all test
RNAs. (b) When plotting sequence recovery per-nucleotide, multi-state gRNAde improves over a
single-state model for structurally flexible regions of RNAs, as characterised by nucleotides that tend
to undergo changes in base pairing (left), nucleotides with greater average solvent accessible surface
area (centre), and nucleotides with higher average RMSD (right) across multiple states. Marginal
histograms in blue show the distribution of values. We plot performance for one consistent random
seed across all models; collated results and ablations are available in Appendix Table 1."
STATE,0.32962588473205257,"Improved recovery in structurally flexible regions.
In Figure 4b, we evaluated gRNAde’s
275"
STATE,0.3306370070778564,"multi-state sequence recovery at a fine-grained, per-nucleotide level. Multi-state GNNs improve
276"
STATE,0.3316481294236603,"sequence recovery over the single-state variant on structurally flexible nucleotides, as characterised
277"
STATE,0.3326592517694641,"by undergoing changes in base pairing/secondary structure, higher average RMSD between 3D
278"
STATE,0.33367037411526795,"coordinates across states, and larger solvent accessible surface area.
279"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3346814964610718,"4.3
Zero-shot ranking of RNA fitness landscape
280"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3356926188068756,"Lastly, we explored the use of gRNAde as a zero-shot ranker of mutants in RNA engineering
281"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3367037411526795,"campaigns. Given the backbone structure of a wild type RNA of interest as well as a candidate set of
282"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.33771486349848334,"mutant sequences, we can compute gRNAde’s perplexity of whether a given sequence folds into the
283"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.33872598584428715,"backbone structure. Perplexity is inversely related to the likelihood of a sequence conditioned on a
284"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.339737108190091,"structure, as described in Section 2.4. We can then rank sequences based on how ‘compatible’ they
285"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.34074823053589487,"are with the backbone structure in order to select a subset to be experimentally validated in wet labs.
286"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3417593528816987,"Retrospective analysis on ribozyme fitness landscape. A recent study by McRae et al. [2024]
287"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.34277047522750254,"determined a cryo-EM structure of a dimeric RNA polymerase ribozyme at 5Å resolution3, along
288"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3437815975733064,"with fitness landscapes of ∼75K mutants for the catalytic subunit 5TU and ∼48K mutants for the
289"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3447927199191102,"scaffolding subunit t1. We design a retrospective study using this data of (sequence, fitness value)
290"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.34580384226491406,"pairs where we simulate an RNA engineering campaign with the aim of improving catalytic subunit
291"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3468149646107179,"fitness over the wild type 5TU sequence.
292"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.34782608695652173,"We consider various design budgets ranging from hundreds to thousands of sequences selected for
293"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3488372093023256,"experimental validation, and compare 4 unsupervised approaches for ranking/selecting variants: (1)
294"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.34984833164812945,"random choice from all ∼75,000 sequences; (2) random choice from all 449 single mutant sequences;
295"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.35085945399393326,"(3) random choice from all single and double mutant sequences (as sequences with higher mutation
296"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3518705763397371,"order tend to be less fit); and (4) negative gRNAde perplexity (lower perplexity is better). For each
297"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3528816986855409,"design budget and ranking approach, we compute the expected maximum change in fitness over the
298"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3538928210313448,"wild type that could be achieved by screening as many variants as allowed in the given design budget.
299"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.35490394337714865,"We run 10,000 simulations to compute confidence intervals for the 3 random baselines.
300"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.35591506572295245,"gRNAde outperforms random baselines in low design budget scenarios. Figure 5 illustrates the
301"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3569261880687563,"results of our retrospective study. At low design budgets of up to hundreds of sequences, which are
302"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3579373104145602,"relevant in the case of a low throughput fitness screening assay, gRNAde outperforms all random
303"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.358948432760364,"baselines in terms of the maximum change in fitness over the wild type. The top 10 mutants as ranked
304"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.35995955510616784,"by gRNAde contain a sequence with 4-fold improved fitness, while the top 200 leads to a 5-fold
305"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3609706774519717,"improvement. Note that gRNAde is used zero-shot here, i.e. it was not fine-tuned on any assay data.
306"
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3619817997977755,"3This RNA was not present in gRNAde’s training data, which contains structures at ≤4.0Å resolution."
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.36299292214357937,1st best (fit.: 2.88)
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3640040444893832,2nd best (fit.: 2.40)
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.36501516683518703,5th best (fit.: 2.23)
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3660262891809909,10th best (fit.: 1.96)
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.36703741152679475,20th best (fit.: 1.61)
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.36804853387259856,50th best (fit.: 1.35)
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3690596562184024,wildtype
ZERO-SHOT RANKING OF RNA FITNESS LANDSCAPE,0.3700707785642063,"1
10
50
100
200
449
1500
5000
10493
Selected sequences for assaying"
X,0.3710819009100101,"0x
1x
0x"
X,0.37209302325581395,2x
X,0.3731041456016178,4x
X,0.3741152679474216,6x
X,0.3751263902932255,8x
X,0.37613751263902934,10x
X,0.37714863498483314,12x
X,0.378159757330637,14x
X,0.37917087967644086,16x
X,0.38018200202224467,18x
X,0.38119312436804853,Expected 'max' fold change over WT
X,0.3822042467138524,"Max Fitness by Sample Size and Condition (n=74,943; simulations=10,000)"
X,0.3832153690596562,Condition
X,0.38422649140546006,"random
n_mut==1
n_mut<=2
gRNAde
0.00
0.69 1.39 1.79 2.08 2.30 2.48 2.64 2.77 2.89"
X,0.3852376137512639,Fitness
X,0.3862487360970677,"Figure 5: Retrospective study of gRNAde for ranking ribozyme mutant fitness.
Using the
backbone structure and mutational fitness landscape data from an RNA polymerase ribozyme [McRae
et al., 2024], we retrospectively analyse how well we can rank variants at multiple design budgets
using random selection vs. gRNAde’s perplexity for mutant sequences conditioned on the backbone
structure (catalytic subunit 5TU). Note that gRNAde is used zero-shot here, i.e. it was not fine-tuned
on any assay data. For stochastic strategies, bars indicate median values, and error bars indicate
the interquartile range estimated from 10,000 simulations per strategy and design budget. At low
throughput design budgets of up to ∼500 sequences, selecting mutants using gRNAde outperforms
random baselines in terms of the expected maximum improvement in fitness over the wild type. In
particular, gRNAde performs better than single site saturation mutagenesis, even when all single
mutants are explored (total of 449 single mutants, 10,493 double mutants for the catalytic subunit
5TU in McRae et al. [2024]). See Appendix Figure 10 for results on scaffolding subunit t1."
X,0.3872598584428716,"Perspective.
Overall, it is promising that gRNAde’s perplexity correlates with experimental
307"
X,0.38827098078867545,"fitness measurements out-of-the-box (zero-shot) and can be a useful ranker of mutant fitness in
308"
X,0.38928210313447925,"our retrospective study. In realistic design scenarios, improvements could likely be obtained by
309"
X,0.3902932254802831,"fine-tuning gRNAde on a low amount of experimental fitness data. For example, latent features from
310"
X,0.391304347826087,"gRNAde may be finetuned or used as input to a prediction head with supervised learning on fitness
311"
X,0.3923154701718908,"landscape data. This study acts as a sanity check before committing to wet lab validation of gRNAde
312"
X,0.39332659251769464,"designs. We see random mutagenesis and directed evolution-based approaches as complementary to
313"
X,0.3943377148634985,"de-novo design and inverse folding approaches like gRNAde. Random mutagenesis can be thought
314"
X,0.3953488372093023,"of as local exploration around a wild type sequence, optimising fitness within an ‘island’ of activity.
315"
X,0.39635995955510617,"Structure-based design approaches are akin to global jumps in sequence space, with the potential to
316"
X,0.39737108190091003,"find new islands further away from the wild type [Huang et al., 2016].
317"
CONCLUSION,0.39838220424671383,"5
Conclusion
318"
CONCLUSION,0.3993933265925177,"We introduce gRNAde, a geometric deep learning pipeline for RNA sequence design conditioned
319"
CONCLUSION,0.40040444893832156,"on one or more 3D backbone structures. gRNAde is superior to the physically based Rosetta for 3D
320"
CONCLUSION,0.40141557128412536,"RNA inverse folding in terms of performance, inference speed, and ease of use. Further, gRNAde
321"
CONCLUSION,0.4024266936299292,"enables explicit multi-state design for structurally flexible RNAs which was previously not possible
322"
CONCLUSION,0.4034378159757331,"with Rosetta. gRNAde’s perplexity correlates with native sequence and structural recovery, and
323"
CONCLUSION,0.4044489383215369,"can be used for zero-shot ranking of mutants in RNA engineering campaigns. To the best of our
324"
CONCLUSION,0.40546006066734075,"knowledge, gRNAde is also the first geometric deep learning architecture for multi-state biomolecule
325"
CONCLUSION,0.4064711830131446,"representation learning; the model is generic and can be repurposed for other learning tasks on
326"
CONCLUSION,0.4074823053589484,"conformational ensembles, including multi-state protein design.
327"
CONCLUSION,0.4084934277047523,"Limitations. Key avenues for future development of gRNAde include supporting multiple interacting
328"
CONCLUSION,0.40950455005055614,"chains, accounting for partner molecules with RNAs, and supporting negative design against undesired
329"
CONCLUSION,0.41051567239635994,"conformations. We discuss practical tradeoffs to using gRNAde in real-world RNA design scenarios
330"
CONCLUSION,0.4115267947421638,"in Appendix B, including limitations due to the current state of 3D RNA structure prediction tools.
331"
REFERENCES,0.41253791708796766,"References
332"
REFERENCES,0.41354903943377147,"B. Adamczyk, M. Antczak, and M. Szachniuk. Rnasolo: a repository of cleaned pdb-derived rna 3d
333"
REFERENCES,0.41456016177957533,"structures. Bioinformatics, 2022. (Cited on page 5)
334"
REFERENCES,0.4155712841253792,"M. Baek, F. DiMaio, I. Anishchenko, J. Dauparas, S. Ovchinnikov, G. R. Lee, J. Wang, Q. Cong,
335"
REFERENCES,0.416582406471183,"L. N. Kinch, R. D. Schaeffer, et al. Accurate prediction of protein structures and interactions using
336"
REFERENCES,0.41759352881698686,"a three-track neural network. Science, 2021. (Cited on page 13)
337"
REFERENCES,0.4186046511627907,"M. Baek, R. McHugh, I. Anishchenko, H. Jiang, D. Baker, and F. DiMaio. Accurate prediction of
338"
REFERENCES,0.4196157735085945,"protein–nucleic acid complexes using rosettafoldna. Nature Methods, 2024. (Cited on page 13)
339"
REFERENCES,0.4206268958543984,"E. Bonnet, P. Rzazewski, and F. Sikora. Designing rna secondary structures is hard. Journal of
340"
REFERENCES,0.42163801820020225,"Computational Biology, 2020. (Cited on page 13)
341"
REFERENCES,0.42264914054600605,"M. M. Bronstein, J. Bruna, T. Cohen, and P. Velickovic. Geometric deep learning: Grids, groups,
342"
REFERENCES,0.4236602628918099,"graphs, geodesics, and gauges. arXiv preprint, 2021. (Cited on page 1)
343"
REFERENCES,0.4246713852376138,"J. Chen, Z. Hu, S. Sun, Q. Tan, Y. Wang, Q. Yu, L. Zong, L. Hong, J. Xiao, T. Shen, et al. Inter-
344"
REFERENCES,0.4256825075834176,"pretable rna foundation model from unannotated data for highly accurate rna structure and function
345"
REFERENCES,0.42669362992922144,"predictions. arXiv preprint, 2022. (Cited on page 13)
346"
REFERENCES,0.4277047522750253,"A. Churkin, M. D. Retwitzer, V. Reinharz, Y. Ponty, J. Waldispühl, and D. Barash. Design of rnas:
347"
REFERENCES,0.4287158746208291,"comparing programs for inverse rna folding. Briefings in bioinformatics, 2018. (Cited on page 2,
348"
REFERENCES,0.42972699696663297,"13)
349"
REFERENCES,0.43073811931243683,"T. R. Damase, R. Sukhovershin, C. Boada, F. Taraballi, R. I. Pettigrew, and J. P. Cooke. The limitless
350"
REFERENCES,0.43174924165824063,"future of rna therapeutics. Frontiers in bioengineering and biotechnology, 2021. (Cited on page 1)
351"
REFERENCES,0.4327603640040445,"R. Das, J. Karanicolas, and D. Baker. Atomic accuracy in predicting and designing noncanonical rna
352"
REFERENCES,0.43377148634984836,"structure. Nature methods, 2010. (Cited on page 1, 2, 5, 6, 13, 14, 15, 19)
353"
REFERENCES,0.43478260869565216,"J. Dauparas, I. Anishchenko, N. Bennett, H. Bai, R. J. Ragotte, L. F. Milles, B. I. Wicky, et al. Robust
354"
REFERENCES,0.435793731041456,"deep learning based protein sequence design using proteinmpnn. Science, 2022. (Cited on page 2,
355"
REFERENCES,0.4368048533872599,"3, 4, 7, 14)
356"
REFERENCES,0.4378159757330637,"W. K. Dawson, M. Maciejczyk, E. J. Jankowska, and J. M. Bujnicki. Coarse-grained modeling of rna
357"
REFERENCES,0.43882709807886755,"3d structure. Methods, 2016. (Cited on page 3)
358"
REFERENCES,0.4398382204246714,"K. Didi, F. Vargas, S. Mathis, V. Dutordoir, E. Mathieu, U. J. Komorowska, and P. Lio. A framework
359"
REFERENCES,0.4408493427704752,"for conditional diffusion modelling with applications in motif scaffolding for protein design. In
360"
REFERENCES,0.4418604651162791,"NeurIPS 2023 Machine Learning for Structural Biology Workshop, 2023. (Cited on page 13)
361"
REFERENCES,0.44287158746208294,"J. A. Doudna and E. Charpentier. The new frontier of genome engineering with crispr-cas9. Science,
362"
REFERENCES,0.44388270980788674,"2014. (Cited on page 1)
363"
REFERENCES,0.4448938321536906,"A. Duval, S. V. Mathis, C. K. Joshi, V. Schmidt, S. Miret, F. D. Malliaros, T. Cohen, P. Lio, Y. Bengio,
364"
REFERENCES,0.44590495449949447,"and M. Bronstein. A hitchhiker’s guide to geometric gnns for 3d atomic systems. arXiv preprint,
365"
REFERENCES,0.44691607684529827,"2023. (Cited on page 1)
366"
REFERENCES,0.44792719919110213,"M. Felletti, J. Stifel, L. A. Wurmthaler, S. Geiger, and J. S. Hartig. Twister ribozymes as highly
367"
REFERENCES,0.448938321536906,"versatile expression platforms for artificial riboswitches. Nature communications, 2016. (Cited on
368"
REFERENCES,0.4499494438827098,"page 1)
369"
REFERENCES,0.45096056622851366,"M. Fey and J. E. Lenssen. Fast graph representation learning with pytorch geometric. ICLR 2019
370"
REFERENCES,0.45197168857431747,"Representation Learning on Graphs and Manifolds Workshop, 2019. (Cited on page 4)
371"
REFERENCES,0.4529828109201213,"L. Fu, B. Niu, Z. Zhu, S. Wu, and W. Li. Cd-hit: accelerated for clustering the next-generation
372"
REFERENCES,0.4539939332659252,"sequencing data. Bioinformatics, 2012. (Cited on page 5)
373"
REFERENCES,0.455005055611729,"L. R. Ganser, M. L. Kelly, D. Herschlag, and H. M. Al-Hashimi. The roles of structural dynamics in
374"
REFERENCES,0.45601617795753285,"the cellular functions of rnas. Nature reviews Molecular cell biology, 2019. (Cited on page 2)
375"
REFERENCES,0.4570273003033367,"D. Han, X. Qi, C. Myhrvold, B. Wang, M. Dai, S. Jiang, M. Bates, Y. Liu, B. An, F. Zhang, et al.
376"
REFERENCES,0.4580384226491405,"Single-stranded dna and rna origami. Science, 2017. (Cited on page 2, 13)
377"
REFERENCES,0.4590495449949444,"S. He, R. Huang, J. Townley, R. C. Kretsch, T. G. Karagianes, D. B. Cox, H. Blair, D. Penzar, V. Vyalt-
378"
REFERENCES,0.46006066734074824,"sev, E. Aristova, et al. Ribonanza: deep learning of rna structure through dual crowdsourcing.
379"
REFERENCES,0.46107178968655205,"bioRxiv, 2024. (Cited on page 13)
380"
REFERENCES,0.4620829120323559,"J. Hoetzel and B. Suess. Structural changes in aptamers are essential for synthetic riboswitch
381"
REFERENCES,0.46309403437815977,"engineering. Journal of Molecular Biology, 2022. (Cited on page 2)
382"
REFERENCES,0.4641051567239636,"P.-S. Huang, S. E. Boyken, and D. Baker. The coming of age of de novo protein design. Nature, 2016.
383"
REFERENCES,0.46511627906976744,"(Cited on page 3, 9)
384"
REFERENCES,0.4661274014155713,"J. Ingraham, V. Garg, R. Barzilay, and T. Jaakkola. Generative models for graph-based protein design.
385"
REFERENCES,0.4671385237613751,"NeurIPS, 2019. (Cited on page 3, 20)
386"
REFERENCES,0.46814964610717896,"J. B. Ingraham, M. Baranov, Z. Costello, K. W. Barber, W. Wang, A. Ismail, V. Frappier, D. M.
387"
REFERENCES,0.4691607684529828,"Lord, C. Ng-Thow-Hing, E. R. Van Vlack, et al. Illuminating protein space with a programmable
388"
REFERENCES,0.47017189079878663,"generative model. Nature, 2023. (Cited on page 13)
389"
REFERENCES,0.4711830131445905,"B. Jing, S. Eismann, P. Suriana, R. J. L. Townshend, and R. Dror. Learning from protein structure
390"
REFERENCES,0.47219413549039435,"with geometric vector perceptrons. In International Conference on Learning Representations,
391"
REFERENCES,0.47320525783619816,"2020. (Cited on page 3, 4, 20)
392"
REFERENCES,0.474216380182002,"C. K. Joshi, C. Bodnar, S. V. Mathis, T. Cohen, and P. Lio. On the expressive power of geometric
393"
REFERENCES,0.4752275025278059,"graph neural networks. In International Conference on Machine Learning, 2023. (Cited on page
394"
REFERENCES,0.4762386248736097,"17)
395"
REFERENCES,0.47724974721941354,"J. Jumper, R. Evans, A. Pritzel, T. Green, M. Figurnov, O. Ronneberger, K. Tunyasuvunakool,
396"
REFERENCES,0.4782608695652174,"R. Bates, A. Zidek, A. Potapenko, et al. Highly accurate protein structure prediction with alphafold.
397"
REFERENCES,0.4792719919110212,"Nature, 2021. (Cited on page 1, 13)
398"
REFERENCES,0.48028311425682507,"M. L. Ken, R. Roy, A. Geng, L. R. Ganser, A. Manghrani, B. R. Cullen, U. Schulze-Gahmen,
399"
REFERENCES,0.48129423660262893,"D. Herschlag, and H. M. Al-Hashimi. Rna conformational propensities determine cellular activity.
400"
REFERENCES,0.48230535894843274,"Nature, 2023. (Cited on page 2, 7)
401"
REFERENCES,0.4833164812942366,"J. K. Leman, B. D. Weitzner, S. M. Lewis, J. Adolf-Bryfogle, N. Alam, R. F. Alford, M. Aprahamian,
402"
REFERENCES,0.48432760364004046,"D. Baker, K. A. Barlow, P. Barth, et al. Macromolecular modeling and design in rosetta: recent
403"
REFERENCES,0.48533872598584427,"methods and frameworks. Nature methods, 2020. (Cited on page 2, 6)
404"
REFERENCES,0.4863498483316481,"K. Leppek, R. Das, and M. Barna. Functional 5’ utr mrna structures in eukaryotic translation
405"
REFERENCES,0.487360970677452,"regulation and how to find them. Nature reviews Molecular cell biology, 2018. (Cited on page 1)
406"
REFERENCES,0.4883720930232558,"S. Li, S. Moayedpour, R. Li, M. Bailey, S. Riahi, L. Kogler-Anele, M. Miladi, J. Miner, D. Zheng,
407"
REFERENCES,0.48938321536905965,"J. Wang, et al. Codonbert: Large language models for mrna design and optimization. bioRxiv,
408"
REFERENCES,0.4903943377148635,"2023a. (Cited on page 13)
409"
REFERENCES,0.4914054600606673,"Y. Li, C. Zhang, C. Feng, R. Pearce, P. Lydia Freddolino, and Y. Zhang.
Integrating end-to-
410"
REFERENCES,0.4924165824064712,"end learning with deep geometrical potentials for ab initio rna structure prediction. Nature
411"
REFERENCES,0.49342770475227504,"Communications, 2023b. (Cited on page 13)
412"
REFERENCES,0.49443882709807885,"M. Mandal and R. R. Breaker. Gene regulation by riboswitches. Nature reviews Molecular cell
413"
REFERENCES,0.4954499494438827,"biology, 2004. (Cited on page 1)
414"
REFERENCES,0.49646107178968657,"E. K. McRae, C. J. Wan, E. L. Kristoffersen, K. Hansen, E. Gianni, I. Gallego, J. F. Curran, J. Attwater,
415"
REFERENCES,0.4974721941354904,"P. Holliger, and E. S. Andersen. Cryo-em structure and functional landscape of an rna polymerase
416"
REFERENCES,0.49848331648129424,"ribozyme. Proceedings of the National Academy of Sciences, 2024. (Cited on page 2, 8, 9, 19)
417"
REFERENCES,0.4994944388270981,"M. Metkar, C. S. Pepin, and M. J. Moore. Tailor made: the art of therapeutic mrna design. Nature
418"
REFERENCES,0.5005055611729019,"Reviews Drug Discovery, 2024. (Cited on page 1)
419"
REFERENCES,0.5015166835187057,"M. G. Mohsen, M. K. Midy, A. Balaji, and R. R. Breaker. Exploiting natural riboswitches for aptamer
420"
REFERENCES,0.5025278058645096,"engineering and validation. Nucleic Acids Research, 2023. (Cited on page 1)
421"
REFERENCES,0.5035389282103134,"K. Mustafina, K. Fukunaga, and Y. Yokobayashi. Design of mammalian on-riboswitches based on
422"
REFERENCES,0.5045500505561172,"tandemly fused aptamer and ribozyme. ACS Synthetic Biology, 2019. (Cited on page 1)
423"
REFERENCES,0.5055611729019212,"R. J. Penic, T. Vlasic, R. G. Huber, Y. Wan, and M. Sikic. Rinalmo: General-purpose rna language
424"
REFERENCES,0.506572295247725,"models can generalize well on structure prediction tasks. arXiv preprint, 2024. (Cited on page 13)
425"
REFERENCES,0.5075834175935288,"F. Runge, D. Stoll, S. Falkner, and F. Hutter. Learning to design RNA. In ICLR, 2019. (Cited on
426"
REFERENCES,0.5085945399393327,"page 13)
427"
REFERENCES,0.5096056622851365,"B. Schneider, B. A. Sweeney, A. Bateman, J. Cerny, T. Zok, and M. Szachniuk. When will rna get its
428"
REFERENCES,0.5106167846309403,"alphafold moment? Nucleic Acids Research, 2023. (Cited on page 2, 5)
429"
REFERENCES,0.5116279069767442,"T. Shen, Z. Hu, Z. Peng, J. Chen, P. Xiong, L. Hong, L. Zheng, Y. Wang, I. King, S. Wang, et al.
430"
REFERENCES,0.512639029322548,"E2efold-3d: End-to-end deep learning method for accurate de novo rna 3d structure prediction.
431"
REFERENCES,0.5136501516683518,"arXiv preprint, 2022. (Cited on page 5)
432"
REFERENCES,0.5146612740141557,"J. Stagno, Y. Liu, Y. Bhandari, C. Conrad, S. Panja, M. Swain, L. Fan, G. Nelson, C. Li, D. Wendel,
433"
REFERENCES,0.5156723963599595,"et al. Structures of riboswitch rna reaction states by mix-and-inject xfel serial crystallography.
434"
REFERENCES,0.5166835187057633,"Nature, 2017. (Cited on page 7)
435"
REFERENCES,0.5176946410515673,"C. Tan, Y. Zhang, Z. Gao, H. Cao, and S. Z. Li. Hierarchical data-efficient representation learning for
436"
REFERENCES,0.5187057633973711,"tertiary structure-based rna design. arXiv preprint, 2023. (Cited on page 13, 14)
437"
REFERENCES,0.5197168857431749,"R. J. Townshend, S. Eismann, A. M. Watkins, R. Rangan, M. Karelina, R. Das, and R. O. Dror.
438"
REFERENCES,0.5207280080889788,"Geometric deep learning of rna structure. Science, 2021. (Cited on page 13)
439"
REFERENCES,0.5217391304347826,"Q. Vicens and J. S. Kieft. Thoughts on how to think (and talk) about rna structure. Proceedings of
440"
REFERENCES,0.5227502527805864,"the National Academy of Sciences, 2022. (Cited on page 13, 17)
441"
REFERENCES,0.5237613751263903,"L. M. Wadley, K. S. Keating, C. M. Duarte, and A. M. Pyle. Evaluating and learning from rna
442"
REFERENCES,0.5247724974721941,"pseudotorsional space: quantitative validation of a reduced representation for rna structure. Journal
443"
REFERENCES,0.5257836198179979,"of molecular biology, 2007. (Cited on page 3)
444"
REFERENCES,0.5267947421638018,"W. Wang, C. Feng, R. Han, Z. Wang, L. Ye, Z. Du, H. Wei, F. Zhang, Z. Peng, and J. Yang. trrosettarna:
445"
REFERENCES,0.5278058645096056,"automated prediction of rna 3d structure with transformer network. Nature Communications, 2023.
446"
REFERENCES,0.5288169868554095,"(Cited on page 13)
447"
REFERENCES,0.5298281092012134,"M. Ward, E. Courtney, and E. Rivas. Fitness functions for rna structure design. Nucleic Acids
448"
REFERENCES,0.5308392315470172,"Research, 2023. (Cited on page 13)
449"
REFERENCES,0.531850353892821,"A. M. Watkins, R. Rangan, and R. Das. Farfar2: improved de novo rosetta prediction of complex
450"
REFERENCES,0.5328614762386249,"global rna folds. Structure, 2020. (Cited on page 13)
451"
REFERENCES,0.5338725985844287,"J. L. Watson, D. Juergens, N. R. Bennett, B. L. Trippe, J. Yim, H. E. Eisenach, W. Ahern, A. J. Borst,
452"
REFERENCES,0.5348837209302325,"R. J. Ragotte, L. F. Milles, et al. De novo design of protein structure and function with rfdiffusion.
453"
REFERENCES,0.5358948432760364,"Nature, 2023. (Cited on page 2, 5, 13)
454"
REFERENCES,0.5369059656218402,"H. K. Wayment-Steele, W. Kladwang, A. I. Strom, J. Lee, A. Treuille, A. Becka, E. Participants, and
455"
REFERENCES,0.537917087967644,"R. Das. Rna secondary structure packages evaluated and improved by high-throughput experiments.
456"
REFERENCES,0.538928210313448,"Nature methods, 2022. (Cited on page 4)
457"
REFERENCES,0.5399393326592518,"R. J. Williams and D. Zipser. A learning algorithm for continually running fully recurrent neural
458"
REFERENCES,0.5409504550050556,"networks. Neural computation, 1989. (Cited on page 4)
459"
REFERENCES,0.5419615773508595,"J. D. Yesselman, D. Eiler, E. D. Carlson, M. R. Gotrik, A. E. d’Aquino, A. N. Ooms, W. Kladwang,
460"
REFERENCES,0.5429726996966633,"P. D. Carlson, X. Shi, D. A. Costantino, et al. Computational design of three-dimensional rna
461"
REFERENCES,0.5439838220424671,"structure and function. Nature nanotechnology, 2019. (Cited on page 2, 13, 14)
462"
REFERENCES,0.544994944388271,"M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. R. Salakhutdinov, and A. J. Smola. Deep sets.
463"
REFERENCES,0.5460060667340748,"NeurIPS, 2017. (Cited on page 4, 20)
464"
REFERENCES,0.5470171890798786,"C. Zhang, M. Shine, A. M. Pyle, and Y. Zhang. Us-align: universal structure alignments of proteins,
465"
REFERENCES,0.5480283114256825,"nucleic acids, and macromolecular complexes. Nature methods, 2022. (Cited on page 5)
466"
REFERENCES,0.5490394337714863,"Y. Zhu, L. Zhu, X. Wang, and H. Jin. Rna-based therapeutics: An overview and prospectus. Cell
467"
REFERENCES,0.5500505561172901,"Death & Disease, 2022. (Cited on page 1)
468"
REFERENCES,0.5510616784630941,"A
Related Work
469"
REFERENCES,0.5520728008088979,"We attempt to briefly summarise recent developments in RNA structure modelling and design, with
470"
REFERENCES,0.5530839231547017,"an emphasis on deep learning-based approaches.
471"
REFERENCES,0.5540950455005056,"RNA inverse folding. Most tools for RNA inverse folding focus on secondary structure without
472"
REFERENCES,0.5551061678463094,"considering 3D geometry [Churkin et al., 2018, Runge et al., 2019] and approach the problem from
473"
REFERENCES,0.5561172901921132,"the lens of energy optimisation [Ward et al., 2023]. Rosetta fixed backbone re-design [Das et al.,
474"
REFERENCES,0.5571284125379171,"2010] is the only energy optimisation-based approach that accounts for 3D structure. Deep neural
475"
REFERENCES,0.5581395348837209,"networks such as gRNAde can incorporate 3D structural constraints and are orders of magnitude
476"
REFERENCES,0.5591506572295247,"faster than optimisation-based approaches; this is particularly attractive for high-throughput design
477"
REFERENCES,0.5601617795753286,"pipelines as solving the inverse folding optimisation problem is NP hard [Bonnet et al., 2020].
478"
REFERENCES,0.5611729019211324,"RNA structure design. Inverse folding models for protein design have often been coupled with
479"
REFERENCES,0.5621840242669363,"backbone generation models which design structural backbones conditioned on various design
480"
REFERENCES,0.5631951466127402,"constraints [Watson et al., 2023, Ingraham et al., 2023, Didi et al., 2023]. Current approaches for
481"
REFERENCES,0.564206268958544,"RNA backbone design use classical (non-learnt) algorithms for aligning 3D RNA motifs [Han et al.,
482"
REFERENCES,0.5652173913043478,"2017, Yesselman et al., 2019], which are small modular pieces of RNA that are believed to fold
483"
REFERENCES,0.5662285136501517,"independently. Such algorithms may be restricted by the use of hand-crafted heuristics and we plan
484"
REFERENCES,0.5672396359959555,"to explore data-driven generative models for RNA backbone design in future work.
485"
REFERENCES,0.5682507583417593,"RNA structure prediction.
There have been several recent efforts to adapt protein folding
486"
REFERENCES,0.5692618806875632,"architectures such as AlphaFold2 [Jumper et al., 2021] and RosettaFold [Baek et al., 2021] for RNA
487"
REFERENCES,0.570273003033367,"structure prediction [Li et al., 2023b, Wang et al., 2023, Baek et al., 2024]. A previous generation of
488"
REFERENCES,0.5712841253791708,"models used GNNs as ranking functions together with Rosetta energy optimisation [Watkins et al.,
489"
REFERENCES,0.5722952477249748,"2020, Townshend et al., 2021]. None of these architectures aim at capturing conformational flexibility
490"
REFERENCES,0.5733063700707786,"of RNAs, unlike gRNAde which represents RNAs as multi-state conformational ensembles. Neither
491"
REFERENCES,0.5743174924165824,"can structure prediction tools be used for RNA design tasks as they are not generative models.
492"
REFERENCES,0.5753286147623863,"RNA language models. Self-supervised language models have been developed for predictive and
493"
REFERENCES,0.5763397371081901,"generative tasks on RNA sequences, including general-purpose models such as RNA FM [Chen
494"
REFERENCES,0.5773508594539939,"et al., 2022] and RiNaLMo [Penic et al., 2024] as well as mRNA-specific CodonBERT [Li et al.,
495"
REFERENCES,0.5783619817997978,"2023a]. RNA sequence data repositories are orders of magnitude larger than those for RNA structure
496"
REFERENCES,0.5793731041456016,"(eg. RiNaLMo is trained on 36 million sequences). However, standard language models can only
497"
REFERENCES,0.5803842264914054,"implicitly capture RNA structure and dynamics through sequence co-occurence statistics, which
498"
REFERENCES,0.5813953488372093,"can pose a chellenge for designing structured RNAs such as riboswitches, aptamers, and ribozymes.
499"
REFERENCES,0.5824064711830131,"RibonanzaNet [He et al., 2024] represents a recent effort in developing structure-informed RNA
500"
REFERENCES,0.583417593528817,"language models by supervised training on experimental readouts from chemical mapping, although
501"
REFERENCES,0.5844287158746209,"RibonanzaNet cannot be used for RNA design. Inverse folding methods like gRNAde are language
502"
REFERENCES,0.5854398382204247,"models conditioned on 3D structure, making them a natural choice for structure-based design.
503"
REFERENCES,0.5864509605662285,"Comparison to contemporaneous work. Concurrently, Tan et al. [2023] also developed a deep
504"
REFERENCES,0.5874620829120324,"learning-based 3D RNA inverse folding model. We want to emphasize that this is independent work,
505"
REFERENCES,0.5884732052578362,"but for completeness we include a discussion on key differences to gRNAde:
506"
REFERENCES,0.58948432760364,"• Methodology:
507"
REFERENCES,0.5904954499494439,"– New capabilities: gRNAde enables explicit multi-state design to generate sequences
508"
REFERENCES,0.5915065722952477,"conditioned on multiple backbone structures, which is not possible with Rosetta nor Tan
509"
REFERENCES,0.5925176946410515,"et al. [2023]’s approach. We have also demonstrated the utility of gRNAde’s perplexity for
510"
REFERENCES,0.5935288169868554,"zero-shot ranking of mutants in RNA engineering campaigns.
511"
REFERENCES,0.5945399393326593,"– Decoding: gRNAde uses an autoregressive decoder with rotation-equivariant GNN layers,
512"
REFERENCES,0.5955510616784631,"while Tan et al. [2023] use a non-autoregressive (one-shot) decoder with rotation-invariant
513"
REFERENCES,0.596562184024267,"layers. In our ablation study (Appendix D), we found autoregressive decoding to show
514"
REFERENCES,0.5975733063700708,"significantly higher 2D and 3D self-consistency scores than non-autoregressive decoding,
515"
REFERENCES,0.5985844287158746,"even though non-autoregressive decoding lead to higher sequence recovery. Autoregressive
516"
REFERENCES,0.5995955510616785,"decoding is more expressive and can condition predictions at each decoding step on past
517"
REFERENCES,0.6006066734074823,"predictions, while one-shot decoders sample from independent probability distributions for
518"
REFERENCES,0.6016177957532861,"each nucleotide. We find autoregressive decoding to be a better inductive bias for predicting
519"
REFERENCES,0.60262891809909,"base pairing and base stacking interactions that are drivers of RNA structure [Vicens and
520"
REFERENCES,0.6036400404448938,"Kieft, 2022]. For instance, G-C and A-U pairs can often be swapped for one another, but
521"
REFERENCES,0.6046511627906976,"non-autoregressive decoding does not capture such paired constraints.
522"
REFERENCES,0.6056622851365016,"• Evaluation:
523"
REFERENCES,0.6066734074823054,"– Evaluation metrics: Tan et al. [2023] focus on measuring native sequence recovery, only.
524"
REFERENCES,0.6076845298281092,"We have additionally introduced structural self-consistency metrics at the 2D and 3D level,
525"
REFERENCES,0.6086956521739131,"which have been shown to better correlate with experimental success in protein design.
526"
REFERENCES,0.6097067745197169,"– Perplexity: We found gRNAde’s perplexity to be correlated with sequence and structural
527"
REFERENCES,0.6107178968655207,"recovery, as well as demonstrated its utility for zero-shot ranking of mutants in RNA
528"
REFERENCES,0.6117290192113246,"engineering. On the other hand, Tan et al. [2023] do not report perplexity and claim that
529"
REFERENCES,0.6127401415571284,"perplexity is an unsuitable metric for RNA design.
530"
REFERENCES,0.6137512639029322,"– Data splitting: While both studies use structural clustering to evaluate generalisation to
531"
REFERENCES,0.6147623862487361,"structurally dissimilar RNAs, Tan et al. [2023]’s test splits are determined randomly. Our
532"
REFERENCES,0.6157735085945399,"experiments use currated test splits from Das et al. [2010] to fairly compare gRNAde
533"
REFERENCES,0.6167846309403437,"to physically based Rosetta, as well as split based on structural flexibility to benchmark
534"
REFERENCES,0.6177957532861477,"multi-state design.
535"
REFERENCES,0.6188068756319515,"• Usage and reproducibility: We release open source training and inference code as well as model
536"
REFERENCES,0.6198179979777553,"checkpoints to enable complete reproducibility. We also release Colab notebooks and detailed
537"
REFERENCES,0.6208291203235592,"tutorials to make gRNAde broadly applicable and useful in real-world RNA design campaigns.
538"
REFERENCES,0.621840242669363,"At present, it is not possible to reproduce the results in Tan et al. [2023] or compare to gRNAde
539"
REFERENCES,0.6228513650151668,"directly as no training code is available.
540"
REFERENCES,0.6238624873609707,"B
FAQs on using gRNAde
541"
REFERENCES,0.6248736097067745,"How to chose the number of states to provide as input to gRNAde? In general, this would depend
542"
REFERENCES,0.6258847320525783,"on the design objective. For instance, designing riboswitches may necessitate multi-state design,
543"
REFERENCES,0.6268958543983822,"while a single-state pipeline may be more sensible for locking an aptamer into its bound conformation
544"
REFERENCES,0.627906976744186,"[Yesselman et al., 2019]. Note that it may be possible to benefit from multi-state gRNAde models
545"
REFERENCES,0.6289180990899899,"even when performing single-state design by using slightly noised variations of the same backbone
546"
REFERENCES,0.6299292214357938,"structure as an input conformational ensemble.
547"
REFERENCES,0.6309403437815976,"How to prioritise or chose amongst designed sequences? We have currently provided 3 types
548"
REFERENCES,0.6319514661274014,"of evaluation metrics: native sequence recovery, structural self-consistency scores and perplexity,
549"
REFERENCES,0.6329625884732053,"towards this end. We suspect that recovery may not be the ideal choice, except for design scenarios
550"
REFERENCES,0.6339737108190091,"where we require certain regions of the RNA sequence to be conserved or native-like. Self-consistency
551"
REFERENCES,0.6349848331648129,"scores may provide an overall more holistic evaluation metric as they accounts for alternative base
552"
REFERENCES,0.6359959555106168,"pairings which still lead to similar structures as well as better capture the recovery of structural motifs
553"
REFERENCES,0.6370070778564206,"responsible for functionality. However, structural self-consistency scores inherit the limitations of
554"
REFERENCES,0.6380182002022244,"the structure prediction methods used as part of their computation. For instance, computing the self-
555"
REFERENCES,0.6390293225480284,"consistency score between an RNA backbone and its own native sequence provides an upper bounds
556"
REFERENCES,0.6400404448938322,"on the maximum score that designs can obtain under a given structure prediction method. Lastly,
557"
REFERENCES,0.641051567239636,"gRNAde’s perplexity estimates the likelihood of a sequence given a backbone and can be useful for
558"
REFERENCES,0.6420626895854399,"ranking designs and mutants in RNA engineering campaigns (especially for design scenarios where
559"
REFERENCES,0.6430738119312437,"structure prediction tools are not performant).
560"
REFERENCES,0.6440849342770475,"In real-world design scenarios, we can pair gRNAde with another machine learning model (an
561"
REFERENCES,0.6450960566228514,"‘oracle’) for ranking or predicting the suitability of designed sequences for the objective (for instance,
562"
REFERENCES,0.6461071789686552,"binding affinity or some other notion of fitness). We hope to conduct further experimental validation
563"
REFERENCES,0.647118301314459,"of gRNAde designs in the wet lab in order to better understand these tradeoffs.
564"
REFERENCES,0.6481294236602629,"Why not average single-state logits over multiple states for multi-state design? ProteinMPNN
565"
REFERENCES,0.6491405460060667,"[Dauparas et al., 2022] proposes to average logits from multiple backbones for multi-state protein
566"
REFERENCES,0.6501516683518705,"design. Here is a simple example to highlight issues with such an approach: Consider two states A
567"
REFERENCES,0.6511627906976745,"and B, and choice of labels X, Y, and Z. For state A: X, Y, Z are assigned probabilities 75%, 20%,
568"
REFERENCES,0.6521739130434783,"5%. For state B: X, Y, Z are assigned probabilities 5%, 20%, 75%. Logically, label Y is the only one
569"
REFERENCES,0.6531850353892821,"that is compatible with both states. However, averaging the probabilities would lead to label X or Z
570"
REFERENCES,0.654196157735086,"being more likely to be sampled in designs. As an alternative, gRNAde is based on multi-state GNNs
571"
REFERENCES,0.6552072800808898,"which can take as input one or more backbone structures and generate sequences conditioned on the
572"
REFERENCES,0.6562184024266936,"conformational ensemble directly.
573"
REFERENCES,0.6572295247724975,"C
3D Visualisation of gRNAde Designs
574"
REFERENCES,0.6582406471183013,"Guanine
Riboswitch"
REFERENCES,0.6592517694641051,aptamer
REFERENCES,0.660262891809909,Tetrahymena
REFERENCES,0.6612740141557129,"Ribozyme
P4-P6 domain"
REFERENCES,0.6622851365015167,Vitamin B12
REFERENCES,0.6632962588473206,"binding
aptamer 0.00 0.25 0.50 0.75 1.00"
REFERENCES,0.6643073811931244,scTM (RhoFold)
REFERENCES,0.6653185035389282,(a) self-consistency TM-score
REFERENCES,0.6663296258847321,"Guanine
Riboswitch"
REFERENCES,0.6673407482305359,aptamer
REFERENCES,0.6683518705763397,Tetrahymena
REFERENCES,0.6693629929221436,"Ribozyme
P4-P6 domain"
REFERENCES,0.6703741152679474,Vitamin B12
REFERENCES,0.6713852376137512,"binding
aptamer 0.00 0.25 0.50 0.75 1.00"
REFERENCES,0.6723963599595552,scGDT (RhoFold) 0.0 0.2 0.4 0.6 0.8 1.0
REFERENCES,0.673407482305359,Perplexity (normalized)
REFERENCES,0.6744186046511628,(b) self-consistency GDT_TS
REFERENCES,0.6754297269969667,"Figure 6: 3D self-consistency scores for 3 representative RNAs from Das et al. [2010]. We use
RhoFold to ‘forward fold’ 100 designs sampled at temperature = 0.5 and plot self-consistency TM-
score and GDT_TS. Each dot corresponds to one designed sequence and is coloured by gRNAde’s
perplexity (normalised per RNA). Designs with lower relative perplexity generally have higher
3D self-consistency and can be considered more ‘designable’. Dotted lines represent TM-score
and GDT_TS thresholds of 0.45 and 0.50, repsectively. Pairs of structures scoring higher than the
threshold correspond to roughly the same fold."
REFERENCES,0.6764408493427705,"Design 1:
GGCAAGUAAUCCCUACGCUAUG
GGUAGGGAGUCUCAGCAGUGAC
CCGUAAAGUUACUACCUUGCCC
perplexity: 1.3097
recovery: 0.5909 (27 edits)
sc2D = 0.9227
scRMSD = 1.3839
scTM = 0.8309
scGDT = 0.8295"
REFERENCES,0.6774519716885743,"Design 2:
CGGUGGUAAGCCCAACGCUAGG
GGUUGGGCGUCUCAGCACAGUC
CCGUAAAGAUUGUACCCACCGG
perplexity: 1.3815
recovery: 0.4091 (37 edits)
sc2D = 0.9227
scRMSD = 2.1249
scTM = 0.6874
scGDT = 0.6780"
REFERENCES,0.6784630940343782,"Design 3:
AGCAAGUAAUGCCAUCGCUAUG
GGAUGGUAGUGUCAGCACUGAC
CCUUAAAGUUAGUACCUUGCUU
perplexity: 1.4247
recovery: 0.5152 (30 edits)
sc2D = 0.9227
scRMSD = 3.2131
scTM = 0.5118
scGDT = 0.5265"
REFERENCES,0.679474216380182,"Figure 7: Cherry-picked designs for Guanine riboswitch aptamer (PDB: 4FE5, sequence:
GGACAUAUAAUCGCGUGGAUAUGGCACGCAAGUUUCUACCGGGCACCGUAAAUGUCCGACUAUGUCC)."
REFERENCES,0.6804853387259858,"Design 1:
GGGGCUCCGGCGACGCAGUCGAAAG
CCCAGCAGUACCAAGCCUCAGGGGA
AACUUUGAGGUGGCCUAACAAAGGA
UACGGUAAUAAGCUGCGGGAAAAGG
UUGUAAGCCGGAGCGAAGACCUAAG
GCACCGCUUUUGGCGGUGCUAUGGU
UGAAGUUAA
perplexity: 1.2462
recovery: 0.7170 (44 edits)
sc2D = 0.8301
scRMSD = 5.4562
scTM = 0.6481
scGDT = 0.4465"
REFERENCES,0.6814964610717897,"Design 2:
GGGGUACCGGCGACGCAGUCGAAUG
CCCUGUGGUACCAAGCCCCGGGGGA
AACUUCGGGGUGGCCUUACCAAGGA
CACGGUAAUAAGCCACGGGAAAUGG
UUGUAAGCCGGUCCGAAGCCCUAAG
GCCGCGCUUUGGGCGCGGCUAUGGG
UGAAGGCAA
perplexity: 1.3273
recovery: 0.6226 (58 edits)
sc2D = 0.6896
scRMSD = 6.7239
scTM = 0.6300
scGDT = 0.4513"
REFERENCES,0.6825075834175935,"Design 3:
GAGGCCACGGCAACGCAGUCUAACG
CCCUGUGGUACCAAGUCUUAGGAGA
AAUUUUAAGAUGGCCUAAUAAAGGA
UAUGGUAAUAAGCCACGGGAAAAGG
UUGUAAGACGUGACGAAGUCCUAAG
GCCACAGUUUUGCUGUGGCUAUGGA
UGGAGUACA
perplexity: 1.3204
recovery: 0.7044 (45 edits)
sc2D = 0.7922
scRMSD = 8.8211
scTM = 0.4582
scGDT = 0.2909"
REFERENCES,0.6835187057633973,"Figure 8: Cherry-picked designs for Tetrahymena Ribozyme P4-P6 domain (PDB: 2R8S, se-
quence: GGAAUUGCGGGAAAGGGGUCAACAGCCGUUCAGUACCAAGUCUCAGGGGAAACUUUGAGAUGGCCUUGCAAAGGGU
AUGGUAAUAAGCUGACGGACAUGGUCCUAACACGCAGCCAAGUCCUAAGUCAACAGAUCUUCUGUUGAUAUGGAUGCAGUUCA)."
REFERENCES,0.6845298281092013,"Design 1:
GUCAAACGCAGCCGAAA
GCGCGAUAGUCCCAGGAA
perplexity = 1.6237
recovery = 0.4571 (16 edits)
sc2D = -0.0074
scRMSD = 3.9505
scTM = 0.2597
scGDT = 0.4786"
REFERENCES,0.6855409504550051,"Design 2:
GGCAAACGCGGCCGAAA
GCGCGUGAGUCCCCGGAC
perplexity = 1.6630
recovery = 0.4857 (16 edits)
sc2D = -0.0099
scRMSD = 3.3549
scTM = 0.2526
scGDT = 0.5000"
REFERENCES,0.6865520728008089,"Design 3:
CGUAGUCGGAGCCGAAG
GGCCGUUAGUCCCAGGAG
perplexity = 1.7020
recovery = 0.4000 (17 edits)
sc2D = 0.4035
scRMSD = 16.4102
scTM = 0.0319
scGDT = 0.0571"
REFERENCES,0.6875631951466128,"Figure 9: Cherry-picked designs for Vitamin B12 binding aptamer (PDB: 1ET4, sequence:
GGAACCGGUGCGCAUAACCACCUCAGUGCGAGCAA)."
REFERENCES,0.6885743174924166,"Table 1: Ablation study and aggregated benchmark results for gRNAde. We report metrics averaged
over 100 test sets samples and standard deviations across 3 consistent random seeds. The percentages
reported in brackets for the 3D self-consistency scores are the percentage of designed samples within
the ‘designability’ threshold values (scRMSD≤2Å, scTM≥0.45, scGDT≥0.5)."
REFERENCES,0.6895854398382204,Self-consistency metrics
REFERENCES,0.6905965621840243,"Max.
Max. train
Perplexity
Native seq.
2D – EternaFold
3D – RhoFold
Split
#states
Model
GNN
length
(↓)
recovery (↑)
scMCC (↑)
scRMSD (↓)
scTM-score (↑)
scGDT_TS (↑)"
REFERENCES,0.6916076845298281,Single-state split
"AR
EQUIV",0.6926188068756319,"1
AR
Equiv
500
1.77±0.07
0.438±0.01
0.624±0.07
13.01±1.18 (0.5%)
0.21±0.0 (14.3%)
0.22±0.0 (12.7%)
1
AR
Equiv
1000
1.73±0.08
0.453±0.01
0.648±0.01
13.10±0.58 (1.0%)
0.20±0.0 (10.8%)
0.21±0.0 (10.6%)
1
AR
Equiv
2500
1.41±0.01
0.493±0.01
0.633±0.03
11.76±0.91 (1.4%)
0.27±0.0 (28.8%)
0.27±0.0 (28.0%)
1
AR
Equiv
5000
1.29±0.02
0.530±0.01
0.585±0.03
11.70±0.56 (1.3%)
0.26±0.0 (24.8%)
0.25±0.0 (20.1%)"
"AR
INV",0.6936299292214358,"1
AR
Inv
5000
1.32±0.04
0.549±0.00
0.612±0.02
11.50±0.64 (1.9%)
0.28±0.0 (32.1%)
0.28±0.0 (26.2%)"
"NAR
INV",0.6946410515672397,"1
NAR
Inv
5000
1.54±0.04
0.571±0.00
0.430±0.02
14.26±0.51 (1.3%)
0.19±0.0 (15.9%)
0.18±0.0 (12.7%)
1
NAR
Equiv
5000
1.46±0.06
0.584±0.00
0.473±0.02
13.04±0.88 (1.3%)
0.23±0.0 (24.0%)
0.22±0.0 (17.9%)"
"AR
EQUIV",0.6956521739130435,"3
AR
Equiv
5000
1.23±0.05
0.539±0.01
0.620±0.01
11.47±1.05 (2.5%)
0.28±0.0 (31.4%)
0.28±0.0 (27.2%)
5
AR
Equiv
5000
1.25±0.01
0.539±0.02
0.596±0.03
11.90±1.00 (2.9%)
0.27±0.0 (31.6%)
0.26±0.0 (26.4%)"
"AR
EQUIV",0.6966632962588474,"Groundtruth sequence prediction baseline:
-
1.000±0.00
0.686±0.00
5.23±0.07 (27.9%)
0.56±0.0 (68.7%)
0.55±0.0 (68.7%)
Random sequence prediction baseline:
-
0.251±0.00
0.012±0.00
24.40±0.34 (0.0%)
0.04±0.0 (0.0%)
0.02±0.0 (0.0%)
ViennaRNA 2D-only baseline:
-
0.259±0.00
0.611±0.00
20.34±0.10 (0.0%)
0.07±0.0 (0.6%)
0.07±0.0 (1.1%)"
"AR
EQUIV",0.6976744186046512,Multi-state split
"AR
EQUIV",0.698685540950455,"1
AR
Equiv
500
1.87±0.06
0.445±0.01
0.603±0.03
13.08±0.20 (3.5%)
0.10±0.0 (1.2%)
0.25±0.0 (20.7%)
1
AR
Equiv
1000
1.84±0.01
0.447±0.01
0.580±0.01
13.02±0.56 (2.3%)
0.09±0.0 (0.9%)
0.25±0.0 (20.4%)
1
AR
Equiv
2500
1.73±0.04
0.480±0.02
0.567±0.01
12.83±0.05 (3.4%)
0.10±0.0 (1.9%)
0.26±0.0 (21.2%)
1
AR
Equiv
5000
1.68±0.03
0.455±0.01
0.569±0.02
12.88±0.20 (4.1%)
0.11±0.0 (1.6%)
0.26±0.0 (22.6%)"
"AR
INV",0.6996966632962589,"1
AR
Inv
5000
1.72±0.01
0.463±0.01
0.559±0.03
13.09±0.27 (4.1%)
0.10±0.0 (2.2%)
0.27±0.0 (23.0%)"
"NAR
INV",0.7007077856420627,"1
NAR
Inv
5000
2.01±0.04
0.457±0.01
0.461±0.01
14.06±0.23 (3.2%)
0.08±0.0 (1.7%)
0.23±0.0 (16.5%)
1
NAR
Equiv
5000
1.89±0.06
0.432±0.01
0.423±0.01
13.63±0.27 (3.6%)
0.09±0.0 (1.2%)
0.24±0.0 (18.3%)"
"AR
EQUIV",0.7017189079878665,"3
AR
Equiv
5000
1.60±0.03
0.467±0.03
0.561±0.03
13.31±0.38 (3.4%)
0.10±0.0 (2.6%)
0.24±0.0 (19.0%)
5
AR
Equiv
5000
1.55±0.04
0.473±0.01
0.549±0.03
13.48±0.79 (3.3%)
0.10±0.0 (3.0%)
0.24±0.0 (20.2%)"
"AR
EQUIV",0.7027300303336703,"Groundtruth sequence prediction baseline:
-
1.000±0.00
0.570±0.01
9.78±0.13 (10.3%)
0.16±0.0 (11.7%)
0.36±0.0 (36.7%)
Random sequence prediction baseline:
-
0.249±0.00
0.128±0.00
21.15±0.21 (0.9%)
0.02±0.0 (0.0%)
0.09±0.0 (3.3%)
ViennaRNA 2D-only baseline:
-
0.258±0.00
0.601±0.00
15.47±0.20 (2.4%)
0.05±0.0 (0.2%)
0.19±0.0 (15.2%)"
"AR
EQUIV",0.7037411526794742,All data
"AR
EQUIV",0.704752275025278,"1
AR
Equiv
5000
1.23±0.01
0.733±0.00
0.627±0.02
8.10±0.28 (20.7%)
0.42±0.0 (46.1%)
0.41±0.0 (43.0%)
2
AR
Equiv
5000
1.21±0.01
0.783±0.01
0.629±0.03
8.40±0.09 (19.1%)
0.42±0.0 (47.8%)
0.41±0.0 (41.7%)
3
AR
Equiv
5000
1.19±0.01
0.787±0.01
0.606±0.02
7.88±0.68 (20.5%)
0.43±0.0 (47.4%)
0.42±0.0 (44.0%)
5
AR
Equiv
5000
1.15±0.01
0.811±0.01
0.617±0.02
7.51±0.30 (20.7%)
0.45±0.0 (50.2%)
0.44±0.0 (46.7%)"
"AR
EQUIV",0.7057633973710818,"D
Ablation Study
575"
"AR
EQUIV",0.7067745197168858,"Table 1 presents an ablation study as well as aggregated benchmark for various configurations of
576"
"AR
EQUIV",0.7077856420626896,"gRNAde. Key takeaways are highlighted below. Note that all results in the main paper are reported
577"
"AR
EQUIV",0.7087967644084934,"for models trained on the maximum length of 5000 nucleotides using autoregressive decoding and
578"
"AR
EQUIV",0.7098078867542973,"rotation-equivariant GNN layers, as this lead to the lowest perplexity values.
579"
"AR
EQUIV",0.7108190091001011,"Max. train RNA length Limiting the maximum length of RNAs used for training can be seen
580"
"AR
EQUIV",0.7118301314459049,"as ablating the use of ribosomal RNA families (which are thousands of nucleotides long and form
581"
"AR
EQUIV",0.7128412537917088,"complexes with specialised ribosomal proteins). We find that training on only short RNAs fewer than
582"
"AR
EQUIV",0.7138523761375126,"1000s of nucleotides leads to worse sequence recovery and 3D self-consistency scores, even though it
583"
"AR
EQUIV",0.7148634984833164,"improves 2D self-consistency across both evaluation splits. This suggests that tertiary interactions
584"
"AR
EQUIV",0.7158746208291203,"learnt from ribosomal RNAs can generalise to other RNA families to some extent (large ribosomal
585"
"AR
EQUIV",0.7168857431749242,"RNAs were excluded from test sets).
586"
"AR
EQUIV",0.717896865520728,"GNN We ablated whether the internal representations of the GVP-GNN are rotation invariant or
587"
"AR
EQUIV",0.7189079878665319,"equivariant. Equivariant GNNs are theoretically more expressive [Joshi et al., 2023] and we do find
588"
"AR
EQUIV",0.7199191102123357,"them more capable at fitting the training distribution (as shown by lower perplexity). However, we do
589"
"AR
EQUIV",0.7209302325581395,"not find significant differences in terms of other performance metrics across different GNN layers.
590"
"AR
EQUIV",0.7219413549039434,"Model ‘AR’ implies autoregressive decoding (described in Section 2.3, uses 4 encoder and 4
591"
"AR
EQUIV",0.7229524772497472,"decoder layers), while ‘NAR’ implies non-autoregressive, one-shot decoding using an MLP (uses 8
592"
"AR
EQUIV",0.723963599595551,"encoder layers). Across both evaluation splits, AR models show significantly higher self-consistency
593"
"AR
EQUIV",0.7249747219413549,"scores than NAR, even though NAR lead to higher sequence recovery. AR is more expressive and
594"
"AR
EQUIV",0.7259858442871587,"can condition predictions at each decoding step on past predictions, while one-shot NAR samples
595"
"AR
EQUIV",0.7269969666329625,"from independent probability distributions for each nucleotide. Thus, AR is a better inductive bias
596"
"AR
EQUIV",0.7280080889787665,"for predicting base pairing and base stacking interactions that are drivers of RNA structure [Vicens
597"
"AR
EQUIV",0.7290192113245703,"and Kieft, 2022]. For instance, G-C and A-U pairs can often be swapped for one another, but
598"
"AR
EQUIV",0.7300303336703741,"non-autoregressive decoding does not capture such paired constraints.
599"
"AR
EQUIV",0.731041456016178,"Max. #states We evaluate the impact of increasing the maximum number of states as input to
600"
"AR
EQUIV",0.7320525783619818,"gRNAde. Multi-state models marginally improve native sequence recovery as well as structural
601"
"AR
EQUIV",0.7330637007077856,"self-consistency scores over an equivalent single state variant, even for the single-state benchmark
602"
"AR
EQUIV",0.7340748230535895,"where the multi-state model is being used with only one state as input. This suggests that seeing
603"
"AR
EQUIV",0.7350859453993933,"multiple states during training can be useful for gRNAde’s performance even for single-state design
604"
"AR
EQUIV",0.7360970677451971,"tasks.
605"
"AR
EQUIV",0.737108190091001,"Non-learnt baselines. We report the performance of two non-learnt baselines to contextualise
606"
"AR
EQUIV",0.7381193124368048,"gRNAde’s performance: for each test sample, simply predicting the groundtruth sequence back
607"
"AR
EQUIV",0.7391304347826086,"and predicting a random sequence. Structural self-consistency scores for the Groundtruth baseline
608"
"AR
EQUIV",0.7401415571284126,"provides a rough upper bounds on the maximum score that any gRNAde designs can theoretically
609"
"AR
EQUIV",0.7411526794742164,"obtain given the current state of 2D/3D structure predictors being used. gRNAde always performs
610"
"AR
EQUIV",0.7421638018200202,"better than the random baseline and often reaches 2D self-consistency scores close to the upper bound.
611"
"AR
EQUIV",0.7431749241658241,"Both 2D and 3D self-consistency scores are inherently limited by the performance of the structure
612"
"AR
EQUIV",0.7441860465116279,"prediction methods used.
613"
"AR
EQUIV",0.7451971688574317,"2D inverse folding baseline.
We additionally report results for ViennaRNA’s 2D-only inverse
614"
"AR
EQUIV",0.7462082912032356,"folding method to further demonstrate the utility of 3D inverse folding. ViennaRNA has improved
615"
"AR
EQUIV",0.7472194135490394,"2D self-consistency scores over gRNAde but fails to capture tertiary interactions in its designs, as
616"
"AR
EQUIV",0.7482305358948432,"evident by poor recovery and 3D self-consistency scores similar to the random baseline.
617"
"AR
EQUIV",0.7492416582406471,"Split. Single- and multi-state splits are described in Section 3; the multi-state split is relatively harder
618"
"AR
EQUIV",0.750252780586451,"than the single-state split based on overall reduced performance for all baselines and models. Models
619"
"AR
EQUIV",0.7512639029322548,"trained on ‘All data’ use all RNASolo samples for training, solely for the purpose of releasing the best
620"
"AR
EQUIV",0.7522750252780587,"possible gRNAde checkpoints for real-world usage. Evaluation metrics for ‘All data’ are reported on
621"
"AR
EQUIV",0.7532861476238625,"the single-state test set.
622"
"AR
EQUIV",0.7542972699696663,"E
Additional Results
623"
"AR
EQUIV",0.7553083923154702,"Table 2: Full results for Figure 2 comparing gRNAde to Rosetta, FARNA and ViennaRNA for
single-state design on 14 RNA structures of interest identified by Das et al. [2010]. Rosetta and
FARNA recovery values are taken from Das et al. [2010], Supplementary Table 2."
"AR
EQUIV",0.756319514661274,"ViennaRNA
FARNA
Rosetta
gRNAde (single-state)
PDB ID
Description
Recovery
Recovery
Recovery
Recovery
Perplexity
2D self-cons."
"CSL
RRE HIGH AFFINITY SITE",0.7573306370070778,"1CSL
RRE high affinity site
0.25
0.20
0.44
0.5719
1.2812
0.8644
1ET4
Vitamin B12 binding RNA aptamer
0.25
0.34
0.44
0.6250
1.3457
-0.0135
1F27
Biotin-binding RNA pseudoknot
0.30
0.36
0.37
0.3437
1.6203
0.4523
1L2X
Viral RNA pseudoknot
0.24
0.45
0.48
0.4721
1.3181
0.5692
1LNT
RNA internal loop of SRP
0.33
0.27
0.53
0.5843
1.4337
0.1379
1Q9A
Sarcin/ricin domain from E.coli 23S rRNA
0.27
0.40
0.41
0.5044
1.3411
0.0597
4FE5
Guanine riboswitch aptamer
0.29
0.28
0.36
0.5300
1.3824
0.9116
1X9C
All-RNA hairpin ribozyme
0.26
0.31
0.50
0.5000
1.3905
0.6630
1XPE
HIV-1 B RNA dimerization initiation site
0.27
0.24
0.40
0.7037
1.2177
0.7768
2GCS
Pre-cleavage state of glmS ribozyme
0.25
0.26
0.44
0.5078
1.3053
0.4062
2GDI
Thiamine pyrophosphate-specific riboswitch
0.25
0.38
0.48
0.6500
1.2363
-0.0251
2OEU
Junctionless hairpin ribozyme
0.23
0.30
0.37
0.9519
1.0913
0.7768
2R8S
Tetrahymena ribozyme P4-P6 domain
0.27
0.36
0.53
0.5689
1.1881
0.7281
354D
Loop E from E. coli 5S rRNA
0.28
0.35
0.55
0.4410
1.4938
0.0430"
"CSL
RRE HIGH AFFINITY SITE",0.7583417593528817,"Overall recovery:
0.27
0.32
0.45
0.5682"
"CSL
RRE HIGH AFFINITY SITE",0.7593528816986855,1st best (fit.: 3.41)
"CSL
RRE HIGH AFFINITY SITE",0.7603640040444893,3rd best (fit.: 3.16)
"CSL
RRE HIGH AFFINITY SITE",0.7613751263902933,10th best (fit.: 2.67)
"CSL
RRE HIGH AFFINITY SITE",0.7623862487360971,50th best (fit.: 2.27)
"CSL
RRE HIGH AFFINITY SITE",0.7633973710819009,200th best (fit.: 1.94)
"CSL
RRE HIGH AFFINITY SITE",0.7644084934277048,wildtype
"CSL
RRE HIGH AFFINITY SITE",0.7654196157735086,"1
10
50
100
200
403
1500
5000
17027
Selected sequences for assaying"
X,0.7664307381193124,"0x
1x
0x"
X,0.7674418604651163,3x
X,0.7684529828109201,6x
X,0.7694641051567239,9x
X,0.7704752275025278,12x
X,0.7714863498483316,15x
X,0.7724974721941354,18x
X,0.7735085945399394,21x
X,0.7745197168857432,24x
X,0.775530839231547,27x
X,0.7765419615773509,30x
X,0.7775530839231547,Expected 'max' fold change over WT
X,0.7785642062689585,"Max Fitness by Sample Size and Condition (n=47,504; simulations=10,000)"
X,0.7795753286147624,Condition
X,0.7805864509605662,"random
n_mut==1
n_mut<=2
gRNAde
0.00 1.10 1.79 2.20 2.48 2.71 2.89 3.04 3.18 3.30 3.40"
X,0.78159757330637,Fitness
X,0.782608695652174,"Figure 10: Retrospective study of gRNAde for ranking ribozyme mutant fitness (t1 subunit).
Using the backbone structure and mutational fitness landscape data from an RNA polymerase
ribozyme [McRae et al., 2024], we retrospectively analyse how well we can rank variants at multiple
design budgets using random selection vs. gRNAde’s perplexity for mutant sequences conditioned on
the backbone structure (scaffolding subunit t1). gRNAde performs better than single site saturation
mutagenesis, even when all single mutants are explored (total of 403 single mutants, 17,027 double
mutants for the scaffolding subunit t1 in McRae et al. [2024]). See Section 4.3 for results on catalytic
subunit 5TU and further discussions."
X,0.7836198179979778,"F
Additional Figures
624"
X,0.7846309403437816,"Figure 11: RNA backbone featurization.
625"
X,0.7856420626895855,"Figure 12: gRNAde model architecture.
626"
X,0.7866531850353893,"Figure 13: In-silico evaluation metrics for gRNAde.
627"
X,0.7876643073811931,"Figure 14: Multi-graph tensor representation of RNA conformational ensembles.
628"
X,0.788675429726997,"Listing 1: Pseudocode for multi-state GNN encoder layer.
629"
X,0.7896865520728008,"Figure 15: RNASolo data statistics.
630 P O5' C5' C4'"
X,0.7906976744186046,"C3'
C2' C1' O4' O3' P P P C4'"
X,0.7917087967644085,"RNA backbone atoms
Coarse-grained features"
X,0.7927199191102123,Node (nucleotide)
X,0.7937310414560161,Backbone chain
D NEIGHBOURHOOD,0.7947421638018201,3D neighbourhood
X DISTANCES,0.7957532861476239,"3x distances
3x angles
3x torsions
Ribose sugar Base"
"-BEAD
REPRESENTATION",0.7967644084934277,"3-bead
representation
(P, C4', N1/N9) N1/N9 5' 3'"
"-BEAD
REPRESENTATION",0.7977755308392316,"Figure 11: gRNAde featurizes RNA backbone structures as 3D geometric graphs. Each RNA
nucleotide is a node in the graph, consisting of 3 coarse-grained beads for the coordinates for P, C4’,
N1 (pyrimidines) or N9 (purines) which are used to compute initial geometric features and edges to
nearest neighbours in 3D space. Backbone chain figure adapted from Ingraham et al. [2019]."
"-BEAD
REPRESENTATION",0.7987866531850354,"GVP-GNN
encoder layer"
"-BEAD
REPRESENTATION",0.7997977755308392,"GVP-GNN
encoder layer"
"-BEAD
REPRESENTATION",0.8008088978766431,Backbone k
"-BEAD
REPRESENTATION",0.8018200202224469,Backbone 1
"-BEAD
REPRESENTATION",0.8028311425682507,Autoregressive
"-BEAD
REPRESENTATION",0.8038422649140546,"decoder
+ ..."
"-BEAD
REPRESENTATION",0.8048533872598584,A G C U
"-BEAD
REPRESENTATION",0.8058645096056622,Per-node
"-BEAD
REPRESENTATION",0.8068756319514662,logits
"-BEAD
REPRESENTATION",0.80788675429727,Deep Set
"-BEAD
REPRESENTATION",0.8088978766430738,Pooling x L x L
"-BEAD
REPRESENTATION",0.8099089989888777,Node Embeddings
"-BEAD
REPRESENTATION",0.8109201213346815,GAGCG_
"-BEAD
REPRESENTATION",0.8119312436804853,"Sampling
Partial
sequence"
"-BEAD
REPRESENTATION",0.8129423660262892,"Figure 12: gRNAde model architecture. One or more RNA backbone geometric graphs are encoded
via a series of SE(3)-equivariant Graph Neural Network layers [Jing et al., 2020] to build latent
representations of the local 3D geometric neighbourhood of each nucleotide within each state.
Representations from multiple states for each nucleotide are then pooled together via permutation
invariant Deep Sets [Zaheer et al., 2017], and fed to an autoregressive decoder to predict a probabilities
over the four possible bases (A, G, C, U). The probability distribution can be sampled to design
a set of candidate sequences. During training, the model is trained end-to-end by minimising a
cross-entropy loss between the predicted probability distribution and the true sequence identity."
"-BEAD
REPRESENTATION",0.813953488372093,Backbone graph
"-BEAD
REPRESENTATION",0.8149646107178968,"Sampled
sequences"
"-BEAD
REPRESENTATION",0.8159757330637007,"Predicted
structures
True
sequence ..."
"-BEAD
REPRESENTATION",0.8169868554095046,gRNAde
"-BEAD
REPRESENTATION",0.8179979777553084,"2D: EternaFold
3D: RhoFold ..."
"-BEAD
REPRESENTATION",0.8190091001011123,"True
structure"
"-BEAD
REPRESENTATION",0.8200202224469161,Sequence recovery
"-BEAD
REPRESENTATION",0.8210313447927199,Structural self-consistency scores
"-BEAD
REPRESENTATION",0.8220424671385238,"2D: MCC, 3D: RMSD, TM, GDT"
"-BEAD
REPRESENTATION",0.8230535894843276,"Figure 13: In-silico evaluation metrics for gRNAde designed sequences. We consider (1) sequence
recovery, the percentage of native nucleotides recovered in designed samples, (2) self-consistency
scores, which are measured by ‘forward folding’ designed sequences using a structure predictor
and measuring how well 2D and 3D structure are recovered (we use EternaFold and RhoFold for
2D/3D structure prediction, respectively). We also report (3) perplexity, the model’s estimate of the
likelihood of a sequence given a backbone."
"-BEAD
REPRESENTATION",0.8240647118301314,Set of RNA Conformations
"-BEAD
REPRESENTATION",0.8250758341759353,Multi-graph
"-BEAD
REPRESENTATION",0.8260869565217391,tensor 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5
"PERMUTE NODES
PERMUTE CONFORMERS",0.8270980788675429,"6
Permute nodes
Permute conformers"
"PERMUTE NODES
PERMUTE CONFORMERS",0.8281092012133469,Rotate 3D features 1 2 3 4 5 6
"PERMUTE NODES
PERMUTE CONFORMERS",0.8291203235591507,"Update with
multi-GNN layer 1 2 3 4 5 6"
"PERMUTE NODES
PERMUTE CONFORMERS",0.8301314459049545,"Figure 14: Multi-graph tensor representation of RNA conformational ensembles, and the asso-
ciated symmetry groups acting on each axis. We process a set of k RNA backbone conformations
with n nodes each into a tensor representation. Each multi-state GNN layer updates the tensor while
being equivariant to the underlying symmetries; pseudocode is available in Listing 1. Here, we show
a tensor of 3D vector-type features with shape n × k × 3. As depicted in the equivariance diagram,
the updated tensor must be equivariant to permutation Sn of n nodes for axis 1, permutation Sk of k
conformers for axis 2, and rotation SO(3)/O(3) of the 3D features for axis 3."
CLASS,0.8311425682507584,"1 class
MultiGVPConv( MessagePassing ):"
CLASS,0.8321536905965622,"2
’’’GVPConv
for
handling
multiple
conformations ’’’ 3"
DEF,0.833164812942366,"4
def
__init__(self , ...): 5
... 6"
DEF,0.8341759352881699,"7
def
forward(self , x_s , x_v , edge_index , edge_attr): 8"
DEF,0.8351870576339737,"9
# stack
scalar
feats
along
axis 1:"
DEF,0.8361981799797775,"10
# [n_nodes , n_conf , d_s] -> [n_nodes , n_conf * d_s]"
DEF,0.8372093023255814,"11
x_s = x_s.view(x_s.shape [0], x_s.shape [1] * x_s.shape [2]) 12"
DEF,0.8382204246713852,"13
# stack
vector
feat
along
axis 1:"
DEF,0.839231547017189,"14
# [n_nodes , n_conf , d_v , 3] -> [n_nodes , n_conf * d_v *3]"
DEF,0.840242669362993,"15
x_v = x_v.view(x_v.shape [0], x_v.shape [1] * x_v.shape [2]*3) 16"
DEF,0.8412537917087968,"17
# message
passing
and
aggregation"
DEF,0.8422649140546006,"18
message = self.propagate("
DEF,0.8432760364004045,"19
edge_index , s=x_s , v=x_v , edge_attr=edge_attr) 20"
DEF,0.8442871587462083,"21
# split
scalar and vector
channels"
RETURN,0.8452982810920121,"22
return
_split_multi(message , d_s , d_v , n_conf) 23"
DEF,0.846309403437816,"24
def
message(self , s_i , v_i , s_j , v_j , edge_attr): 25"
DEF,0.8473205257836198,"26
# unstack
scalar
feats:"
DEF,0.8483316481294236,"27
# [n_nodes , n_conf * d] -> [n_nodes , n_conf , d_s]"
DEF,0.8493427704752275,"28
s_i = s_i.view(s_i.shape [0], s_i.shape [1]// d_s , d_s)"
DEF,0.8503538928210314,"29
s_j = s_j.view(s_j.shape [0], s_j.shape [1]// d_s , d_s) 30"
DEF,0.8513650151668352,"31
# unstack
vector
feats:"
DEF,0.8523761375126391,"32
# [n_nodes , n_conf * d_v *3] -> [n_nodes , n_conf , d_v , 3]"
DEF,0.8533872598584429,"33
v_i = v_i.view(v_i.shape [0], v_i.shape [1]//( d_v *3), d_v , 3)"
DEF,0.8543983822042467,"34
v_j = v_j.view(v_j.shape [0], v_j.shape [1]//( d_v *3), d_v , 3) 35"
DEF,0.8554095045500506,"36
# message
function
for edge j-i"
DEF,0.8564206268958544,"37
message = tuple_cat ((s_j , v_j), edge_attr , (s_i , v_i))"
DEF,0.8574317492416582,"38
message = self.message_func(message)
# GVP 39"
DEF,0.8584428715874621,"40
# merge
scalar and vector
channels
along
axis 1"
RETURN,0.8594539939332659,"41
return
_merge_multi (* message) 42"
DEF,0.8604651162790697,"43 def
_split_multi(x, d_s , d_v , n_conf):"
DEF,0.8614762386248737,"44
’’’"
SPLITS A MERGED,0.8624873609706775,"45
Splits a merged
representation of (s, v) back into a tuple."
SPLITS A MERGED,0.8634984833164813,"46
’’’"
SPLITS A MERGED,0.8645096056622852,"47
s = x[..., :-3 * d_v * n_conf ]. view(x.shape [0], n_conf , d_s)"
SPLITS A MERGED,0.865520728008089,"48
v = x[...,
-3 * d_v * n_conf :]. view(x.shape [0], n_conf , d_v , 3)"
SPLITS A MERGED,0.8665318503538928,"49
return s, v 50"
DEF,0.8675429726996967,"51 def
_merge_multi(s, v):"
DEF,0.8685540950455005,"52
’’’"
DEF,0.8695652173913043,"53
Merges a tuple (s, v) into a single ‘torch.Tensor ‘,"
"WHERE THE VECTOR
CHANNELS
ARE
FLATTENED
AND",0.8705763397371082,"54
where the vector
channels
are
flattened
and"
APPENDED TO THE SCALAR,0.871587462082912,"55
appended to the scalar
channels."
APPENDED TO THE SCALAR,0.8725985844287159,"56
’’’"
APPENDED TO THE SCALAR,0.8736097067745198,"57
# s: [n_nodes , n_conf , d] -> [n_nodes , n_conf * d_s]"
APPENDED TO THE SCALAR,0.8746208291203236,"58
s = s.view(s.shape [0], s.shape [1] * s.shape [2])"
APPENDED TO THE SCALAR,0.8756319514661274,"59
# v: [n_nodes , n_conf , d, 3] -> [n_nodes , n_conf * d_v *3]"
APPENDED TO THE SCALAR,0.8766430738119313,"60
v = v.view(v.shape [0], v.shape [1] * v.shape [2]*3)"
RETURN,0.8776541961577351,"61
return
torch.cat([s, v],
-1)
Listing 1: PyG-style pseudocode for a multi-state GVP-GNN layer. We update node features for
each conformer independently while maintaining permutation equivariance of the updated feature
tensors along both the first (no. of nodes) and second (no. of conformations) axes."
RETURN,0.8786653185035389,"0
1000
2000
3000
4000
Sequence length 0 200 400 600 800 1000 1200 1400"
RETURN,0.8796764408493428,Frequency
RETURN,0.8806875631951466,"Histogram of sequence lengths
Distribution: 684.9 ± 1072.8, Max: 4455, Min: 11"
RETURN,0.8816986855409504,"0
50
100
150
200
0 100 200 300"
RETURN,0.8827098078867543,"(a) Sequence length.
The dataset is long-tailed
in terms of RNA sequence length, with many
short sequences including aptamers, riboswitches,
ribozymes, and tRNAs (fewer than 200 nucleotides).
The dataset also includes several longer ribosomal
RNAs (thousands of nucleotides)."
RETURN,0.8837209302325582,"0
10
20
30
40
50
Number of structures per sequence 0 500 1000 1500 2000 2500"
RETURN,0.884732052578362,Frequency
RETURN,0.8857431749241659,Histogram of no. of structures per unique sequence
RETURN,0.8867542972699697,"Distribution: 2.84 ± 9.39, Max: 267, Min: 1"
RETURN,0.8877654196157735,"5
10
15
20
0 200 400 600 800"
RETURN,0.8887765419615774,Sequences with >1 structure
RETURN,0.8897876643073812,"(b) Number of structures per sequence. The dataset
covers a wide range of RNA conformation ensembles,
with on average 3 structures per sequence. There
are multiple structures available for 1,547 sequences.
The remaining 2,676 sequences have one correspond-
ing structure."
RETURN,0.890798786653185,"0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5"
RETURN,0.8918099089989889,Avg. pairwise RMSD among structures per sequence (Å) 0 50 100 150 200 250 300 350 400
RETURN,0.8928210313447927,Frequency
RETURN,0.8938321536905965,Histogram of avg. pairwise RMSD per sequence
RETURN,0.8948432760364005,"Distribution: 1.33Å ± 1.89, Max: 18.35Å, Min: 0.00Å"
RETURN,0.8958543983822043,"0
1
2
3
4
5
0 20 40 60"
RETURN,0.8968655207280081,"(c) Average pairwise RMSD per sequence. For
1,547 sequences with multiple structures, there is
significant structural diversity among conformations.
On average, the pairwise C4’ RMSD among the set
of structures for a sequence is greater than 1Å."
RETURN,0.897876643073812,"101
102
103"
RETURN,0.8988877654196158,Sequence length (log scale) 0 1 2 3 4 5 6 7
RETURN,0.8998988877654196,Avg. pairwise RMSD among structures (Å)
RETURN,0.9009100101112234,"(d) Bivariate distribution for sequence length vs.
avg. RMSD. The joint plot illustrates how structural
diversity (measured by avg. pairwise RMSD) varies
across sequence lengths. We notice similar structural
variations regardless of sequence length."
RETURN,0.9019211324570273,"Figure 15: RNASolo data statistics. We plot histograms to visualise the diversity of RNAs available
in terms of (a) sequence length, (b) number of structures available per sequence, as well as (c)
structural variation among conformations for those RNA that have multiple structures. The bivariate
distribution plot (d) for sequence length vs. average pairwise RMSD illustrates structural diversity
regardless of sequence lengths."
RETURN,0.9029322548028311,"NeurIPS Paper Checklist
631"
CLAIMS,0.9039433771486349,"1. Claims
632"
CLAIMS,0.9049544994944388,"Question: Do the main claims made in the abstract and introduction accurately reflect the paper’s
633"
CLAIMS,0.9059656218402427,"contributions and scope?
634"
CLAIMS,0.9069767441860465,"Answer: [Yes]
635"
CLAIMS,0.9079878665318504,"Justification: Yes, the main claims made in the abstract are that the proposed 3D RNA design
636"
CLAIMS,0.9089989888776542,"method, gRNAde, improves sequence recovery over Rosetta, is capable of multi-state design,
637"
CLAIMS,0.910010111223458,"and can be useful for zero-shot ranking of RNA fitness landscapes. All the claims are supported
638"
CLAIMS,0.9110212335692619,"by empirical results and expanded upon in detail in the rest of the paper.
639"
LIMITATIONS,0.9120323559150657,"2. Limitations
640"
LIMITATIONS,0.9130434782608695,"Question: Does the paper discuss the limitations of the work performed by the authors?
641"
LIMITATIONS,0.9140546006066734,"Answer: [Yes]
642"
LIMITATIONS,0.9150657229524772,"Justification: Yes, we have discussed limitations at several places, including the conclusion
643"
LIMITATIONS,0.916076845298281,"section, an FAQ section, as well as a detailed ablation study in the appendix.
644"
THEORY ASSUMPTIONS AND PROOFS,0.917087967644085,"3. Theory Assumptions and Proofs
645"
THEORY ASSUMPTIONS AND PROOFS,0.9180990899898888,"Question: For each theoretical result, does the paper provide the full set of assumptions and a
646"
THEORY ASSUMPTIONS AND PROOFS,0.9191102123356926,"complete (and correct) proof?
647"
THEORY ASSUMPTIONS AND PROOFS,0.9201213346814965,"Answer: [NA]
648"
THEORY ASSUMPTIONS AND PROOFS,0.9211324570273003,"Justification: The paper does not include theoretical results.
649"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9221435793731041,"4. Experimental Result Reproducibility
650"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.923154701718908,"Question: Does the paper fully disclose all the information needed to reproduce the main
651"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9241658240647118,"experimental results of the paper to the extent that it affects the main claims and/or conclusions
652"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9251769464105156,"of the paper (regardless of whether the code and data are provided or not)?
653"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9261880687563195,"Answer: [Yes]
654"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9271991911021233,"Justification: All code, data, and pretrained models are publicly available, along with detailed
655"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9282103134479271,"instructions on installation, reproducing results, and real-world usage.
656"
OPEN ACCESS TO DATA AND CODE,0.9292214357937311,"5. Open access to data and code
657"
OPEN ACCESS TO DATA AND CODE,0.9302325581395349,"Question: Does the paper provide open access to the data and code, with sufficient instructions
658"
OPEN ACCESS TO DATA AND CODE,0.9312436804853387,"to faithfully reproduce the main experimental results, as described in supplemental material?
659"
OPEN ACCESS TO DATA AND CODE,0.9322548028311426,"Answer: [Yes]
660"
OPEN ACCESS TO DATA AND CODE,0.9332659251769464,"Justification: All data and code is publicly available, including the exact commands and environ-
661"
OPEN ACCESS TO DATA AND CODE,0.9342770475227502,"ments needed to access the raw data, process the data, and reproduce the results.
662"
OPEN ACCESS TO DATA AND CODE,0.9352881698685541,"6. Experimental Setting/Details
663"
OPEN ACCESS TO DATA AND CODE,0.9362992922143579,"Question: Does the paper specify all the training and test details (e.g., data splits, hyperparame-
664"
OPEN ACCESS TO DATA AND CODE,0.9373104145601617,"ters, how they were chosen, type of optimizer, etc.) necessary to understand the results?
665"
OPEN ACCESS TO DATA AND CODE,0.9383215369059656,"Answer: [Yes]
666"
OPEN ACCESS TO DATA AND CODE,0.9393326592517695,"Justification: The experimental setup is presented in detail as a dedicated section in the main
667"
OPEN ACCESS TO DATA AND CODE,0.9403437815975733,"text, as well as extensively documented in the code.
668"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9413549039433772,"7. Experiment Statistical Significance
669"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.942366026289181,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
670"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9433771486349848,"information about the statistical significance of the experiments?
671"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9443882709807887,"Answer: [Yes]
672"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9453993933265925,"Justification: All results are accompanied by error bars and confidence intervals, along with the
673"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9464105156723963,"factors of variability that the error bars capture.
674"
EXPERIMENTS COMPUTE RESOURCES,0.9474216380182002,"8. Experiments Compute Resources
675"
EXPERIMENTS COMPUTE RESOURCES,0.948432760364004,"Question: For each experiment, does the paper provide sufficient information on the computer
676"
EXPERIMENTS COMPUTE RESOURCES,0.9494438827098078,"resources (type of compute workers, memory, time of execution) needed to reproduce the
677"
EXPERIMENTS COMPUTE RESOURCES,0.9504550050556118,"experiments?
678"
EXPERIMENTS COMPUTE RESOURCES,0.9514661274014156,"Answer: [Yes]
679"
EXPERIMENTS COMPUTE RESOURCES,0.9524772497472194,"Justification: Yes, the paper and code provide information on the computer resources used for
680"
EXPERIMENTS COMPUTE RESOURCES,0.9534883720930233,"this work. However, we currently do not have estimes on the total compute used.
681"
CODE OF ETHICS,0.9544994944388271,"9. Code Of Ethics
682"
CODE OF ETHICS,0.9555106167846309,"Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS
683"
CODE OF ETHICS,0.9565217391304348,"Code of Ethics https://neurips.cc/public/EthicsGuidelines?
684"
CODE OF ETHICS,0.9575328614762386,"Answer: [Yes]
685"
CODE OF ETHICS,0.9585439838220424,"Justification: The research conforms with the NeurIPS Code of Ethics.
686"
BROADER IMPACTS,0.9595551061678463,"10. Broader Impacts
687"
BROADER IMPACTS,0.9605662285136501,"Question: Does the paper discuss both potential positive societal impacts and negative societal
688"
BROADER IMPACTS,0.961577350859454,"impacts of the work performed?
689"
BROADER IMPACTS,0.9625884732052579,"Answer: [Yes]
690"
BROADER IMPACTS,0.9635995955510617,"Justification: We hope that our tools contributes to the development of RNA-based therapeutics
691"
BROADER IMPACTS,0.9646107178968655,"towards improving health outcomes. We have attempted to make gRNAde as convinient to use
692"
BROADER IMPACTS,0.9656218402426694,"as possible towards this end. We do not foresee any immediate negative societal impact of our
693"
BROADER IMPACTS,0.9666329625884732,"work.
694"
SAFEGUARDS,0.967644084934277,"11. Safeguards
695"
SAFEGUARDS,0.9686552072800809,"Question: Does the paper describe safeguards that have been put in place for responsible release
696"
SAFEGUARDS,0.9696663296258847,"of data or models that have a high risk for misuse (e.g., pretrained language models, image
697"
SAFEGUARDS,0.9706774519716885,"generators, or scraped datasets)?
698"
SAFEGUARDS,0.9716885743174924,"Answer: [NA]
699"
SAFEGUARDS,0.9726996966632963,"Justification: The paper poses no such risks.
700"
LICENSES FOR EXISTING ASSETS,0.9737108190091001,"12. Licenses for existing assets
701"
LICENSES FOR EXISTING ASSETS,0.974721941354904,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in the
702"
LICENSES FOR EXISTING ASSETS,0.9757330637007078,"paper, properly credited and are the license and terms of use explicitly mentioned and properly
703"
LICENSES FOR EXISTING ASSETS,0.9767441860465116,"respected?
704"
LICENSES FOR EXISTING ASSETS,0.9777553083923155,"Answer: [Yes]
705"
LICENSES FOR EXISTING ASSETS,0.9787664307381193,"Justification: Original owners of any assets used as part of our stidy are appropriately credited.
706"
NEW ASSETS,0.9797775530839231,"13. New Assets
707"
NEW ASSETS,0.980788675429727,"Question: Are new assets introduced in the paper well documented and is the documentation
708"
NEW ASSETS,0.9817997977755308,"provided alongside the assets?
709"
NEW ASSETS,0.9828109201213346,"Answer: [Yes]
710"
NEW ASSETS,0.9838220424671386,"Justification: Our datasets, code, and model checkpoints are publicly available under the
711"
NEW ASSETS,0.9848331648129424,"permissive MIT License.
712"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9858442871587462,"14. Crowdsourcing and Research with Human Subjects
713"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9868554095045501,"Question: For crowdsourcing experiments and research with human subjects, does the paper
714"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9878665318503539,"include the full text of instructions given to participants and screenshots, if applicable, as well as
715"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9888776541961577,"details about compensation (if any)?
716"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9898887765419616,"Answer: [NA]
717"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9908998988877654,"Justification: The paper does not involve crowdsourcing nor research with human subjects.
718"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9919110212335692,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
719"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9929221435793731,"Subjects
720"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.993933265925177,"Question: Does the paper describe potential risks incurred by study participants, whether such
721"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9949443882709808,"risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or
722"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9959555106167847,"an equivalent approval/review based on the requirements of your country or institution) were
723"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9969666329625885,"obtained?
724"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9979777553083923,"Answer: [NA]
725"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9989888776541962,"Justification: The paper does not involve crowdsourcing nor research with human subjects.
726"
