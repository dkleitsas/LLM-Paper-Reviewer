Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0017452006980802793,"In learning with noisy labels, the sample selection approach is very popular, which
regards small-loss data as correctly labeled during training. However, losses are
generated on-the-ﬂy based on the model being trained with noisy labels, and
thus large-loss data are likely but not certain to be incorrect. There are actually
two possibilities of a large-loss data point: (a) it is mislabeled, and then its loss
decreases slower than other data, since deep neural networks “learn patterns ﬁrst”;
(b) it belongs to an underrepresented group of data and has not been selected yet. In
this paper, we incorporate the uncertainty of losses by adopting interval estimation
instead of point estimation of losses, where lower bounds of the conﬁdence intervals
of losses derived from distribution-free concentration inequalities, but not losses
themselves, are used for sample selection. In this way, we also give large-loss but
less selected data a try; then, we can better distinguish between the cases (a) and
(b) by seeing if the losses effectively decrease with the uncertainty after the try. As
a result, we can better explore underrepresented data that are correctly labeled but
seem to be mislabeled at ﬁrst glance. Experiments demonstrate that the proposed
method is superior to baselines and robust to a broad range of label noise types."
INTRODUCTION,0.0034904013961605585,"1
INTRODUCTION"
INTRODUCTION,0.005235602094240838,"Learning with noisy labels is one of the most challenging problems in weakly-supervised learning,
since noisy labels are ubiquitous in the real world (Mirzasoleiman et al., 2020; Yu et al., 2019; Nishi
et al., 2021; Arazo et al., 2019; Yang et al., 2021a; Bai & Liu, 2021). For instance, both crowdsourcing
and web crawling yield large numbers of noisy labels everyday (Han et al., 2018). Noisy labels can
severely impair the performance of deep neural networks with strong memorization capacities (Zhang
et al., 2017; Zhang & Sabuncu, 2018; Pleiss et al., 2020; Lukasik et al., 2020; Chen et al., 2022)."
INTRODUCTION,0.006980802792321117,"To reduce the inﬂuence of noisy labels, a lot of approaches have been recently proposed (Natarajan
et al., 2013; Liu & Tao, 2016; Ma et al., 2018; Yang et al., 2021b; Zheng et al., 2020; Xia et al., 2019;
2020; Tanaka et al., 2018; Malach & Shalev-Shwartz, 2017; Li et al., 2020b; Menon et al., 2018;
Thekumparampil et al., 2018; Xu et al., 2019; Kim et al., 2019; Jiang et al., 2020; Harutyunyan et al.,
2020). They can be generally divided into two main categories. The ﬁrst one is to estimate the noise
transition matrix (Patrini et al., 2017; Shu et al., 2020; Hendrycks et al., 2018; Yang et al., 2021c; Wu
et al., 2022), which denotes the probabilities that clean labels ﬂip into noisy labels. However, the
noise transition matrix is hard to be estimated accurately, especially when the number of classes is
large (Yu et al., 2019). The second approach is sample selection, which is our focus in this paper. This
approach is based on selecting possibly clean examples from a mini-batch for training (Han et al.,
2018; Wang et al., 2018; Yao et al., 2020a; Wang et al., 2019; Yu et al., 2019; Lee et al., 2019; Wang
et al., 2019; Yao et al., 2022). Intuitively, if we can exploit less noisy data for network parameter
updates, the network will be more robust."
INTRODUCTION,0.008726003490401396,"A major question in sample selection is what criteria can be used to select possibly clean examples.
At the present stage, the selection based on the small-loss criteria is the most common method, and
has been veriﬁed to be effective in many circumstances (Han et al., 2018; Jiang et al., 2018; Yu et al.,"
INTRODUCTION,0.010471204188481676,†Corresponding author
INTRODUCTION,0.012216404886561954,Published as a conference paper at ICLR 2022
INTRODUCTION,0.013961605584642234,"1
2
3
4
5
Epoch 0.25 0.50 0.75 1.00 1.25 1.50 1.75 Loss"
INTRODUCTION,0.015706806282722512,"Clean
Mislabeled
Clean (Mean)
Mislabeled (Mean)"
INTRODUCTION,0.017452006980802792,"Clean
Mislabeled
Clean Balanced Clean Imbalanced
0.0 0.2 0.4 0.6 0.8 1.0 1.2"
INTRODUCTION,0.019197207678883072,Average Loss
INTRODUCTION,0.020942408376963352,"Figure 1: Illustrations of uncertainty of losses. Experiments are conducted on the imbalanced noisy MNIST
dataset. Left: uncertainty of small-loss examples. At the beginning of training (Epochs 1 and 2), due to the
instability of the current prediction, the network gives a larger loss to the clean example and does not select it
for updates. If we consider the mean of training losses at different epochs, the clean example can be equipped
with a smaller loss and then selected for updates. Right: uncertainty of large-loss examples. Since the deep
network learns easy examples at the beginning of training, it gives a large loss to clean imbalanced data with
non-dominant labels, which causes such data unable to be selected and severely inﬂuence generalization."
INTRODUCTION,0.02268760907504363,"2019; Wei et al., 2020; Yao et al., 2020a). Speciﬁcally, since deep networks learn patterns ﬁrst (Arpit
et al., 2017), they would ﬁrst memorize training data of clean labels and then those of noisy labels
with the assumption that clean labels are of the majority in a noisy class. Small-loss examples can
thus be regarded as clean examples with high probability. Therefore, in each iteration, prior methods
(Han et al., 2018; Wei et al., 2020) select the small-loss examples based on the predictions of the
current network for robust training."
INTRODUCTION,0.02443280977312391,"However, such a selection procedure is debatable, since it arguably does not consider uncertainty
in selection. The uncertainty comes from two aspects. First, this procedure has uncertainty about
small-loss examples. Speciﬁcally, the procedure uses limited time intervals and only exploits the
losses provided by the current predictions. For this reason, the estimation for the noisy class posterior
is unstable (Yao et al., 2020b), which causes the network predictions to be equally unstable. It
thus takes huge risks to only use losses provided by the current predictions (Figure 1, left). Once
wrong selection is made, the inferiority of accumulated errors will arise (Yu et al., 2019). Second,
this procedure has uncertainty about large-loss examples. To be speciﬁc, deep networks learn easy
examples at the beginning of training, but ignore some clean examples with large losses. Nevertheless,
such examples are always critical for generalization. For instance, when learning with imbalanced
data, distinguishing the examples with non-dominant labels are more pivotal during training (Menon
et al., 2020; Wei et al., 2021). Deep networks often give large losses to such examples (Figure 1,
right). Therefore, when learning under the realistic scenes, e.g., learning with noisy imbalanced data,
prior sample selection methods cannot address such an issue well."
INTRODUCTION,0.02617801047120419,"To relieve the above issues, we study the uncertainty of losses in the sample selection procedure to
combat noisy labels. To reduce the uncertainty of small-loss examples, we extend time intervals and
utilize the mean of training losses at different training iterations. In consideration of the bad inﬂuence
of mislabeled data on training losses, we build two robust mean estimators from the perspectives of
soft truncation and hard truncation w.r.t. the truncation level, respectively. Soft truncation makes
the mean estimation more robust by holistically changing the behavior of losses. Hard truncation
makes the mean estimation more robust by locally removing outliers from losses. To reduce the
uncertainty of large-loss examples, we encourage networks to pick the sample that has not been
selected in a conservative way. Furthermore, to address the two issues simultaneously, we derive
concentration inequalities (Boucheron et al., 2013) for robust mean estimation and further employ
statistical conﬁdence bounds (Auer, 2002) to consider the number of times an example was selected
during training."
INTRODUCTION,0.027923211169284468,"The study of uncertainty of losses in learning with noisy labels can be justiﬁed as follows. In statistical
learning, it is known that uncertainty is related to the quality of data (Vapnik, 2013). Philosophically,
we need variety decrease for selected data and variety search for unselected data, which share a
common objective, i.e., reduce the uncertainty of data to improve generalization (Moore, 1990). This
is our original intention, since noisy labels could bring more uncertainty because of the low quality
of noisy data. Nevertheless, due to the harm of noisy labels for generalization, we need to strike a
good balance between variety decrease and search. Technically, our method is specially designed for"
INTRODUCTION,0.029668411867364748,Published as a conference paper at ICLR 2022
INTRODUCTION,0.031413612565445025,"handling noisy labels, which robustly uses network predictions and conservatively seeks less selected
examples meanwhile to reduce the uncertainty of losses and then generalize well."
INTRODUCTION,0.03315881326352531,"Before delving into details, we clearly emphasize our contributions in two folds. First, we reveal prior
sample selection criteria in learning with noisy labels have some potential weaknesses and discuss
them in detail. The new selection criteria are then proposed with detailed theoretical analyses. Second,
we experimentally validate the proposed method on both synthetic noisy balanced/imbalanced datasets
and real-world noisy datasets, on which it achieves superior robustness compared with the state-
of-the-art methods in learning with noisy labels. The rest of the paper is organized as follows. In
Section 2, we propose our robust learning paradigm step by step. Experimental results are discussed
in Section 3. The conclusion is given in Section 4."
METHOD,0.034904013961605584,"2
METHOD"
METHOD,0.03664921465968586,"In this section, we ﬁrst introduce the problem setting and some background (Section 2.1). Then we
discuss how to exploit training losses at different iterations (Section 2.2). Finally, we introduce the
proposed method, which exploits training losses at different iterations more robustly and encourages
networks to pick the sample that is less selected but could be correctly labeled (Section 2.3)."
PRELIMINARIES,0.038394415357766144,"2.1
PRELIMINARIES"
PRELIMINARIES,0.04013961605584642,"Let X and Y be the input and output spaces. Consider a k-class classiﬁcation problem, i.e., Y = [k],
where [k] = {1, . . . , k}. In learning with noisy labels, the training data are all sampled from a
corrupted distribution on X × Y. We are given a sample with noisy labels, i.e., ˜S = {(x, ˜y)}, where
˜y is the noisy label. The aim is to learn a robust classiﬁer that could assign clean labels to test data by
only exploiting a training sample with noisy labels."
PRELIMINARIES,0.041884816753926704,"Let f : X →Rk be the classiﬁer with learnable parameters w. At the i-th iteration during training,
the parameters of the classiﬁer f can be denoted as wi. Let ℓ: Rk × Y →R be a surrogate loss
function for k-class classiﬁcation. We exploit the softmax cross entropy loss in this paper. Given an
arbitrary training example (x, ˜y), at the i-th iteration, we can obtain a loss ℓi, i.e., ℓi = ℓ(f(wi; x), ˜y).
Hence, until the t-th iteration, we can obtain a training loss set Lt about the example (x, ˜y), i.e.,
Lt = {ℓ1, . . . , ℓt}."
PRELIMINARIES,0.04363001745200698,"In this paper, we assume that the training losses in Lt conform to a Markov process, which is to
represent a changing system under the assumption that future states only depend on the current
state (the Markov property). More speciﬁcally, at the i-th iteration, if we exploit an optimization
algorithm for parameter updates (e.g., the stochastic gradient descent algorithm (Bottou, 2012)) and
omit other dependencies (e.g., ˜S), we will have P(wi|wi−1, . . . , w0) = P(wi|wi−1), which means
that the future state of the classiﬁer f only depends on the current state. Furthermore, given a training
example and the parameters of the classiﬁer f, we can determine the loss of the training example as
discussed. Therefore, the training losses in Lt will also conform to a Markov process."
EXTENDED TIME INTERVALS,0.04537521815008726,"2.2
EXTENDED TIME INTERVALS"
EXTENDED TIME INTERVALS,0.04712041884816754,"As limited time interval cannot address the instability issue of the estimation for the noisy class
posterior well (Pleiss et al., 2020), we extend time intervals and exploit the training losses at different
training iterations for sample selection. One straightforward idea is to use the mean of training losses
at different training iterations. Hence, the selection criterion could be"
EXTENDED TIME INTERVALS,0.04886561954624782,"˜µ = 1 t t
X"
EXTENDED TIME INTERVALS,0.0506108202443281,"i=1
ℓi.
(1)"
EXTENDED TIME INTERVALS,0.05235602094240838,"It is intuitive and reasonable to use such a selection criterion for sample selection, since the operation
of averaging can mitigate the risks caused by the unstable estimation for the noisy class posterior,
following better generalization. Nevertheless, such a method could arguably achieve suboptimal
classiﬁcation performance for learning with noisy labels. The main reason is that, due to the great
harm of mislabeled data, part of training losses are with too large uncertainty and could be seen as
outliers. Therefore, it could be biased to use the mean of training losses consisting of such outliers
(Diakonikolas et al., 2020), which further inﬂuences sample selection. More evaluations for our
claims are provided in Section 3."
EXTENDED TIME INTERVALS,0.05410122164048865,Published as a conference paper at ICLR 2022
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.055846422338568937,"2.3
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.05759162303664921,"We extend time intervals and meanwhile exploit the training losses at different training iterations
more robustly. Speciﬁcally, we build two robust mean estimators from the perspectives of soft
truncation and hard truncation (Catoni, 2012). Note that for speciﬁc tasks, it is feasible to decide
the types of robust mean estimation with statistical tests based on some assumptions (Chakrabarty
& Samorodnitsky, 2012). We leave the analysis as future work. Two distribution-free robust mean
estimators are introduced as follows."
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.059336823734729496,"Soft truncation. We extend a classical M-estimator from (Catoni, 2012) and exploit the widest
possible choice of the inﬂuence function. More speciﬁcally, give a random variable X, let us consider
a non-decreasing inﬂuence function ψ : R →R such that
ψ(X) = log(1 + X + X2/2), X ≥0.
(2)
The choice of ψ is inspired by the Taylor expansion of the exponential function, which can make the
estimation results more robust by reducing the side effect of extremum holistically. The illustration
for this inﬂuence function is provided in Appendix A.1. For our task, given the observations on
training losses, i.e., Lt = {ℓ1, . . . , ℓt}, we estimate the mean robustly as follows:"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.06108202443280977,"˜µs = 1 t t
X"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.06282722513089005,"i=1
ψ(ℓi).
(3)"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.06457242582897033,We term the above robust mean estimator (3) the soft estimator.
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.06631762652705062,"Hard truncation. We propose a new robust mean estimator based on hard truncation. Speciﬁcally,
given the observations on training losses Lt, we ﬁrst exploit the K-nearest neighbor (KNN) algorithm
(Liao & Vemuri, 2002) to remove some underlying outliers in Lt. The number of outliers is denoted
by to(to < t), which can be adaptively determined as discussed in (Zhao et al., 2019). Note that we
can also employ other algorithms, e.g., principal component analysis (Shyu et al., 2003) and the local
outlier factor (Breunig et al., 2000), to identify underlying outliers in Lt. The main reason we employ
KNN is because of its relatively low computation costs (Zhao et al., 2019)."
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.06806282722513089,"The truncated loss observations on training losses are denoted by Lt−to. We then utilize Lt−to for
the mean estimation. As the potential outliers are removed with high probability, the robustness of
the estimation results will be enhanced. We denote such an estimated mean as ˜µh. We have"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.06980802792321117,"˜µh =
1
t −to X"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.07155322862129145,"ℓi∈Lt−to
ℓi.
(4)"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.07329842931937172,The corresponding estimator (4) is termed the hard estimator.
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.07504363001745201,"We derive concentration inequalities for the soft and hard estimators respectively. The search strategy
for less selected examples and overall selection criterion are then provided. Note that we do not need
to explicitly quantify the mean of training losses. We only need to sort the training examples based
on the proposed selection criterion and then use the selected examples for robust training."
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.07678883071553229,"Theorem 1 Let Zn = {z1, · · · , zn} be an observation set with mean µz and variance σ2. By
exploiting the non-decreasing inﬂuence function ψ(z) = log(1 + z + z2/2). For any ϵ > 0, we have

1
n n
X"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.07853403141361257,"i=1
ψ(zi) −µz"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.08027923211169284,≤σ2(n + σ2 log(ϵ−1)
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.08202443280977312,"n2
)
n −σ2
,
(5)"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.08376963350785341,with probability at least 1 −2ϵ.
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.08551483420593368,Proof can be found in Appendix A.1.
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.08726003490401396,"Theorem 2 Let Zn = {z1, . . . , zn} be a (not necessarily time homogeneous) Markov chain with
mean µz, taking values in a Polish state space Λ1 × . . . × Λn, and with a minimal mixing time τmin.
The truncated set with hard truncation is denoted by Zno, with no < n. If |zi| is upper bounded by Z.
For any ϵ1 > 0 and ϵ2 > 0, we have"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.08900523560209424,"1
n −no X"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.09075043630017451,"zi∈Zn\Zno
−µz"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.0924956369982548,"≤
1
n −no"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.09424083769633508,"
2Z
r"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.09598603839441536,2τmin log 2
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.09773123909249563,"ϵ1
+ 2Zno n r"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.09947643979057591,2τmin log 2n ϵ2
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.1012216404886562,"
,
(6)"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.10296684118673648,with probability at least 1 −ϵ1 −ϵ2.
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.10471204188481675,Published as a conference paper at ICLR 2022
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.10645724258289703,"Proof can be found in Appendix A.2. For our task, let the training loss be upper-bounded by L. The
value of L can be determined easily by training networks on noisy datasets and observing the loss
distribution (Arazo et al., 2019)."
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.1082024432809773,"Conservative search and selection criteria. In this paper, we will use the concentration inequalities
(5) and (6) to present conservative search and the overall sample selection criterion. Speciﬁcally,
we exploit their lower bounds and consider the selected number of examples during training. The
selection of the examples that are less selected is encouraged."
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.1099476439790576,"Denote the number of times one example was selected by nt(nt ≤t). Let ϵ =
1
2t. For the
circumstance with soft truncation, the selection criterion is"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.11169284467713787,"ℓ⋆
s = ˜µs −σ2(t + σ2 log(2t)"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.11343804537521815,"t2
)
nt −σ2
.
(7)"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.11518324607329843,Let ϵ1 = ϵ2 = 1
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.1169284467713787,"2t, for the situation with hard truncation, by rewriting (6), the selection criterion is"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.11867364746945899,"ℓ⋆
h = ˜µh −2√2τminL(t +
√"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.12041884816753927,"2to)
(t −to)
√ t s"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.12216404886561955,log(4t)
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.12390924956369982,"nt
.
(8)"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.1256544502617801,"Note that we directly replace t with nt. If an example is rarely selected during training, nt will be far
less than n, which causes the lower bounds to change drastically. Hence, we do not use the mean of
all training losses, but use the mean of training losses in ﬁxed-length time intervals. More details
about this can be checked in Section 3."
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.1273996509598604,"For the selection criteria (7) and (8), we can see that they consist of two terms and have one term
with a minus sign. The ﬁrst term in Eq. (7) (or Eq. (8)) is to reduce the uncertainty of small-loss
examples, where we use robust mean estimation on training losses. The second term, i.e., the
statistical conﬁdence bound, is to encourage the network to choose the less selected examples (with
a small nt). The two terms are constraining and balanced with σ2 or τmin. To avoid introducing
strong assumptions on the underlying distribution of losses (Chakrabarty & Samorodnitsky, 2012),
we tune σ and τmin with a noisy validation set. For the mislabeled data, although the model has high
uncertainties on them (i.e., a small nt) and tends to pick them, the overﬁtting to the mislabeled data
is harmful. Also, the mislabeled data and clean data are rather hard to distinguish in some cases as
discussed. Thus, we should search underlying clean data in a conservative way. In this paper, we
initialize σ and τmin with small values. This way can reduce the adverse effects of mislabeled data
and meanwhile select the clean examples with large losses, which helps generalize. More evaluations
will be presented in Section 3."
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.12914485165794065,"Algorithm 1 CNLCU Algorithm.
1: Input θ1 and θ2, learning rate η, ﬁxed τ, epoch Tk and
Tmax, iteration tmax;
for T = 1, 2, . . . , Tmax do"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.13089005235602094,"2: Shufﬂe training dataset ˜S;
for t = 1, . . . , tmax do"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.13263525305410123,"3: Fetch mini-batch ¯S from ˜S;
4: Obtain ¯S1 = arg minS′:|S′|≥R(T )| ¯S| ℓ⋆(θ1, S′);
// calculated with Eq. (7) or Eq. (8)
5: Obtain ¯S2 = arg minS′:|S′|≥R(T )| ¯S| ℓ⋆(θ2, S′);
// calculated with Eq. (7) or Eq. (8)
6: Update θ1 = θ1 −η∇ℓ(θ1, ¯S2);
7: Update θ2 = θ2 −η∇ℓ(θ2, ¯S1);
end"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.1343804537521815,"8: Update R(T) = 1 −min
n
T
Tk τ, τ
o
;"
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.13612565445026178,"end
9: Output θ1 and θ2."
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.13787085514834205,"The overall procedure of the proposed
method, which combats noisy labels
by concerning uncertainty (CNLCU),
is provided in Algorithm 1. CNLCU
works in a mini-batch manner since
all deep learning training methods are
based on stochastic gradient descent.
Following (Han et al., 2018), we ex-
ploit two networks with parameters θ1
and θ2 respectively to teach each other.
Speciﬁcally, when a mini-batch ¯S is
formed (Step 3), we let two networks
select a small proportion of examples
in this mini-batch with Eq. (7) or (8)
(Step 4 and Step 5). The number of
instances is controlled by the function
R(T), and two networks only select
R(T) percentage of examples out of
the mini-batch. The value of R(T)
should be larger at the beginning of
training, and be smaller when the number of epochs goes large, which can make better use of memo-
rization effects of deep networks (Han et al., 2018) for sample selection. Then, the selected instances
are fed into its peer network for parameter updates (Step 6 and Step 7)."
ROBUST MEAN ESTIMATION AND CONSERVATIVE SEARCH,0.13961605584642234,Published as a conference paper at ICLR 2022
EXPERIMENTS,0.14136125654450263,"3
EXPERIMENTS"
EXPERIMENTS,0.1431064572425829,"In this section, we evaluate the robustness of our proposed method to noisy labels with comprehensive
experiments on the synthetic balanced noisy datasets (Section 3.1), synthetic imbalanced noisy
datasets (Section 3.2), and real-world noisy dataset (Section 3.3)."
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.14485165794066318,"3.1
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.14659685863874344,"Datasets. We verify the effectiveness of our method on the manually corrupted version of the follow-
ing datasets: MNIST (LeCun et al.), F-MNIST (Xiao et al., 2017), CIFAR-10 (Krizhevsky, 2009),
and CIFAR-100 (Krizhevsky, 2009), because these datasets are popularly used for the evaluation of
learning with noisy labels in the literature (Han et al., 2018; Yu et al., 2019; Wu et al., 2021; Lee
et al., 2019). The four datasets are class-balanced. The important statistics of the used synthetic
datasets are summarized in Appendix B.1."
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.14834205933682373,"Generating noisy labels. We consider broad types of label noise: (1). Symmetric noise (abbreviated
as Sym.) (Wu et al., 2020; Ma et al., 2018). (2) Asymmetric noise (abbreviated as Asym.) (Ma et al.,
2020; Xia et al., 2021; Wei et al., 2020). (3) Pairﬂip noise (abbreviated as Pair.) (Han et al., 2018; Yu
et al., 2019; Zheng et al., 2020). (4). Tridiagonal noise (abbreviated as Trid.) (Zhang et al., 2021). (5).
Instance noise (abbreviated as Ins.) (Cheng et al., 2020; Xia et al., 2020). The noise rate is set to 20%
and 40% to ensure clean labels are diagonally dominant (Ma et al., 2020). More details about above
noise are provided in Appendix B.1. We leave out 10% of noisy training examples as a validation set."
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.15008726003490402,"Baselines. We compare the proposed method (Algorithm 1) with following methods which focus on
sample selection, and implement all methods with default parameters by PyTorch, and conduct all
the experiments on NVIDIA Titan Xp GPUs. (1). S2E (Yao et al., 2020a), which properly controls
the sample selection process so that deep networks can better beneﬁt from the memorization effects.
(2). MentorNet (Jiang et al., 2018), which learns a curriculum to ﬁlter out noisy data. We use
self-paced MentorNet in this paper. (3). Co-teaching (Han et al., 2018), which trains two networks
simultaneously and cross-updates parameters of peer networks. (4). SIGUA (Han et al., 2020),
which exploits stochastic integrated gradient underweighted ascent to handle noisy labels. We use
self-teaching SIGUA in this paper. (5). JoCor (Wei et al., 2020), which reduces the diversity of
networks to improve robustness. To avoid too dense tables, we provide results of other sample
selection methods and other types of baselines such as adding regularization. All results are presented
in Appendix B.2. Here, we term our methods with soft truncation and hard truncation as CNLCU-S
and CNLCU-H respectively."
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.1518324607329843,"Network structure and optimizer. For MNIST, F-MNIST, and CIFAR-10, we use a 9-layer CNN
structure from (Han et al., 2018). Due to the limited space, the experimental details on CIFAR-100
are provided in Appendix B.3. All network structures we used here are standard test beds for weakly-
supervised learning. For all experiments, the Adam optimizer (Kingma & Ba, 2014) (momentum=0.9)
is used with an initial learning rate of 0.001, and the batch size is set to 128 and we run 200 epochs.
We linearly decay learning rate to zero from 80 to 200 epochs as did in (Han et al., 2018). We take
two networks with the same architecture but different initializations as two classiﬁers as did in (Han
et al., 2018; Yu et al., 2019; Wei et al., 2020), since even with the same network and optimization
method, different initializations can lead to different local optimal (Han et al., 2018). The details of
network structures can be checked in Appendix C."
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.15357766143106458,"For the hyper-parameters σ2 and τmin, we determine them in the range {10−1, 10−2, 10−3, 10−4}
with a noisy validation set. Note that the use of hyperparameters aims to reduce the dependency
on strong assumptions and thus make our methods perform well in practice. We provide more
details about this in Appendix D. Here, we assume the noise level τ is known and set R(T) =
1 −min{ T"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.15532286212914484,"Tk τ, τ} with Tk=10. If τ is not known in advanced, it can be inferred using validation sets
(Liu & Tao, 2016; Yu et al., 2018). As for performance measurement, we use test accuracy, i.e., test
accuracy = (# of correct prediction) / (# of testing). All experiments are repeated ﬁve times. We
report the mean and standard deviation of experimental results."
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.15706806282722513,"Experimental results. The experimental results about test accuracy are provided in Tables 1, 2, and
3. Speciﬁcally, for MNIST, as can be seen, our proposed methods, i.e., CNLCU-S and CNLCU-H,
produce the best results in the vast majority of cases. In some cases such as asymmetric noise, the
baseline S2E outperforms ours, which beneﬁts the accurate estimation for the number of selected"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.15881326352530542,Published as a conference paper at ICLR 2022
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.16055846422338568,"Noise type
Sym.
Asym.
Pair.
Trid.
Ins.
Method/Noise
20%
40%
20%
40%
20%
40%
20%
40%
20%
40%"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.16230366492146597,"S2E
98.46
±0.06
95.62
±0.91
99.05
±0.02
98.45
±0.26
98.56
±0.32
94.22
±0.79
99.02
±0.09
97.23
±1.26
97.93
±1.26
94.02
±2.39"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.16404886561954624,"MentorNet
95.04
±0.03
92.08
±0.42
96.32
±0.17
90.86
±0.97
93.19
±0.17
90.93
±1.54
96.42
±0.09
93.28
±1.37
94.65
±0.73
90.11
±1.26"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.16579406631762653,"Co-teaching
97.53
±0.12
95.62
±0.30
98.25
±0.08
95.08
±0.43
96.05
±0.96
94.16
±1.37
98.05
±0.06
96.18
±0.85
97.96
±0.09
95.02
±0.39"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.16753926701570682,"SIGUA
92.31
±1.10
91.88
±0.92
93.96
±0.82
62.59
±0.15
93.77
±1.40
86.22
±1.75
94.92
±0.83
83.46
±2.98
92.90
±1.82
86.34
±3.51"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.16928446771378708,"JoCor
98.42
±0.14
98.04
±0.07
98.05
±0.37
94.55
±1.08
98.01
±0.19
96.85
±0.43
98.45
±0.17
96.98
±0.25
98.62
±0.06
96.07
±0.31"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.17102966841186737,"CNLCU-S
98.82
±0.03
98.31
±0.05
98.93
±0.06
97.67
±0.22
98.86
±0.06
97.71
±0.64
99.09
±0.04
98.02
±0.17
98.77
±0.08
97.78
±0.25"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.17277486910994763,"CNLCU-H
98.70
±0.06
98.24
±0.06
99.01
±0.04
98.01
±0.03
98.44
±0.19
97.37
±0.32
98.89
±0.15
97.92
±0.05
98.74
±0.16
97.42
±0.39"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.17452006980802792,Table 1: Test accuracy (%) on MNIST over the last ten epochs. The best two results are in bold.
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.1762652705061082,"Noise type
Sym.
Asym.
Pair.
Trid.
Ins.
Method/Noise
20%
40%
20%
40%
20%
40%
20%
40%
20%
40%"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.17801047120418848,"S2E
89.99
±2.07
75.32
±5.84
89.00
±0.95
81.03
±1.93
88.66
±1.32
67.09
±4.03
89.53
±2.63
77.29
±3.97
88.65
±2.12
79.35
±3.04"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.17975567190226877,"MentorNet
90.37
±0.17
86.53
±0.65
89.69
±0.19
67.21
±2.94
87.92
±1.08
83.70
±0.49
88.74
±0.33
85.63
±0.59
87.52
±0.15
83.27
±1.42"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.18150087260034903,"Co-teaching
91.48
±0.10
88.80
±0.29
91.03
±0.14
68.07
±4.58
90.77
±0.23
86.91
±0.71
91.24
±0.11
89.18
±0.36
90.60
±0.12
87.90
±0.45"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.18324607329842932,"SIGUA
87.64
±1.29
87.23
±0.72
76.97
±2.59
45.96
±3.40
69.59
±5.75
68.93
±2.80
79.97
±3.23
76.14
±4.24
76.92
±5.09
74.89
±4.84"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.1849912739965096,"JoCor
91.97
±0.13
89.96
±0.19
90.95
±0.21
79.79
±2.39
91.52
±0.24
87.40
±0.58
92.01
±0.17
89.42
±0.33
91.43
±0.71
87.59
±0.94"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.18673647469458987,"CNLCU-S
92.37
±0.15
91.45
±0.28
92.57
±0.15
83.14
±1.77
92.04
±0.26
88.20
±0.44
92.24
±0.17
90.08
±0.34
91.69
±0.10
89.02
±1.02"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.18848167539267016,"CNLCU-H
92.42
±0.21
91.60
±0.19
92.60
±0.18
82.69
±0.43
91.70
±0.18
87.70
±0.69
92.33
±0.26
90.22
±0.71
91.50
±0.21
88.79
±1.22"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.19022687609075042,Table 2: Test accuracy on F-MNIST over the last ten epochs. The best two results are in bold.
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.19197207678883071,"small-loss examples. For F-MNIST, the training data becomes complicated. S2E cannot achieve the
accurate estimation in such situation and thus has no great performance like it got on MNIST. Our
methods achieve varying degrees of lead over baselines. For CIFAR-10, our methods once again
outperforms all the baseline methods. Although some baseline, e.g., Co-teaching, can work well
in some cases, experimental results show that it cannot handle various noise types. In contrast, the
proposed methods achieve superior robustness against broad noise types. The results mean that our
methods can be better applied to actual scenarios, where the noise is diversiform.
Ablation study. We ﬁrst conduct the ablation study to analyze the sensitivity of the length of time
intervals. In order to avoid too dense ﬁgures, we exploit MNIST and F-MNIST with the mentioned
noise settings as representative examples. For CNLCU-S, the length of time intervals is chosen in
the range from 3 to 8. For CNLCU-H, the length of time intervals is chosen in the range from 10 to
15. Note that the reason for their different lengths is that their different mechanisms. Speciﬁcally,
CNLCU-S holistically changes the behavior of losses, but does not remove any loss from the loss set.
We thus do not need too long length of time intervals. As a comparison, CNLCU-H needs to remove
some outliers from the loss set as discussed. The length should be longer to guarantee the number of
examples available for robust mean estimation. The experimental results are provided in Appendix
B.4, which show the proposed CNLCU-S and CNLCU-H are robust to the choices of the length of
time intervals. Such robustness to hyperparameters means our methods can be applied in practice and
does not need too much effect to tune the hyperparameters."
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.193717277486911,"Furthermore, since our methods concern uncertainty from two aspects, i.e., the uncertainty from both
small-loss and large-loss examples, we conduct experiments to analyze each part of our methods.
Also, as mentioned, we compare robust mean estimation with non-robust mean estimation when
learning with noisy labels. More details are provided in Appendix B.4."
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.19546247818499127,Published as a conference paper at ICLR 2022
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.19720767888307156,"Noise type
Sym.
Asym.
Pair.
Trid.
Ins.
Method/Noise
20%
40%
20%
40%
20%
40%
20%
40%
20%
40%"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.19895287958115182,"S2E
80.78
±0.88
69.72
±3.94
84.03
±1.01
75.04
±1.24
81.72
±0.93
61.50
±4.63
81.44
±0.59
64.39
±2.82
79.89
±0.26
62.42
±3.11"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.2006980802792321,"MentorNet
80.92
±0.48
74.67
±1.17
80.37
±0.26
71.69
±1.06
77.98
±0.31
69.39
±1.73
78.02
±0.29
71.56
±0.93
77.02
±0.71
68.17
±2.52"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.2024432809773124,"Co-teaching
82.35
±0.16
77.96
±0.39
83.87
±0.24
73.43
±0.62
80.94
±0.46
72.81
±0.92
81.17
±0.60
74.37
±0.64
79.92
±0.57
73.29
±1.62"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.20418848167539266,"SIGUA
78.19
±0.22
77.67
±0.41
75.14
±0.36
52.76
±0.68
74.41
±0.81
61.91
±5.27
75.75
±0.53
74.05
±0.41
74.34
±0.39
67.98
±1.34"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.20593368237347295,"JoCor
80.96
±0.25
76.65
±0.43
81.39
±0.74
69.92
±1.63
80.33
±0.20
71.62
±1.05
79.03
±0.13
74.33
±1.09
78.21
±0.34
71.46
±1.27"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.20767888307155322,"CNLCU-S
83.03
±0.21
78.25
±0.70
85.06
±0.17
75.34
±0.32
83.16
±0.25
73.19
±1.25
82.77
±0.32
74.37
±1.37
82.03
±0.37
73.67
±1.09"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.2094240837696335,"CNLCU-H
83.03
±0.47
78.33
±0.50
84.95
±0.27
75.29
±0.80
83.39
±0.68
73.40
±1.53
82.52
±0.71
74.79
±1.13
81.93
±0.25
73.58
±1.39"
EXPERIMENTS ON SYNTHETIC BALANCED NOISY DATASETS,0.2111692844677138,Table 3: Test accuracy (%) on CIFAR-10 over the last ten epochs. The best two results are in bold.
EXPERIMENTS ON SYNTHETIC IMBALANCED NOISY DATASETS,0.21291448516579406,"3.2
EXPERIMENTS ON SYNTHETIC IMBALANCED NOISY DATASETS"
EXPERIMENTS ON SYNTHETIC IMBALANCED NOISY DATASETS,0.21465968586387435,"Experimental setup. We exploit MNIST and F-MNIST. For these two datasets, we reduce the number
of training examples along with the labels from “0” to “4” to 1% of previous numbers. We term such
synthetic imbalanced noisy datasets as IM-MNIST and IM-F-MNIST respectively. This setting aims
to simulate the extremely imbalanced circumstance, which is common in practice. Moreover, we
exploit asymmetric noise, since these types of noise can produce more imbalanced case (Patrini et al.,
2017; Ma et al., 2020). Other settings such as the network structure and optimizer are the same as
those in experiments on synthetic balanced noisy datasets."
EXPERIMENTS ON SYNTHETIC IMBALANCED NOISY DATASETS,0.2164048865619546,"As for performance measurements, we use test accuracy. In addition, we exploit the selected ratio of
training examples with the imbalanced classes, i.e., selected ratio=(# of selected imbalanced labels /
# of all selected labels). Intuitively, a higher selected ratio means the proposed method can make
better use of training examples with the imbalanced classes, following better generalization (Kang
et al., 2020)."
EXPERIMENTS ON SYNTHETIC IMBALANCED NOISY DATASETS,0.2181500872600349,"Experimental results. The test accuracy achieved on IM-MNIST and IM-F-MNIST is presented in
Figure 2. Recall the experimental results in Tables 1 and 2, we can see that the imbalanced issue is
catastrophic to the sample selection approach when learning with noisy labels. For IM-MNIST, as
can be seen, all the baselines have serious overﬁtting in the early stages of training. The curves of test
accuracy drop dramatically. As a comparison, the proposed CNLCU-S and CNLCU-H can give a
try to large-loss but less selected data which are possible to be clean but equipped with imbalanced
labels. Therefore, our methods always outperform baselines clearly. In the case of Asym. 10%, our
methods achieve nearly 30% lead over baselines. For IM-F-MNIST, we can also see that our methods
perform well and always achieve about 5% lead over all the baselines. Note that due to the huge
challenge of this task, some baseline, e.g., S2E, has a large error bar. In addition, the baseline SIGUA
performs badly. It is because SIGUA exploits stochastic integrated gradient underweighted ascent on
large-loss examples, which makes the examples with imbalanced classes more difﬁcult to be selected
than them in other sample selection methods. Due to the limited space, the selected ratio achieved on
IM-MNIST and IM-F-MNIST is presented in Appendix B.5, which explain well why our methods
perform better than multiple baselines."
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2198952879581152,"3.3
EXPERIMENTS ON REAL-WORLD NOISY DATASETS"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.22164048865619546,"Experimental setup. To verify the efﬁcacy of our methods in the real-world scenario, we conduct
experiments on the noisy dataset Clothing1M (Xiao et al., 2015). Speciﬁcally, for experiments
on Clothing1M, we use the 1M images with noisy labels for training and 10k clean data for test
respectively. Note that we do not use the 50k clean training data in all the experiments. For
preprocessing, we resize the image to 256×256, crop the middle 224×224 as input, and perform
normalization. The experiments on Clothing1M are performed once due to the huge computational
cost. We leave 10% noisy training data as a validation set for model selection. Note that we do not
exploit the resampling trick during training (Li et al., 2020a). Here, Best denotes the test accuracy of
the epoch where the validation accuracy was optimal. Last denotes test accuracy of the last epoch. For"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.22338568935427575,Published as a conference paper at ICLR 2022
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.225130890052356,"S2E
MentorNet
Co-teaching
SIGUA
JoCor
CNLCU-S
CNLCU-H"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2268760907504363,"– Asym. 10% –
– Asym. 20% –
– Asym. 30% –
– Asym. 40% –"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2286212914485166,– IM-MNIST –
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.23036649214659685,"0
50
100
150
200
Epoch 20 40 60 80 100"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.23211169284467714,Test Accuracy
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2338568935427574,"0
50
100
150
200
Epoch 20 40 60 80 100"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2356020942408377,Test Accuracy
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.23734729493891799,"0
50
100
150
200
Epoch 20 40 60 80 100"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.23909249563699825,Test Accuracy
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.24083769633507854,"0
50
100
150
200
Epoch 20 40 60 80"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2425828970331588,Test Accuracy
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2443280977312391,– IM-F-MNIST –
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.24607329842931938,"0
50
100
150
200
Epoch 10 20 30 40 50 60 70"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.24781849912739964,Test Accuracy
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.24956369982547993,"0
50
100
150
200
Epoch 10 20 30 40 50 60 70"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2513089005235602,Test Accuracy
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2530541012216405,"0
50
100
150
200
Epoch 10 20 30 40 50 60"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2547993019197208,Test Accuracy
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.25654450261780104,"0
50
100
150
200
Epoch 10 20 30 40 50 60"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2582897033158813,Test Accuracy
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2600349040139616,"Figure 2: Test accuracy vs. number of epochs on IM-MNIST and IM-F-MNIST. The error bar for
standard deviation in each ﬁgure has been shaded."
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2617801047120419,"the experiments on Clothing1M, we use ResNet-18 and ResNet-50 which are pretrained on ImageNet.
We also use the Adam optimizer and set the batch size to 64. During the training stage, we run 15
epochs in total and set the learning rate 8 × 10−4, 5 × 10−4, and 5 × 10−5 for 5 epochs each."
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.26352530541012215,"Experimental results. The results on Clothing1M are provided in Table 4. Speciﬁcally, the
proposed methods get better results than state-of-the-art methods on Best. With ResNet-18, we
achieve improvements of +1.28% and +0.99%. With ResNet-50, we achieve improvements of
+2.51% and +2.16%. Likewise, the proposed methods outperform all the baselines on Last. We
achieve improvements of +1.01% and +0.54% with ResNet-18, and improvements of +2.47% and
+2.05% with ResNet-50. All these results verify the effectiveness of the proposed methods."
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.26527050610820246,"Methods
S2E
MentorNet
Co-teaching
SIGUA
JoCor
CNLCU-S
CNLCU-H
Best (R-18)
67.34
68.36
69.37
62.89
70.09
71.37
71.08
Last (R-18)
65.90
67.42
68.62
58.73
69.75
70.76
70.29
Best (R-50)
68.03
67.25
67.94
65.37
69.06
71.57
71.22
Last (R-50)
66.25
66.59
67.05
60.77
68.41
70.88
70.46"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2670157068062827,"Table 4: Test accuracy (%) on Clothing1M. “R-18” (resp. “R-50”) means that we exploit ResNet-18
(resp. ResNet-50). The best two results are in bold."
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.268760907504363,"Methods
Food-101
WebVision (Mini)
Clothing1M
DivideMix
86.73
77.32
74.76
DivideMix-S
86.92
77.53
74.90
DivideMix-H
86.88
77.48
74.82"
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.2705061082024433,"Table 5: The test accuracy (%) on three real-world datasets.
DivideMix-S (resp. DivideMix-H) means that our CNLCU-S
(resp. CNLCU-H) is combined with the advanced techniques
in DivideMix. The best two results are in bold."
EXPERIMENTS ON REAL-WORLD NOISY DATASETS,0.27225130890052357,"Combining with semi-supervised
learning. For combating noisy labels
in real-world noisy datasets, the state-
of-the-art methods, e.g., DivideMix
(Li et al., 2020a), always employ the
semi-supervised learning technology.
As our methods mainly focus on sam-
ple selection, to make the comparison
fair, we combine our methods with
semi-supervised learning. The sample selection procedure in DivideMix is replaced by our methods.
Other settings are kept the same. Following prior works (Ma et al., 2020), the experiments are
conducted on three real-world noisy datasets, i.e., Food-101 (Bossard et al., 2014), WebVision (Mini)
(Li et al., 2017), and Clothing1M (Xiao et al., 2015). The results are provided in Table 5. As can be
seen, the proposed methods are superior and can be used to improve the cutting edge performance."
CONCLUSION,0.27399650959860383,"4
CONCLUSION"
CONCLUSION,0.2757417102966841,"In this paper, we focus on promoting the prior sample selection in learning with noisy labels, which
starts from concerning the uncertainty of losses during training. We robustly use the training losses at
different iterations to reduce the uncertainty of small-loss examples, and adopt conﬁdence interval
estimation to reduce the uncertainty of large-loss examples. Experiments are conducted on benchmark
datasets, demonstrating the effectiveness of our method. We believe that this paper opens up new
possibilities in the topics of using sample selection to handle noisy labels, especially in improving
the robustness of models on imbalanced noisy datasets."
CONCLUSION,0.2774869109947644,Published as a conference paper at ICLR 2022
ETHICS STATEMENT,0.2792321116928447,"5
ETHICS STATEMENT"
ETHICS STATEMENT,0.28097731239092494,"This paper doesn’t raise any ethics concerns. This study doesn’t involve any human subjects, practices
to data set releases, potentially harmful insights, methodologies and applications, potential conﬂicts
of interest and sponsorship, discrimination/bias/fairness concerns, privacy and security issues, legal
compliance, and research integrity issues."
ETHICS STATEMENT,0.28272251308900526,ACKNOWLEDGMENT
ETHICS STATEMENT,0.2844677137870855,"XBX is supported by Australian Research Council Projects DE-190101473. TLL is partially supported
by Australian Research Council Projects DE-190101473, IC-190100031, and DP-220102121. BH
was supported by the RGC Early Career Scheme No. 22200720 and NSFC Young Scientists Fund
No. 62006202. MMG is supported by Australian Research Council Projects DE-210101624. JY
is sponsored by CAAI-Huawei MindSpore Open Fund (CAAIXSJLJJ-2021-016B). GN and MS
are supported by JST AIP Acceleration Research Grant Number JPMJCR20U3, Japan. MS is also
supported by the Institute for AI and Beyond, UTokyo."
REFERENCES,0.2862129144851658,REFERENCES
REFERENCES,0.2879581151832461,"Eric Arazo, Diego Ortego, Paul Albert, Noel O’Connor, and Kevin McGuinness. Unsupervised label
noise modeling and loss correction. In ICML, pp. 312–321, 2019."
REFERENCES,0.28970331588132636,"Devansh Arpit, Stanisław Jastrz˛ebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S
Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. A closer look at
memorization in deep networks. In ICML, pp. 233–242, 2017."
REFERENCES,0.2914485165794066,"Peter Auer. Using conﬁdence bounds for exploitation-exploration trade-offs. Journal of Machine
Learning Research, 3(Nov):397–422, 2002."
REFERENCES,0.2931937172774869,"Yingbin Bai and Tongliang Liu. Me-momentum: Extracting hard conﬁdent examples from noisily
labeled data. In ICCV, pp. 9312–9321, 2021."
REFERENCES,0.2949389179755672,"Lukas Bossard, Matthieu Guillaumin, and Luc Van Gool. Food-101–mining discriminative compo-
nents with random forests. In ECCV, pp. 446–461, 2014."
REFERENCES,0.29668411867364747,"Léon Bottou. Stochastic gradient descent tricks. In Neural networks: Tricks of the trade, pp. 421–436.
Springer, 2012."
REFERENCES,0.29842931937172773,"Stéphane Boucheron, Gábor Lugosi, and Pascal Massart. Concentration inequalities: A nonasymptotic
theory of independence. Oxford university press, 2013."
REFERENCES,0.30017452006980805,"Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and Jörg Sander. Lof: identifying density-
based local outliers. In SIGMOD, pp. 93–104, 2000."
REFERENCES,0.3019197207678883,"Olivier Catoni. Challenging the empirical mean and empirical variance: a deviation study. In Annales
de l’IHP Probabilités et statistiques, volume 48, pp. 1148–1185, 2012."
REFERENCES,0.3036649214659686,"Arijit Chakrabarty and Gennady Samorodnitsky. Understanding heavy tails in a bounded world or, is
a truncated heavy tail heavy or not? Stochastic models, 28(1):109–143, 2012."
REFERENCES,0.3054101221640489,"Haw-Shiuan Chang, Erik Learned-Miller, and Andrew McCallum. Active bias: Training more
accurate neural networks by emphasizing high variance samples. In NeurIPS, pp. 1002–1012,
2017."
REFERENCES,0.30715532286212915,"Ling-Hao Chen, He Li, and Wenhao Yang. Anomman: Detect anomaly on multi-view attributed
networks. arXiv preprint arXiv:2201.02822, 2022."
REFERENCES,0.3089005235602094,"Peng Chen, Xinghu Jin, Xiang Li, and Lihu Xu. A generalized catoni’s m-estimator under ﬁnite α-th
moment assumption with α ∈(1, 2). arXiv preprint arXiv:2010.05008, 2020."
REFERENCES,0.3106457242582897,"Pengfei Chen, Ben Ben Liao, Guangyong Chen, and Shengyu Zhang. Understanding and utilizing
deep neural networks trained with noisy labels. In ICML, pp. 1062–1070, 2019."
REFERENCES,0.31239092495637,Published as a conference paper at ICLR 2022
REFERENCES,0.31413612565445026,"Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamohanarao, and Dacheng Tao. Learning with bounded
instance-and label-dependent label noise. In ICML, 2020."
REFERENCES,0.3158813263525305,"Ilias Diakonikolas and Daniel M Kane. Recent advances in algorithmic high-dimensional robust
statistics. arXiv preprint arXiv:1911.05911, 2019."
REFERENCES,0.31762652705061084,"Ilias Diakonikolas, Daniel M Kane, and Ankit Pensia. Outlier robust mean estimation with subgaus-
sian rates via stability. arXiv preprint arXiv:2007.15618, 2020."
REFERENCES,0.3193717277486911,"Evarist Giné, Rafał Latała, and Joel Zinn. Exponential and moment inequalities for u-statistics. In
High Dimensional Probability II, pp. 13–38. Springer, 2000."
REFERENCES,0.32111692844677137,"Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi
Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. In
NeurIPS, pp. 8527–8537, 2018."
REFERENCES,0.3228621291448517,"Bo Han, Gang Niu, Xingrui Yu, Quanming Yao, Miao Xu, Ivor Tsang, and Masashi Sugiyama. Sigua:
Forgetting may make learning with noisy labels more robust. In ICML, pp. 4006–4016, 2020."
REFERENCES,0.32460732984293195,"Hrayr Harutyunyan, Kyle Reing, Greg Ver Steeg, and Aram Galstyan. Improving generalization by
controlling label-noise information in neural network weights. In ICML, pp. 4071–4081, 2020."
REFERENCES,0.3263525305410122,"Dan Hendrycks, Mantas Mazeika, Duncan Wilson, and Kevin Gimpel. Using trusted data to train
deep networks on labels corrupted by severe noise. In NeurIPS, 2018."
REFERENCES,0.32809773123909247,"Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. MentorNet: Learning data-
driven curriculum for very deep neural networks on corrupted labels. In ICML, pp. 2309–2318,
2018."
REFERENCES,0.3298429319371728,"Lu Jiang, Di Huang, Mason Liu, and Weilong Yang. Beyond synthetic noise: Deep learning on
controlled noisy labels. In ICML, pp. 4804–4815, 2020."
REFERENCES,0.33158813263525305,"Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi Feng, and Yannis
Kalantidis. Decoupling representation and classiﬁer for long-tailed recognition. In ICLR, 2020."
REFERENCES,0.3333333333333333,"Youngdong Kim, Junho Yim, Juseung Yun, and Junmo Kim. Nlnl: Negative learning for noisy labels.
In ICCV, pp. 101–110, 2019."
REFERENCES,0.33507853403141363,"Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014."
REFERENCES,0.3368237347294939,"Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, 2009."
REFERENCES,0.33856893542757416,"Yann LeCun, Corinna Cortes, and Christopher J.C. Burges. The MNIST database of handwritten
digits. http://yann.lecun.com/exdb/mnist/."
REFERENCES,0.3403141361256545,"Kimin Lee, Sukmin Yun, Kibok Lee, Honglak Lee, Bo Li, and Jinwoo Shin. Robust inference via
generative classiﬁers for handling noisy labels. In ICML, pp. 3763–3772, 2019."
REFERENCES,0.34205933682373474,"Junnan Li, Richard Socher, and Steven C.H. Hoi. Dividemix: Learning with noisy labels as semi-
supervised learning. In ICLR, 2020a."
REFERENCES,0.343804537521815,"Mingchen Li, Mahdi Soltanolkotabi, and Samet Oymak. Gradient descent with early stopping is
provably robust to label noise for overparameterized neural networks. In AISTATS, 2020b."
REFERENCES,0.34554973821989526,"Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van Gool. Webvision database: Visual
learning and understanding from web data. arXiv preprint arXiv:1708.02862, 2017."
REFERENCES,0.3472949389179756,"Yihua Liao and V Rao Vemuri. Use of k-nearest neighbor classiﬁer for intrusion detection. Computers
& security, 21(5):439–448, 2002."
REFERENCES,0.34904013961605584,"Liu Liu, Tianyang Li, and Constantine Caramanis. High dimensional robust m-estimation: Arbitrary
corruption and heavy tails. arXiv preprint arXiv:1901.08237, 2019."
REFERENCES,0.3507853403141361,Published as a conference paper at ICLR 2022
REFERENCES,0.3525305410122164,"Tongliang Liu and Dacheng Tao. Classiﬁcation with noisy labels by importance reweighting. IEEE
Transactions on pattern analysis and machine intelligence, 38(3):447–461, 2016."
REFERENCES,0.3542757417102967,"Eyal Lubetzky and Allan Sly. Cutoff for the ising model on the lattice. Inventiones mathematicae,
191(3):719–755, 2013."
REFERENCES,0.35602094240837695,"Michal Lukasik, Srinadh Bhojanapalli, Aditya Menon, and Sanjiv Kumar. Does label smoothing
mitigate label noise? In ICML, pp. 6448–6458, 2020."
REFERENCES,0.35776614310645727,"Yueming Lyu and Ivor W Tsang. Curriculum loss: Robust learning and generalization against label
corruption. In ICLR, 2020."
REFERENCES,0.35951134380453753,"Xingjun Ma, Yisen Wang, Michael E Houle, Shuo Zhou, Sarah M Erfani, Shu-Tao Xia, Sudanthi
Wijewickrema, and James Bailey. Dimensionality-driven learning with noisy labels. In ICML, pp.
3361–3370, 2018."
REFERENCES,0.3612565445026178,"Xingjun Ma, Hanxun Huang, Yisen Wang, Simone Romano, Sarah Erfani, and James Bailey. Nor-
malized loss functions for deep learning with noisy labels. In ICML, pp. 6543–6553, 2020."
REFERENCES,0.36300174520069806,"Eran Malach and Shai Shalev-Shwartz. Decoupling"" when to update"" from"" how to update"". In
NeurIPS, pp. 960–970, 2017."
REFERENCES,0.3647469458987784,"Aditya Krishna Menon, Brendan Van Rooyen, and Nagarajan Natarajan. Learning from binary labels
with instance-dependent noise. Machine Learning, 107(8-10):1561–1595, 2018."
REFERENCES,0.36649214659685864,"Aditya Krishna Menon, Sadeep Jayasumana, Ankit Singh Rawat, Himanshu Jain, Andreas Veit, and
Sanjiv Kumar. Long-tail learning via logit adjustment. arXiv preprint arXiv:2007.07314, 2020."
REFERENCES,0.3682373472949389,"Baharan Mirzasoleiman, Kaidi Cao, and Jure Leskovec. Coresets for robust training of neural
networks against noisy labels. In NeurIPS, 2020."
REFERENCES,0.3699825479930192,"Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of Machine Learning.
MIT Press, 2018."
REFERENCES,0.3717277486910995,"David S Moore. Uncertainty. On the shoulders of giants: New approaches to numeracy, pp. 95–137,
1990."
REFERENCES,0.37347294938917974,"Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning with
noisy labels. In NeurIPS, pp. 1196–1204, 2013."
REFERENCES,0.37521815008726006,"Kento Nishi, Yi Ding, Alex Rich, and Tobias Höllerer. Augmentation strategies for learning with
noisy labels. arXiv preprint arXiv:2103.02130, 2021."
REFERENCES,0.3769633507853403,"Laura Niss and Ambuj Tewari. What you see may not be what you get: Ucb bandit algorithms robust
to ϵ-contamination. In UAI, pp. 450–459, 2020."
REFERENCES,0.3787085514834206,"Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making
deep neural networks robust to label noise: A loss correction approach. In CVPR, pp. 1944–1952,
2017."
REFERENCES,0.38045375218150085,"Daniel Paulin et al. Concentration inequalities for markov chains by marton couplings and spectral
methods. Electronic Journal of Probability, 20, 2015."
REFERENCES,0.38219895287958117,"Geoff Pleiss, Tianyi Zhang, Ethan R Elenberg, and Kilian Q Weinberger. Identifying mislabeled data
using the area under the margin ranking. In NeurIPS, 2020."
REFERENCES,0.38394415357766143,"Gareth O Roberts, Jeffrey S Rosenthal, et al. General state space markov chains and mcmc algorithms.
Probability surveys, 1:20–71, 2004."
REFERENCES,0.3856893542757417,"Jun Shu, Qian Zhao, Zengben Xu, and Deyu Meng. Meta transition adaptation for robust deep
learning with noisy labels. arXiv preprint arXiv:2006.05697, 2020."
REFERENCES,0.387434554973822,"Mei-Ling Shyu, Shu-Ching Chen, Kanoksri Sarinnapakorn, and LiWu Chang. A novel anomaly
detection scheme based on principal component classiﬁer. Technical report, 2003."
REFERENCES,0.38917975567190227,Published as a conference paper at ICLR 2022
REFERENCES,0.39092495636998253,"Hwanjun Song, Minseok Kim, Dongmin Park, Yooju Shin, and Jae-Gil Lee. Learning from noisy
labels with deep neural networks: A survey. arXiv preprint arXiv:2007.08199, 2020."
REFERENCES,0.39267015706806285,"Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, and Kiyoharu Aizawa. Joint optimization framework
for learning with noisy labels. In CVPR, 2018."
REFERENCES,0.3944153577661431,"Kiran K Thekumparampil, Ashish Khetan, Zinan Lin, and Sewoong Oh. Robustness of conditional
gans to noisy labels. In NeurIPS, pp. 10271–10282, 2018."
REFERENCES,0.3961605584642234,"Vladimir Vapnik. The nature of statistical learning theory. Springer science & business media, 2013."
REFERENCES,0.39790575916230364,"Xiaobo Wang, Shuo Wang, Jun Wang, Hailin Shi, and Tao Mei. Co-mining: Deep face recognition
with noisy labels. In ICCV, pp. 9358–9367, 2019."
REFERENCES,0.39965095986038396,"Yisen Wang, Weiyang Liu, Xingjun Ma, James Bailey, Hongyuan Zha, Le Song, and Shu-Tao Xia.
Iterative learning with open-set noisy labels. In CVPR, pp. 8688–8696, 2018."
REFERENCES,0.4013961605584642,"Hongxin Wei, Lei Feng, Xiangyu Chen, and Bo An. Combating noisy labels by agreement: A joint
training method with co-regularization. In CVPR, pp. 13726–13735, 2020."
REFERENCES,0.4031413612565445,"Tong Wei, Jiang-Xin Shi, Wei-Wei Tu, and Yu-Feng Li. Robust long-tailed learning under label noise.
arXiv preprint arXiv:2108.11569, 2021."
REFERENCES,0.4048865619546248,"Kirk M Wolter. Introduction to variance estimation, volume 53. Springer, 2007."
REFERENCES,0.40663176265270506,"Pengxiang Wu, Songzhu Zheng, Mayank Goswami, Dimitris Metaxas, and Chao Chen. A topological
ﬁlter for learning with label noise. In NeurIPS, 2020."
REFERENCES,0.4083769633507853,"Songhua Wu, Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Nannan Wang, Haifeng Liu,
and Gang Niu. Class2simi: A noise reduction perspective on learning with noisy labels. In ICML,
2021."
REFERENCES,0.41012216404886565,"Songhua Wu, Mingming Gong, Bo Han, Yang Liu, and Tongliang Liu. Fair classiﬁcation with
instance-dependent label noise. In Clear, 2022."
REFERENCES,0.4118673647469459,"Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and Masashi Sugiyama.
Are anchor points really indispensable in label-noise learning? In NeurIPS, pp. 6835–6846, 2019."
REFERENCES,0.41361256544502617,"Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu,
Dacheng Tao, and Masashi Sugiyama. Part-dependent label noise: Towards instance-dependent
label noise. In NeurIPS, 2020."
REFERENCES,0.41535776614310643,"Xiaobo Xia, Tongliang Liu, Bo Han, Chen Gong, Nannan Wang, Zongyuan Ge, and Yi Chang.
Robust early-learning: Hindering the memorization of noisy labels. In ICLR, 2021."
REFERENCES,0.41710296684118675,"Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking
machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017."
REFERENCES,0.418848167539267,"Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive noisy
labeled data for image classiﬁcation. In CVPR, pp. 2691–2699, 2015."
REFERENCES,0.4205933682373473,"Bing Xu, Naiyan Wang, Tianqi Chen, and Mu Li. Empirical evaluation of rectiﬁed activations in
convolutional network. arXiv preprint arXiv:1505.00853, 2015."
REFERENCES,0.4223385689354276,"Yilun Xu, Peng Cao, Yuqing Kong, and Yizhou Wang. L_dmi: A novel information-theoretic loss
function for training deep nets robust to label noise. In NeurIPS, pp. 6222–6233, 2019."
REFERENCES,0.42408376963350786,"Shuo Yang, Lu Liu, and Min Xu. Free lunch for few-shot learning: Distribution calibration. In ICLR,
2021a."
REFERENCES,0.4258289703315881,"Shuo Yang, Songhua Wu, Tongliang Liu, and Min Xu. Bridging the gap between few-shot and many-
shot learning via distribution calibration. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 2021b."
REFERENCES,0.42757417102966844,Published as a conference paper at ICLR 2022
REFERENCES,0.4293193717277487,"Shuo Yang, Erkun Yang, Bo Han, Yang Liu, Min Xu, Gang Niu, and Tongliang Liu. Estimating
instance-dependent label-noise transition matrix using dnns. arXiv preprint arXiv:2105.13001,
2021c."
REFERENCES,0.43106457242582896,"Quanming Yao, Hansi Yang, Bo Han, Gang Niu, and James Tin-Yau Kwok. Searching to exploit
memorization effect in learning with noisy labels. In ICML, pp. 10789–10798, 2020a."
REFERENCES,0.4328097731239092,"Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, Jiankang Deng, Gang Niu, and Masashi Sugiyama.
Dual t: Reducing estimation error for transition matrix in label-noise learning. In NeurIPS, 2020b."
REFERENCES,0.43455497382198954,"Yu Yao, Tongliang Liu, Mingming Gong, Bo Han, Gang Niu, and Kun Zhang. Instance-dependent
label-noise learning under a structural causal model. In NeurIPS, 2021."
REFERENCES,0.4363001745200698,"Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, Gang Niu, Masashi Sugiyama, and Dacheng Tao.
Rethinking class-prior estimation for positive-unlabeled learning. In ICLR, 2022."
REFERENCES,0.43804537521815007,"Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor W Tsang, and Masashi Sugiyama. How does
disagreement beneﬁt co-teaching? In ICML, 2019."
REFERENCES,0.4397905759162304,"Xiyu Yu, Tongliang Liu, Mingming Gong, Kayhan Batmanghelich, and Dacheng Tao. An efﬁcient
and provable approach for mixture proportion estimation using linear independence assumption.
In CVPR, pp. 4480–4489, 2018."
REFERENCES,0.44153577661431065,"Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. In ICLR, 2017."
REFERENCES,0.4432809773123909,"Yivan Zhang, Gang Niu, and Masashi Sugiyama. Learning noise transition matrix from only noisy
labels via total variation regularization. In ICML, 2021."
REFERENCES,0.44502617801047123,"Zhilu Zhang and Mert Sabuncu. Generalized cross entropy loss for training deep neural networks
with noisy labels. In NeurIPS, pp. 8778–8788, 2018."
REFERENCES,0.4467713787085515,"Yue Zhao, Zain Nasrullah, and Zheng Li. Pyod: A python toolbox for scalable outlier detection.
Journal of Machine Learning Research, 20(96):1–7, 2019."
REFERENCES,0.44851657940663175,"Songzhu Zheng, Pengxiang Wu, Aman Goswami, Mayank Goswami, Dimitris Metaxas, and Chao
Chen. Error-bounded correction of noisy labels. In ICML, pp. 11447–11457, 2020."
REFERENCES,0.450261780104712,Published as a conference paper at ICLR 2022
REFERENCES,0.45200698080279234,APPENDIX
REFERENCES,0.4537521815008726,"The appendices are organized as follows. Section A details the proofs for our theorems. Section B
presents more experimental results. Section C shows the details of used network structures. Section D
gives more justiﬁcations for our theoretical analyses. Section E provides more discussions on learning
by considering uncertainty. Section F provides more discussions on sample selection methods."
REFERENCES,0.45549738219895286,"A
PROOF OF THEORETICAL RESULTS"
REFERENCES,0.4572425828970332,"A.1
PROOF OF THEOREM 1"
REFERENCES,0.45898778359511344,"For the circumstance with soft truncation, ˜µz = 1"
REFERENCES,0.4607329842931937,"n
Pn
i=1 ψ(zi). As suggested in (Catoni, 2012), we
can exploit ˜µ−
z and ˜µ+
z such that
˜µ−
z ≤˜µz ≤˜µ+
z ,
(9)"
REFERENCES,0.462478184991274,"to derive a bound for ˜µz. For some positive real parameter α, we deﬁne"
REFERENCES,0.4642233856893543,"r(˜µz) = n
X"
REFERENCES,0.46596858638743455,"i=1
ψ [α(zi −˜µz)] = 0.
(10)"
REFERENCES,0.4677137870855148,Let us introduce the quantity
REFERENCES,0.4694589877835951,"r(θ) = 1 αn n
X"
REFERENCES,0.4712041884816754,"i=1
ψ [α(zi −θ)] .
(11)"
REFERENCES,0.47294938917975565,"With the exponential moment inequality (Giné et al., 2000) and the Cr inequality (Mohri et al., 2018),
we have"
REFERENCES,0.47469458987783597,"exp{αnr(θ)} ≤

1 + α(µz −θ) + α2[σ2 + (µz −θ)2]
	n"
REFERENCES,0.47643979057591623,"≤exp{nα(µz −θ) + nα2[σ2 + (µz −θ)2]}.
(12)"
REFERENCES,0.4781849912739965,"In the same way,"
REFERENCES,0.4799301919720768,"exp{−αnr(θ)} ≤exp{−nα(µz −θ) + nα2[σ2 + (µz −θ)2]}.
(13)"
REFERENCES,0.4816753926701571,If we deﬁne for any µs ∈R the bounds
REFERENCES,0.48342059336823734,B−(θ) = µz −θ −α[σ2 + (µz −θ)2] −log(ϵ−1)
REFERENCES,0.4851657940663176,"αn
(14) and"
REFERENCES,0.4869109947643979,B+(θ) = µz −θ + α[σ2 + (µz −θ)2] + log(ϵ−1)
REFERENCES,0.4886561954624782,"αn
.
(15)"
REFERENCES,0.49040139616055844,"From (Chen et al., 2020) (Lemma 2.2), we obtain that"
REFERENCES,0.49214659685863876,"P(r(θ) > B−(θ)) ≥1 −ϵ
and
P(r(θ) < B+(θ)) ≥1 −ϵ.
(16)"
REFERENCES,0.493891797556719,"Let ˜µ−
z be the largest solution of the quadratic equation B−(θ) and ˜µ+
z be the smallest solution of the
quadratic equation B+(θ). Also, to guarantee the solution of the quadratic equation, we assume"
REFERENCES,0.4956369982547993,4α2σ2 + 4 log(ϵ−1)
REFERENCES,0.4973821989528796,"n
≤1.
(17)"
REFERENCES,0.49912739965095987,"From (Chen et al., 2020) (Theorem 2.6), we then have"
REFERENCES,0.5008726003490401,"˜µ−
z ≥µz −ασ2 + log(ϵ−1)"
REFERENCES,0.5026178010471204,"αn
α −1
,
(18) and"
REFERENCES,0.5043630017452007,"˜µ+
z ≤µz + ασ2 + log(ϵ−1)"
REFERENCES,0.506108202443281,"αn
α −1
.
(19)"
REFERENCES,0.5078534031413613,Published as a conference paper at ICLR 2022
REFERENCES,0.5095986038394416,"With probability at least 1-2ϵ, we have ˜µ−
z ≤˜µz ≤˜µ+
z . We can choose α =
n
σ2 . Then we have"
REFERENCES,0.5113438045375218,|˜µz −µz| ≤σ2(n + σ2 log(ϵ−1)
REFERENCES,0.5130890052356021,"n2
)
n −σ2
,
(20)"
REFERENCES,0.5148342059336823,which holds with probability at least 1-2ϵ.
REFERENCES,0.5165794066317626,We exploit the lower bound and let ϵ = 1
REFERENCES,0.518324607329843,2t. Then we have
REFERENCES,0.5200698080279232,"ℓ⋆
s = ˜µs −σ2(t + σ2 log(2t)"
REFERENCES,0.5218150087260035,"t2
)
nt −σ2
,
(21)"
REFERENCES,0.5235602094240838,where nt denotes the number of times that the example was selected in the time intervals.
REFERENCES,0.525305410122164,"0
2
4
6
8
10
x 0 2 4 6 8 10 y y = x"
REFERENCES,0.5270506108202443,y = log(1 + x + x2/2)
REFERENCES,0.5287958115183246,Figure 3: The illustration of the inﬂuence function for the soft estimator.
REFERENCES,0.5305410122164049,"Here, we provide the graph of the used inﬂuence function for the soft estimator, which explains the
mechanism of the function y = log(1 + x + x2/2) more clearly. The illustration is presented in
Figure 3. As can be seen, when x is large and may be an outlier, the inﬂuence function can reduce its
negative impact for mean estimation. Therefore, we exploit such an inﬂuence function for robust
mean estimation, which brings better classiﬁcation performance."
REFERENCES,0.5322862129144852,"A.2
PROOF OF THEOREM 2"
REFERENCES,0.5340314136125655,"Lemma 1 ((Paulin et al., 2015)) Let Zn = {z1, . . . , zn} be a (not necessarily time homogeneous)
Markov chain with mean µz, taking values in a Polish state space Λ1 × . . . × Λn, with a mixing time
τ(υ) (for 0 ≤υ ≤1). Let"
REFERENCES,0.5357766143106457,"τmin =
inf
0≤υ<1 τ(υ) ·
2 −υ 1 −υ"
REFERENCES,0.537521815008726,"2
.
(22)"
REFERENCES,0.5392670157068062,"For some η ∈R+, suppose that f : Λ →R satisﬁes the following inequality:"
REFERENCES,0.5410122164048866,"f(a) −f(b) ≤ n
X"
REFERENCES,0.5427574171029669,"i=1
η1[ai ̸= bi],
(23)"
REFERENCES,0.5445026178010471,"for every a, b ∈Λ. Then for any ϵ ≥0, we have"
REFERENCES,0.5462478184991274,"P(|f(Zn) −Ef(Zn)| ≥ϵ) ≤2 exp
 −2ϵ2"
REFERENCES,0.5479930191972077,η2τmin
REFERENCES,0.5497382198952879,"
.
(24)"
REFERENCES,0.5514834205933682,"The detailed deﬁnition of the mixing time for the Markov chain can be found in (Paulin et al., 2015;
Roberts et al., 2004). Let f be the mean function. Following the prior work on mean estimation (Liu
et al., 2019; Diakonikolas et al., 2020; Diakonikolas & Kane, 2019; Niss & Tewari, 2020), without
loss of generality, we assume µz = 0 for the underlying true distribution, and |zi| is upper bounded
by Z. Then we can set η to 4Z/n for Eq. (23). Combining the above analyses, we can revise Eq. (24)
as follows: P"
N,0.5532286212914486,"1
n n
X"
N,0.5549738219895288,"i=1
zi ≥2Z n r"
N,0.5567190226876091,2τmin log 2 ϵ1 !
N,0.5584642233856894,"≤ϵ1,
(25)"
N,0.5602094240837696,Published as a conference paper at ICLR 2022 and
N,0.5619546247818499,"P

max
i∈[n] |zi| ≥2Z n r"
N,0.5636998254799301,2τmin log 2n ϵ2
N,0.5654450261780105,"
≤ϵ2,
(26)"
N,0.5671902268760908,"for ϵ1 > 0 and ϵ2 > 0. If we remove the potential outliers Zno from Zn. Therefore, we have"
N,0.568935427574171,"1
n −no X"
N,0.5706806282722513,"zi∈Zn\Zno
−µz"
N,0.5724258289703316,"=
1
n −no  X"
N,0.5741710296684118,"zi∈Zn
−
X"
N,0.5759162303664922,zi∈Zno 
N,0.5776614310645725,"≤
1
n −no    X zi∈Zn +  X"
N,0.5794066317626527,zi∈Zno   
N,0.581151832460733,"≤
1
n −no  X zi∈Zn"
N,0.5828970331588132,"+ no max
i∈[n] |zi| !"
N,0.5846422338568935,"≤
1
n −no"
N,0.5863874345549738,"
2Z
r"
N,0.5881326352530541,2τmin log 2
N,0.5898778359511344,"ϵ1
+ 2Zno n r"
N,0.5916230366492147,"2τmin log 2n ϵ2 
, (27)"
N,0.5933682373472949,which holds with probability at least 1 −ϵ1 −ϵ2.
N,0.5951134380453752,"For our task, we exploit the concentration inequality. Let ϵ1 = ϵ2 = 1"
N,0.5968586387434555,"2t, and the losses be bounded by
L. Next we can obtain"
N,0.5986038394415357,"|˜µh −µ| ≤
2L
t −to p"
N,0.6003490401396161,2τmin log(4t) + to t p
N,0.6020942408376964,"4τmin log(4t)
"
N,0.6038394415357766,"= 2√2τminL(t +
√"
N,0.6055846422338569,"2to)
(t −to)t p"
N,0.6073298429319371,"log(4t)
(28)"
N,0.6090750436300174,with the probability at least 1 −1
N,0.6108202443280978,"t . In practice, it is easy to identify the value of L. For example, we
can training deep networks on noisy datasets to observe the loss distributions. Then, we exploit the
lower bound such that"
N,0.612565445026178,"ℓ⋆
h = ˜µh −2√2τminL(t +
√"
N,0.6143106457242583,"2to)
(t −to)
√ t s"
N,0.6160558464223386,log(4t)
N,0.6178010471204188,"nt
(29)"
N,0.6195462478184991,for sample selection.
N,0.6212914485165794,"B
COMPLEMENTARY EXPERIMENTAL ANALYSES"
N,0.6230366492146597,"# of training
# of testing
# of class
size
MNIST
60,000
10,000
10
28×28×1
F-MNIST
60,000
10,000
10
28×28×1
CIFAR-10
50,000
10,000
10
32×32×3
CIFAR-100
50,000
10,000
100
32×32×3"
N,0.62478184991274,Table 6: Summary of synthetic datasets used in the experiments.
N,0.6265270506108203,"B.1
THE DETAILS OF DATASETS AND GENERATING NOISY LABELS"
N,0.6282722513089005,"For the details of datasets, the important statistics of the used datasets are summarized in Table 6."
N,0.6300174520069808,"For the details of generating noisy labels, we exploit both class-dependent and instance-dependent
label noise which include ﬁve types of synthetic label noise to verify the effectiveness of the proposed
method. Here, we describe the details of the noise setting as follows:"
N,0.631762652705061,(1). Class-dependent label noise:
N,0.6335078534031413,"• Symmetric noise: this kind of label noise is generated by ﬂipping labels in each class uniformly to
incorrect labels of other classes."
N,0.6352530541012217,Published as a conference paper at ICLR 2022
N,0.6369982547993019,"0
1
2
3
4
5
6
7
8
9"
N,0.6387434554973822,"0
1
2
3
4
5
6
7
8
9"
N,0.6404886561954625,"0.8
0.022 0.022 0.022 0.022 0.022 0.022 0.022 0.022 0.022"
N,0.6422338568935427,"0.022
0.8
0.022 0.022 0.022 0.022 0.022 0.022 0.022 0.022"
N,0.643979057591623,"0.022 0.022
0.8
0.022 0.022 0.022 0.022 0.022 0.022 0.022"
N,0.6457242582897034,"0.022 0.022 0.022
0.8
0.022 0.022 0.022 0.022 0.022 0.022"
N,0.6474694589877836,"0.022 0.022 0.022 0.022
0.8
0.022 0.022 0.022 0.022 0.022"
N,0.6492146596858639,"0.022 0.022 0.022 0.022 0.022
0.8
0.022 0.022 0.022 0.022"
N,0.6509598603839442,"0.022 0.022 0.022 0.022 0.022 0.022
0.8
0.022 0.022 0.022"
N,0.6527050610820244,"0.022 0.022 0.022 0.022 0.022 0.022 0.022
0.8
0.022 0.022"
N,0.6544502617801047,"0.022 0.022 0.022 0.022 0.022 0.022 0.022 0.022
0.8
0.022"
N,0.6561954624781849,"0.022 0.022 0.022 0.022 0.022 0.022 0.022 0.022 0.022
0.8"
N,0.6579406631762653,Symmetric (a)
N,0.6596858638743456,"0
1
2
3
4
5
6
7
8
9"
N,0.6614310645724258,"0
1
2
3
4
5
6
7
8
9"
N,0.6631762652705061,"1
0
0
0
0
0
0
0
0
0"
N,0.6649214659685864,"0
1
0
0
0
0
0
0
0
0"
N,0.6666666666666666,"0
0
0.8
0
0
0
0
0.2
0
0"
N,0.6684118673647469,"0
0
0
0.8
0
0
0
0
0.2
0"
N,0.6701570680628273,"0
0
0
0
1
0
0
0
0
0"
N,0.6719022687609075,"0
0
0
0
0
0.8
0.2
0
0
0"
N,0.6736474694589878,"0
0
0
0
0
0.2
0.8
0
0
0"
N,0.675392670157068,"0
0
0
0
0
0
0
1
0
0"
N,0.6771378708551483,"0
0
0
0
0
0
0
0
1
0"
N,0.6788830715532286,"0
0
0
0
0
0
0
0
0
1"
N,0.680628272251309,Asymmetric (b)
N,0.6823734729493892,"0
1
2
3
4
5
6
7
8
9"
N,0.6841186736474695,"0
1
2
3
4
5
6
7
8
9"
N,0.6858638743455497,"0.8
0.2
0
0
0
0
0
0
0
0"
N,0.68760907504363,"0
0.8
0.2
0
0
0
0
0
0
0"
N,0.6893542757417103,"0
0
0.8
0.2
0
0
0
0
0
0"
N,0.6910994764397905,"0
0
0
0.8
0.2
0
0
0
0
0"
N,0.6928446771378709,"0
0
0
0
0.8
0.2
0
0
0
0"
N,0.6945898778359512,"0
0
0
0
0
0.8
0.2
0
0
0"
N,0.6963350785340314,"0
0
0
0
0
0
0.8
0.2
0
0"
N,0.6980802792321117,"0
0
0
0
0
0
0
0.8
0.2
0"
N,0.699825479930192,"0
0
0
0
0
0
0
0
0.8
0.2"
N,0.7015706806282722,"0.2
0
0
0
0
0
0
0
0
0.8"
N,0.7033158813263525,Pairflip (c)
N,0.7050610820244329,"0
1
2
3
4
5
6
7
8
9"
N,0.7068062827225131,"0
1
2
3
4
5
6
7
8
9"
N,0.7085514834205934,"0.8
0.1
0
0
0
0
0
0
0
0.1"
N,0.7102966841186736,"0.1
0.8
0.1
0
0
0
0
0
0
0"
N,0.7120418848167539,"0
0.1
0.8
0.1
0
0
0
0
0
0"
N,0.7137870855148342,"0
0
0.1
0.8
0.1
0
0
0
0
0"
N,0.7155322862129145,"0
0
0
0.1
0.8
0.1
0
0
0
0"
N,0.7172774869109948,"0
0
0
0
0.1
0.8
0.1
0
0
0"
N,0.7190226876090751,"0
0
0
0
0
0.1
0.8
0.1
0
0"
N,0.7207678883071553,"0
0
0
0
0
0
0.1
0.8
0.1
0"
N,0.7225130890052356,"0
0
0
0
0
0
0
0.1
0.8
0.1"
N,0.7242582897033158,"0.1
0
0
0
0
0
0
0
0.1
0.8"
N,0.7260034904013961,Tridiagonal (d)
N,0.7277486910994765,"Figure 4: Synthetic class-dependent transition matrices used in our experiments on MNIST. The noise
rate is set to 20%."
N,0.7294938917975567,"Noise type
Sym.
Asym.
Pair.
Trid.
Ins.
Method/Noise
20%
40%
20%
40%
20%
40%
20%
40%
20%
40%"
N,0.731239092495637,"NPCL
98.66
±0.03
98.21
±0.11
98.89
±0.02
96.14
±1.21
98.06
±0.24
97.50
±0.18
98.84
±0.05
97.62
±0.29
97.25
±0.63
95.75
±1.04"
N,0.7329842931937173,"INCV
98.58
±0.14
98.37
±0.06
98.89
±0.06
97.67
±0.26
97.98
±0.21
97.21
±0.39
98.74
±0.17
97.65
±0.32
96.83
±1.04
94.97
±1.35"
N,0.7347294938917975,"APL
98.76
±0.06
94.92
±0.31
98.63
±0.05
88.65
±1.72
98.66
±0.10
68.44
±2.95
98.93
±0.04
76.44
±3.04
97.63
±0.73
87.90
±1.94"
N,0.7364746945898778,"CDR
94.77
±0.17
92.16
±0.73
96.73
±0.19
91.05
±0.76
93.25
±0.90
71.02
±3.89
94.06
±0.92
70.28
±4.01
93.17
±0.96
77.45
±3.04"
N,0.7382198952879581,Table 7: Test accuracy (%) on MNIST over the last ten epochs.
N,0.7399650959860384,"• Asymmetic noise : this kind of label noise is generated by ﬂipping labels within a set of
similar classes.
In this paper, for MNIST, ﬂipping 2→7, 3→8, 5↔6.
For F-MNIST, ﬂip-
ping TSHIRT→SHIRT, PULLOVER→COAT, SANDALS→SNEAKER. For CIFAR-10, ﬂipping
TRUCK→AUTOMOBILE, BIRD→AIRPLANE, DEER→HORSE, CAT↔DOG. For CIFAR-100,
the 100 classes are grouped into 20 super-classes, and each has 5 sub-classes. Each class is then
ﬂipped into the next within the same super-class."
N,0.7417102966841187,• Pairﬂip noise: the noise ﬂips each class to its adjacent class.
N,0.743455497382199,"• Tridiagonal noise: the noise corresponds to a spectral of classes where adjacent classes are easier
to be mutually mislabeled, unlike the unidirectional pair ﬂipping. It can be implemented by two
consecutive pair ﬂipping transformations in the opposite direction."
N,0.7452006980802792,(2). Instance-dependent label noise:
N,0.7469458987783595,"• Instance noise: the noise is quite realistic, where the probability that an instance is mislabeled
depends on its features. We generate this type of label noise to validate the effectiveness of the
proposed method as did in (Xia et al., 2020; Yao et al., 2021)."
N,0.7486910994764397,"We use synthetic noisy MNIST as an example and plot the noise transition matrices in Figure 4. The
noise rate is set to 20%."
N,0.7504363001745201,"B.2
COMPARISON WITH OTHER BASELINES"
N,0.7521815008726004,"We focus on the sample selection approach in learning with noisy labels. In the main paper (Section
3.1), we fairly compare our methods with the baselines which also focus on sample selection. We
add two other sample-selection baselines here. As suggested by the related survey (Song et al., 2020),
the sample selection methods can be divided into three categories: (a) “Multi-network Learning”, (b)
“Multi-round Learning”, and (c) “Hybrid Approach”. As our method belongs to (a), we exploit INCV
(Chen et al., 2019) which belongs to (b), and NPCL (Lyu & Tsang, 2020) which belongs to (c), to
make the comparison more comprehensive."
N,0.7539267015706806,"Here, we also evaluate other types of baselines. We exploit APL (Ma et al., 2020) and CDR (Xia
et al., 2021), which add implicit regularization from different perspectives. The experiments are
conducted on MNIST and F-MNIST. Other experimental settings are the same as those in the main
paper. The experimental results are provided in Tables 7 and 8, which show that the proposed methods
are superior to these baselines with respect to classiﬁcation performance."
N,0.7556719022687609,Published as a conference paper at ICLR 2022
N,0.7574171029668412,"Noise type
Sym.
Asym.
Pair.
Trid.
Ins.
Method/Noise
20%
40%
20%
40%
20%
40%
20%
40%
20%
40%"
N,0.7591623036649214,"NPCL
91.65
±0.37
86.72
±2.30
91.20
±0.06
70.65
±2.83
91.07
±0.22
85.03
±1.94
90.99
±0.15
88.79
±1.04
90.77
±0.85
86.34
±2.78"
N,0.7609075043630017,"INCV
91.66
±0.31
85.39
±1.14
91.35
±0.70
65.82
±4.32
90.26
±0.38
85.73
±1.92
91.76
±0.17
88.42
±1.55
89.54
±1.79
86.21
±2.86"
N,0.7626527050610821,"APL
91.73
±0.20
89.06
±0.41
90.13
±0.17
80.34
±0.63
90.22
±0.80
78.54
±4.33
90.84
±0.22
86.53
±0.76
90.96
±0.77
85.55
±2.86"
N,0.7643979057591623,"CDR
85.62
±0.96
71.83
±1.37
89.78
±0.41
79.05
±1.39
85.72
±0.65
69.07
±2.31
86.75
±1.19
73.63
±2.82
85.92
±1.43
73.14
±3.12"
N,0.7661431064572426,Table 8: Test accuracy on F-MNIST over the last ten epochs.
N,0.7678883071553229,"B.3
EXPERIMENTS ON SYNTHETIC CIFAR-100"
N,0.7696335078534031,"For CIFAR-100, we use a 7-layer CNN structure from (Yu et al., 2019; Yao et al., 2020a). Other
experimental settings are the same as those in the experiments on MNIST, F-MNIST, and CIFAR-10.
The results are provided in Table 9. We can see the proposed method outperforms all the baselines."
N,0.7713787085514834,"Noise type
Sym.
Asym.
Pair.
Trid.
Ins.
Method/Noise
20%
40%
20%
40%
20%
40%
20%
40%
20%
40%"
N,0.7731239092495636,"S2E
44.59
±0.32
25.78
±5.44
42.18
±1.73
26.81
±2.25
42.99
±1.54
26.96
±2.48
43.16
±0.93
27.72
±3.56
43.13
±0.67
27.12
±3.86"
N,0.774869109947644,"MentorNet
43.15
±0.42
37.62
±0.89
41.03
±0.22
28.27
±0.41
40.06
±0.37
27.17
±0.92
42.20
±0.30
31.74
±0.88
40.54
±0.69
33.09
±1.53"
N,0.7766143106457243,"Co-teaching
45.17
±0.25
40.95
±0.52
42.76
±0.34
30.27
±0.33
42.50
±0.39
30.07
±0.17
44.41
±0.41
34.96
±0.35
42.23
±0.52
35.87
±1.47"
N,0.7783595113438045,"SIGUA
42.03
±0.33
40.53
±0.49
36.67
±0.25
26.71
±0.42
36.48
±0.37
26.73
±0.33
39.21
±0.40
32.69
±0.36
39.19
±0.32
33.51
±0.43"
N,0.7801047120418848,"JoCor
45.93
±0.21
41.56
±0.57
42.89
±0.37
29.19
±1.42
42.12
±0.35
30.12
±0.65
44.98
±0.27
34.23
±1.13
44.28
±0.59
35.60
±0.99"
N,0.7818499127399651,"CNLCU-S
46.09
±0.29
42.11
±0.70
43.06
±0.28
30.47
±0.37
43.08
±0.92
30.33
±0.74
45.19
±0.90
35.49
±1.30
44.80
±0.70
36.23
±0.49"
N,0.7835951134380453,"CNLCU-H
46.27
±0.38
42.05
±0.87
43.21
±0.93
30.55
±0.72
43.25
±0.75
30.79
±0.86
45.02
±1.06
35.24
±0.93
45.02
±1.07
36.17
±1.54"
N,0.7853403141361257,Table 9: Test accuracy (%) on CIFAR-100 over the last ten epochs. The best two results are in bold.
N,0.787085514834206,"B.4
EXPERIMENTS FOR ABLATION STUDY"
N,0.7888307155322862,"We conduct the ablation study to analyze the sensitivity of the length of time intervals. The results
are shown in Figure 5 and 6. As we can seen, the proposed method, i.e., CNLCU-S and CNLCU-H
are robust to the choices of hyperparameters."
N,0.7905759162303665,"– Sym. –
– Asym. –
– Pair. –
– Trid. –
– Ins. –"
N,0.7923211169284468,– MNIST –
N,0.794066317626527,"3
4
5
6
7
8
Time Interval 98.20 98.40 98.60 98.80 99.00"
N,0.7958115183246073,Test Accuracy
N,0.7975567190226877,"20% noise
40% noise"
N,0.7993019197207679,"3
4
5
6
7
8
Time Interval 97.25 97.50 97.75 98.00 98.25 98.50 98.75 99.00"
N,0.8010471204188482,Test Accuracy
N,0.8027923211169284,"3
4
5
6
7
8
Time Interval 97.00 97.50 98.00 98.50 99.00"
N,0.8045375218150087,Test Accuracy
N,0.806282722513089,"3
4
5
6
7
8
Time Interval 97.60 97.80 98.00 98.20 98.40 98.60 98.80 99.00 99.20"
N,0.8080279232111692,Test Accuracy
N,0.8097731239092496,"3
4
5
6
7
8
Time Interval 97.25 97.50 97.75 98.00 98.25 98.50 98.75"
N,0.8115183246073299,Test Accuracy
N,0.8132635253054101,– F-MNIST –
N,0.8150087260034904,"3
4
5
6
7
8
Time Interval 91.00 91.50 92.00 92.50 93.00"
N,0.8167539267015707,Test Accuracy
N,0.8184991273996509,"20% noise
40% noise"
N,0.8202443280977313,"3
4
5
6
7
8
Time Interval 82.00 84.00 86.00 88.00 90.00 92.00"
N,0.8219895287958116,Test Accuracy
N,0.8237347294938918,"3
4
5
6
7
8
Time Interval 87.00 88.00 89.00 90.00 91.00 92.00 93.00"
N,0.8254799301919721,Test Accuracy
N,0.8272251308900523,"3
4
5
6
7
8
Time Interval 89.00 89.50 90.00 90.50 91.00 91.50 92.00 92.50"
N,0.8289703315881326,Test Accuracy
N,0.8307155322862129,"3
4
5
6
7
8
Time Interval 88.00 89.00 90.00 91.00 92.00"
N,0.8324607329842932,Test Accuracy
N,0.8342059336823735,"Figure 5: Illustrations of the hyperparameter sensitivity for the proposed CNLCU-S. The error bar
for standard deviation in each ﬁgure has been shaded."
N,0.8359511343804538,"Note that in this paper, we concern uncertainty from two aspects, i.e., the uncertainty about small-loss
examples and the uncertainty about large-loss examples. Here, we conduct ablation study to show the"
N,0.837696335078534,Published as a conference paper at ICLR 2022
N,0.8394415357766143,"– Sym. –
– Asym. –
– Pair. –
– Trid. –
– Ins. –"
N,0.8411867364746946,– MNIST –
N,0.8429319371727748,"10
11
12
13
14
15
Time Interval 98.00 98.20 98.40 98.60 98.80"
N,0.8446771378708552,Test Accuracy
N,0.8464223385689355,"20% noise
40% noise"
N,0.8481675392670157,"10
11
12
13
14
15
Time Interval 97.60 97.80 98.00 98.20 98.40 98.60 98.80 99.00"
N,0.849912739965096,Test Accuracy
N,0.8516579406631762,"10
11
12
13
14
15
Time Interval 96.50 97.00 97.50 98.00 98.50"
N,0.8534031413612565,Test Accuracy
N,0.8551483420593369,"10
11
12
13
14
15
Time Interval 97.80 98.00 98.20 98.40 98.60 98.80 99.00 99.20"
N,0.8568935427574171,Test Accuracy
N,0.8586387434554974,"10
11
12
13
14
15
Time Interval 97.00 97.50 98.00 98.50 99.00"
N,0.8603839441535777,Test Accuracy
N,0.8621291448516579,– F-MNIST –
N,0.8638743455497382,"10
11
12
13
14
15
Time Interval 90.75 91.00 91.25 91.50 91.75 92.00 92.25 92.50 92.75"
N,0.8656195462478184,Test Accuracy
N,0.8673647469458988,"20% noise
40% noise"
N,0.8691099476439791,"10
11
12
13
14
15
Time Interval 82.00 84.00 86.00 88.00 90.00 92.00"
N,0.8708551483420593,Test Accuracy
N,0.8726003490401396,"10
11
12
13
14
15
Time Interval 87.00 88.00 89.00 90.00 91.00 92.00"
N,0.8743455497382199,Test Accuracy
N,0.8760907504363001,"10
11
12
13
14
15
Time Interval 89.00 89.50 90.00 90.50 91.00 91.50 92.00 92.50"
N,0.8778359511343804,Test Accuracy
N,0.8795811518324608,"10
11
12
13
14
15
Time Interval 87.00 88.00 89.00 90.00 91.00"
N,0.881326352530541,Test Accuracy
N,0.8830715532286213,"Figure 6: Illustrations of the hyperparameter sensitivity for the proposed CNLCU-H. The error bar
for standard deviation in each ﬁgure has been shaded."
N,0.8848167539267016,"effect of removing different components to provide insights into what makes the proposed methods
successful. The experiments are conducted on MNIST and F-MNIST. Other experimental settings
are the same as those in the main paper (Section 3.1). Note that we employ two networks to teach
each other following (Han et al., 2018). Therefore, when we do not consider uncertainty in sample
selection, the proposed methods will reduce to the baseline Co-teaching (Han et al., 2018)."
N,0.8865619546247818,"To study the effect of concerning uncertainty about small-loss examples, we remove the concerns
about large-loss examples, i.e., the network is not encouraged to choose the less selected examples for
updates. We express such a setting as “without concerning about large-loss examples” (abbreviated
as w/o cl). To study the effect of concerning uncertainty about large-loss examples, we remove the
concerns about small-loss examples, i.e., we only exploit the predictions of the current network. We
express such a setting as “without concerning about small-loss examples” (abbreviated as w/o cs).
Besides, we express the setting which directly uses non-robust mean as Co-teaching-M."
N,0.8883071553228621,"The experimental results of ablation study are provided in Tables 10 and 11. As can be seen, both
aspects of uncertainty concerns can improve the robustness of models. Therefore, combining two
uncertainty concerns, we can better combat noisy labels. In addition, robust mean estimation is
superior to the non-robust mean in learning with noisy labels."
N,0.8900523560209425,"Noise type
Sym.
Asym.
Pair.
Trid.
Ins.
Method/Noise
20%
40%
20%
40%
20%
40%
20%
40%
20%
40%"
N,0.8917975567190227,"CNLCU-S
98.82
±0.03
98.31
±0.05
98.93
±0.06
97.67
±0.22
98.86
±0.06
97.71
±0.64
99.09
±0.04
98.02
±0.17
98.77
±0.08
97.78
±0.25"
N,0.893542757417103,"CNLCU-S w/o cl
98.02
±0.08
96.83
±0.29
98.50
±0.04
96.25
±0.13
98.22
±0.13
96.08
±0.75
98.64
±0.31
97.25
±0.24
98.17
±0.20
97.13
±0.40"
N,0.8952879581151832,"CNLCU-S w/o cs
98.15
±0.20
97.12
±0.22
98.36
±0.07
96.39
±0.48
98.04
±0.24
96.12
±0.68
98.74
±0.05
97.30
±0.52
98.11
±0.15
97.32
±0.43"
N,0.8970331588132635,"CNLCU-H
98.70
±0.06
98.24
±0.06
99.01
±0.04
98.01
±0.03
98.44
±0.19
97.37
±0.32
98.89
±0.15
97.92
±0.05
98.74
±0.16
97.42
±0.39"
N,0.8987783595113438,"CNLCU-H w/o cl
98.06
±0.13
96.92
±0.23
98.39
±0.04
96.51
±0.57
97.04
±0.87
95.62
±0.93
98.33
±0.47
97.41
±0.92
98.01
±0.20
96.15
±0.28"
N,0.900523560209424,"CNLCU-H w/o cs
98.19
±0.22
97.05
±0.49
98.76
±0.59
97.17
±0.60
97.26
±1.19
96.31
±0.25
98.29
±0.17
97.65
±0.92
98.34
±0.36
96.49
±0.48"
N,0.9022687609075044,"Co-teaching-M
97.72
±0.08
97.78
±0.32
98.27
±0.03
95.42
±0.42
96.22
±0.10
95.01
±0.65
97.92
±0.14
96.64
±0.77
98.02
±0.04
96.03
±0.57"
N,0.9040139616055847,"Co-teaching
97.53
±0.12
95.62
±0.30
98.25
±0.08
95.08
±0.43
96.05
±0.96
94.16
±1.37
98.05
±0.06
96.18
±0.85
97.96
±0.09
95.02
±0.39"
N,0.9057591623036649,Table 10: Test accuracy (%) on MNIST over last ten epochs.
N,0.9075043630017452,"B.5
RESULTS ON SYNTHETIC IMBALANCED NOISY DATASETS"
N,0.9092495636998255,"In the main paper, we have provided the test accuracy on synthetic imbalanced noisy datasets in
Figure 2. Due to the limited space, we provide the selected ratio achieved on IM-MNIST and IM-F-
MNIST in Table 12. The results explain well why our methods perform better on synthetic imbalanced
noisy datasets, i.e., our methods can make better use of training examples with the imbalanced classes.
Note that since we give a try to large-loss but less selected data in a conservative way, the selected"
N,0.9109947643979057,Published as a conference paper at ICLR 2022
N,0.912739965095986,"Noise type
Sym.
Asym.
Pair.
Trid.
Ins.
Method/Noise
20%
40%
20%
40%
20%
40%
20%
40%
20%
40%"
N,0.9144851657940664,"CNLCU-S
92.37
±0.15
91.45
±0.28
92.57
±0.15
83.14
±1.77
92.04
±0.26
88.20
±0.44
92.24
±0.17
90.08
±0.34
91.69
±0.10
89.02
±1.02"
N,0.9162303664921466,"CNLCU-S w/o cl
91.77
±0.35
89.40
±0.26
91.25
±0.30
72.93
±2.63
91.53
±0.17
87.31
±0.59
91.31
±0.52
89.50
±0.32
91.09
±0.13
88.45
±0.57"
N,0.9179755671902269,"CNLCU-S w/o cs
91.85
±0.33
90.76
±0.28
91.94
±0.09
80.99
±2.74
91.28
±0.20
87.31
±0.72
91.39
±0.07
89.29
±0.51
90.98
±0.43
88.73
±0.62"
N,0.9197207678883071,"CNLCU-H
92.42
±0.21
91.60
±0.19
92.60
±0.18
82.69
±0.43
91.70
±0.18
87.70
±0.69
92.33
±0.26
90.22
±0.71
91.50
±0.21
88.79
±1.22"
N,0.9214659685863874,"CNLCU-H w/o cl
91.70
±0.04
90.05
±0.31
91.08
±0.06
71.35
±2.30
91.03
±0.29
87.22
±0.72
91.59
±0.07
90.01
±0.24
90.80
±0.27
88.31
±1.09"
N,0.9232111692844677,"CNLCU-H w/o cs
91.82
±0.13
90.92
±0.42
92.45
±0.25
80.73
±1.63
91.21
±0.17
87.49
±0.32
92.08
±0.13
89.72
±0.24
91.21
±0.38
88.62
±0.73"
N,0.924956369982548,"Co-teaching-M
91.33
±0.18
89.05
±0.73
91.14
±0.90
71.03
±3.73
90.85
±0.61
86.95
±0.19
91.50
±0.46
89.18
±0.44
90.74
±1.06
88.25
±0.92"
N,0.9267015706806283,"Co-teaching
91.48
±0.10
88.80
±0.29
91.03
±0.14
68.07
±4.58
90.77
±0.23
86.91
±0.71
91.24
±0.11
89.18
±0.36
90.60
±0.12
87.90
±0.45"
N,0.9284467713787086,Table 11: Test accuracy (%) on F-MNIST over last ten epochs.
N,0.9301919720767888,"Dataset
IM-MNIST
IM-F-MNIST
Method/Noise
10%
20%
30%
40%
10%
20%
30%
40%"
N,0.9319371727748691,"S2E
0.13
±0.12
0.11
±0.05
0.09
±0.02
0.05
±0.01
0.13
±0.04
0.17
±0.03
0.16
±0.02
0.12
±0.04"
N,0.9336823734729494,"MentorNet
0.10
±0.02
0.15
±0.02
0.12
±0.03
0.13
±0.02
0.12
±0.01
0.15
±0.03
0.09
±0.01
0.14
±0.02"
N,0.9354275741710296,"Co-teaching
0.09
±0.03
0.07
±0.02
0.05
±0.01
0.12
±0.01
0.17
±0.05
0.04
±0.00
0.13
±0.04
0.07
±0.01"
N,0.93717277486911,"SIGUA
0.04
±0.00
0.04
±0.00
0.01
±0.00
0.02
±0.00
0.03
±0.00
0.02
±0.00
0.04
±0.00
0.00
±0.00"
N,0.9389179755671903,"JoCor
0.11
±0.04
0.08
±0.01
0.07
±0.03
0.06
±0.02
0.05
±0.01
0.13
±0.04
0.13
±0.03
0.07
±0.02"
N,0.9406631762652705,"CNLCU-S
0.60
±0.11
0.37
±0.09
0.39
±0.04
0.38
±0.06
0.35
±0.03
0.39
±0.04
0.36
±0.03
0.30
±0.02"
N,0.9424083769633508,"CNLCU-H
0.57
±0.13
0.32
±0.01
0.37
±0.07
0.32
±0.05
0.34
±0.02
0.35
±0.06
0.32
±0.04
0.28
±0.03"
N,0.944153577661431,Table 12: Selected ratio (%) on IM-MNIST and IM-F-MNIST. The best two results are in bold.
N,0.9458987783595113,"ratio is still far away from the class prior probability on the test set, i.e., 10%. However, a little
improvement of the selection ratio can bring a considerable improvement of test accuracy. These
results tell us that, in the sample selection approach when learning with noisy labels, improving
the selected ratio of training examples with the imbalanced classes is challenging but promising for
generalization. This practical problem deserves to be studied in depth."
N,0.9476439790575916,"B.6
EXPERIMENTS WITH HIGH NOISE LEVELS"
N,0.9493891797556719,"In the main paper, we set the noise rates to be smaller than 50%, which ensures that clean labels in
noisy classes are diagonally dominant in all label noise settings. To demonstrate the effectiveness
of our method with high noise levels, we conduct experiments on MNIST and F-MNIST with 50%,
60%, and 70% symmetric noise. The experimental results are presented in Table 13. As can be seen,
the proposed methods can achieve the best performance in almost all cases."
N,0.9511343804537522,"C
COMPLEMENTARY EXPLANATION FOR NETWORK STRUCTURES"
N,0.9528795811518325,"Table 14 describes the 9-layer CNN (Han et al., 2018) used on MNIST, F-MNIST, and CIFAR-10.
Table 15 describes the 7-layer CNN (Yu et al., 2019) used on CIFAR-100. Here, LReLU stands for
Leaky ReLU (Xu et al., 2015). The slopes of all LReLU functions in the networks are set to 0.01.
Note that that the 7/9-layer CNN is a standard and common practice in weakly supervised learning.
We decided to use these CNNs, since then the experimental results are directly comparable with
previous approaches in the same area, i.e., learning with noisy labels."
N,0.9546247818499127,Published as a conference paper at ICLR 2022
N,0.956369982547993,"Dataset
MNIST
F-MNIST
Method/Noise
50%
60%
70%
50%
60%
70%
APL
84.97±2.97
75.68±1.22
70.11±0.52
76.80±3.21
72.77±4.37
68.39±7.17
CDR
76.85±2.46
57.22±1.92
54.22±0.94
53.41±1.81
45.82±2.77
41.33±3.69
INCV
96.14±0.33
94.12±1.13
92.13±0.75
84.92±0.60
82.79±1.64
80.12±0.26
NPCL
97.05±0.14
94.77±0.73
93.58±1.26
86.07±1.33
83.29±2.65
79.39±1.58
S2E
87.76±2.39
79.24±4.79
50.30±7.82
62.20±3.94
59.88±1.27
45.88±7.96
MentorNet
91.14±0.17
90.11±0.37
88.72±0.46
86.51±0.11
85.91±0.44
83.27±0.55
Co-teaching
95.60±0.38
95.44±0.30
94.11±0.38
88.72±0.14
87.92±0.34
85.92±0.72
SIGUA
91.35±2.62
88.62±1.93
86.08±6.04
83.39±3.29
79.36±4.54
72.14±4.28
JoCor
97.14±0.10
96.47± 0.46
95.01±0.29
89.16±0.27
87.93±0.61
86.99±0.92
CNLCU-S
97.78±0.07
96.73±0.31
96.02±0.38
89.56±0.25
88.56±0.59
87.54±0.42
CNLCU-H
97.64±0.25
96.45±0.55
95.30±0.26
89.77±0.29
88.07±0.62
87.40±1.05"
N,0.9581151832460733,"Table 13: Test accuracy on MNIST and F-MNIST with high noise levels over the last ten epochs. The
best two results are in bold."
N,0.9598603839441536,"CNN on MNIST
CNN on F-MNIST
CNN on CIFAR-10
28×28 Gray Image
28×28 Gray Image
32×32 RGB Image
3×3 conv, 128 LReLU
3×3 conv, 128 LReLU
3×3 conv, 128 LReLU"
N,0.9616055846422339,"2×2 max-pool
dropout, p = 0.25
3×3 conv, 256 LReLU
3×3 conv, 256 LReLU
3×3 conv, 256 LReLU"
N,0.9633507853403142,"2×2 max-pool
dropout, p = 0.25
3×3 conv, 512 LReLU
3×3 conv, 256 LReLU
3×3 conv, 128 LReLU"
N,0.9650959860383944,"avg-pool
dense 128→10
dense 128→10
dense 128→10"
N,0.9668411867364747,"Table 14: The CNN on MNIST, F-MNIST, and CIFAR-
10."
N,0.9685863874345549,CNN on CIFAR-100
N,0.9703315881326352,"32×32 RGB Image
3×3 conv, 64 ReLU
3×3 conv, 64 ReLU"
N,0.9720767888307156,"2×2 max-pool
3×3 conv, 128 ReLU
3×3 conv, 128 ReLU"
N,0.9738219895287958,"2×2 max-pool
3×3 conv, 196 ReLU
3×3 conv, 196 ReLU"
N,0.9755671902268761,"2×2 max-pool
dense 256→100"
N,0.9773123909249564,Table 15: The CNN on CIFAR-100.
N,0.9790575916230366,"D
NEEDED ASSUMPTIONS WITHOUT NOISY VALIDATION SETS"
N,0.9808027923211169,"In the main paper, a noisy validation set is exploited to determine σ2 and τmin. We discuss, if we do
not use the noisy validation set, what assumptions we will need."
N,0.9825479930191972,"• In statistical learning, it is an important problem for estimating the variance of a data
distribution. However, it is hard to obtain an accurate estimation from a ﬁnite sample. To
reduce the estimation errors, some kinds of assumptions are often needed, e.g., random
sampling assumptions, replacement assumptions, and strict distribution assumptions. We
suggest the readers to refer (Wolter, 2007) for more details.
• For the accurate estimation of τmin, we have to assume that the Markov chain can exhibit a
cutoff, which means that the total variation distance decreases very rapidly in a small interval
(Paulin et al., 2015). Readers can check the Figure 1 of (Lubetzky & Sly, 2013) for better
understanding."
N,0.9842931937172775,"E
FURTHER DISCUSSION ON LEARNING BY UNCERTAINTY"
N,0.9860383944153578,"We discuss a related work named ActiveBias (Chang et al., 2017) on learning with uncertainty,
although it studies the predicted probability, rather than the loss. In general, the differences between
our work and ActiveBias lie in the different problems, different focuses, and different technical
implementation. In more detail, we summarize the main differences between the two works in the
following:"
N,0.987783595113438,"• ActiveBias mainly focuses on mining hard examples to help generalization. Although it
mentions the label-noise problem, it does not consider comprehensive noise settings. Also,"
N,0.9895287958115183,Published as a conference paper at ICLR 2022
N,0.9912739965095986,"the baselines are SGD, ADAM, and other optimization methods, but not the methods are
specially designed for learning with noisy labels. In contrast, our work mainly focuses on
learning with noisy labels and has more comprehensive experiments, which explore the
performance of different label-noise methods under noisy supervision."
N,0.9930191972076788,"• ActiveBias focuses on using the hard examples, but not too difﬁcult examples, which is
stated in the original paper. In the imbalanced setting of this paper, clean imbalanced data
are too difﬁcult to distinguish with the predictions of models (Figure 1, right) and therefore
are too difﬁcult examples. Our methods aim to make use of such examples. Experiments
show that such examples are of great importance for generalization."
N,0.9947643979057592,"• The introduction of uncertainty in ActiveBias relies on the estimation of the prediction
variance but does not consider the bad inﬂuence of mislabeled data/outliers on this estimation.
Our methods use the loss distribution and the side effect of mislabeled data is considered by
robust mean estimators."
N,0.9965095986038395,"F
RELATED WORK ON SAMPLE SELECTION"
N,0.9982547993019197,"In this paper, we focus on the procedure of using the small-loss criterion for sample selection, which
is very commonly used in learning with noisy labels and shared by the state-of-the-art methods. We
review prior effects in this line. Existing methods (Jiang et al., 2018; Han et al., 2018; Yu et al.,
2019; Wei et al., 2020; Lyu & Tsang, 2020) focus on the class-balanced problem. Based on the
memorization effect of deep networks, they select examples with small losses for network updates
and drop examples with large losses. The main reason is that clean examples are more likely to
have small losses, but mislabeled examples are more likely to have large losses in class-balanced
cases. Distinctly, these methods ignore the clean examples with large losses, following suboptimal
generalization. When the training dataset is noisy and extremely imbalanced, prior methods are weak.
It is because since they cannot select clean hard examples within non-dominant classes effectively
based on losses, which is shown in the main paper. Unfortunately, such examples are critical for
generalization. We are the ﬁrst one to focus on this important problem and tackle it by considering
the uncertainty of losses."
