Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.003205128205128205,"As machine learning conferences grow rapidly, many are concerned that individ-
uals will be left behind on the basis of traits such as gender and geography. We
leverage historic ICLR submissions from 2017 to 2021 to investigate the impact
of gender and country of origin both on representation and paper review outcomes
at ICLR. We also study various hypotheses that could explain gender represen-
tation disparities at ICLR, with a focus on factors that impact the likelihood of
an author returning to the conference in consecutive years. Finally, we probe the
interplay between paper topic and review outcomes, and perform a study on how
the inclusion of theorems in a paper and the size of the author list correlates with
paper scores."
INTRODUCTION,0.00641025641025641,"1
INTRODUCTION"
INTRODUCTION,0.009615384615384616,"It is well known that the ﬁeld of computer science has strong representation disparities across both
racial/ethnic and gender categories (Zweben & Bizot, 2021; Muro et al., 2018; Dillon Jr et al., 2015).
For example, women comprised just 23.6% of enrollees in computation graduate programs in 2020,
and only 1.2% of awarded PhDs were to Black students (Zweben & Bizot, 2021). While these
statistics paint a concerning picture of the ﬁeld’s ability to recruit and retain students from diverse
backgrounds, representation at ICLR is considerably more distorted. Last year, Tran et al. (2020)
reported that only 12.1% of ICLR papers from US universities were lead by a woman ﬁrst author.
Using methods described in this paper, we observe that this number decreased to 10.62% in 2021."
INTRODUCTION,0.01282051282051282,"Gender representation disparity is quite extreme at ICLR, even within the context of well-known
disparities in computer science at large. This motivates us to study these representation disparities
more deeply, and we seek to identify and analyze theories for why they might exist. In particular, we
are interested in whether issues concerning authorship, community, and the review process can be
identiﬁed as factors that inﬂuence the representation of different groups. We consider these issues:"
INTRODUCTION,0.016025641025641024,"• Retention We ﬁnd that women who attend ICLR are less likely to return to the conference
the following year than men. We study a number of factors that may contribute to this
effect. We ﬁnd that women are much more likely to return when they are mentored by a
woman and that both women and men are far less likely to return after receiving negative
scores during review. At the same time, women are advantaged by working with slightly
larger authorship teams, which tends to result in more positive outcomes."
INTRODUCTION,0.019230769230769232,"• Country of Origin We ﬁnd that papers from western nations tend to score higher, while
papers from East and South Asia score lower than the conference average, although no
signiﬁcant bias against Asian papers is detected when acceptance decisions are made, con-
trolling for reviewer scores."
INTRODUCTION,0.022435897435897436,"• Topic Breakdown & Theory vs Empirical papers We see that papers containing theo-
rems are far more likely to be accepted than non-theory papers. Further, women tend to
submit papers to topics with slightly lower acceptance rates than men."
INTRODUCTION,0.02564102564102564,"• Industry Afﬁliations Papers from Google, Facebook, and Microsoft are much more likely
to be accepted on average. Interestingly, women ﬁrst authors are slightly more prevalent
among industry papers than among academic papers."
INTRODUCTION,0.028846153846153848,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.03205128205128205,"While the focus of our study is on demographic differences in review outcomes, a number of recent
studies have been conducted on the review process at large, with a focus on reproducibility and
quality of reviews (Rogers & Augenstein, 2020; Bharadhwaj et al., 2020; Stelmakh et al., 2020b;a;
Fiez et al., 2020; Manzoor & Shah, 2020; Shah et al., 2018; Stelmakh et al., 2019)."
DATASET CONSTRUCTION,0.035256410256410256,"2
DATASET CONSTRUCTION"
DATASET CONSTRUCTION,0.038461538461538464,"Our analysis is based on a dataset we acquired using the APIs of OpenReview and SemanticScholar,
followed by extensive hand-labeling procedures conducted by the authors. From OpenReview, we
obtained titles, paper text, author lists, emails, scores, and reviews for ICLR papers from 2017-
2021. In total, 8,553 submissions were obtained: 2,978 from ICLR 2021, 2,560 from ICLR 2020,
1,565 from ICLR 2019, 960 from ICLR 2018, and 490 from ICLR 2017. To identify an author’s
institution, we used the author’s email listed on their OpenReview proﬁle and then mapped them to
institutions with the open source World University and Domains dataset."
DATASET CONSTRUCTION,0.041666666666666664,"We used SemanticScholar to scrape author- and paper-speciﬁc data. Author-speciﬁc data includes
the number of citations, publications, inﬂuential papers, and h-index of each author on the paper.
These data was obtained by scraping every paper by each author on SemanticScholar, identifying pa-
pers with titles that were either identical or similar as measured by edit distance, and hand-validating
to see if identiﬁed papers were correct. Paper-speciﬁc data includes the number of citations."
DATASET CONSTRUCTION,0.04487179487179487,"To study the role that gender plays in the review process, we hand-labeled gender for ﬁrst and last
authors on ICLR 2021 submissions. These labels were produced without relying on an automated
process and rather by searching for gendered pronouns that appeared on personal webpages, social
media, and CVs if applicable, and choosing the canonical gender for the name otherwise. We chose
this process because ICLR has broad international participation, and automated gender inference
tools, while more reproducible, are known to have unusually strong biases and inaccuracies on
non-western identities (Santamar´ıa & Mihaljevi´c, 2018). We consider only binary gender labels.
Future work should consider the experiences of non-binary and transgender people, however these
populations cannot be easily studied using the statistical methods used in this paper."
GENDER REPRESENTATION AT ICLR,0.04807692307692308,"3
GENDER REPRESENTATION AT ICLR"
GENDER REPRESENTATION AT ICLR,0.05128205128205128,"Tran et al. (2020) identiﬁed that women are highly under-represented at ICLR; in 2019, women
made up 23.2% of all CS PhD students in the US (Zweben & Bizot, 2020), while only 12.1% of ﬁrst
authors at ICLR from US universities were women. We ﬁnd that this disparity widened in 2020,
with women compromising just 10.62% of ﬁrst authors and 10.77% of last authors. For comparison,
women comprised 23.4% of enrollees in doctoral CS programs and 24.8% of computer science,
computer engineering, and information programs combined (Zweben & Bizot, 2021)."
GENDER REPRESENTATION AT ICLR,0.05448717948717949,"There are many complex social and economic factors that likely contribute to the under-
representation of women in computer science, including conﬁdence gaps between men and women
in STEM classrooms (Lubienski et al., 2013), stereotypes of skill levels and gender roles in aca-
demics (Lubienski et al., 2013), differences in workplace treatment between men and women (Funk
& Parker, 2018), and even differences in income after graduation (Xu, 2015). However, the repre-
sentation disparity at ICLR is strikingly more lopsided than what is observed in the computer science
community at large, which indicates community-speciﬁc factors that inﬂuence representation."
GENDER REPRESENTATION AT ICLR,0.057692307692307696,"In this section, we consider various hypotheses for why such a strong disparity in representation
might exist at ICLR. While there may be a range of sociological factors at play that are outside
the scope of our study, we focus on factors that can be analyzed through publicly available data.
Throughout this section, we focus on the likelihood of women returning to ICLR after appearing
once. We focus only on the return rate of ﬁrst authors. This is because last authors are unlikely to be
ﬁrst time attendees and often have long professional careers in ML that make them likely to return
to the conference regardless of the factors identiﬁed below."
GENDER REPRESENTATION AT ICLR,0.060897435897435896,Under review as a conference paper at ICLR 2022
RETENTION,0.0641025641025641,"3.1
RETENTION"
RETENTION,0.0673076923076923,"We observe that ICLR has somewhat more difﬁculty retaining women participants than men. Among
ﬁrst-time conference attendees in 2020, of the women who appeared as ﬁrst author on a paper,
19.79% returned in 2021, compared to 23.83% for men. Expanding to account for all 2020 attendees
regardless of their number of appearances, this mild discrepancy remains; the return rate for women
was 28.12% compared to 31.64% for men."
RETENTION,0.07051282051282051,"As for why this discrepancy exists, the difference in return rate could be explained in part by out-
comes in the review process. We hypothesize that authors receiving strongly negative feedback on
their contributions may be less likely to return to the conference and that the relatively lower scores
women receive make them less likely to return. Tran et al. (2020) reported that papers from women
ﬁrst authors on average scored 0.16 points lower than men in 2020. Our 2021 data shows a present
but smaller gender gap with women ﬁrst authors on average scoring 0.13 points lower than men ﬁrst
authors (p = 0.03). This gender discrepancy is clearly visible in the score histograms in Figure 1.
There is no discernible gender gap for last authors."
RETENTION,0.07371794871794872,(a) First Author
RETENTION,0.07692307692307693,"2
4
6
8
10
Score 0.00 0.05 0.10 0.15 0.20 0.25"
RETENTION,0.08012820512820513,Density
RETENTION,0.08333333333333333,Legend
RETENTION,0.08653846153846154,"Female First
Male First"
RETENTION,0.08974358974358974,(b) Last Author
RETENTION,0.09294871794871795,"2
4
6
8
10
Score 0.00 0.05 0.10 0.15 0.20 0.25"
RETENTION,0.09615384615384616,Density
RETENTION,0.09935897435897435,Legend
RETENTION,0.10256410256410256,"Female Last
Male Last"
RETENTION,0.10576923076923077,"Figure 1: Histogram of average scores by gender, ﬁrst and last author, ICLR 2017 - ICLR 2021. We
observe a pronounced gap in ﬁrst author scores, but a mostly equal distribution for last authors."
RETENTION,0.10897435897435898,"This hypothesis is indeed supported by the data – review scores strongly correlate with retention
rates. A logistic model predicting author return probability as a function of mean reviewer score and
gender identiﬁes reviewer scores as a strong factor in predicting author return (p = 0.015, Table 1).
This trend is a signiﬁcant factor within both the men and women sub-populations (see Table 5 in the
Appendix). In a separate test, women with rejected papers had a return rate of 24.28% while men
with rejected papers had a return rate of 30.28% (p = 0.073)."
RETENTION,0.11217948717948718,"Research on small minority peer groups in STEM ﬁelds (Etzkowitz et al., 1992; Rosser & Lane,
2002) suggests that the effect of reviewer scores may be stronger for women than for men, however
we did not detect this as a signiﬁcant factor in Table 1)."
RETENTION,0.11538461538461539,"Table 1: Return rate for ﬁrst authors as a function of mean reviewer score and gender indicator.
The logistic regression model had a 70.8% accuracy and a hold-out set containing 30% of 2,122 ﬁrst
authors."
RETENTION,0.11858974358974358,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
RETENTION,0.12179487179487179,"mean reviewer score
0.236
0.097
2.430
0.015
gender indicator
0.374
0.460
0.811
0.417
gender × mean review
-0.045
0.102
-0.441
0.659
constant
-1.960
0.437
-4.488
0.000"
RETENTION,0.125,Under review as a conference paper at ICLR 2022
AMOUNT OF PROFESSIONAL EXPERIENCE,0.1282051282051282,"3.2
AMOUNT OF PROFESSIONAL EXPERIENCE"
AMOUNT OF PROFESSIONAL EXPERIENCE,0.13141025641025642,"Negative reviewer scores are commonplace in the machine learning community at large. One may
expect experienced authors to be well acquainted with this fact, and therefore less strongly impacted
by negative scores than those authors receiving their ﬁrst ever round of reviews. In this section,
we quantify how author experience correlates with the return rate of ﬁrst authors. We consider
the relation between professional experience and ﬁrst author outcomes, in addition to last author’s
experience level."
AMOUNT OF PROFESSIONAL EXPERIENCE,0.1346153846153846,"We identify “ﬁrst-time” authors as people who did not submit a paper to ICLR in 2017-2019. Note
that we use “ﬁrst author” to refer to author order, and “ﬁrst time author” to refer to lack of prior
submissions. We ﬁnd that ﬁrst time authors are less likely to return to ICLR than other authors
(p<0.001). This effect is still highly signiﬁcant even after controlling for reviewer scores. Women
ﬁrst-time authors return with a rate of 20.36%, while men ﬁrst-time authors return with a rate of
24.54%. The observations in this study are applicable to many attendees, as 65% of women and
63% of men are ﬁrst-time authors."
AMOUNT OF PROFESSIONAL EXPERIENCE,0.13782051282051283,"We also consider the number of publications an author has and how it correlates with their return
rate. After controlling for reviewer scores1, we ﬁnd that the number of publications of the ﬁrst
author was correlated with return rate, but not to a statistically signiﬁcant degree (p = 0.143, Table
6). We ﬁnd that the number of citations is not a good indicator of return rate, possibly because it
varies wildly for young researchers."
MENTORSHIP AND GENDER PAIRING,0.14102564102564102,"3.3
MENTORSHIP AND GENDER PAIRING"
MENTORSHIP AND GENDER PAIRING,0.14423076923076922,"Gender researchers in STEM ﬁelds have often cited the gender pairing of mentors and mentees as a
major factor in predicting author productivity (Gaule & Piacentini, 2018; Pezzoni et al., 2016; Kato
& Song, 2018). At ICLR, we ﬁnd that ﬁrst authors are more likely to return to the conference if
their mentor is of the same gender as they are. Women ﬁrst authors with women last authors had
a return rate of 42.22% while women ﬁrst authors with male last authors had a return rate of only
25.40% (p = 0.02). A similar trend existed for men, who returned 46.36% of the time with a male
last author, and only 31.01% of the time with a women last author (p<0.001)."
MENTORSHIP AND GENDER PAIRING,0.14743589743589744,"Curiously, women-women teams had a lower acceptance rate (23.5% vs 27.3%) than women-man
teams, and yet women-women teams still result in much higher retention. Furthermore, when we
control for paper scores, a logistic model still identiﬁes gender pairing as yielding a highly signiﬁcant
boost to return rate (p=0.01)."
MENTORSHIP AND GENDER PAIRING,0.15064102564102563,"Finally, we see that the experience of the last author, as measured by the log of their total citation
count, correlates strongly with ﬁrst author return rate. After controlling for reviewer scores, we ﬁnd
that the citation count of the last author is a signiﬁcant factor in predicting ﬁrst author return rate,
with more experienced last authors making return more likely (p = 0.002; Table 7)."
AUTHORSHIP TEAMS,0.15384615384615385,"4
AUTHORSHIP TEAMS"
AUTHORSHIP TEAMS,0.15705128205128205,"In this section, we investigate whether larger authorship teams perform better. Our study is motivated
by the prevalence of personal accounts of isolation among women in computer science (Sankar,
2015; Fisher & Margolis, 2002; Frenkel, 1990) which posits that the relatively smaller peer group
for women may result in having fewer collaborators, and as a result fewer co-authors. Our study
does not ﬁnd evidence of this and, in fact, indicates that women tend to have larger authorship teams
than men."
AUTHORSHIP TEAMS,0.16025641025641027,"For this study, we consider papers with 1 author, 2 authors, 3 authors, 4 authors, 5 authors, 6 authors,
7 authors, and 8 or more authors. These categories had 274, 1396, 2144, 1896, 1276, 767, 410, and
383 submissions, respectively."
AUTHORSHIP TEAMS,0.16346153846153846,"We ﬁnd that mean reviewer scores increase monotonically with the number of authors (Figure 3).
This is consistent with published observations that collaborative papers in the sciences generally"
AUTHORSHIP TEAMS,0.16666666666666666,"1Less experienced authors are likely to receive lower scores, making them less likely to return. Our model
includes reviewer score as a control variable to remove this effect."
AUTHORSHIP TEAMS,0.16987179487179488,Under review as a conference paper at ICLR 2022
AUTHORSHIP TEAMS,0.17307692307692307,"(a) First Author, Author List Size Distribution"
AUTHORSHIP TEAMS,0.1762820512820513,"1
2
3
4
5
6
7
8
9
Number of Authors 0.00 0.05 0.10 0.15 0.20 0.25"
AUTHORSHIP TEAMS,0.1794871794871795,Density
AUTHORSHIP TEAMS,0.18269230769230768,Legend
AUTHORSHIP TEAMS,0.1858974358974359,"Male
Female"
AUTHORSHIP TEAMS,0.1891025641025641,"(b) Last Author, Author List Size Distribution"
AUTHORSHIP TEAMS,0.19230769230769232,"1
2
3
4
5
6
7
8
9
Number of Authors 0.00 0.05 0.10 0.15 0.20 0.25"
AUTHORSHIP TEAMS,0.1955128205128205,Density
AUTHORSHIP TEAMS,0.1987179487179487,Legend
AUTHORSHIP TEAMS,0.20192307692307693,"Male
Female"
AUTHORSHIP TEAMS,0.20512820512820512,"Figure 2: Distributions of number of co-authors based on gender. With respect to the gender of (left)
ﬁrst author (right) last author."
AUTHORSHIP TEAMS,0.20833333333333334,"score better and accrue citations faster than single author papers (Shneiderman, 2018; 2016; Perk-
mann et al., 2013). A regression model controlling for reviewer scores does not ﬁnd a signiﬁcant
correlation between author number and acceptance rate, i.e., ACs do not appear to preferentially
accept papers with more authors."
AUTHORSHIP TEAMS,0.21153846153846154,"0
1
2
3
4
5
6
7
Number of Authors 4.2 4.4 4.6 4.8 5.0 5.2 5.4"
AUTHORSHIP TEAMS,0.21474358974358973,Mean Reviewer Score
AUTHORSHIP TEAMS,0.21794871794871795,"1
2
3
4
5
6
7
8+
Number of Authors 0.00 0.02 0.04 0.06 0.08 0.04"
AUTHORSHIP TEAMS,0.22115384615384615,"0.06
0.06 0.07 0.05"
AUTHORSHIP TEAMS,0.22435897435897437,"0.09
0.09 0.05"
AUTHORSHIP TEAMS,0.22756410256410256,"Figure 3: (left) Mean reviewer scores as a function of number of authors, ICLR 2017 to ICLR 2021.
(right) Percent of women-led papers in each authorship category, ICLR 2017 to ICLR 2021."
AUTHORSHIP TEAMS,0.23076923076923078,"It might be possible that papers with more authors are more likely to be accepted due to the higher
probability of personal connections with an AC. We do not ﬁnd enough support for this hypothesis;
a regression model controlling for reviewer scores does not ﬁnd a signiﬁcant correlation between
author number and acceptance rate, i.e., ACs do not appear to preferentially accept papers with
more authors."
AUTHORSHIP TEAMS,0.23397435897435898,"We ﬁnd that women on average were part of larger authorship teams. Men ﬁrst author papers had on
average 4.06 authors, while women had 4.25. Men last author papers had 4.06 authors on average,
Women had 4.37. See Figure 2 for the distributions."
GEOGRAPHIC REPRESENTATION,0.23717948717948717,"5
GEOGRAPHIC REPRESENTATION"
GEOGRAPHIC REPRESENTATION,0.2403846153846154,"This section breaks down how a paper’s country of origin correlates with review outcomes. We
focus on academic (rather than industrial) papers, as they are associated with a university with a
well-deﬁned location. We attribute a paper to the national afﬁliation of its last author. We separate
the papers into ten different regions: Australia and New Zealand (96 papers), Canada (333 papers),
East Asia (including China, Japan, Mongolia, North Korea, South Korea, and Taiwan, 498 papers),"
GEOGRAPHIC REPRESENTATION,0.24358974358974358,Under review as a conference paper at ICLR 2022
GEOGRAPHIC REPRESENTATION,0.2467948717948718,"Mainland Europe (498 papers), the Middle East (including Bahrain, Cyprus, Egypt, Iran, Iraq, Israel,
Jordan, Kuwait, Lebanon, Oman, Palestine, Qatar, Saudi Arabia, the Syrian Arab Republic, Turkey,
the United Arab Emirates, and Yemen, 113 papers), Russia (13 papers), South America (13 papers),
South Asia (including Afghanistan, Bangladesh, Bhutan, India, Nepal, Pakistan, Sri Lanka and the
Maldives, 355 papers), the UK and Ireland (438 papers), and the United States (2345 papers)."
GEOGRAPHIC REPRESENTATION,0.25,"Charts showing the geographic distribution of submitted and accepted papers appear in Figure 4.
Papers from the US and Canada on average scored 0.1 and 0.22 points higher than the conference
average respectively, while papers from East Asia and South Asia scored 0.36 and 0.55 points lower
than the conference average, respectively. Other regions did not deviate from the average score in a
substantial way. The acceptance rate of the conference over the years studied was 30.19%, while the
acceptance rate for the US was 34.58% (p < 0.001), Canada was 35.73% (p = 0.012), East Asian
was 19.27% (p < 0.001), and South Asia was 22.53% (p < 0.001). See Table 10 in the appendix."
GEOGRAPHIC REPRESENTATION,0.2532051282051282,"A logistic model that predicts acceptance as a function of mean reviewer score and an indicator vari-
able for East and South Asia indicates that, controlling for scores, papers from East and South Asia
were slightly less likely to be accepted by ACs. This discrepancy in acceptance rates is equivalent
to a change in mean reviewer score of 0.098 and had borderline p-value 0.11 (Table 2)."
GEOGRAPHIC REPRESENTATION,0.2564102564102564,(a) All Papers US
GEOGRAPHIC REPRESENTATION,0.25961538461538464,Canada
GEOGRAPHIC REPRESENTATION,0.26282051282051283,Aus + NZ
GEOGRAPHIC REPRESENTATION,0.266025641025641,Mid East
GEOGRAPHIC REPRESENTATION,0.2692307692307692,UK/Ireland
GEOGRAPHIC REPRESENTATION,0.2724358974358974,mainland Europe Other
GEOGRAPHIC REPRESENTATION,0.27564102564102566,East Asian
GEOGRAPHIC REPRESENTATION,0.27884615384615385,South Asia 0.0 0.1 0.2 0.3 0.4
GEOGRAPHIC REPRESENTATION,0.28205128205128205,"0.5
0.51 0.07"
GEOGRAPHIC REPRESENTATION,0.28525641025641024,"0.02
0.02"
GEOGRAPHIC REPRESENTATION,0.28846153846153844,"0.09
0.09 0.01 0.11 0.08"
GEOGRAPHIC REPRESENTATION,0.2916666666666667,(b) Accepted Papers US
GEOGRAPHIC REPRESENTATION,0.2948717948717949,Canada
GEOGRAPHIC REPRESENTATION,0.2980769230769231,Aus + NZ
GEOGRAPHIC REPRESENTATION,0.30128205128205127,Mid East
GEOGRAPHIC REPRESENTATION,0.30448717948717946,UK/Ireland
GEOGRAPHIC REPRESENTATION,0.3076923076923077,mainland Europe Other
GEOGRAPHIC REPRESENTATION,0.3108974358974359,East Asian
GEOGRAPHIC REPRESENTATION,0.3141025641025641,South Asia 0.0 0.1 0.2 0.3 0.4 0.5 0.57 0.08
GEOGRAPHIC REPRESENTATION,0.3173076923076923,"0.02
0.02"
GEOGRAPHIC REPRESENTATION,0.32051282051282054,"0.09
0.09 0.01"
GEOGRAPHIC REPRESENTATION,0.32371794871794873,"0.07
0.06"
GEOGRAPHIC REPRESENTATION,0.3269230769230769,Figure 4: Geographic distribution of papers submitted and accepted
GEOGRAPHIC REPRESENTATION,0.3301282051282051,"It appears that the scoring difference between papers of Western and Asian origins is likely explained
in part by Asian authors having less professional experience on average than authors from other
regions. 84% of papers of East and South Asian origin were lead by a ﬁrst-time author, whereas
ﬁrst-time authors lead 66% of papers from the US. We also suspect that scores are affected by gaps
in English language experience in addition to cultural differences in how non-Western speakers write
and communicate, although we are not able to quantify these latter impacts."
GEOGRAPHIC REPRESENTATION,0.3333333333333333,"Table 2: Impact of East Asian origin on acceptance, all submissions to ICLR from 2017 to 2021.
Logistic regression predicting paper acceptance as a function of mean reviewer score and an indica-
tor of whether the paper was from East Asia. The model achieves 90% accuracy on a hold-out set
containing 30% of 2021 papers."
GEOGRAPHIC REPRESENTATION,0.33653846153846156,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
GEOGRAPHIC REPRESENTATION,0.33974358974358976,"mean reviewer score
3.0912
0.074
41.506
0.000
east asia indicator
-0.2880
0.180
-1.598
0.110
constant
-18.2774
0.437
-41.796
0.000"
TOPIC DISTRIBUTION,0.34294871794871795,"6
TOPIC DISTRIBUTION"
TOPIC DISTRIBUTION,0.34615384615384615,"To understand how the topic of a paper correlates with the likelihood of it being accepted,
we deﬁne a high-level categorization of papers based on hand-curated keywords.
When
any of these keywords appear in the paper title and/or abstract, we assign the topic to the"
TOPIC DISTRIBUTION,0.34935897435897434,Under review as a conference paper at ICLR 2022
TOPIC DISTRIBUTION,0.3525641025641026,(a) Topic vs Submission rate
TOPIC DISTRIBUTION,0.3557692307692308,Adversarial
TOPIC DISTRIBUTION,0.358974358974359,Bayesian
TOPIC DISTRIBUTION,0.36217948717948717,Fairness
TOPIC DISTRIBUTION,0.36538461538461536,Gen. Model. Graph
TOPIC DISTRIBUTION,0.3685897435897436,MetaLearning NLP
TOPIC DISTRIBUTION,0.3717948717948718,Optimization RL
TOPIC DISTRIBUTION,0.375,Theory
TOPIC DISTRIBUTION,0.3782051282051282,Transformers
TOPIC DISTRIBUTION,0.3814102564102564,Vision 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0
TOPIC DISTRIBUTION,0.38461538461538464,Submission rate (in %) 13.9
TOPIC DISTRIBUTION,0.38782051282051283,"3.31
2.71 14.17 9.14 5.93 9.64 2.37 4.09 20.24 9.11 5.4"
TOPIC DISTRIBUTION,0.391025641025641,(b) Topic vs Acceptance rate
TOPIC DISTRIBUTION,0.3942307692307692,Adversarial
TOPIC DISTRIBUTION,0.3974358974358974,Bayesian
TOPIC DISTRIBUTION,0.40064102564102566,Fairness
TOPIC DISTRIBUTION,0.40384615384615385,Gen. Model. Graph
TOPIC DISTRIBUTION,0.40705128205128205,MetaLearning NLP
TOPIC DISTRIBUTION,0.41025641025641024,Optimization RL
TOPIC DISTRIBUTION,0.41346153846153844,Theory
TOPIC DISTRIBUTION,0.4166666666666667,Transformers
TOPIC DISTRIBUTION,0.4198717948717949,Vision 0 5 10 15 20 25 30 35
TOPIC DISTRIBUTION,0.4230769230769231,Acceptance rate (in %)
TOPIC DISTRIBUTION,0.42628205128205127,29.39 28.25 32.14
TOPIC DISTRIBUTION,0.42948717948717946,29.74 29.06 30.67 32.92
TOPIC DISTRIBUTION,0.4326923076923077,35.91 36.05 33.21 28.57 26.89
TOPIC DISTRIBUTION,0.4358974358974359,Figure 5: Topic level submission and acceptance rates on papers submitted from ICLR 2017 - 2021.
TOPIC DISTRIBUTION,0.4391025641025641,"paper (some papers appear in multiple topics).
The high-level topics used in this study
are:
Adversarial, Bayesian, Fairness, Generative models, Graph ML,
Meta-Learning, NLP, Optimization, Reinforcement Learning (RL),
Theory, Transformers, and Vision.
We refer the reader to Appendix A.1 for the
keywords used in this study."
TOPIC DISTRIBUTION,0.4423076923076923,"In Figure 5a, we show the percentage of papers falling into each of the topic categories. The numbers
are computed on ICLR papers from 2017 to 2021. Theory forms the biggest chunk followed
by Generative models and Adversarial ML. In Figure 5b, we show the percentage of
accepted papers for a given category. Reinforcement Learning was the most successful
topic followed by Optimization and Theory. We see in Fig. 6a that women were less likely
than men to submit a paper in these three categories and more likely to submit in Vision and
Transformers which were the least successful topics at ICLR. When it comes to topic level
acceptance rates, women did better than men in Meta-Learning, Fairness, and Theory and
almost comparable in Vision (Fig. 6b)."
TOPIC DISTRIBUTION,0.44551282051282054,"We also examine how paper submission rates per topic changed based on the geography of the
ﬁrst author in Figure 8 (left). We examine 4 regions - USA, Canada, Europe, Asia. US submitted
the highest proportion of papers in Theory, while Asia was highest in NLP, Transformers,
Europe in Bayesian, Generative Models and Canada in Theory, Meta-Learning,
and Fairness."
TOPIC DISTRIBUTION,0.44871794871794873,(a) Topic level submission rate - Men vs Women
TOPIC DISTRIBUTION,0.4519230769230769,Adversarial
TOPIC DISTRIBUTION,0.4551282051282051,Bayesian
TOPIC DISTRIBUTION,0.4583333333333333,Fairness
TOPIC DISTRIBUTION,0.46153846153846156,Gen. Model. Graph
TOPIC DISTRIBUTION,0.46474358974358976,MetaLearning NLP
TOPIC DISTRIBUTION,0.46794871794871795,Optimization RL
TOPIC DISTRIBUTION,0.47115384615384615,Theory
TOPIC DISTRIBUTION,0.47435897435897434,Transformers
TOPIC DISTRIBUTION,0.4775641025641026,Vision 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0
TOPIC DISTRIBUTION,0.4807692307692308,Submission rate (in %)
TOPIC DISTRIBUTION,0.483974358974359,First-author gender
TOPIC DISTRIBUTION,0.48717948717948717,"men
women"
TOPIC DISTRIBUTION,0.49038461538461536,(b) Topic level acceptance rate - Men vs Women
TOPIC DISTRIBUTION,0.4935897435897436,Adversarial
TOPIC DISTRIBUTION,0.4967948717948718,Bayesian
TOPIC DISTRIBUTION,0.5,Fairness
TOPIC DISTRIBUTION,0.5032051282051282,Gen. Model. Graph
TOPIC DISTRIBUTION,0.5064102564102564,MetaLearning NLP
TOPIC DISTRIBUTION,0.5096153846153846,Optimization RL
TOPIC DISTRIBUTION,0.5128205128205128,Theory
TOPIC DISTRIBUTION,0.5160256410256411,Transformers
TOPIC DISTRIBUTION,0.5192307692307693,Vision 0 5 10 15 20 25 30 35
TOPIC DISTRIBUTION,0.5224358974358975,Acceptance rate (in %)
TOPIC DISTRIBUTION,0.5256410256410257,First-author gender
TOPIC DISTRIBUTION,0.5288461538461539,"men
women"
TOPIC DISTRIBUTION,0.532051282051282,"Figure 6: Topic breakdown by gender, submission vs accepted papers, ICLR 2017 - ICLR 2021."
TOPIC DISTRIBUTION,0.5352564102564102,"6.1
DO PAPERS WITH THEOREMS DO BETTER THAN EMPIRICAL PAPERS?"
TOPIC DISTRIBUTION,0.5384615384615384,"It is common across sub-ﬁelds to categorize papers as theory papers and empirical papers, and
it is colloquially thought by many that papers containing a theorem are more likely to be ac-"
TOPIC DISTRIBUTION,0.5416666666666666,Under review as a conference paper at ICLR 2022
TOPIC DISTRIBUTION,0.5448717948717948,"cepted to a conference than purely empirical studies. We classify a paper as a theorem paper if
the paper body contains any of the following patterns: ""Theorem:"", ""Theorem <number>"",
""Proposition:"", ""Proposition <number>"", ""Lemma:"", ""Lemma <number>"", Out
of the 8553 papers in the data set, 2321 submissions had at least one of the aforementioned patterns."
TOPIC DISTRIBUTION,0.5480769230769231,"Theorem papers on average scored 0.34 points higher than papers classiﬁed as non-theorem papers
(p<0.001). The score distribution for the two kinds of papers is depicted in Figure 7. In all paper
topics, papers with theorems out-performed those without theorems, although not always by a sta-
tistically signiﬁcant margin, with Fairness and NLP getting the biggest boosts (Table 12). Among
women ﬁrst authors, 26.7% of papers contained a theorem compared to 31.1% for men (p = 0.028).
Finally, although theorem papers may receive higher mean reviewer scores, they do not receive a
bonus at the AC level (Table 3). We also examine how likely researchers from different demograph-
ics added a theorem in papers from different topics in Figures 7 (right) and 8 (right). We see women
were more likely to have a theorem in Theory and Fairness topics, while men were more likely
to have one in Optimization and RL topics. When it comes to region-level trends, the US was
more likely to have a theorem in most of the topics while Canada was less likely."
TOPIC DISTRIBUTION,0.5512820512820513,"2
4
6
8
10
Score 0.00 0.05 0.10 0.15 0.20 0.25"
TOPIC DISTRIBUTION,0.5544871794871795,Density
TOPIC DISTRIBUTION,0.5576923076923077,Legend
TOPIC DISTRIBUTION,0.5608974358974359,"Not Theorem
Theorem"
TOPIC DISTRIBUTION,0.5641025641025641,Adversarial
TOPIC DISTRIBUTION,0.5673076923076923,Bayesian
TOPIC DISTRIBUTION,0.5705128205128205,Fairness
TOPIC DISTRIBUTION,0.5737179487179487,Gen. Model. Graph
TOPIC DISTRIBUTION,0.5769230769230769,MetaLearning NLP
TOPIC DISTRIBUTION,0.5801282051282052,Optimization RL
TOPIC DISTRIBUTION,0.5833333333333334,Theory
TOPIC DISTRIBUTION,0.5865384615384616,Transformers
TOPIC DISTRIBUTION,0.5897435897435898,Vision 0 10 20 30 40 50 60 70 80
TOPIC DISTRIBUTION,0.592948717948718,Probability of theorem in a submitted paper
TOPIC DISTRIBUTION,0.5961538461538461,First author gender
TOPIC DISTRIBUTION,0.5993589743589743,"women
men"
TOPIC DISTRIBUTION,0.6025641025641025,"Figure 7: (left) The distribution of paper scores with and without a theorem. (right) Fraction of
theorem papers by topic - Men vs Women"
TOPIC DISTRIBUTION,0.6057692307692307,Adversarial
TOPIC DISTRIBUTION,0.6089743589743589,Bayesian
TOPIC DISTRIBUTION,0.6121794871794872,Fairness
TOPIC DISTRIBUTION,0.6153846153846154,Gen. Model. Graph
TOPIC DISTRIBUTION,0.6185897435897436,MetaLearning NLP
TOPIC DISTRIBUTION,0.6217948717948718,Optimization RL
TOPIC DISTRIBUTION,0.625,Theory
TOPIC DISTRIBUTION,0.6282051282051282,Transformers
TOPIC DISTRIBUTION,0.6314102564102564,Vision 0 5 10 15 20
TOPIC DISTRIBUTION,0.6346153846153846,Submission rate (in %)
TOPIC DISTRIBUTION,0.6378205128205128,Region
TOPIC DISTRIBUTION,0.6410256410256411,"Asia
Canada
Europe
US"
TOPIC DISTRIBUTION,0.6442307692307693,Adversarial
TOPIC DISTRIBUTION,0.6474358974358975,Bayesian
TOPIC DISTRIBUTION,0.6506410256410257,Fairness
TOPIC DISTRIBUTION,0.6538461538461539,Gen. Model. Graph
TOPIC DISTRIBUTION,0.657051282051282,MetaLearning NLP
TOPIC DISTRIBUTION,0.6602564102564102,Optimization RL
TOPIC DISTRIBUTION,0.6634615384615384,Theory
TOPIC DISTRIBUTION,0.6666666666666666,Transformers
TOPIC DISTRIBUTION,0.6698717948717948,Vision 0 20 40 60 80
TOPIC DISTRIBUTION,0.6730769230769231,Probability of theorem in a submitted paper
TOPIC DISTRIBUTION,0.6762820512820513,Region
TOPIC DISTRIBUTION,0.6794871794871795,"Asia
Canada
Europe
US"
TOPIC DISTRIBUTION,0.6826923076923077,"Figure 8: In this ﬁgure we study topic distribution with respect to geography. (left) Fraction of
papers by topic across regions (right) Fraction of theorem papers by topic across regions."
TOPIC DISTRIBUTION,0.6858974358974359,"7
HOW DO INDUSTRY PAPERS REVIEW?"
TOPIC DISTRIBUTION,0.6891025641025641,"In this section, we break down the review statistics for industry papers submitted and published by
Google (including DeepMind), Facebook, and Microsoft. In 2021, we ﬁnd that papers from each of
these organizations scored better on average than a typical conference paper. Without controlling for
scores, all three organizations were signiﬁcantly more likely the have papers accepted in 2021. The
conference acceptance rate for 2021 was 28.87%, while the rate for Google was 43.29% (p<.001),"
TOPIC DISTRIBUTION,0.6923076923076923,Under review as a conference paper at ICLR 2022
TOPIC DISTRIBUTION,0.6955128205128205,"Table 3: Theorem impact on acceptance, all submissions to ICLR from 2017 to 2021. Logistic
regression predicting paper acceptance as a function of mean reviewer score and a theorem indicator.
The model achieves 89% accuracy on a hold-out set containing 30% of 2021 papers."
TOPIC DISTRIBUTION,0.6987179487179487,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
TOPIC DISTRIBUTION,0.7019230769230769,"mean reviewer score
3.0926
0.075
41.470
0.000
theorem indicator
0.0518
0.085
0.609
0.542
constant
-18.3113
0.438
-41.795
0.000"
TOPIC DISTRIBUTION,0.7051282051282052,"Table 4: Industry impact on acceptance, Google, Facebook, and Microsoft, ICLR 2021. Logistic
regression predicting paper acceptance as a function of 3 industry indicators. The model achieves
70% accuracy on a hold-out set containing 30% of 2021 papers."
TOPIC DISTRIBUTION,0.7083333333333334,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
TOPIC DISTRIBUTION,0.7115384615384616,"google
0.7050
0.110
6.428
0.000
facebook
0.4859
0.168
2.896
0.004
microsoft
0.3573
0.166
2.147
0.032
constant
-25.6433
0.636
-40.350
.000"
TOPIC DISTRIBUTION,0.7147435897435898,"Facebook was 38.80% (p = 0.004), and Microsoft was 42.42% (p = 0.032). Women made up
slightly more ﬁrst authors on industry papers (12.86%) than they did on all papers (10.62%)."
TOPIC DISTRIBUTION,0.717948717948718,"Tran et al. (2020) ﬁnds that, controlling for reviewer scores, ACs were relatively less likely to accept
a paper from Microsoft (-.50 points, p = 0.003) while submissions from Google (.007 points,
p = 0.932) and Facebook (.07 points, p = 0.630) received non-signiﬁcant acceptance boosts at
the AC level at ICLR 2020. When controlling for score using the same procedures as Tran et al.
(2020) for consistency, we ﬁnd that at ICLR 2021, although the negative bias towards Microsoft
submissions disappeared (.08 points, p = 0.204), a positive bonus on Google submissions surfaced
(.118 points, p = 0.008). See Table 13."
CONCLUSION,0.7211538461538461,"8
CONCLUSION"
CONCLUSION,0.7243589743589743,"Using publicly available historical data and hand-curated datasets, this article examines the interplay
between demographics, representation, and review outcomes at ICLR. This study has several impor-
tant limitations that must be acknowledged. First, this is an observational study where we were not
able to do controlled experiments or identify causal relationships. Second, non-i.i.d. review scores
caused by people reviewing multiple papers, and violations of parametric assumptions, can cause
Type-I errors. These issues have been particularly problematic when detecting bias in reviews (Stel-
makh et al., 2019). Finally, note that ICLR was a virtual conference in 2020 and 2021, which may
impact demographics. Furthermore, while we did ﬁnd signiﬁcant results for some factors, we also
report trends that, in some situations, did not rise to the level of statistical signiﬁcance. Unfortu-
nately, our sample size is limited by the number of submissions, and the relatively small number of
women at ICLR limits the statistical power of our tests."
CONCLUSION,0.7275641025641025,"The study has two major goals: to raise awareness of representational issues at ICLR and to pro-
duce actionable conclusions. One of the strongest actionable conclusions reached in this paper is
that mentorship is important; women were far more likely to return to the conference when work-
ing with a women last author (25% vs 42%). Furthermore, we suspect much of the disparity in
acceptance rate of papers from Asia is due to English language experience – another factor that can
be addressed by mentorship. Finally, we know that ﬁrst authors paired with more experienced last
authors scored better (which promotes retention) and have improved retention rates overall. Collec-
tively, this evidence supports the use of mentorship and role model pairing programs to enhancing
representation."
CONCLUSION,0.7307692307692307,Under review as a conference paper at ICLR 2022
ETHICS STATEMENT,0.7339743589743589,"9
ETHICS STATEMENT"
ETHICS STATEMENT,0.7371794871794872,"This study was conducted using publicly available datasets and without surveying participants. For
this reason, we do not consider this study to raise privacy or data security issues, or to constitute
human subject research in the US federally deﬁned sense."
ETHICS STATEMENT,0.7403846153846154,"Finally, there is a risk that our observations of lower reviewer scores among some sub-populations
may promote stereotypes or reinforce negative opinions. We emphasize here that correlation does
not imply causation, and the negative effects observed in this study are the result of confounding
variables, some of which we tried and succeeded to identify, and some of which we did not."
REFERENCES,0.7435897435897436,REFERENCES
REFERENCES,0.7467948717948718,"Homanga Bharadhwaj, Dylan Turpin, Animesh Garg, and Ashton Anderson. De-anonymization of
authors through arxiv submissions during double-blind review. arXiv preprint arXiv:2007.00177,
2020."
REFERENCES,0.75,"Edward C Dillon Jr, Juan E Gilbert, Jerlando FL Jackson, and LJ Charleston. The state of african
americans in computer science-the need to increase representation. Computing Research News,
21(8):2–6, 2015."
REFERENCES,0.7532051282051282,"Henry Etzkowitz, Carol Kemelgor, Michael Neuschatz, and Brian Uzzi. Athena unbound: Barriers
to women in academic science and engineering. Science and Public Policy, 19(3):157–179, 1992."
REFERENCES,0.7564102564102564,"Tanner Fiez, Nihar Shah, and Lillian Ratliff. A super* algorithm to optimize paper bidding in peer
review. In Conference on Uncertainty in Artiﬁcial Intelligence, pp. 580–589. PMLR, 2020."
REFERENCES,0.7596153846153846,"Allan Fisher and Jane Margolis. Unlocking the clubhouse: the carnegie mellon experience. ACM
SIGCSE Bulletin, 34(2):79–83, 2002."
REFERENCES,0.7628205128205128,"Karen A Frenkel. Women and computing. Communications of the ACM, 33(11):34–46, 1990."
REFERENCES,0.7660256410256411,Cary Funk and Kim Parker. Women and men in stem often at odds over workplace equity. 2018.
REFERENCES,0.7692307692307693,"Patrick Gaule and Mario Piacentini. An advisor like me? Advisor gender and post-graduate careers
in science. Research Policy, 47(4):805–813, 2018."
REFERENCES,0.7724358974358975,"Takao Kato and Yang Song. An advisor like me: Does gender matter?
IZA Institute of Labor
Economics Discussion Paper Series, Jun 2018."
REFERENCES,0.7756410256410257,"Sarah T Lubienski, Joseph P Robinson, Corinna C Crane, and Colleen M Ganley. Brief report: Girls’
and boys’ mathematics achievement, affect, and experiences: Findings from ecls-k. Journal for
Research in Mathematics Education, 44(4):634–645, 2013."
REFERENCES,0.7788461538461539,"Emaad Manzoor and Nihar B Shah. Uncovering latent biases in text: Method and application to
peer review. arXiv preprint arXiv:2010.15300, 2020."
REFERENCES,0.782051282051282,"Mark Muro, Alan Berube, and Jacob Whiton. Black and hispanic underrepresentation in tech: It’s
time to change the equation. The Brookings Institution, 2018."
REFERENCES,0.7852564102564102,"Markus Perkmann, Valentina Tartari, Maureen McKelvey, Erkko Autio, Anders Brostr¨om, Pablo
D’este, Riccardo Fini, Aldo Geuna, Rosa Grimaldi, Alan Hughes, et al. Academic engagement
and commercialisation: A review of the literature on university–industry relations. Research
policy, 42(2):423–442, 2013."
REFERENCES,0.7884615384615384,"Michele Pezzoni, Jacques Mairesse, Paula Stephan, and Julia Lane. Gender and the publication
output of graduate students: A case study. PLoS One, 11(1):e0145146, 2016."
REFERENCES,0.7916666666666666,"Anna Rogers and Isabelle Augenstein. What can we do to improve peer review in nlp?
arXiv
preprint arXiv:2010.03863, 2020."
REFERENCES,0.7948717948717948,"Sue V Rosser and Eliesh O’Neil Lane. Key barriers for academic institutions seeking to retain female
scientists and engineers: Family-unfriendly policies. low numbers, stereotypes, and harassment.
Journal of Women and Minorities in Science and Engineering, 8(2), 2002."
REFERENCES,0.7980769230769231,Under review as a conference paper at ICLR 2022
REFERENCES,0.8012820512820513,"Pooja Sankar. The pervasive bias against female computer science majors. Fortune Magazine, 2015."
REFERENCES,0.8044871794871795,"Luc´ıa Santamar´ıa and Helena Mihaljevi´c. Comparison and benchmark of name-to-gender inference
services. PeerJ Computer Science, 4:e156, 2018."
REFERENCES,0.8076923076923077,"Nihar B Shah, Behzad Tabibian, Krikamol Muandet, Isabelle Guyon, and Ulrike Von Luxburg.
Design and analysis of the nips 2016 review process. Journal of machine learning research,
2018."
REFERENCES,0.8108974358974359,"Ben Shneiderman. The new ABCs of research: Achieving breakthrough collaborations. Oxford
University Press, 2016."
REFERENCES,0.8141025641025641,"Ben Shneiderman. Twin-win model: A human-centered approach to research success. Proceedings
of the National Academy of Sciences, 115(50):12590–12594, 2018."
REFERENCES,0.8173076923076923,"Ivan Stelmakh, Nihar Shah, and Aarti Singh. On testing for biases in peer review. Advances in
Neural Information Processing Systems, 32:5286–5296, 2019."
REFERENCES,0.8205128205128205,"Ivan Stelmakh, Charvi Rastogi, Nihar B Shah, Aarti Singh, and Hal Daum´e III. A large scale ran-
domized controlled trial on herding in peer-review discussions. arXiv preprint arXiv:2011.15083,
2020a."
REFERENCES,0.8237179487179487,"Ivan Stelmakh, Nihar B Shah, Aarti Singh, and Hal Daum´e III. A novice-reviewer experiment to
address scarcity of qualiﬁed reviewers in large conferences. arXiv preprint arXiv:2011.15050,
2020b."
REFERENCES,0.8269230769230769,"David Tran, Alex Valtchanov, Keshav Ganapathy, Raymond Feng, Eric Slud, Micah Goldblum,
and Tom Goldstein. An open review of openreview: A critical analysis of the machine learning
conference review process. arXiv preprint arXiv:2010.05137, 2020."
REFERENCES,0.8301282051282052,"Yonghong Xu. Focusing on women in stem: A longitudinal examination of gender-based earning
gap of college graduates. The Journal of Higher Education, 86(4):489–523, 2015."
REFERENCES,0.8333333333333334,"Stuart Zweben and Betsy Bizot. 2019 taulbee survey. Computing Research News, 2020."
REFERENCES,0.8365384615384616,"Stuart Zweben and Betsy Bizot. 2020 taulbee survey. Computing Research News, 2021."
REFERENCES,0.8397435897435898,"A
APPENDIX"
REFERENCES,0.842948717948718,"A.1
BREAKDOWN OF PAPERS BY TOPIC"
REFERENCES,0.8461538461538461,"The topics [and keywords] used were Vision [computer vision, object detection, segmentation,
pose estimation, optical character recognition, structure from motion, facial recognition, face recog-
nition], NLP [nlp, named-entity, machine translation, language model, word embeddings, part-of-
speech, natural language, BERT, GPT], Meta-learning [few-shot, meta learning, transfer learn-
ing, zero-shot], Adversarial ML [adversarial attack, poisoning, backdoor, adversarial exam-
ple, adversarially robust, adversarial training, certiﬁed robust, certiﬁably robust], Generative
modelling [generative adversarial network, gan, vae, variational autoencoder, diffusion models],
Fairness [gender, racial, racist, biased, unfair, demographic, ethnic, ethical], Optimization
[optimization theory, convergence rate, convex optimization, rate of convergence, global conver-
gence, local convergence, stationary point], Graph [graph, tabular], Transformers [attention,
transformer], Bayesian [bayesian], Reinforcement Learning (RL) [temporal difference
learning, value function, value network, policy gradient, actor critic, actor-critic, A2C, PPO, Q-
learning, Q learning, Q value, Bellman, DQN, Deep Q-network, mujoco, OpenSim RL, PyGame
Learning Environment, Unity ML, OpenAI Gym]."
REFERENCES,0.8493589743589743,"A.2
ADDITIONAL LOGISTIC REGRESSION SUMMARIES"
REFERENCES,0.8525641025641025,Under review as a conference paper at ICLR 2022
REFERENCES,0.8557692307692307,"Table 5: Return rate for ﬁrst authors as a function of mean reviewer score for men (top) and
women (bottom). The logistic regression models have a 69.2% and 78.1% accuracy and a hold-out
set containing 30% of 1,848 male and 30% of 243 female ﬁrst authors. Mean reviewer score is a
stronger factor on the return rate of women than men."
REFERENCES,0.8589743589743589,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
REFERENCES,0.8621794871794872,"mean reviewer score
0.1987
0.031
6.092
0.000
constant
-1.5866
0.146
-10.886
0.000"
REFERENCES,0.8653846153846154,"mean reviewer score
0.2356
0.097
2.43
0.015
constant
-1.9602
0.437
-4.488
0.000"
REFERENCES,0.8685897435897436,"Table 6: Experience level of the ﬁrst author on return rate The logistic regression models have
69.5% and 67.84%, accuracy, respectively, on a hold-out set containing 30% of 2122 ﬁrst authors."
REFERENCES,0.8717948717948718,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
REFERENCES,0.875,"first time author indicator
-1.1427
0.099
-11.586
0.000
mean reviewer score
0.1820
0.030
6.120
0.000
constant
-0.8021
0.153
-5.241
0.000"
REFERENCES,0.8782051282051282,"log base 10 publications
0.1388
0.095
1.464
0.143
mean reviewer score
0.1927
0.030
6.451
0.000
constant
-1.8050
0.183
-9.859
0.000"
REFERENCES,0.8814102564102564,"Table 7: Experience of the last author on the return rate of the ﬁrst author The logistic regres-
sion models have 64.78% accuracy on a hold-out set containing 30% of 2,122 ﬁrst authors."
REFERENCES,0.8846153846153846,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
REFERENCES,0.8878205128205128,"log base 10 citation
0.1668
0.053
3.155
0.002
mean reviewer score
0.1788
0.035
4.888
0.000
constant
-1.9845
0.223
-8.891
0.000"
REFERENCES,0.8910256410256411,"Table 8: Return rate for ﬁrst authors as a function of a gender indicator. The logistic regression
model had a 70.8% accuracy and a hold-out set containing 30% of 2122 ﬁrst authors."
REFERENCES,0.8942307692307693,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
REFERENCES,0.8974358974358975,"gender indicator
0.2104
0.152
1.381
0.167
constant
-0.9977
0.144
-6.928
0.000"
REFERENCES,0.9006410256410257,Under review as a conference paper at ICLR 2022
REFERENCES,0.9038461538461539,"Table 9: Gender impact on acceptance, ICLR 2021. Logistic regression predicting paper accep-
tance as a function of mean paper reviewer score and a gender indicator variable for both the ﬁrst
and last author. The model achieves 91% accuracy on a hold-out set containing 30% of 2021 papers.
The results were inconclusive. Papers with ﬁrst and last authors that were unlabelled were excluded."
REFERENCES,0.907051282051282,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
REFERENCES,0.9102564102564102,"mean reviewer score
4.2505
0.182
23.312
0.000
gender indicator, first author
-0.1363
0.215
-0.635
0.525
constant
-25.4785
1.098
-23.210
0.000"
REFERENCES,0.9134615384615384,"mean reviewer score
4.2523
0.179
23.778
0.000
gender indicator, last author
0.0283
0.235
0.120
0.904
constant
-25.6643
1.091
-23.514
0.000"
REFERENCES,0.9166666666666666,"Table 10: Country of origin impact on acceptance, all submissions to ICLR from 2017 to 2021.
Logistic regression predicting paper acceptance as a function of an indicator of what country it was
from. The model achieves 70% accuracy on a hold-out set containing 30% of 2021 papers."
REFERENCES,0.9198717948717948,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
REFERENCES,0.9230769230769231,"US
0.2506
0.056
4.492
0.000
Canada
0.3011
0.120
2.518
0.012
South America
0.0770
0.602
0.128
0.898
Australia/NZ
0.0006
0.227
0.003
0.998
Middle East
-0.2050
0.230
-0.893
0.372
UK/Ireland
-0.0233
0.147
-0.159
0.874
Mainland Europe
0.0921
0.109
0.844
0.398
Russia
0.3259
0.579
0.562
0.574
South Asia
-0.3468
0.132
-2.632
0.008
East Asia
-0.5442
0.119
-4.578
0.000
constant
-0.8879
0.035
-25.347
0.000"
REFERENCES,0.9262820512820513,"Table 11: Country of origin impact on acceptance, all submissions to ICLR from 2017 to 2021.
Logistic regression predicting paper acceptance as a function of mean reviewer score and an indi-
cator of what country it was from. The model achieves 90% accuracy on a hold-out set containing
30% of 2021 papers."
REFERENCES,0.9294871794871795,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
REFERENCES,0.9326923076923077,"mean reviewer score
3.0962
0.075
41.426
0.000
US
0.0770
0.093
0.827
0.408
Canada
0.0714
0.196
0.364
0.716
South America
1.4728
0.973
1.514
0.130
Australia/NZ
-0.0628
0.356
-0.176
0.860
Middle East
-0.1418
0.375
-0.378
0.705
UK/Ireland
0.3342
0.241
1.384
0.166
Mainland Europe
-0.1479
0.181
-0.818
0.414
Russia
-0.0601
0.833
-0.072
0.942
South Asia
0.0807
0.236
0.341
0.733
East Asia
-0.2593
0.185
-1.401
0.161
constant
-18.3354
0.440
-41.656
0.000"
REFERENCES,0.9358974358974359,Under review as a conference paper at ICLR 2022
REFERENCES,0.9391025641025641,"Table 12: Theorem impact on acceptance for each category, all submissions to ICLR from 2017
to 2021. Logistic regression predicting paper acceptance for each category as a function of a theorem
indicator. The models have a 68.72%, 74.83%, 66.91%, 68.63%, 70.11%, 72.12%, 66.66%, 69.68%,
63.63%, 70.19%, 70.96%, 61.4% accuracy on a hold-out set containing 30% of all papers."
REFERENCES,0.9423076923076923,"Regressions are for topics in the following order: Theory, Vision, NLP, Adversarial, Generative
Modelling, Meta-Learning, Fairness, Transformers, Optimization, Graph, Bayesian, and RL."
REFERENCES,0.9455128205128205,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
REFERENCES,0.9487179487179487,"theorem indicator
0.1612
0.097
1.667
0.095
constant
-0.7764
0.071
-10.904
0.000"
REFERENCES,0.9519230769230769,"theorem indicator
0.3625
0.273
1.327
0.185
constant
-1.0557
0.110
-9.580
0.000"
REFERENCES,0.9551282051282052,"theorem indicator
0.6300
0.205
3.066
0.002
constant
-0.7925
0.077
-10.271
0.000"
REFERENCES,0.9583333333333334,"theorem indicator
0.3160
0.129
2.454
0.014
constant
-0.9762
0.075
-12.969
0.000"
REFERENCES,0.9615384615384616,"theorem indicator
0.3597
0.142
2.536
0.011
constant
-0.9391
0.074
-12.616
0.000"
REFERENCES,0.9647435897435898,"theorem indicator
0.1627
0.257
0.633
0.526
constant
-0.8372
0.100
-8.334
0.000"
REFERENCES,0.967948717948718,"theorem indicator
1.2009
0.489
2.456
0.014
constant
-1.4523
0.335
-4.336
0.000"
REFERENCES,0.9711538461538461,"theorem indicator
0.3199
0.197
1.624
0.104
constant
-0.9705
0.084
-11.511
0.000"
REFERENCES,0.9743589743589743,"theorem indicator
0.3474
0.406
0.856
0.392
constant
-0.8755
0.376
-2.326
0.020"
REFERENCES,0.9775641025641025,"theorem indicator
0.2986
0.164
1.821
0.069
constant
-0.9793
0.091
-10.758
0.000"
REFERENCES,0.9807692307692307,"theorem indicator
0.4187
0.271
1.547
0.122
constant
-1.0622
0.155
-6.852
0.000"
REFERENCES,0.9839743589743589,"theorem indicator
0.3792
0.221
1.715
0.086
constant
-0.7056
0.137
-5.163
0.000"
REFERENCES,0.9871794871794872,Under review as a conference paper at ICLR 2022
REFERENCES,0.9903846153846154,"Table 13: Industry impact on acceptance, Google, Facebook, and Microsoft, ICLR 2021. Lo-
gistic regression predicting paper acceptance as a function of mean reviewer score and 3 industry
indicators. The model achieves 91% accuracy on a hold-out set containing 30% of 2021 papers."
REFERENCES,0.9935897435897436,"Variable
Coefﬁcient
Std. Error
Z-score
p-value"
REFERENCES,0.9967948717948718,"mean reviewer score
4.2521
.106
40.006
0.000
google
.5036
.191
2.639
.008
facebook
-0.1219
.291
-.0419
.675
microsoft
.3420
.269
1.270
.204
constant
-25.6433
0.636
-40.350
.000"
