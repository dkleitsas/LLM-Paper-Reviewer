Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0008130081300813008,"Continual Test-Time Adaptation (CTTA) task investigates effective domain adapta-
1"
ABSTRACT,0.0016260162601626016,"tion under the scenario of continuous domain shifts during testing time. Due to the
2"
ABSTRACT,0.0024390243902439024,"utilization of solely unlabeled samples, there exists significant uncertainty in model
3"
ABSTRACT,0.0032520325203252032,"updates, leading CTTA to encounter severe error accumulation issues. In this paper,
4"
ABSTRACT,0.0040650406504065045,"we introduce VCoTTA, a variational Bayesian approach to measure uncertainties
5"
ABSTRACT,0.004878048780487805,"in CTTA. At the source stage, we transform a pretrained deterministic model into
6"
ABSTRACT,0.005691056910569106,"a Bayesian Neural Network (BNN) via a variational warm-up strategy, injecting
7"
ABSTRACT,0.0065040650406504065,"uncertainties into the model. During the testing time, we employ a mean-teacher
8"
ABSTRACT,0.007317073170731708,"update strategy using variational inference for the student model and exponential
9"
ABSTRACT,0.008130081300813009,"moving average for the teacher model. Our novel approach updates the student
10"
ABSTRACT,0.00894308943089431,"model by combining priors from both the source and teacher models. The evidence
11"
ABSTRACT,0.00975609756097561,"lower bound is formulated as the cross-entropy between the student and teacher
12"
ABSTRACT,0.01056910569105691,"models, along with the Kullback-Leibler (KL) divergence of the prior mixture.
13"
ABSTRACT,0.011382113821138212,"Experimental results on three datasets demonstrate the method’s effectiveness in
14"
ABSTRACT,0.012195121951219513,"mitigating error accumulation within the CTTA framework. Our code is anony-
15"
ABSTRACT,0.013008130081300813,"mously available at https://anonymous.4open.science/r/vcotta-D2C3/.
16"
INTRODUCTION,0.013821138211382113,"1
Introduction
17"
INTRODUCTION,0.014634146341463415,"Continual Test-Time Adaptation (CTTA) [51] aims to enable a model to accommodate a sequence
18"
INTRODUCTION,0.015447154471544716,"of distinct distribution shifts during the testing time, making it applicable to various risk-sensitive
19"
INTRODUCTION,0.016260162601626018,"applications in open environments, such as autonomous driving and medical imaging. However, real-
20"
INTRODUCTION,0.01707317073170732,"world non-stationary test data exhibit high uncertainty in their temporal dynamics [23], presenting
21"
INTRODUCTION,0.01788617886178862,"challenges related to error accumulation [51]. Previous CTTA studies rely on methods that enforce
22"
INTRODUCTION,0.01869918699186992,"prediction confidence, such as entropy minimization. However, these approaches often lead to
23"
INTRODUCTION,0.01951219512195122,"predictions that are overly confident and less well-calibrated, thus limiting the model’s ability to
24"
INTRODUCTION,0.02032520325203252,"quantify risks during predictions. The reliable estimation of uncertainty becomes particularly crucial
25"
INTRODUCTION,0.02113821138211382,"in the context of continual distribution shift [40]. It is meaningful to design a model capable of
26"
INTRODUCTION,0.02195121951219512,"encoding the uncertainty associated with temporal dynamics and effectively handling distribution
27"
INTRODUCTION,0.022764227642276424,"shifts. The objective of this paper is to devise a CTTA procedure that not only enhances predictive
28"
INTRODUCTION,0.023577235772357725,"accuracy under distribution shifts but also provides reliable uncertainty estimates.
29"
INTRODUCTION,0.024390243902439025,"To address the above problem, we refer to the Bayesian Inference (BI) [1], which retains a distribution
30"
INTRODUCTION,0.025203252032520326,"over model parameters that indicates the plausibility of different settings given the observed data, and
31"
INTRODUCTION,0.026016260162601626,"it has been witnessed as effective in traditional continual learning tasks [38]. In Bayesian continual
32"
INTRODUCTION,0.026829268292682926,"learning, the posterior in the last learning task is set to be the current prior which will be multiplied
33"
INTRODUCTION,0.027642276422764227,"by the current likelihood. This kind of prior transmission is designed to reduce catastrophic forgetting
34"
INTRODUCTION,0.028455284552845527,"in continual learning. However, this is not feasible in CTTA because unlabeled data may introduce
35"
INTRODUCTION,0.02926829268292683,"unreliable prior. As shown in Fig. 1, an unreliable prior may lead to a poor posterior, which may then
36"
INTRODUCTION,0.03008130081300813,"propagate errors to the next inference, leading to the accumulation of errors.
37 BNN BNN"
INTRODUCTION,0.030894308943089432,"BNN
Source BNN"
INTRODUCTION,0.03170731707317073,Domain shift
INTRODUCTION,0.032520325203252036,Domain shift
INTRODUCTION,0.03333333333333333,Adaptation using
INTRODUCTION,0.03414634146341464,unreliable prior Error acc umu lati on ...
INTRODUCTION,0.034959349593495934,Domain shift
INTRODUCTION,0.03577235772357724,"Train
Test"
INTRODUCTION,0.036585365853658534,"Figure 1: In CTTA task, a BNN model is first trained on a source dataset, and then is used to adapt
to updated with unreliable priors, which may result in error accumulations."
INTRODUCTION,0.03739837398373984,"Thus, we delve into the utilization of BI framework to evaluate model uncertainty in CTTA, aiming
38"
INTRODUCTION,0.038211382113821135,"to mitigate the impact of unreliable priors and reduce the error propagation. To approximate the
39"
INTRODUCTION,0.03902439024390244,"intractable likelihood in BI, we adopt to use online Variational Inference (VI) [49, 42], and accordingly
40"
INTRODUCTION,0.03983739837398374,"name our method Variational Continual Test-Time Adaptation (VCoTTA). At the source stage,
41"
INTRODUCTION,0.04065040650406504,"we first transform a pretrained deterministic model, say CNN, into a Bayesian Neural Network
42"
INTRODUCTION,0.041463414634146344,"(BNN) by a variational warm-up strategy, where the local reparameterization trick [27] is used to
43"
INTRODUCTION,0.04227642276422764,"inject uncertainties into the source model. During the testing phase, we employ a mean-teacher
44"
INTRODUCTION,0.043089430894308944,"update strategy, where the student model is updated via VI and the teacher model is updated by
45"
INTRODUCTION,0.04390243902439024,"the exponential moving average. Specifically, for the update of the student model, we propose to
46"
INTRODUCTION,0.044715447154471545,"use a mixture of priors from both the source and teacher models, then the Evidence Lower BOund
47"
INTRODUCTION,0.04552845528455285,"(ELBO) becomes the cross-entropy between the student and teachers plus the KL divergence of the
48"
INTRODUCTION,0.046341463414634146,"prior mixture. We demonstrate the effectiveness of the proposed method on three datasets, and the
49"
INTRODUCTION,0.04715447154471545,"results show that the proposed method can mitigate the error accumulation in CTTA and obtain clear
50"
INTRODUCTION,0.04796747967479675,"performance improvements.
51"
INTRODUCTION,0.04878048780487805,"Our contributions are three-fold:
52"
INTRODUCTION,0.04959349593495935,"(1) This paper develops VCoTTA, a simple yet general framework for continual test-time adaptation
53"
INTRODUCTION,0.05040650406504065,"that leverages online VI within BNN.
54"
INTRODUCTION,0.05121951219512195,"(2) We propose to transform an off-the-shelf model into a BNN via a variational warm-up strategy,
55"
INTRODUCTION,0.05203252032520325,"which injects uncertainties into the model.
56"
INTRODUCTION,0.052845528455284556,"(3) We build a mean-teacher structure for CTTA, and propose a strategy to blend the teacher’s prior
57"
INTRODUCTION,0.05365853658536585,"with the source’s prior to mitigate unreliable prior problem.
58"
RELATED WORK,0.05447154471544716,"2
Related Work
59"
CONTINUAL TEST-TIME ADAPTATION,0.055284552845528454,"2.1
Continual Test-Time Adaptation
60"
CONTINUAL TEST-TIME ADAPTATION,0.05609756097560976,"Test-Time Adaptation (TTA) enables the model to dynamically adjust to the characteristics of the
61"
CONTINUAL TEST-TIME ADAPTATION,0.056910569105691054,"test data, i.e. target domain, in a source-free and online manner [25, 46, 50]. Previous works have
62"
CONTINUAL TEST-TIME ADAPTATION,0.05772357723577236,"enhanced TTA performance through the designs of unsupervised loss [37, 58, 32, 9, 7, 17]. These
63"
CONTINUAL TEST-TIME ADAPTATION,0.05853658536585366,"endeavours primarily focus on enhancing adaptation within a fixed target domain, representing a
64"
CONTINUAL TEST-TIME ADAPTATION,0.05934959349593496,"single-domain TTA setup, where models adapt to a specific target domain and then reset to their
65"
CONTINUAL TEST-TIME ADAPTATION,0.06016260162601626,"original pretrained state with the source domain, prepared for the next target domain adaptation.
66"
CONTINUAL TEST-TIME ADAPTATION,0.06097560975609756,"Recently, CTTA [51] has been introduced to tackle TTA within a continuously changing target
67"
CONTINUAL TEST-TIME ADAPTATION,0.061788617886178863,"domain, involving long-term adaptation. This configuration often grapples with the challenge of error
68"
CONTINUAL TEST-TIME ADAPTATION,0.06260162601626017,"accumulation [47, 51]. Specifically, prolonged exposure to unsupervised loss from unlabeled test
69"
CONTINUAL TEST-TIME ADAPTATION,0.06341463414634146,"data during long-term adaptation may result in significant error accumulation. Additionally, as the
70"
CONTINUAL TEST-TIME ADAPTATION,0.06422764227642276,"model is intent on learning new knowledge, it is prone to forgetting source knowledge, which poses
71"
CONTINUAL TEST-TIME ADAPTATION,0.06504065040650407,"challenges when accurately classifying test samples similar to the source distribution.
72"
CONTINUAL TEST-TIME ADAPTATION,0.06585365853658537,"To solve the two challenges, the majority of the existing methods focus on improving the confidence of
73"
CONTINUAL TEST-TIME ADAPTATION,0.06666666666666667,"the source model during the testing phase. These methods employ the mean-teacher architecture [47]
74"
CONTINUAL TEST-TIME ADAPTATION,0.06747967479674796,"to mitigate error accumulation, where the student learns to align with the teacher and the teacher
75"
CONTINUAL TEST-TIME ADAPTATION,0.06829268292682927,"updates via moving average with the student. As to the challenge of forgetting source knowledge,
76"
CONTINUAL TEST-TIME ADAPTATION,0.06910569105691057,"some methods adopt augmentation-averaged predictions [51, 2, 11, 55] for the teacher model,
77"
CONTINUAL TEST-TIME ADAPTATION,0.06991869918699187,"strengthening the teacher’s confidence to reduce the influence from highly out-of-distribution samples.
78"
CONTINUAL TEST-TIME ADAPTATION,0.07073170731707316,"Some methods, such as [11, 6], propose to adopt the contrastive loss to maintain the already learnt
79"
CONTINUAL TEST-TIME ADAPTATION,0.07154471544715447,"semantic information. Some methods believe that the source model is more reliable, thus they are
80"
CONTINUAL TEST-TIME ADAPTATION,0.07235772357723577,"designed to restore the source parameters [51, 2]. Though the above methods keep the model from
81"
CONTINUAL TEST-TIME ADAPTATION,0.07317073170731707,"confusion of vague pseudo labels, they may suffer from overly confident predictions that are less
82"
CONTINUAL TEST-TIME ADAPTATION,0.07398373983739838,"calibrated. To mitigate this issue, it is helpful to estimate the uncertainty in the neural network.
83"
BAYESIAN NEURAL NETWORK,0.07479674796747968,"2.2
Bayesian Neural Network
84"
BAYESIAN NEURAL NETWORK,0.07560975609756097,"Bayesian framework is natural to incorporate past knowledge and sequentially update the belief with
85"
BAYESIAN NEURAL NETWORK,0.07642276422764227,"new data [59]. The bulk of work on Bayesian deep learning has focused on scalable approximate
86"
BAYESIAN NEURAL NETWORK,0.07723577235772358,"inference methods. These methods include stochastic VI [22, 34], dropout [16, 27] and Laplace
87"
BAYESIAN NEURAL NETWORK,0.07804878048780488,"approximation [41, 15] etc., and leveraging the stochastic gradient descent (SGD) trajectory, either
88"
BAYESIAN NEURAL NETWORK,0.07886178861788617,"for a deterministic approximation or sampling. In a BNN, we specify a prior p(θ) over the neural
89"
BAYESIAN NEURAL NETWORK,0.07967479674796749,"network parameters, and compute the posterior distribution over parameters conditioned on training
90"
BAYESIAN NEURAL NETWORK,0.08048780487804878,"data, p(θ|D) ∝p(θ)p(D|θ). This procedure should give considerable advantages for reasoning
91"
BAYESIAN NEURAL NETWORK,0.08130081300813008,"about predictive uncertainty, which is especially relevant in the small-data setting.
92"
BAYESIAN NEURAL NETWORK,0.08211382113821138,"Crucially, when performing Bayesian inference, we need to choose a prior distribution that accurately
93"
BAYESIAN NEURAL NETWORK,0.08292682926829269,"reflects the prior beliefs about the model parameters before seeing any data [18, 14]. In conventional
94"
BAYESIAN NEURAL NETWORK,0.08373983739837398,"static machine learning, the most common choice for the prior distribution over the BNN weights
95"
BAYESIAN NEURAL NETWORK,0.08455284552845528,"is the simplest one: the isotropic Gaussian distribution. However, this choice has been proved
96"
BAYESIAN NEURAL NETWORK,0.08536585365853659,"indeed suboptimal for BNNs [14]. Recently, some studies estimate uncertainty in continual learning
97"
BAYESIAN NEURAL NETWORK,0.08617886178861789,"within a BNN framework, such as [38, 12, 13, 28]. They set the current prior to the previous
98"
BAYESIAN NEURAL NETWORK,0.08699186991869919,"posterior to mitigate catastrophic forgetting. However, the prior transmission is not reliable in the
99"
BAYESIAN NEURAL NETWORK,0.08780487804878048,"unsupervised CTTA task. Any prior mistakes will be enlarged by adaptation progress, manifesting
100"
BAYESIAN NEURAL NETWORK,0.0886178861788618,"error accumulation. To solve the unreliable prior problem, this paper proposes a prior mixture method
101"
BAYESIAN NEURAL NETWORK,0.08943089430894309,"based on VI.
102"
VARIATIONAL INFERENCE IN CTTA,0.09024390243902439,"3
Variational Inference in CTTA
103"
VARIATIONAL INFERENCE IN CTTA,0.0910569105691057,"We start from the supervised BI in typical continual learning, where the model aims to learn multiple
104"
VARIATIONAL INFERENCE IN CTTA,0.091869918699187,"classification tasks in sequence. Let D = {(xn, yn)}N
n=1 be the training set, where xn and yn
105"
VARIATIONAL INFERENCE IN CTTA,0.09268292682926829,"denotes the training sample and the corresponding class label. The task t is to learn a direct posterior
106"
VARIATIONAL INFERENCE IN CTTA,0.09349593495934959,"approximation over the model parameter θ as follows.
107"
VARIATIONAL INFERENCE IN CTTA,0.0943089430894309,"p(θ|D1:t) ∝pt(θ)p(Dt|θ),
(1)"
VARIATIONAL INFERENCE IN CTTA,0.0951219512195122,"where p(θ|D1:t) denotes the posterior of sequential tasks on the learned parameter and p(Dt|θ) is
108"
VARIATIONAL INFERENCE IN CTTA,0.0959349593495935,"the likelihood of the current task. The current prior pt(θ) is regarded as the given knowledge. [38]
109"
VARIATIONAL INFERENCE IN CTTA,0.09674796747967479,"proposes that this current prior can be the posterior learned in the last task, i.e., pt(θ) = p(θ|D1:t−1),
110"
VARIATIONAL INFERENCE IN CTTA,0.0975609756097561,"where the inference becomes
111"
VARIATIONAL INFERENCE IN CTTA,0.0983739837398374,"p(θ|D1:t) ∝p(θ|D1:t−1)p(Dt|θ).
(2)"
VARIATIONAL INFERENCE IN CTTA,0.0991869918699187,"The detailed process can be shown in Appendix A.
112"
VARIATIONAL INFERENCE IN CTTA,0.1,"In contrast to continual learning, CTTA faces a sequence of learning tasks in test time without any
113"
VARIATIONAL INFERENCE IN CTTA,0.1008130081300813,"label information, requiring the model to adapt to each novel domain sequentially. In this case,
114"
VARIATIONAL INFERENCE IN CTTA,0.1016260162601626,"we assume that each domain is i.i.d. and the classes are separable following many unsupervised
115"
VARIATIONAL INFERENCE IN CTTA,0.1024390243902439,"studies [36, 48, 5], more details about the assumption can be seen in Appendix B.1. We use
116"
VARIATIONAL INFERENCE IN CTTA,0.10325203252032521,"U = {xn}N
n=1 to represent the unlabeled test dataset. The CTTA model is first trained on a source
117"
VARIATIONAL INFERENCE IN CTTA,0.1040650406504065,"dataset D0, and then adapted to unlabeled test domains starting from U1. For the t-th adaptation, we
118"
VARIATIONAL INFERENCE IN CTTA,0.1048780487804878,"have
119"
VARIATIONAL INFERENCE IN CTTA,0.10569105691056911,"p(θ|U1:t ∪D0) ∝pt(θ)p(Ut|θ).
(3)
Similarly, we can set the last posterior to be the current prior, i.e., pt(θ) = p(θ|U1:t−1 ∪D0) and
120"
VARIATIONAL INFERENCE IN CTTA,0.10650406504065041,"p1(θ) = p(θ|D0). However, employing BI for adaptation on unlabeled testing data can result
121"
VARIATIONAL INFERENCE IN CTTA,0.1073170731707317,"in untrustworthy posterior estimates. Therefore, during subsequent adaptation, the untrustworthy
122"
VARIATIONAL INFERENCE IN CTTA,0.108130081300813,"posterior automatically transform into unreliable priors, leading to error accumulation. In other words,
123"
VARIATIONAL INFERENCE IN CTTA,0.10894308943089431,Source Prior 
VARIATIONAL INFERENCE IN CTTA,0.10975609756097561,"EMA 
Student Posterior "
VARIATIONAL INFERENCE IN CTTA,0.11056910569105691,"Next
Teacher Prior "
VARIATIONAL INFERENCE IN CTTA,0.11138211382113822,Test Data Mix
VARIATIONAL INFERENCE IN CTTA,0.11219512195121951,Teacher Prior 
VARIATIONAL INFERENCE IN CTTA,0.11300813008130081,"Figure 2: VCoTTA is built on mean-teacher structure, and conducts VI in CTTA using a mixture of
teacher prior and source prior. The next teacher prior is updated by the exponential moving average."
VARIATIONAL INFERENCE IN CTTA,0.11382113821138211,"an unreliable prior pt(θ) will make the current posterior even less trustworthy. Moreover, the joint
124"
VARIATIONAL INFERENCE IN CTTA,0.11463414634146342,"likelihood p(Ut|θ) for t > 0 is intractable on unlabeled data.
125"
VARIATIONAL INFERENCE IN CTTA,0.11544715447154472,"To make the BI feasible in CTTA task, in this paper, we transform the question to an easy-to-compute
126"
VARIATIONAL INFERENCE IN CTTA,0.11626016260162601,"form. Referring to [20], the unsupervised inference can be transformed into
127"
VARIATIONAL INFERENCE IN CTTA,0.11707317073170732,"p(θ|U) ∝p(θ) exp (−λH(U|θ)) ,
(4)"
VARIATIONAL INFERENCE IN CTTA,0.11788617886178862,"where H denotes the conditional entropy and λ is a scalar hyperparameter to weigh the entropy term.
128"
VARIATIONAL INFERENCE IN CTTA,0.11869918699186992,"This simple form reveals that the prior belief about the conditional entropy of labels is given by the
129"
VARIATIONAL INFERENCE IN CTTA,0.11951219512195121,"inputs. The observation of the input U provides information on the drift of the input distribution, which
130"
VARIATIONAL INFERENCE IN CTTA,0.12032520325203253,"can be used to update the belief over the learned parameters θ through Eq. (4). Consequently, this
131"
VARIATIONAL INFERENCE IN CTTA,0.12113821138211382,"allows the utilization of unlabeled data for BI. More detailed derivations can be seen in Appendix B.2.
132"
VARIATIONAL INFERENCE IN CTTA,0.12195121951219512,"In a BNN, the posterior distribution is often intractable and some approximation methods are required,
133"
VARIATIONAL INFERENCE IN CTTA,0.12276422764227642,"even when calculating the initial posterior. In this paper, we leverage online VI, as it typically
134"
VARIATIONAL INFERENCE IN CTTA,0.12357723577235773,"outperforms the other methods for complex models in the static setting [4]. VI defines a variational
135"
VARIATIONAL INFERENCE IN CTTA,0.12439024390243902,"distribution q(θ) to approxmiate the posterior p(θ|U). The approximation process is as follows.
136"
VARIATIONAL INFERENCE IN CTTA,0.12520325203252033,"qt(θ) = arg min
q∈Q KL

q(θ) ∥1"
VARIATIONAL INFERENCE IN CTTA,0.12601626016260162,"Zt
pt(θ)e−λH(Ut|θ)

,
(5)"
VARIATIONAL INFERENCE IN CTTA,0.12682926829268293,"where Q is the distribution searching space and Zt is the intractable normalizing hyperparameter.
137"
VARIATIONAL INFERENCE IN CTTA,0.12764227642276424,"Thus, referring to the derivations in Appendix C, the ELBO is computed by
138"
VARIATIONAL INFERENCE IN CTTA,0.12845528455284552,"ELBO = −λEθ∼q(θ)H(Ut|θ) −KL (q(θ)||pt(θ)) .
(6)"
VARIATIONAL INFERENCE IN CTTA,0.12926829268292683,"Optimizing with Eq. (6) makes model adapt to domain shift. While VI offers a good framework
139"
VARIATIONAL INFERENCE IN CTTA,0.13008130081300814,"for measuring uncertainty in CTTA, it is noteworthy that VI does not directly address the issue of
140"
VARIATIONAL INFERENCE IN CTTA,0.13089430894308943,"unreliable priors. The error accumulation remains a significant concern.
141"
VARIATIONAL INFERENCE IN CTTA,0.13170731707317074,"Despite this, the form of the ELBO in variational inference offers a pathway for mitigating the impact
142"
VARIATIONAL INFERENCE IN CTTA,0.13252032520325202,"of unreliable priors. In Eq. (6), the entropy term may result in overly confident predictions that are
143"
VARIATIONAL INFERENCE IN CTTA,0.13333333333333333,"less calibrated, while the KL term may be directly affected by an unreliable prior. In the following
144"
VARIATIONAL INFERENCE IN CTTA,0.13414634146341464,"section, we will discuss how to solve the problems when computing the two terms.
145"
ADAPTATION AND INFERENCE IN VCOTTA,0.13495934959349593,"4
Adaptation and Inference in VCoTTA
146"
ADAPTATION AND INFERENCE IN VCOTTA,0.13577235772357724,"4.1
Entropy term: VI by Mean-Teacher Architecture
147"
ADAPTATION AND INFERENCE IN VCOTTA,0.13658536585365855,"In the above section, we introduce the VI in CTTA but challenges remain, i.e., the unreliable prior.
148"
ADAPTATION AND INFERENCE IN VCOTTA,0.13739837398373983,"To mitigate the challenge in the entropy term, we adopt a Mean-Teacher (MT) structure [47] in the
149"
ADAPTATION AND INFERENCE IN VCOTTA,0.13821138211382114,"Bayesian inference process. MT is initially proposed in semi-supervised and unsupervised learning,
150"
ADAPTATION AND INFERENCE IN VCOTTA,0.13902439024390245,"where the teacher model guides the unlabeled data, helping the model generalize and improve
151"
ADAPTATION AND INFERENCE IN VCOTTA,0.13983739837398373,"performance with the utilization of large-scale unlabeled data.
152"
ADAPTATION AND INFERENCE IN VCOTTA,0.14065040650406505,"MT structure is composed of a student model and a teacher model, where the student model learns
153"
ADAPTATION AND INFERENCE IN VCOTTA,0.14146341463414633,"from the teacher and the teacher updates using Exponential Moving Average (EMA) [24]. In VI, the
154"
ADAPTATION AND INFERENCE IN VCOTTA,0.14227642276422764,"student is set to be the variational distribution q(θ), which is a Gaussian mean-field approximation
155"
ADAPTATION AND INFERENCE IN VCOTTA,0.14308943089430895,"for its simplicity. It is achieved by stacking the biases and weights of the network as follows.
156"
ADAPTATION AND INFERENCE IN VCOTTA,0.14390243902439023,"q(θ) =
Y"
ADAPTATION AND INFERENCE IN VCOTTA,0.14471544715447154,"d N
 
θd; µd, diag(σ2
d)

,
(7)"
ADAPTATION AND INFERENCE IN VCOTTA,0.14552845528455285,"where d denotes each dimension of the parameter. The teacher model ¯p(θ) (we use bar to distinguish
157"
ADAPTATION AND INFERENCE IN VCOTTA,0.14634146341463414,"the general prior) is also a Gaussian distribution. Thus, the student model is updated by aligning it
158"
ADAPTATION AND INFERENCE IN VCOTTA,0.14715447154471545,"with the teacher model through the use of a cross-entropy (CE) loss
159"
ADAPTATION AND INFERENCE IN VCOTTA,0.14796747967479676,"LCE(q, ¯p) = −Eθ∼q(θ)Ex∼U [¯p(x|θ) log q(x|θ)] .
(8)"
ADAPTATION AND INFERENCE IN VCOTTA,0.14878048780487804,"In our implementation, we also try to use Symmetric Cross-Entropy (SCE) [53] in CTTA,
160"
ADAPTATION AND INFERENCE IN VCOTTA,0.14959349593495935,"LSCE(q, ¯p) = −Eθ∼q(θ)Ex∼U

¯p(x|θ) log q(x|θ) + q(x|θ) log ¯p(x|θ)

.
(9)"
ADAPTATION AND INFERENCE IN VCOTTA,0.15040650406504066,"SCE balances the gradient for high and low confidence, benefiting the unsupervised learning.
161"
ADAPTATION AND INFERENCE IN VCOTTA,0.15121951219512195,"4.2
KL term: Mixture-of-Gaussian Prior
162"
ADAPTATION AND INFERENCE IN VCOTTA,0.15203252032520326,"For the KL term, to reduce the impact of unreliable prior, we propose a mixing-up approach to
163"
ADAPTATION AND INFERENCE IN VCOTTA,0.15284552845528454,"combining the teacher and source prior adaptatively. The source prior is warmed up upon the
164"
ADAPTATION AND INFERENCE IN VCOTTA,0.15365853658536585,"pretrained deterministic model p1(θ) = p(θ|D0) (see Sec. 4.3.1). The teacher model ¯pt(θ) is
165"
ADAPTATION AND INFERENCE IN VCOTTA,0.15447154471544716,"updated by EMA (see Sec. 4.3.3). We assume that the prior should be the mixture of the two Gaussian
166"
ADAPTATION AND INFERENCE IN VCOTTA,0.15528455284552845,"priors. Using only the source prior, the adaptation is limited. While using only the teacher prior, the
167"
ADAPTATION AND INFERENCE IN VCOTTA,0.15609756097560976,"prior is prone to be unreliable.
168"
ADAPTATION AND INFERENCE IN VCOTTA,0.15691056910569107,"We use the mean entropy derived from a given serious data augmentation to represent the confidence
169"
ADAPTATION AND INFERENCE IN VCOTTA,0.15772357723577235,"of the two prior models, and mix up the two priors with a modulating factor
170 α = 1 |I| X"
ADAPTATION AND INFERENCE IN VCOTTA,0.15853658536585366,"i∈I
eH(x|θ0)/τ"
ADAPTATION AND INFERENCE IN VCOTTA,0.15934959349593497,"eH(x|θ0)/τ + eH(x|¯θ)/τ ,
(10)"
ADAPTATION AND INFERENCE IN VCOTTA,0.16016260162601625,"where I denotes augmentation types. θ0 and ¯θ are the parameters of the source model and the teacher
171"
ADAPTATION AND INFERENCE IN VCOTTA,0.16097560975609757,"model. τ means the temperature factor. Thus, as shown in Fig. 3(b), the current prior pt(θ) is set to
172"
ADAPTATION AND INFERENCE IN VCOTTA,0.16178861788617885,"the mixture of priors as
173"
ADAPTATION AND INFERENCE IN VCOTTA,0.16260162601626016,"pt(θ) = α · p1(θ) + (1 −α) · ¯pt(θ).
(11)
In the VI, we use the upper bound to update the KL term [31] (see Appendix D.1) for simplicity,
174"
ADAPTATION AND INFERENCE IN VCOTTA,0.16341463414634147,"KL (q||pt) ≤α · KL (q||p0) + (1 −α) · KL (q||¯pt) .
(12)"
ADAPTATION AND INFERENCE IN VCOTTA,0.16422764227642275,"Furthermore, we also improve the teacher-student alignment in the entropy term (see Eq. (9)) by
175"
ADAPTATION AND INFERENCE IN VCOTTA,0.16504065040650406,"picking up the augmented logits with a larger confidence than the raw data. That is, we replace the
176"
ADAPTATION AND INFERENCE IN VCOTTA,0.16585365853658537,"teacher log-likelihood log ¯p(x|θ) by
177"
ADAPTATION AND INFERENCE IN VCOTTA,0.16666666666666666,"log ¯p′(x|θ) =
P"
ADAPTATION AND INFERENCE IN VCOTTA,0.16747967479674797,"i∈I 1 (f(¯p(x′
i)) > f(¯p(x)) + ϵ) · log ¯p(x′
i)
P"
ADAPTATION AND INFERENCE IN VCOTTA,0.16829268292682928,"i∈I 1 (f(¯p(x′
i)) > f(¯p(x)) + ϵ)
,
(13)"
ADAPTATION AND INFERENCE IN VCOTTA,0.16910569105691056,"where, for brevity, we let ¯p(x′
i) = ¯p(x′
i|θ) and ¯p(x) = ¯p(x)|θ) in short. f(·) is the confidence
178"
ADAPTATION AND INFERENCE IN VCOTTA,0.16991869918699187,"function. ϵ denotes the confidence margin and 1(·) is an indicator function. Eq. (13) can be regarded
179"
ADAPTATION AND INFERENCE IN VCOTTA,0.17073170731707318,"as a filter, meaning that for each sample, the reliable teacher is represented by the average of its
180"
ADAPTATION AND INFERENCE IN VCOTTA,0.17154471544715447,"augmentations with ϵ more confidence. In Appendix D.2, we prove that the proposed mixture-of-
181"
ADAPTATION AND INFERENCE IN VCOTTA,0.17235772357723578,"Gaussian is benifical to CTTA. In Appendix E.1, we discuss the influence of different ϵ.
182"
ADAPTATION AND INFERENCE,0.17317073170731706,"4.3
Adaptation and Inference
183"
VARIATIONAL WARM-UP,0.17398373983739837,"4.3.1
Variational Warm-up
184"
VARIATIONAL WARM-UP,0.17479674796747968,"To obtain a source BNN, instead of training a model from scratch on the source data D0, we transform
185"
VARIATIONAL WARM-UP,0.17560975609756097,"a pretrained deterministic CNN to a BNN by variational warm-up strategy. Specifically, we leverage
186"
VARIATIONAL WARM-UP,0.17642276422764228,"the local reparameterization trick [27] to add stochastic parameters, and warm up the model:
187"
VARIATIONAL WARM-UP,0.1772357723577236,"q0(θ) = arg min
q∈Q KL

q(θ) ∥1"
VARIATIONAL WARM-UP,0.17804878048780487,"Z0
p(θ)p(D0|θ)

,
(14)"
VARIATIONAL WARM-UP,0.17886178861788618,"where p(θ) represents the prior distribution, say the pretrained deterministic model. Eq. (14) denotes
188"
VARIATIONAL WARM-UP,0.1796747967479675,"a standard VI on the source data, and we optimize the ELBO to obtain the variational distribution [49].
189"
VARIATIONAL WARM-UP,0.18048780487804877,"By the variational warm-up, we can easily transform an off-the-shelf pretrained model into a BNN
190"
VARIATIONAL WARM-UP,0.18130081300813009,"with a stochastic dynamic. The variational warm-up strategy is outlined in Algorithm 1.
191"
VARIATIONAL WARM-UP,0.1821138211382114,Algorithm 1 Variational warm-up
VARIATIONAL WARM-UP,0.18292682926829268,"1: Input: Source data D0, pretrained model p0(θ)
2: Initialize prior distribution p(θ) with p0(θ)
3: Update p(θ|D0) ≈q0(θ) by p(θ) and D0 using Eq. (14)
4: Output: Source prior p1(θ) = p(θ|D0)"
VARIATIONAL WARM-UP,0.183739837398374,"The warm-up strategy is a common
192"
VARIATIONAL WARM-UP,0.18455284552845527,"approach in TTA and CTTA tasks to
193"
VARIATIONAL WARM-UP,0.18536585365853658,"further build knowledge structure for
194"
VARIATIONAL WARM-UP,0.1861788617886179,"the source model, such as [26, 45, 11,
195"
VARIATIONAL WARM-UP,0.18699186991869918,"8]. Some other methods may not use
196"
VARIATIONAL WARM-UP,0.1878048780487805,"warm-up but still use the source data,
197"
VARIATIONAL WARM-UP,0.1886178861788618,"such as [39]. The warm-up strategy
198"
VARIATIONAL WARM-UP,0.18943089430894308,"uses the source data only before deploying the model to CTTA scenario, and it is regarded as a part
199"
VARIATIONAL WARM-UP,0.1902439024390244,"of pretraining. All of these methods using source data are operationalized in source-free at test time
200"
VARIATIONAL WARM-UP,0.1910569105691057,"and find it is beneficial to CTTA. We use the warm-up to inject the uncertainties into a given source
201"
VARIATIONAL WARM-UP,0.191869918699187,"model, i.e., turning an off-the-shelf pretrained CNN model into a pretrained BNN model. This is
202"
VARIATIONAL WARM-UP,0.1926829268292683,"convenient to obtain a pretrained BNN, because the warm-up strategy uses only a few epochs. We
203"
VARIATIONAL WARM-UP,0.19349593495934958,"offer more discussions and experiments on the proposed variational warm-up strategy in Appendix F.
204"
STUDENT UPDATE VIA VI,0.1943089430894309,"4.3.2
Student update via VI
205"
STUDENT UPDATE VIA VI,0.1951219512195122,"The student model qt(θ) is adapted by approximating using Eq. (5), and is optimized on:
206"
STUDENT UPDATE VIA VI,0.19593495934959348,"L(qt) = LSCE(qt, ¯p′
t) + α · KL (qt||q0) + (1 −α) · KL (qt||¯qt) ,
(15)"
STUDENT UPDATE VIA VI,0.1967479674796748,"where ¯p′
t is the current augmented teacher model in Eq. (13), and p1(θ) ≈q0(θ), ¯pt(θ) ≈¯qt(θ).
207"
STUDENT UPDATE VIA VI,0.1975609756097561,"The KL term between two Gaussians can be computed in a closed form.
208"
TEACHER UPDATE VIA EMA,0.1983739837398374,"4.3.3
Teacher update via EMA
209"
TEACHER UPDATE VIA EMA,0.1991869918699187,"The teacher model is updated using EMA. Let (µ, σ) and (¯µ, ¯σ) be the mean and standard deviation
210"
TEACHER UPDATE VIA EMA,0.2,"of the student and teacher model, respectively. At test time, the teacher model ¯qt(θ) is updated by
211"
TEACHER UPDATE VIA EMA,0.2008130081300813,"¯µ ←β ¯µ + (1 −β)µ,
¯σ ←β ¯σ + (1 −β)σ.
(16)"
TEACHER UPDATE VIA EMA,0.2016260162601626,"Although the std is not used in the cross entropy to compute the likelihood, the teacher prior
212"
TEACHER UPDATE VIA EMA,0.20243902439024392,"distribution is important to adjust the student distribution via the KL term.
213"
MODEL INFERENCE,0.2032520325203252,"4.3.4
Model inference
214"
MODEL INFERENCE,0.2040650406504065,"At any time, CTTA model needs to predict and adapt to the unlabeled test data. In our VCoTTA, we
215"
MODEL INFERENCE,0.2048780487804878,"also use the mixed prior to serve as the inference model. That is, for a test data point x, the model
216"
MODEL INFERENCE,0.2056910569105691,"inference is represented by
217"
MODEL INFERENCE,0.20650406504065041,"pt(x) =
Z
p(x|θ)pt(θ)dθ =
Z
αp(x|θ)p1(θ) + (1 −α)p(x|θ)¯pt(θ)dθ,
(17)"
MODEL INFERENCE,0.2073170731707317,"For the data prediction, the model only uses the expectation to reduce the stochastic, but leverages
218"
MODEL INFERENCE,0.208130081300813,"stochastic dynamics in domain adaptation.
219"
THE ALGORITHM,0.20894308943089432,"4.3.5
The algorithm
220"
THE ALGORITHM,0.2097560975609756,Algorithm 2 Variational CTTA
THE ALGORITHM,0.2105691056910569,"1: Input: Source data D0, pretrained model p0(θ), Un-
labeled test data from different domain U1:T
2: p1(θ) = Variational warm-up(D0, p0(θ)). // Alg. 1
3: for Domain shift t = 1 to T do
4:
for Test data x ∼Ut do
5:
Model predict for x (Eq. (17))
6:
Update student model using x (Eq. (15))
7:
Update teacher model via EMA (Eq. (16))
8:
end for
9: end for"
THE ALGORITHM,0.21138211382113822,"We illustrate the whole algorithm in Al-
221"
THE ALGORITHM,0.2121951219512195,"gorithm 2. We first transform an off-the-
222"
THE ALGORITHM,0.21300813008130082,"shelf pretrained model into BNN via the
223"
THE ALGORITHM,0.2138211382113821,"variational warm-up strategy (Sec. 4.3.1).
224"
THE ALGORITHM,0.2146341463414634,"After that, we obtain a BNN, and for each
225"
THE ALGORITHM,0.21544715447154472,"domain shift, we forward and adapt each
226"
THE ALGORITHM,0.216260162601626,"test data point in an MT architecture. For
227"
THE ALGORITHM,0.21707317073170732,"a data point x, we first predict the class la-
228"
THE ALGORITHM,0.21788617886178863,"bel using the mixture of the source model
229"
THE ALGORITHM,0.2186991869918699,"and the teacher model (Sec. 4.3.4). Then,
230"
THE ALGORITHM,0.21951219512195122,"we update the student model using VI,
231"
THE ALGORITHM,0.22032520325203253,"where we use cross entropy to compute
232"
THE ALGORITHM,0.22113821138211381,"the entropy term and use the mixture of
233"
THE ALGORITHM,0.22195121951219512,"priors for the KL term (Sec. 4.3.2). Finally, we update the BNN teacher model via EMA (Sec. 4.3.3).
234"
THE ALGORITHM,0.22276422764227644,"See more details in Appendix G. The process is feasible for any test data without labels.
235"
THE ALGORITHM,0.22357723577235772,"Table 1: Classification error rate (%) for the standard CIFAR10-to-CIFAR10C CTTA task. All results
are evaluated with the largest corruption severity level 5 in an online fashion. C1 to C15 are 15
corruptions for the datasets (see Sec. 5.1). CIFAR100C and ImagenetC use the same setup."
THE ALGORITHM,0.22439024390243903,"Method
C1
C2
C3
C4
C5
C6
C7
C8
C9
C10
C11
C12
C13
C14
C15
Avg"
THE ALGORITHM,0.2252032520325203,"Source
72.3
65.7
72.9
46.9
54.3
34.8
42.0
25.1
41.3
26.0
9.3
46.7
26.6
58.5
30.3
43.5
BN
28.1
26.1
36.3
12.8
35.3
14.2
12.1
17.3
17.4
15.3
8.4
12.6
23.8
19.7
27.3
20.4
Tent [50]
24.8
20.6
28.5
15.1
31.7
17.0
15.6
18.3
18.3
18.1
11.0
16.8
23.9
18.6
23.9
20.1
CoTTA [51]
24.5
21.5
25.9
12.0
27.7
12.2
10.7
15.0
14.1
12.7
7.6
11.0
18.5
13.6
17.7
16.3
RoTTA [56]
30.3
25.4
34.6
18.3
34.0
14.7
11.0
16.4
14.6
14.0
8.0
12.4
20.3
16.8
19.4
19.3
PETAL [2]
23.7
21.4
26.3
11.8
28.8
12.4
10.4
14.8
13.9
12.6
7.4
10.6
18.3
13.1
17.1
16.2
SATA [6]
23.9
20.1
28.0
11.6
27.4
12.6
10.2
14.1
13.2
12.2
7.4
10.3
19.1
13.3
18.5
16.1
DSS [52]
24.1
21.3
25.4
11.7
26.9
12.2
10.5
14.5
14.1
12.5
7.8
10.8
18.0
13.1
17.3
16.0
SWA [55]
23.9
20.5
24.5
11.2
26.3
11.8
10.1
14.0
12.7
11.5
7.6
9.5
17.6
12.0
15.8
15.3"
THE ALGORITHM,0.22601626016260162,"VCoTTA (Ours)
18.1
14.9
22.0
9.7
22.6
11.0
9.5
11.4
10.6
10.5
6.5
9.4
15.6
11.0
14.5
13.1"
THE ALGORITHM,0.22682926829268293,Table 2: Classification error rate (%) for the standard CIFAR100-to-CIFAR100C CTTA task.
THE ALGORITHM,0.22764227642276422,"Method
C1
C2
C3
C4
C5
C6
C7
C8
C9
C10
C11
C12
C13
C14
C15
Avg"
THE ALGORITHM,0.22845528455284553,"Source
73.0
68.0
39.4
29.3
54.1
30.8
28.8
39.5
45.8
50.3
29.5
55.1
37.2
74.7
41.2
46.4
BN
42.1
40.7
42.7
27.6
41.9
29.7
27.9
34.9
35
41.5
26.5
30.3
35.7
32.9
41.2
35.4
Tent [50]
37.2
35.8
41.7
37.9
51.2
48.3
48.5
58.4
63.7
71.1
70.4
82.3
88.0
88.5
90.4
60.9
CoTTA [51]
40.1
37.7
39.7
26.9
38.0
27.9
26.4
32.8
31.8
40.3
24.7
26.9
32.5
28.3
33.5
32.5
RoTTA [56]
49.1
44.9
45.5
30.2
42.7
29.5
26.1
32.2
30.7
37.5
24.7
26.9
32.5
28.3
33.5
32.5
PETAL [2]
38.3
36.4
38.6
25.9
36.8
27.3
25.4
32.0
30.8
38.7
24.4
26.4
31.5
26.9
32.5
31.5
SATA [6]
36.5
33.1
35.1
25.9
34.9
27.7
25.4
29.5
29.9
33.1
23.6
26.7
31.9
27.5
35.2
30.3
DSS [52]
39.7
36.0
37.2
26.3
35.6
27.5
25.1
31.4
30.0
37.8
24.2
26.0
30.0
26.3
31.1
30.9
SWA [55]
39.4
36.4
37.4
25.0
36.0
26.6
25.0
29.1
28.4
35.0
23.5
25.1
28.5
25.8
29.6
30.0"
THE ALGORITHM,0.22926829268292684,"VCoTTA (Ours)
35.3
32.8
38.9
23.8
34.6
25.5
23.2
27.5
26.7
30.4
22.1
23.0
28.1
24.2
30.4
28.4"
EXPERIMENT,0.23008130081300812,"5
Experiment
236"
EXPERIMENTAL SETTING,0.23089430894308943,"5.1
Experimental Setting
237"
EXPERIMENTAL SETTING,0.23170731707317074,"Dataset. In our experiments, we employ the CIFAR10C, CIFAR100C, and ImageNetC datasets as
238"
EXPERIMENTAL SETTING,0.23252032520325203,"benchmarks to assess the robustness of classification models. Each dataset comprises 15 distinct
239"
EXPERIMENTAL SETTING,0.23333333333333334,"types of corruption, each applied at five different levels of severity (from 1 to 5). These corruptions
240"
EXPERIMENTAL SETTING,0.23414634146341465,"are systematically applied to test images from the original CIFAR10 and CIFAR100 datasets, as well
241"
EXPERIMENTAL SETTING,0.23495934959349593,"as validation images from the original ImageNet dataset. For simplicity in tables, we use C1 to C15
242"
EXPERIMENTAL SETTING,0.23577235772357724,"to represent the 15 types of corruption, i.e., C1: Gaussian, C2: Shot, C3: Impulse C4: Defocus, C5:
243"
EXPERIMENTAL SETTING,0.23658536585365852,"Glass, C6: Motion, C7: Zoom, C8: Snow, C9: Frost, C10: Fog, C11: Brightness, C12: Contrast, C13:
244"
EXPERIMENTAL SETTING,0.23739837398373984,"Elastic, C14: Pixelate, C15: Jpeg.
245"
EXPERIMENTAL SETTING,0.23821138211382115,"Pretrained Model. Following previous studies [50, 51], we adopt pretrained WideResNet-28 [57]
246"
EXPERIMENTAL SETTING,0.23902439024390243,"model for CIFAR10to-CIFAR10C, pretrained ResNeXt-29 [54] for CIFAR100-to-CIFAR100C, and
247"
EXPERIMENTAL SETTING,0.23983739837398374,"standard pretrained ResNet-50 [21] for ImageNet-to-ImagenetC. Note in our VCoTTA [51], we
248"
EXPERIMENTAL SETTING,0.24065040650406505,"further warm up the pretrained model to obtain the stochastic dynamics for each dataset. Similar to
249"
EXPERIMENTAL SETTING,0.24146341463414633,"CoTTA, we update all the trainable parameters in all experiments. The augmentation number is set to
250"
EXPERIMENTAL SETTING,0.24227642276422764,"32 for all compared methods that use the augmentation strategy.
251"
METHODS TO BE COMPARED,0.24308943089430896,"5.2
Methods to be Compared
252"
METHODS TO BE COMPARED,0.24390243902439024,"We compare our VCoTTA with multiple state-of-the-art (SOTA) methods. SOURCE denotes the
253"
METHODS TO BE COMPARED,0.24471544715447155,"baseline pretrained model without any adaptation. BN [30, 43] keeps the network parameters frozen,
254"
METHODS TO BE COMPARED,0.24552845528455283,"but only updates Batch Normalization. TENT [50] updates via Shannon entropy for unlabeled
255"
METHODS TO BE COMPARED,0.24634146341463414,"test data. CoTTA [51] builds the MT structure and uses randomly restoring parameters to the
256"
METHODS TO BE COMPARED,0.24715447154471545,"source model. SATA [6] modifies the batch-norm affine parameters using source anchoring-based
257"
METHODS TO BE COMPARED,0.24796747967479674,"self-distillation to ensure the model incorporates knowledge of newly encountered domains while
258"
METHODS TO BE COMPARED,0.24878048780487805,"avoiding catastrophic forgetting. SWA [55] refines the pseudo-label learning process from the
259"
METHODS TO BE COMPARED,0.24959349593495936,"perspective of the instantaneous and long-term impact of noisy pseudo-labels. PETAL [2] tries to
260"
METHODS TO BE COMPARED,0.25040650406504067,"estimate the uncertainty in CTTA, which is similar to BNN, but it ignores the unreliable prior problem.
261"
METHODS TO BE COMPARED,0.25121951219512195,"All compared methods adopt the same backbone, pretrained model and hyperparameters.
262"
METHODS TO BE COMPARED,0.25203252032520324,Table 3: Classification error rate (%) for the standard ImageNet-to-ImageNetC CTTA task.
METHODS TO BE COMPARED,0.2528455284552846,"Method
C1
C2
C3
C4
C5
C6
C7
C8
C9
C10
C11
C12
C13
C14
C15
Avg"
METHODS TO BE COMPARED,0.25365853658536586,"Source
95.3
95.0
95.3
86.1
91.9
87.4
77.9
85.1
79.9
79.0
45.4
96.2
86.6
77.5
66.1
83.0
BN
87.7
87.4
87.8
88.0
87.7
78.3
63.9
67.4
70.3
54.7
36.4
88.7
58.0
56.6
67.0
72.0
Tent [50]
85.6
79.9
78.3
82.0
79.5
71.4
59.5
65.8
66.4
55.2
40.4
80.4
55.6
53.5
59.3
67.5
CoTTA [51]
87.4
86.0
84.5
85.9
83.9
74.3
62.6
63.2
63.6
51.9
38.4
72.7
50.4
45.4
50.2
66.7
RoTTA [56]
88.3
82.8
82.1
91.3
83.7
72.9
59.4
66.2
64.3
53.3
35.6
74.5
54.3
48.2
52.6
67.3
PETAL [2]
87.4
85.8
84.4
85.0
83.9
74.4
63.1
63.5
64.0
52.4
40.0
74.0
51.7
45.2
51.0
67.1
DSS [52]
84.6
80.4
78.7
83.9
79.8
74.9
62.9
62.8
62.9
49.7
37.4
71.0
49.5
42.9
48.2
64.6"
METHODS TO BE COMPARED,0.25447154471544714,"VCoTTA (Ours)
81.8
78.9
80.0
83.4
81.4
70.8
60.3
61.1
61.7
46.4
35.7
71.7
50.1
47.1
52.9
64.2"
COMPARISON RESULTS,0.2552845528455285,"5.3
Comparison Results
263"
COMPARISON RESULTS,0.25609756097560976,"We show the major comparisons with the SOTA methods in Tables 1, 2 and 3. We have the following
264"
COMPARISON RESULTS,0.25691056910569104,"observations. First, no adaptation at the test time (SOURCE) suffers from serious domain shift, which
265"
COMPARISON RESULTS,0.2577235772357724,"shows the necessity of the CTTA. Second, traditional TTA methods that ignore the continual shift
266"
COMPARISON RESULTS,0.25853658536585367,"in test time perform poorly such as TENT and BN. We also find that simple Shannon entropy is
267"
COMPARISON RESULTS,0.25934959349593495,"effective in the first several domain shifts, especially in complex 1,000-classes ImageNetC, but shows
268"
COMPARISON RESULTS,0.2601626016260163,"significant performance drops in the following shifts. Third, the mean-teacher structure is very useful
269"
COMPARISON RESULTS,0.26097560975609757,"in CTTA, such as COTTA and PETAL, which means that the pseudo-label is useful in domain shift.
270"
COMPARISON RESULTS,0.26178861788617885,"In the previous method, the error accumulation leads to the unreliable pseudo labels, then the model
271"
COMPARISON RESULTS,0.26260162601626014,"may get more negative transfers in CTTA along the timeline. The proposed VCOTTA outperforms
272"
COMPARISON RESULTS,0.2634146341463415,"other methods on all the three datasets, such as 13.1% vs. 15.3% (SWA) on CIFAR10C, 28.4%
273"
COMPARISON RESULTS,0.26422764227642276,"vs. 30.0% (SWA) on CIFAR100C and 64.2% vs. 66.7% (COTTA) on ImageNetC. We hold the
274"
COMPARISON RESULTS,0.26504065040650404,"opinion that the prior will inevitably drift in CTTA, but VCOTTA slows down the process via the
275"
COMPARISON RESULTS,0.2658536585365854,"prior mixture. We also find that the superiority is more obvious in the early adaptation, which may be
276"
COMPARISON RESULTS,0.26666666666666666,"influenced by the different corruption orders. We analyze the order problem in Appendix H.
277"
ABLATION STUDY,0.26747967479674795,"5.4
Ablation Study
278"
ABLATION STUDY,0.2682926829268293,"We evaluate the two components in Table 4, i.e., the Variational Warm-Up (VWU) and the Symmetric
279"
ABLATION STUDY,0.26910569105691057,"Cross-Entropy (SCE) via ablation. The ablation results show that the two components are both
280"
ABLATION STUDY,0.26991869918699185,"important for VCOTTA. First, the VWU is used to inject stochastic dynamics into an off-the-shelf
281"
ABLATION STUDY,0.2707317073170732,"pretrained model. Without the VWU, the performance of VCOTTA drops to 18.4% from 13.9% on
282"
ABLATION STUDY,0.27154471544715447,"CIFAR10C, 31.5% from 28.8% on CIFAR100C and 68.1% from 64.2% on ImageNetC. Also, the
283"
ABLATION STUDY,0.27235772357723576,"SCE can further improve the performance on CIFAR10C and CIFAR100C, because SCE balances
284"
ABLATION STUDY,0.2731707317073171,"the gradient for high and low confidence predictions. We also find that SCE is ineffective for complex
285"
ABLATION STUDY,0.2739837398373984,"ImageNetC, and the reason may be the class sensitivity imbalance, causing the model to lean more
286"
ABLATION STUDY,0.27479674796747966,"towards one direction during optimization.
287"
ABLATION STUDY,0.275609756097561,Table 4: Ablation study on under severity 5.
ABLATION STUDY,0.2764227642276423,No. VWU SCE CIFAR10C CIFAR100C ImageNetC
ABLATION STUDY,0.27723577235772356,"1
18.4
31.5
68.1
2
√
17.1
31.2
68.3
3
√
13.9
28.8
64.2
4
√
√
13.1
28.4
64.7"
ABLATION STUDY,0.2780487804878049,Table 5: Different weights for mixture of priors.
ABLATION STUDY,0.2788617886178862,"No.
α
1 −α CIFAR10C CIFAR100C ImageNetC"
ABLATION STUDY,0.27967479674796747,"1
1
0
17.4
35.0
69.9
2
0
1
16.3
33.7
71.2
3
0.5
0.5
14.7
31.3
67.0
4
Eq. (10)
13.1
28.4
64.7"
MIXTURE OF PRIORS,0.2804878048780488,"5.5
Mixture of Priors
288"
MIXTURE OF PRIORS,0.2813008130081301,"In Sec. 4.2, we introduce a Gaussian mixture strategy, where the current prior is approximated as the
289"
MIXTURE OF PRIORS,0.2821138211382114,"weighted sum of the source prior and the teacher prior. The weights are determined by computing the
290"
MIXTURE OF PRIORS,0.28292682926829266,"entropy over multiple augmentations of two models. To assess the effectiveness of these weights, we
291"
MIXTURE OF PRIORS,0.283739837398374,"compare them with three naive weighting configurations: using only the source model, using only the
292"
MIXTURE OF PRIORS,0.2845528455284553,"teacher model, and a simple average with equal weights for both models. The results, as presented in
293"
MIXTURE OF PRIORS,0.28536585365853656,"Table 5, reveal that relying solely on the source model or the teacher model (i.e., weighting with (1, 0)
294"
MIXTURE OF PRIORS,0.2861788617886179,"and (0, 1)) results in suboptimal performance. Additionally, naive weighting with equal contributions
295"
MIXTURE OF PRIORS,0.2869918699186992,"from both models (i.e., (0.5, 0.5)) proves ineffective for CTTA due to the inherent uncertainty in both
296"
MIXTURE OF PRIORS,0.28780487804878047,"models. In contrast, the proposed adaptive weights for the Gaussian mixture in CTTA demonstrate its
297"
MIXTURE OF PRIORS,0.2886178861788618,"effectiveness. This underscores the significance of striking a balance between the two prior models in
298"
MIXTURE OF PRIORS,0.2894308943089431,"an unsupervised environment. The trade-off implies the need to discern when the source model’s
299"
MIXTURE OF PRIORS,0.29024390243902437,"knowledge is more applicable and when the teacher model’s shifting knowledge takes precedence.
300"
UNCERTAINTY ESTIMATION,0.2910569105691057,"5.6
Uncertainty Estimation
301"
UNCERTAINTY ESTIMATION,0.291869918699187,"To evaluate the uncertainty estimation, we use negative loglikelihood (NLL) and Brier Score (BS) [3].
302"
UNCERTAINTY ESTIMATION,0.2926829268292683,"Both NLL and BS are proper scoring rules [19], and they are minimized if and only if the predicted
303"
UNCERTAINTY ESTIMATION,0.2934959349593496,"distribution becomes identical to the actual distribution:
304"
UNCERTAINTY ESTIMATION,0.2943089430894309,"NLL = −E(x,y)∈Dtest log(p(y|x, θ)),
BS = E(x,y)∈Dtest (p(y|x, θ) −Onehot(y))2 ,"
UNCERTAINTY ESTIMATION,0.2951219512195122,"where Dtest denotes the test set, i.e., the unsupervised test dataset U with labels. We evaluate NLL and
305"
UNCERTAINTY ESTIMATION,0.2959349593495935,"BS with a severity level of 5 for all corruption types, and the compared results with SOTAs are shown
306"
UNCERTAINTY ESTIMATION,0.2967479674796748,"in Table 6. We have the following observations. First, most methods suffer from low confidence in
307"
UNCERTAINTY ESTIMATION,0.2975609756097561,"terms of NLL and BS because of the drift priors, where the model is unreliable gradually, and the error
308"
UNCERTAINTY ESTIMATION,0.2983739837398374,"accumulation makes the model perform poorly. Our approach outperforms most other approaches in
309"
UNCERTAINTY ESTIMATION,0.2991869918699187,"terms of NLL and BS, demonstrating the superiority in improving uncertainty estimation. We also
310"
UNCERTAINTY ESTIMATION,0.3,"find that PETAL [2] shows good NLL and BS, because PETAL forces the prediction over-confident
311"
UNCERTAINTY ESTIMATION,0.3008130081300813,"to unreliable priors, thus PETAL shows unsatisfactory results on adaptation accuracy, such as 31.5%
312"
UNCERTAINTY ESTIMATION,0.3016260162601626,"vs. 28.4% (Ours) on CIFAR100C.
313"
UNCERTAINTY ESTIMATION,0.3024390243902439,Table 6: Uncertainty estimation via NLL and BS.
UNCERTAINTY ESTIMATION,0.3032520325203252,"Method
CIFAR10C
CIFAR100C
ImageNetC
NLL
BS
NLL
BS
NLL
BS"
UNCERTAINTY ESTIMATION,0.3040650406504065,"Source
3.0566 0.7478 2.4933 0.6707 5.0703 0.9460
BN
0.9988 0.3354 1.3932 0.4740 3.9971 0.8345
Tent
1.9391 0.3713 7.1097 1.0838 3.6902 0.8281
CoTTA
0.7192 0.2761 1.2907 0.4433 3.6235 0.7972
PETAL
0.5899 0.2458 1.2267 0.4327 3.6391 0.8017"
UNCERTAINTY ESTIMATION,0.3048780487804878,VCoTTA 0.5421 0.2130 1.2287 0.4307 3.4469 0.8092
UNCERTAINTY ESTIMATION,0.3056910569105691,Table 7: Gradually changing on severity 5.
UNCERTAINTY ESTIMATION,0.3065040650406504,"Method
CIFAR10C CIFAR100C ImageNetC"
UNCERTAINTY ESTIMATION,0.3073170731707317,"Source
23.9
32.9
81.7
BN
13.5
29.7
54.1
TENT
39.1
72.7
53.7
CoTTA
10.6
26.3
42.1
PETAL
10.5
27.1
60.5"
UNCERTAINTY ESTIMATION,0.308130081300813,"VCoTTA
8.9
24.4
39.9"
GRADUALLY CORRUPTION,0.3089430894308943,"5.7
Gradually Corruption
314"
GRADUALLY CORRUPTION,0.3097560975609756,"We also show gradual corruption results instead of constant severity in the major comparison, and the
315"
GRADUALLY CORRUPTION,0.3105691056910569,"results are reported in Table 7. Specifically, each corruption adopts the gradual changing sequence:
316"
GRADUALLY CORRUPTION,0.31138211382113823,"1 →2 →3 →4 →5 →4 →3 →2 →1, where the severity level is the lowest 1 when corruption
317"
GRADUALLY CORRUPTION,0.3121951219512195,"type changes, therefore, the type change is gradual. The distribution shift within each type is also
318"
GRADUALLY CORRUPTION,0.3130081300813008,"gradual. Under this situation, our VCoTTA also outperforms other methods, such as 8.9% vs. 10.5%
319"
GRADUALLY CORRUPTION,0.31382113821138213,"(PETAL) on CIFAR10C, and 24.4% vs. 26.3% (COTTA) on CIFAR100C. The results show that the
320"
GRADUALLY CORRUPTION,0.3146341463414634,"proposed VCOTTA based on BNN is also effective when the distribution change is uncertain.
321"
CONCLUSION AND LIMITATION,0.3154471544715447,"6
Conclusion and Limitation
322"
CONCLUSION AND LIMITATION,0.31626016260162604,"Conclusion: In this paper, we proposed a variational Bayesian inference approach, termed VCoTTA,
323"
CONCLUSION AND LIMITATION,0.3170731707317073,"to estimate uncertainties in CTTA. At the pretrained stage, we first transformed an off-the-shelf
324"
CONCLUSION AND LIMITATION,0.3178861788617886,"pretrained deterministic CNN into a BNN using a variational warm-up strategy, thereby injecting
325"
CONCLUSION AND LIMITATION,0.31869918699186994,"uncertainty into the source model. At the test time, we implemented a mean-teacher update strategy,
326"
CONCLUSION AND LIMITATION,0.3195121951219512,"where the student model is updated via variational inference, while the teacher model is refined by the
327"
CONCLUSION AND LIMITATION,0.3203252032520325,"exponential moving average. Specifically, to update the student model, we proposed a novel approach
328"
CONCLUSION AND LIMITATION,0.32113821138211385,"that utilizes a mixture of priors from both the source and teacher models. Consequently, the ELBO
329"
CONCLUSION AND LIMITATION,0.32195121951219513,"can be formulated as the cross-entropy between the student and teacher models, combined with the
330"
CONCLUSION AND LIMITATION,0.3227642276422764,"KL divergence of the prior mixture. We demonstrated the effectiveness of the proposed method on
331"
CONCLUSION AND LIMITATION,0.3235772357723577,"three datasets, and the results show that the proposed method can mitigate the issue of unreliable
332"
CONCLUSION AND LIMITATION,0.32439024390243903,"prior within the CTTA framework.
333"
CONCLUSION AND LIMITATION,0.3252032520325203,"Limitation: The efficacy of the proposed method relies on injecting uncertainty into the model during
334"
CONCLUSION AND LIMITATION,0.3260162601626016,"the pre-training phase, which may be unavailable in scenarios where pretraining is already completed,
335"
CONCLUSION AND LIMITATION,0.32682926829268294,"and original data is inaccessible. Additionally, constructing and training BNN models are inherently
336"
CONCLUSION AND LIMITATION,0.3276422764227642,"more complex compared to CNNs, highlighting the importance of enhancing computational efficiency.
337"
CONCLUSION AND LIMITATION,0.3284552845528455,"The Gaussian mixture method relies on multiple data augmentations, which also incurs computational
338"
CONCLUSION AND LIMITATION,0.32926829268292684,"costs. Future endeavors could explore more efficient approaches for Gaussian mixture.
339"
REFERENCES,0.3300813008130081,"References
340"
REFERENCES,0.3308943089430894,"[1] George EP Box and George C Tiao. Bayesian inference in statistical analysis. John Wiley & Sons, 2011.
341"
REFERENCES,0.33170731707317075,"[2] Dhanajit Brahma and Piyush Rai. A probabilistic framework for lifelong test-time adaptation. In Proceed-
342"
REFERENCES,0.33252032520325203,"ings of the Computer Vision and Pattern Recognition, 2023.
343"
REFERENCES,0.3333333333333333,"[3] Glenn W Brier. Verification of forecasts expressed in terms of probability. Journal of the Monthly Weather
344"
REFERENCES,0.33414634146341465,"Review, 78(1):1–3, 1950.
345"
REFERENCES,0.33495934959349594,"[4] Thang Bui, Daniel Hernández-Lobato, Jose Hernandez-Lobato, Yingzhen Li, and Richard Turner. Deep
346"
REFERENCES,0.3357723577235772,"gaussian processes for regression using approximate expectation propagation. In Proceedings of the
347"
REFERENCES,0.33658536585365856,"International Conference on Machine Learning, 2016.
348"
REFERENCES,0.33739837398373984,"[5] Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. Deep clustering for unsupervised
349"
REFERENCES,0.3382113821138211,"learning of visual features. In Proceedings of the European Conference on Computer Vision, pages
350"
REFERENCES,0.33902439024390246,"132–149, 2018.
351"
REFERENCES,0.33983739837398375,"[6] Goirik Chakrabarty, Manogna Sreenivas, and Soma Biswas. Sata: Source anchoring and target alignment
352"
REFERENCES,0.34065040650406503,"network for continual test time adaptation. arXiv preprint arXiv:2304.10113, 2023.
353"
REFERENCES,0.34146341463414637,"[7] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In
354"
REFERENCES,0.34227642276422765,"Proceedings of the Computer Vision and Pattern Recognition, 2022.
355"
REFERENCES,0.34308943089430893,"[8] Ziyang Chen, Yiwen Ye, Mengkang Lu, Yongsheng Pan, and Yong Xia. Each test image deserves a
356"
REFERENCES,0.3439024390243902,"specific prompt: Continual test-time adaptation for 2d medical image segmentation. arXiv preprint
357"
REFERENCES,0.34471544715447155,"arXiv:2311.18363, 2023.
358"
REFERENCES,0.34552845528455284,"[9] Sungha Choi, Seunghan Yang, Seokeon Choi, and Sungrack Yun. Improving test-time adaptation via shift-
359"
REFERENCES,0.3463414634146341,"agnostic weight regularization and nearest source prototypes. In Procedings of the European Conference
360"
REFERENCES,0.34715447154471546,"on Computer Vision, 2022.
361"
REFERENCES,0.34796747967479674,"[10] Thomas M Cover. Elements of information theory. John Wiley & Sons, 1999.
362"
REFERENCES,0.348780487804878,"[11] Mario Döbler, Robert A Marsden, and Bin Yang. Robust mean teacher for continual and gradual test-time
363"
REFERENCES,0.34959349593495936,"adaptation. In Proceedings of the Computer Vision and Pattern Recognition, 2023.
364"
REFERENCES,0.35040650406504065,"[12] Sayna Ebrahimi, Mohamed Elhoseiny, Trevor Darrell, and Marcus Rohrbach. Uncertainty-guided continual
365"
REFERENCES,0.35121951219512193,"learning with bayesian neural networks. In Procedings of the International Conference on Learning
366"
REFERENCES,0.35203252032520327,"Representations, 2019.
367"
REFERENCES,0.35284552845528455,"[13] Sebastian Farquhar and Yarin Gal. A unifying bayesian view of continual learning. arXiv preprint
368"
REFERENCES,0.35365853658536583,"arXiv:1902.06494, 2019.
369"
REFERENCES,0.3544715447154472,"[14] Vincent Fortuin, Adrià Garriga-Alonso, Sebastian W Ober, Florian Wenzel, Gunnar Ratsch, Richard E
370"
REFERENCES,0.35528455284552846,"Turner, Mark van der Wilk, and Laurence Aitchison. Bayesian neural network priors revisited. In
371"
REFERENCES,0.35609756097560974,"Procedings of the International Conference on Learning Representations, 2021.
372"
REFERENCES,0.3569105691056911,"[15] Karl Friston, Jérémie Mattout, Nelson Trujillo-Barreto, John Ashburner, and Will Penny. Variational free
373"
REFERENCES,0.35772357723577236,"energy and the laplace approximation. Journal of the Neuroimage, 34(1):220–234, 2007.
374"
REFERENCES,0.35853658536585364,"[16] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty
375"
REFERENCES,0.359349593495935,"in deep learning. In Procedings of the International Conference on Machine Learning, 2016.
376"
REFERENCES,0.36016260162601627,"[17] Yossi Gandelsman, Yu Sun, Xinlei Chen, and Alexei Efros. Test-time training with masked autoencoders.
377"
REFERENCES,0.36097560975609755,"In Procedings of the Advances in Neural Information Processing Systems, 2022.
378"
REFERENCES,0.3617886178861789,"[18] Andrew Gelman, John B Carlin, Hal S Stern, and Donald B Rubin. Bayesian data analysis. Chapman and
379"
REFERENCES,0.36260162601626017,"Hall/CRC, 1995.
380"
REFERENCES,0.36341463414634145,"[19] Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal
381"
REFERENCES,0.3642276422764228,"of the American Statistical Association, 102(477):359–378, 2007.
382"
REFERENCES,0.3650406504065041,"[20] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Proceedings
383"
REFERENCES,0.36585365853658536,"of the Advances in Neural Information Processing Systems, 2004.
384"
REFERENCES,0.36666666666666664,"[21] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition.
385"
REFERENCES,0.367479674796748,"In Proceedings of the Computer Vision and Pattern Recognition, 2016.
386"
REFERENCES,0.36829268292682926,"[22] José Miguel Hernández-Lobato and Ryan Adams. Probabilistic backpropagation for scalable learning of
387"
REFERENCES,0.36910569105691055,"bayesian neural networks. In Procedings of the International Conference on Machine Learning, 2015.
388"
REFERENCES,0.3699186991869919,"[23] Hengguan Huang, Xiangming Gu, Hao Wang, Chang Xiao, Hongfu Liu, and Ye Wang. Extrapolative
389"
REFERENCES,0.37073170731707317,"continuous-time bayesian neural network for fast training-free test-time adaptation. In Proceedings of the
390"
REFERENCES,0.37154471544715445,"Advances in Neural Information Processing Systems, 2022.
391"
REFERENCES,0.3723577235772358,"[24] J Stuart Hunter. The exponentially weighted moving average. Journal of the Quality Technology, 18(4):203–
392"
REFERENCES,0.37317073170731707,"210, 1986.
393"
REFERENCES,0.37398373983739835,"[25] Vidit Jain and Erik Learned-Miller. Online domain adaptation of a pre-trained cascade of classifiers. In
394"
REFERENCES,0.3747967479674797,"Proceedings of the Computer Vision and Pattern Recognition, 2011.
395"
REFERENCES,0.375609756097561,"[26] Sanghun Jung, Jungsoo Lee, Nanhee Kim, Amirreza Shaban, Byron Boots, and Jaegul Choo. Cafa:
396"
REFERENCES,0.37642276422764226,"Class-aware feature alignment for test-time adaptation. In Proceedings of the IEEE/CVF International
397"
REFERENCES,0.3772357723577236,"Conference on Computer Vision, pages 19060–19071, 2023.
398"
REFERENCES,0.3780487804878049,"[27] Durk P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local reparameterization
399"
REFERENCES,0.37886178861788616,"trick. In Proceedings of the Advances in Neural Information Processing Systems, 2015.
400"
REFERENCES,0.3796747967479675,"[28] Richard Kurle, Botond Cseke, Alexej Klushyn, Patrick Van Der Smagt, and Stephan Günnemann. Continual
401"
REFERENCES,0.3804878048780488,"learning with bayesian neural networks for non-stationary data. In Procedings of the International
402"
REFERENCES,0.38130081300813007,"Conference on Learning Representations, 2019.
403"
REFERENCES,0.3821138211382114,"[29] Dong-Hyun Lee. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural
404"
REFERENCES,0.3829268292682927,"networks. In Workshop on Challenges in Representation Learning, International Conference on Machine
405"
REFERENCES,0.383739837398374,"Learning, volume 3, page 896, 2013.
406"
REFERENCES,0.3845528455284553,"[30] Zhizhong Li and Derek Hoiem. Learning without forgetting. Journal of the IEEE Transactions on Pattern
407"
REFERENCES,0.3853658536585366,"Analysis and Machine Intelligence, 40(12):2935–2947, 2017.
408"
REFERENCES,0.3861788617886179,"[31] GuoJun Liu, Yang Liu, MaoZu Guo, Peng Li, and MingYu Li. Variational inference with gaussian mixture
409"
REFERENCES,0.38699186991869916,"model and householder flow. Journal of the Neural Networks, 109:43–55, 2019.
410"
REFERENCES,0.3878048780487805,"[32] Yuejiang Liu, Parth Kothari, Bastien Van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre
411"
REFERENCES,0.3886178861788618,"Alahi. Ttt++: When does self-supervised test-time training fail or thrive? In Procedings of the Advances in
412"
REFERENCES,0.38943089430894307,"Neural Information Processing Systems, 2021.
413"
REFERENCES,0.3902439024390244,"[33] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Unsupervised domain adaptation with
414"
REFERENCES,0.3910569105691057,"residual transfer networks. In Proceedings of the Advances in Neural Information Processing Systems,
415"
REFERENCES,0.39186991869918697,"2016.
416"
REFERENCES,0.3926829268292683,"[34] Christos Louizos and Max Welling. Multiplicative normalizing flows for variational bayesian neural
417"
REFERENCES,0.3934959349593496,"networks. In Procedings of the International Conference on Machine Learning, 2017.
418"
REFERENCES,0.3943089430894309,"[35] Wesley J Maddox, Pavel Izmailov, Timur Garipov, Dmitry P Vetrov, and Andrew Gordon Wilson. A simple
419"
REFERENCES,0.3951219512195122,"baseline for bayesian uncertainty in deep learning. In Proceedings of the Advances in Neural Information
420"
REFERENCES,0.3959349593495935,"Processing Systems, 2019.
421"
REFERENCES,0.3967479674796748,"[36] David J Miller and Hasan Uyar. A mixture of experts classifier with learning based on both labelled and
422"
REFERENCES,0.3975609756097561,"unlabelled data. In Proceedings of the Advances in Neural Information Processing Systems, 1996.
423"
REFERENCES,0.3983739837398374,"[37] Chaithanya Kumar Mummadi, Robin Hutmacher, Kilian Rambach, Evgeny Levinkov, Thomas Brox, and
424"
REFERENCES,0.3991869918699187,"Jan Hendrik Metzen. Test-time adaptation to distribution shift by confidence maximization and input
425"
REFERENCES,0.4,"transformation. arXiv preprint arXiv:2106.14999, 2021.
426"
REFERENCES,0.4008130081300813,"[38] Cuong V Nguyen, Yingzhen Li, Thang D Bui, and Richard E Turner. Variational continual learning. In
427"
REFERENCES,0.4016260162601626,"Proceedings of the International Conference on Learning Representations, 2018.
428"
REFERENCES,0.4024390243902439,"[39] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan.
429"
REFERENCES,0.4032520325203252,"Efficient test-time model adaptation without forgetting. In Proceedings of the International Conference on
430"
REFERENCES,0.4040650406504065,"Machine Learning, pages 16888–16905, 2022.
431"
REFERENCES,0.40487804878048783,"[40] Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian Nowozin, Joshua Dillon,
432"
REFERENCES,0.4056910569105691,"Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model’s uncertainty? evaluating predictive
433"
REFERENCES,0.4065040650406504,"uncertainty under dataset shift. In Proceedings of the Advances in Neural Information Processing Systems,
434"
REFERENCES,0.4073170731707317,"2019.
435"
REFERENCES,0.408130081300813,"[41] Hippolyt Ritter, Aleksandar Botev, and David Barber. A scalable laplace approximation for neural networks.
436"
REFERENCES,0.4089430894308943,"In Procedings of the International Conference on Learning Representations, 2018.
437"
REFERENCES,0.4097560975609756,"[42] Masa-Aki Sato. Online model selection based on the variational bayes. Journal of the Neural Computation,
438"
REFERENCES,0.4105691056910569,"13:1649–1681, 2001.
439"
REFERENCES,0.4113821138211382,"[43] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge.
440"
REFERENCES,0.4121951219512195,"Improving robustness against common corruptions by covariate shift adaptation. In Proceedings of the
441"
REFERENCES,0.41300813008130083,"Advances in Neural Information Processing Systems, 2020.
442"
REFERENCES,0.4138211382113821,"[44] Yoram Singer and Manfred KK Warmuth. Batch and on-line parameter estimation of gaussian mixtures
443"
REFERENCES,0.4146341463414634,"based on the joint entropy. In Procedings of the Advances in Neural Information Processing Systems, 1998.
444"
REFERENCES,0.41544715447154473,"[45] Junha Song, Jungsoo Lee, In So Kweon, and Sungha Choi. Ecotta: Memory-efficient continual test-time
445"
REFERENCES,0.416260162601626,"adaptation via self-distilled regularization. In Proceedings of the IEEE/CVF Conference on Computer
446"
REFERENCES,0.4170731707317073,"Vision and Pattern Recognition, pages 11920–11929, 2023.
447"
REFERENCES,0.41788617886178864,"[46] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with
448"
REFERENCES,0.4186991869918699,"self-supervision for generalization under distribution shifts. In Procedings of the International Conference
449"
REFERENCES,0.4195121951219512,"on Machine Learning, 2020.
450"
REFERENCES,0.42032520325203254,"[47] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency tar-
451"
REFERENCES,0.4211382113821138,"gets improve semi-supervised deep learning results. In Proceedings of the Advances in Neural Information
452"
REFERENCES,0.4219512195121951,"Processing Systems, 2017.
453"
REFERENCES,0.42276422764227645,"[48] Jesper E Van Engelen and Holger H Hoos. A survey on semi-supervised learning. Machine Learning,
454"
REFERENCES,0.42357723577235773,"109(2):373–440, 2020.
455"
REFERENCES,0.424390243902439,"[49] Chong Wang, John Paisley, and David M Blei. Online variational inference for the hierarchical dirichlet
456"
REFERENCES,0.42520325203252035,"process. In Proceedings of the International Conference on Artificial Intelligence and Statistics, 2011.
457"
REFERENCES,0.42601626016260163,"[50] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-
458"
REFERENCES,0.4268292682926829,"time adaptation by entropy minimization. In Proceedings of the International Conference on Learning
459"
REFERENCES,0.4276422764227642,"Representations, 2020.
460"
REFERENCES,0.42845528455284554,"[51] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In
461"
REFERENCES,0.4292682926829268,"Proceedings of the Computer Vision and Pattern Recognition, 2022.
462"
REFERENCES,0.4300813008130081,"[52] Yanshuo Wang, Jie Hong, Ali Cheraghian, Shafin Rahman, David Ahmedt-Aristizabal, Lars Petersson, and
463"
REFERENCES,0.43089430894308944,"Mehrtash Harandi. Continual test-time domain adaptation via dynamic sample selection. In Proceedings
464"
REFERENCES,0.4317073170731707,"of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 1701–1710, 2024.
465"
REFERENCES,0.432520325203252,"[53] Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey. Symmetric cross entropy
466"
REFERENCES,0.43333333333333335,"for robust learning with noisy labels. In Proceedings of the Computer Vision and Pattern Recognition,
467"
REFERENCES,0.43414634146341463,"2019.
468"
REFERENCES,0.4349593495934959,"[54] Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. Aggregated residual trans-
469"
REFERENCES,0.43577235772357725,"formations for deep neural networks. In Proceedings of the Computer Vision and Pattern Recognition,
470"
REFERENCES,0.43658536585365854,"2017.
471"
REFERENCES,0.4373983739837398,"[55] Xu Yang, Yanan Gu, Kun Wei, and Cheng Deng. Exploring safety supervision for continual test-time
472"
REFERENCES,0.43821138211382116,"domain adaptation. In Proceedings of the International Joint Conference on Artificial Intelligence, 2023.
473"
REFERENCES,0.43902439024390244,"[56] Longhui Yuan, Binhui Xie, and Shuang Li.
Robust test-time adaptation in dynamic scenarios.
In
474"
REFERENCES,0.4398373983739837,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15922–
475"
REFERENCES,0.44065040650406506,"15932, 2023.
476"
REFERENCES,0.44146341463414634,"[57] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. In Procedings of the British Machine
477"
REFERENCES,0.44227642276422763,"Vision Conference, 2016.
478"
REFERENCES,0.44308943089430897,"[58] Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and
479"
REFERENCES,0.44390243902439025,"augmentation. In Procedings of the Advances in Neural Information Processing Systems, 2022.
480"
REFERENCES,0.44471544715447153,"[59] Tingting Zhao, Zifeng Wang, Aria Masoomi, and Jennifer Dy. Deep bayesian unsupervised lifelong
481"
REFERENCES,0.44552845528455287,"learning. Journal of the Neural Networks, 149:95–106, 2022.
482"
REFERENCES,0.44634146341463415,"[60] Aurick Zhou and Sergey Levine. Bayesian adaptation for covariate shift. In Proceedings of the Advances
483"
REFERENCES,0.44715447154471544,"in Neural Information Processing Systems, 2021.
484"
REFERENCES,0.4479674796747967,"Variational Continual Test-Time Adaptation
(Appendix)"
REFERENCES,0.44878048780487806,"A
Bayesian Inference (BI) in Traditional CL and CTTA
485"
REFERENCES,0.44959349593495934,"As described in Sec. 3, we first illustrate the BI has been studied in traditional Continual Learning
486"
REFERENCES,0.4504065040650406,"(CL) methods. In this section, we compare the BI in CL and CTTA in detail and show the differences
487"
REFERENCES,0.45121951219512196,"with some related works. The comparison can be seen in Fig. 3. For the CL, BI is conducted by the
488"
REFERENCES,0.45203252032520325,"posterior propagation, that is, the prior of next task is equal to the current posterior. This is feasible in
489"
REFERENCES,0.45284552845528453,"supervised CL, where the data label is provided. For the CTTA, the posterior is not trustworthy using
490"
REFERENCES,0.45365853658536587,"only pseudo labels to adapt to a new domain. Thus, propagate the untrustworthy posterior to the next
491"
REFERENCES,0.45447154471544715,"stage would make unreliable prior, which will result in error accumulation. In the proposed VCoTTA,
492"
REFERENCES,0.45528455284552843,"we propose to solve the problem via enhancing the two terms in VI (see Sec. 4).
493 Prior"
REFERENCES,0.4560975609756098,"Equal
Posterior "
REFERENCES,0.45691056910569106,Next Prior 
REFERENCES,0.45772357723577234,Labeled Data
REFERENCES,0.4585365853658537,(a) BI in continual learning
REFERENCES,0.45934959349593496,Source Prior  EMA
REFERENCES,0.46016260162601624,Posterior 
REFERENCES,0.4609756097560976,"Next
Teacher Prior "
REFERENCES,0.46178861788617886,Unlabeled
REFERENCES,0.46260162601626015,"Data     
Teacher Prior  Mix"
REFERENCES,0.4634146341463415,(b) BI in CTTA
REFERENCES,0.46422764227642277,"Figure 3: Bayesian inference comparison between continual learning and CTTA. We find the
traditional prior transmission is infeasible in CTTA because of the unreliable prior from unlabeled
data. In our method, we place CTTA in a mean-teacher structure, and design BI in CTTA using a
mixture of teacher prior and source prior. The next teacher prior is updated by the exponential moving
average."
REFERENCES,0.46504065040650405,"VCL [38] is a classic CL study that uses VI, our work is also inspired by VCL but has the following
494"
REFERENCES,0.4658536585365854,"difference. (1) The tasks are different: VCL studies supervised CL task, while our VCoTTA studies
495"
REFERENCES,0.4666666666666667,"unsupervised CTTA task. (2) The challenges are differnt: CL only suffers from catastrophic forgetting
496"
REFERENCES,0.46747967479674796,"(CF), while CTTA sufffers from both CF and error accumulation. (3) Ways of BI are different: To
497"
REFERENCES,0.4682926829268293,"conduct BI, one needs to compute prior and likelihood. For the prior, the current prior of VCL is set
498"
REFERENCES,0.4691056910569106,"to be the previous posterior, while in CTTA such a prior may be unreliable. For the likelihood, VCL
499"
REFERENCES,0.46991869918699186,"can directly compute likelihood, CTTA is under unsupervised setting, thus in our work, we deduce
500"
REFERENCES,0.47073170731707314,"the BI in CTTA using conditional entropy. (4) The update strategies are different: To reduce error
501"
REFERENCES,0.4715447154471545,"accumulation in unsupervised scenario, we employ a mean-teacher update strategy using VI for the
502"
REFERENCES,0.47235772357723577,"student model and exponential moving average for the teacher model, and compute a prior mixture
503"
REFERENCES,0.47317073170731705,"to guide the student update. Moreover, VCL maintains an extra coreset from the training set, while
504"
REFERENCES,0.4739837398373984,"VCoTTA never store any data during the test time.
505"
REFERENCES,0.47479674796747967,"We also find another recent work named PETAL [2] that estimates uncertainties in CTTA. The
506"
REFERENCES,0.47560975609756095,"BI formulation is similar between PETAL and ours, which is derived from [20], but PETAL use
507"
REFERENCES,0.4764227642276423,"different method to conduct the inference: (1) PETAL only uses CNN and does not estimate the model
508"
REFERENCES,0.4772357723577236,"uncertainties, while VCoTTA uses BNN to model the uncertainties during test time. (2) PETAL
509"
REFERENCES,0.47804878048780486,"ignores the unreliable prior in CTTA, and follow the VCL setting that use the previous posterior
510"
REFERENCES,0.4788617886178862,"as the current prior. (3) We conduct BI using variational inference while PETAL use SWAG [35].
511"
REFERENCES,0.4796747967479675,"SWAG has advantages in terms of computational efficiency and stability during training, especially in
512"
REFERENCES,0.48048780487804876,"scenarios where computational resources are limited. However, SWAG might not handle unreliable
513"
REFERENCES,0.4813008130081301,"priors as effectively as VI since it doesn’t explicitly model the posterior distribution. (4) We have
514"
REFERENCES,0.4821138211382114,"compared with PETAL in our experiment (see Tables 1, 2, 3), and our method outperforms PETAL
515"
REFERENCES,0.48292682926829267,"on all datasets.
516"
REFERENCES,0.483739837398374,"B
CTTA Approximation by BI
517"
REFERENCES,0.4845528455284553,"B.1
Assumption on Class Separability
518"
REFERENCES,0.4853658536585366,"In our method, we use the conditional entropy to alternate the intractable computing of likelihood.
519"
REFERENCES,0.4861788617886179,"Note that the use of entropy in unsupervised scenario needs to satisfy the class-separable assumption.
520"
REFERENCES,0.4869918699186992,"In fact, unlabeled data do not convey category information but still carry information. Miller and
521"
REFERENCES,0.4878048780487805,"Uyar [36] theoretically proved that utilizing unlabeled samples to train classifiers can improve
522"
REFERENCES,0.4886178861788618,"classification performance if there is a connection between the target and sample distributions.
523"
REFERENCES,0.4894308943089431,"It is a common practice in unsupervised/semi-supervised learning to establish the relationship
524"
REFERENCES,0.4902439024390244,"between unlabeled data and the target by making some reasonable assumptions to obtain category-
525"
REFERENCES,0.49105691056910566,"relevant information from unlabeled data. Common assumptions include the Smoothness assumption,
526"
REFERENCES,0.491869918699187,"Cluster assumption, Manifold assumption, Low-density separation assumption, etc. For example,
527"
REFERENCES,0.4926829268292683,"the well-known clustering-based methods utilize the cluster assumption to generate pseudo-labels
528"
REFERENCES,0.49349593495934957,"for unsupervised learning [48]. Caron et al. [5] assumes that ""the model trained on labeled data
529"
REFERENCES,0.4943089430894309,"will produce high uncertainty estimation for unseen data"" in domain adaptation tasks to benefit the
530"
REFERENCES,0.4951219512195122,"classifier from unlabeled data lacking category information.
531"
REFERENCES,0.4959349593495935,"Bengio et al. in [20] proposed the conditional entropy and point out that ""These studies conclude that
532"
REFERENCES,0.4967479674796748,"the (asymptotic) information content of unlabeled examples decreases as classes overlap. Thus, the
533"
REFERENCES,0.4975609756097561,"assumption that classes are well separated is sensible if we expect to take advantage of unlabeled
534"
REFERENCES,0.4983739837398374,"examples."" This assumption has been applied to many studies, for example in [29, 33, 60, 2]. In
535"
REFERENCES,0.4991869918699187,"the CTTA task of this paper, as the task progresses, the domain shifts, but the categories in the task
536"
REFERENCES,0.5,"remain unchanged. Therefore, under the assumption that unlabeled data contains information, we
537"
REFERENCES,0.5008130081300813,"can reasonably continue to use conditional entropy in the current scenario. To sum up, whether in
538"
REFERENCES,0.5016260162601626,"unsupervised TTA or in the Bayesian field, this assumption is not difficult to achieve or has never
539"
REFERENCES,0.5024390243902439,"been applied. We can quite naturally continue to use this assumption in the context of this paper.
540"
REFERENCES,0.5032520325203252,"B.2
BI during Test Time
541"
REFERENCES,0.5040650406504065,"The goal of CTTA is to learn a posterior distribution p(θ|U1:T ∪D0) from a source dataset D0,
542"
REFERENCES,0.5048780487804878,"and a sequence of unlabeled test data from U1 to UT . Following [60], assuming we have multiple
543"
REFERENCES,0.5056910569105691,"input-generating distributions that the source dataset D0 is drawn from a distribution ϕ, and ˜ϕt
544"
REFERENCES,0.5065040650406504,"specifies the shifted of the t-th unlabeled test dataset which we aim to adapt to. Let the parameters
545"
REFERENCES,0.5073170731707317,"of the model be θ,then following the semi-supervised learning framework [20], we incorporate all
546"
REFERENCES,0.508130081300813,"input-generating distributions into the belief over the model parameters θ as follows
547"
REFERENCES,0.5089430894308943,"p(θ|ϕ, ˜ϕ1, · · · , ˜ϕT ) ∝p(θ) exp (−λ0Hθ,ϕ(Y |X)) T
Y"
REFERENCES,0.5097560975609756,"t=1
exp

−λtHθ, ˜ϕt(Y |X)

,
(18)"
REFERENCES,0.510569105691057,"where the inputs X are sampled i.i.d. from a generative model with parameters ϕ, while the corre-
548"
REFERENCES,0.5113821138211382,"sponding labels Y are sampled from a conditional distribution p(Y |X, θ), which is parameterized
549"
REFERENCES,0.5121951219512195,"by the model parameters θ. p(θ) is a prior distribution over θ. {λ0, λ1, · · · , λT } are the factors for
550"
REFERENCES,0.5130081300813009,"approximation weighting. Generally, the entropy term Hθ,ϕ(Y |X) represents the cross entropy of
551"
REFERENCES,0.5138211382113821,"the supervised learning, and the entropy term Hθ, ˜ϕt(Y |X) for t > 0 denotes the Shannon entropy of
552"
REFERENCES,0.5146341463414634,"the unsupervised learning.
553"
REFERENCES,0.5154471544715448,"Following [60], we can empirically use a point estimation to get a plug-in Bayesian approach to
554"
REFERENCES,0.516260162601626,"approximate the above formula:
555"
REFERENCES,0.5170731707317073,p(θ|U1:T ∪D0)
REFERENCES,0.5178861788617887,"∝
p(θ)
Y"
REFERENCES,0.5186991869918699,"∀x,y∈D0
p(y|x, θ) exp  −λ0 |D0| X"
REFERENCES,0.5195121951219512,"∀x∈D0
H(Y |x, θ) ! T
Y"
REFERENCES,0.5203252032520326,"t=1
exp  −λt |Ut| X"
REFERENCES,0.5211382113821138,"∀x∈Ut
H(Y |x, θ) ! ."
REFERENCES,0.5219512195121951,"(19)
To make the formula feasible to CTTA, that is, no source data is available at the test time, we set
556"
REFERENCES,0.5227642276422764,λ0 = 0. And the source knowledge can be represented by p(θ|D0) ∝p(θ) Q
REFERENCES,0.5235772357723577,"∀x,y∈D0 p(y|x, θ).
557"
REFERENCES,0.524390243902439,"Thus, for the t-th test domain, the Bayesian inference in CTTA can be represented as follows:
558"
REFERENCES,0.5252032520325203,p(θ|U1:t ∪D0) ∝p(θ|D0) tY
REFERENCES,0.5260162601626016,"i=1
exp  −λi |Ui| X"
REFERENCES,0.526829268292683,"∀x∈Ui
H(Y |x, θ) !"
REFERENCES,0.5276422764227642,∝p(θ|U1:t−1 ∪D0) exp  −λt |Ut| X
REFERENCES,0.5284552845528455,"∀x∈Ut
H(Y |x, θ) ! , (20)"
REFERENCES,0.5292682926829269,"where H(Ut|θ) =
1
|Ut|
P"
REFERENCES,0.5300813008130081,"∀x∈Ut H(Y |x, θ) and the above formula can be rewritten in simplicity as
559"
REFERENCES,0.5308943089430894,"p(θ|U1:t ∪D0) ∝p(θ|U1:t−1 ∪D0)e−λH(Ut|θ) = pt(θ)e−λH(Ut|θ),
(21)"
REFERENCES,0.5317073170731708,"which specifies the Bayesian inference process on continuously arriving unlabeled data in CTTA.
560"
REFERENCES,0.532520325203252,"C
ELBO of the VI in CTTA
561"
REFERENCES,0.5333333333333333,"We built VI for CTTA in Sec. 3, where we initialize a variational distribution q(θ) to approximate the
562"
REFERENCES,0.5341463414634147,"real posterior. For the test domain t, we optimize the variational distribution as follows:
563"
REFERENCES,0.5349593495934959,"qt(θ) = arg min
q∈Q KL

q(θ) ∥1"
REFERENCES,0.5357723577235772,"Zt
pt(θ)e−λH(Ut|θ)

,
(22)"
REFERENCES,0.5365853658536586,"where Q is the distribution searching space, and pt(θ) is the current prior.
564"
REFERENCES,0.5373983739837398,"Following the definition of KL divergence and the standard derivation of the Evidence Lower BOund
565"
REFERENCES,0.5382113821138211,"(ELBO) is as the following formulas. Specifically, the KL divergence is expanded as
566"
REFERENCES,0.5390243902439025,"KL

q(θ) ∥1"
REFERENCES,0.5398373983739837,"Zt
pt(θ)e−λH(Ut|θ)
 = −
Z"
REFERENCES,0.540650406504065,"θ
q(θ) log"
ZT,0.5414634146341464,"1
Zt
pt(θ)e−λH(Ut|θ)"
ZT,0.5422764227642276,"q(θ)
dθ = −
Z"
ZT,0.5430894308943089,"θ
q(θ) log 1"
ZT,0.5439024390243903,"Zt
e−λH(Ut|θ)dθ −
Z"
ZT,0.5447154471544715,"θ
q(θ) log pt(θ)"
ZT,0.5455284552845528,"q(θ) dθ =
Z"
ZT,0.5463414634146342,"θ
q(θ) log Ztdθ + λ
Z"
ZT,0.5471544715447154,"θ
q(θ)H(Ut|θ)dθ −
Z"
ZT,0.5479674796747968,"θ
q(θ) log pt(θ)"
ZT,0.5487804878048781,q(θ) dθ
ZT,0.5495934959349593,"= log Zt + λEθ∼q(θ)H(Ut|θ) + KL (q(θ) ∥pt(θ)) , (23)"
ZT,0.5504065040650407,"where the first constant term can be reduced in the optimization. Thus, we can optimize the variational
567"
ZT,0.551219512195122,"distribution via the ELBO:
568"
ZT,0.5520325203252032,"qt(θ) = arg min
q∈Q KL

q(θ) ∥1"
ZT,0.5528455284552846,"Zt
pt(θ)e−λH(Ut|θ)
"
ZT,0.5536585365853659,"= arg max
q∈Q −λEθ∼q(θ)H(Ut|θ) −KL (q(θ) ∥pt(θ))"
ZT,0.5544715447154471,"= arg max
q∈Q ELBO. (24)"
ZT,0.5552845528455285,"In our case, the former entropy term can be more effectively replaced by the cross entropy or
569"
ZT,0.5560975609756098,"symmetric cross entropy (SCE) between the student model and the teacher model in a mean-teacher
570"
ZT,0.556910569105691,"architecture (see Sec. 4.1). For the latter KL term, we can substitute a variational approximation
571"
ZT,0.5577235772357724,"that we deem closest to the current-stage prior pt(θ) into the KL divergence. When the prior is a
572"
ZT,0.5585365853658537,"multivariate Gaussian distribution, this term can be computed in closed form as
573"
ZT,0.5593495934959349,"KL (N(µ1, Σ1) ∥N(µ2, Σ2)) =
1
2"
ZT,0.5601626016260163,"
tr(Σ−1
2 Σ1) + (µ2 −µ1)⊤Σ−1
2 (µ2 −µ1) −k + ln
det(Σ2)"
ZT,0.5609756097560976,det(Σ1)
ZT,0.5617886178861788,"
.
(25)"
ZT,0.5626016260162602,"where Σ = diag(σ2), k represents the dimensionality of the distributions, tr(·) denotes the trace of a
574"
ZT,0.5634146341463414,"matrix, and det(·) stands for the determinant of a matrix. For the case that the prior is a mixture of
575"
ZT,0.5642276422764227,"Gaussian distributions, we can refer to the next section to get its upper bound.
576"
ZT,0.5650406504065041,"D
Mixture-of-Gaussian Prior
577"
ZT,0.5658536585365853,"D.1
Upper Bound of the Mixture of Two KL Divergencies
578"
ZT,0.5666666666666667,"We refer to the lemma that was stated for the mixture of Gaussian in [44].
The KL divergence
579"
ZT,0.567479674796748,"between two mixture distributions p = Pk
i=1 αipi and p′ = Pk
i=1 αip′
i is upper-bounded by
580"
ZT,0.5682926829268292,"KL(p ∥p′) ≤KL(α ∥α′) + k
X"
ZT,0.5691056910569106,"i=1
αiKL(pi ∥p′
i),
(26)"
ZT,0.5699186991869919,"where α = (α1, α2, · · · , αk) and α′ = (α′
1, α′
2, · · · , α′
k) are the weights of the mixture components.
581"
ZT,0.5707317073170731,"The equality holds if and only if αipi/Pk
j=1 αjpj = α′
ip′
i/Pk
j=1 α′
jp′
j for all i.
Using the log-sum
582"
ZT,0.5715447154471545,"inequality [10], we have
583 KL( k
X"
ZT,0.5723577235772358,"i=1
αipi ∥ k
X"
ZT,0.573170731707317,"i=1
αip′
i) =
Z  k
X"
ZT,0.5739837398373984,"i=1
αipi !"
ZT,0.5747967479674797,"log
Pk
i=1 αipi
Pk
i=1 αip′
i"
ZT,0.5756097560975609,"≤
Z
k
X"
ZT,0.5764227642276423,"i=1
αipi log αipi"
ZT,0.5772357723577236,"αip′
i = k
X"
ZT,0.5780487804878048,"i=1
αi"
ZT,0.5788617886178862,"Z
pi log αi"
ZT,0.5796747967479675,"α′
i
+
Z
pi log pi p′
i "
ZT,0.5804878048780487,"= KL(α ∥α′) + k
X"
ZT,0.5813008130081301,"i=1
αiKL(pi ∥p′
i)."
ZT,0.5821138211382114,"In our algorithm, q(θ) is set to be a mixture of Gaussian distributions, i.e., pt(θ) = α · p1(θ) + (1 −
584"
ZT,0.5829268292682926,"α) · ¯pt(θ). In the above inequality, let q(θ) = Pk
i=1 αiq(θ), we can get the upper bound of the KL
585"
ZT,0.583739837398374,"divergence between q(θ) and pt(θ):
586"
ZT,0.5845528455284553,"KL(q ∥pt) ≤α · KL (q||p1) + (1 −α) · KL (q||¯pt) .
(27)"
ZT,0.5853658536585366,"So the lower bound (24) can be redefined as
587"
ZT,0.5861788617886179,L = −λEθ∼q(θ)H(Ut|θ) −KL (q(θ) ∥pt(θ))
ZT,0.5869918699186992,≥−λEθ∼q(θ)H(Ut|θ) −α · KL (q||p1) −(1 −α) · KL (q||¯pt)
ZT,0.5878048780487805,"def
= L′, (28)"
ZT,0.5886178861788618,"Then, we have obtained a lower bound that can be optimized through closed-form calculations as
588"
ZT,0.5894308943089431,"the source prior distribution q0(θ) and the teacher prior distribution ¯qt(θ) are multivariate Gaussian
589"
ZT,0.5902439024390244,"distributions, which means we can also optimize L′ with Eq. (25).
590"
ZT,0.5910569105691057,"D.2
Advantage of the Mixture of Gaussian Prior
591"
ZT,0.591869918699187,"In this subsection, we illustrate why the mixture of Gaussian prior are beneficial to CTTA. First of
592"
ZT,0.5926829268292683,"all, we can start from defining what is a better distribution for CTTA. Assume there exists an ideal
593"
ZT,0.5934959349593496,"prior distribution ˆpt, which effectively represents the distribution of the model after learning all past
594"
ZT,0.5943089430894309,"knowledge, including that from the source and unlabeled datasets. Then we can use the difference
595"
ZT,0.5951219512195122,"between a distribution and the ideal distribution ˆpt (here we use KL divergence) to measure the
596"
ZT,0.5959349593495935,"goodness of a distribution, i.e., KL(·||ˆpt).
597"
ZT,0.5967479674796748,"Generally, neither the source prior p1 (trained on labeled data) nor the adapted prior ¯pt (adapt
598"
ZT,0.5975609756097561,"on unlabeled data, being unreliable) can be completely consistent with ˆpt. Considering that, as t
599"
ZT,0.5983739837398374,"increases, the difference between ¯pt and ˆpt will increase without an upper bound due to the error
600"
ZT,0.5991869918699188,"accumulation (since t is infinitely growing). The source prior p1 cannot adapt to the unlabeled data,
601"
ZT,0.6,"but it contains important information from the labeled data, and the ideal distribution cannot forget the
602"
ZT,0.6008130081300813,"source information too much, so we can assume that the difference between p1 and ˆpt is a constant,
603"
ZT,0.6016260162601627,"i.e., KL(p1||ˆpt) < U, where U is a constant upper bound. Accordingly, it can be considered that
604"
ZT,0.6024390243902439,"mixing the source prior p1 and the adapted prior ¯pt in some way is beneficial for reducing KL(·||ˆpt).
605"
ZT,0.6032520325203252,"In our paper, we consider using a simple Gaussian mixture, i.e., pt = αtp1 + (1 −αt)¯pt, where α is
606"
ZT,0.6040650406504066,"computed by Eq. (10). It is easy to illustrate the benefits of this idea using the following inequality:
607"
ZT,0.6048780487804878,"KL(pt||ˆpt) = KL [(αtp1 + (1 −αt)¯pt)||ˆpt]
≤αtKL(p1||ˆpt) + (1 −αt)KL(¯pt||ˆpt)
≤αtU + (1 −αt)KL(¯pt||ˆpt).
(29)"
ZT,0.6056910569105691,"In Eq. (29), if KL(¯pt||ˆpt) ≥U, which can be satisfied as mentioned above, then we have"
ZT,0.6065040650406504,"KL(pt||ˆpt) ≤KL(¯pt||ˆpt),"
ZT,0.6073170731707317,"This indicates that the mixed distribution pt is closer to the ideal distribution ˆpt than the adapted
608"
ZT,0.608130081300813,"prior ¯pt. A similar idea can be found in the stochatic restoration in CoTTA [51], where the author
609"
ZT,0.6089430894308943,"randomly restore parts of parameters of the current model into the parameters of source model.
610"
ZT,0.6097560975609756,"E
Augmentation Analysis
611"
ZT,0.6105691056910569,"In our method, we use the standard augmentation following CoTTA [51]. In this subsection, we
612"
ZT,0.6113821138211382,"analyze the some characteristics via experiments.
613"
ZT,0.6121951219512195,"E.1
Confidence Margin
614"
ZT,0.6130081300813008,"First, we analyze the margin ϵ in Eq. (13). We experimentally validate different margins with more
615"
ZT,0.6138211382113821,"choices. Experimental results are shown in Tables 8. The results indicate that different datasets
616"
ZT,0.6146341463414634,"may require different margins to control confidence. Moreover, Eq. (13) signifies that the reliable
617"
ZT,0.6154471544715447,"teacher likelihood is represented by the mean of its augmentations with ϵ more confidence than the
618"
ZT,0.616260162601626,"teacher itself. Tables 8 illustrates the selection of ϵ in our approach on CIFAR10C, CIFAR100C
619"
ZT,0.6170731707317073,"and ImageNetC. Note that when ϵ = −1, it means no margin is used and the method will use all
620"
ZT,0.6178861788617886,"augmentated samples, i.e., without using Eq. (13). The results show that the proposed margin can
621"
ZT,0.6186991869918699,"effectively filter out unreliable augmented samples and achieve a better teacher log-likelihood.
622"
ZT,0.6195121951219512,Table 8: Analysis on confidence margin.
ZT,0.6203252032520326,"No.
ϵ
CIFAR10C
ϵ
CIFAR100C
ϵ
ImageNetC"
ZT,0.6211382113821138,"1
-1
15.1
-1
29.3
-1
66.4
2
0
13.23
0
28.78
0
65.0
3
1e-4
13.23
0.1
28.55
1e-3
65.0
4
1e-3
13.22
0.2
28.45
1e-2
64.8
5
1e-2
13.14
0.3
28.43
1e-1
64.7
6
1e-1
13.31
0.4
28.54
2e-1
66.2"
ZT,0.6219512195121951,"E.2
Different Number of Augmentation
623"
ZT,0.6227642276422765,"In our method, we also use augmentation to enhance the confidence. We then evaluate the the number
624"
ZT,0.6235772357723577,"of augmentation in Eq. (10). The results can be seen in Table 9, and shows that increasing the number
625"
ZT,0.624390243902439,"of augmentations can enhance effectiveness, but this hyperparameter ceases to have a significant
626"
ZT,0.6252032520325204,"impact after reaching 32.
627"
ZT,0.6260162601626016,Table 9: Different number of augmentation.
ZT,0.6268292682926829,"Method
0
4
8
16
32
64"
ZT,0.6276422764227643,"CoTTA
17.5
17.0
16.6
16.5
16.3
16.2
PETAL
17.3
16.9
16.4
16.1
16.0
16.0"
ZT,0.6284552845528455,"VCoTTA
14.9
13.8
13.6
13.3
13.1
13.1"
ZT,0.6292682926829268,"F
Further Discussion on Variational Warm-up Strategy
628"
ZT,0.6300813008130082,"We have discussed the Variational Warm-Up (VWU) strategy in Sec. 4.3.1, and explain that the
629"
ZT,0.6308943089430894,"warm-up strategy is a common practice in TTA and CTTA. In this section, we further discuss some
630"
ZT,0.6317073170731707,"attributes of the proposed variational warm-up strategy.
631"
ZT,0.6325203252032521,"In our method, the VWU strategy is used to turn an off-the-shelf CNN to a pretrained BNN. The
632"
ZT,0.6333333333333333,"advantage of this approach is that pretrained CNNs are readily available (e.g., directly leveraging
633"
ZT,0.6341463414634146,"official models in PyTorch), while pretrained BNNs are challenging to obtain, especially for large-
634"
ZT,0.634959349593496,"scale datasets. Moreover, training BNNs is more difficult compared to training CNNs. Therefore,
635"
ZT,0.6357723577235772,"constructing BNN pretrained models based on existing CNN pretrained models is a feasible approach.
636"
ZT,0.6365853658536585,"Additionally, we find that such a warm-up strategy requires only a few epochs to achieve satisfactory
637"
ZT,0.6373983739837399,"results. To validate the characteristics of the proposed VWU strategy, we designed the following
638"
ZT,0.6382113821138211,"experiments.
639"
ZT,0.6390243902439025,"F.1
Warm-up on CNN vs. Directly Pretraining BNN
640"
ZT,0.6398373983739838,"First, we conducted experiments to compare the performance of obtaining pretrained BNN models
641"
ZT,0.640650406504065,"using the warm-up approach versus directly training the source model with BNN. We pretrain the
642"
ZT,0.6414634146341464,"BNN also use VI as describing in Sec. 4.3.1. The results can be seen in Table 10. As we can see, the
643"
ZT,0.6422764227642277,"results are at the same level, for example VI pretraining is with 13.2% error rate while the proposed
644"
ZT,0.6430894308943089,"VWU achieves 13.1% on CIFAR10C. However, if we direct turn a pretrained CNN to a BNN by
645"
ZT,0.6439024390243903,"adding random stochastic parameters, without warm-up strategy, the results drop to 17.1%. This
646"
ZT,0.6447154471544716,"shows that VWU is a feasible strategy to obtain a pretrained BNN.
647"
ZT,0.6455284552845528,Table 10: Error comparison between varional warm-up on CNN and directly pretraining BNN.
ZT,0.6463414634146342,"Method
CIFAR10C
CIFAR100C
ImagenetC"
ZT,0.6471544715447154,"BNN (Random) →BNN + VI pretraining
13.2
29.0
65.5
CNN (Pretrained) →BNN w/o VWU
17.1
31.2
68.3
CNN (Pretrained) →BNN w/ VWU
13.1
28.4
64.7"
ZT,0.6479674796747967,"F.2
Number of Warm-up Epochs
648"
ZT,0.6487804878048781,"In our implementation, we employ only a limited number of epochs for variational warm-up, say 5
649"
ZT,0.6495934959349593,"epochs. This is due to the fact that the pretrained model fits well in CNN, thus requiring minimal
650"
ZT,0.6504065040650406,"adjustments to the mean of BNN. Additionally, the standard deviation (std) is initialized to be small.
651"
ZT,0.651219512195122,"Consequently, only a small number of iterations are necessary to update the BNN, and the step size is
652"
ZT,0.6520325203252032,"also kept small. Experimentation on the epoch number of variational warm-up reveals that keeping
653"
ZT,0.6528455284552845,"increasing epochs ( > 5) will diminishes performance, as shown in Fig. 5.
654 Error 64.0 64.5 65.0 65.5 66.0"
ZT,0.6536585365853659,Number of epoch
ZT,0.6544715447154471,"1
2
3
4
5
6
7
8
9
10"
ZT,0.6552845528455284,"Figure 4: Comparisons on different warm-up
epochs (CIFAR10C). Error 13.0 13.5 14.0 14.5 15.0"
ZT,0.6560975609756098,Data portion
ZT,0.656910569105691,"1/10
1/4
1/2
1/4
1"
ZT,0.6577235772357723,"Figure 5: Comparisons on different warm-up data
scale (CIFAR10C)."
ZT,0.6585365853658537,"F.3
Only Portion Usage of Source Dataset in Warm-up
655"
ZT,0.6593495934959349,"As we response to the weakness, the warm-up strategy is a common approach in TTA and CTTA
656"
ZT,0.6601626016260163,"tasks and it is regarded as a part of pretraining stage. We also evaluate how if we only use partial
657"
ZT,0.6609756097560976,"data for warm-up, and the results are as follow. The experimental results demonstrate that a moderate
658"
ZT,0.6617886178861788,"reduction in sample size still maintains certain effectiveness of the warmup strategy. However,
659"
ZT,0.6626016260162602,"excessive reduction, such as reducing to 1/10, leads to a certain decline in effectiveness. This is
660"
ZT,0.6634146341463415,"because the warmup strategy aims to incorporate statistical information of the dataset into the model,
661"
ZT,0.6642276422764227,"and insufficient data may result in inaccurate performance.
662"
ZT,0.6650406504065041,"G
Recursive Variational Approximation Process in VCoTTA
663"
ZT,0.6658536585365854,"In this section, we show the algorithmic workflow utilizing variational approximation in VCoTTA.
664"
ZT,0.6666666666666666,"Before testing time: First, we adopt a variational warm-up strategy to inject stochastic dynamics into
665"
ZT,0.667479674796748,"the model before adaptation. Given the source dataset D0, we can use a variational approximation of
666"
ZT,0.6682926829268293,"p(θ|D0) as follows
667"
ZT,0.6691056910569105,"p(θ|D0) = p1(θ) ≈q0(θ) = arg min
q∈Q KL

q(θ) ∥1"
ZT,0.6699186991869919,"Z0
p(θ)p(D0|θ)

,
(30)"
ZT,0.6707317073170732,"where we use the pretrained deterministic model p0(θ) as the prior distribution.
668"
ZT,0.6715447154471544,"When the domain shift: Then, at the beginning of the test time, we set the prior in task t as
669"
ZT,0.6723577235772358,"pt(θ) = α · p1(θ) + (1 −α) · ¯pt(θ) and variational approximation, where p1(θ) ≈q0(θ) and
670"
ZT,0.6731707317073171,"¯pt(θ) ≈¯qt(θ). For ¯qt(θ), which means the real-time posterior probability of the teacher model for
671"
ZT,0.6739837398373983,"the t-th test domain, is constantly updated by qt(θ) via EMA (see Sec. 4.3.3) during the test phase.
672"
ZT,0.6747967479674797,"Note that we do not have ¯qt(θ) for the first update in the t-th phase. In fact, we use qt−1(θ) construct
673"
ZT,0.675609756097561,"the prior, thus we have pt(θ) ≈α · p1(θ) + (1 −α) · qt−1(θ). This is the variational distribution
674"
ZT,0.6764227642276422,"that should be used to approximate the prior in the absence of a teacher model in the first step, as
675"
ZT,0.6772357723577236,"well as the approximation that should be used when not employing the MT architecture. Note that
676"
ZT,0.6780487804878049,"the process is not required to inform the model that the domain produces a shift.
677"
ZT,0.6788617886178862,"During the testing time of a domain: With the approximation to pt(θ) and analysis from Ap-
678"
ZT,0.6796747967479675,"pendix B.2, we get qt(θ) for student model at the test domain t as follows:
679"
ZT,0.6804878048780488,"qt(θ) = arg min
q∈Q KL

q(θ) ∥1"
ZT,0.6813008130081301,"Zt
pt(θ)e−λH(Ut|θ)

,
(31)"
ZT,0.6821138211382114,"which means, we can recursively derive pt+1(θ) and the following variational distributions, thereby
680"
ZT,0.6829268292682927,"achieving the goal of VCoTTA.
681"
ZT,0.683739837398374,"H
Different Orders of Corruption
682"
ZT,0.6845528455284553,"As we discuss in the major comparisons (see Sec 5.3), the performance may be affected by the
683"
ZT,0.6853658536585366,"corruption order. To provide a more comprehensive evaluation of the matter of the order, we conduct
684"
ZT,0.6861788617886179,"10 different orders from Sec 5.3, and show the average performance of all compared methods.
685"
ZT,0.6869918699186992,"10 independent random orders of corruption are all under the severity level of 5. The results
686"
ZT,0.6878048780487804,"are shown in Table 11. We find that the order of corruption is minor on simple datasets such as
687"
ZT,0.6886178861788618,"CIFAR10C and CIFAR100C, but small std on difficult datasets such as ImageNetC. The proposed
688"
ZT,0.6894308943089431,"VCOTTA outperforms other methods on the average error of CIFAR10C and CIFAR100C under 10
689"
ZT,0.6902439024390243,"different corruption orders, which shows the effectiveness of the prior calibration in CTTA. Moreover,
690"
ZT,0.6910569105691057,"VCOTTA has comparable results with PETAL on ImageNetC, but smaller std over 10 orders, which
691"
ZT,0.691869918699187,"shows the robustness of the proposed method.
692"
ZT,0.6926829268292682,Table 11: Comparisons over 10 orders (avg ± std).
ZT,0.6934959349593496,"Method
CIFAR10C
CIFAR100C
ImageNetC"
ZT,0.6943089430894309,"CoTTA
17.3±0.3
32.2±0.3
63.4±3.0
PETAL
16.0±0.1
33.8±0.3
62.7±2.6"
ZT,0.6951219512195121,"VCoTTA
13.1±0.1
28.2±0.2
62.8±1.1"
ZT,0.6959349593495935,"I
Corruption Loops
693"
ZT,0.6967479674796748,"In the real-world scenario, the testing domain may reappear in the future. We evaluate the test
694"
ZT,0.697560975609756,"conditions continually 10 times to evaluate the long-term adaptation performance on CIFAR10C.
695"
ZT,0.6983739837398374,"That is, the test data will be re-inference and re-adapt for 9 more turns under severity 5. Full
696"
ZT,0.6991869918699187,"results can be found in Fig. 6. The results show that most compared methods obtain performance
697"
ZT,0.7,"improvement in the first several loops, but suffer from performance drop in the following loops. This
698"
ZT,0.7008130081300813,"means that the model drift can be even useful in early loops, but the drift becomes hard because of
699"
ZT,0.7016260162601626,"the unreliable prior. The results also indicate that our method outperforms others in this long-term
700"
ZT,0.7024390243902439,"adaptation situation and has only small performance drops.
701"
ZT,0.7032520325203252,"1
2
3
4
5
6
7
8
9
10 13 14 15 16 17 Error"
ZT,0.7040650406504065,"CoTTA
PETAL
VCoTTA"
ZT,0.7048780487804878,Figure 6: 10 loops under a same corruption order (CIFAR10C).
ZT,0.7056910569105691,"J
Experiment on Online Setting
702"
ZT,0.7065040650406504,"CTTA does operate in an online setting, where all testing data is used only once. However, the current
703"
ZT,0.7073170731707317,"focus of CTTA research primarily revolves around batch-mode online settings, with batch sizes
704"
ZT,0.708130081300813,"typically set to 200 in our experiments like other SOTAs. In CTTA, strict online learning settings
705"
ZT,0.7089430894308943,"where each data point is processed individually are under-researched. In fact, our method can be
706"
ZT,0.7097560975609756,"applied in scenarios with online learning or small batch sizes. However, it’s important to note that the
707"
ZT,0.7105691056910569,"batch normalization (BN) layers is disabled when the batch size is 1. We experimented with batch
708"
ZT,0.7113821138211383,"size of 1 on CIFAR10C, and compare the results with some baseline methods. The comparison results
709"
ZT,0.7121951219512195,"are shown in Table 12. The results show that small batch size in CTTA makes worse performance.
710"
ZT,0.7130081300813008,"We believe this is because a small batch size amplifies the uncertainty in model training.
711"
ZT,0.7138211382113822,Table 12: Error comparisons of strict online learning (batch size = 1).
ZT,0.7146341463414634,"Method
Batch size 1
Batch size 200"
ZT,0.7154471544715447,"TENT
43.5
20.1
CoTTA
42.4
16.3
VCoTTA
39.1
13.1"
ZT,0.7162601626016261,"K
Time and Memory Cost
712"
ZT,0.7170731707317073,"We implement our method using a single RTX-4090 GPU card. We provide the memory and time cost
713"
ZT,0.7178861788617886,"in Table 13. Our proposed VCoTTA method does not offer an advantage in terms of memory usage.
714"
ZT,0.71869918699187,"This is because in the BNN framework, additional standard deviations are required for implementing
715"
ZT,0.7195121951219512,"local reparameterization tricks. However, during the testing phase, this does not significantly impact
716"
ZT,0.7203252032520325,"the efficiency of the model. This is because during testing, only the student model employs variational
717"
ZT,0.7211382113821139,"inference, which requires uncertainty parameters.
718"
ZT,0.7219512195121951,Table 13: Time and memory cost comparisons.
ZT,0.7227642276422764,"Method
Memory
Time per corruption"
ZT,0.7235772357723578,"CoTTA
10.3Gb
272s
PETAL
10.2Gb
261s
VCoTTA
11.1Gb
279s"
ZT,0.724390243902439,"NeurIPS Paper Checklist
719"
ZT,0.7252032520325203,"The checklist is designed to encourage best practices for responsible machine learning research,
720"
ZT,0.7260162601626017,"addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove
721"
ZT,0.7268292682926829,"the checklist: The papers not including the checklist will be desk rejected. The checklist should
722"
ZT,0.7276422764227642,"follow the references and follow the (optional) supplemental material. The checklist does NOT count
723"
ZT,0.7284552845528456,"towards the page limit.
724"
ZT,0.7292682926829268,"Please read the checklist guidelines carefully for information on how to answer these questions. For
725"
ZT,0.7300813008130081,"each question in the checklist:
726"
ZT,0.7308943089430894,"• You should answer [Yes] , [No] , or [NA] .
727"
ZT,0.7317073170731707,"• [NA] means either that the question is Not Applicable for that particular paper or the
728"
ZT,0.732520325203252,"relevant information is Not Available.
729"
ZT,0.7333333333333333,"• Please provide a short (1–2 sentence) justification right after your answer (even for NA).
730"
ZT,0.7341463414634146,"The checklist answers are an integral part of your paper submission. They are visible to the
731"
ZT,0.734959349593496,"reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it
732"
ZT,0.7357723577235772,"(after eventual revisions) with the final version of your paper, and its final version will be published
733"
ZT,0.7365853658536585,"with the paper.
734"
ZT,0.7373983739837399,"The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.
735"
ZT,0.7382113821138211,"While ""[Yes] "" is generally preferable to ""[No] "", it is perfectly acceptable to answer ""[No] "" provided a
736"
ZT,0.7390243902439024,"proper justification is given (e.g., ""error bars are not reported because it would be too computationally
737"
ZT,0.7398373983739838,"expensive"" or ""we were unable to find the license for the dataset we used""). In general, answering
738"
ZT,0.740650406504065,"""[No] "" or ""[NA] "" is not grounds for rejection. While the questions are phrased in a binary way, we
739"
ZT,0.7414634146341463,"acknowledge that the true answer is often more nuanced, so please just use your best judgment and
740"
ZT,0.7422764227642277,"write a justification to elaborate. All supporting evidence can appear either in the main paper or the
741"
ZT,0.7430894308943089,"supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification
742"
ZT,0.7439024390243902,"please point to the section(s) where related material for the question can be found.
743"
ZT,0.7447154471544716,"IMPORTANT, please:
744"
ZT,0.7455284552845528,"• Delete this instruction block, but keep the section heading “NeurIPS paper checklist"",
745"
ZT,0.7463414634146341,"• Keep the checklist subsection headings, questions/answers and guidelines below.
746"
ZT,0.7471544715447155,"• Do not modify the questions and only use the provided macros for your answers.
747"
CLAIMS,0.7479674796747967,"1. Claims
748"
CLAIMS,0.748780487804878,"Question: Do the main claims made in the abstract and introduction accurately reflect the
749"
CLAIMS,0.7495934959349594,"paper’s contributions and scope?
750"
CLAIMS,0.7504065040650406,"Answer: [Yes]
751"
CLAIMS,0.751219512195122,"Justification: We made clear claims to illustrate that we evaluate the uncertainty in CTTA
752"
CLAIMS,0.7520325203252033,"task using variational inference.
753"
CLAIMS,0.7528455284552845,"Guidelines:
754"
CLAIMS,0.7536585365853659,"• The answer NA means that the abstract and introduction do not include the claims
755"
CLAIMS,0.7544715447154472,"made in the paper.
756"
CLAIMS,0.7552845528455284,"• The abstract and/or introduction should clearly state the claims made, including the
757"
CLAIMS,0.7560975609756098,"contributions made in the paper and important assumptions and limitations. A No or
758"
CLAIMS,0.7569105691056911,"NA answer to this question will not be perceived well by the reviewers.
759"
CLAIMS,0.7577235772357723,"• The claims made should match theoretical and experimental results, and reflect how
760"
CLAIMS,0.7585365853658537,"much the results can be expected to generalize to other settings.
761"
CLAIMS,0.759349593495935,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
762"
CLAIMS,0.7601626016260162,"are not attained by the paper.
763"
LIMITATIONS,0.7609756097560976,"2. Limitations
764"
LIMITATIONS,0.7617886178861789,"Question: Does the paper discuss the limitations of the work performed by the authors?
765"
LIMITATIONS,0.7626016260162601,"Answer: [Yes]
766"
LIMITATIONS,0.7634146341463415,"Justification: We discuss the limitation in the last section.
767"
LIMITATIONS,0.7642276422764228,"Guidelines:
768"
LIMITATIONS,0.765040650406504,"• The answer NA means that the paper has no limitation while the answer No means that
769"
LIMITATIONS,0.7658536585365854,"the paper has limitations, but those are not discussed in the paper.
770"
LIMITATIONS,0.7666666666666667,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
771"
LIMITATIONS,0.767479674796748,"• The paper should point out any strong assumptions and how robust the results are to
772"
LIMITATIONS,0.7682926829268293,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
773"
LIMITATIONS,0.7691056910569106,"model well-specification, asymptotic approximations only holding locally). The authors
774"
LIMITATIONS,0.7699186991869919,"should reflect on how these assumptions might be violated in practice and what the
775"
LIMITATIONS,0.7707317073170732,"implications would be.
776"
LIMITATIONS,0.7715447154471544,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
777"
LIMITATIONS,0.7723577235772358,"only tested on a few datasets or with a few runs. In general, empirical results often
778"
LIMITATIONS,0.7731707317073171,"depend on implicit assumptions, which should be articulated.
779"
LIMITATIONS,0.7739837398373983,"• The authors should reflect on the factors that influence the performance of the approach.
780"
LIMITATIONS,0.7747967479674797,"For example, a facial recognition algorithm may perform poorly when image resolution
781"
LIMITATIONS,0.775609756097561,"is low or images are taken in low lighting. Or a speech-to-text system might not be
782"
LIMITATIONS,0.7764227642276422,"used reliably to provide closed captions for online lectures because it fails to handle
783"
LIMITATIONS,0.7772357723577236,"technical jargon.
784"
LIMITATIONS,0.7780487804878049,"• The authors should discuss the computational efficiency of the proposed algorithms
785"
LIMITATIONS,0.7788617886178861,"and how they scale with dataset size.
786"
LIMITATIONS,0.7796747967479675,"• If applicable, the authors should discuss possible limitations of their approach to
787"
LIMITATIONS,0.7804878048780488,"address problems of privacy and fairness.
788"
LIMITATIONS,0.78130081300813,"• While the authors might fear that complete honesty about limitations might be used by
789"
LIMITATIONS,0.7821138211382114,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
790"
LIMITATIONS,0.7829268292682927,"limitations that aren’t acknowledged in the paper. The authors should use their best
791"
LIMITATIONS,0.7837398373983739,"judgment and recognize that individual actions in favor of transparency play an impor-
792"
LIMITATIONS,0.7845528455284553,"tant role in developing norms that preserve the integrity of the community. Reviewers
793"
LIMITATIONS,0.7853658536585366,"will be specifically instructed to not penalize honesty concerning limitations.
794"
THEORY ASSUMPTIONS AND PROOFS,0.7861788617886178,"3. Theory Assumptions and Proofs
795"
THEORY ASSUMPTIONS AND PROOFS,0.7869918699186992,"Question: For each theoretical result, does the paper provide the full set of assumptions and
796"
THEORY ASSUMPTIONS AND PROOFS,0.7878048780487805,"a complete (and correct) proof?
797"
THEORY ASSUMPTIONS AND PROOFS,0.7886178861788617,"Answer: [Yes]
798"
THEORY ASSUMPTIONS AND PROOFS,0.7894308943089431,"Justification: We provide the assumption and proofs mostly in appendix.
799"
THEORY ASSUMPTIONS AND PROOFS,0.7902439024390244,"Guidelines:
800"
THEORY ASSUMPTIONS AND PROOFS,0.7910569105691057,"• The answer NA means that the paper does not include theoretical results.
801"
THEORY ASSUMPTIONS AND PROOFS,0.791869918699187,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
802"
THEORY ASSUMPTIONS AND PROOFS,0.7926829268292683,"referenced.
803"
THEORY ASSUMPTIONS AND PROOFS,0.7934959349593496,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
804"
THEORY ASSUMPTIONS AND PROOFS,0.7943089430894309,"• The proofs can either appear in the main paper or the supplemental material, but if
805"
THEORY ASSUMPTIONS AND PROOFS,0.7951219512195122,"they appear in the supplemental material, the authors are encouraged to provide a short
806"
THEORY ASSUMPTIONS AND PROOFS,0.7959349593495935,"proof sketch to provide intuition.
807"
THEORY ASSUMPTIONS AND PROOFS,0.7967479674796748,"• Inversely, any informal proof provided in the core of the paper should be complemented
808"
THEORY ASSUMPTIONS AND PROOFS,0.7975609756097561,"by formal proofs provided in appendix or supplemental material.
809"
THEORY ASSUMPTIONS AND PROOFS,0.7983739837398374,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
810"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7991869918699187,"4. Experimental Result Reproducibility
811"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
812"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8008130081300813,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
813"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8016260162601626,"of the paper (regardless of whether the code and data are provided or not)?
814"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.802439024390244,"Answer: [Yes]
815"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8032520325203252,"Justification: We use open-source dataset and provide a anonymous code link.
816"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8040650406504065,"Guidelines:
817"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8048780487804879,"• The answer NA means that the paper does not include experiments.
818"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8056910569105691,"• If the paper includes experiments, a No answer to this question will not be perceived
819"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8065040650406504,"well by the reviewers: Making the paper reproducible is important, regardless of
820"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8073170731707318,"whether the code and data are provided or not.
821"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.808130081300813,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
822"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8089430894308943,"to make their results reproducible or verifiable.
823"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8097560975609757,"• Depending on the contribution, reproducibility can be accomplished in various ways.
824"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8105691056910569,"For example, if the contribution is a novel architecture, describing the architecture fully
825"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8113821138211382,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
826"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8121951219512196,"be necessary to either make it possible for others to replicate the model with the same
827"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8130081300813008,"dataset, or provide access to the model. In general. releasing code and data is often
828"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8138211382113821,"one good way to accomplish this, but reproducibility can also be provided via detailed
829"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8146341463414634,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
830"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8154471544715447,"of a large language model), releasing of a model checkpoint, or other means that are
831"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.816260162601626,"appropriate to the research performed.
832"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8170731707317073,"• While NeurIPS does not require releasing code, the conference does require all submis-
833"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8178861788617886,"sions to provide some reasonable avenue for reproducibility, which may depend on the
834"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8186991869918699,"nature of the contribution. For example
835"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8195121951219512,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
836"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8203252032520325,"to reproduce that algorithm.
837"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8211382113821138,"(b) If the contribution is primarily a new model architecture, the paper should describe
838"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8219512195121951,"the architecture clearly and fully.
839"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8227642276422764,"(c) If the contribution is a new model (e.g., a large language model), then there should
840"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8235772357723578,"either be a way to access this model for reproducing the results or a way to reproduce
841"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.824390243902439,"the model (e.g., with an open-source dataset or instructions for how to construct
842"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8252032520325203,"the dataset).
843"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8260162601626017,"(d) We recognize that reproducibility may be tricky in some cases, in which case
844"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8268292682926829,"authors are welcome to describe the particular way they provide for reproducibility.
845"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8276422764227642,"In the case of closed-source models, it may be that access to the model is limited in
846"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8284552845528456,"some way (e.g., to registered users), but it should be possible for other researchers
847"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.8292682926829268,"to have some path to reproducing or verifying the results.
848"
OPEN ACCESS TO DATA AND CODE,0.8300813008130081,"5. Open access to data and code
849"
OPEN ACCESS TO DATA AND CODE,0.8308943089430895,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
850"
OPEN ACCESS TO DATA AND CODE,0.8317073170731707,"tions to faithfully reproduce the main experimental results, as described in supplemental
851"
OPEN ACCESS TO DATA AND CODE,0.832520325203252,"material?
852"
OPEN ACCESS TO DATA AND CODE,0.8333333333333334,"Answer: [Yes]
853"
OPEN ACCESS TO DATA AND CODE,0.8341463414634146,"Justification: We provide the anonymous code link.
854"
OPEN ACCESS TO DATA AND CODE,0.8349593495934959,"Guidelines:
855"
OPEN ACCESS TO DATA AND CODE,0.8357723577235773,"• The answer NA means that paper does not include experiments requiring code.
856"
OPEN ACCESS TO DATA AND CODE,0.8365853658536585,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
857"
OPEN ACCESS TO DATA AND CODE,0.8373983739837398,"public/guides/CodeSubmissionPolicy) for more details.
858"
OPEN ACCESS TO DATA AND CODE,0.8382113821138212,"• While we encourage the release of code and data, we understand that this might not be
859"
OPEN ACCESS TO DATA AND CODE,0.8390243902439024,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
860"
OPEN ACCESS TO DATA AND CODE,0.8398373983739837,"including code, unless this is central to the contribution (e.g., for a new open-source
861"
OPEN ACCESS TO DATA AND CODE,0.8406504065040651,"benchmark).
862"
OPEN ACCESS TO DATA AND CODE,0.8414634146341463,"• The instructions should contain the exact command and environment needed to run to
863"
OPEN ACCESS TO DATA AND CODE,0.8422764227642277,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
864"
OPEN ACCESS TO DATA AND CODE,0.843089430894309,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
865"
OPEN ACCESS TO DATA AND CODE,0.8439024390243902,"• The authors should provide instructions on data access and preparation, including how
866"
OPEN ACCESS TO DATA AND CODE,0.8447154471544716,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
867"
OPEN ACCESS TO DATA AND CODE,0.8455284552845529,"• The authors should provide scripts to reproduce all experimental results for the new
868"
OPEN ACCESS TO DATA AND CODE,0.8463414634146341,"proposed method and baselines. If only a subset of experiments are reproducible, they
869"
OPEN ACCESS TO DATA AND CODE,0.8471544715447155,"should state which ones are omitted from the script and why.
870"
OPEN ACCESS TO DATA AND CODE,0.8479674796747968,"• At submission time, to preserve anonymity, the authors should release anonymized
871"
OPEN ACCESS TO DATA AND CODE,0.848780487804878,"versions (if applicable).
872"
OPEN ACCESS TO DATA AND CODE,0.8495934959349594,"• Providing as much information as possible in supplemental material (appended to the
873"
OPEN ACCESS TO DATA AND CODE,0.8504065040650407,"paper) is recommended, but including URLs to data and code is permitted.
874"
OPEN ACCESS TO DATA AND CODE,0.8512195121951219,"6. Experimental Setting/Details
875"
OPEN ACCESS TO DATA AND CODE,0.8520325203252033,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
876"
OPEN ACCESS TO DATA AND CODE,0.8528455284552846,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
877"
OPEN ACCESS TO DATA AND CODE,0.8536585365853658,"results?
878"
OPEN ACCESS TO DATA AND CODE,0.8544715447154472,"Answer: [Yes]
879"
OPEN ACCESS TO DATA AND CODE,0.8552845528455284,"Justification: We follow previous to set the experiments.
880"
OPEN ACCESS TO DATA AND CODE,0.8560975609756097,"Guidelines:
881"
OPEN ACCESS TO DATA AND CODE,0.8569105691056911,"• The answer NA means that the paper does not include experiments.
882"
OPEN ACCESS TO DATA AND CODE,0.8577235772357723,"• The experimental setting should be presented in the core of the paper to a level of detail
883"
OPEN ACCESS TO DATA AND CODE,0.8585365853658536,"that is necessary to appreciate the results and make sense of them.
884"
OPEN ACCESS TO DATA AND CODE,0.859349593495935,"• The full details can be provided either with the code, in appendix, or as supplemental
885"
OPEN ACCESS TO DATA AND CODE,0.8601626016260162,"material.
886"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8609756097560975,"7. Experiment Statistical Significance
887"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8617886178861789,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
888"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8626016260162601,"information about the statistical significance of the experiments?
889"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8634146341463415,"Answer: [Yes]
890"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8642276422764228,"Justification: We offer the 10 different task orders to reduce the influence of stochastic and
891"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.865040650406504,"provide the avg ± std in Appendix H.
892"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8658536585365854,"Guidelines:
893"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8666666666666667,"• The answer NA means that the paper does not include experiments.
894"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8674796747967479,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
895"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8682926829268293,"dence intervals, or statistical significance tests, at least for the experiments that support
896"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8691056910569106,"the main claims of the paper.
897"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8699186991869918,"• The factors of variability that the error bars are capturing should be clearly stated (for
898"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8707317073170732,"example, train/test split, initialization, random drawing of some parameter, or overall
899"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8715447154471545,"run with given experimental conditions).
900"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8723577235772357,"• The method for calculating the error bars should be explained (closed form formula,
901"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8731707317073171,"call to a library function, bootstrap, etc.)
902"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8739837398373984,"• The assumptions made should be given (e.g., Normally distributed errors).
903"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8747967479674796,"• It should be clear whether the error bar is the standard deviation or the standard error
904"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.875609756097561,"of the mean.
905"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8764227642276423,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
906"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8772357723577235,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
907"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8780487804878049,"of Normality of errors is not verified.
908"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8788617886178862,"• For asymmetric distributions, the authors should be careful not to show in tables or
909"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8796747967479674,"figures symmetric error bars that would yield results that are out of range (e.g. negative
910"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8804878048780488,"error rates).
911"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8813008130081301,"• If error bars are reported in tables or plots, The authors should explain in the text how
912"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8821138211382114,"they were calculated and reference the corresponding figures or tables in the text.
913"
EXPERIMENTS COMPUTE RESOURCES,0.8829268292682927,"8. Experiments Compute Resources
914"
EXPERIMENTS COMPUTE RESOURCES,0.883739837398374,"Question: For each experiment, does the paper provide sufficient information on the com-
915"
EXPERIMENTS COMPUTE RESOURCES,0.8845528455284553,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
916"
EXPERIMENTS COMPUTE RESOURCES,0.8853658536585366,"the experiments?
917"
EXPERIMENTS COMPUTE RESOURCES,0.8861788617886179,"Answer: [Yes]
918"
EXPERIMENTS COMPUTE RESOURCES,0.8869918699186992,"Justification: We provide the compute resources in Appendix K.
919"
EXPERIMENTS COMPUTE RESOURCES,0.8878048780487805,"Guidelines:
920"
EXPERIMENTS COMPUTE RESOURCES,0.8886178861788618,"• The answer NA means that the paper does not include experiments.
921"
EXPERIMENTS COMPUTE RESOURCES,0.8894308943089431,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
922"
EXPERIMENTS COMPUTE RESOURCES,0.8902439024390244,"or cloud provider, including relevant memory and storage.
923"
EXPERIMENTS COMPUTE RESOURCES,0.8910569105691057,"• The paper should provide the amount of compute required for each of the individual
924"
EXPERIMENTS COMPUTE RESOURCES,0.891869918699187,"experimental runs as well as estimate the total compute.
925"
EXPERIMENTS COMPUTE RESOURCES,0.8926829268292683,"• The paper should disclose whether the full research project required more compute
926"
EXPERIMENTS COMPUTE RESOURCES,0.8934959349593496,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
927"
EXPERIMENTS COMPUTE RESOURCES,0.8943089430894309,"didn’t make it into the paper).
928"
CODE OF ETHICS,0.8951219512195122,"9. Code Of Ethics
929"
CODE OF ETHICS,0.8959349593495934,"Question: Does the research conducted in the paper conform, in every respect, with the
930"
CODE OF ETHICS,0.8967479674796748,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
931"
CODE OF ETHICS,0.8975609756097561,"Answer: [Yes]
932"
CODE OF ETHICS,0.8983739837398373,"Justification: We confirm that we conducted in the paper conform with the NeurIPS Code of
933"
CODE OF ETHICS,0.8991869918699187,"Ethics.
934"
CODE OF ETHICS,0.9,"Guidelines:
935"
CODE OF ETHICS,0.9008130081300812,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
936"
CODE OF ETHICS,0.9016260162601626,"• If the authors answer No, they should explain the special circumstances that require a
937"
CODE OF ETHICS,0.9024390243902439,"deviation from the Code of Ethics.
938"
CODE OF ETHICS,0.9032520325203252,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
939"
CODE OF ETHICS,0.9040650406504065,"eration due to laws or regulations in their jurisdiction).
940"
BROADER IMPACTS,0.9048780487804878,"10. Broader Impacts
941"
BROADER IMPACTS,0.9056910569105691,"Question: Does the paper discuss both potential positive societal impacts and negative
942"
BROADER IMPACTS,0.9065040650406504,"societal impacts of the work performed?
943"
BROADER IMPACTS,0.9073170731707317,"Answer: [NA]
944"
BROADER IMPACTS,0.908130081300813,"Justification: Nor applicable. We study machine learning problem on public dataset such as
945"
BROADER IMPACTS,0.9089430894308943,"CIFAR10.
946"
BROADER IMPACTS,0.9097560975609756,"Guidelines:
947"
BROADER IMPACTS,0.9105691056910569,"• The answer NA means that there is no societal impact of the work performed.
948"
BROADER IMPACTS,0.9113821138211382,"• If the authors answer NA or No, they should explain why their work has no societal
949"
BROADER IMPACTS,0.9121951219512195,"impact or why the paper does not address societal impact.
950"
BROADER IMPACTS,0.9130081300813008,"• Examples of negative societal impacts include potential malicious or unintended uses
951"
BROADER IMPACTS,0.9138211382113821,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
952"
BROADER IMPACTS,0.9146341463414634,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
953"
BROADER IMPACTS,0.9154471544715447,"groups), privacy considerations, and security considerations.
954"
BROADER IMPACTS,0.916260162601626,"• The conference expects that many papers will be foundational research and not tied
955"
BROADER IMPACTS,0.9170731707317074,"to particular applications, let alone deployments. However, if there is a direct path to
956"
BROADER IMPACTS,0.9178861788617886,"any negative applications, the authors should point it out. For example, it is legitimate
957"
BROADER IMPACTS,0.9186991869918699,"to point out that an improvement in the quality of generative models could be used to
958"
BROADER IMPACTS,0.9195121951219513,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
959"
BROADER IMPACTS,0.9203252032520325,"that a generic algorithm for optimizing neural networks could enable people to train
960"
BROADER IMPACTS,0.9211382113821138,"models that generate Deepfakes faster.
961"
BROADER IMPACTS,0.9219512195121952,"• The authors should consider possible harms that could arise when the technology is
962"
BROADER IMPACTS,0.9227642276422764,"being used as intended and functioning correctly, harms that could arise when the
963"
BROADER IMPACTS,0.9235772357723577,"technology is being used as intended but gives incorrect results, and harms following
964"
BROADER IMPACTS,0.9243902439024391,"from (intentional or unintentional) misuse of the technology.
965"
BROADER IMPACTS,0.9252032520325203,"• If there are negative societal impacts, the authors could also discuss possible mitigation
966"
BROADER IMPACTS,0.9260162601626016,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
967"
BROADER IMPACTS,0.926829268292683,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
968"
BROADER IMPACTS,0.9276422764227642,"feedback over time, improving the efficiency and accessibility of ML).
969"
SAFEGUARDS,0.9284552845528455,"11. Safeguards
970"
SAFEGUARDS,0.9292682926829269,"Question: Does the paper describe safeguards that have been put in place for responsible
971"
SAFEGUARDS,0.9300813008130081,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
972"
SAFEGUARDS,0.9308943089430894,"image generators, or scraped datasets)?
973"
SAFEGUARDS,0.9317073170731708,"Answer: [NA]
974"
SAFEGUARDS,0.932520325203252,"Justification: No such risks.
975"
SAFEGUARDS,0.9333333333333333,"Guidelines:
976"
SAFEGUARDS,0.9341463414634147,"• The answer NA means that the paper poses no such risks.
977"
SAFEGUARDS,0.9349593495934959,"• Released models that have a high risk for misuse or dual-use should be released with
978"
SAFEGUARDS,0.9357723577235773,"necessary safeguards to allow for controlled use of the model, for example by requiring
979"
SAFEGUARDS,0.9365853658536586,"that users adhere to usage guidelines or restrictions to access the model or implementing
980"
SAFEGUARDS,0.9373983739837398,"safety filters.
981"
SAFEGUARDS,0.9382113821138212,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
982"
SAFEGUARDS,0.9390243902439024,"should describe how they avoided releasing unsafe images.
983"
SAFEGUARDS,0.9398373983739837,"• We recognize that providing effective safeguards is challenging, and many papers do
984"
SAFEGUARDS,0.9406504065040651,"not require this, but we encourage authors to take this into account and make a best
985"
SAFEGUARDS,0.9414634146341463,"faith effort.
986"
LICENSES FOR EXISTING ASSETS,0.9422764227642276,"12. Licenses for existing assets
987"
LICENSES FOR EXISTING ASSETS,0.943089430894309,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
988"
LICENSES FOR EXISTING ASSETS,0.9439024390243902,"the paper, properly credited and are the license and terms of use explicitly mentioned and
989"
LICENSES FOR EXISTING ASSETS,0.9447154471544715,"properly respected?
990"
LICENSES FOR EXISTING ASSETS,0.9455284552845529,"Answer: [Yes]
991"
LICENSES FOR EXISTING ASSETS,0.9463414634146341,"Justification: We referred to open-source code from various methods and developed our own
992"
LICENSES FOR EXISTING ASSETS,0.9471544715447154,"implementation of the core algorithm.
993"
LICENSES FOR EXISTING ASSETS,0.9479674796747968,"Guidelines:
994"
LICENSES FOR EXISTING ASSETS,0.948780487804878,"• The answer NA means that the paper does not use existing assets.
995"
LICENSES FOR EXISTING ASSETS,0.9495934959349593,"• The authors should cite the original paper that produced the code package or dataset.
996"
LICENSES FOR EXISTING ASSETS,0.9504065040650407,"• The authors should state which version of the asset is used and, if possible, include a
997"
LICENSES FOR EXISTING ASSETS,0.9512195121951219,"URL.
998"
LICENSES FOR EXISTING ASSETS,0.9520325203252032,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
999"
LICENSES FOR EXISTING ASSETS,0.9528455284552846,"• For scraped data from a particular source (e.g., website), the copyright and terms of
1000"
LICENSES FOR EXISTING ASSETS,0.9536585365853658,"service of that source should be provided.
1001"
LICENSES FOR EXISTING ASSETS,0.9544715447154472,"• If assets are released, the license, copyright information, and terms of use in the
1002"
LICENSES FOR EXISTING ASSETS,0.9552845528455285,"package should be provided. For popular datasets, paperswithcode.com/datasets
1003"
LICENSES FOR EXISTING ASSETS,0.9560975609756097,"has curated licenses for some datasets. Their licensing guide can help determine the
1004"
LICENSES FOR EXISTING ASSETS,0.9569105691056911,"license of a dataset.
1005"
LICENSES FOR EXISTING ASSETS,0.9577235772357724,"• For existing datasets that are re-packaged, both the original license and the license of
1006"
LICENSES FOR EXISTING ASSETS,0.9585365853658536,"the derived asset (if it has changed) should be provided.
1007"
LICENSES FOR EXISTING ASSETS,0.959349593495935,"• If this information is not available online, the authors are encouraged to reach out to
1008"
LICENSES FOR EXISTING ASSETS,0.9601626016260163,"the asset’s creators.
1009"
NEW ASSETS,0.9609756097560975,"13. New Assets
1010"
NEW ASSETS,0.9617886178861789,"Question: Are new assets introduced in the paper well documented and is the documentation
1011"
NEW ASSETS,0.9626016260162602,"provided alongside the assets?
1012"
NEW ASSETS,0.9634146341463414,"Answer: [NA]
1013"
NEW ASSETS,0.9642276422764228,"Justification: No new assets will be released.
1014"
NEW ASSETS,0.9650406504065041,"Guidelines:
1015"
NEW ASSETS,0.9658536585365853,"• The answer NA means that the paper does not release new assets.
1016"
NEW ASSETS,0.9666666666666667,"• Researchers should communicate the details of the dataset/code/model as part of their
1017"
NEW ASSETS,0.967479674796748,"submissions via structured templates. This includes details about training, license,
1018"
NEW ASSETS,0.9682926829268292,"limitations, etc.
1019"
NEW ASSETS,0.9691056910569106,"• The paper should discuss whether and how consent was obtained from people whose
1020"
NEW ASSETS,0.9699186991869919,"asset is used.
1021"
NEW ASSETS,0.9707317073170731,"• At submission time, remember to anonymize your assets (if applicable). You can either
1022"
NEW ASSETS,0.9715447154471545,"create an anonymized URL or include an anonymized zip file.
1023"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9723577235772358,"14. Crowdsourcing and Research with Human Subjects
1024"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.973170731707317,"Question: For crowdsourcing experiments and research with human subjects, does the paper
1025"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9739837398373984,"include the full text of instructions given to participants and screenshots, if applicable, as
1026"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9747967479674797,"well as details about compensation (if any)?
1027"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.975609756097561,"Answer: [NA]
1028"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9764227642276423,"Justification: We use public dataset.
1029"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9772357723577236,"Guidelines:
1030"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9780487804878049,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1031"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9788617886178862,"human subjects.
1032"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9796747967479674,"• Including this information in the supplemental material is fine, but if the main contribu-
1033"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9804878048780488,"tion of the paper involves human subjects, then as much detail as possible should be
1034"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9813008130081301,"included in the main paper.
1035"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9821138211382113,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
1036"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9829268292682927,"or other labor should be paid at least the minimum wage in the country of the data
1037"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.983739837398374,"collector.
1038"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9845528455284552,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
1039"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9853658536585366,"Subjects
1040"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9861788617886179,"Question: Does the paper describe potential risks incurred by study participants, whether
1041"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9869918699186991,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
1042"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9878048780487805,"approvals (or an equivalent approval/review based on the requirements of your country or
1043"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9886178861788618,"institution) were obtained?
1044"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.989430894308943,"Answer: [NA]
1045"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9902439024390244,"Justification: We do not involve crowdsourcing nor research with human subjects.
1046"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9910569105691057,"Guidelines:
1047"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.991869918699187,"• The answer NA means that the paper does not involve crowdsourcing nor research with
1048"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9926829268292683,"human subjects.
1049"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9934959349593496,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
1050"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9943089430894309,"may be required for any human subjects research. If you obtained IRB approval, you
1051"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9951219512195122,"should clearly state this in the paper.
1052"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9959349593495935,"• We recognize that the procedures for this may vary significantly between institutions
1053"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9967479674796748,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
1054"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9975609756097561,"guidelines for their institution.
1055"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9983739837398374,"• For initial submissions, do not include any information that would break anonymity (if
1056"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9991869918699187,"applicable), such as the institution conducting the review.
1057"
