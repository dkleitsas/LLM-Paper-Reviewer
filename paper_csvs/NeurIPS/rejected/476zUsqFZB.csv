Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0013175230566534915,"In recent years, deep learning methods have been widely applied to chemical
1"
ABSTRACT,0.002635046113306983,"reaction prediction due to the time consuming and resource intensive nature of
2"
ABSTRACT,0.003952569169960474,"designing synthetic pathways. However, with the majority of models being trained
3"
ABSTRACT,0.005270092226613966,"on the US Patent Office dataset, many proposed architectures lack interpretability
4"
ABSTRACT,0.006587615283267457,"by modeling chemical reactions as overall transformations. These models map
5"
ABSTRACT,0.007905138339920948,"directly from reactants to products, and provide minimal insight into the underlying
6"
ABSTRACT,0.00922266139657444,"driving forces of a reaction. In order to improve interpretrability and provide
7"
ABSTRACT,0.010540184453227932,"insight into the causality of a chemical reaction, we train various machine learning
8"
ABSTRACT,0.011857707509881422,"frameworks on the PMechDB dataset. This dataset contains polar elementary
9"
ABSTRACT,0.013175230566534914,"steps, which model chemical reactions as a sequence of steps associated with
10"
ABSTRACT,0.014492753623188406,"movements of electrons. Through training on PMechDB, we have created a new
11"
ABSTRACT,0.015810276679841896,"system for polar mechanistic reaction prediction: PMechRP. Our findings indicate
12"
ABSTRACT,0.017127799736495388,"that PMechRP is able to provide both accurate and interpretrable predictions, with
13"
ABSTRACT,0.01844532279314888,"a novel two-step transformer based method achieving the highest top-5 accuracy at
14"
ABSTRACT,0.019762845849802372,"89.9%.
15"
INTRODUCTION,0.021080368906455864,"1
Introduction
16"
INTRODUCTION,0.022397891963109356,"Two main approaches exist for the prediction of chemical reactions: machine learning based methods,
17"
INTRODUCTION,0.023715415019762844,"and quantum chemistry based methods [1, 13, 5, 8]. While quantum chemistry models offer detailed
18"
INTRODUCTION,0.025032938076416336,"prediction of chemical properties, their computational demands render them feasible only for a
19"
INTRODUCTION,0.026350461133069828,"limited scope of reaction systems, precluding their use for broad-spectrum, high-throughput reaction
20"
INTRODUCTION,0.02766798418972332,"prediction. Conversely, ML models offer computational efficiency and scalability, making them
21"
INTRODUCTION,0.028985507246376812,"well-suited for application across larger chemical systems and datasets. Countless ML models have
22"
INTRODUCTION,0.030303030303030304,"been devised for tasks such as reaction yield prediction [16], reaction classification [14], chemical
23"
INTRODUCTION,0.03162055335968379,"property prediction [4, 2], and both forward and reverse reaction prediction [6, 20, 3, 10].
24 25"
INTRODUCTION,0.03293807641633729,"Although ML models offer a high-throughput and highly adaptable chemical prediction, a significant
26"
INTRODUCTION,0.034255599472990776,"drawback lies in their lack of interpretability when compared to quantum chemistry or simulation
27"
INTRODUCTION,0.03557312252964427,"based methods. The predominant approach of predicting reactions as overall transformations results
28"
INTRODUCTION,0.03689064558629776,"in a black-box scenario, where predicted products emerge directly from reactants without insight into
29"
INTRODUCTION,0.03820816864295125,"intermediate transition states. Although these models may achieve high accuracy on datasets like
30"
INTRODUCTION,0.039525691699604744,"the US Patent Office dataset [11], their outputs pose challenges for organic chemists, who typically
31"
INTRODUCTION,0.04084321475625823,"reason through chemical synthesis via arrow-pushing mechanisms rather than overall transformations.
32"
INTRODUCTION,0.04216073781291173,"An example of a overall transformation vs a mechanistic elementary step approach can be seen in
33"
INTRODUCTION,0.043478260869565216,"Figure 1. The elementary step approach breaks the overall transformation down into a sequence of
34"
INTRODUCTION,0.04479578392621871,"arrow pushing steps, which illustrate the flow of electrons and the shifting of atoms.
35 O CF3"
INTRODUCTION,0.0461133069828722,"CN
H2NOC F S N
N H2NOC F NH CO2Me CF3 CN S N
C O CF3"
INTRODUCTION,0.04743083003952569,"CN
H2NOC F S N
N OMe .. H2NOC F NH CO2Me CF3 CN S"
INTRODUCTION,0.048748353096179184,"N
C
.. H2NOC F N CO2Me N S
CN CF3 H S+ O- S+
-O"
INTRODUCTION,0.05006587615283267,"S+
-O.. H2NOC F N
N S
CN CF3 S+
HO .. O"
INTRODUCTION,0.05138339920948617,"OMe
:
O CF3"
INTRODUCTION,0.052700922266139656,"CN
H2NOC F S N
N S+
HO S+
HO -OMe"
INTRODUCTION,0.05401844532279315,enzalutamide 95 °C
INTRODUCTION,0.05533596837944664,OVERALL TRANSFORMATION
INTRODUCTION,0.05665349143610013,Stepwise arrow-pushing mechanism
INTRODUCTION,0.057971014492753624,"sales > $6 billion / yr
(anti-cancer)"
INTRODUCTION,0.05928853754940711,"Figure 1: Example of an overall transformation vs an elementary step approach. This is a the final
reaction step in the synthesis of enzalutamide, a drug used to treat prostate cancer that generates over
$6 billion a year in revenue [21]."
INTRODUCTION,0.06060606060606061,"By thinking about reactions as occurring through many elementary steps, organic chemists are
36"
INTRODUCTION,0.061923583662714096,"able to reason about the underlying driving forces of a reaction. When training ML models to
37"
INTRODUCTION,0.06324110671936758,"forecast elementary step reactions, we effectively guide them to emulate an organic chemists’ thought
38"
INTRODUCTION,0.06455862977602109,"processes, thereby generating predictions that are readily interpretable and serve as practical aids for
39"
INTRODUCTION,0.06587615283267458,"organic synthesis design.
40"
DATA,0.06719367588932806,"2
Data
41"
DATA,0.06851119894598155,"To develop predictive models for polar reaction mechanisms, we undertook training on the recently
42"
DATA,0.06982872200263504,"introduced PMechDB dataset. This dataset comprises more than 12,700 polar elementary steps,
43"
DATA,0.07114624505928854,"each balanced, partially atom mapped, and manually verified by a team of organic chemists. Each
44"
DATA,0.07246376811594203,"reaction represents a single elementary step polar reaction. These entries have been collected through
45"
DATA,0.07378129117259552,"manual curation from a diverse array of chemistry literature and textbooks [19]. These reactions
46"
DATA,0.07509881422924901,"are stored as smiles strings, and notably, the reactions contain arrow pushing information, providing
47"
DATA,0.0764163372859025,"insights into the reactivity of individual atoms within each reaction. Leveraging the manually curated
48"
DATA,0.077733860342556,"reactions within the dataset, we conducted an 80/10/10 train/val/test split via random sampling from
49"
DATA,0.07905138339920949,"the ""manually_curated_all.csv"" file. For models which perform cross-validation, the validation data
50"
DATA,0.08036890645586298,"was combined with the training data.
51"
METHODS,0.08168642951251646,"3
Methods
52"
METHODS,0.08300395256916997,"Here we describe two different machine learning approaches for predicting polar elementary step
53"
METHODS,0.08432147562582346,"mechanisms. Namely, we describe the reactive atom two-step approach, the single-step seq-to-seq
54"
METHODS,0.08563899868247694,"prediction methods, and a spectator focused two-step transformer method.
55"
TWO-STEP PREDICTION,0.08695652173913043,"3.1
Two-Step Prediction
56"
TWO-STEP PREDICTION,0.08827404479578392,"The two-step prediction model comprises distinct phases. Initially, the model undertakes the task
57"
TWO-STEP PREDICTION,0.08959156785243742,"of predicting reactive atoms within the given reaction. Subsequently, these identified reactive sites
58"
TWO-STEP PREDICTION,0.09090909090909091,"are paired to formulate potential reaction mechanisms, followed by the application of a ranker
59"
TWO-STEP PREDICTION,0.0922266139657444,"model to rank the plausibility of these proposed mechanisms. This architectural design yields
60"
TWO-STEP PREDICTION,0.09354413702239789,"highly interpretable predictions, enabling a granular understanding of the model’s rationale. When
61"
TWO-STEP PREDICTION,0.09486166007905138,"generating predictions, users can discern precisely which atoms are deemed reactive, and they can
62"
TWO-STEP PREDICTION,0.09617918313570488,"view the precise arrow-pushing mechanism predicted by the model. From the view point of organic
63"
TWO-STEP PREDICTION,0.09749670619235837,"chemists, the two-step architecture offers greater transparency compared to single-step approaches,
64"
TWO-STEP PREDICTION,0.09881422924901186,"as the arrow pushing mechanism provides justification for why the final products were predicted.
65"
SIAMESE ARCHITECTURE,0.10013175230566534,"3.1.1
Siamese Architecture
66"
SIAMESE ARCHITECTURE,0.10144927536231885,"The two-step siamese architecture [6] comprises three distinct models, each serving a specific function.
67"
SIAMESE ARCHITECTURE,0.10276679841897234,"Initially, two separate reactive atom predictor models are instantiated. One model is specifically
68"
SIAMESE ARCHITECTURE,0.10408432147562582,"trained for predicting source atoms, while the other is trained for predicting sink atoms. To train
69"
SIAMESE ARCHITECTURE,0.10540184453227931,"the source and sink models, the electron-donating atom from the intermolecular arrow is labeled
70"
SIAMESE ARCHITECTURE,0.1067193675889328,"as the source atom, while the electron-accepting atom is labeled as the sink atom. This labeling
71"
SIAMESE ARCHITECTURE,0.1080368906455863,"process employs the reactive sites identification method as detailed in [6]. Atoms are represented
72"
SIAMESE ARCHITECTURE,0.10935441370223979,"by continuous vectors derived from predefined atomic and graph-topological features, utilizing a
73"
SIAMESE ARCHITECTURE,0.11067193675889328,"neighborhood of size 3. Subsequently, both source and sink classifiers are trained to categorize these
74"
SIAMESE ARCHITECTURE,0.11198945981554677,"feature vectors accordingly. After the trained reactive atom classifiers predict source and sink atoms,
75"
SIAMESE ARCHITECTURE,0.11330698287220026,"these atoms are paired together to enumerate possible arrow pushing mechanisms. Afterwards, a
76"
SIAMESE ARCHITECTURE,0.11462450592885376,"siamese architecture is used as a plasubility ranker model, which then ranks the plausibility of each
77"
SIAMESE ARCHITECTURE,0.11594202898550725,"potential mechanism to generate a final set of predictions. A visual representation of the source and
78"
SIAMESE ARCHITECTURE,0.11725955204216074,"sink pair is provided in Figure 2.
79"
ORBCHAIN,0.11857707509881422,"3.1.2
OrbChain
80"
ORBCHAIN,0.11989459815546773,"A polar elementary step reaction Rxn can be modeled as the following: a set of reactant molecules
81"
ORBCHAIN,0.12121212121212122,"R = {r0, r1, . . . , rn}, a set of product molecules P = {p0, p1, . . . , pn}, and a set of arrows α =
82"
ORBCHAIN,0.1225296442687747,"{a0, a1, . . . , am}, which transforms R into P. We consider a molecular orbital (MO) m(∗)
i
to be
83"
ORBCHAIN,0.12384716732542819,"associated with four parameters: m = (a,e,n,c), where a represents the atom corresponding to the
84"
ORBCHAIN,0.1251646903820817,"molecular orbital, e denotes the number of electrons contained in the MO, n corresponds to the atom
85"
ORBCHAIN,0.12648221343873517,"adjacent to atom a in the case of a bond orbital, and c represents a possible chain of filled or unfilled
86"
ORBCHAIN,0.12779973649538867,"MOs. Based on the methods described in [6, 9, 18], we model a polar mechanism as an interaction
87"
ORBCHAIN,0.12911725955204217,"between two reactive molecular orbitals (m(∗)
1 , m(∗)
2 ), where one orbital is the ""source"" orbital and
88"
ORBCHAIN,0.13043478260869565,"acts as a nucleophile, while the other orbital is the ""sink"" orbital and acts as the electrophile. Given
89"
ORBCHAIN,0.13175230566534915,"atom mapped reactants and products, and A, we can uniquely determine the reactive pair of orbitals
90"
ORBCHAIN,0.13306982872200263,"in R used to create P. Conversely, given the reactive pair of orbitals (m(∗)
1 , m(∗)
2 ) and the reactants R,
91"
ORBCHAIN,0.13438735177865613,"we can generate P given R.
92"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.13570487483530963,"3.1.3
Reactive Atom Prediction and Plausibility Ranking
93"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.1370223978919631,"We enumerate over all molecular orbitals found in reactants R, and divide orbitals into reactive
94"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.1383399209486166,"and non-reactive orbitals. These positive and negative examples are used to train the source and
95"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.13965744400527008,"sink identification models. Rather than directly predicting the reactive MOs, we perform a binary
96"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.14097496706192358,"classification prediction on the label of atom a, which is associated with the molecular orbital. We
97"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.1422924901185771,"adopt the reactive sites identification method from [6] and represent atoms using continuous vectors
98"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.14361001317523056,"becased on predefined graph-topological and physiochemical features. We train two models: a source
99"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.14492753623188406,"model and a sink model. The source model predicts a binary classification label for whether or not an
100"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.14624505928853754,"atom is a source, while the sink predicts a binary classification for whether or not an atom is a sink.
101"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.14756258234519104,"The training data was constructed by extracting the labeled source, and the labeled sink atom from
102"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.14888010540184454,"each reaction as positive examples, and then randomly sampling non-source or non-sink examples to
103"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.15019762845849802,"use as negative examples.
104 C O Br- O Br + H 10
20"
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.15151515151515152,C[CH+:20]CCOC.[Br-:10]>>C[CH:20](CCOC)[Br:10] 10=20
REACTIVE ATOM PREDICTION AND PLAUSIBILITY RANKING,0.152832674571805,"Figure 2: An example of a simple polar elementary step. The electron pushing arrows can be seen in
blue, while the source and sink sites are seen in red. The bromine atom labeled 10 is the source atom.
The carbon atom labeled 20 is the sink atom. The corresponding SMILES string and arrow codes can
be seen below."
PLAUSIBILITY RANKING,0.1541501976284585,"3.2
Plausibility Ranking
105"
PLAUSIBILITY RANKING,0.155467720685112,"Once a set of source atoms and sink atoms are predicted, these two sets are paired together to generate
106"
PLAUSIBILITY RANKING,0.15678524374176547,"pairs of molecular orbitals. A siamese network is used to rank the resulting molecular orbital pairs to
107"
PLAUSIBILITY RANKING,0.15810276679841898,"generate the final reaction mechanism predictions.
108"
SEQ-TO-SEQ PREDICTION,0.15942028985507245,"3.3
Seq-to-seq Prediction
109"
SEQ-TO-SEQ PREDICTION,0.16073781291172595,"In addition to exploring two-step models, we also explore the performance of text-based models. An
110"
SEQ-TO-SEQ PREDICTION,0.16205533596837945,"exceedingly common representation of chemical reactions is in the form of SMILES strings (simplified
111"
SEQ-TO-SEQ PREDICTION,0.16337285902503293,"molecular-input line-entry system), which is a text-based representation. This representation lends
112"
SEQ-TO-SEQ PREDICTION,0.16469038208168643,"itself towards NLP models such as transformers. These architectures model reaction prediction as a
113"
SEQ-TO-SEQ PREDICTION,0.16600790513833993,"translation problem, wherein they are translating from reactant SMILES to product SMILES. These
114"
SEQ-TO-SEQ PREDICTION,0.1673254281949934,"models have achieved state-of-the-art accuracies when predicting overall chemical transformations.
115"
SEQ-TO-SEQ PREDICTION,0.1686429512516469,"However, these models possess several drawbacks in that they are more difficult to interpret and do
116"
SEQ-TO-SEQ PREDICTION,0.16996047430830039,"not explicitly encode important molecular information such as invariance to atom permutations. This
117"
SEQ-TO-SEQ PREDICTION,0.1712779973649539,"means that the same reaction can be represented by a large number of different SMILES strings, and
118"
SEQ-TO-SEQ PREDICTION,0.1725955204216074,"additional strategies such as data augmentation may be needed to prevent a transformer model from
119"
SEQ-TO-SEQ PREDICTION,0.17391304347826086,"making different predictions for identical sets of reactants.
120"
MOLECULAR TRANSFORMER,0.17523056653491437,"3.3.1
Molecular Transformer
121"
MOLECULAR TRANSFORMER,0.17654808959156784,"We utilize the innovative text-based reaction predictor, Molecular Transformer [15], which employs a
122"
MOLECULAR TRANSFORMER,0.17786561264822134,"bidirectional encoder and autoregressive decoder coupled with a fully connected network to generate
123"
MOLECULAR TRANSFORMER,0.17918313570487485,"probability distributions over potential tokens. The pre-trained Molecular Transformers underwent
124"
MOLECULAR TRANSFORMER,0.18050065876152832,"training using various versions of the USPTO dataset. We did not separate reactants and reagents,
125"
MOLECULAR TRANSFORMER,0.18181818181818182,"so the model pre-trained using the USPTO_MIT_mixed dataset was selected and subsequently fine
126"
MOLECULAR TRANSFORMER,0.1831357048748353,"tuned on the PMechDB dataset.
127"
CHEMFORMER,0.1844532279314888,"3.3.2
Chemformer
128"
CHEMFORMER,0.1857707509881423,"In addition to the molecular transformer, we also adopt the Chemformer model [7], which is another
129"
CHEMFORMER,0.18708827404479578,"transformer-based reaction predictor. The Chemformer model also employs a bidirectional encoder
130"
CHEMFORMER,0.18840579710144928,"and autoregressive decoder with a fully connected network to generate probability distributions
131"
CHEMFORMER,0.18972332015810275,"over potential tokens. The Chemformer model was pre-trained on molecular reconstruction and
132"
CHEMFORMER,0.19104084321475626,"classification tasks using a dataset of 100M SMILES strings from the ZINC-15 [17] dataset. Af-
133"
CHEMFORMER,0.19235836627140976,"terwards, the model was fine-tuned on various downstream tasks including forward prediction and
134"
CHEMFORMER,0.19367588932806323,"retrosynthesis. The pre-training substantially improved the model’s generalizability and convergence
135"
CHEMFORMER,0.19499341238471674,"times on downstream tasks, such as USPTO forward prediction, compared to randomly initialized
136"
CHEMFORMER,0.1963109354413702,"models. We chose to start from the model fine-tuned on USPTO-mixed since reactants and reagents
137"
CHEMFORMER,0.1976284584980237,"are not separated in the PMechDB dataset. This model was subsequently fine-tuned on the PMechDB
138"
CHEMFORMER,0.19894598155467721,"dataset for mechanistic-level predictions. The vocabulary of the model was expanded by 66 tokens to
139"
CHEMFORMER,0.2002635046113307,"account for unseen atoms in the PMechDB dataset.
140"
TWO-STEP TRANSFORMER ARCHITECTURE,0.2015810276679842,"3.3.3
Two-Step Transformer Architecture
141"
TWO-STEP TRANSFORMER ARCHITECTURE,0.2028985507246377,"During experiments, all models were observed to exhibit a significant decrease in performance
142"
TWO-STEP TRANSFORMER ARCHITECTURE,0.20421607378129117,"in reaction prediction as the size of the reactants grows. A quantitative analysis of the effects
143"
TWO-STEP TRANSFORMER ARCHITECTURE,0.20553359683794467,"of spectators, and the number of atoms can be found in Figure 5 and Figure 6 respectively. To
144"
TWO-STEP TRANSFORMER ARCHITECTURE,0.20685111989459815,"combat this, we propose a novel two-step architecture for transformers. Firstly, we use the source
145"
TWO-STEP TRANSFORMER ARCHITECTURE,0.20816864295125165,"and sink reactive atom models from the siamese architecture to predict top-2 reactive atoms of
146"
TWO-STEP TRANSFORMER ARCHITECTURE,0.20948616600790515,"the model. Reactant molecules which contain the predicted reactive atoms are considered to be
147"
TWO-STEP TRANSFORMER ARCHITECTURE,0.21080368906455862,"non-spectator molecules. Since we take top-2 predictions from the source and sink models, we
148"
TWO-STEP TRANSFORMER ARCHITECTURE,0.21212121212121213,"predict at most 2 sink molecules, and at most 2 source molecules. Pairing the sinks and sources
149"
TWO-STEP TRANSFORMER ARCHITECTURE,0.2134387351778656,"together, we can have at most 4-unique source-sink combinations. After the combinations are
150"
TWO-STEP TRANSFORMER ARCHITECTURE,0.2147562582345191,"generated, we run a top-5 prediction using our best performing transformer on each combination.
151"
TWO-STEP TRANSFORMER ARCHITECTURE,0.2160737812911726,"Hence a fine-tuned chemformer model was used on each combination, as well as on the original
152"
TWO-STEP TRANSFORMER ARCHITECTURE,0.21739130434782608,"reactants. After generating predictions for the source-sink combinations, the molecules which were
153"
TWO-STEP TRANSFORMER ARCHITECTURE,0.21870882740447958,"deemed as spectators and removed are added back into the predicted products. If there are fewer than
154"
TWO-STEP TRANSFORMER ARCHITECTURE,0.22002635046113306,"4-unique source-sink combinations, more predictions are made on the original reactants until 5 total
155"
TWO-STEP TRANSFORMER ARCHITECTURE,0.22134387351778656,"predictions are generated. For each reaction, we take the output predictions, canonicalize them, and
156"
TWO-STEP TRANSFORMER ARCHITECTURE,0.22266139657444006,"then perform a simple majority vote with ties being broken randomly.
157 158 159"
TWO-STEP TRANSFORMER ARCHITECTURE,0.22397891963109354,"This architecture takes inspiration from common practices in organic chemistry. Often times when
160"
TWO-STEP TRANSFORMER ARCHITECTURE,0.22529644268774704,"an organic chemist aims to predict the outcome of a set of reactants, they quickly look through all
161"
TWO-STEP TRANSFORMER ARCHITECTURE,0.22661396574440051,"reactant molecules, and filter away molecules which are likely to be spectators or non-reactive, before
162"
TWO-STEP TRANSFORMER ARCHITECTURE,0.22793148880105402,"focusing on a few molecules of interest. By performing a two-step prediction, we are able to first
163"
TWO-STEP TRANSFORMER ARCHITECTURE,0.22924901185770752,"filter away potential spectator ions, then predict the reaction mechanism after reducing the space of
164"
TWO-STEP TRANSFORMER ARCHITECTURE,0.230566534914361,"possible reactions exponentially. A considerable performance increase was observed after performing
165"
TWO-STEP TRANSFORMER ARCHITECTURE,0.2318840579710145,"this method of ensembling. The results can be seen in Table 3 and Table 4.
166"
MULTI-TASK LEARNING,0.233201581027668,"3.4
Multi-task learning
167"
MULTI-TASK LEARNING,0.23451910408432147,"Due to the highly related nature of many chemistry prediction tasks, multitask learning can be used to
168"
MULTI-TASK LEARNING,0.23583662714097497,"develop robust models which may demonstrate improved learning efficiency and prediction accuracy.
169"
MULTI-TASK LEARNING,0.23715415019762845,"T5Chem is one such model, which leverages multitask learning on a transformer architecture to
170"
MULTI-TASK LEARNING,0.23847167325428195,"perform 5 different tasks. The T5Chem multi-task transformer architecture is able to perform for-
171"
MULTI-TASK LEARNING,0.23978919631093545,"ward/backwards prediction, reaction yield prediction, reaction classification, and reagents prediction
172"
MULTI-TASK LEARNING,0.24110671936758893,"[12]. This architecture was first pretrained with a BERT-like MLM objective on 97 million PubChem
173"
MULTI-TASK LEARNING,0.24242424242424243,"molecules. Then, the model was further fine-tuned on 5 different tasks using the USPTO_500_MT
174"
MULTI-TASK LEARNING,0.2437417654808959,"dataset. We selected this model, and fine-tuned it using the 80/10/10 split of the manually curated
175"
MULTI-TASK LEARNING,0.2450592885375494,"PMechDB reactions.
176"
RESULTS AND DISCUSSION,0.2463768115942029,"4
Results and Discussion
177"
PERFORMANCE ON PMECHDB DATASET,0.24769433465085638,"4.1
Performance on PMechDB Dataset
178"
PERFORMANCE ON PMECHDB DATASET,0.2490118577075099,"We assess the performance of the two-step prediction method, comprising reactive sites identification
179"
PERFORMANCE ON PMECHDB DATASET,0.2503293807641634,"and plausibility ranking. The top-N accuracy of the reactive sites identification on PMechDB is
180"
PERFORMANCE ON PMECHDB DATASET,0.2516469038208169,"presented in Table 7. Reactive site identification is considered correct if both the source and sink
181"
PERFORMANCE ON PMECHDB DATASET,0.25296442687747034,"atom were correctly identified within the top-N predictions of each model.
182"
PERFORMANCE ON PMECHDB DATASET,0.25428194993412384,Table 1: Reactive Atom Classification for Siamese Architecture
PERFORMANCE ON PMECHDB DATASET,0.25559947299077734,"Top-1
Top-2
Top-3
Top-5
Top-10"
PERFORMANCE ON PMECHDB DATASET,0.25691699604743085,"53.8
79.0
86.8
91.8
94.4"
PERFORMANCE ON PMECHDB DATASET,0.25823451910408435,"The source and sink ranking models are able to predict the reactive atoms with relatively high
183"
PERFORMANCE ON PMECHDB DATASET,0.2595520421607378,"accuracy. Although the reactive atom models are able to filter down the number of potentially reactive
184"
PERFORMANCE ON PMECHDB DATASET,0.2608695652173913,"atoms significantly, due to the large number of atoms and aromatic structures contained in the polar
185"
PERFORMANCE ON PMECHDB DATASET,0.2621870882740448,"reactions, enumerating all possible molecular orbital pairs leads to a large number of possible reaction
186"
PERFORMANCE ON PMECHDB DATASET,0.2635046113306983,"mechanisms fed into the ranker model. Several reaction fingerprints were used for plausibility ranking.
187"
PERFORMANCE ON PMECHDB DATASET,0.2648221343873518,"The results can be found in Table 2.
188"
PERFORMANCE ON PMECHDB DATASET,0.26613965744400525,Table 2: Plausibility Ranking for Two-Step Architecture
PERFORMANCE ON PMECHDB DATASET,0.26745718050065875,"Model Type
Top-1
Top-2
Top-3
Top-4
Top-5"
PERFORMANCE ON PMECHDB DATASET,0.26877470355731226,"reactionFP
39.5
56.3
65.6
70.3
73.0
DRFP
37.3
52.2
60.1
67.1
72.5
rxnfp
35.1
51.3
60.5
66.1
70.0"
PERFORMANCE ON PMECHDB DATASET,0.27009222661396576,"In order to perform two-step prediction, both reactive site identification and plausibility ranking must
189"
PERFORMANCE ON PMECHDB DATASET,0.27140974967061926,"be performed. Thus for the best performing two-step model, we use the reactionFP fingerprint for
190"
PERFORMANCE ON PMECHDB DATASET,0.2727272727272727,"plausibility ranking. Therefore in Table 3, we consider this as the best two-step siamese model. For
191"
PERFORMANCE ON PMECHDB DATASET,0.2740447957839262,"the Chemformer, MolTransformer, and T5Chem models, we fine-tuned the pretrained models on the
192"
PERFORMANCE ON PMECHDB DATASET,0.2753623188405797,"PMechDB datset. The results comparing all the trained models can be seen in Table 3
193"
PERFORMANCE ON PMECHDB DATASET,0.2766798418972332,Table 3: Top-N Accuracy of Trained Models
PERFORMANCE ON PMECHDB DATASET,0.2779973649538867,"Model Type
Top-1
Top-3
Top-5
Top-10"
PERFORMANCE ON PMECHDB DATASET,0.27931488801054016,"Best Two-Step Siamese
39.5
65.6
73.0
76.6
MolTransformer
59.1
66.3
69.2
70.1
T5Chem
56.6
69.1
73.7
77.5
Chemformer
74.0
84.1
85.2
87.2
Two-Step Transformer
80.6
88.8
89.9
91.0"
PERFORMANCE ON PMECHDB DATASET,0.28063241106719367,"Although the Siamese two-step model allows for improved interpretability due to its direct prediction
194"
PERFORMANCE ON PMECHDB DATASET,0.28194993412384717,"of arrows, the models based on Chemformer yield the most accurate predictions, with the two-step
195"
PERFORMANCE ON PMECHDB DATASET,0.28326745718050067,"transformer model outperforming all other models significantly. The effects of various ensemble
196"
PERFORMANCE ON PMECHDB DATASET,0.2845849802371542,"sizes can be seen in Table 4.
197"
PERFORMANCE ON PMECHDB DATASET,0.2859025032938076,Table 4: Effects of Ensemble Size on Top-N Accuracy
PERFORMANCE ON PMECHDB DATASET,0.2872200263504611,"ensemblesize
Top-1
Top-3
Top-5
Top-10"
PERFORMANCE ON PMECHDB DATASET,0.2885375494071146,"2
71.8
85.8
86.9
87.7
3
77.8
87.5
88.5
89.2
4
79.8
88.7
90.0
90.7
5
80.6
88.8
89.9
91.0"
PRETRAINING,0.2898550724637681,"4.1.1
Pretraining
198"
PRETRAINING,0.29117259552042163,"Pretraining the Chemformer models made a large difference in performance, the effects of pretraining
199"
PRETRAINING,0.2924901185770751,"can be seen in Table 5.
200"
PRETRAINING,0.2938076416337286,"The large increase in performance from the pretraining, indicates overlap between the USPTO
201"
PRETRAINING,0.2951251646903821,"dataset and the PMechDB dataset. This is in stark contrast to radical mechanisms, which exhibited
202"
PRETRAINING,0.2964426877470356,"lower performance when using a pretrained model [18]. This suggests that radical reactions are
203"
PRETRAINING,0.2977602108036891,"underrepresented in USPTO datasets compared to polar reactions, and that pre-trained transformer
204"
PRETRAINING,0.29907773386034253,"models would be expected to have higher performance on polar reactions.
205"
PATHWAY SEARCH,0.30039525691699603,"4.2
Pathway Search
206"
PATHWAY SEARCH,0.30171277997364954,"In addition to predicting single-step elementary reactions, further work is being done to evaluate and
207"
PATHWAY SEARCH,0.30303030303030304,"improve the model’s performance on predicting polar mechanistic pathways. This involves chaining
208"
PATHWAY SEARCH,0.30434782608695654,Table 5: Top-N Accuracy of Chemformer Models
PATHWAY SEARCH,0.30566534914361,"Model Type
Top-1
Top-3
Top-5
Top-10"
PATHWAY SEARCH,0.3069828722002635,"no-pretraining
39.9
55.6
58.7
60.4
pretrained on zinc
74.9
77.0
82.8
84.5
pretrained on zinc and USPTO Mixed
74.0
84.1
85.2
87.2"
PATHWAY SEARCH,0.308300395256917,"several elementary steps together to transform a list of starting reactants to a list of target products.
209"
PATHWAY SEARCH,0.3096179183135705,"An example of a simple two-step mechanism correctly predicted by the ensemble transformer model
210"
PATHWAY SEARCH,0.310935441370224,"can be seen in Figure 3.
211 N O OH O O
N +
+ H O"
PATHWAY SEARCH,0.31225296442687744,"OH
N
H +"
PATHWAY SEARCH,0.31357048748353095,Figure 3: A simple 2-step mechanism correctly predicted by ensemble transformer model.
PATHWAY SEARCH,0.31488801054018445,"Although the transformer architectures outperform all other models in single step predictions on
212"
PATHWAY SEARCH,0.31620553359683795,"the test dataset, the reactions contained in PMechDB are mostly 1-2 reactant reactions, and contain
213"
PATHWAY SEARCH,0.31752305665349145,"very limited spectator ions. This results in the transformer models having a strong performance on
214"
PATHWAY SEARCH,0.3188405797101449,"reactions which contain 1-2 reactants, but inconsistent performance on reactions with one or more
215"
PATHWAY SEARCH,0.3201581027667984,"spectator ions. An example of this can be seen in the following elementary step which contains a
216"
PATHWAY SEARCH,0.3214756258234519,"spectator benzene ring. 4
217"
PATHWAY SEARCH,0.3227931488801054,"When the chemformer model is asked to predict on Step A, it does not recover the correct products,
218"
PATHWAY SEARCH,0.3241106719367589,"while on Step B with spectators removed, it ranks the products as the top-1 prediction. Interestingly,
219"
PATHWAY SEARCH,0.3254281949934124,"the two-step transformer model is able to correctly predict this step. Comparing the various methods
220"
PATHWAY SEARCH,0.32674571805006586,"numerically, the two-step models appear to demonstrate significantly less performance degradation in
221"
PATHWAY SEARCH,0.32806324110671936,"predicting elementary steps with spectator molecules. Figure 5 demonstrates the top-5 accuracies of
222"
PATHWAY SEARCH,0.32938076416337286,"the various models as the number of reactant molecules is varied, while Figure 6 demonstrates the
223"
PATHWAY SEARCH,0.33069828722002637,"top-5 accuracies as the number of atoms contained in the reactants is varied.
224"
PATHWAY SEARCH,0.33201581027667987,"The two-step transformer model can be seen to outperform both the chemformer and siamese
225"
PATHWAY SEARCH,0.3333333333333333,"architectures. When comparing the models, it seems that the number of reactant atoms has a much
226"
PATHWAY SEARCH,0.3346508563899868,"smaller effect on the prediction accuracy of the transformer models when compared to the siamese
227"
PATHWAY SEARCH,0.3359683794466403,"architecture. Perhaps this indicates that the transformer models are able to implicitly learn which
228"
PATHWAY SEARCH,0.3372859025032938,"reactive atoms it should pay attention to without being distracted by large unreactive substructures.
229 230"
PATHWAY SEARCH,0.3386034255599473,"H
Br+
Al-
Cl
Cl"
PATHWAY SEARCH,0.33992094861660077,"Cl
CH2
+ H"
PATHWAY SEARCH,0.3412384716732543,"Br
Al- Cl Cl Cl +
+
+ H"
PATHWAY SEARCH,0.3425559947299078,"Br+
Al-
Cl Cl Cl CH2
+ H"
PATHWAY SEARCH,0.3438735177865613,"Br
Al- Cl Cl Cl + A) B)"
PATHWAY SEARCH,0.3451910408432148,"Figure 4: Step A represents the elementary step with the spectator molecule benzene included. Step
B represents the elementary step with the benzene ring excluded. 85.7 93.8 82.5 87 80 78.1"
PATHWAY SEARCH,0.3465085638998682,"60.1
59.5 80.2 92.3"
PATHWAY SEARCH,0.34782608695652173,"79.1
80.4"
PATHWAY SEARCH,0.34914361001317523,"50
55
60
65
70
75
80
85
90
95
100"
PATHWAY SEARCH,0.35046113306982873,"1
2
3
4+"
PATHWAY SEARCH,0.35177865612648224,Accuracy
PATHWAY SEARCH,0.3530961791831357,Number of Molecules
PATHWAY SEARCH,0.3544137022397892,Top-5 Accuracy vs Number of Molecules
PATHWAY SEARCH,0.3557312252964427,"Two-Step Chemformer
Two-Step Siamese
Chemformer"
PATHWAY SEARCH,0.3570487483530962,"Figure 5: Comparing the top-5 accuracies of both the transformer and two-step models as number of
reactant molecules is varied. 95.1"
PATHWAY SEARCH,0.3583662714097497,"86.5
85.9
86 83.5"
PATHWAY SEARCH,0.35968379446640314,"66.3
64 55.9 91.9"
PATHWAY SEARCH,0.36100131752305664,"83.9
82
82.8"
PATHWAY SEARCH,0.36231884057971014,"50
55
60
65
70
75
80
85
90
95
100"
PATHWAY SEARCH,0.36363636363636365,"0-15
15-30
30-45
45+"
PATHWAY SEARCH,0.36495388669301715,Accuracy
PATHWAY SEARCH,0.3662714097496706,Number of Reactant Atoms
PATHWAY SEARCH,0.3675889328063241,Top-5 Accuracy vs Number of Reactant Atoms
PATHWAY SEARCH,0.3689064558629776,"Two-Step Chemformer
Two-Step Siamese
Chemformer"
PATHWAY SEARCH,0.3702239789196311,"Figure 6: Comparing the top-5 accuracies of both the transformer and two-step models as number of
reactant atoms is varied."
PATHWAY SEARCH,0.3715415019762846,"Notably, the two-step transformer model strongly outperforms the chemformer model when
231"
PATHWAY SEARCH,0.37285902503293805,"it views reactions which contain more than 2 reactant molecules. This suggests the first step
232"
PATHWAY SEARCH,0.37417654808959155,"manages to filter away the spectator ions to some extent and makes the prediction task easier for the
233"
PATHWAY SEARCH,0.37549407114624506,"transformer model.
234"
LIMITATIONS,0.37681159420289856,"5
Limitations
235"
LIMITATIONS,0.37812911725955206,"Lastly, we note there are several limitations with the current state of the PMechRP polar reaction
236"
LIMITATIONS,0.3794466403162055,"system. Firsly, the PMechDB dataset includes less than 13,000 steps. This means the dataset is
237"
LIMITATIONS,0.380764163372859,"relatively small for training large architectures, and it may be difficult for these models to generalize
238"
LIMITATIONS,0.3820816864295125,"well to all forms of experimental chemistry. Secondly, the transformer models directly translate from
239"
LIMITATIONS,0.383399209486166,"reactants to products, without generating the arrow pushing mechanisms. Although the elementary
240"
LIMITATIONS,0.3847167325428195,"step predictions still offer significant interpretability, the two-step siamese method offers greater
241"
LIMITATIONS,0.38603425559947296,"insight into the causality of a reaction by directly showing the flow of electrons. Additional methods
242"
LIMITATIONS,0.38735177865612647,"could be developed to predict arrow codes or reactive orbitals using a transformer architecture in
243"
LIMITATIONS,0.38866930171277997,"order to offer predictions with arrow pushing mechanisms.
244"
CONCLUSION,0.38998682476943347,"6
Conclusion
245"
CONCLUSION,0.391304347826087,"We developed and compared several reaction prediction systems for polar reaction mechanisms.
246"
CONCLUSION,0.3926218708827404,"Through our analysis, we have created the reaction prediction system, PMechRP. This predictor offers
247"
CONCLUSION,0.3939393939393939,"a fresh perspective on reaction prediction by specifically targeting polar reactions and operating at
248"
CONCLUSION,0.3952569169960474,"the mechanistic reaction level. From the viewpoint of organic chemists, mechanistic level reaction
249"
CONCLUSION,0.3965744400527009,"prediction offers immense interpretabiltiy benefits, and has a lot of potential to aid in the prediction of
250"
CONCLUSION,0.39789196310935443,"synthetic pathways. We utilized PMechDB datasets to train and develop a wide range of architectures.
251"
CONCLUSION,0.39920948616600793,"Our findings demonstrate that the most accurate models are based on a two-step process, where
252"
CONCLUSION,0.4005270092226614,"spectators are filtered out to generate a variety of reactants before they are fed into an ensemble
253"
CONCLUSION,0.4018445322793149,"transformer architecture. Leveraging PMechDB datasets, our polar predictor marks a significant step
254"
CONCLUSION,0.4031620553359684,"towards interpretable reaction prediction.
255"
REFERENCES,0.4044795783926219,"References
256"
REFERENCES,0.4057971014492754,"[1] Roman M Balabin and Ekaterina I Lomakina. Neural network approach to quantum-chemistry
257"
REFERENCES,0.40711462450592883,"data: Accurate prediction of density functional theory energies. The journal of chemical physics,
258"
REFERENCES,0.40843214756258234,"131(7), 2009.
259"
REFERENCES,0.40974967061923584,"[2] Connor W Coley, Regina Barzilay, William H Green, Tommi S Jaakkola, and Klavs F Jensen.
260"
REFERENCES,0.41106719367588934,"Convolutional embedding of attributed molecular graphs for physical property prediction.
261"
REFERENCES,0.41238471673254284,"Journal of chemical information and modeling, 57(8):1757–1772, 2017.
262"
REFERENCES,0.4137022397891963,"[3] Connor W Coley, Regina Barzilay, Tommi S Jaakkola, William H Green, and Klavs F Jensen.
263"
REFERENCES,0.4150197628458498,"Prediction of organic reaction outcomes using machine learning. ACS central science, 3(5):434–
264"
REFERENCES,0.4163372859025033,"443, 2017.
265"
REFERENCES,0.4176548089591568,"[4] Connor W Coley, Wengong Jin, Luke Rogers, Timothy F Jamison, Tommi S Jaakkola, William H
266"
REFERENCES,0.4189723320158103,"Green, Regina Barzilay, and Klavs F Jensen. A graph-convolutional neural network model for
267"
REFERENCES,0.42028985507246375,"the prediction of chemical reactivity. Chemical science, 10(2):370–377, 2019.
268"
REFERENCES,0.42160737812911725,"[5] Larry A Curtiss, Paul C Redfern, and Krishnan Raghavachari. Gaussian-4 theory. The Journal
269"
REFERENCES,0.42292490118577075,"of chemical physics, 126(8), 2007.
270"
REFERENCES,0.42424242424242425,"[6] David Fooshee, Aaron Mood, Eugene Gutman, Mohammadamin Tavakoli, Gregor Urban,
271"
REFERENCES,0.42555994729907776,"Frances Liu, Nancy Huynh, David Van Vranken, and Pierre Baldi. Deep learning for chemical
272"
REFERENCES,0.4268774703557312,"reaction prediction. Molecular Systems Design & Engineering, 3(3):442–452, 2018.
273"
REFERENCES,0.4281949934123847,"[7] Ross Irwin, Spyridon Dimitriadis, Jiazhen He, and Esben Jannik Bjerrum. Chemformer: a pre-
274"
REFERENCES,0.4295125164690382,"trained transformer for computational chemistry. Machine Learning: Science and Technology,
275"
REFERENCES,0.4308300395256917,"3(1):015022, 2022.
276"
REFERENCES,0.4321475625823452,"[8] Dora Kadish, Aaron D Mood, Mohammadamin Tavakoli, Eugene S Gutman, Pierre Baldi, and
277"
REFERENCES,0.43346508563899866,"David L Van Vranken. Methyl cation affinities of canonical organic functional groups. The
278"
REFERENCES,0.43478260869565216,"Journal of Organic Chemistry, 86(5):3721–3729, 2021.
279"
REFERENCES,0.43610013175230566,"[9] Matthew A Kayala, Chloé-Agathe Azencott, Jonathan H Chen, and Pierre Baldi. Learning to
280"
REFERENCES,0.43741765480895917,"predict chemical reactions. Journal of chemical information and modeling, 51(9):2209–2222,
281"
REFERENCES,0.43873517786561267,"2011.
282"
REFERENCES,0.4400527009222661,"[10] Matthew A Kayala and Pierre Baldi. Reactionpredictor: prediction of complex chemical
283"
REFERENCES,0.4413702239789196,"reactions at the mechanistic level using machine learning. Journal of chemical information and
284"
REFERENCES,0.4426877470355731,"modeling, 52(10):2526–2540, 2012.
285"
REFERENCES,0.4440052700922266,"[11] Daniel Mark Lowe. Extraction of chemical structures and reactions from the literature. PhD
286"
REFERENCES,0.4453227931488801,"thesis, 2012.
287"
REFERENCES,0.44664031620553357,"[12] Jieyu Lu and Yingkai Zhang. Unified deep learning model for multitask reaction predictions
288"
REFERENCES,0.4479578392621871,"with explanation. Journal of chemical information and modeling, 62(6):1376–1387, 2022.
289"
REFERENCES,0.4492753623188406,"[13] Gabriel A Pinheiro, Johnatan Mucelini, Marinalva D Soares, Ronaldo C Prati, Juarez LF
290"
REFERENCES,0.4505928853754941,"Da Silva, and Marcos G Quiles. Machine learning prediction of nine molecular properties based
291"
REFERENCES,0.4519104084321476,"on the smiles representation of the qm9 quantum-chemistry dataset. The Journal of Physical
292"
REFERENCES,0.45322793148880103,"Chemistry A, 124(47):9854–9866, 2020.
293"
REFERENCES,0.45454545454545453,"[14] Daniel Probst, Philippe Schwaller, and Jean-Louis Reymond. Reaction classification and yield
294"
REFERENCES,0.45586297760210803,"prediction using the differential reaction fingerprint drfp. Digital discovery, 1(2):91–97, 2022.
295"
REFERENCES,0.45718050065876153,"[15] Philippe Schwaller, Teodoro Laino, Théophile Gaudin, Peter Bolgar, Christopher A Hunter,
296"
REFERENCES,0.45849802371541504,"Costas Bekas, and Alpha A Lee. Molecular transformer: a model for uncertainty-calibrated
297"
REFERENCES,0.4598155467720685,"chemical reaction prediction. ACS central science, 5(9):1572–1583, 2019.
298"
REFERENCES,0.461133069828722,"[16] Philippe Schwaller, Alain C Vaucher, Teodoro Laino, and Jean-Louis Reymond. Prediction
299"
REFERENCES,0.4624505928853755,"of chemical reaction yields using deep learning. Machine learning: science and technology,
300"
REFERENCES,0.463768115942029,"2(1):015016, 2021.
301"
REFERENCES,0.4650856389986825,"[17] Teague Sterling and John J Irwin. Zinc 15–ligand discovery for everyone. Journal of chemical
302"
REFERENCES,0.466403162055336,"information and modeling, 55(11):2324–2337, 2015.
303"
REFERENCES,0.46772068511198944,"[18] Mohammadamin Tavakoli, Pierre Baldi, Ann Marie Carlton, Yin Ting Chiu, Alexander Shmakov,
304"
REFERENCES,0.46903820816864294,"and David Van Vranken. Ai for interpretable chemistry: Predicting radical mechanistic pathways
305"
REFERENCES,0.47035573122529645,"via contrastive learning. Advances in Neural Information Processing Systems, 36, 2024.
306"
REFERENCES,0.47167325428194995,"[19] Mohammadamin Tavakoli, Ryan J Miller, Mirana Claire Angel, Michael A Pfeiffer, Eugene S
307"
REFERENCES,0.47299077733860345,"Gutman, Aaron D Mood, David Van Vranken, and Pierre Baldi. Pmechdb: A public database of
308"
REFERENCES,0.4743083003952569,"elementary polar reaction steps. Journal of Chemical Information and Modeling, 2024.
309"
REFERENCES,0.4756258234519104,"[20] Shuangjia Zheng, Jiahua Rao, Zhongyue Zhang, Jun Xu, and Yuedong Yang. Predicting
310"
REFERENCES,0.4769433465085639,"retrosynthetic reactions using self-corrected transformer neural networks. Journal of chemical
311"
REFERENCES,0.4782608695652174,"information and modeling, 60(1):47–55, 2019.
312"
REFERENCES,0.4795783926218709,"[21] Ai-Nan Zhou, Bonan Li, Lejun Ruan, Yeting Wang, Gengli Duan, and Jianqi Li. An improved
313"
REFERENCES,0.48089591567852435,"and practical route for the synthesis of enzalutamide and potential impurities study. Chinese
314"
REFERENCES,0.48221343873517786,"Chemical Letters, 28(2):426–430, 2017.
315"
REFERENCES,0.48353096179183136,"A
Appendix / supplemental material
316"
REFERENCES,0.48484848484848486,"In this appendix, we provide additional details about the experiments and models trained.
317"
REFERENCES,0.48616600790513836,"A.1
Compute Resources
318"
REFERENCES,0.4874835309617918,"All models were trained using a single NVidia Titan X GPU.
319"
REFERENCES,0.4888010540184453,"A.2
PMechDB Dataset
320"
REFERENCES,0.4901185770750988,"Here we provide some Figures 7, 8 displaying the the number of atoms and atom types found in the
321"
REFERENCES,0.4914361001317523,"PMechDB dataset [19]
322"
REFERENCES,0.4927536231884058,"0
25
50
75
100
125
150
175
200
Number of Atoms in Reaction 0 250 500 750 1000 1250 1500 1750"
REFERENCES,0.49407114624505927,Frequency
REFERENCES,0.49538866930171277,Number of Atoms in Manually Curated Train Dataset
REFERENCES,0.49670619235836627,"Figure 7: The distribution of the total number of atoms contained in each reaction for the manually
curated training dataset."
REFERENCES,0.4980237154150198,"C
O
N
H
F
S
Cl
Br
Si
P
B
I
Na
Li
Al
Atoms 103 104 105"
REFERENCES,0.4993412384716733,Counts (log scale)
REFERENCES,0.5006587615283268,Top 15 Most Common Atoms in Manually Curated Train Reactions
REFERENCES,0.5019762845849802,Figure 8: The distribution of atoms for the reactions in the manually curated training dataset.
REFERENCES,0.5032938076416338,"A.3
Reactive Atom Prediction
323"
REFERENCES,0.5046113306982872,"A fingerprint of length 800 is constructed for each atom. This fingerprint includes 700 graph-
324"
REFERENCES,0.5059288537549407,"topological features. These features are extracted using a neighborhood of size 3 with the method
325"
REFERENCES,0.5072463768115942,"described in [6]. The remaining features consist of physiochemical properties such as valence number,
326"
REFERENCES,0.5085638998682477,"electronegativity, etc.
327"
REFERENCES,0.5098814229249012,"The source and sink prediction models are trained using the ""manually_curated_all.csv"" file, where
328"
REFERENCES,0.5111989459815547,"a 90/10 train/test split was performed. Each training reaction is processed to extract the atom
329"
REFERENCES,0.5125164690382081,"fingerprints, the atom is given a label 1 if it is reactive, and 0 if it is non-reactive. The final output
330"
REFERENCES,0.5138339920948617,"layer performs a binary classification on a reactive atom. The parameters of the source and sink
331"
REFERENCES,0.5151515151515151,"prediction models can be seen below:
332"
REFERENCES,0.5164690382081687,Table 6: Source and Sink Model Parameters
REFERENCES,0.5177865612648221,"Batch Size
Num Layers
Layer Dim
Act
Reg"
REFERENCES,0.5191040843214756,"64
5
512-256-128-164-1
RELU
L2"
REFERENCES,0.5204216073781291,"A.4
Plausibility Ranking
333"
REFERENCES,0.5217391304347826,"We tested 3 fingerprints. The reactionFP fingerprint is extracted using the features explained in [6]
334"
REFERENCES,0.5230566534914362,"to create a fingerprint of length 3200. For the rxnfp fingerprint, we use the default configuration to
335"
REFERENCES,0.5243741765480896,"create a fingerprint of size 256. We use the DRFP fingerprint with a size of 2048 with the default
336"
REFERENCES,0.525691699604743,"configuration.
337"
REFERENCES,0.5270092226613966,"The parameters of the ranker models can be seen below:
338"
REFERENCES,0.52832674571805,Table 7: Source and Sink Model Parameters
REFERENCES,0.5296442687747036,"Batch Size
Num Layers
Layer Dim
Act
Reg"
REFERENCES,0.530961791831357,"200
3
360-360-1
Tanh
Dropout (0.5)"
REFERENCES,0.5322793148880105,"NeurIPS Paper Checklist
339"
REFERENCES,0.5335968379446641,"The checklist is designed to encourage best practices for responsible machine learning research,
340"
REFERENCES,0.5349143610013175,"addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove
341"
REFERENCES,0.5362318840579711,"the checklist: The papers not including the checklist will be desk rejected. The checklist should
342"
REFERENCES,0.5375494071146245,"follow the references and follow the (optional) supplemental material. The checklist does NOT count
343"
REFERENCES,0.538866930171278,"towards the page limit.
344"
REFERENCES,0.5401844532279315,"Please read the checklist guidelines carefully for information on how to answer these questions. For
345"
REFERENCES,0.541501976284585,"each question in the checklist:
346"
REFERENCES,0.5428194993412385,"• You should answer [Yes] , [No] , or [NA] .
347"
REFERENCES,0.544137022397892,"• [NA] means either that the question is Not Applicable for that particular paper or the
348"
REFERENCES,0.5454545454545454,"relevant information is Not Available.
349"
REFERENCES,0.546772068511199,"• Please provide a short (1–2 sentence) justification right after your answer (even for NA).
350"
REFERENCES,0.5480895915678524,"The checklist answers are an integral part of your paper submission. They are visible to the
351"
REFERENCES,0.549407114624506,"reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it
352"
REFERENCES,0.5507246376811594,"(after eventual revisions) with the final version of your paper, and its final version will be published
353"
REFERENCES,0.5520421607378129,"with the paper.
354"
REFERENCES,0.5533596837944664,"The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.
355"
REFERENCES,0.5546772068511199,"While ""[Yes] "" is generally preferable to ""[No] "", it is perfectly acceptable to answer ""[No] "" provided a
356"
REFERENCES,0.5559947299077734,"proper justification is given (e.g., ""error bars are not reported because it would be too computationally
357"
REFERENCES,0.5573122529644269,"expensive"" or ""we were unable to find the license for the dataset we used""). In general, answering
358"
REFERENCES,0.5586297760210803,"""[No] "" or ""[NA] "" is not grounds for rejection. While the questions are phrased in a binary way, we
359"
REFERENCES,0.5599472990777339,"acknowledge that the true answer is often more nuanced, so please just use your best judgment and
360"
REFERENCES,0.5612648221343873,"write a justification to elaborate. All supporting evidence can appear either in the main paper or the
361"
REFERENCES,0.5625823451910409,"supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification
362"
REFERENCES,0.5638998682476943,"please point to the section(s) where related material for the question can be found.
363"
REFERENCES,0.5652173913043478,"IMPORTANT, please:
364"
REFERENCES,0.5665349143610013,"• Delete this instruction block, but keep the section heading “NeurIPS paper checklist"",
365"
REFERENCES,0.5678524374176548,"• Keep the checklist subsection headings, questions/answers and guidelines below.
366"
REFERENCES,0.5691699604743083,"• Do not modify the questions and only use the provided macros for your answers.
367"
CLAIMS,0.5704874835309618,"1. Claims
368"
CLAIMS,0.5718050065876152,"Question: Do the main claims made in the abstract and introduction accurately reflect the
369"
CLAIMS,0.5731225296442688,"paper’s contributions and scope?
370"
CLAIMS,0.5744400527009222,"Answer: [Yes]
371"
CLAIMS,0.5757575757575758,"Justification: The paper clearly outlines its contributions and scope. All contributions are
372"
CLAIMS,0.5770750988142292,"backed by evaluating the accuracy of the models, and providing tables and plots for the
373"
CLAIMS,0.5783926218708827,"performance.
374"
CLAIMS,0.5797101449275363,"Guidelines:
375"
CLAIMS,0.5810276679841897,"• The answer NA means that the abstract and introduction do not include the claims
376"
CLAIMS,0.5823451910408433,"made in the paper.
377"
CLAIMS,0.5836627140974967,"• The abstract and/or introduction should clearly state the claims made, including the
378"
CLAIMS,0.5849802371541502,"contributions made in the paper and important assumptions and limitations. A No or
379"
CLAIMS,0.5862977602108037,"NA answer to this question will not be perceived well by the reviewers.
380"
CLAIMS,0.5876152832674572,"• The claims made should match theoretical and experimental results, and reflect how
381"
CLAIMS,0.5889328063241107,"much the results can be expected to generalize to other settings.
382"
CLAIMS,0.5902503293807642,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
383"
CLAIMS,0.5915678524374176,"are not attained by the paper.
384"
LIMITATIONS,0.5928853754940712,"2. Limitations
385"
LIMITATIONS,0.5942028985507246,"Question: Does the paper discuss the limitations of the work performed by the authors?
386"
LIMITATIONS,0.5955204216073782,"Answer: [Yes]
387"
LIMITATIONS,0.5968379446640316,"Justification: The paper does discuss the limitations of the work. We analyze and address
388"
LIMITATIONS,0.5981554677206851,"situations where the model performs poorly, such as on reactions with a large number of
389"
LIMITATIONS,0.5994729907773386,"spectator ions or atoms.
390"
LIMITATIONS,0.6007905138339921,"Guidelines:
391"
LIMITATIONS,0.6021080368906456,"• The answer NA means that the paper has no limitation while the answer No means that
392"
LIMITATIONS,0.6034255599472991,"the paper has limitations, but those are not discussed in the paper.
393"
LIMITATIONS,0.6047430830039525,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
394"
LIMITATIONS,0.6060606060606061,"• The paper should point out any strong assumptions and how robust the results are to
395"
LIMITATIONS,0.6073781291172595,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
396"
LIMITATIONS,0.6086956521739131,"model well-specification, asymptotic approximations only holding locally). The authors
397"
LIMITATIONS,0.6100131752305665,"should reflect on how these assumptions might be violated in practice and what the
398"
LIMITATIONS,0.61133069828722,"implications would be.
399"
LIMITATIONS,0.6126482213438735,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
400"
LIMITATIONS,0.613965744400527,"only tested on a few datasets or with a few runs. In general, empirical results often
401"
LIMITATIONS,0.6152832674571805,"depend on implicit assumptions, which should be articulated.
402"
LIMITATIONS,0.616600790513834,"• The authors should reflect on the factors that influence the performance of the approach.
403"
LIMITATIONS,0.6179183135704874,"For example, a facial recognition algorithm may perform poorly when image resolution
404"
LIMITATIONS,0.619235836627141,"is low or images are taken in low lighting. Or a speech-to-text system might not be
405"
LIMITATIONS,0.6205533596837944,"used reliably to provide closed captions for online lectures because it fails to handle
406"
LIMITATIONS,0.621870882740448,"technical jargon.
407"
LIMITATIONS,0.6231884057971014,"• The authors should discuss the computational efficiency of the proposed algorithms
408"
LIMITATIONS,0.6245059288537549,"and how they scale with dataset size.
409"
LIMITATIONS,0.6258234519104084,"• If applicable, the authors should discuss possible limitations of their approach to
410"
LIMITATIONS,0.6271409749670619,"address problems of privacy and fairness.
411"
LIMITATIONS,0.6284584980237155,"• While the authors might fear that complete honesty about limitations might be used by
412"
LIMITATIONS,0.6297760210803689,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
413"
LIMITATIONS,0.6310935441370223,"limitations that aren’t acknowledged in the paper. The authors should use their best
414"
LIMITATIONS,0.6324110671936759,"judgment and recognize that individual actions in favor of transparency play an impor-
415"
LIMITATIONS,0.6337285902503293,"tant role in developing norms that preserve the integrity of the community. Reviewers
416"
LIMITATIONS,0.6350461133069829,"will be specifically instructed to not penalize honesty concerning limitations.
417"
THEORY ASSUMPTIONS AND PROOFS,0.6363636363636364,"3. Theory Assumptions and Proofs
418"
THEORY ASSUMPTIONS AND PROOFS,0.6376811594202898,"Question: For each theoretical result, does the paper provide the full set of assumptions and
419"
THEORY ASSUMPTIONS AND PROOFS,0.6389986824769434,"a complete (and correct) proof?
420"
THEORY ASSUMPTIONS AND PROOFS,0.6403162055335968,"Answer: [NA]
421"
THEORY ASSUMPTIONS AND PROOFS,0.6416337285902504,"Justification: The paper does not include theoretical results.
422"
THEORY ASSUMPTIONS AND PROOFS,0.6429512516469038,"Guidelines:
423"
THEORY ASSUMPTIONS AND PROOFS,0.6442687747035574,"• The answer NA means that the paper does not include theoretical results.
424"
THEORY ASSUMPTIONS AND PROOFS,0.6455862977602108,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
425"
THEORY ASSUMPTIONS AND PROOFS,0.6469038208168643,"referenced.
426"
THEORY ASSUMPTIONS AND PROOFS,0.6482213438735178,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
427"
THEORY ASSUMPTIONS AND PROOFS,0.6495388669301713,"• The proofs can either appear in the main paper or the supplemental material, but if
428"
THEORY ASSUMPTIONS AND PROOFS,0.6508563899868248,"they appear in the supplemental material, the authors are encouraged to provide a short
429"
THEORY ASSUMPTIONS AND PROOFS,0.6521739130434783,"proof sketch to provide intuition.
430"
THEORY ASSUMPTIONS AND PROOFS,0.6534914361001317,"• Inversely, any informal proof provided in the core of the paper should be complemented
431"
THEORY ASSUMPTIONS AND PROOFS,0.6548089591567853,"by formal proofs provided in appendix or supplemental material.
432"
THEORY ASSUMPTIONS AND PROOFS,0.6561264822134387,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
433"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6574440052700923,"4. Experimental Result Reproducibility
434"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6587615283267457,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
435"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6600790513833992,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
436"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6613965744400527,"of the paper (regardless of whether the code and data are provided or not)?
437"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6627140974967062,"Answer: [Yes]
438"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6640316205533597,"Justification: We clearly describe the architectures used, as well as any modifications made
439"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6653491436100132,"to them. The hyperparameters and dimensions of the models can be found in the appendix.
440"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6666666666666666,"The PMechDB dataset is publically available and can be accessed by any user.
441"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6679841897233202,"Guidelines:
442"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6693017127799736,"• The answer NA means that the paper does not include experiments.
443"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6706192358366272,"• If the paper includes experiments, a No answer to this question will not be perceived
444"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6719367588932806,"well by the reviewers: Making the paper reproducible is important, regardless of
445"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6732542819499341,"whether the code and data are provided or not.
446"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6745718050065876,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
447"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6758893280632411,"to make their results reproducible or verifiable.
448"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6772068511198946,"• Depending on the contribution, reproducibility can be accomplished in various ways.
449"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6785243741765481,"For example, if the contribution is a novel architecture, describing the architecture fully
450"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6798418972332015,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
451"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6811594202898551,"be necessary to either make it possible for others to replicate the model with the same
452"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6824769433465085,"dataset, or provide access to the model. In general. releasing code and data is often
453"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6837944664031621,"one good way to accomplish this, but reproducibility can also be provided via detailed
454"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6851119894598156,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
455"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.686429512516469,"of a large language model), releasing of a model checkpoint, or other means that are
456"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6877470355731226,"appropriate to the research performed.
457"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.689064558629776,"• While NeurIPS does not require releasing code, the conference does require all submis-
458"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6903820816864296,"sions to provide some reasonable avenue for reproducibility, which may depend on the
459"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.691699604743083,"nature of the contribution. For example
460"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6930171277997365,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
461"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.69433465085639,"to reproduce that algorithm.
462"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6956521739130435,"(b) If the contribution is primarily a new model architecture, the paper should describe
463"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.696969696969697,"the architecture clearly and fully.
464"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6982872200263505,"(c) If the contribution is a new model (e.g., a large language model), then there should
465"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.6996047430830039,"either be a way to access this model for reproducing the results or a way to reproduce
466"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7009222661396575,"the model (e.g., with an open-source dataset or instructions for how to construct
467"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7022397891963109,"the dataset).
468"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7035573122529645,"(d) We recognize that reproducibility may be tricky in some cases, in which case
469"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7048748353096179,"authors are welcome to describe the particular way they provide for reproducibility.
470"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7061923583662714,"In the case of closed-source models, it may be that access to the model is limited in
471"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7075098814229249,"some way (e.g., to registered users), but it should be possible for other researchers
472"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7088274044795784,"to have some path to reproducing or verifying the results.
473"
OPEN ACCESS TO DATA AND CODE,0.7101449275362319,"5. Open access to data and code
474"
OPEN ACCESS TO DATA AND CODE,0.7114624505928854,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
475"
OPEN ACCESS TO DATA AND CODE,0.7127799736495388,"tions to faithfully reproduce the main experimental results, as described in supplemental
476"
OPEN ACCESS TO DATA AND CODE,0.7140974967061924,"material?
477"
OPEN ACCESS TO DATA AND CODE,0.7154150197628458,"Answer: [No]
478"
OPEN ACCESS TO DATA AND CODE,0.7167325428194994,"Justification: For the existing models, their codes can be found online at their respective git
479"
OPEN ACCESS TO DATA AND CODE,0.7180500658761528,"repositories. For the two-step models which predict reactive atoms, the codes use openeye
480"
OPEN ACCESS TO DATA AND CODE,0.7193675889328063,"software, which is a commercial library to do most of the chemoinformatics processing and
481"
OPEN ACCESS TO DATA AND CODE,0.7206851119894598,"thus this code cannot be released. Everything else from the paper is publically available
482"
OPEN ACCESS TO DATA AND CODE,0.7220026350461133,"including the PMechDB dataset.
483"
OPEN ACCESS TO DATA AND CODE,0.7233201581027668,"Guidelines:
484"
OPEN ACCESS TO DATA AND CODE,0.7246376811594203,"• The answer NA means that paper does not include experiments requiring code.
485"
OPEN ACCESS TO DATA AND CODE,0.7259552042160737,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
486"
OPEN ACCESS TO DATA AND CODE,0.7272727272727273,"public/guides/CodeSubmissionPolicy) for more details.
487"
OPEN ACCESS TO DATA AND CODE,0.7285902503293807,"• While we encourage the release of code and data, we understand that this might not be
488"
OPEN ACCESS TO DATA AND CODE,0.7299077733860343,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
489"
OPEN ACCESS TO DATA AND CODE,0.7312252964426877,"including code, unless this is central to the contribution (e.g., for a new open-source
490"
OPEN ACCESS TO DATA AND CODE,0.7325428194993412,"benchmark).
491"
OPEN ACCESS TO DATA AND CODE,0.7338603425559947,"• The instructions should contain the exact command and environment needed to run to
492"
OPEN ACCESS TO DATA AND CODE,0.7351778656126482,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
493"
OPEN ACCESS TO DATA AND CODE,0.7364953886693018,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
494"
OPEN ACCESS TO DATA AND CODE,0.7378129117259552,"• The authors should provide instructions on data access and preparation, including how
495"
OPEN ACCESS TO DATA AND CODE,0.7391304347826086,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
496"
OPEN ACCESS TO DATA AND CODE,0.7404479578392622,"• The authors should provide scripts to reproduce all experimental results for the new
497"
OPEN ACCESS TO DATA AND CODE,0.7417654808959157,"proposed method and baselines. If only a subset of experiments are reproducible, they
498"
OPEN ACCESS TO DATA AND CODE,0.7430830039525692,"should state which ones are omitted from the script and why.
499"
OPEN ACCESS TO DATA AND CODE,0.7444005270092227,"• At submission time, to preserve anonymity, the authors should release anonymized
500"
OPEN ACCESS TO DATA AND CODE,0.7457180500658761,"versions (if applicable).
501"
OPEN ACCESS TO DATA AND CODE,0.7470355731225297,"• Providing as much information as possible in supplemental material (appended to the
502"
OPEN ACCESS TO DATA AND CODE,0.7483530961791831,"paper) is recommended, but including URLs to data and code is permitted.
503"
OPEN ACCESS TO DATA AND CODE,0.7496706192358367,"6. Experimental Setting/Details
504"
OPEN ACCESS TO DATA AND CODE,0.7509881422924901,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
505"
OPEN ACCESS TO DATA AND CODE,0.7523056653491436,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
506"
OPEN ACCESS TO DATA AND CODE,0.7536231884057971,"results?
507"
OPEN ACCESS TO DATA AND CODE,0.7549407114624506,"Answer: [Yes]
508"
OPEN ACCESS TO DATA AND CODE,0.7562582345191041,"Justification: The paper specifies the data splits and hyperparameters necessary to reproduce
509"
OPEN ACCESS TO DATA AND CODE,0.7575757575757576,"the results.
510"
OPEN ACCESS TO DATA AND CODE,0.758893280632411,"Guidelines:
511"
OPEN ACCESS TO DATA AND CODE,0.7602108036890646,"• The answer NA means that the paper does not include experiments.
512"
OPEN ACCESS TO DATA AND CODE,0.761528326745718,"• The experimental setting should be presented in the core of the paper to a level of detail
513"
OPEN ACCESS TO DATA AND CODE,0.7628458498023716,"that is necessary to appreciate the results and make sense of them.
514"
OPEN ACCESS TO DATA AND CODE,0.764163372859025,"• The full details can be provided either with the code, in appendix, or as supplemental
515"
OPEN ACCESS TO DATA AND CODE,0.7654808959156785,"material.
516"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.766798418972332,"7. Experiment Statistical Significance
517"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7681159420289855,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
518"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.769433465085639,"information about the statistical significance of the experiments?
519"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7707509881422925,"Answer: [No]
520"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7720685111989459,"Justification: There are not error bars to report, the models were assessed based on their
521"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7733860342555995,"reaction prediction accuracy. They were evaluated once on the test set, so there are no error
522"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7747035573122529,"bars.
523"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7760210803689065,"Guidelines:
524"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7773386034255599,"• The answer NA means that the paper does not include experiments.
525"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7786561264822134,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
526"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7799736495388669,"dence intervals, or statistical significance tests, at least for the experiments that support
527"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7812911725955204,"the main claims of the paper.
528"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.782608695652174,"• The factors of variability that the error bars are capturing should be clearly stated (for
529"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7839262187088274,"example, train/test split, initialization, random drawing of some parameter, or overall
530"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7852437417654808,"run with given experimental conditions).
531"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7865612648221344,"• The method for calculating the error bars should be explained (closed form formula,
532"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7878787878787878,"call to a library function, bootstrap, etc.)
533"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7891963109354414,"• The assumptions made should be given (e.g., Normally distributed errors).
534"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7905138339920948,"• It should be clear whether the error bar is the standard deviation or the standard error
535"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7918313570487484,"of the mean.
536"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7931488801054019,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
537"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7944664031620553,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
538"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7957839262187089,"of Normality of errors is not verified.
539"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7971014492753623,"• For asymmetric distributions, the authors should be careful not to show in tables or
540"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7984189723320159,"figures symmetric error bars that would yield results that are out of range (e.g. negative
541"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.7997364953886693,"error rates).
542"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8010540184453228,"• If error bars are reported in tables or plots, The authors should explain in the text how
543"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8023715415019763,"they were calculated and reference the corresponding figures or tables in the text.
544"
EXPERIMENTS COMPUTE RESOURCES,0.8036890645586298,"8. Experiments Compute Resources
545"
EXPERIMENTS COMPUTE RESOURCES,0.8050065876152833,"Question: For each experiment, does the paper provide sufficient information on the com-
546"
EXPERIMENTS COMPUTE RESOURCES,0.8063241106719368,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
547"
EXPERIMENTS COMPUTE RESOURCES,0.8076416337285902,"the experiments?
548"
EXPERIMENTS COMPUTE RESOURCES,0.8089591567852438,"Answer: [Yes]
549"
EXPERIMENTS COMPUTE RESOURCES,0.8102766798418972,"Justification: This information can be found in the appendix.
550"
EXPERIMENTS COMPUTE RESOURCES,0.8115942028985508,"Guidelines:
551"
EXPERIMENTS COMPUTE RESOURCES,0.8129117259552042,"• The answer NA means that the paper does not include experiments.
552"
EXPERIMENTS COMPUTE RESOURCES,0.8142292490118577,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
553"
EXPERIMENTS COMPUTE RESOURCES,0.8155467720685112,"or cloud provider, including relevant memory and storage.
554"
EXPERIMENTS COMPUTE RESOURCES,0.8168642951251647,"• The paper should provide the amount of compute required for each of the individual
555"
EXPERIMENTS COMPUTE RESOURCES,0.8181818181818182,"experimental runs as well as estimate the total compute.
556"
EXPERIMENTS COMPUTE RESOURCES,0.8194993412384717,"• The paper should disclose whether the full research project required more compute
557"
EXPERIMENTS COMPUTE RESOURCES,0.8208168642951251,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
558"
EXPERIMENTS COMPUTE RESOURCES,0.8221343873517787,"didn’t make it into the paper).
559"
CODE OF ETHICS,0.8234519104084321,"9. Code Of Ethics
560"
CODE OF ETHICS,0.8247694334650857,"Question: Does the research conducted in the paper conform, in every respect, with the
561"
CODE OF ETHICS,0.8260869565217391,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
562"
CODE OF ETHICS,0.8274044795783926,"Answer: [Yes]
563"
CODE OF ETHICS,0.8287220026350461,"Justification: To our knowledge the paper conforms with the code of ethics.
564"
CODE OF ETHICS,0.8300395256916996,"Guidelines:
565"
CODE OF ETHICS,0.8313570487483531,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
566"
CODE OF ETHICS,0.8326745718050066,"• If the authors answer No, they should explain the special circumstances that require a
567"
CODE OF ETHICS,0.83399209486166,"deviation from the Code of Ethics.
568"
CODE OF ETHICS,0.8353096179183136,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
569"
CODE OF ETHICS,0.836627140974967,"eration due to laws or regulations in their jurisdiction).
570"
BROADER IMPACTS,0.8379446640316206,"10. Broader Impacts
571"
BROADER IMPACTS,0.839262187088274,"Question: Does the paper discuss both potential positive societal impacts and negative
572"
BROADER IMPACTS,0.8405797101449275,"societal impacts of the work performed?
573"
BROADER IMPACTS,0.841897233201581,"Answer: [Yes]
574"
BROADER IMPACTS,0.8432147562582345,"Justification: The paper discussed the ability of the model to be applied to synthetic pathway
575"
BROADER IMPACTS,0.8445322793148881,"prediction, which is a very important challenge of chemistry, and the ability of the models
576"
BROADER IMPACTS,0.8458498023715415,"to provide interpretable predictions for chemistry.
577"
BROADER IMPACTS,0.847167325428195,"Guidelines:
578"
BROADER IMPACTS,0.8484848484848485,"• The answer NA means that there is no societal impact of the work performed.
579"
BROADER IMPACTS,0.849802371541502,"• If the authors answer NA or No, they should explain why their work has no societal
580"
BROADER IMPACTS,0.8511198945981555,"impact or why the paper does not address societal impact.
581"
BROADER IMPACTS,0.852437417654809,"• Examples of negative societal impacts include potential malicious or unintended uses
582"
BROADER IMPACTS,0.8537549407114624,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
583"
BROADER IMPACTS,0.855072463768116,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
584"
BROADER IMPACTS,0.8563899868247694,"groups), privacy considerations, and security considerations.
585"
BROADER IMPACTS,0.857707509881423,"• The conference expects that many papers will be foundational research and not tied
586"
BROADER IMPACTS,0.8590250329380764,"to particular applications, let alone deployments. However, if there is a direct path to
587"
BROADER IMPACTS,0.8603425559947299,"any negative applications, the authors should point it out. For example, it is legitimate
588"
BROADER IMPACTS,0.8616600790513834,"to point out that an improvement in the quality of generative models could be used to
589"
BROADER IMPACTS,0.8629776021080369,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
590"
BROADER IMPACTS,0.8642951251646904,"that a generic algorithm for optimizing neural networks could enable people to train
591"
BROADER IMPACTS,0.8656126482213439,"models that generate Deepfakes faster.
592"
BROADER IMPACTS,0.8669301712779973,"• The authors should consider possible harms that could arise when the technology is
593"
BROADER IMPACTS,0.8682476943346509,"being used as intended and functioning correctly, harms that could arise when the
594"
BROADER IMPACTS,0.8695652173913043,"technology is being used as intended but gives incorrect results, and harms following
595"
BROADER IMPACTS,0.8708827404479579,"from (intentional or unintentional) misuse of the technology.
596"
BROADER IMPACTS,0.8722002635046113,"• If there are negative societal impacts, the authors could also discuss possible mitigation
597"
BROADER IMPACTS,0.8735177865612648,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
598"
BROADER IMPACTS,0.8748353096179183,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
599"
BROADER IMPACTS,0.8761528326745718,"feedback over time, improving the efficiency and accessibility of ML).
600"
SAFEGUARDS,0.8774703557312253,"11. Safeguards
601"
SAFEGUARDS,0.8787878787878788,"Question: Does the paper describe safeguards that have been put in place for responsible
602"
SAFEGUARDS,0.8801054018445322,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
603"
SAFEGUARDS,0.8814229249011858,"image generators, or scraped datasets)?
604"
SAFEGUARDS,0.8827404479578392,"Answer: [NA]
605"
SAFEGUARDS,0.8840579710144928,"Justification: The paper does not have risk for misuse. It simply describes architectures
606"
SAFEGUARDS,0.8853754940711462,"which are useful for specifically predicting elementary step reactions. The models currently
607"
SAFEGUARDS,0.8866930171277997,"have no ability to design synthetic pathways for a target molecule, they must be first provided
608"
SAFEGUARDS,0.8880105401844532,"with a list of reactants to produce a set of products.
609"
SAFEGUARDS,0.8893280632411067,"Guidelines:
610"
SAFEGUARDS,0.8906455862977603,"• The answer NA means that the paper poses no such risks.
611"
SAFEGUARDS,0.8919631093544137,"• Released models that have a high risk for misuse or dual-use should be released with
612"
SAFEGUARDS,0.8932806324110671,"necessary safeguards to allow for controlled use of the model, for example by requiring
613"
SAFEGUARDS,0.8945981554677207,"that users adhere to usage guidelines or restrictions to access the model or implementing
614"
SAFEGUARDS,0.8959156785243741,"safety filters.
615"
SAFEGUARDS,0.8972332015810277,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
616"
SAFEGUARDS,0.8985507246376812,"should describe how they avoided releasing unsafe images.
617"
SAFEGUARDS,0.8998682476943346,"• We recognize that providing effective safeguards is challenging, and many papers do
618"
SAFEGUARDS,0.9011857707509882,"not require this, but we encourage authors to take this into account and make a best
619"
SAFEGUARDS,0.9025032938076416,"faith effort.
620"
LICENSES FOR EXISTING ASSETS,0.9038208168642952,"12. Licenses for existing assets
621"
LICENSES FOR EXISTING ASSETS,0.9051383399209486,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
622"
LICENSES FOR EXISTING ASSETS,0.9064558629776021,"the paper, properly credited and are the license and terms of use explicitly mentioned and
623"
LICENSES FOR EXISTING ASSETS,0.9077733860342556,"properly respected?
624"
LICENSES FOR EXISTING ASSETS,0.9090909090909091,"Answer: [Yes]
625"
LICENSES FOR EXISTING ASSETS,0.9104084321475626,"Justification: Papers are cited. The models used have public access git repos. The PMechDB
626"
LICENSES FOR EXISTING ASSETS,0.9117259552042161,"dataset is governed by the Creative Commons Attribution-NonCommercial-NoDerivs (CC-
627"
LICENSES FOR EXISTING ASSETS,0.9130434782608695,"BY-NC-ND) license.
628"
LICENSES FOR EXISTING ASSETS,0.9143610013175231,"Guidelines:
629"
LICENSES FOR EXISTING ASSETS,0.9156785243741765,"• The answer NA means that the paper does not use existing assets.
630"
LICENSES FOR EXISTING ASSETS,0.9169960474308301,"• The authors should cite the original paper that produced the code package or dataset.
631"
LICENSES FOR EXISTING ASSETS,0.9183135704874835,"• The authors should state which version of the asset is used and, if possible, include a
632"
LICENSES FOR EXISTING ASSETS,0.919631093544137,"URL.
633"
LICENSES FOR EXISTING ASSETS,0.9209486166007905,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
634"
LICENSES FOR EXISTING ASSETS,0.922266139657444,"• For scraped data from a particular source (e.g., website), the copyright and terms of
635"
LICENSES FOR EXISTING ASSETS,0.9235836627140975,"service of that source should be provided.
636"
LICENSES FOR EXISTING ASSETS,0.924901185770751,"• If assets are released, the license, copyright information, and terms of use in the
637"
LICENSES FOR EXISTING ASSETS,0.9262187088274044,"package should be provided. For popular datasets, paperswithcode.com/datasets
638"
LICENSES FOR EXISTING ASSETS,0.927536231884058,"has curated licenses for some datasets. Their licensing guide can help determine the
639"
LICENSES FOR EXISTING ASSETS,0.9288537549407114,"license of a dataset.
640"
LICENSES FOR EXISTING ASSETS,0.930171277997365,"• For existing datasets that are re-packaged, both the original license and the license of
641"
LICENSES FOR EXISTING ASSETS,0.9314888010540184,"the derived asset (if it has changed) should be provided.
642"
LICENSES FOR EXISTING ASSETS,0.932806324110672,"• If this information is not available online, the authors are encouraged to reach out to
643"
LICENSES FOR EXISTING ASSETS,0.9341238471673254,"the asset’s creators.
644"
NEW ASSETS,0.9354413702239789,"13. New Assets
645"
NEW ASSETS,0.9367588932806324,"Question: Are new assets introduced in the paper well documented and is the documentation
646"
NEW ASSETS,0.9380764163372859,"provided alongside the assets?
647"
NEW ASSETS,0.9393939393939394,"Answer: [Yes]
648"
NEW ASSETS,0.9407114624505929,"Justification: We have provided descriptions of the various methods and experiments, as
649"
NEW ASSETS,0.9420289855072463,"well as their limitations.
650"
NEW ASSETS,0.9433465085638999,"Guidelines:
651"
NEW ASSETS,0.9446640316205533,"• The answer NA means that the paper does not release new assets.
652"
NEW ASSETS,0.9459815546772069,"• Researchers should communicate the details of the dataset/code/model as part of their
653"
NEW ASSETS,0.9472990777338604,"submissions via structured templates. This includes details about training, license,
654"
NEW ASSETS,0.9486166007905138,"limitations, etc.
655"
NEW ASSETS,0.9499341238471674,"• The paper should discuss whether and how consent was obtained from people whose
656"
NEW ASSETS,0.9512516469038208,"asset is used.
657"
NEW ASSETS,0.9525691699604744,"• At submission time, remember to anonymize your assets (if applicable). You can either
658"
NEW ASSETS,0.9538866930171278,"create an anonymized URL or include an anonymized zip file.
659"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9552042160737813,"14. Crowdsourcing and Research with Human Subjects
660"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9565217391304348,"Question: For crowdsourcing experiments and research with human subjects, does the paper
661"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9578392621870883,"include the full text of instructions given to participants and screenshots, if applicable, as
662"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9591567852437418,"well as details about compensation (if any)?
663"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9604743083003953,"Answer: [NA]
664"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9617918313570487,"Justification: This does not apply.
665"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9631093544137023,"Guidelines:
666"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9644268774703557,"• The answer NA means that the paper does not involve crowdsourcing nor research with
667"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9657444005270093,"human subjects.
668"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9670619235836627,"• Including this information in the supplemental material is fine, but if the main contribu-
669"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9683794466403162,"tion of the paper involves human subjects, then as much detail as possible should be
670"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9696969696969697,"included in the main paper.
671"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9710144927536232,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
672"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9723320158102767,"or other labor should be paid at least the minimum wage in the country of the data
673"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9736495388669302,"collector.
674"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9749670619235836,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
675"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9762845849802372,"Subjects
676"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9776021080368906,"Question: Does the paper describe potential risks incurred by study participants, whether
677"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9789196310935442,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
678"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9802371541501976,"approvals (or an equivalent approval/review based on the requirements of your country or
679"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9815546772068511,"institution) were obtained?
680"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9828722002635046,"Answer: [NA]
681"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9841897233201581,"Justification: This does not apply.
682"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9855072463768116,"Guidelines:
683"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9868247694334651,"• The answer NA means that the paper does not involve crowdsourcing nor research with
684"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9881422924901185,"human subjects.
685"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9894598155467721,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
686"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9907773386034255,"may be required for any human subjects research. If you obtained IRB approval, you
687"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9920948616600791,"should clearly state this in the paper.
688"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9934123847167325,"• We recognize that the procedures for this may vary significantly between institutions
689"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.994729907773386,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
690"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9960474308300395,"guidelines for their institution.
691"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.997364953886693,"• For initial submissions, do not include any information that would break anonymity (if
692"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9986824769433466,"applicable), such as the institution conducting the review.
693"
