Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.007352941176470588,"To optimize survival, organisms need to accurately and efficiently relay new in-
1
formation throughout their systems for processing and responses. Furthermore,
2
they benefit from predicting environmental occurrences, or in mathematical terms,
3
understanding the probability distribution of their environment, based on both
4
personal experiences and inherited evolutionary memory. These twin objectives
5
of information transmission and learning environmental probabilistic distributions
6
form the core of an organism’s information processing system. While the early
7
vision neuroscience field has primarily focused on the former, employing infor-
8
mation theory as a guiding framework [3, 32, 19, 1, 9, 28], the latter is largely
9
explored by the machine learning community via probabilistic generative models.
10
However, the relationship between these two objectives has not been thoroughly
11
investigated. In this paper, we study a biologically inspired information processing
12
model and prove that these two objectives can be achieved independently. By
13
evenly partitioning the input space to model input probability, our model bypasses
14
the often intractable normalization factor computation. When applied to image
15
patches, this model produces a sparse, nonlinear binary population code similar
16
to early visual systems, with features like edge-detection and orientation-selective
17
units. Our results not only offer potential new insights into the functioning of
18
neurons in early vision systems, but also present a novel approach to represent
19
natural image patches.
20"
INTRODUCTION,0.014705882352941176,"1
Introduction
21"
INTRODUCTION,0.022058823529411766,"Nature, through billions of years of evolution, has likely developed optimal methods for processing
22
visual information within the constraints of biological feasibility. However, attempting to precisely
23
emulate every detail of these biological systems [30, 21] in order to construct an optimal visual
24
information processing model presents significant complexities, especially without a comprehensive
25
understanding of the underlying principles.
26"
INTRODUCTION,0.029411764705882353,"In parallel, deep learning models, particularly Convolutional Neural Networks (CNNs), have demon-
27
strated exceptional performance in various computer vision tasks, such as image classification, object
28
detection, and semantic segmentation. Despite their success, these models still fall short of biological
29
vision systems in several key areas such as the ability to generalize from limited data, robustness to
30
variations, 3D understanding, and processing speed and efficiency.
31"
INTRODUCTION,0.03676470588235294,"Moreover, deep learning models pose several unresolved challenges. Firstly, their decision-making
32
processes are often opaque, leading to the ""black box"" label. Secondly, deep learning architectures
33
typically involve numerous layers without explicit functions associated with each layer [12, 8], unlike
34
the biological brain where each stage of visual processing has a distinct role and purpose [7]. Lastly,he
35"
INTRODUCTION,0.04411764705882353,"sequence of information processing in deep learning models is largely dictated by their architectural
36
structure. It is still a question how to ascertain when one processing stage is finished and when it’s
37
appropriate to pass information to the next layer.
38"
INTRODUCTION,0.051470588235294115,"Drawing inspiration from biological systems and prior studies [19, 1, 9, 28], and with a view to
39
find an alternative approach to the current deep learning framework, this paper aims to explore the
40
fundamentals of the first stage of an optimal visual information processing system. This exploration is
41
undertaken incrementally, starting from a single pixel, and progressively advancing to image patches.
42"
ONE PIXEL,0.058823529411764705,"2
One Pixel
43"
ONE PIXEL,0.0661764705882353,"We begin with the simplest conceivable case, where the input to the model consists of a single pixel
44
with one color channel. Although seemingly trivial, this model can represent various biological units.
45
For example, it could model the eyespot of single-celled organisms like Euglena, the large monopolar
46
cells found in an insect’s compound eye or the bipolar cells in the retina. The single pixel case has
47
been studied [14, 1]. We aim to review it to introduce the central concepts and the main theory, which
48
will also be applicable to more complex scenarios.
49"
ONE PIXEL,0.07352941176470588,"Let us denote the light intensity of the pixel as x, and let p(x) represent its probability distribution.
50
We define an information processing unit (IPU) as a model that receives inputs and passes processed
51
information to subsequent stages. As the first stage in an organism’s information processing system,
52
the single pixel IPU carries the same dual objectives as later stages: transmitting information and
53
learning environmental probabilistic distributions. Therefore, the two objectives for the single pixel
54
IPU are to transmit information about x efficiently through its output and to learn p(x).
55"
ONE PIXEL,0.08088235294117647,"Information is quantified by Shannon entropy. To compute the Shannon entropy of the input, we
56
assume x is a discrete variable with M states, after all light intensity is quantized according to quantum
57
mechanics, although M could be a very large number, making x practically indistinguishable from a
58
continuous variable. The information obtained from the pixel when we know the intensity is x can be
59
represented as I(x) = −log p(x). The average information a state of the pixel contains, the Shannon
60
entropy, is given by:
61"
ONE PIXEL,0.08823529411764706,"Hp = − M
X"
ONE PIXEL,0.09558823529411764,"i=1
p(xi) log p(xi).
(1)"
ONE PIXEL,0.10294117647058823,"The IPU transforms the input x into the output y = f(x), where the output space comprises N
62
distinct states. In contrast to previous studies that assumed one-to-one mapping between input and
63
output, here we posit that N ≪M. This assumption is more congruent with biological constraints;
64
for instance, the luminance resolution levels at synapse terminals in a zebrafish’s retina are only about
65
10 [25]. Moreover, this assures that after processing the information is significantly reduced, thereby
66
simplifying the tasks for subsequent stages.
67"
ONE PIXEL,0.11029411764705882,"The function f(x) assigns x into N groups, each corresponding to a fixed y. We denote all x values
68
in group j as Gj, and the size of this group as nj. The entropy of the output is given by
69"
ONE PIXEL,0.11764705882352941,"HQ = − N
X"
ONE PIXEL,0.125,"j=1
Q(yj) log Q(yj),
(2)"
ONE PIXEL,0.1323529411764706,"where Q(y) represents the probability distribution of the output states.
70"
ONE PIXEL,0.13970588235294118,"Previous research [14, 1] has primarily emphasized the first objective of an IPU, which is maximizing
71
the rate of transmission [19]. This goal is particularly relevant for early-stage IPUs, where the
72
distinction between signal and noise is not yet clear. Maximizing the rate of transmission is equivalent
73
to maximizing HQ (see proof in Appendix A), leading to a constant Q(y). Biological neurons have
74
been observed to follow this coding scheme [14].
75"
ONE PIXEL,0.14705882352941177,"Simultaneously, an IPU should also strive to fullfil the second objective and model p(x) as accurately
76
as possible. Mathematically, this involves minimizing the Kullback–Leibler divergence between
77"
ONE PIXEL,0.15441176470588236,"p(x) and the distribution learned by the IPU. This raises an interesting question: Are these two
78
optimization objectives contradictory, or do they essentially represent the same task?
79"
EVEN CODE PRINCIPLE,0.16176470588235295,"3
Even Code Principle
80"
EVEN CODE PRINCIPLE,0.16911764705882354,"To determine how an IPU models p(x) we need to translate the output probability distribution Q(y)
81
into the input space as q(x). q(x) is a step function:
82
q(x) = qj, for x ∈Gj,
(3)
and we have the following relations:
83"
EVEN CODE PRINCIPLE,0.17647058823529413,"Q(yj) =
X"
EVEN CODE PRINCIPLE,0.18382352941176472,"x∈Gj
p(x) =
X"
EVEN CODE PRINCIPLE,0.19117647058823528,"x∈Gj
q(x) = njqj.
(4)"
EVEN CODE PRINCIPLE,0.19852941176470587,"Minimizing the difference between p(x) and q(x) can be achieved by minimizing their Kull-
84
back–Leibler divergence:
85
DKL(p||q)
=
Hpq −Hp,
(5)
where Hpq is the cross entropy. It can be proved that the cross entropy Hpq is equal to the entropy of
86
the learned distribution in the input space defined as (see proof in Appendix B):
87"
EVEN CODE PRINCIPLE,0.20588235294117646,"Hq = −
X"
EVEN CODE PRINCIPLE,0.21323529411764705,"x
q(x) log q(x),
(6)"
EVEN CODE PRINCIPLE,0.22058823529411764,"and we get
88
DKL(p||q) = Hq −Hp.
(7)
Since Hp is fixed, minimizing the KL divergence requires minimizing Hq. The previous question now
89
transforms into understanding the relationship between maximizing the entropy of the distribution in
90
the output space (HQ) and minimizing the entropy of the learned distribution in the input space (Hq).
91"
EVEN CODE PRINCIPLE,0.22794117647058823,"Suppose we have two adjacent zones in the transformed space where the corresponding Q(y1) and
92
Q(y2) are not equal, let’s assume Q(y1) > Q(y2). One can reduce the inequality by shifting the
93
boundary between these two zones and moving one x value from G1 to G2. This shift corresponds
94
to a small change of probability, δ, for both zones. Note that δ is comparable to q1 and q2, as we
95
assume the distribution is smooth. We know that reducing the inequality of Q(y1) and Q(y2) always
96
increases HQ. If the two optimization problems are the same, then Hq should increase; if they are
97
contradictory, Hq should decrease. The change of Hq can be calculated as:
98"
EVEN CODE PRINCIPLE,0.23529411764705882,∆Hq = −[Q(y1) −δ] log Q(y1) −δ
EVEN CODE PRINCIPLE,0.2426470588235294,"n1 −1
−[Q(y2) + δ] log Q(y2) + δ"
EVEN CODE PRINCIPLE,0.25,n2 + 1
EVEN CODE PRINCIPLE,0.25735294117647056,+ Q(y1) log Q(y1)
EVEN CODE PRINCIPLE,0.2647058823529412,"n1
+ Q(y2) log Q(y2)"
EVEN CODE PRINCIPLE,0.27205882352941174,"n2
(8)"
EVEN CODE PRINCIPLE,0.27941176470588236,= q2 −q1 + δ(log q1 −log q2 + 1
EVEN CODE PRINCIPLE,0.2867647058823529,"n1
+ 1"
EVEN CODE PRINCIPLE,0.29411764705882354,"n2
) + O(δ2) + O( 1"
EVEN CODE PRINCIPLE,0.3014705882352941,"n2
1
) + O( 1"
EVEN CODE PRINCIPLE,0.3088235294117647,"n2
2
)
(9)"
EVEN CODE PRINCIPLE,0.3161764705882353,≈q2 −q1 + δ log q1
EVEN CODE PRINCIPLE,0.3235294117647059,"q2
.
(10)"
EVEN CODE PRINCIPLE,0.33088235294117646,"The change can either be positive or negative depending on q1 and q2. Since minimizing Hq and
99
maximizing HQ are not contradictory, these objectives can be tackled independently. Given a fixed
100
number of output levels N, we first maximize HQ to retain as much input information as possible. If
101
further refinement of p(x) modeling is required, we can increase the output resolution N.
102"
EVEN CODE PRINCIPLE,0.3382352941176471,"The aforementioned reasoning extends naturally to multivariate scenarios, as no assumptions about
103
one-dimensionality of the input were made. We articulate the goal of a general information processing
104
unit as follows: An information processing unit (IPU) transforms input space with M states into
105
output space with N states, where N ≪M. Given a smooth input probability distribution as
106
M →∞and a piecewise smooth transformation function, the sole goal of an IPU with a fixed output
107
resolution N is to yield an even output probability distribution, hence retaining maximum information
108
from the input. To attain better modeling precision, the output resolution N of the IPU should be
109
increased. This will be referred to as the principle of even code. In the next sections, we will apply
110
the even code principle to more complex inputs.
111"
TWO PIXELS,0.34558823529411764,"4
Two Pixels
112"
TWO PIXELS,0.35294117647058826,"For two pixels (x1, x2), we can either use one IPU directly to model p(x1, x2) or use two IPUs to
113
model p(x1) and p(x2) separately, followed by another IPU to model the outputs p(y1, y2). We will
114
use the second approach, as processing as much information locally reduces the cost of information
115
transfer. In fact, when images are stored on computers, gamma encoding is utilized to create an
116
approximately even distribution of pixel values. When these images are displayed, pixel values
117
undergo gamma correction to recover the original statistics for human eyes to process. In the
118
following sections, we will assume that all pixel values x have already been processed by dedicated
119
IPUs, resulting in a roughly even probability distribution.
120"
TWO PIXELS,0.3602941176470588,"The probability distribution p(x1, x2) of natural images is relatively simple. The majority of the
121
probability is concentrated around the diagonal line x1 −x2 = 0, with p(x1, x2) rapidly decaying
122
as |x1 −x2| increases (see Fig. 1 (a) for example). Intuitively, we can use lines parallel or/and
123
perpendicular to x1 −x2 = 0 to divide the probability distribution into even partitions.
124"
ONE BASIS,0.36764705882352944,"4.1
One Basis
125"
ONE BASIS,0.375,"To investigate how IPUs learn p(x1, x2), we conduct numerical experiments using a multilayer
126
perceptron (MLP) as the IPU to approximate y = f(x) and model p(x) [23]. Other function
127
approximation methods may also be applicable. To partition the input probability distribution with
128
one set of parallel lines, only one IPU with N output nodes is needed. According to the even code
129
principle, for each input, only one of the N output nodes should be activated, and the probability
130
of activating any one of the N output nodes should be equal. We use the softmax function as the
131
last layer of the MLP to ensure each output value is within [0, 1], and that if a node is activated
132
(output value equals 1), it is the only node being activated. We use stochastic gradient descent and
133
the following loss function to train the MLP:
134 E =
X"
ONE BASIS,0.38235294117647056,"i
⟨ysi⟩s log⟨ysi⟩s + k⟨−
X"
ONE BASIS,0.3897058823529412,"i
ysi log ysi⟩s.
(11)"
ONE BASIS,0.39705882352941174,"ysi represents the value of the i-th output node for the s-th input sample, while ⟨⟩s denotes the average
135
over all samples in a training batch. The first term in the loss function ensures each output node has
136
an equal chance to be activated on average. The second term promotes activation of only one node
137
per input while suppressing the remaining nodes, mimicking lateral inhibition when combined with
138
the softmax function. The factor k balances the two terms to achieve the desired result. Fig. 1 (a)
139
show the results learned by MLPs with 16 output nodes.
140"
MULTIPLE BASES,0.40441176470588236,"4.2
Multiple Bases
141"
MULTIPLE BASES,0.4117647058823529,"To partition the input space with two sets of orthogonal lines we need two MLPs. The orthogonality
142
is achieved by enforcing
143"
MULTIPLE BASES,0.41911764705882354,"Q(y1, y2) =
1
N1N2
,
(12)"
MULTIPLE BASES,0.4264705882352941,"where N1 and N2 represent the number of output nodes of the two MLPs (refer Appendix C for
144
proof). If more than two orthogonal bases are required for partitioning the space, we can enforce
145
Eq. (12) for each combination of two bases to ensure orthogonality between them. The loss function
146
for multiple orthogonal bases with independent states is
147"
MULTIPLE BASES,0.4338235294117647,"E =
1
 B
2

X"
MULTIPLE BASES,0.4411764705882353,"<b,b′> X"
MULTIPLE BASES,0.4485294117647059,"ij
⟨ybsiyb′sj⟩s log⟨ybsiyb′sj⟩s + k B ⟨− B
X b=1 X"
MULTIPLE BASES,0.45588235294117646,"i
ybsi log ybsi⟩s,
(13)"
MULTIPLE BASES,0.4632352941176471,"where b is the base index, and B is the number of bases. P"
MULTIPLE BASES,0.47058823529411764,"<b,b′> denotes the sum over all
 B
2

148
combinations of two distinct bases. ybsiyb′sj is the probability Q(yb, yb′) for the sample s when yb
149
and yb′ take their i-th and j-th value respectively.
150"
MULTIPLE BASES,0.47794117647058826,"Fig. 1 (b) shows an example of two-pixel input space partitioning using two orthogonal bases. For a
151
more detailed discussion on the experiments and additional results, refer to Appendix D.
152"
MULTIPLE BASES,0.4852941176470588,"(a)
(b)"
MULTIPLE BASES,0.49264705882352944,"Figure 1: Evenly partitioning the two-pixel probability distribution learned by multilayer perceptrons
(MLPs). The X and Y axes represent the rescaled intensities x1 and x2 of the two pixels in the range
[0, 1]. The quantity n(x1, x2) + 1 is plotted in gray on a log scale, where n(x1, x2) denotes the
number of occurrences of the two-pixel values among the sampled data. Color lines indicate the
boundaries of states for each basis learned by an MLP, with one color representing one basis. (a) One
basis with 16 independent states, which partitions the space based on the total intensity x1 + x2. (b)
Two orthogonal bases, each with 10 independent states, dividing the space based on the total intensity
x1 + x2 and the contrast x1 −x2 approximately."
MULTIPLE BASES,0.5,"Additionally, it’s worth noting that orthogonal bases with independent states might model grid cells
153
[11] in the entorhinal cortex, though this topic is beyond the scope of the current paper.
154"
IMAGE PATCHES,0.5073529411764706,"5
Image Patches
155"
IMAGE PATCHES,0.5147058823529411,"Next we move on to study gray and color image patches. We use x to represent the vector of input
156
pixel values of the image patch. The multivariate input probability distribution p(x) is considerably
157
more complex compared to the previous examples. If we use only one basis to discretize the input
158
probability space (e.g. Fig. 1 (a) in Appendix D), the required number of independent states for a good
159
approximation would be very large, making the evaluation of the softmax function computationally
160
expensive. On the other hand, using multiple orthogonal bases would also significantly increase the
161
computational cost to ensure orthogonality if the number of bases is more than just a few. Additionally,
162
determining the optimal number of bases and the number of independent states for each basis are
163
challenging.
164"
IMAGE PATCHES,0.5220588235294118,"Aside from the computational cost, another issue arises when working with image patches: we want
165
the representation to capture the similarity between inputs. However, using orthogonal bases with
166
independent states makes it difficult to gauge input similarity through methods such as calculating
167
the difference between representations, even if we can establish an order for the states of each basis.
168
Therefore, we need a more suitable coding scheme for complex inputs like image patches.
169"
IMAGE PATCHES,0.5294117647058824,"Real-valued vectors are a natural choice, given their extensive use in representing a variety of entities
170
such as images, texts, and categorical variables [13, 22, 10]. The norm of the difference between
171
two vectors can function as a measure of similarity. Nevertheless, if we want the representation y to
172
mirror input similarity, each value of y should encapsulate all samples perceived as identical within
173
the same group G. Under this constraint, Q(y) cannot remain constant, thereby conflicting with the
174
even code principle.
175"
IMAGE PATCHES,0.5367647058823529,"The resolution to this conflict involves permitting the representation to mirror input similarity at the
176
most granular level, while enforcing the even code principle at a larger scale in the transformed space.
177
We will detail this method in subsequent sections.
178"
LOSS FUNCTION,0.5441176470588235,"5.1
Loss Function
179"
LOSS FUNCTION,0.5514705882352942,"To promote even distribution, we incorporate a loss function that compels input samples to repel each
180
other in the transformed space. This repulsive force diminishes with increasing distance, as described
181
by the following equation:
182
E = ⟨−ln |ys −ys′|⟩<s,s′>.
(14)
Here, −ln |ys −ys′| represents the potential energy due to the repulsive force, which is proportional
183
to the inverse of the Minkowski distance between the representations of samples s and s′ in the
184
transformed space. Alternative forms of potential energy and distance measures could also be
185
applicable. ⟨⟩<s,s′> denotes the average over all sample pairs.
186"
LOSS FUNCTION,0.5588235294117647,"Should numerous samples converge at one point in the transformed space, they will exert a strong
187
repulsive force in the surrounding area, thereby discouraging other samples from occupying nearby
188
positions. To prevent samples from pushing each other infinitely far apart, we restrict the represen-
189
tation values to be within the range [0, 1]. With this constraint, the repulsive force pushes samples
190
towards the vertices of the unit hypercube, effectively reducing the representations from real vectors
191
to binary vectors. As a result, an even distribution is achieved on a larger scale in the transformed
192
space, which consists solely of the vertices.
193"
LOSS FUNCTION,0.5661764705882353,"In the context of binary vectors, the collection of output nodes can be viewed as a vocabulary,
194
and activated nodes by an input image patch act as its representative tokens. Unlike fixed-length
195
representations with real-valued vectors, binary representations can employ fewer tokens for more
196
common image patches (e.g., homogeneous patches), and more tokens for less common, structurally-
197
rich patches. This can be accomplished by introducing a second term, ⟨|ys|⟩s, to the loss function,
198
which echoes the sparsity regularization term found in various studies [9, 16, 26, 27, 29, 4]. The
199
updated loss function becames:
200"
LOSS FUNCTION,0.5735294117647058,"E = ⟨−ln |ys −ys′|⟩<s,s′> + α⟨|ys|⟩s,
(15)"
LOSS FUNCTION,0.5808823529411765,"where α is a free parameter to adjust sparsity.
201"
LOSS FUNCTION,0.5882352941176471,"In practice, we add a small value ϵ = 10−38 to the distance, allowing slightly different samples
202
to share the same representation and enhancing numerical stability. Another approach to improve
203
numerical stability involves using a theoretically equivalent form of the loss function, which instead
204
of allowing samples to repel each other in the output space, we enable nodes to repel one another,
205
encouraging output nodes to be as independent as possible [24].
206"
EXPERIMENTS,0.5955882352941176,"5.2
Experiments
207"
EXPERIMENTS,0.6029411764705882,"In the following experiments, we use either a single MLP with N outputs, or N MLPs each with
208
one output, as the IPU to approximate the transformation function y = f(x) and model p(x). The
209
last layer of the MLP is a sigmoid layer, ensuring the output value ranges between 0 and 1. Our
210
training data comprises random image patches extracted from the COCO 2017 image dataset [18] or
211
the ImageNet dataset [6]. No image preprocessing is used. Additional training details are provided in
212
Appendix E.
213"
OUTPUT STATISTICS,0.6102941176470589,"5.2.1
Output Statistics
214"
OUTPUT STATISTICS,0.6176470588235294,"First, we examine the statistics of the learned representation. Across all experiments, we observe
215
qualitatively similar output statistics, irrespective of the IPU architectures and training specifics,
216
provided the training has properly converged. For illustration, we present an example using a model
217
trained on 5 × 5 color image patches. It uses 96 MLPs, each with one output node and a middle
218
layer of 48 nodes, as the IPU. Following training, the model is used to generate representations for 1
219
million random image patches for this analysis.
220"
OUTPUT STATISTICS,0.625,"(a)
(b)"
OUTPUT STATISTICS,0.6323529411764706,"Figure 2: Statistical analysis of the learned representation using the loss function Eq. (15). (a)
Histogram of the model’s output values on a log scale. (b) Probability of an output node being
activated by a random image patch."
OUTPUT STATISTICS,0.6397058823529411,"Fig. 2 (a) presents the histogram of output values on a logarithmic scale. The vast majority of output
221
values are either at 0 or 1. As such during inference, we can round the outputs to yield a binary
222
representation. Fig. 2 (b) illustrates the probability of an output node being activated by a random
223
image patch. All nodes demonstrate similar activation probabilities, indicating an even distribution at
224
this coarse scale. Further statistical analysis of the output representation is available in Appendix F.
225"
IMAGE PATCH SIMILARITY,0.6470588235294118,"5.2.2
Image Patch Similarity
226"
IMAGE PATCH SIMILARITY,0.6544117647058824,"Next, to examine how the learned representation reflects the similarity between image patches, we
227
display 16 random image patches, each followed by 9 image patches similar to them in the binary
228
representation space, as shown in Fig. 3 (a). The same 5 × 5 color image patch model is used. The
229
learned representation clearly captures perceptual similarity. The results shown in Fig. 2, Fig. 3 (a),
230
and additional results in Appendix E confirm that with the loss function Eq. (15), we can indeed learn
231
a sparse binary representation which reflects the image similarity while adhering to the even code
232
principle.
233"
IMAGE PATCH SIMILARITY,0.6617647058823529,"For comparison with a traditional convolutional neural network, we present the results generated with
234
the first 10 layers of a VGG16 model [31] pre-trained on ImageNet in Fig. 3 (b). The image patch
235
representation from the first 10 layers of the VGG16 model is a float vector of size 128. The even
236
code model, with only 96 binary outputs, achieves results similar to the VGG16 model. These 96
237
binary outputs occupy the same storage space as a float vector of length 3 — just 1/42 of the VGG16
238
representation’s size, which underscores the exceptional efficiency of the even code method in image
239
patch representation.
240"
LOCAL EDGE DETECTORS AND ORIENTATION-SELECTIVE UNITS,0.6691176470588235,"5.2.3
Local Edge Detectors and Orientation-Selective Units
241"
LOCAL EDGE DETECTORS AND ORIENTATION-SELECTIVE UNITS,0.6764705882352942,"Biological visual systems’ initial stages are known to possess local edge detectors and orientation-
242
selective units [17, 2]. While CNNs have been successfully trained to detect boundaries via supervised
243
learning [20], their initial layers have not shown proficiency in edge detection [15]. Notably, prevalent
244
local edge detection algorithms, such as the Canny edge detector [5], still primarily rely on non-deep
245
learning methods.
246"
LOCAL EDGE DETECTORS AND ORIENTATION-SELECTIVE UNITS,0.6838235294117647,"Does the even code model, proposed as the initial stage of an optimal image processing system,
247
resemble biological systems more closely? To answer this, we trained an even code model on 4 × 4
248
grayscale image patches and applied it to images with a stride of 1 pixel, generating feature maps for
249
each output node. The model comprises a MLP with 64 outputs and an intermediary layer with 100
250
nodes. Fig. 4 illustrates the feature maps of 4 output nodes of the even code model for 4 different
251
input images. It also shows edges generated by the Canny edge detector as comparison. Interestingly,
252"
LOCAL EDGE DETECTORS AND ORIENTATION-SELECTIVE UNITS,0.6911764705882353,"(a) Even code model with 96 binary outputs
(b) Early layers of VGG16 with 128 real outputs"
LOCAL EDGE DETECTORS AND ORIENTATION-SELECTIVE UNITS,0.6985294117647058,"Figure 3: Image patches with the shortest distance in the representation space to 16 randomly selected
image patches. The first column presents the 16 random image patches, while the succeeding nine
columns display patches that are closest to the first-column patches in the same row. (a) Distances
are computed using using an even code model with 96 binary outputs. (b) Distances are computed
using the first 10 layers of a pretrained VGG16 model with 128 real outputs."
LOCAL EDGE DETECTORS AND ORIENTATION-SELECTIVE UNITS,0.7058823529411765,"with this simple network architecture, the even code model demonstrated a remarkable capability in
253
edge detection, rivaling the multi-stage Canny edge detector.
254"
LOCAL EDGE DETECTORS AND ORIENTATION-SELECTIVE UNITS,0.7132352941176471,"Furthermore, Fig. 5 shows the feature maps of 5 output nodes for a sample bike image. Spokes of
255
different orientations activate different nodes, indicating that these output nodes of the even code
256
model have varying orientation preferences, similar to orientation-selective units found in bilogical
257
systems.
258"
CONCLUSION,0.7205882352941176,"6
Conclusion
259"
CONCLUSION,0.7279411764705882,"In summary, this paper demonstrates that maximizing the information-carrying capacity of output
260
channels and modeling the input probability distribution are not mutually exclusive objectives and
261
can be pursued independently. Given a specific output resolution, the sole goal of an information
262
processing unit is to preserve as much information from the input as possible by ensuring an even
263
distribution of samples in the output space. We applied the even code principle to study the probability
264
distributions of two-pixel systems and image patches. For the two-pixel system, we learned orthogonal
265
bases with independent states to model its probability distribution. For image patches, the even code
266
approach naturally led to a nonlinear sparse binary representation. The even code model also shares
267
additional similarities with early visual systems, such as the presence of local edge-detecting and
268
orientation-selective units. These similarities suggest that the even code model could potentially
269
serve as a new representation for neurons in early visual systems.
270"
CONCLUSION,0.7352941176470589,"Figure 4: Feature maps of nodes resembling local edge detectors. The first column presents four
grayscale test images. Each subsequent column, except the last one, displays the feature maps
corresponding to the same output node for the four test images. The last column shows edges
generated by the multi-stage Canny edge detector for comparison."
CONCLUSION,0.7426470588235294,"Figure 5: Feature maps of five orientation-selective nodes applied to a test image. Spokes in different
orientations activate distinct nodes, illustrating the orientation-selectivity of these nodes."
CONCLUSION,0.75,"There are several intriguing directions for future research. First, the even code model has been
271
applied to inputs ranging from as simple as one pixel to more complex color image patches. Can we
272
extend its application beyond the early stage of visual information processing? Second, the even code
273
model could be extended to videos by incorporating an additional time dimension alongside color,
274
width, and height dimensions. Investigating time-varying inputs, which produce spike train-like
275
outputs, and conducting an in-depth comparison with early visual systems would be very interesting.
276
Third, the even code model can also be extended to binocular vision data by adding another input
277
dimension of size two. Whether the model with binocular and/or video data can construct a 3D
278
model of the world based on data of two spatial dimensions is an intriguing question. Fourth, while
279
this paper focuses on visual information, the even code model is a general method that could be
280
applied to model other multivariate probability distributions as well. Lastly, on the application
281
side, the even code model has potential in various areas, including local edge detection, image and
282
video compression/denoising/retrieval, texture classification, and multispectral/hyperspectral image
283
processing.
284"
REFERENCES,0.7573529411764706,"References
285"
REFERENCES,0.7647058823529411,"[1] Joseph J. Atick. Could information theory provide an ecological theory of sensory processing?
286
Network: Computation in neural systems, 3(2):213–251, 1992.
287"
REFERENCES,0.7720588235294118,"[2] Tom Baden, Philipp Berens, Katrin Franke, Miroslav Román Rosón, Matthias Bethge, and
288
Thomas Euler.
The functional diversity of retinal ganglion cells in the mouse.
Nature,
289
529(7586):345–350, 2016.
290"
REFERENCES,0.7794117647058824,"[3] Horace B Barlow et al. Possible principles underlying the transformation of sensory messages.
291
Sensory communication, 1(01):217–233, 1961.
292"
REFERENCES,0.7867647058823529,"[4] Michael Beyeler, Emily L. Rounds, Kristofor D. Carlson, Nikil Dutt, and Jeffrey L. Krichmar.
293
Neural correlates of sparse coding and dimensionality reduction. PLOS Computational Biology,
294
15(6):e1006908, jun 2019.
295"
REFERENCES,0.7941176470588235,"[5] John Canny. A computational approach to edge detection. IEEE Transactions on pattern
296
analysis and machine intelligence, (6):679–698, 1986.
297"
REFERENCES,0.8014705882352942,"[6] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-
298
scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern
299
recognition, pages 248–255. Ieee, 2009.
300"
REFERENCES,0.8088235294117647,"[7] James J DiCarlo, Davide Zoccolan, and Nicole C Rust. How does the brain solve visual object
301
recognition? Neuron, 73(3):415–434, 2012.
302"
REFERENCES,0.8161764705882353,"[8] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,
303
Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al.
304
An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint
305
arXiv:2010.11929, 2020.
306"
REFERENCES,0.8235294117647058,"[9] David J. Field. What Is the Goal of Sensory Coding? Neural Computation, 6(4):559–601, jul
307
1994.
308"
REFERENCES,0.8308823529411765,"[10] Cheng Guo and Felix Berkhahn. Entity embeddings of categorical variables. arXiv preprint
309
arXiv:1604.06737, 2016.
310"
REFERENCES,0.8382352941176471,"[11] Torkel Hafting, Marianne Fyhn, Sturla Molden, May Britt Moser, and Edvard I. Moser. Mi-
311
crostructure of a spatial map in the entorhinal cortex. Nature 2005 436:7052, 436(7052):801–
312
806, jun 2005.
313"
REFERENCES,0.8455882352941176,"[12] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
314
recognition. arxiv 2015. arXiv preprint arXiv:1512.03385, 14, 2015.
315"
REFERENCES,0.8529411764705882,"[13] G. E. Hinton and R. R. Salakhutdinov. Reducing the Dimensionality of Data with Neural
316
Networks. Science, 313(5786):504–507, 2006.
317"
REFERENCES,0.8602941176470589,"[14] Simon Laughlin. A Simple Coding Procedure Enhances a Neuron’s Information Capacity.
318
Zeitschrift für Naturforschung C, 36(9-10):910–912, oct 1981.
319"
REFERENCES,0.8676470588235294,"[15] Minh Le and Subhradeep Kayal. Revisiting edge detection in convolutional neural networks. In
320
2021 International Joint Conference on Neural Networks (IJCNN), pages 1–9. IEEE, 2021.
321"
REFERENCES,0.875,"[16] Ann B Lee, Kim S Pedersen, and David Mumford. The Nonlinear Statistics of High-Contrast
322
Patches in Natural Images. International Journal of Computer Vision, 54(5413):83–103, 2003.
323"
REFERENCES,0.8823529411764706,"[17] William R Levick. Receptive fields and trigger features of ganglion cells in the visual streak of
324
the rabbit’s retina. The Journal of physiology, 188(3):285, 1967.
325"
REFERENCES,0.8897058823529411,"[18] Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays,
326
Pietro Perona, Deva Ramanan, C. Lawrence Zitnick, and Piotr Dollár. Microsoft coco: Common
327
objects in context, 2014.
328"
REFERENCES,0.8970588235294118,"[19] Ralph Linsker. Self-organization in a perceptual network. Computer, 21(3):105–117, 1988.
329"
REFERENCES,0.9044117647058824,"[20] David R Martin, Charless C Fowlkes, and Jitendra Malik. Learning to detect natural image
330
boundaries using local brightness, color, and texture cues. IEEE transactions on pattern analysis
331
and machine intelligence, 26(5):530–549, 2004.
332"
REFERENCES,0.9117647058823529,"[21] Richard H. Masland. The Neuronal Organization of the Retina, oct 2012.
333"
REFERENCES,0.9191176470588235,"[22] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word
334
representations in vector space. arXiv preprint arXiv:1301.3781, 2013.
335"
REFERENCES,0.9264705882352942,"[23] Guido Montúfar, Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio. On the Number of
336
Linear Regions of Deep Neural Networks. Advances in Neural Information Processing Systems,
337
4(January):2924–2932, feb 2014.
338"
REFERENCES,0.9338235294117647,"[24] Jean Pierre Nadal and Nestor Parga. Nonlinear neurons in the low-noise limit: a factorial code
339
maximizes information transfer. http://dx.doi.org/10.1088/0954-898X_5_4_008, 5(4):565–581,
340
2009.
341"
REFERENCES,0.9411764705882353,"[25] Benjamin Odermatt, Anton Nikolaev, and Leon Lagnado. Encoding of Luminance and Contrast
342
by Linear and Nonlinear Synapses in the Retina. Neuron, 73:758–773, 2012.
343"
REFERENCES,0.9485294117647058,"[26] Bruno A Olshausen. sparse codes and spikes. Probabilistic models of the brain, page 257, 2002.
344"
REFERENCES,0.9558823529411765,"[27] Bruno A Olshausen and David J Field. Sparse coding of sensory inputs. Current opinion in
345
neurobiology, 14(4):481–487, 2004.
346"
REFERENCES,0.9632352941176471,"[28] Bruno A. Olshausen and David J. Field. Emergence of simple-cell receptive field properties by
347
learning a sparse code for natural images. Nature, oct 2015.
348"
REFERENCES,0.9705882352941176,"[29] Marc’Aurelio Ranzato, Christopher Poultney, Sumit Chopra, and Yann Cun. Efficient learning of
349
sparse representations with an energy-based model. Advances in neural information processing
350
systems, 19, 2006.
351"
REFERENCES,0.9779411764705882,"[30] Joshua R. Sanes and S. Lawrence Zipursky. Design Principles of Insect and Vertebrate Visual
352
Systems, 2010.
353"
REFERENCES,0.9852941176470589,"[31] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale
354
image recognition. arXiv preprint arXiv:1409.1556, 2014.
355"
REFERENCES,0.9926470588235294,"[32] JH van Hateren. A theory of maximizing sensory information. Biol. Cybern, 68:23–29, 1992.
356"
