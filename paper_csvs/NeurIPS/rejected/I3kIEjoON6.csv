Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.00102880658436214,"For a very long time, computational approaches to the design of new ma-
1"
ABSTRACT,0.00205761316872428,"terials have relied on an iterative process of finding a candidate material
2"
ABSTRACT,0.0030864197530864196,"and modeling its properties. AI has played a crucial role in this regard,
3"
ABSTRACT,0.00411522633744856,"helping to accelerate the discovery and optimization of crystal properties
4"
ABSTRACT,0.0051440329218107,"and structures through advanced computational methodologies and data-
5"
ABSTRACT,0.006172839506172839,"driven approaches. To address the problem of new materials design and
6"
ABSTRACT,0.00720164609053498,"fasten the process of new materials search, we have applied latest generative
7"
ABSTRACT,0.00823045267489712,"approaches to the problem of crystal structure design, trying to solve the
8"
ABSTRACT,0.009259259259259259,"inverse problem: by given properties generate a structure that satisfies them
9"
ABSTRACT,0.0102880658436214,"without utilizing supercomputer powers. In our work we propose two ap-
10"
ABSTRACT,0.01131687242798354,"proaches: 1) conditional structure modification: optimization of the stability
11"
ABSTRACT,0.012345679012345678,"of an arbitrary atomic configuration, using the energy difference between the
12"
ABSTRACT,0.013374485596707819,"most energetically favorable structure and all its less stable polymorphs and
13"
ABSTRACT,0.01440329218106996,"2) conditional structure generation. We used a representation for materials
14"
ABSTRACT,0.015432098765432098,"that includes the following information: lattice, atom coordinates, atom
15"
ABSTRACT,0.01646090534979424,"types, chemical features, space group and formation energy of the structure.
16"
ABSTRACT,0.01748971193415638,"The loss function was optimized to take into account the periodic boundary
17"
ABSTRACT,0.018518518518518517,"conditions of crystal structures. We have applied Diffusion models approach,
18"
ABSTRACT,0.01954732510288066,"Flow matching, usual Autoencoder (AE) and compared the results of the
19"
ABSTRACT,0.0205761316872428,"models and approaches. As a metric for the study, physical pymatgen
20"
ABSTRACT,0.021604938271604937,"matcher was employed: we compare target structure with generated one
21"
ABSTRACT,0.02263374485596708,"using default tolerances. So far, our modifier and generator produce struc-
22"
ABSTRACT,0.023662551440329218,"tures with needed properties with accuracy 41% and 82% respectively. To
23"
ABSTRACT,0.024691358024691357,"prove the offered methodology efficiency, inference have been carried out,
24"
ABSTRACT,0.0257201646090535,"resulting in several potentially new structures with formation energy below
25"
ABSTRACT,0.026748971193415638,"the AFLOW-derived convex hulls.
26"
INTRODUCTION,0.027777777777777776,"1
Introduction
27"
INTRODUCTION,0.02880658436213992,"The search for novel materials with specified properties has been a cornerstone of scientific
28"
INTRODUCTION,0.029835390946502057,"exploration for decades. From the discovery of semiconductors revolutionizing electronics
29"
INTRODUCTION,0.030864197530864196,"to the development of superalloys enhancing aerospace technologies, the synthesis of new
30"
INTRODUCTION,0.03189300411522634,"materials has continually propelled technological advancements.
31"
INTRODUCTION,0.03292181069958848,"However, traditional methods for material discovery often employ exhaustive trial and error
32"
INTRODUCTION,0.033950617283950615,"experimental approaches. In turn, computational efforts, relying on density functional theory
33"
INTRODUCTION,0.03497942386831276,"(DFT)[1] approaches, usually require huge amounts of computing power. In this regard,
34"
INTRODUCTION,0.0360082304526749,"automatic descriptor generators[2], GNNs[3][4] and transferable GNN models [5] fueled
35"
INTRODUCTION,0.037037037037037035,"combination of these methods and machine learning (ML) approaches. In particular, the
36"
INTRODUCTION,0.03806584362139918,"utilization of generative machine learning models, such as Variational Autoencoder[6] and
37"
INTRODUCTION,0.03909465020576132,"GANs[7], presents a paradigm shift in how crystal structures are generated and optimized.
38"
INTRODUCTION,0.040123456790123455,"By harnessing the power of data-driven approaches, we can navigate the vast landscape of
39"
INTRODUCTION,0.0411522633744856,"possible crystal structures with unprecedented efficiency and precision.
40"
INTRODUCTION,0.04218106995884774,"Recent advancements in the field of materials discovery have yielded promising results
41"
INTRODUCTION,0.043209876543209874,"through various innovative approaches. For instance, FTCP[6] utilizes Autoencoders for
42"
INTRODUCTION,0.044238683127572016,"uncovering new materials, while CubicGAN[7] leverages GANs for the discovery of cubic
43"
INTRODUCTION,0.04526748971193416,"crystal materials. Additionally, Physics Guided Crystal Generative Model (PGCGM)[8] has
44"
INTRODUCTION,0.046296296296296294,"introduced a method for generating crystal structures based on specific space groups encoding.
45"
INTRODUCTION,0.047325102880658436,"DP-CDVAE[9] is a model, that combines VAE and diffusion approaches. MatterGen[10]
46"
INTRODUCTION,0.04835390946502058,"employed equivariant GNNs as score matching function in diffusion processes for crystal
47"
INTRODUCTION,0.04938271604938271,"structure generation.
48"
INTRODUCTION,0.050411522633744855,"One of the most discussed frameworks is GNoME[11] that has made most recent and large
49"
INTRODUCTION,0.051440329218107,"advancements in the field of the new materials discovery employs a sophisticated pipeline
50"
INTRODUCTION,0.05246913580246913,"to discover new materials, particularly focusing on inorganic crystals. This allows for the
51"
INTRODUCTION,0.053497942386831275,"discovery of innovative materials beyond known structures.
52"
INTRODUCTION,0.05452674897119342,"After generating candidate structures through both pipelines, GNoME evaluates their stability
53"
INTRODUCTION,0.05555555555555555,"by predicting their formation energies. Based on the comparison of the obtained formation
54"
INTRODUCTION,0.056584362139917695,"energy with those of the known competing phases (i.e. stability assessment), the model selects
55"
INTRODUCTION,0.05761316872427984,"the most promising candidates for further evaluation using known theoretical frameworks.
56"
INTRODUCTION,0.05864197530864197,"The question of the completeness of chemical space arises due to two main concerns with
57"
INTRODUCTION,0.059670781893004114,"GNoME-derived stable structures. Firstly, they mostly contain three or more unique elements,
58"
INTRODUCTION,0.060699588477366256,"while ternary and quaternary structures are less explored than binary compounds. Secondly,
59"
INTRODUCTION,0.06172839506172839,"the comparison of GNoME-discovered structures to the Materials Project, which has 154,718
60"
INTRODUCTION,0.06275720164609054,"materials, is flawed since larger databases like AFLOW, NOMAD, and the Open Quantum
61"
INTRODUCTION,0.06378600823045268,"Materials Database contain millions of entries. This raises questions about the novelty of
62"
INTRODUCTION,0.06481481481481481,"the discovered materials.
63"
INTRODUCTION,0.06584362139917696,"In this study, we present an end-to-end framework for the generation of crystal structures with
64"
INTRODUCTION,0.0668724279835391,"specified properties using advanced generative AI techniques. The basis architecture of the
65"
INTRODUCTION,0.06790123456790123,"models is Autoencoder, enabling encoding and decoding structural representations. Then, the
66"
INTRODUCTION,0.06893004115226338,"most commonly used generative approaches in image generation were utilized to model prob-
67"
INTRODUCTION,0.06995884773662552,"ability distribution transformations, and to capture complex underlying structure-property
68"
INTRODUCTION,0.07098765432098765,"relationships within our dataset: Flow Matching[12], Denoising Diffusion Probabilistic
69"
INTRODUCTION,0.0720164609053498,"Models(DDPM)[13], and Denoising Diffusion Implicit Models(DDIM)[14]. Through the
70"
INTRODUCTION,0.07304526748971193,"integration of these techniques, we aim to transcend conventional limitations in materials
71"
INTRODUCTION,0.07407407407407407,"discovery, paving the way for accelerated predictions of materials with desired properties.
72"
INTRODUCTION,0.07510288065843622,"To employ model architectures often used for image/video generation, a matrix represen-
73"
INTRODUCTION,0.07613168724279835,"tation of crystal structures was developed, containing crucial information such as chemical
74"
INTRODUCTION,0.07716049382716049,"composition, atomic coordinates, symmetries (space group), and formation energies. Within
75"
INTRODUCTION,0.07818930041152264,"the approach proposed, it has become important to develop a novel metric for assessing
76"
INTRODUCTION,0.07921810699588477,"the similarity between generated structures and target configurations. This metric obviates
77"
INTRODUCTION,0.08024691358024691,"the need for computationally expensive DFT calculations, allowing for rapid validation and
78"
INTRODUCTION,0.08127572016460906,"refinement of generated structures. Furthermore, we introduce a loss function that accounts
79"
INTRODUCTION,0.0823045267489712,"for the periodic boundary conditions inherent in crystal lattices, ensuring the fidelity of the
80"
INTRODUCTION,0.08333333333333333,"generated structures.
81"
INTRODUCTION,0.08436213991769548,"Our study explores two distinct approaches for crystal structure prediction: 1) conditional
82"
INTRODUCTION,0.08539094650205761,"structure modification and 2) conditional structure generation. The former involves optimiz-
83"
INTRODUCTION,0.08641975308641975,"ing the stability of existing structures by generating more stable polymorphs, while the latter
84"
INTRODUCTION,0.0874485596707819,"entails the generation of entirely new structures based on user-defined criteria. Through
85"
INTRODUCTION,0.08847736625514403,"rigorous analysis, we demonstrate the efficacy of our approach in discovering novel materials
86"
INTRODUCTION,0.08950617283950617,"with desired properties.
87"
INTRODUCTION,0.09053497942386832,"Importantly, to validate the utility of our framework, we conducted a series of generation
88"
INTRODUCTION,0.09156378600823045,"experiments using the Vienna Ab initio simulation package(VASP)[15] as a tool for inference
89"
INTRODUCTION,0.09259259259259259,"validation. Remarkably, our method facilitated the discovery of 6 structures below the
90"
INTRODUCTION,0.09362139917695474,"corresponding convex hull. This significant outcome underscores the remarkable potential of
91"
INTRODUCTION,0.09465020576131687,"our framework in uncovering thermodynamically stable materials, thereby offering promising
92"
INTRODUCTION,0.09567901234567901,"avenues for advanced materials discovery and design.
93"
INTRODUCTION,0.09670781893004116,"2
Data, Dataset
94"
DATA OVERVIEW,0.09773662551440329,"2.1
Data overview
95"
DATA OVERVIEW,0.09876543209876543,"In this study, the AFLOW database[16] was utilized as a source of data on the structures
96"
DATA OVERVIEW,0.09979423868312758,"and properties of materials. AFLOW is an extensive and comprehensive database that
97"
DATA OVERVIEW,0.10082304526748971,"consolidates a vast array of materials-related information, offering an expansive repository
98"
DATA OVERVIEW,0.10185185185185185,"for crystallographic data, computed properties, and various other materials-science-related
99"
DATA OVERVIEW,0.102880658436214,"datasets. AFLOW database contains more than 3.5 million structures.
100"
DATA OVERVIEW,0.10390946502057613,"From the extensive collection housed within AFLOW, the focus was narrowed to select only
101"
DATA OVERVIEW,0.10493827160493827,"polymorphs, because models are trained to distinguish composition-property and structure-
102"
DATA OVERVIEW,0.10596707818930041,"property relations with numerous structures of the same chemical composition. Specifically,
103"
DATA OVERVIEW,0.10699588477366255,"the selection process targeted polymorphic structures with 4 to 60 atoms within their unit
104"
DATA OVERVIEW,0.10802469135802469,"cells. This criterion aimed to encompass a diverse yet manageable subset of structures,
105"
DATA OVERVIEW,0.10905349794238683,"balancing complexity with computational feasibility. By filtering polymorphs based on their
106"
DATA OVERVIEW,0.11008230452674897,"atom count, the dataset was balanced.
107"
DATA OVERVIEW,0.1111111111111111,"Moreover, in order to decrease the complexity of the data, we have removed all structures
108"
DATA OVERVIEW,0.11213991769547325,"containing elements and space groups found in less than 1% of all structures. The entire
109"
DATA OVERVIEW,0.11316872427983539,"dataset consisted of more than 85000 polymorph groups including more than 2.1 million
110"
DATA OVERVIEW,0.11419753086419752,"structures. The minimum size of group of polymorphs was 7 samples and the maximum one
111"
DATA OVERVIEW,0.11522633744855967,"was 71 samples. The total number of space groups was 19 and the total number of chemical
112"
DATA OVERVIEW,0.11625514403292181,"species over the dataset was 55. Each structure S in the dataset is described by the following
113"
DATA OVERVIEW,0.11728395061728394,"features:
114"
DATA OVERVIEW,0.1183127572016461,"• Fractional coordinates of atoms in the lattice basis Xcoord (has 60 rows with 3
115"
DATA OVERVIEW,0.11934156378600823,"coordinates x, y, z each) and Xlattice (matrix 3 by 3 constructed of 3 base vectors).
116"
DATA OVERVIEW,0.12037037037037036,"Overall matrix X of structure is constructed as
117"
DATA OVERVIEW,0.12139917695473251,"X
64×3 = concatatenation(Xcoord
60×3 , padding
1×3
, Xlattice
3×3 )
(1)"
DATA OVERVIEW,0.12242798353909465,"• Chemical elements which are presented as a one-hot matrix elementsij of size
64 × 103 (including padding), where ones are positioned at the indices corresponding
to the position of a certain chemical element in the periodic table."
DATA OVERVIEW,0.12345679012345678,"elementsij =
1
if i-th atom’s element number from the periodic table = j
0
otherwise"
DATA OVERVIEW,0.12448559670781893,"• Elemental property matrix elementalProperties containing 22 chemical features
118"
DATA OVERVIEW,0.12551440329218108,"encoding chemical elements obtained from [8]. The properties of each element were
119"
DATA OVERVIEW,0.12654320987654322,"calculated using Mendeleev package[17].
120"
DATA OVERVIEW,0.12757201646090535,"• Space group spg of a structure. We use the space group encoding method presented in
121"
DATA OVERVIEW,0.1286008230452675,"[8], when each space group is represented by a 192 × 4 × 4 matrix, which corresponds
122"
DATA OVERVIEW,0.12962962962962962,"to 192 possible symmetry operations.
123"
DATA OVERVIEW,0.13065843621399176,"• Structure formation energy E
124"
DATA OVERVIEW,0.13168724279835392,"• Nsites - number of atoms in a crystal lattice.
125"
DATA OVERVIEW,0.13271604938271606,"2.2
Data representation. Modification task
126"
DATA OVERVIEW,0.1337448559670782,"The crystal pair sampling strategy involves handling a potential data leakage: possible
127"
DATA OVERVIEW,0.13477366255144033,"inclusion of structures from the same polymorph group but with different energies into training
128"
DATA OVERVIEW,0.13580246913580246,"and validation subsets. To mitigate this issue, the polymorph group formulas were initially
129"
DATA OVERVIEW,0.1368312757201646,"divided into distinct training and validation sets, ensuring a relatively balanced distribution
130"
DATA OVERVIEW,0.13786008230452676,"of chemical elements across these subsets. Subsequently, the pairs were categorized into two
131"
DATA OVERVIEW,0.1388888888888889,"groups: those with low-energy (lowest energy in polymorph group) targets designated as
132"
DATA OVERVIEW,0.13991769547325103,"lowestEnergyPairs = (Si, S0)∀i ∈[1, ..., structuresNum] and those with non-low-energy
133"
DATA OVERVIEW,0.14094650205761317,"targets, all structures except the most optimal one, formed as nonLowestEnergyPairs =
134"
DATA OVERVIEW,0.1419753086419753,"(Si, Sj)| i > j > 0. The validation set was constructed as a subset of lowestEnergyPairs.
135"
DATA OVERVIEW,0.14300411522633744,"The training set was dynamically constructed every epoch from lowestEnergyPairs and
136"
DATA OVERVIEW,0.1440329218106996,"nonlowestEnergyPairs, preserving equal numbers of pairs sampled and maintaining a
137"
DATA OVERVIEW,0.14506172839506173,"limited count per polymorph group. This strategy ensured a robust separation between
138"
DATA OVERVIEW,0.14609053497942387,"training and validation sets, thus preventing data leakage and improving model performance.
139"
DATA OVERVIEW,0.147119341563786,"Each pair sample {Sinit, Starget} ∈pairDataset consisted of the information about each
140"
DATA OVERVIEW,0.14814814814814814,"structure (hereinafter, we will call them initial and target structures). The following data
141"
DATA OVERVIEW,0.14917695473251028,"was used:
142"
DATA OVERVIEW,0.15020576131687244,"• Coordinates and lattice information of initial and target structures Xinit, Xtarget
143"
DATA OVERVIEW,0.15123456790123457,"• Difference in formation energies between initial and target structures Ediff =
144"
DATA OVERVIEW,0.1522633744855967,"Etarget −Einit
145"
DATA OVERVIEW,0.15329218106995884,"• Space group of target structure spgtarget
146"
DATA OVERVIEW,0.15432098765432098,"• Elements matrix elemetsMatrix, elemental property matrix elementalProperties
147"
DATA OVERVIEW,0.15534979423868311,"and number of sites numSites, which are the same for initial and target structure
148"
DATA OVERVIEW,0.15637860082304528,"because of identical chemical composition.
149"
DATA OVERVIEW,0.1574074074074074,"The modification task involved transforming the input structure Xinit into the target structure
150"
DATA OVERVIEW,0.15843621399176955,"Xtarget.
151"
DATA OVERVIEW,0.15946502057613168,"2.3
Data representation. Generation task
152"
DATA OVERVIEW,0.16049382716049382,"In its tern the generation task receives normal or uniform (depends on a model) noise as
153"
DATA OVERVIEW,0.16152263374485595,"input from which the structure is generated, which is akin to the image generation processes
154"
DATA OVERVIEW,0.16255144032921812,"in computer vision tasks.
155"
DATA OVERVIEW,0.16358024691358025,"For the generation task, an additional dataset was constructed. Data for the generation task
156"
DATA OVERVIEW,0.1646090534979424,"is slightly simpler, while it considers only {Starget}. Therefore, the models can be trained on
157"
DATA OVERVIEW,0.16563786008230452,"all structures available, rather than pairs. The following data is used:
158"
DATA OVERVIEW,0.16666666666666666,"• Coordinates and lattice information of target structure Xtarget
159"
DATA OVERVIEW,0.16769547325102882,"• Formation energy of target structure Etarget
160"
DATA OVERVIEW,0.16872427983539096,"• Space group of target structure spgtarget
161"
DATA OVERVIEW,0.1697530864197531,"• Elements matrix elemetsMatrix, elemental property matrix elementalProperties
162"
DATA OVERVIEW,0.17078189300411523,"and number of sites numSites of target structure.
163"
LOSS AND METRICS,0.17181069958847736,"3
Loss and metrics
164"
ATOMIC COORDINATES,0.1728395061728395,"3.1
Atomic coordinates
165"
ATOMIC COORDINATES,0.17386831275720166,"The atomic coordinates are represented as a 60 × 3 matrix, where each row corresponds
166"
ATOMIC COORDINATES,0.1748971193415638,"to the coordinates of an atom. The L1 loss was utilized during the training of a model for
167"
ATOMIC COORDINATES,0.17592592592592593,"predicting atomic coordinates.
168"
ATOMIC COORDINATES,0.17695473251028807,"L1(preds, target)i = ||predsi −targeti||1 = P3
j=1 |predsij −targetij|, where target and pred
169"
ATOMIC COORDINATES,0.1779835390946502,"are target and predicted atomic coordinate matrices.
170"
LATTICE,0.17901234567901234,"3.2
Lattice
171"
LATTICE,0.1800411522633745,"The lattice itself is represented as a 3x3 matrix, where each row signifies a directing basis
172"
LATTICE,0.18106995884773663,"vector. In this case, we have also used the L1 norm as a loss function.
173"
PERIODIC BOUNDARY CONDITION LOSS,0.18209876543209877,"3.3
Periodic boundary condition loss
174"
PERIODIC BOUNDARY CONDITION LOSS,0.1831275720164609,"This section presents an enhanced loss function, designed for the regression model (see
175"
PERIODIC BOUNDARY CONDITION LOSS,0.18415637860082304,"Section 5.1), that addresses this challenge by integrating periodic boundary conditions into
176"
PERIODIC BOUNDARY CONDITION LOSS,0.18518518518518517,"the loss calculation, outperforming the conventional L1 loss function. In the field of ML
177"
PERIODIC BOUNDARY CONDITION LOSS,0.18621399176954734,"applied to atomic structures, even slight displacement of atomic coordinates is crucial and
178"
PERIODIC BOUNDARY CONDITION LOSS,0.18724279835390947,"employing appropriate loss functions that consider the periodic nature of atomic structures
179"
PERIODIC BOUNDARY CONDITION LOSS,0.1882716049382716,"increases the flexibility of model predictions.
180"
PERIODIC BOUNDARY CONDITION LOSS,0.18930041152263374,"In the dataset representing atomic structures, it is crucial to acknowledge the presence
181"
PERIODIC BOUNDARY CONDITION LOSS,0.19032921810699588,"of atoms residing at various positions within the lattice framework. Certain atoms are
182"
PERIODIC BOUNDARY CONDITION LOSS,0.19135802469135801,"positioned at the vertices, edges, or faces of the lattice. According to periodic boundary
183"
PERIODIC BOUNDARY CONDITION LOSS,0.19238683127572018,"conditions (PBC), identical atoms in the vicinity of vertices, edges, or faces but also exist in
184"
PERIODIC BOUNDARY CONDITION LOSS,0.1934156378600823,"analogous positions across the lattice. Implementation of such an invariance within the loss
185"
PERIODIC BOUNDARY CONDITION LOSS,0.19444444444444445,"function helps in effectively capturing periodic pattern of crystals, enhancing the model’s
186"
PERIODIC BOUNDARY CONDITION LOSS,0.19547325102880658,"capability to learn and predict atomic structures more comprehensively.
187"
PERIODIC BOUNDARY CONDITION LOSS,0.19650205761316872,"(a)
(b) (c)"
PERIODIC BOUNDARY CONDITION LOSS,0.19753086419753085,"Figure 1: Illustration of atoms at a)vertices, b)edges, and c)faces of lattice under periodic
boundary conditions"
PERIODIC BOUNDARY CONDITION LOSS,0.19855967078189302,"The loss function is being calculated as minimum of distances from predicted point to the
188"
PERIODIC BOUNDARY CONDITION LOSS,0.19958847736625515,"target one taking into account 26 its periodic images (according to PBC) A.4.
189"
PERIODIC BOUNDARY CONDITION LOSS,0.2006172839506173,"The empirical validation of this enhanced loss function showcases its superiority(Figure4) in
190"
PERIODIC BOUNDARY CONDITION LOSS,0.20164609053497942,"capturing discrepancies within atomic structures, thus indicating its potential as a robust
191"
PERIODIC BOUNDARY CONDITION LOSS,0.20267489711934156,"tool for improving the accuracy of ML models in materials science applications.
192"
METRIC,0.2037037037037037,"3.4
Metric
193"
METRIC,0.20473251028806586,"As a metric, we have chosen an analogue of accuracy: the generated structures are compared
194"
METRIC,0.205761316872428,"to the target structures using a specialized matcher, yielding the proportion of structures that
195"
METRIC,0.20679012345679013,"successfully pass the matching process. For metric calculation, we employed the Pymatgen
196"
METRIC,0.20781893004115226,"StructureMatcher with the default set of parameters (ltol = 0.2, stol = 0.3, angle_tol = 5).
197"
METRIC,0.2088477366255144,"Although this approach is less accurate than structure relaxation using ab initio calculations
198"
METRIC,0.20987654320987653,"and comparing the structure formation energy with the energy above the hull, it enables
199"
METRIC,0.2109053497942387,"model validation to be performed orders of magnitude faster than the traditional method.
200"
MODEL,0.21193415637860083,"4
Model
201"
MODEL,0.21296296296296297,"For experiments, a 1d UNet model (see Figure2 (b)) architecture similar to the 2d UNet model
202"
MODEL,0.2139917695473251,"described in [18] was utilized along with 2D and 1D convolutional neural networks (CNNs)
203"
MODEL,0.21502057613168724,"for the space group and element matrix embeddings, respectively. Based on this model, 3
204"
MODEL,0.21604938271604937,"different training processes have been developed: ordinary regression model, Conditional
205"
MODEL,0.21707818930041153,"Flow Matching (CFM)[19] model, and diffusion model.
206"
MODEL,0.21810699588477367,"The model was conditioned (see Figure2 (a)) on the following data: time condition (t), the
207"
MODEL,0.2191358024691358,"same as in [18], element condition (el), formation energy difference condition (Ediff), and
208"
MODEL,0.22016460905349794,"desirable space group (spg). elemb, spgemb and Ediff are concatenated into one embedding
209"
MODEL,0.22119341563786007,"Cemb. t is fed into the Transformer Positional Encoding Layer and transformed into an
210"
MODEL,0.2222222222222222,"embedding Temb. The two embeddings: Cemb and Temb are then applied into one condition.
211"
MODEL,0.22325102880658437,"(a) Condition block
(b) UNet"
MODEL,0.2242798353909465,"Figure 2: a)Formation of conditions using formation energy, space group, and elemental
representation, and b)Schematic depiction of the model architecture"
METHODOLOGY,0.22530864197530864,"5
Methodology
212"
METHODOLOGY,0.22633744855967078,"In this work, two approaches are proposed: crystal structure generation and crystal structure
213"
METHODOLOGY,0.2273662551440329,"modification. For the generation approach, crystal structures are generated from normal
214"
METHODOLOGY,0.22839506172839505,"or uniform noise and conditioned to t, el, E, spg. Within the generation, we employed
215"
METHODOLOGY,0.2294238683127572,"three algorithms: DDPM, DDIM, and CFM models. For the modification approach, crystal
216"
METHODOLOGY,0.23045267489711935,"structures are generated by modifying other structures, while conditioning to el, Ediff, spg
217"
METHODOLOGY,0.23148148148148148,"(and optionally t, not used in ordinary regression UNet). For the modification task, we have
218"
METHODOLOGY,0.23251028806584362,"employed three algorithms: UNet Regression model, diffusion model, based on Palette[20]
219"
METHODOLOGY,0.23353909465020575,"approach, and CFM model. For the generation task, we have employed four algorithms:
220"
METHODOLOGY,0.2345679012345679,"diffusion models with DDPM and DDIM samplers, and CFM models on Uniform and Normal
221"
METHODOLOGY,0.23559670781893005,"noise.
222"
REGRESSION MODEL,0.2366255144032922,"5.1
Regression model
223"
REGRESSION MODEL,0.23765432098765432,"During the training stage, the structure coordinates and lattice x0, elements features el, space
224"
REGRESSION MODEL,0.23868312757201646,"group spg and Ediff are used as conditions. The model is trained to return x1 structure
225"
REGRESSION MODEL,0.2397119341563786,"coordinates and lattice (Algorithm 1). As for the inference process, one can see the details
226"
REGRESSION MODEL,0.24074074074074073,"in the Algorithm 2
227"
CONDITIONAL FLOW MATCHING MODELS,0.2417695473251029,"5.2
Conditional Flow Matching models
228"
CONDITIONAL FLOW MATCHING MODELS,0.24279835390946503,"CFM is a fast method for training Continuous Normalizing Flows (CNF)[21] models without
229"
CONDITIONAL FLOW MATCHING MODELS,0.24382716049382716,"the need for simulations. It offers a training objective that enables conditional generative
230"
CONDITIONAL FLOW MATCHING MODELS,0.2448559670781893,"modeling and accelerates both training and inference.
231"
CONDITIONAL FLOW MATCHING MODELS,0.24588477366255143,"The basic way of training CFM model (Algorithm 3) organized as follows: during the
232"
CONDITIONAL FLOW MATCHING MODELS,0.24691358024691357,"training stage, x0 and x1 are sampled from the source distribution and the target distribution
233"
CONDITIONAL FLOW MATCHING MODELS,0.24794238683127573,"respectively, then a linear interpolation xt is calculated as xt = tx1 + (1 −t)x0 (exponential
234"
CONDITIONAL FLOW MATCHING MODELS,0.24897119341563786,"moving average between distributions x0 and x1; t is sampled from a uniform distribution
235"
CONDITIONAL FLOW MATCHING MODELS,0.25,"U(0, 1)), and afterwards pass the xt and t as inputs to our model fθ, forcing the model to
236"
CONDITIONAL FLOW MATCHING MODELS,0.25102880658436216,"predict a velocity from the distribution x0 to x1. Therefore, the loss for CFM model is
237"
CONDITIONAL FLOW MATCHING MODELS,0.25205761316872427,"the following: LCF M = Et,x1,x0[||fθ(xt, t) −(x1 −x0)||2] = Et,x1,x0[||fθ(tx1 + (1 −t)x0, t) −
238"
CONDITIONAL FLOW MATCHING MODELS,0.25308641975308643,"(x1 −x0)||2]
239"
CONDITIONAL FLOW MATCHING MODELS,0.25411522633744854,"For the modification approach, x0 and x1 are both sampled from our dataset distribution
240"
CONDITIONAL FLOW MATCHING MODELS,0.2551440329218107,"according to the sampling strategy for modification mentioned in 2.2. Also, the model is
241"
CONDITIONAL FLOW MATCHING MODELS,0.25617283950617287,"conditioned to el, spg1, Ediff, besides t (see Algorithm 4)
242"
CONDITIONAL FLOW MATCHING MODELS,0.257201646090535,"For the generation approach, we tested two noise distributions for the x0: normal distribu-
243"
CONDITIONAL FLOW MATCHING MODELS,0.25823045267489714,"tion N(0, 1) and uniform noise distribution U(0, 1), which resulted in significantly better
244"
CONDITIONAL FLOW MATCHING MODELS,0.25925925925925924,"performance. The intuition for using uniform distribution instead of normal one was inspired
245"
CONDITIONAL FLOW MATCHING MODELS,0.2602880658436214,"by the diagram of x, y, z coordinate distribution (Figure 3). The model is also conditioned
246"
CONDITIONAL FLOW MATCHING MODELS,0.2613168724279835,"to el, spg1, E, and t (see Algorithm 5)
247"
CONDITIONAL FLOW MATCHING MODELS,0.2623456790123457,"During the sampling stage, we generate X1 structure by the given X0 by solving the following
248"
CONDITIONAL FLOW MATCHING MODELS,0.26337448559670784,"ordinary differential equation (ODE): dxt = fθ(xt, t, el, spg1, E)dt, beginning with x0. In
249"
CONDITIONAL FLOW MATCHING MODELS,0.26440329218106995,"order to solve the ODE, the Euler method was employed: xt+h = xt + hfθ(xt, t, el, spg1, E)
250"
CONDITIONAL FLOW MATCHING MODELS,0.2654320987654321,"(Algorithm 6)
251"
DIFFUSION MODELS,0.2664609053497942,"5.3
Diffusion models
252"
DIFFUSION MODELS,0.2674897119341564,"In our work, we observe diffusion models. Diffusion models generate samples from a target
253"
DIFFUSION MODELS,0.26851851851851855,"distribution x1, starting from a source distribution x0 ∼N(0, I).
254"
DIFFUSION MODELS,0.26954732510288065,"During training, these models are trained to reverse a Markovian forward process, which
255"
DIFFUSION MODELS,0.2705761316872428,"adds noise x0 to the data step by step. Meaning, diffusion models are trained to predict the
256"
DIFFUSION MODELS,0.2716049382716049,"noise added to the data samples x1. In order to train a model in this setup, the following loss
257"
DIFFUSION MODELS,0.2726337448559671,"function is used, Lsimple = Et,x1,x0[||x0 −fθ(√¯αtx1 + √1 −¯αtx0, t)||2] where ¯αt = Qt
s=1 αs
258"
DIFFUSION MODELS,0.2736625514403292,"and αt = 1 −βt (βt is the variance by which added noise is being scheduled on each step t).
259"
DIFFUSION MODELS,0.27469135802469136,"Our modification approach is based on Palette, which enables sample-to-sample generation
260"
DIFFUSION MODELS,0.2757201646090535,"(from noise ϵ ∼N(0, 1)) using x0 structure coordinates and lattice, el, spg1, Ediff and t as
261"
DIFFUSION MODELS,0.2767489711934156,"conditions for generation of x1 using the DDPM algorithm. Sampling stage is performed by
262"
DIFFUSION MODELS,0.2777777777777778,"a backward diffusion process with linear scheduler (see Algorithms 7, 8).
263"
DIFFUSION MODELS,0.2788065843621399,"For the generation approach ((Algorithm 9), x0 is sampled from a normal distribution and
264"
DIFFUSION MODELS,0.27983539094650206,"el, spg1, E, t are fed into the model as conditions. During our experiments, we tested
265"
DIFFUSION MODELS,0.2808641975308642,"2 approaches: DDPM(Algorithm 10) classic approach and DDIM(Algorithm 11) which
266"
DIFFUSION MODELS,0.28189300411522633,"results in usage of smaller number of sampling steps in order to speed up the generation
267"
DIFFUSION MODELS,0.2829218106995885,"process. Moreover, DDIM enables the process of generating samples from random noise to
268"
DIFFUSION MODELS,0.2839506172839506,"be deterministic.
269"
EXPERIMENT RESULTS,0.28497942386831276,"6
Experiment Results
270"
EXPERIMENT RESULTS,0.28600823045267487,"All the models presented in tables (Table 1 and Table 2) have been trained with the same
271"
EXPERIMENT RESULTS,0.28703703703703703,"hyperparameters and architectures. The metric used is described in Section 3.4. We also
272"
EXPERIMENT RESULTS,0.2880658436213992,"provide all experiment details in A.3.
273"
EXPERIMENT RESULTS,0.2890946502057613,"Table 1: Validation metrics on generation task
DDPM
DDIM
CFM N(0, 1)
CFM U(0, 1)"
EXPERIMENT RESULTS,0.29012345679012347,"0.8074
0.82
0.482
0.8097"
EXPERIMENT RESULTS,0.2911522633744856,Table 2: Validation metrics on modification task
EXPERIMENT RESULTS,0.29218106995884774,"Ordinary Model
Diffusion
CFM"
EXPERIMENT RESULTS,0.2932098765432099,"0.4148
0.3653
0.2059"
INFERENCE,0.294238683127572,"7
Inference
274"
INFERENCE,0.2952674897119342,"In order to demonstrate a potential of the proposed approaches, we have chosen a chemical
275"
INFERENCE,0.2962962962962963,"composition, containing numerous variations and phases of structures composed of [W, B,
276"
INFERENCE,0.29732510288065844,"Ta] with well-explored convex hull. Structures that lie on the convex hull are considered to
277"
INFERENCE,0.29835390946502055,"be thermodynamically stable, and the ones above it are either metastable or unstable.
278"
INFERENCE PIPELINE,0.2993827160493827,"7.1
Inference pipeline
279"
INFERENCE PIPELINE,0.3004115226337449,"The proposed testing procedure involves generating test conditions for structures, passing
280"
INFERENCE PIPELINE,0.301440329218107,"them to the trained generative models, pre-optimizing the generated structures to accelerate
281"
INFERENCE PIPELINE,0.30246913580246915,"the following ab initio calculations, and final relaxation and formation energy calculating using
282"
INFERENCE PIPELINE,0.30349794238683125,"VASP. Although in this work two approaches were proposed: Generation and Modification,
283"
INFERENCE PIPELINE,0.3045267489711934,"the following pipeline has only been applied to generation models, due to the fact, that
284"
INFERENCE PIPELINE,0.3055555555555556,"modification approach is based on structure-polymorphs, which leads to the necessity to
285"
INFERENCE PIPELINE,0.3065843621399177,"have at least one structure with needed composition, which is not always so. That fact
286"
INFERENCE PIPELINE,0.30761316872427985,"makes generation models much more flexible in generation structures not only with needed
287"
INFERENCE PIPELINE,0.30864197530864196,"properties, but also with needed composition. Another advantage of the generation models is
288"
INFERENCE PIPELINE,0.3096707818930041,"value of metric that is two times bigger than in modification tasks. The inference algorithm
289"
INFERENCE PIPELINE,0.31069958847736623,"is as follows:
290"
INFERENCE PIPELINE,0.3117283950617284,"1. Test Condition Formation:
291"
INFERENCE PIPELINE,0.31275720164609055,"• The chosen chemical formulas were utilized for feature extraction of el. Three
292"
INFERENCE PIPELINE,0.31378600823045266,"chemical compositions have been used: 1) Ta1W1B6, 2) Ta1W2B5 and 3)
293"
INFERENCE PIPELINE,0.3148148148148148,"Ta2W1B5.
294"
INFERENCE PIPELINE,0.31584362139917693,"• We have taken spg presented in the dataset as an additional condition, obtaining
295"
INFERENCE PIPELINE,0.3168724279835391,"19 space groups.
296"
INFERENCE PIPELINE,0.31790123456790126,"• Finally, a set of target formation energies E has been formed. We have carried
297"
INFERENCE PIPELINE,0.31893004115226337,"out three experiments: 1) starting from the energy of the convex hull and
298"
INFERENCE PIPELINE,0.31995884773662553,"decreasing with a step of 0.01 eV/atom, 2) starting from the energy of the
299"
INFERENCE PIPELINE,0.32098765432098764,"convex hull and decreasing with a step of 0.1 eV/atom, and 3) starting from the
300"
INFERENCE PIPELINE,0.3220164609053498,"energy 1 eV/atom less than the energy of the convex hull and decreasing with a
301"
INFERENCE PIPELINE,0.3230452674897119,"step of 0.01 eV/atom. In total, 21 energy values were used for every inference
302"
INFERENCE PIPELINE,0.32407407407407407,"run.
303"
INFERENCE PIPELINE,0.32510288065843623,"• Final inference conditions were obtained by making all possible combinations of
304"
INFERENCE PIPELINE,0.32613168724279834,"spg and E for a certain composition el
305"
INFERENCE PIPELINE,0.3271604938271605,"2. Model Inference: The conditions from the step 1 have been put to one of the trained
306"
INFERENCE PIPELINE,0.3281893004115226,"models, resulting in the generation of structures. Two models have been employed:
307"
INFERENCE PIPELINE,0.3292181069958848,"Diffusion approach and Flow matching
308"
INFERENCE PIPELINE,0.33024691358024694,"3. Pre-Optimization: Following the generation of all structures, each structure has been
309"
INFERENCE PIPELINE,0.33127572016460904,"pre-optimized using the PyMatGen structure relaxation method. The method used
310"
INFERENCE PIPELINE,0.3323045267489712,"m3gnet [22] model with default parameters. PyMatGen pre-optimization contributed
311"
INFERENCE PIPELINE,0.3333333333333333,"to overall speedup of further VASP relaxation.
312"
INFERENCE PIPELINE,0.3343621399176955,"4. Structure relaxation: Pre-optimized structures were relaxed using VASP (the rec-
313"
INFERENCE PIPELINE,0.33539094650205764,"ommended pseudopotentials, plane wave energy cutoff of 500 eV, Ediif and Ediffg
314"
INFERENCE PIPELINE,0.33641975308641975,"convergence criteria of 10−5 and −10−2 were used).
315"
INFERENCE RESULTS,0.3374485596707819,"7.2
Inference results
316"
INFERENCE RESULTS,0.338477366255144,"To summarize, 6 experiments have been carried out for two different models and for three
317"
INFERENCE RESULTS,0.3395061728395062,"formation energy conditionings.
Every experiment includes 3*380 structures, per 380
318"
INFERENCE RESULTS,0.3405349794238683,"structures for every single chemical composition. The results of experiments can be seen in
319"
INFERENCE RESULTS,0.34156378600823045,"Table 3
320"
INFERENCE RESULTS,0.3425925925925926,"As can be seen, 4 structures were obtained with formation energies significantly lower than
321"
INFERENCE RESULTS,0.3436213991769547,"those obtained from the AFLOW-derived convex hull. Thus, it can be concluded that
322"
INFERENCE RESULTS,0.3446502057613169,"this observation indicates the potential stability of the generated structures rather than
323"
INFERENCE RESULTS,0.345679012345679,"differences in the computational methods used in this work and during AFLOW generation.
324"
INFERENCE RESULTS,0.34670781893004116,"Another four structures also have energies below the convex hull, but in the vicinity of it.
325"
INFERENCE RESULTS,0.3477366255144033,"Thus, their potential stability should be interpreted with caution.
326"
DATA AVAILABILITY,0.3487654320987654,"8
Data availability
327"
DATA AVAILABILITY,0.3497942386831276,"The raw crystal dataset is downloaded from
328"
DATA AVAILABILITY,0.3508230452674897,"https://aflowlib.org
329"
DATA AVAILABILITY,0.35185185185185186,"Table 3: Inference results. Each matrix element corresponds to either the minimal energy
above the hull achieved in an experiment or the energy above the hull of structures with
energies below the hull."
DATA AVAILABILITY,0.35288065843621397,"Ta1W1B6,
meV/atom
Ta1W2B5,
meV/atom
Ta2W1B5,
meV/atom"
DATA AVAILABILITY,0.35390946502057613,Diffusion
DATA AVAILABILITY,0.3549382716049383,"energy step = 0.01
energy gap = 0
10,41
3,275
13,079"
DATA AVAILABILITY,0.3559670781893004,"energy step = 0.1
energy gap = 0
11,835
3,83
−0, 042"
DATA AVAILABILITY,0.35699588477366256,"energy step = 0.01
energy gap = 1
97,676
−1, 409
5,539"
DATA AVAILABILITY,0.35802469135802467,Flow-Matching
DATA AVAILABILITY,0.35905349794238683,"energy step = 0.01
energy gap = 0
11,981
−0, 483
−0, 466
−0, 387
−5, 426"
DATA AVAILABILITY,0.360082304526749,"energy step = 0.1
energy gap = 0
11,286
0,037
−5, 497"
DATA AVAILABILITY,0.3611111111111111,"energy step = 0.01
energy gap = 1
9,529
−4, 852
1,029"
CODE AVAILABILITY,0.36213991769547327,"9
Code availability
330"
CODE AVAILABILITY,0.3631687242798354,"The source code for training and inferencing our models can be obtained from GitHub at
331"
CODE AVAILABILITY,0.36419753086419754,"https://github.com/AIRI-Institute/conditional-crystal-generation
332"
CONCLUSION,0.36522633744855965,"10
Conclusion
333"
CONCLUSION,0.3662551440329218,"In this article, we have offered two approaches to generate crystal structures: conditional
334"
CONCLUSION,0.36728395061728397,"generation and conditional modification. The first approach is significantly more flexible
335"
CONCLUSION,0.3683127572016461,"as it does not require structure-polymorphs, enabling the generation of structures without
336"
CONCLUSION,0.36934156378600824,"restrictions on chemical composition, which can be crucial in certain scenarios. Another
337"
CONCLUSION,0.37037037037037035,"advantage of the first approach is the simplicity of data preprocessing; it only requires the
338"
CONCLUSION,0.3713991769547325,"chemical composition, space group, atom coordinates, and formation energies.
339"
CONCLUSION,0.3724279835390947,"Our methodology has experimentally proven its effectiveness, resulting in four confident
340"
CONCLUSION,0.3734567901234568,"potentially new crystal structures with the following energies above the hull: {-1.409, -5.497,
341"
CONCLUSION,0.37448559670781895,"-5.426, and -4.852} meV/atom, and four uncertain candidates with energies of {-0.483, -0.466,
342"
CONCLUSION,0.37551440329218105,"-0.387, and -0.042} meV/atom. We have demonstrated that conditional generation approaches,
343"
CONCLUSION,0.3765432098765432,"commonly used in image generation, are also fruitful in the design of new materials.
344"
CONCLUSION,0.3775720164609053,"Although the proposed methodology demonstrates its efficiency in generating potentially
345"
CONCLUSION,0.3786008230452675,"new crystal structures, it has certain limitations. Firstly, the data is represented in a matrix
346"
CONCLUSION,0.37962962962962965,"form, which does not account for all possible symmetries of the crystal structures. Secondly,
347"
CONCLUSION,0.38065843621399176,"the structures in the dataset range from 4 to 60 atoms per unit cell, with most structures
348"
CONCLUSION,0.3816872427983539,"containing fewer than 8 atoms per unit cell. However, to perform well on structures with a
349"
CONCLUSION,0.38271604938271603,"large number of atoms per unit cell, the models just should be pretrained on a dataset that
350"
CONCLUSION,0.3837448559670782,"includes larger structures.
351"
CONCLUSION,0.38477366255144035,"Furthermore, despite the limited number of experiments(6) and structures generated (7182),
352"
CONCLUSION,0.38580246913580246,"we succeeded in identifying hypothetically new structures. We hope that our article will
353"
CONCLUSION,0.3868312757201646,"help to reveal the potential of generative AI in design of new materials with targeted
354"
CONCLUSION,0.38786008230452673,"thermodynamic properties and inspire other researchers to be part of this innovative journey
355"
CONCLUSION,0.3888888888888889,"in materials design. We believe that rapid and efficient generation of novel materials can lead
356"
CONCLUSION,0.389917695473251,"to breakthroughs in various fields such as electronics, pharmaceuticals, and energy storage.
357"
CONCLUSION,0.39094650205761317,"This can accelerate technological advancements and make cutting-edge technologies more
358"
CONCLUSION,0.39197530864197533,"accessible and affordable.
359"
REFERENCES,0.39300411522633744,"References
360"
REFERENCES,0.3940329218106996,"[1] Diola Bagayoko. Understanding density functional theory (dft) and completing it in
361"
REFERENCES,0.3950617283950617,"practice. AIP Advances, 4(12), 2014.
362"
REFERENCES,0.39609053497942387,"[2] Alexander Dunn, Qi Wang, Alex Ganose, Daniel Dopp, and Anubhav Jain. Benchmark-
363"
REFERENCES,0.39711934156378603,"ing materials property prediction methods: the matbench test set and automatminer
364"
REFERENCES,0.39814814814814814,"reference algorithm. npj Computational Materials, 6(1):138, 2020.
365"
REFERENCES,0.3991769547325103,"[3] Roman A Eremin, Innokentiy S Humonen, Alexey A Kazakov, Vladimir D Lazarev,
366"
REFERENCES,0.4002057613168724,"Anatoly P Pushkarev, and Semen A Budennyy. Graph neural networks for predicting
367"
REFERENCES,0.4012345679012346,"structural stability of cd-and zn-doped γ-cspbi3. Computational Materials Science,
368"
REFERENCES,0.4022633744855967,"232:112672, 2024.
369"
REFERENCES,0.40329218106995884,"[4] Alexey N Korovin, Innokentiy S Humonen, Artem I Samtsevich, Roman A Eremin,
370"
REFERENCES,0.404320987654321,"AI Vasilev, Vladimir D Lazarev, and Semen A Budennyy. Boosting heterogeneous
371"
REFERENCES,0.4053497942386831,"catalyst discovery by structurally constrained deep learning models. Materials Today
372"
REFERENCES,0.4063786008230453,"Chemistry, 30:101541, 2023.
373"
REFERENCES,0.4074074074074074,"[5] Alexandre Duval, Simon V Mathis, Chaitanya K Joshi, Victor Schmidt, Santiago
374"
REFERENCES,0.40843621399176955,"Miret, Fragkiskos D Malliaros, Taco Cohen, Pietro Li`o, Yoshua Bengio, and Michael
375"
REFERENCES,0.4094650205761317,"Bronstein. A hitchhiker’s guide to geometric gnns for 3d atomic systems. arXiv preprint
376"
REFERENCES,0.4104938271604938,"arXiv:2312.07511, 2023.
377"
REFERENCES,0.411522633744856,"[6] Zekun Ren, Siyu Isaac Parker Tian, Juhwan Noh, Felipe Oviedo, Guangzong Xing, Jiali
378"
REFERENCES,0.4125514403292181,"Li, Qiaohao Liang, Ruiming Zhu, Armin G Aberle, Shijing Sun, et al. An invertible
379"
REFERENCES,0.41358024691358025,"crystallographic representation for general inverse design of inorganic crystals with
380"
REFERENCES,0.41460905349794236,"targeted properties. Matter, 5(1):314–335, 2022.
381"
REFERENCES,0.4156378600823045,"[7] Yong Zhao, Mohammed Al-Fahdi, Ming Hu, Edirisuriya MD Siriwardane, Yuqi Song,
382"
REFERENCES,0.4166666666666667,"Alireza Nasiri, and Jianjun Hu.
High-throughput discovery of novel cubic crystal
383"
REFERENCES,0.4176954732510288,"materials using deep generative neural networks. Advanced Science, 8(20):2100566,
384"
REFERENCES,0.41872427983539096,"2021.
385"
REFERENCES,0.41975308641975306,"[8] Yong Zhao, Edirisuriya M Dilanga Siriwardane, Zhenyao Wu, Nihang Fu, Mohammed
386"
REFERENCES,0.4207818930041152,"Al-Fahdi, Ming Hu, and Jianjun Hu. Physics guided deep learning for generative design
387"
REFERENCES,0.4218106995884774,"of crystal materials with symmetry constraints. npj Computational Materials, 9(1):38,
388"
REFERENCES,0.4228395061728395,"2023.
389"
REFERENCES,0.42386831275720166,"[9] Teerachote Pakornchote,
Natthaphon Choomphon-Anomakhun,
Sorrjit Arrerut,
390"
REFERENCES,0.42489711934156377,"Chayanon Atthapak, Sakarn Khamkaeo, Thiparat Chotibut, and Thiti Bovornratanaraks.
391"
REFERENCES,0.42592592592592593,"Diffusion probabilistic models enhance variational autoencoder for crystal structure
392"
REFERENCES,0.4269547325102881,"generative modeling. Scientific Reports, 14(1):1275, 2024.
393"
REFERENCES,0.4279835390946502,"[10] Claudio Zeni, Robert Pinsler, Daniel Z¨ugner, Andrew Fowler, Matthew Horton, Xiang
394"
REFERENCES,0.42901234567901236,"Fu, Sasha Shysheya, Jonathan Crabb´e, Lixin Sun, Jake Smith, et al. Mattergen: a
395"
REFERENCES,0.43004115226337447,"generative model for inorganic materials design. arXiv preprint arXiv:2312.03687, 2023.
396"
REFERENCES,0.43106995884773663,"[11] Amil Merchant, Simon Batzner, Samuel S Schoenholz, Muratahan Aykol, Gowoon
397"
REFERENCES,0.43209876543209874,"Cheon, and Ekin Dogus Cubuk. Scaling deep learning for materials discovery. Nature,
398"
REFERENCES,0.4331275720164609,"624(7990):80–85, 2023.
399"
REFERENCES,0.43415637860082307,"[12] Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le. Flow
400"
REFERENCES,0.4351851851851852,"matching for generative modeling. arXiv preprint arXiv:2210.02747, 2022.
401"
REFERENCES,0.43621399176954734,"[13] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In
402"
REFERENCES,0.43724279835390945,"H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, Advances in
403"
REFERENCES,0.4382716049382716,"Neural Information Processing Systems, volume 33, pages 6840–6851. Curran Associates,
404"
REFERENCES,0.43930041152263377,"Inc., 2020.
405"
REFERENCES,0.4403292181069959,"[14] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models.
406"
REFERENCES,0.44135802469135804,"In International Conference on Learning Representations, 2021.
407"
REFERENCES,0.44238683127572015,"[15] Guangyu Sun, Jen¨o K¨urti, P´eter Rajczy, Miklos Kertesz, J¨urgen Hafner, and Georg
408"
REFERENCES,0.4434156378600823,"Kresse. Performance of the vienna ab initio simulation package (vasp) in chemical
409"
REFERENCES,0.4444444444444444,"applications. Journal of Molecular Structure: THEOCHEM, 624(1-3):37–45, 2003.
410"
REFERENCES,0.4454732510288066,"[16] Stefano Curtarolo, Wahyu Setyawan, Gus LW Hart, Michal Jahnatek, Roman V Chep-
411"
REFERENCES,0.44650205761316875,"ulskii, Richard H Taylor, Shidong Wang, Junkai Xue, Kesong Yang, Ohad Levy, et al.
412"
REFERENCES,0.44753086419753085,"Aflow: An automatic framework for high-throughput materials discovery. Computational
413"
REFERENCES,0.448559670781893,"Materials Science, 58:218–226, 2012.
414"
REFERENCES,0.4495884773662551,"[17] Łukasz Mentel. mendeleev – a python resource for properties of chemical elements, ions
415"
REFERENCES,0.4506172839506173,"and isotopes.
416"
REFERENCES,0.45164609053497945,"[18] Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion proba-
417"
REFERENCES,0.45267489711934156,"bilistic models. In International Conference on Machine Learning, pages 8162–8171.
418"
REFERENCES,0.4537037037037037,"PMLR, 2021.
419"
REFERENCES,0.4547325102880658,"[19] Yaron Lipman, Ricky T. Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le.
420"
REFERENCES,0.455761316872428,"Flow matching for generative modeling. In The Eleventh International Conference on
421"
REFERENCES,0.4567901234567901,"Learning Representations, 2023.
422"
REFERENCES,0.45781893004115226,"[20] Chitwan Saharia, William Chan, Huiwen Chang, Chris A. Lee, Jonathan Ho, Tim
423"
REFERENCES,0.4588477366255144,"Salimans, David J. Fleet, and Mohammad Norouzi. Palette: Image-to-image diffusion
424"
REFERENCES,0.45987654320987653,"models, 2022.
425"
REFERENCES,0.4609053497942387,"[21] Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural
426"
REFERENCES,0.4619341563786008,"ordinary differential equations. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman,
427"
REFERENCES,0.46296296296296297,"N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing
428"
REFERENCES,0.46399176954732513,"Systems, volume 31. Curran Associates, Inc., 2018.
429"
REFERENCES,0.46502057613168724,"[22] Chi Chen and Shyue Ong. A universal graph deep learning interatomic potential for
430"
REFERENCES,0.4660493827160494,"the periodic table. Nature Computational Science, 2:718–728, 11 2022.
431"
REFERENCES,0.4670781893004115,"A
Appendix section 1
432"
REFERENCES,0.46810699588477367,"A.1
Distribution of atomic coordinates
433"
REFERENCES,0.4691358024691358,"Figure 3: Distribution of the components of fractional atomic coordinates (X, Y, Z)"
REFERENCES,0.47016460905349794,"A.2
Pseudocode
434"
REFERENCES,0.4711934156378601,Algorithm 1 Training Regression Modification Model
REFERENCES,0.4722222222222222,"1: repeat
2:
x0 ∼q(x0); x1 ∼q(x1); el ∼q(el); spg1 ∼q(spg1); E ∼q(E)
3:
L ←||x1 −fθ(x0, t, el, spg1, E)||
4:
θ ←Update(θ, ∇θL(θ))
5: until converge"
REFERENCES,0.4732510288065844,Algorithm 2 Inferencing Regression Modification Model
REFERENCES,0.4742798353909465,"1: x0 ∼q(x0); el ∼q(el); spg1 ∼q(spg1); E ∼q(E)
2: x1 = fθ(x0, t, el, spg1, E)
3: return x1"
REFERENCES,0.47530864197530864,Algorithm 3 CFM Training
REFERENCES,0.4763374485596708,"1: repeat
2:
x0 ∼q(x0); x1 ∼q(x1)
3:
t ∼U(0, 1)
4:
xt = tx1 + (1 −t)x0
5:
LCF M ←||fθ(xt, t) −(x1 −x0)||
6:
θ ←Update(θ, ∇θLCF M(θ))
7: until converge"
REFERENCES,0.4773662551440329,Algorithm 4 Training CFM for Modification
REFERENCES,0.4783950617283951,"1: repeat
2:
x0 ∼q(x0); x1 ∼q(x1); el ∼q(el); spg1 ∼q(spg1); E ∼q(E)
3:
t ∼U(0, 1)
4:
xt = tx1 + (1 −t)x0
5:
LCF M ←||fθ(xt, t, el, spg1, E) −(x1 −x0)||
6:
θ ←Update(θ, ∇θLCF M(θ))
7: until converge"
REFERENCES,0.4794238683127572,Algorithm 5 Training CFM for Generation
REFERENCES,0.48045267489711935,"1: repeat
2:
x0 ∼N(0, 1) or x0 ∼U(0, 1)
3:
x1 ∼q(x1); el ∼q(el); spg1 ∼q(spg1); E ∼q(E)
4:
t ∼U(0, 1)
5:
xt = tx1 + (1 −t)x0
6:
LCF M ←||fθ(xt, t, el, spg1, E) −(x1 −x0)||
7:
θ ←Update(θ, ∇θLCF M(θ))
8: until converge"
REFERENCES,0.48148148148148145,Algorithm 6 Sampling with CFM for Modification or Generation
REFERENCES,0.4825102880658436,1: h = 1
REFERENCES,0.4835390946502058,"T
2: x0 ∼q(x0) or x0 ∼N(0, 1) or x0 ∼U(0, 1)
3: el ∼q(el); spg1 ∼q(spg1); E ∼q(E)
4: for dot = 1, . . . , T do
5:
xt+1 = xt + hfθ(xt, t, el, spg1, E)
6: end for
7: return x1"
REFERENCES,0.4845679012345679,Algorithm 7 Training DM for Modification
REFERENCES,0.48559670781893005,"1: repeat
2:
x0 ∼q(x0); x1 ∼q(x1); el ∼q(el); spg1 ∼q(spg1); E ∼q(E)
3:
t ∼U({1, . . . , T})
4:
ϵ ∼N(0, I)
5:
LD ←||ϵ −fθ(√¯αtx1 + √1 −¯αtϵ, x0, t, el, spg1, E)||
6:
θ ←Update(θ, ∇θLD(θ))
7: until converge"
REFERENCES,0.48662551440329216,Algorithm 8 Sampling with DM for Modification
REFERENCES,0.4876543209876543,"1: xT ∼N(0, I)
2: for dot = T, . . . 1 do
3:
x0 ∼q(x0); x1 ∼q(x1); el ∼q(el); spg1 ∼q(spg1); E ∼q(E)
4:
z ∼N(0, I) if t > 1 else z = 0
5:
xt−1 =
1
√αt (xt −
1−αt
√1−¯
αt fθ(xt, x0, t, el, spg1, E)) + √1 −αtz"
REFERENCES,0.4886831275720165,"6: end for
7: return x1"
REFERENCES,0.4897119341563786,Algorithm 9 Training DM for Generation
REFERENCES,0.49074074074074076,"1: repeat
2:
x1 ∼q(x1); el ∼q(el); spg1 ∼q(spg1); E ∼q(E)
3:
t ∼U({1, . . . , T})
4:
ϵ ∼N(0, I)
5:
LD ←||ϵ −fθ(√¯αtx1 + √1 −¯αtϵ, t, el, spg1, E)||
6:
θ ←Update(θ, ∇θLD(θ))
7: until converge"
REFERENCES,0.49176954732510286,Algorithm 10 DDPM Sampling
REFERENCES,0.492798353909465,"1: xT ∼N(0, I)
2: for dot = T, . . . 1 do
3:
x1 ∼q(x1); el ∼q(el); spg1 ∼q(spg1); E ∼q(E)
4:
z ∼N(0, I) if t > 1 else z = 0
5:
xt−1 =
1
√αt (xt −
1−αt
√1−¯
αt fθ(xt, t, el, spg1, E)) + √1 −αtz"
REFERENCES,0.49382716049382713,"6: end for
7: return x1"
REFERENCES,0.4948559670781893,Algorithm 11 DDIM Sampling
REFERENCES,0.49588477366255146,"1: xT ∼N(0, I)
2: for dot = T, . . . 1 with step C do
3:
x0 ∼q(x0); x1 ∼q(x1); el ∼q(el); spg1 ∼q(spg1); E ∼q(E)
4:
z ∼N(0, I) if t > 1 else z = 0
5:
xθ = fθ(xt, t, el, spg1, E)"
REFERENCES,0.49691358024691357,"6:
xt−1 = √αt−1( xt−√1−αtxθ
√αt
) +
p"
REFERENCES,0.49794238683127573,"1 −αt−1 −σ2
t xθ + σtz
7:
8: end for
9: return x1"
REFERENCES,0.49897119341563784,"A.3
Experiment Details
435"
REFERENCES,0.5,"All the experiments use the same hyperparameters for the model:
436"
REFERENCES,0.5010288065843621,"• num_res_blocks = 7
437"
REFERENCES,0.5020576131687243,"• attention_resolution = (1, 2, 4, 8)
438"
REFERENCES,0.5030864197530864,"• model_channels = 128
439"
REFERENCES,0.5041152263374485,"In all the experiments models are trained with the same training parameters:
440"
REFERENCES,0.5051440329218106,"• optimizer = Adam
441"
REFERENCES,0.5061728395061729,"– betas = (0.9, 0.999)
442"
REFERENCES,0.507201646090535,"– eps = 1e-08
443"
REFERENCES,0.5082304526748971,"– weight_decay = 0
444"
REFERENCES,0.5092592592592593,"• batch_size = 256
445"
REFERENCES,0.5102880658436214,"• epochs = 400
446"
REFERENCES,0.5113168724279835,"• learning_rate = 1e-4
447"
REFERENCES,0.5123456790123457,"• lr_warmup_steps = 500
448"
REFERENCES,0.5133744855967078,"• random_state = 42
449"
REFERENCES,0.51440329218107,"An important note, that all our experiments have been conducted in mixed precision in fp16.
450"
REFERENCES,0.5154320987654321,"Generation task: Diffusion Model (DDPM):
451"
REFERENCES,0.5164609053497943,"• num_train_timesteps = 1000 (diffusion process discretization)
452"
REFERENCES,0.5174897119341564,"• beta_start = 0.0001
453"
REFERENCES,0.5185185185185185,"• beta_end = 0.02
454"
REFERENCES,0.5195473251028807,"• num_inference_steps = 100
455"
REFERENCES,0.5205761316872428,"• beta_schedule = ""squaredcos_cap_v2"" (cosine)
456"
REFERENCES,0.5216049382716049,"Diffusion Model (DDIM):
457"
REFERENCES,0.522633744855967,"• num_train_timesteps = 1000 (diffusion process discretization)
458"
REFERENCES,0.5236625514403292,"• beta_start = 0.0001
459"
REFERENCES,0.5246913580246914,"• beta_end = 0.02
460"
REFERENCES,0.5257201646090535,"• num_inference_steps = 100
461"
REFERENCES,0.5267489711934157,"• beta_schedule = ""squaredcos_cap_v2"" (cosine)
462"
REFERENCES,0.5277777777777778,"Flow Matching x0 ∼N(0, 1):
463"
REFERENCES,0.5288065843621399,"• num_inference_steps = 100
464"
REFERENCES,0.529835390946502,"Flow Matching x0 ∼U(0, 1):
465"
REFERENCES,0.5308641975308642,"• num_inference_steps = 100
466"
REFERENCES,0.5318930041152263,"Modification task:
467"
REFERENCES,0.5329218106995884,"Regression UNet:
468"
REFERENCES,0.5339506172839507,"• num_inference_steps = 1
469"
REFERENCES,0.5349794238683128,"Diffusion Model:
470"
REFERENCES,0.5360082304526749,"• num_train_timesteps = 1000 (diffusion process discretization)
471"
REFERENCES,0.5370370370370371,"• beta_start = 0.0001
472"
REFERENCES,0.5380658436213992,"• beta_end = 0.02
473"
REFERENCES,0.5390946502057613,"• num_inference_steps = 100
474"
REFERENCES,0.5401234567901234,"• beta_schedule = ""squaredcos_cap_v2"" (cosine)
475"
REFERENCES,0.5411522633744856,"Flow Matching:
476"
REFERENCES,0.5421810699588477,"• num_inference_steps = 100
477"
REFERENCES,0.5432098765432098,"A.4
PBC Loss details
478"
REFERENCES,0.5442386831275721,"The PBC loss function operates through several steps:
479"
REFERENCES,0.5452674897119342,"1. Vertices evaluation: If the target coordinate of the atom is lattice vertex (all 3
coordinates x, y, zare equal to 1 or 0), then loss between prediction point predsi and
target point targeti is being calculated using following formula:"
REFERENCES,0.5462962962962963,"Lvertex(predsi, targeti) =
min
v∈vertices ||predsi −v||,"
REFERENCES,0.5473251028806584,"where vertices is a set of 8 possible positions according to PBC ({0, 0, 0}, {0, 0, 1},
480"
REFERENCES,0.5483539094650206,"..., {1, 1, 1}).
481"
REFERENCES,0.5493827160493827,"2. Edges evaluation: If the target coordinate of the atom is located on lattice edge (two
482"
REFERENCES,0.5504115226337448,"coordinates are equal to 1 or 0 and one is not). For example, a lattice edge atom
483"
REFERENCES,0.551440329218107,"at point {0, 1, 0.3} has identical atoms at points {0, 0, 0.3}, {1, 0, 0.3}, {1, 1, 0.3}. As
484"
REFERENCES,0.5524691358024691,"we can see, in this example z-coordinate is fixed but x and y are exchangeable.
485"
REFERENCES,0.5534979423868313,"Therefore, if the target point is represented as {x, y, z}, we can use the following
486"
REFERENCES,0.5545267489711934,"formula:
487"
REFERENCES,0.5555555555555556,"Ledge(predsi, targeti) =
min
e∈edgeP oints ||predsi −e||,"
REFERENCES,0.5565843621399177,"where edgePoints is a set of 4 possible positions according to PBC.
488"
REFERENCES,0.5576131687242798,"• Case of fixed point x: edgePoints = {{x, 0, 0}, {x, 0, 1}, {x, 1, 0}, {x, 1, 1}}
489"
REFERENCES,0.558641975308642,"• Case of fixed point y: edgePoints = {{0, y, 0}, {0, y, 1}, {1, y, 0}, {1, y, 1}}
490"
REFERENCES,0.5596707818930041,"• Case of fixed point z: edgePoints = {{0, 0, z}, {0, 1, z}, {1, 0, z}, {1, 1, z}}
491"
REFERENCES,0.5606995884773662,"3. Sides evaluation: If the target coordinate of the atom is located on lattice side (one
492"
REFERENCES,0.5617283950617284,"coordinate is equal to 1 or 0 and two are not). For example, lattice side atom at
493"
REFERENCES,0.5627572016460906,"point {0, 0.5, 0.3} has identical atom at point {1, 0.5, 0.3}. In this example y and
494"
REFERENCES,0.5637860082304527,"z coordinates are fixed but x is exchangeable. Therefore, if the target point is
495"
REFERENCES,0.5648148148148148,"represented as {x, y, z}, we can use the following formula:
496"
REFERENCES,0.565843621399177,"Lsize(predsi, targeti) =
min
s∈sideP oints ||predsi −s||,"
REFERENCES,0.5668724279835391,"where sidePoints is a set of 2 possible positions according to PBC.
497"
REFERENCES,0.5679012345679012,"• Case of exchangeable point x: sidePoints = {{0, y, z}, {1, y, z}}
498"
REFERENCES,0.5689300411522634,"• Case of exchangeable point y: sidePoints = {{x, 0, z}, {x, 1, z}}
499"
REFERENCES,0.5699588477366255,"• Case of exchangeable point z: sidePoints = {{x, y, 0}, {x, y, 1}}
500"
REFERENCES,0.5709876543209876,"(a) Target structure
(b) Prediction"
REFERENCES,0.5720164609053497,"Figure 4: Example of using PBC-aware loss. The depicted structures (Mo2Nb2Ta2W2) are
visually different, but in fact they are exact the same. It is confirmed by insignificant value
of PBC-aware loss"
REFERENCES,0.573045267489712,"4. Points, which don’t belong to the groups above, are processed using the default loss
501"
REFERENCES,0.5740740740740741,"function.
502"
REFERENCES,0.5751028806584362,"Since the min(x1, x2, ..., xn) function is undifferentiable at multiple points (xi = xj ∀i ̸= j
), it makes a loss function to have a more complicated surface. Therefore, we used a norm
function with order k →−∞which is differentiable at all points as a replacement."
REFERENCES,0.5761316872427984,"mindiff(x1, x2, ..., xn) = ( n
X"
REFERENCES,0.5771604938271605,"i=1
|xi|k)
1
k
k −→−∞"
REFERENCES,0.5781893004115226,"Therefore, overall PBC-aware loss for a structure is represented as:
503"
REFERENCES,0.5792181069958847,"LP BC(preds, target) = n
X"
REFERENCES,0.5802469135802469,"i=1
I(targeti is vertex point)Lvertex(predsi, targeti)"
REFERENCES,0.581275720164609,"+I(targeti is edge point)Ledge(predsi, targeti)
+I(targeti is side point)Lside(predsi, targeti)
+I(targeti is usual point)L2(predsi, targeti)"
REFERENCES,0.5823045267489712,"As the count of atoms varies across different structures, the LP BC metric tends to yield
504"
REFERENCES,0.5833333333333334,"higher values for structures featuring a larger number of atoms. Thus, it is important to
505"
REFERENCES,0.5843621399176955,"normalize the loss function with the number of atoms in the structure if it would be used in
506"
REFERENCES,0.5853909465020576,"batches with structures with different number of atoms. Therefore, a PBC-aware loss for a
507"
REFERENCES,0.5864197530864198,"batch of structures is formulated as:
508"
REFERENCES,0.5874485596707819,"LbatchP BC(batchPreds, batchTargets) ="
REFERENCES,0.588477366255144,"batchSize
X i=1"
NUMSITESI,0.5895061728395061,"1
numSitesi
LP BC(batchPredsi, batchTargetsi)"
NUMSITESI,0.5905349794238683,"Compute resources
509"
NUMSITESI,0.5915637860082305,"For our computational needs in model training and inference, we deployed a total of three
510"
NUMSITESI,0.5925925925925926,"GPU servers with the following configurations:
511"
NUMSITESI,0.5936213991769548,"Server 1:
512"
NUMSITESI,0.5946502057613169,"• GPU: NVIDIA A100/80G
513"
NUMSITESI,0.595679012345679,"• CPU: 8vCPU of Intel(R) Xeon(R) Gold 6248R @ 3.00 GHz
514"
NUMSITESI,0.5967078189300411,"• RAM: 64Gb
515"
NUMSITESI,0.5977366255144033,"Server 2:
516"
NUMSITESI,0.5987654320987654,"• GPU: NVIDIA V100 (32GB)
517"
NUMSITESI,0.5997942386831275,"• CPU: 8vCPU of Intel(R) Xeon(R) Gold 6278C @ 2.60 GHz
518"
NUMSITESI,0.6008230452674898,"• RAM: 64Gb
519"
NUMSITESI,0.6018518518518519,"Server 3:
520"
NUMSITESI,0.602880658436214,"• GPU: NVIDIA V100 (32GB)
521"
NUMSITESI,0.6039094650205762,"• CPU: 8vCPU of Intel(R) Xeon(R) Gold 6278C @ 2.60 GHz
522"
NUMSITESI,0.6049382716049383,"• RAM: 64Gb
523"
NUMSITESI,0.6059670781893004,"Every model training time consumed up to 2 weeks employing computing power of one GPU
524"
NUMSITESI,0.6069958847736625,"server.
525"
NUMSITESI,0.6080246913580247,"For the ab-initio calculations implemented in VASP, we deployed a total of 5 identical CPU
526"
NUMSITESI,0.6090534979423868,"servers with the following configurations:
527"
NUMSITESI,0.6100823045267489,"• CPU: 64vCPU of Intel(R) Xeon(R) Gold 6278C CPU @ 2.60GHz
528"
NUMSITESI,0.6111111111111112,"• RAM: 256Gb
529"
NUMSITESI,0.6121399176954733,"Structure relaxation with VASP for all six experiments mentioned in Table 3 took more that
530"
NUMSITESI,0.6131687242798354,"180 thousand CPU hours. Computing power of all CPU servers was employed.
531"
NUMSITESI,0.6141975308641975,"NeurIPS Paper Checklist
532"
NUMSITESI,0.6152263374485597,"The checklist is designed to encourage best practices for responsible machine learning research,
533"
NUMSITESI,0.6162551440329218,"addressing issues of reproducibility, transparency, research ethics, and societal impact. Do
534"
NUMSITESI,0.6172839506172839,"not remove the checklist: The papers not including the checklist will be desk rejected. The
535"
NUMSITESI,0.6183127572016461,"checklist should follow the references and follow the (optional) supplemental material. The
536"
NUMSITESI,0.6193415637860082,"checklist does NOT count towards the page limit.
537"
NUMSITESI,0.6203703703703703,"Please read the checklist guidelines carefully for information on how to answer these questions.
538"
NUMSITESI,0.6213991769547325,"For each question in the checklist:
539"
NUMSITESI,0.6224279835390947,"• You should answer [Yes] , [No] , or [NA] .
540"
NUMSITESI,0.6234567901234568,"• [NA] means either that the question is Not Applicable for that particular paper or
541"
NUMSITESI,0.6244855967078189,"the relevant information is Not Available.
542"
NUMSITESI,0.6255144032921811,"• Please provide a short (1–2 sentence) justification right after your answer (even for
543"
NUMSITESI,0.6265432098765432,"NA).
544"
NUMSITESI,0.6275720164609053,"The checklist answers are an integral part of your paper submission. They are visible to the
545"
NUMSITESI,0.6286008230452675,"reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also
546"
NUMSITESI,0.6296296296296297,"include it (after eventual revisions) with the final version of your paper, and its final version
547"
NUMSITESI,0.6306584362139918,"will be published with the paper.
548"
NUMSITESI,0.6316872427983539,"The reviewers of your paper will be asked to use the checklist as one of the factors in their
549"
NUMSITESI,0.6327160493827161,"evaluation. While ""[Yes] "" is generally preferable to ""[No] "", it is perfectly acceptable to
550"
NUMSITESI,0.6337448559670782,"answer ""[No] "" provided a proper justification is given (e.g., ""error bars are not reported
551"
NUMSITESI,0.6347736625514403,"because it would be too computationally expensive"" or ""we were unable to find the license for
552"
NUMSITESI,0.6358024691358025,"the dataset we used""). In general, answering ""[No] "" or ""[NA] "" is not grounds for rejection.
553"
NUMSITESI,0.6368312757201646,"While the questions are phrased in a binary way, we acknowledge that the true answer
554"
NUMSITESI,0.6378600823045267,"is often more nuanced, so please just use your best judgment and write a justification to
555"
NUMSITESI,0.6388888888888888,"elaborate. All supporting evidence can appear either in the main paper or the supplemental
556"
NUMSITESI,0.6399176954732511,"material, provided in appendix. If you answer [Yes] to a question, in the justification please
557"
NUMSITESI,0.6409465020576132,"point to the section(s) where related material for the question can be found.
558"
NUMSITESI,0.6419753086419753,"IMPORTANT, please:
559"
NUMSITESI,0.6430041152263375,"• Delete this instruction block, but keep the section heading “NeurIPS paper checklist"",
560"
NUMSITESI,0.6440329218106996,"• Keep the checklist subsection headings, questions/answers and guidelines below.
561"
NUMSITESI,0.6450617283950617,"• Do not modify the questions and only use the provided macros for your answers.
562"
CLAIMS,0.6460905349794238,"1. Claims
563"
CLAIMS,0.647119341563786,"Question: Do the main claims made in the abstract and introduction accurately
564"
CLAIMS,0.6481481481481481,"reflect the paper’s contributions and scope?
565"
CLAIMS,0.6491769547325102,"Answer: [Yes] ,
566"
CLAIMS,0.6502057613168725,"Justification: The main claims made in the abstract and introduction do accurately
567"
CLAIMS,0.6512345679012346,"reflect the paper’s contributions and scope. Every aspects mentioned in the abstract
568"
CLAIMS,0.6522633744855967,"and introduction are further revealed in the main paper.
569"
CLAIMS,0.6532921810699589,"Guidelines:
570"
CLAIMS,0.654320987654321,"• The answer NA means that the abstract and introduction do not include the
571"
CLAIMS,0.6553497942386831,"claims made in the paper.
572"
CLAIMS,0.6563786008230452,"• The abstract and/or introduction should clearly state the claims made, including
573"
CLAIMS,0.6574074074074074,"the contributions made in the paper and important assumptions and limitations.
574"
CLAIMS,0.6584362139917695,"A No or NA answer to this question will not be perceived well by the reviewers.
575"
CLAIMS,0.6594650205761317,"• The claims made should match theoretical and experimental results, and reflect
576"
CLAIMS,0.6604938271604939,"how much the results can be expected to generalize to other settings.
577"
CLAIMS,0.661522633744856,"• It is fine to include aspirational goals as motivation as long as it is clear that
578"
CLAIMS,0.6625514403292181,"these goals are not attained by the paper.
579"
LIMITATIONS,0.6635802469135802,"2. Limitations
580"
LIMITATIONS,0.6646090534979424,"Question: Does the paper discuss the limitations of the work performed by the
581"
LIMITATIONS,0.6656378600823045,"authors?
582"
LIMITATIONS,0.6666666666666666,"Answer: [Yes]
583"
LIMITATIONS,0.6676954732510288,"Justification: All the limitations are discussed in the conclusion section. More
584"
LIMITATIONS,0.668724279835391,"specifically, limitations are 1) in number of atoms per unit cell of crystal structure
585"
LIMITATIONS,0.6697530864197531,"that model can work with and 2) symmetries that our structure representation is
586"
LIMITATIONS,0.6707818930041153,"able to encode. For example, crystals have infinite periodic structure. There is no
587"
LIMITATIONS,0.6718106995884774,"possible way to
588"
LIMITATIONS,0.6728395061728395,"Guidelines:
589"
LIMITATIONS,0.6738683127572016,"• The answer NA means that the paper has no limitation while the answer No
590"
LIMITATIONS,0.6748971193415638,"means that the paper has limitations, but those are not discussed in the paper.
591"
LIMITATIONS,0.6759259259259259,"• The authors are encouraged to create a separate ""Limitations"" section in their
592"
LIMITATIONS,0.676954732510288,"paper.
593"
LIMITATIONS,0.6779835390946503,"• The paper should point out any strong assumptions and how robust the results
594"
LIMITATIONS,0.6790123456790124,"are to violations of these assumptions (e.g., independence assumptions, noiseless
595"
LIMITATIONS,0.6800411522633745,"settings, model well-specification, asymptotic approximations only holding
596"
LIMITATIONS,0.6810699588477366,"locally). The authors should reflect on how these assumptions might be violated
597"
LIMITATIONS,0.6820987654320988,"in practice and what the implications would be.
598"
LIMITATIONS,0.6831275720164609,"• The authors should reflect on the scope of the claims made, e.g., if the approach
599"
LIMITATIONS,0.684156378600823,"was only tested on a few datasets or with a few runs. In general, empirical
600"
LIMITATIONS,0.6851851851851852,"results often depend on implicit assumptions, which should be articulated.
601"
LIMITATIONS,0.6862139917695473,"• The authors should reflect on the factors that influence the performance of the
602"
LIMITATIONS,0.6872427983539094,"approach. For example, a facial recognition algorithm may perform poorly when
603"
LIMITATIONS,0.6882716049382716,"image resolution is low or images are taken in low lighting. Or a speech-to-text
604"
LIMITATIONS,0.6893004115226338,"system might not be used reliably to provide closed captions for online lectures
605"
LIMITATIONS,0.6903292181069959,"because it fails to handle technical jargon.
606"
LIMITATIONS,0.691358024691358,"• The authors should discuss the computational efficiency of the proposed algo-
607"
LIMITATIONS,0.6923868312757202,"rithms and how they scale with dataset size.
608"
LIMITATIONS,0.6934156378600823,"• If applicable, the authors should discuss possible limitations of their approach
609"
LIMITATIONS,0.6944444444444444,"to address problems of privacy and fairness.
610"
LIMITATIONS,0.6954732510288066,"• While the authors might fear that complete honesty about limitations might
611"
LIMITATIONS,0.6965020576131687,"be used by reviewers as grounds for rejection, a worse outcome might be that
612"
LIMITATIONS,0.6975308641975309,"reviewers discover limitations that aren’t acknowledged in the paper. The
613"
LIMITATIONS,0.698559670781893,"authors should use their best judgment and recognize that individual actions in
614"
LIMITATIONS,0.6995884773662552,"favor of transparency play an important role in developing norms that preserve
615"
LIMITATIONS,0.7006172839506173,"the integrity of the community. Reviewers will be specifically instructed to not
616"
LIMITATIONS,0.7016460905349794,"penalize honesty concerning limitations.
617"
THEORY ASSUMPTIONS AND PROOFS,0.7026748971193416,"3. Theory Assumptions and Proofs
618"
THEORY ASSUMPTIONS AND PROOFS,0.7037037037037037,"Question: For each theoretical result, does the paper provide the full set of assump-
619"
THEORY ASSUMPTIONS AND PROOFS,0.7047325102880658,"tions and a complete (and correct) proof?
620"
THEORY ASSUMPTIONS AND PROOFS,0.7057613168724279,"Answer: [NA] .
621"
THEORY ASSUMPTIONS AND PROOFS,0.7067901234567902,"Justification: Our work does not include significant theoretical results due to the
622"
THEORY ASSUMPTIONS AND PROOFS,0.7078189300411523,"fact that it is mainly focused on experiments.
623"
THEORY ASSUMPTIONS AND PROOFS,0.7088477366255144,"Guidelines:
624"
THEORY ASSUMPTIONS AND PROOFS,0.7098765432098766,"• The answer NA means that the paper does not include theoretical results.
625"
THEORY ASSUMPTIONS AND PROOFS,0.7109053497942387,"• All the theorems, formulas, and proofs in the paper should be numbered and
626"
THEORY ASSUMPTIONS AND PROOFS,0.7119341563786008,"cross-referenced.
627"
THEORY ASSUMPTIONS AND PROOFS,0.7129629629629629,"• All assumptions should be clearly stated or referenced in the statement of any
628"
THEORY ASSUMPTIONS AND PROOFS,0.7139917695473251,"theorems.
629"
THEORY ASSUMPTIONS AND PROOFS,0.7150205761316872,"• The proofs can either appear in the main paper or the supplemental material,
630"
THEORY ASSUMPTIONS AND PROOFS,0.7160493827160493,"but if they appear in the supplemental material, the authors are encouraged to
631"
THEORY ASSUMPTIONS AND PROOFS,0.7170781893004116,"provide a short proof sketch to provide intuition.
632"
THEORY ASSUMPTIONS AND PROOFS,0.7181069958847737,"• Inversely, any informal proof provided in the core of the paper should be
633"
THEORY ASSUMPTIONS AND PROOFS,0.7191358024691358,"complemented by formal proofs provided in appendix or supplemental material.
634"
THEORY ASSUMPTIONS AND PROOFS,0.720164609053498,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
635"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7211934156378601,"4. Experimental Result Reproducibility
636"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7222222222222222,"Question: Does the paper fully disclose all the information needed to reproduce
637"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7232510288065843,"the main experimental results of the paper to the extent that it affects the main
638"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7242798353909465,"claims and/or conclusions of the paper (regardless of whether the code and data are
639"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7253086419753086,"provided or not)?
640"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7263374485596708,"Answer: [Yes]
641"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.727366255144033,"Justification: The paper fully discloses all the information needed to reproduce the
642"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7283950617283951,"main experimental results. The information includes: 1) all hyperparameters for
643"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7294238683127572,"the models, including the random seed they were performed on 2) crystal structures
644"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7304526748971193,"used as a data, 3) VASP settings.
645"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7314814814814815,"Guidelines:
646"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7325102880658436,"• The answer NA means that the paper does not include experiments.
647"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7335390946502057,"• If the paper includes experiments, a No answer to this question will not be
648"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7345679012345679,"perceived well by the reviewers: Making the paper reproducible is important,
649"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.73559670781893,"regardless of whether the code and data are provided or not.
650"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7366255144032922,"• If the contribution is a dataset and/or model, the authors should describe the
651"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7376543209876543,"steps taken to make their results reproducible or verifiable.
652"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7386831275720165,"• Depending on the contribution, reproducibility can be accomplished in various
653"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7397119341563786,"ways. For example, if the contribution is a novel architecture, describing the
654"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7407407407407407,"architecture fully might suffice, or if the contribution is a specific model and
655"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7417695473251029,"empirical evaluation, it may be necessary to either make it possible for others to
656"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.742798353909465,"replicate the model with the same dataset, or provide access to the model. In
657"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7438271604938271,"general. releasing code and data is often one good way to accomplish this, but
658"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7448559670781894,"reproducibility can also be provided via detailed instructions for how to replicate
659"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7458847736625515,"the results, access to a hosted model (e.g., in the case of a large language model),
660"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7469135802469136,"releasing of a model checkpoint, or other means that are appropriate to the
661"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7479423868312757,"research performed.
662"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7489711934156379,"• While NeurIPS does not require releasing code, the conference does require all
663"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.75,"submissions to provide some reasonable avenue for reproducibility, which may
664"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7510288065843621,"depend on the nature of the contribution. For example
665"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7520576131687243,"(a) If the contribution is primarily a new algorithm, the paper should make it
666"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7530864197530864,"clear how to reproduce that algorithm.
667"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7541152263374485,"(b) If the contribution is primarily a new model architecture, the paper should
668"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7551440329218106,"describe the architecture clearly and fully.
669"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7561728395061729,"(c) If the contribution is a new model (e.g., a large language model), then there
670"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.757201646090535,"should either be a way to access this model for reproducing the results or a
671"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7582304526748971,"way to reproduce the model (e.g., with an open-source dataset or instructions
672"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7592592592592593,"for how to construct the dataset).
673"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7602880658436214,"(d) We recognize that reproducibility may be tricky in some cases, in which
674"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7613168724279835,"case authors are welcome to describe the particular way they provide for
675"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7623456790123457,"reproducibility. In the case of closed-source models, it may be that access to
676"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7633744855967078,"the model is limited in some way (e.g., to registered users), but it should be
677"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.76440329218107,"possible for other researchers to have some path to reproducing or verifying
678"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7654320987654321,"the results.
679"
OPEN ACCESS TO DATA AND CODE,0.7664609053497943,"5. Open access to data and code
680"
OPEN ACCESS TO DATA AND CODE,0.7674897119341564,"Question: Does the paper provide open access to the data and code, with sufficient
681"
OPEN ACCESS TO DATA AND CODE,0.7685185185185185,"instructions to faithfully reproduce the main experimental results, as described in
682"
OPEN ACCESS TO DATA AND CODE,0.7695473251028807,"supplemental material?
683"
OPEN ACCESS TO DATA AND CODE,0.7705761316872428,"Answer: [Yes]
684"
OPEN ACCESS TO DATA AND CODE,0.7716049382716049,"Justification: The raw crystal dataset can be downloaded from https://aflowlib.org.
685"
OPEN ACCESS TO DATA AND CODE,0.772633744855967,"The source code for training and inferencing our models can be obtained from
686"
OPEN ACCESS TO DATA AND CODE,0.7736625514403292,"GitHub at https://github.com/AIRI-Institute/conditional-crystal-generation. Both
687"
OPEN ACCESS TO DATA AND CODE,0.7746913580246914,"data and code are also referenced in the main paper’s Section 9 and Section 9 .
688"
OPEN ACCESS TO DATA AND CODE,0.7757201646090535,"Guidelines:
689"
OPEN ACCESS TO DATA AND CODE,0.7767489711934157,"• The answer NA means that paper does not include experiments requiring code.
690"
OPEN ACCESS TO DATA AND CODE,0.7777777777777778,"• Please see the NeurIPS code and data submission guidelines (https://nips.
691"
OPEN ACCESS TO DATA AND CODE,0.7788065843621399,"cc/public/guides/CodeSubmissionPolicy) for more details.
692"
OPEN ACCESS TO DATA AND CODE,0.779835390946502,"• While we encourage the release of code and data, we understand that this might
693"
OPEN ACCESS TO DATA AND CODE,0.7808641975308642,"not be possible, so “No” is an acceptable answer. Papers cannot be rejected
694"
OPEN ACCESS TO DATA AND CODE,0.7818930041152263,"simply for not including code, unless this is central to the contribution (e.g., for
695"
OPEN ACCESS TO DATA AND CODE,0.7829218106995884,"a new open-source benchmark).
696"
OPEN ACCESS TO DATA AND CODE,0.7839506172839507,"• The instructions should contain the exact command and environment needed
697"
OPEN ACCESS TO DATA AND CODE,0.7849794238683128,"to run to reproduce the results.
See the NeurIPS code and data submis-
698"
OPEN ACCESS TO DATA AND CODE,0.7860082304526749,"sion guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy)
699"
OPEN ACCESS TO DATA AND CODE,0.7870370370370371,"for more details.
700"
OPEN ACCESS TO DATA AND CODE,0.7880658436213992,"• The authors should provide instructions on data access and preparation, in-
701"
OPEN ACCESS TO DATA AND CODE,0.7890946502057613,"cluding how to access the raw data, preprocessed data, intermediate data, and
702"
OPEN ACCESS TO DATA AND CODE,0.7901234567901234,"generated data, etc.
703"
OPEN ACCESS TO DATA AND CODE,0.7911522633744856,"• The authors should provide scripts to reproduce all experimental results for
704"
OPEN ACCESS TO DATA AND CODE,0.7921810699588477,"the new proposed method and baselines. If only a subset of experiments are
705"
OPEN ACCESS TO DATA AND CODE,0.7932098765432098,"reproducible, they should state which ones are omitted from the script and why.
706"
OPEN ACCESS TO DATA AND CODE,0.7942386831275721,"• At submission time, to preserve anonymity, the authors should release
707"
OPEN ACCESS TO DATA AND CODE,0.7952674897119342,"anonymized versions (if applicable).
708"
OPEN ACCESS TO DATA AND CODE,0.7962962962962963,"• Providing as much information as possible in supplemental material (appended
709"
OPEN ACCESS TO DATA AND CODE,0.7973251028806584,"to the paper) is recommended, but including URLs to data and code is permitted.
710"
OPEN ACCESS TO DATA AND CODE,0.7983539094650206,"6. Experimental Setting/Details
711"
OPEN ACCESS TO DATA AND CODE,0.7993827160493827,"Question: Does the paper specify all the training and test details (e.g., data splits,
712"
OPEN ACCESS TO DATA AND CODE,0.8004115226337448,"hyperparameters, how they were chosen, type of optimizer, etc.)
necessary to
713"
OPEN ACCESS TO DATA AND CODE,0.801440329218107,"understand the results?
714"
OPEN ACCESS TO DATA AND CODE,0.8024691358024691,"Answer: [Yes]
715"
OPEN ACCESS TO DATA AND CODE,0.8034979423868313,"Justification: All the training and testing details and all the hyperparameters for
716"
OPEN ACCESS TO DATA AND CODE,0.8045267489711934,"the experiments are mentioned in the paper.
717"
OPEN ACCESS TO DATA AND CODE,0.8055555555555556,"Guidelines:
718"
OPEN ACCESS TO DATA AND CODE,0.8065843621399177,"• The answer NA means that the paper does not include experiments.
719"
OPEN ACCESS TO DATA AND CODE,0.8076131687242798,"• The experimental setting should be presented in the core of the paper to a level
720"
OPEN ACCESS TO DATA AND CODE,0.808641975308642,"of detail that is necessary to appreciate the results and make sense of them.
721"
OPEN ACCESS TO DATA AND CODE,0.8096707818930041,"• The full details can be provided either with the code, in appendix, or as
722"
OPEN ACCESS TO DATA AND CODE,0.8106995884773662,"supplemental material.
723"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8117283950617284,"7. Experiment Statistical Significance
724"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8127572016460906,"Question: Does the paper report error bars suitably and correctly defined or other
725"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8137860082304527,"appropriate information about the statistical significance of the experiments?
726"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8148148148148148,"Answer: [No]
727"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.815843621399177,"Justification: Firstly, calculating statistical significance for all our experiments
728"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8168724279835391,"is computationally expensive. Secondly, experimental results(crystal structures
729"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8179012345679012,"obtained from model inference) have been approved by further ab-initio calculations
730"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8189300411522634,"implemented in VASP.
731"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8199588477366255,"Guidelines:
732"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8209876543209876,"• The answer NA means that the paper does not include experiments.
733"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8220164609053497,"• The authors should answer ""Yes"" if the results are accompanied by error bars,
734"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.823045267489712,"confidence intervals, or statistical significance tests, at least for the experiments
735"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8240740740740741,"that support the main claims of the paper.
736"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8251028806584362,"• The factors of variability that the error bars are capturing should be clearly
737"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8261316872427984,"stated (for example, train/test split, initialization, random drawing of some
738"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8271604938271605,"parameter, or overall run with given experimental conditions).
739"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8281893004115226,"• The method for calculating the error bars should be explained (closed form
740"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8292181069958847,"formula, call to a library function, bootstrap, etc.)
741"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8302469135802469,"• The assumptions made should be given (e.g., Normally distributed errors).
742"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.831275720164609,"• It should be clear whether the error bar is the standard deviation or the standard
743"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8323045267489712,"error of the mean.
744"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8333333333333334,"• It is OK to report 1-sigma error bars, but one should state it. The authors
745"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8343621399176955,"should preferably report a 2-sigma error bar than state that they have a 96%
746"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8353909465020576,"CI, if the hypothesis of Normality of errors is not verified.
747"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8364197530864198,"• For asymmetric distributions, the authors should be careful not to show in
748"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8374485596707819,"tables or figures symmetric error bars that would yield results that are out of
749"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.838477366255144,"range (e.g. negative error rates).
750"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8395061728395061,"• If error bars are reported in tables or plots, The authors should explain in the
751"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8405349794238683,"text how they were calculated and reference the corresponding figures or tables
752"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8415637860082305,"in the text.
753"
EXPERIMENTS COMPUTE RESOURCES,0.8425925925925926,"8. Experiments Compute Resources
754"
EXPERIMENTS COMPUTE RESOURCES,0.8436213991769548,"Question: For each experiment, does the paper provide sufficient information on the
755"
EXPERIMENTS COMPUTE RESOURCES,0.8446502057613169,"computer resources (type of compute workers, memory, time of execution) needed
756"
EXPERIMENTS COMPUTE RESOURCES,0.845679012345679,"to reproduce the experiments?
757"
EXPERIMENTS COMPUTE RESOURCES,0.8467078189300411,"Answer: [Yes]
758"
EXPERIMENTS COMPUTE RESOURCES,0.8477366255144033,"Justification: In the paper, we state all the compute powers that we have employed
759"
EXPERIMENTS COMPUTE RESOURCES,0.8487654320987654,"for AI model training and ab-initio calculations. One can observe it in Section A.4.
760"
EXPERIMENTS COMPUTE RESOURCES,0.8497942386831275,"Guidelines:
761"
EXPERIMENTS COMPUTE RESOURCES,0.8508230452674898,"• The answer NA means that the paper does not include experiments.
762"
EXPERIMENTS COMPUTE RESOURCES,0.8518518518518519,"• The paper should indicate the type of compute workers CPU or GPU, internal
763"
EXPERIMENTS COMPUTE RESOURCES,0.852880658436214,"cluster, or cloud provider, including relevant memory and storage.
764"
EXPERIMENTS COMPUTE RESOURCES,0.8539094650205762,"• The paper should provide the amount of compute required for each of the
765"
EXPERIMENTS COMPUTE RESOURCES,0.8549382716049383,"individual experimental runs as well as estimate the total compute.
766"
EXPERIMENTS COMPUTE RESOURCES,0.8559670781893004,"• The paper should disclose whether the full research project required more
767"
EXPERIMENTS COMPUTE RESOURCES,0.8569958847736625,"compute than the experiments reported in the paper (e.g., preliminary or failed
768"
EXPERIMENTS COMPUTE RESOURCES,0.8580246913580247,"experiments that didn’t make it into the paper).
769"
CODE OF ETHICS,0.8590534979423868,"9. Code Of Ethics
770"
CODE OF ETHICS,0.8600823045267489,"Question: Does the research conducted in the paper conform, in every respect, with
771"
CODE OF ETHICS,0.8611111111111112,"the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
772"
CODE OF ETHICS,0.8621399176954733,"Answer: [Yes]
773"
CODE OF ETHICS,0.8631687242798354,"Justification: Our research, working process, data and code correspond with NeurIPS
774"
CODE OF ETHICS,0.8641975308641975,"Code of Ethics in https://neurips.cc/public/EthicsGuidelines
775"
CODE OF ETHICS,0.8652263374485597,"Guidelines:
776"
CODE OF ETHICS,0.8662551440329218,"• The answer NA means that the authors have not reviewed the NeurIPS Code
777"
CODE OF ETHICS,0.8672839506172839,"of Ethics.
778"
CODE OF ETHICS,0.8683127572016461,"• If the authors answer No, they should explain the special circumstances that
779"
CODE OF ETHICS,0.8693415637860082,"require a deviation from the Code of Ethics.
780"
CODE OF ETHICS,0.8703703703703703,"• The authors should make sure to preserve anonymity (e.g., if there is a special
781"
CODE OF ETHICS,0.8713991769547325,"consideration due to laws or regulations in their jurisdiction).
782"
BROADER IMPACTS,0.8724279835390947,"10. Broader Impacts
783"
BROADER IMPACTS,0.8734567901234568,"Question: Does the paper discuss both potential positive societal impacts and
784"
BROADER IMPACTS,0.8744855967078189,"negative societal impacts of the work performed?
785"
BROADER IMPACTS,0.8755144032921811,"Answer: [Yes]
786"
BROADER IMPACTS,0.8765432098765432,"Justification: The broad societal impacts are discussed int the conclusion section.
787"
BROADER IMPACTS,0.8775720164609053,"Guidelines:
788"
BROADER IMPACTS,0.8786008230452675,"• The answer NA means that there is no societal impact of the work performed.
789"
BROADER IMPACTS,0.8796296296296297,"• If the authors answer NA or No, they should explain why their work has no
790"
BROADER IMPACTS,0.8806584362139918,"societal impact or why the paper does not address societal impact.
791"
BROADER IMPACTS,0.8816872427983539,"• Examples of negative societal impacts include potential malicious or unintended
792"
BROADER IMPACTS,0.8827160493827161,"uses (e.g., disinformation, generating fake profiles, surveillance), fairness consid-
793"
BROADER IMPACTS,0.8837448559670782,"erations (e.g., deployment of technologies that could make decisions that unfairly
794"
BROADER IMPACTS,0.8847736625514403,"impact specific groups), privacy considerations, and security considerations.
795"
BROADER IMPACTS,0.8858024691358025,"• The conference expects that many papers will be foundational research and
796"
BROADER IMPACTS,0.8868312757201646,"not tied to particular applications, let alone deployments. However, if there
797"
BROADER IMPACTS,0.8878600823045267,"is a direct path to any negative applications, the authors should point it out.
798"
BROADER IMPACTS,0.8888888888888888,"For example, it is legitimate to point out that an improvement in the quality
799"
BROADER IMPACTS,0.8899176954732511,"of generative models could be used to generate deepfakes for disinformation.
800"
BROADER IMPACTS,0.8909465020576132,"On the other hand, it is not needed to point out that a generic algorithm for
801"
BROADER IMPACTS,0.8919753086419753,"optimizing neural networks could enable people to train models that generate
802"
BROADER IMPACTS,0.8930041152263375,"Deepfakes faster.
803"
BROADER IMPACTS,0.8940329218106996,"• The authors should consider possible harms that could arise when the technology
804"
BROADER IMPACTS,0.8950617283950617,"is being used as intended and functioning correctly, harms that could arise when
805"
BROADER IMPACTS,0.8960905349794238,"the technology is being used as intended but gives incorrect results, and harms
806"
BROADER IMPACTS,0.897119341563786,"following from (intentional or unintentional) misuse of the technology.
807"
BROADER IMPACTS,0.8981481481481481,"• If there are negative societal impacts, the authors could also discuss possible
808"
BROADER IMPACTS,0.8991769547325102,"mitigation strategies (e.g., gated release of models, providing defenses in addition
809"
BROADER IMPACTS,0.9002057613168725,"to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a
810"
BROADER IMPACTS,0.9012345679012346,"system learns from feedback over time, improving the efficiency and accessibility
811"
BROADER IMPACTS,0.9022633744855967,"of ML).
812"
SAFEGUARDS,0.9032921810699589,"11. Safeguards
813"
SAFEGUARDS,0.904320987654321,"Question: Does the paper describe safeguards that have been put in place for
814"
SAFEGUARDS,0.9053497942386831,"responsible release of data or models that have a high risk for misuse (e.g., pretrained
815"
SAFEGUARDS,0.9063786008230452,"language models, image generators, or scraped datasets)?
816"
SAFEGUARDS,0.9074074074074074,"Answer: [NA]
817"
SAFEGUARDS,0.9084362139917695,"Justification: The paper poses no such risks.
818"
SAFEGUARDS,0.9094650205761317,"Guidelines:
819"
SAFEGUARDS,0.9104938271604939,"• The answer NA means that the paper poses no such risks.
820"
SAFEGUARDS,0.911522633744856,"• Released models that have a high risk for misuse or dual-use should be released
821"
SAFEGUARDS,0.9125514403292181,"with necessary safeguards to allow for controlled use of the model, for example
822"
SAFEGUARDS,0.9135802469135802,"by requiring that users adhere to usage guidelines or restrictions to access the
823"
SAFEGUARDS,0.9146090534979424,"model or implementing safety filters.
824"
SAFEGUARDS,0.9156378600823045,"• Datasets that have been scraped from the Internet could pose safety risks. The
825"
SAFEGUARDS,0.9166666666666666,"authors should describe how they avoided releasing unsafe images.
826"
SAFEGUARDS,0.9176954732510288,"• We recognize that providing effective safeguards is challenging, and many papers
827"
SAFEGUARDS,0.918724279835391,"do not require this, but we encourage authors to take this into account and
828"
SAFEGUARDS,0.9197530864197531,"make a best faith effort.
829"
LICENSES FOR EXISTING ASSETS,0.9207818930041153,"12. Licenses for existing assets
830"
LICENSES FOR EXISTING ASSETS,0.9218106995884774,"Question: Are the creators or original owners of assets (e.g., code, data, models),
831"
LICENSES FOR EXISTING ASSETS,0.9228395061728395,"used in the paper, properly credited and are the license and terms of use explicitly
832"
LICENSES FOR EXISTING ASSETS,0.9238683127572016,"mentioned and properly respected?
833"
LICENSES FOR EXISTING ASSETS,0.9248971193415638,"Answer: [Yes]
834"
LICENSES FOR EXISTING ASSETS,0.9259259259259259,"Justification: The models utilized in this research are appropriately cited within
835"
LICENSES FOR EXISTING ASSETS,0.926954732510288,"the text, including references to the AFLOW database. We have no commercial
836"
LICENSES FOR EXISTING ASSETS,0.9279835390946503,"interests related to the use of these models and the crystal structure database. The
837"
LICENSES FOR EXISTING ASSETS,0.9290123456790124,"code used in this study was entirely developed by our team.
838"
LICENSES FOR EXISTING ASSETS,0.9300411522633745,"Guidelines:
839"
LICENSES FOR EXISTING ASSETS,0.9310699588477366,"• The answer NA means that the paper does not use existing assets.
840"
LICENSES FOR EXISTING ASSETS,0.9320987654320988,"• The authors should cite the original paper that produced the code package or
841"
LICENSES FOR EXISTING ASSETS,0.9331275720164609,"dataset.
842"
LICENSES FOR EXISTING ASSETS,0.934156378600823,"• The authors should state which version of the asset is used and, if possible,
843"
LICENSES FOR EXISTING ASSETS,0.9351851851851852,"include a URL.
844"
LICENSES FOR EXISTING ASSETS,0.9362139917695473,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
845"
LICENSES FOR EXISTING ASSETS,0.9372427983539094,"• For scraped data from a particular source (e.g., website), the copyright and
846"
LICENSES FOR EXISTING ASSETS,0.9382716049382716,"terms of service of that source should be provided.
847"
LICENSES FOR EXISTING ASSETS,0.9393004115226338,"• If assets are released, the license, copyright information, and terms of use in
848"
LICENSES FOR EXISTING ASSETS,0.9403292181069959,"the package should be provided. For popular datasets, paperswithcode.com/
849"
LICENSES FOR EXISTING ASSETS,0.941358024691358,"datasets has curated licenses for some datasets. Their licensing guide can help
850"
LICENSES FOR EXISTING ASSETS,0.9423868312757202,"determine the license of a dataset.
851"
LICENSES FOR EXISTING ASSETS,0.9434156378600823,"• For existing datasets that are re-packaged, both the original license and the
852"
LICENSES FOR EXISTING ASSETS,0.9444444444444444,"license of the derived asset (if it has changed) should be provided.
853"
LICENSES FOR EXISTING ASSETS,0.9454732510288066,"• If this information is not available online, the authors are encouraged to reach
854"
LICENSES FOR EXISTING ASSETS,0.9465020576131687,"out to the asset’s creators.
855"
NEW ASSETS,0.9475308641975309,"13. New Assets
856"
NEW ASSETS,0.948559670781893,"Question: Are new assets introduced in the paper well documented and is the
857"
NEW ASSETS,0.9495884773662552,"documentation provided alongside the assets?
858"
NEW ASSETS,0.9506172839506173,"Answer: [Yes]
859"
NEW ASSETS,0.9516460905349794,"Justification: The primary assets of our research are: 1) the methodology, and 2) the
860"
NEW ASSETS,0.9526748971193416,"code for training models and performing inference. Both are thoroughly documented.
861"
NEW ASSETS,0.9537037037037037,"Guidelines:
862"
NEW ASSETS,0.9547325102880658,"• The answer NA means that the paper does not release new assets.
863"
NEW ASSETS,0.9557613168724279,"• Researchers should communicate the details of the dataset/code/model as part
864"
NEW ASSETS,0.9567901234567902,"of their submissions via structured templates. This includes details about
865"
NEW ASSETS,0.9578189300411523,"training, license, limitations, etc.
866"
NEW ASSETS,0.9588477366255144,"• The paper should discuss whether and how consent was obtained from people
867"
NEW ASSETS,0.9598765432098766,"whose asset is used.
868"
NEW ASSETS,0.9609053497942387,"• At submission time, remember to anonymize your assets (if applicable). You
869"
NEW ASSETS,0.9619341563786008,"can either create an anonymized URL or include an anonymized zip file.
870"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9629629629629629,"14. Crowdsourcing and Research with Human Subjects
871"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9639917695473251,"Question: For crowdsourcing experiments and research with human subjects, does
872"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9650205761316872,"the paper include the full text of instructions given to participants and screenshots,
873"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9660493827160493,"if applicable, as well as details about compensation (if any)?
874"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9670781893004116,"Answer: [NA]
875"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9681069958847737,"Justification: The paper does not involve crowdsourcing nor research with human
876"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9691358024691358,"subjects.
877"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.970164609053498,"Guidelines:
878"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9711934156378601,"• The answer NA means that the paper does not involve crowdsourcing nor
879"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9722222222222222,"research with human subjects.
880"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9732510288065843,"• Including this information in the supplemental material is fine, but if the main
881"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9742798353909465,"contribution of the paper involves human subjects, then as much detail as
882"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9753086419753086,"possible should be included in the main paper.
883"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9763374485596708,"• According to the NeurIPS Code of Ethics, workers involved in data collection,
884"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.977366255144033,"curation, or other labor should be paid at least the minimum wage in the
885"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9783950617283951,"country of the data collector.
886"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9794238683127572,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
887"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9804526748971193,"Subjects
888"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9814814814814815,"Question: Does the paper describe potential risks incurred by study participants,
889"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9825102880658436,"whether such risks were disclosed to the subjects, and whether Institutional Review
890"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9835390946502057,"Board (IRB) approvals (or an equivalent approval/review based on the requirements
891"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9845679012345679,"of your country or institution) were obtained?
892"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.98559670781893,"Answer: [NA]
893"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9866255144032922,"Justification: The paper does not involve crowdsourcing nor research with human
894"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9876543209876543,"subjects
895"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9886831275720165,"Guidelines:
896"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9897119341563786,"• The answer NA means that the paper does not involve crowdsourcing nor
897"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9907407407407407,"research with human subjects.
898"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9917695473251029,"• Depending on the country in which research is conducted, IRB approval (or
899"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.992798353909465,"equivalent) may be required for any human subjects research. If you obtained
900"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9938271604938271,"IRB approval, you should clearly state this in the paper.
901"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9948559670781894,"• We recognize that the procedures for this may vary significantly between
902"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9958847736625515,"institutions and locations, and we expect authors to adhere to the NeurIPS
903"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9969135802469136,"Code of Ethics and the guidelines for their institution.
904"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9979423868312757,"• For initial submissions, do not include any information that would break
905"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9989711934156379,"anonymity (if applicable), such as the institution conducting the review.
906"
