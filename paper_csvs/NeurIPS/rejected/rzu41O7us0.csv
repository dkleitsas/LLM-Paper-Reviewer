Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0022123893805309734,"Neuronal responses associated with complex tasks are superpositions of several
1"
ABSTRACT,0.004424778761061947,"elementary physiological and functional motifs. Important challenges in this context
2"
ABSTRACT,0.00663716814159292,"relate to identification of elementary responses (also known as basic functional
3"
ABSTRACT,0.008849557522123894,"neuronal networks), combinations of responses for given tasks, and their use in task
4"
ABSTRACT,0.011061946902654867,"and efficacy prediction, and physiological characterization. Task-specific functional
5"
ABSTRACT,0.01327433628318584,"MRI (fMRI) images provide excellent datasets for studying the neuronal basis of cog-
6"
ABSTRACT,0.015486725663716814,"nitive processes. In this work, we focus on the problem of deconvolving task-specific
7"
ABSTRACT,0.017699115044247787,"aggregate neuronal networks into elementary networks, to use these networks for
8"
ABSTRACT,0.01991150442477876,"functional characterization, and to “explain” these networks by mapping them to
9"
ABSTRACT,0.022123893805309734,"underlying physiological regions of the brain. This task poses a number of challenges
10"
ABSTRACT,0.024336283185840708,"due to very high dimensionality, small number of samples, acquisition variability,
11"
ABSTRACT,0.02654867256637168,"and noise. We propose a deconvolution method based on supervised non-negative
12"
ABSTRACT,0.028761061946902654,"matrix factorization (SupNMF) that identifies elementary networks as factors of a
13"
ABSTRACT,0.030973451327433628,"suitably constructed matrix. We show the following important results: (i) SupNMF
14"
ABSTRACT,0.033185840707964605,"reveals cognitive ""building blocks"" of task connectomes that are physiologically
15"
ABSTRACT,0.035398230088495575,"interpretable; (ii) SupNMF factors can be used to predict tasks with high accuracy;
16"
ABSTRACT,0.03761061946902655,"and (iii) SupNMF outperforms other supervised factoring techniques both in terms
17"
ABSTRACT,0.03982300884955752,"of prediction accuracy and interpretability. More broadly, our framework provides
18"
ABSTRACT,0.0420353982300885,"important insights into the physiological underpinnings of brain function.
19"
INTRODUCTION,0.04424778761061947,"1
Introduction
20"
INTRODUCTION,0.046460176991150445,"Connectomic studies use functional brain images of human subjects performing tasks to elucidate
21"
INTRODUCTION,0.048672566371681415,"complex cognitive processes. Functional Magnetic Resonance Imaging (fMRI) is a common imaging
22"
INTRODUCTION,0.05088495575221239,"modality used to analyze the underlying natural processes in healthy individuals and the dysregulation
23"
INTRODUCTION,0.05309734513274336,"of such processes due to disease and/or injury. Functional networks derived from fMRIs typically
24"
INTRODUCTION,0.05530973451327434,"superpose many neurophysiological responses elicited by stimuli.
Identifying and separating
25"
INTRODUCTION,0.05752212389380531,"functional networks into their basic building blocks is essential to explain the shared, and unique
26"
INTRODUCTION,0.059734513274336286,"aspects of neuronal responses across heterogeneous populations performing different tasks. Ideally,
27"
INTRODUCTION,0.061946902654867256,"these elemental networks should be grounded in neurophysiology, identifying coherent modules of
28"
INTRODUCTION,0.06415929203539823,"neural responses that are interpretable by neuroscientists and other domain experts.
29"
INTRODUCTION,0.06637168141592921,"The method of choice for connectomic analysis is Independent Component Analysis (ICA) [36, 24],
30"
INTRODUCTION,0.06858407079646017,"which is used on individual fMRIs to spatially localize regions of interest. Group-ICA [13, 10, 34]
31"
INTRODUCTION,0.07079646017699115,"combines fMRIs across individuals to model shared regions of interest. Other ML-based interpretable
32"
INTRODUCTION,0.07300884955752213,"methods have been proposed in the recent past [19, 26, 33, 29]. However, these methods are limited
33"
INTRODUCTION,0.0752212389380531,"in their ability to handle large datasets with diverse subjects (young v/s old, healthy v/s diseased) per-
34"
INTRODUCTION,0.07743362831858407,"forming a variety of cognitive tasks. Large-scale efforts, such as the Human Connectome Project [46],
35"
INTRODUCTION,0.07964601769911504,"Cambridge Centre for Ageing and Neuroscience (Cam-CAN) dataset [42], and Alzheimer’s Disease
36"
INTRODUCTION,0.08185840707964602,"Neuroimaging Initiative (ADNI) [25] have each collected and curated neuroimages from cohorts of
37"
INTRODUCTION,0.084070796460177,"several hundred subjects. Current efforts by the UK Biobank will image over 100,000 individuals [35].
38"
INTRODUCTION,0.08628318584070796,"Each of these datasets includes subjects of different ages, stages of neuroplasticity, and degeneration.
39"
INTRODUCTION,0.08849557522123894,"In this paper, we propose a novel framework that deconvolves networks derived from fMRIs of subjects
40"
INTRODUCTION,0.09070796460176991,"performing different tasks into a small set of elementary networks that serve as building blocks that are:
41"
INTRODUCTION,0.09292035398230089,"(i) shared across large cohorts; (ii) can be composed into task-specific networks; and (iii) are predictive
42"
INTRODUCTION,0.09513274336283185,"of tasks and efficacy. We call these networks canonical task connectomes. Our framework also com-
43"
INTRODUCTION,0.09734513274336283,"putes the extent of expression of these networks for each task, along with its neurophysiological basis.
44"
INTRODUCTION,0.09955752212389381,"Our approach first combines individual functional networks into a population-level matrix X. We then
45"
INTRODUCTION,0.10176991150442478,"deconvolve this matrix into its factors A and S such that each column A(i,∗) corresponds to a canonical
46"
INTRODUCTION,0.10398230088495575,"task connectome, and the corresponding row S(∗,i) characterizes the extent to which the canonical
47"
INTRODUCTION,0.10619469026548672,"network is expressed in every subject. However, since individual samples (fMRIs) correspond to
48"
INTRODUCTION,0.1084070796460177,"subjects performing different tasks, the latent canonical representations must encode this important
49"
INTRODUCTION,0.11061946902654868,"information. We accomplish this by formulating a suitable supervised matrix factorization problem,
50"
INTRODUCTION,0.11283185840707964,"where factors are guided by a supervision matrix of tasks and subjects.
51"
INTRODUCTION,0.11504424778761062,"We present experimental results on the “unrelated set” of subjects in the Human Connectome Project.
52"
INTRODUCTION,0.1172566371681416,"We compare results from two methods – Supervised Singular Value Decomposition (SupSVD) and
53"
INTRODUCTION,0.11946902654867257,"Supervised Non-Negative Matrix Factorization (SupNMF) on subjects from HCP at rest and for
54"
INTRODUCTION,0.12168141592920353,"six tasks (Language, Emotional Processing, Gambling, Motor, Relational Processing, and Social
55"
INTRODUCTION,0.12389380530973451,"Processing). Our results show that:
56"
INTRODUCTION,0.1261061946902655,"• Canonical task connectomes have high task-specificity. We show that our approach constructs
57"
INTRODUCTION,0.12831858407079647,"networks that uniquely characterize different tasks and are therefore excellent markers of tasks.
58"
INTRODUCTION,0.13053097345132744,"• Canonical task connectomes are generalizable across cohorts. We show that canonical
59"
INTRODUCTION,0.13274336283185842,"representations obtained on a suitably constructed train set can accurately predict tasks being
60"
INTRODUCTION,0.13495575221238937,"performed by the test set. We also show that SupNMF outperforms SupSVD in terms of
61"
INTRODUCTION,0.13716814159292035,"prediction accuracy across ranges of parameters.
62"
INTRODUCTION,0.13938053097345132,"• Canonical task connectomes identify common neural processes. We show that our approach
63"
INTRODUCTION,0.1415929203539823,"finds functional networks that are shared across tasks. This enables novel interpretations
64"
INTRODUCTION,0.14380530973451328,"of processes and responses associated with different task stimuli.
65"
INTRODUCTION,0.14601769911504425,"• Canonical task connectomes have a strong physiological basis. We show that the canonical
66"
INTRODUCTION,0.14823008849557523,"connectomes can be mapped to regions of the brain to identify physiological underpinnings
67"
INTRODUCTION,0.1504424778761062,"of tasks, that are in strong agreement with literature in neurosciences.
68"
INTRODUCTION,0.15265486725663716,"The rest of the paper is organized as follows: in Sections 2.2 and 2.3, we discuss relevant methods
69"
INTRODUCTION,0.15486725663716813,"for supervised matrix factorization. In Section 2.1, we provide details for our proposed framework.
70"
INTRODUCTION,0.1570796460176991,"Then, we describe the HCP dataset and the preprocessing pipeline. This is followed by comprehensive
71"
INTRODUCTION,0.1592920353982301,"experimental results in section 3, where we demonstrate the interpretability and generalizability of our
72"
INTRODUCTION,0.16150442477876106,"proposed approach. Finally, we conclude with related methods in Section 4 and discussion in Section 5.
73"
METHODS AND MATERIALS,0.16371681415929204,"2
Methods and Materials
74"
METHODS AND MATERIALS,0.16592920353982302,"We describe our formulation and solution to the problem of identifying interpretable task-specific
75"
METHODS AND MATERIALS,0.168141592920354,"brain networks, called “connectomes” from neuroimaging datasets of subjects performing a variety
76"
METHODS AND MATERIALS,0.17035398230088494,"of cognitive tasks. Connectomes are networks in which regions of the brain correspond to nodes and
77"
METHODS AND MATERIALS,0.17256637168141592,"correlated activity quantifies the strength of edges across corresponding nodes (regions). We describe,
78"
METHODS AND MATERIALS,0.1747787610619469,"in more detail, the process of construction of connectomes in Section 2.4.
79"
METHODS AND MATERIALS,0.17699115044247787,"We hypothesize and validate that neuronal activity observed during a task is composed of a small set
80"
METHODS AND MATERIALS,0.17920353982300885,"of elementary patterns or motifs. Correspondingly, the observed connectome is a superposition of
81"
METHODS AND MATERIALS,0.18141592920353983,"these motifs that we call canonical task connectomes. The goal of our formulation and methods is
82"
METHODS AND MATERIALS,0.1836283185840708,"to demonstrate the existence and applications of such canonical task connectomes.
83"
METHODS AND MATERIALS,0.18584070796460178,"We abstract our connectome as a region×region similarity matrix. Our problem of finding canonical
84"
METHODS AND MATERIALS,0.18805309734513273,"task connectomes can be formulated as one of Supervised Matrix Factorization (SMF) – a family of
85"
METHODS AND MATERIALS,0.1902654867256637,"deconvolution techniques that expresses a data matrix as a sum of low-rank factors. The specific factors
86"
METHODS AND MATERIALS,0.19247787610619468,"are determined by the optimization criteria and constraints associated with different methods. In
87"
METHODS AND MATERIALS,0.19469026548672566,"SMF, the factors are further guided by additional information (in our case, task labels associated with
88"
METHODS AND MATERIALS,0.19690265486725664,"subjects) written as a supervision matrix. We use two state-of-the-art supervised matrix factorization
89"
METHODS AND MATERIALS,0.19911504424778761,"techniques – Supervised Non-negative Matrix Factorization (SupNMF) and Supervised Singular
90"
METHODS AND MATERIALS,0.2013274336283186,"Value Decomposition (SupSVD) to compute matrix factors. We suitably formulate our deconvolution
91"
METHODS AND MATERIALS,0.20353982300884957,"problem for using these techniques, apply them to a large cohort of subjects, comprehensively compare
92"
METHODS AND MATERIALS,0.20575221238938052,"their performance, and show that our formulation, combined with SupNMF yields highly interpretable,
93"
METHODS AND MATERIALS,0.2079646017699115,"consistent, and strong task-specific signals.
94"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.21017699115044247,"2.1
Overview of our proposed framework
95"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.21238938053097345,"We write an observed connectome matrix CO ∈Rd×d as a linear combination of a small number of
96"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.21460176991150443,"latent (i.e., unobserved) matrices Cl.
97"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2168141592920354,"C(j)
O = r
X"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.21902654867256638,"i=1
S(j,i)C(i)
l
(1)"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.22123893805309736,"Here, r denotes the number of latent connectomes (i.e., the dimensionality of latent space), i denotes
98"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2234513274336283,"the index of latent connectome, j is the index of observed connectome (subject or data sample) in the
99"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.22566371681415928,"dataset, and S∈Rn×r represents the matrix of coefficients corresponding to the weights associated with
100"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.22787610619469026,"each latent matrix. Each connectome (data sample) in the dataset has an associated task-label vector
101"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.23008849557522124,"y∈{0,1}t, where t is the number of tasks. A connectome has exactly one non-zero in its label vector,
102"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2323008849557522,"corresponding to the task that was being performed by the subject during imaging. We aim to learn latent
103"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2345132743362832,"factors and use them to construct a predictor f that takes in a row of S and correctly predicts the task.
104"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.23672566371681417,"ˆy(j) =f(S(j,∗))
(2)
Here, f :Rr →{0,1}t. Combining equations 1 and 2, we get our objective function
105"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.23893805309734514,"minimize
S,f,Cl n
X j=1"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2411504424778761,"
||C(j)
O − r
X"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.24336283185840707,"i=1
S(i,j)C(i)
l ||2
F +λ(y(j)−f(S(j,∗))))2
(3)"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.24557522123893805,"Here, n denotes the total number of data samples, and d denotes the number of regions in each
106"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.24778761061946902,"connectome. The first term in the objective function minimizes the approximation error, and the second
107"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.25,"term minimizes the classification error. The relative importance of the two terms are controlled by the
108"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.252212389380531,"tuneable parameter λ. Rather than working with tensors, we simplify our setting by: a) vectorizing
109"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.25442477876106195,"the connectomes and stacking them column-wise into a population-level data matrix, X∈RO(d2)×n;
110"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.25663716814159293,"and b) modeling f(.) as a linear function. We create a one-hot matrix Y to represent labels for the
111"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2588495575221239,"different cognitive tasks performed by the subjects. We now model the problem as one of supervised
112"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2610619469026549,"matrix factorization. We compute the factors using different matrix factorization techniques – NMF,
113"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.26327433628318586,"SVD, SupNMF, and SupSVD. We discuss the latter two approaches in Sec 2.2 and 2.3 respectively.
114"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.26548672566371684,"On this matrix, we note that the columns of the basis matrix are connectomes that are superposed to
115"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2676991150442478,"approximate of the columns of X. We call them “canonical task connectomes”. Our results show that
116"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.26991150442477874,"these representations strongly correlate with anatomical and physiological processes associated with
117"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2721238938053097,"different tasks.
118"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2743362831858407,"To show the generalizability of these canonical representations, we divide the cohort randomly into
119"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.27654867256637167,"train and test sets. We use the canonical representation computed from the train set to infer cognitive
120"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.27876106194690264,"tasks performed by subjects in the test set. In Fig. 1, we illustrate the general framework. Using the
121"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2809734513274336,"train set, we find a small number of canonical task connectomes that serve as basis vectors to explain
122"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2831858407079646,"brain activity in a large cohort. For the test set, we find coefficients that best fit the previously computed
123"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.2853982300884956,"basis. Next, we learn a model to map coefficients in the train set to labels. We use this model on the
124"
OVERVIEW OF OUR PROPOSED FRAMEWORK,0.28761061946902655,"test coefficients to predict tasks performed.
125"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.28982300884955753,"2.2
Supervised Non-negative Matrix Factorization
126"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.2920353982300885,"Let X ∈Rp×n
≥0 denote the data matrix, Y ∈Rk×n
≥0
denote a class label matrix, and k the number of
127"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.2942477876106195,"different classes. Supervised Non-negative Matrix Factorization (SupNMF) is defined as:
128"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.29646017699115046,"argmin
A,S,B≥0
||X−AS||2
F +λ||Y−BS||2
F
(4)"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.29867256637168144,"Figure 1: Overview of our framework: (1) The training phase deconvolves the data matrix of vectorized
connectomes in the training set into a small number of basis vectors; (2) The testing phase computes
the coefficients of the functional basis and predicts the task on new subjects."
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.3008849557522124,"Here, A ∈Rp×r
≥0 is the (non-negative) “basis matrix” which is a low-rank, latent description of the
129"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.3030973451327434,"columns of X, S ∈Rr×n
≥0
is the (non-negative) matrix of coefficients that provides the weights to
130"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.3053097345132743,"each of the latent factors required to explain each data-point, B∈Rk×r
≥0 is the matrix that minimizes
131"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.3075221238938053,"classification error, and λ controls the relative importance of the supervision term. The first term
132"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.30973451327433627,"minimizes the error in reconstructing the data matrix and the second term minimizes classification error.
133"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.31194690265486724,"A few points to note: a) When λ=0, this formulation reduces to unsupervised Non-negative Matrix
134"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.3141592920353982,"Factorization [47] [31]; b) objectives such as information divergence can be used in lieu of the
135"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.3163716814159292,"Frobenius Norm [22]. This problem has been modeled as a block multi-convex problem by Haddock
136"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.3185840707964602,"et al. [22] to derive the following algorithm with multiplicative updates. In the algorithm, M⊙N
137"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.32079646017699115,"represents the Hadamard Product (i.e., element-wise product) of matrices M and N. Similarly M N
138"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.3230088495575221,"represents Hadamard Division.
139"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.3252212389380531,"Algorithm 1: Supervised NMF
Input:X,Y,r,λ,N
Initialize: A∈Rp×r
≥0 , B∈Rk×r
≥0 , S ∈Rr×n
≥0
for i = 1 ,..., N do"
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.3274336283185841,A←A⊙XST SST
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.32964601769911506,B←B⊙YST BSST
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.33185840707964603,S←S⊙AT X+λBT Y
SUPERVISED NON-NEGATIVE MATRIX FACTORIZATION,0.334070796460177,"AT AS+λBT BS
end"
SUPERVISED SVD,0.336283185840708,"2.3
Supervised SVD
140"
SUPERVISED SVD,0.33849557522123896,"Supervised Singular Value Decomposition (SupSVD) [32] incorporates a supervision matrix into
141"
SUPERVISED SVD,0.3407079646017699,"conventional SVD. It assumes that the data matrix X∈Rn×p contains latent, low-rank information
142"
SUPERVISED SVD,0.34292035398230086,"that is shared with the supervision matrix Y∈Rn×k. The SupSVD model can be expressed as follows:
143"
SUPERVISED SVD,0.34513274336283184,"X=UVT +E
U=YB+F
(5)"
SUPERVISED SVD,0.3473451327433628,"Here, U ∈Rn×r is a latent score matrix, V ∈Rp×r is a full-rank loading matrix, and B ∈Rk×r is
144"
SUPERVISED SVD,0.3495575221238938,"a coefficient matrix, with F ∈Rn×r and E ∈Rn×p being error matrices. For model estimation, a
145"
SUPERVISED SVD,0.35176991150442477,"modified version of the expectation–maximization (EM) algorithm was proposed by Li et al. [32].
146"
DATA,0.35398230088495575,"2.4
Data
147"
DATA,0.3561946902654867,"We validate our model and methods on data from the Human Connectome Project (HCP) Young Adult
148"
DATA,0.3584070796460177,"dataset [46]. Specifically, we use the fMRIs from the set of 100 “unrelated subjects”. For each subject,
149"
DATA,0.3606194690265487,"we have separate fMRIs when they are at rest, and while they perform six cognitive tasks (Language,
150"
DATA,0.36283185840707965,"Emotional Processing, Gambling, Motor, Relational Processing, and Social Processing) [2]. We first
151"
DATA,0.36504424778761063,"use the Minimal Pre-Processing Pipeline prescribed by the HCP consortium [18]. This process includes
152"
DATA,0.3672566371681416,"spatial artifact/distortion removal, head motion correction, registration, and normalization to standard
153"
DATA,0.3694690265486726,"space. For each input noisy fMRI, the Minimal Preprocessing Pipeline outputs a clean and standardized
154"
DATA,0.37168141592920356,"voxel×time time-series matrix. Then, we use the Atlas of Glasser et al. [17] to aggregate this matrix
155"
DATA,0.37389380530973454,"into a region×time matrix. We note that each region consists of proximal voxels with shared anatomy.
156"
DATA,0.37610619469026546,"In all, the Glasser Atlas demarcates 180 regions in each hemisphere (360 in total). We then create the
157"
DATA,0.37831858407079644,"functional connectome (FC) matrix for each fMRI by computing the Pearson Correlation between all
158"
DATA,0.3805309734513274,"pairs of regions. In all, we have 700 FCs (100 subjects×7 tasks). We vectorize the upper triangular
159"
DATA,0.3827433628318584,"matrix of each FC and stack them side by side to create a population-level matrix of size 700×64620.
160"
RESULTS,0.38495575221238937,"3
Results
161"
RESULTS,0.38716814159292035,"In this section, we show that our canonical task connectomes are highly specific to a small subset of
162"
RESULTS,0.3893805309734513,"tasks, and as a consequence provide both an understanding of the neural response, as well as the ability
163"
RESULTS,0.3915929203539823,"to predict tasks. Then, we provide evidence of strong spatial localization for these representative
164"
RESULTS,0.3938053097345133,"brain networks, which establishes interpretability on the basis of neuro-anatomy. We also show that
165"
RESULTS,0.39601769911504425,"the regions implicated in the tasks are supported by prior experimental studies, which establishes
166"
RESULTS,0.39823008849557523,"physiological interpretations.
167"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4004424778761062,"3.1
Canonical Task Connectomes have High Task Specificity
168"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4026548672566372,"In the first set of results, we demonstrate that our connectomes encode information that is unique
169"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.40486725663716816,"to each task. This is non-trivial because of: a) inherent heterogeneity in basal brain activity across
170"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.40707964601769914,"individuals; b) individual-level differences in cognitive processes to perform a task; c) diversity of
171"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4092920353982301,"task conditions; and d) noise in the imaging modality. Using four methods for matrix factorization
172"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.41150442477876104,"– SupNMF, NMF, SupSVD, and SVD, we deconvolve the population-level matrix X to find different
173"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.413716814159292,"sets of canonical task connectomes and the corresponding linear coefficients that quantify the extent
174"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.415929203539823,"to which each canonical task connectome is present in every functional connectome. For the purposes
175"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.41814159292035397,"of visualization, we project the coefficients’ matrix (S for NMF/SupNMF, and U for SVD/SupSVD)
176"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.42035398230088494,"into two dimensions using UMAP, shown in Fig 2. We observe that in each case, resting-state (Red)
177"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4225663716814159,"FCs are always clustered separately. This confirms that resting-state brain activity is very different
178"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4247787610619469,"from all task-specific brain activity. We also see that Language (Blue) and Social Processing (Purple)
179"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4269911504424779,"are also clearly separated by all four methods. This suggests that the task-specific networks in the
180"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.42920353982300885,"case of these two tasks are strongly distinct, and can be deconvolved with no supervision.
181"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4314159292035398,"However, other tasks – Emotion Processing (Green), Gambling (Amber), Motor (Pink), and Social
182"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4336283185840708,"Processing (Gray) are separated only by SupNMF (Fig 2a. The lack of separation observed in NMF,
183"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4358407079646018,"SVD, and SupSVD strongly indicates that the canonical representations obtained by SupNMF are most
184"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.43805309734513276,"task-specific. To quantify the task discriminatory power of our approach, we cluster the coefficients
185"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.44026548672566373,"using k-means for k={1,...,7} and compute the Adjusted Rand Index (ARI) in each case. The results
186"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4424778761061947,"are shown in Fig 3. It is evident that ARI for SupNMF is significantly higher for all choices of k. For
187"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4446902654867257,"NMF, SVD, and SupSVD, ARI plateaus at k=4, which is consistent with the UMAP plots.
188"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4469026548672566,"Since Canonical Task Connectomes are shown to be task-specific, they provide excellent
189"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4491150442477876,"representations to classify tasks performed by a test subject.
190"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.45132743362831856,"(a) UMAP of SupNMF
(b) UMAP of NMF"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.45353982300884954,"(c) UMAP of SupSVD
(d) UMAP of SVD"
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4557522123893805,"Figure 2: Task-specificity of canonical task connectomes obtained by different methods. We use UMAP
to visualize the “coefficients matrix” for different tasks. (a)-(d) show the results for SupNMF, NMF,
SupSVD, and SVD respectively. We see that Rest (Red), Language (Blue), and Social (Purple) are
clustered in all four cases. However, the remaining tasks are only separated by SupNMF."
CANONICAL TASK CONNECTOMES HAVE HIGH TASK SPECIFICITY,0.4579646017699115,"Figure 3: ARI values for k-means clustering on the coefficients obtained by SupNMF, NMF, SupSVD,
and SVD. We observe that ARI for SupNMF is consistently higher than other methods."
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.46017699115044247,"3.2
Canonical Task Connectomes are Generalizable across Cohorts
191"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.46238938053097345,"We show that canonical task connectomes are stable representations of different tasks. To demonstrate
192"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.4646017699115044,"this, we first compute the canonical representations on a training set. Then, we predict the task
193"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.4668141592920354,"performed in the test-set. More specifically, we create Xtrain and Xtest by 80/20 random splits of the
194"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.4690265486725664,"subjects. We deconvolve Xtrain to find the canonical task connectomes ˜A and the coefficient matrix
195"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.47123893805309736,"˜S, and use ˜S along with corresponding task labels to train a classifier. Now, given a test subject (or
196"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.47345132743362833,"test set), we compute the least-squares solution ˆS using ˆS= ˜A†Xtest. Finally, we predict the labels
197"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.4756637168141593,"of Xtest using ˆS and the trained classifier.
198"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.4778761061946903,"We compare the test accuracy of SVD, NMF, SupNMF, and SupSVD using three classifiers – K-nearest
199"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.48008849557522126,"neighbor, support vector machine, and a 3-layer perceptron. In Table 1, we summarize the results
200"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.4823008849557522,"for rank-10 approximations, averaged across 10 runs. The factors computed by SupNMF yield high
201"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.48451327433628316,"accuracy (>88%) for all three classifiers. The factors output by SupSVD and NMF also perform well
202"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.48672566371681414,"in predicting task conditions. This can be attributed to the fact that while individual factors of SupSVD
203"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.4889380530973451,"and NMF are not task-specific, the combinations of different factors still have reasonable predictive
204"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.4911504424778761,"Table 1: Test accuracy using different classifiers
Method
SupNMF
SupSVD
NMF
SVD"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.49336283185840707,"KNN
88.54 ± 0.49
83.30 ± 2.00
82.64 ± 2.02
69.11 ± 4.24
MLP
88.14 ± 2.16
83.96 ± 2.53
87.36 ± 2.33
74.44 ± 3.98
SVM
87.64 ± 2.00
86.09 ± 3.31
86.86 ± 1.70
73.61 ± 2.73"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.49557522123893805,"power. This is evident from Fig. 4, where we show the normalized and thresholded columns of ˜S from
205"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.497787610619469,"both SupNMF and NMF. In SupNMF, most connectomes from a common task are assigned to the
206"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.5,"same “canonical connectome”. However, in NMF, we see that connectomes from a common task are
207"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.5022123893805309,"assigned to different factors. The accuracy of predicting on the basis of singular vectors is poor, due
208"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.504424778761062,"to the orthogonality constraints enforced on the columns of U. We show similar plots for SupSVD
209"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.5066371681415929,"and SVD in Supplementary Section 1.
210"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.5088495575221239,"(a) Coefficients of SupNMF on test set
(b) Coefficients of NMF on test set"
CANONICAL TASK CONNECTOMES ARE GENERALIZABLE ACROSS COHORTS,0.5110619469026548,"Figure 4: Coefficient matrices of SupNMF and NMF for test connectomes. We L-1 normalize the
columns of ˜S obtained by both SupNMF and NMF and fit to the Normal Distribution. We then use
90 percentile as the cutoff to discard small values in both matrices. For coefficients in SupNMF, we see
that each “canonical connectome” is assigned to one task in most cases. This is evident by the minimal
mixing of colors. However, in NMF, we see that coefficients corresponding to a common task are
spread across different “canonical connectomes”. In this figure, each task(color) has 20 connectomes.
We compute rank-10 coefficient matrices in both cases."
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5132743362831859,"3.3
Canonical Task Connectomes have a Strong Anatomical and Physiological Basis
211"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5154867256637168,"We show that: a) each canonical task connectome is spatially localized to anatomically demarcated
212"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5176991150442478,"lobes; and b) the regions enriched in each canonical connectome are known to be implicated in the
213"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5199115044247787,"corresponding task. As before, we deconvolve the population-level matrix X to compute A and S. In
214"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5221238938053098,"this experiment, we use rank 20 approximation to aid in the interpretation. From each column A(∗,i),
215"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5243362831858407,"we construct region×region canonical task connectome Ci. Finally, we create adjacency matrices
216"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5265486725663717,"by retaining the top 5% of edges from Ci.
217"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5287610619469026,"In Fig 6, we visualize the task-specific connectomes. We restrict our analysis to nodes with degree>35
218"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5309734513274337,"(p-value < 1e-5). We note that edges containing the Prefrontal Cortex are over-represented in A4, A5,
219"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5331858407079646,"A7, and A18; MotorStrip is over-represented in A17; Parietal Lobe is over-represented in A2, A4,
220"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5353982300884956,"and A20; and the Occipital Lobe is over-represented in A1, A2, and A9. In each case, the observation
221"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5376106194690266,"is statistically significant with p-values < 1e-10. We note that the temporal lobe is the only major region
222"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5398230088495575,"not represented in these canonical connectomes. In all, this high degree of spatial locality indicates
223"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5420353982300885,"a strong anatomical basis.
224"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5442477876106194,"Next, we normalize the columns of S given by SupNMF and fit to a Gaussian and retain only those
225"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5464601769911505,"non-zero values higher than 90 percentile. In Fig. 5, the rows of S are visualized in a combined graph.
226"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5486725663716814,"It is evident that the non-zeros of these significant coefficients are highly selective of tasks. In fact,
227"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5508849557522124,"coefficients are active only for one specific task. With the knowledge of both the anatomical basis
228"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5530973451327433,"of each canonical connectome (Fig. 6 and their associated tasks (Fig. 5), we can now establish the
229"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5553097345132744,"physiological basis for these canonical connectomes. We find that our method finds patterns that are
230"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5575221238938053,"supported by neuroscience experiments reported in literature. Regions in the left prefrontal cortex
231"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5597345132743363,"are associated with word and sentence comprehension [16], which is over-represented in A4 of Fig 6
232"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5619469026548672,"corresponding to the language task, as shown in S4 of 5. The dorsal Default Mode Network (dDMN) is
233"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5641592920353983,"known to be active during Rest [5]. The anatomical regions for this functional network to the posterior
234"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5663716814159292,"cingulate cortex (in the limbic node), and the angular gyrus found in the posterior part of the inferior
235"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5685840707964602,"parietal lobe, which is over-represented in A9 of Fig 6. Additionally substructures corresponding
236"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5707964601769911,"to the dorsal medial prefrontal cortex are also found in A9. We see that rest connectomes are strongly
237"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5730088495575221,"activated for the corresponding column in the S matrix, as shown in Figure 4. The regions implicated
238"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5752212389380531,"in social processing are the medial prefrontal cortex, which is located in the prefrontal cortex of
239"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.577433628318584,"the frontal lobe [15]. In our results, these nodes are over-represented in A18. Finally, the regions
240"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5796460176991151,"implicated in relational processing are dorsolateral Prefrontal Cortex rostrolateral prefrontal cortex
241"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.581858407079646,"and posterior parietal cortex [23]. These regions are over-represented in A20, and A3 respectively.
242"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.584070796460177,"Figure 5: Coefficients matrix S of SupNMF. We normalize the columns of S and fit to the Normal
Distribution. We then use 90 percentile as the cutoff to discard small values. Each row of S is nearly
exclusive to one task (as indicated by the minimal mixing of colors/ tasks). We combined all rows
of S into one plot for effective visualization (by summing across columns). The colors code for rest
and six tasks. Within each rectangle bounding box, we have the entire cohort of 100 subjects . A1 A6 A11 A16"
CANONICAL TASK CONNECTOMES HAVE A STRONG ANATOMICAL AND PHYSIOLOGICAL BASIS,0.5862831858407079,"Figure 6: Canonical Task Connectomes have strong anatomical basis. In each of the 20 canonical task
connectomes, the disconnected semi-circles represent the two hemispheres. Each dot in the inner side
of these hemispheres corresponds to a micro-region in the brain. In all, there are 360 micro-regions,
each can be mapped directly to one of the coarser lobes. The connectomes shown here have strong
spatial localization. As an example, nearly all edges in A1 and A2 have one end in the Right Occipital
Lobe. This visualization uses the BioimageSuite [37]"
RELATED WORK,0.588495575221239,"4
Related Work
243"
RELATED WORK,0.5907079646017699,"Matrix Factorization Independent Component Analysis (ICA) and its variants are widely used in
244"
RELATED WORK,0.5929203539823009,"fMRI analysis. Spatial Independent Component Analysis (ICA) [36, 48, 40, 7, 6] methods decompose
245"
RELATED WORK,0.5951327433628318,"fMRI data into a set of spatially independent components. They identify patterns of activity across
246"
RELATED WORK,0.5973451327433629,"the brain that are independent of one another. This information is used to identify distinct networks
247"
RELATED WORK,0.5995575221238938,"of brain regions involved in various cognitive processes. In a typical ICA model, the source signals
248"
RELATED WORK,0.6017699115044248,"are assumed to be statistically independent and non-Gaussian, with an unknown linear mixing
249"
RELATED WORK,0.6039823008849557,"process. The model assumes that every observed vector x∈Rm is generated by a linear mixture of n
250"
RELATED WORK,0.6061946902654868,"independent sources x=As, where s∈Rn is an N-dimensional vector whose elements are the random
251"
RELATED WORK,0.6084070796460177,"variables that refer to the independent sources and A ∈Rm×n is an unknown mixing matrix. ICA
252"
RELATED WORK,0.6106194690265486,"aims to estimate an unmixing matrix W∈Rn×m such that the recovered sources: y =Wx=WAs
253"
RELATED WORK,0.6128318584070797,"is a good representation of the true sources s. Applying the typical ICA model to fMRI data, we
254"
RELATED WORK,0.6150442477876106,"have data X = AS, where X ∈RN×V spans N time points and V voxels, and S contains spatially
255"
RELATED WORK,0.6172566371681416,"independent source signals. Group ICA is an extension of spatial ICA that allows the identification
256"
RELATED WORK,0.6194690265486725,"of common patterns of activity across multiple subjects in a study. A popular implementation of Group
257"
RELATED WORK,0.6216814159292036,"ICA is Multivariate Exploratory Linear Decomposition into Independent Components (MELODIC)
258"
RELATED WORK,0.6238938053097345,"[3], which is part of the fMRI Standard Library (FSL). Other approaches for multi-subject analysis
259"
RELATED WORK,0.6261061946902655,"using ICA have been proposed [8, 14, 20, 38, 4]. The model in Calhoun et al. [8] defines Group ICA
260"
RELATED WORK,0.6283185840707964,"as Xi = AiS, where Xi ∈RNi×V is the fMRI observation for subject i with Ni time points and V
261"
RELATED WORK,0.6305309734513275,"voxels. Group ICA captures a group subspace with independent spatial maps and time courses. Then,
262"
RELATED WORK,0.6327433628318584,"these are used to reconstruct subject-specific spatial maps Si and time courses Ai. Group ICA has
263"
RELATED WORK,0.6349557522123894,"been widely used to study functional connectivity differences between groups of healthy and clinical
264"
RELATED WORK,0.6371681415929203,"populations [43, 11], as well as to identify brain networks associated with specific cognitive processes
265"
RELATED WORK,0.6393805309734514,"across a group of individuals [12, 28]. However, both Spatial and Group ICA are limited as they are
266"
RELATED WORK,0.6415929203539823,"unsupervised approaches that find dominant patterns in the entire dataset. This comes at the expense of
267"
RELATED WORK,0.6438053097345132,"ignoring more intricate patterns such as: a) differences across individual subjects; and b) shared patterns
268"
RELATED WORK,0.6460176991150443,"with subsets of subjects (such as disease, cognitive tasks, etc). Since the “canonical task connectomes”
269"
RELATED WORK,0.6482300884955752,"computed in our approach are guided by additional information relating to subjects/ samples (such
270"
RELATED WORK,0.6504424778761062,"as task or disease labels), our approach is more flexible and powerful than traditional approaches.
271"
RELATED WORK,0.6526548672566371,"Other interpretable methods Subspace clustering methods are used in fMRI to partition data into sub-
272"
RELATED WORK,0.6548672566371682,"spaces and assign each data point (e.g., voxel or region of interest) to its corresponding subspace. This
273"
RELATED WORK,0.6570796460176991,"allows for the identification of different brain activity patterns or functional connectivity profiles within
274"
RELATED WORK,0.6592920353982301,"data. Several subspace clustering methods have been applied to fMRI data such as spectral clustering
275"
RELATED WORK,0.661504424778761,"[21, 9, 1], sparse subspace clustering [41, 30], low-rank and sparse decomposition (LRSD) [44, 45, 39].
276"
RELATED WORK,0.6637168141592921,"Subspace clustering reveals distinct brain activity patterns, functional networks, or connectivity profiles
277"
RELATED WORK,0.665929203539823,"within the data. However, there are some key limitations of subspace clustering including its unsu-
278"
RELATED WORK,0.668141592920354,"pervised nature, reliance on unlabeled data, limited generalization to new datasets, and challenges in
279"
RELATED WORK,0.6703539823008849,"interpreting identified subspaces. In contrast, we demonstrate that our method generates task-specific
280"
RELATED WORK,0.672566371681416,"feature representations, is generalizable, and facilitates interpretation by domain experts. Graph Neural
281"
RELATED WORK,0.6747787610619469,"NetworksandotherDeepNeural Networkmodels havealsobeenusedto identifyregions ofinterest(and
282"
RELATED WORK,0.6769911504424779,"functional networks) shared across a cohort of subjects [33, 29, 27]. However, these methods cannot
283"
RELATED WORK,0.6792035398230089,"separate the distinct networks, which limits their applicability to our problem. Our framework explains
284"
RELATED WORK,0.6814159292035398,"observed (composite) brain activity in terms of elementary networks, which have biological basis.
285"
CONCLUSION,0.6836283185840708,"5
Conclusion
286"
CONCLUSION,0.6858407079646017,"We presented a new problem and framework for fMRI analysis that deconvolves an input set of
287"
CONCLUSION,0.6880530973451328,"neuroimages of subjects performing different cognitive tasks into a compact set of task-specific
288"
CONCLUSION,0.6902654867256637,"elementary networks called “canonical task connectomes”. We formulate our problem as one of
289"
CONCLUSION,0.6924778761061947,"supervised matrix factorization and show that the resulting latent factors/ networks can be interpreted
290"
CONCLUSION,0.6946902654867256,"as “building blocks” for the different cognitive tasks. We show experimental results on the Human
291"
CONCLUSION,0.6969026548672567,"Connectome Project dataset, which demonstrate that SupNMF captures the natural task-specific
292"
CONCLUSION,0.6991150442477876,"structure in suitably abstracted neuroimages. We also show that these canonical task connectomes
293"
CONCLUSION,0.7013274336283186,"are useful biomarkers to predict the task being performed. Additionally, we show anatomical and
294"
CONCLUSION,0.7035398230088495,"physiological underpinnings for the networks identified by our framework.
295"
CONCLUSION,0.7057522123893806,"Our framework can be extended to more complex applications, such as: a) understanding shared and
296"
CONCLUSION,0.7079646017699115,"unique functional networks across different pathologies; and b) how task-specific networks can get
297"
CONCLUSION,0.7101769911504425,"dysregulated due to the onset, and progression of diseases.
298"
REFERENCES,0.7123893805309734,"References
299"
REFERENCES,0.7146017699115044,"[1] Esraa Al-sharoa, Mahmood A. Al-khassaweneh, and Selin Aviyente. Temporal block spectral clustering for
300"
REFERENCES,0.7168141592920354,"multi-layer temporal functional connectivity networks. 2018 IEEE Statistical Signal Processing Workshop
301"
REFERENCES,0.7190265486725663,"(SSP), pages 503–507, 2018.
302"
REFERENCES,0.7212389380530974,"[2] Deanna M Barch, Gregory C Burgess, Michael P Harms, Steven E Petersen, Bradley L Schlaggar, Maurizio
303"
REFERENCES,0.7234513274336283,"Corbetta, Matthew F Glasser, Sandra Curtiss, Sachin Dixit, Cindy Feldt, et al. Function in the human
304"
REFERENCES,0.7256637168141593,"connectome: task-fmri and individual differences in behavior. Neuroimage, 80:169–189, 2013.
305"
REFERENCES,0.7278761061946902,"[3] Christian F Beckmann and Stephen M Smith. Probabilistic independent component analysis for functional
306"
REFERENCES,0.7300884955752213,"magnetic resonance imaging. IEEE transactions on medical imaging, 23(2):137–152, 2004.
307"
REFERENCES,0.7323008849557522,"[4] Christian F. Beckmann and Stephen M. Smith. Tensorial extensions of independent component analysis
308"
REFERENCES,0.7345132743362832,"for multisubject fmri analysis. NeuroImage, 25:294–311, 2005.
309"
REFERENCES,0.7367256637168141,"[5] Bharat Biswal, F Zerrin Yetkin, Victor M Haughton, and James S Hyde. Functional connectivity in the motor
310"
REFERENCES,0.7389380530973452,"cortex of resting human brain using echo-planar mri. Magnetic resonance in medicine, 34(4):537–541, 1995.
311"
REFERENCES,0.7411504424778761,"[6] Vince D. Calhoun and T. Adalı. Unmixing fmri with independent component analysis. IEEE Engineering
312"
REFERENCES,0.7433628318584071,"in Medicine and Biology Magazine, 25:79–90, 2006.
313"
REFERENCES,0.745575221238938,"[7] Vince D. Calhoun and T. Adalı. Multisubject independent component analysis of fmri: A decade of intrinsic
314"
REFERENCES,0.7477876106194691,"networks, default mode, and neurodiagnostic discovery. IEEE Reviews in Biomedical Engineering, 5:60–73,
315"
REFERENCES,0.75,"2012.
316"
REFERENCES,0.7522123893805309,"[8] Vince D. Calhoun, T. Adalı, Godfrey D. Pearlson, and James J. Pekar. A method for making group inferences
317"
REFERENCES,0.754424778761062,"from functional mri data using independent component analysis. Human Brain Mapping, 14, 2001.
318"
REFERENCES,0.7566371681415929,"[9] Richard Cameron Craddock, George Andrew James, Paul E. Holtzheimer, Xiaoping Hu, and Helen S.
319"
REFERENCES,0.7588495575221239,"Mayberg. A whole brain fmri atlas generated via spatially constrained spectral clustering. Human Brain
320"
REFERENCES,0.7610619469026548,"Mapping, 33, 2012.
321"
REFERENCES,0.7632743362831859,"[10] Yuhui Du and Yong Fan. Group information guided ica for fmri data analysis. Neuroimage, 69:157–197, 2013.
322"
REFERENCES,0.7654867256637168,"[11] Yuhui Du and Yong Fan. Group information guided ica for fmri data analysis. NeuroImage, 69:157–197,
323"
REFERENCES,0.7676991150442478,"2013.
324"
REFERENCES,0.7699115044247787,"[12] Ahmed Abou Elseoud. Exploring functional brain networks using independent component analysis :
325"
REFERENCES,0.7721238938053098,"functional brain networks connectivity. 2013.
326"
REFERENCES,0.7743362831858407,"[13] Fabrizio Esposito, Tommaso Scarabino, Aapo Hyvarinen, Johan Himberg, Elia Formisano, Silvia Comani,
327"
REFERENCES,0.7765486725663717,"Gioacchino Tedeschi, Rainer Goebel, Erich Seifritz, and Francesco Di Salle. Independent component
328"
REFERENCES,0.7787610619469026,"analysis of fmri group studies by self-organizing clustering. Neuroimage, 25(1):193–205, 2005.
329"
REFERENCES,0.7809734513274337,"[14] Fabrizio Esposito, Tommaso Scarabino, Aapo Hyvärinen, Johan Himberg, Elia Formisano, Silvia Comani,
330"
REFERENCES,0.7831858407079646,"Gioacchino Tedeschi, Rainer Goebel, Erich Seifritz, and Francesco Di Salle. Independent component
331"
REFERENCES,0.7853982300884956,"analysis of fmri group studies by self-organizing clustering. NeuroImage, 25:193–205, 2005.
332"
REFERENCES,0.7876106194690266,"[15] Chris D Frith. The social brain? Philosophical Transactions of the Royal Society B: Biological Sciences,
333"
REFERENCES,0.7898230088495575,"362(1480):671–678, 2007.
334"
REFERENCES,0.7920353982300885,"[16] John DE Gabrieli, Russell A Poldrack, and John E Desmond. The role of left prefrontal cortex in language
335"
REFERENCES,0.7942477876106194,"and memory. Proceedings of the national Academy of Sciences, 95(3):906–913, 1998.
336"
REFERENCES,0.7964601769911505,"[17] Matthew F Glasser, Timothy S Coalson, Emma C Robinson, Carl D Hacker, John Harwell, Essa Yacoub,
337"
REFERENCES,0.7986725663716814,"Kamil Ugurbil, Jesper Andersson, Christian F Beckmann, Mark Jenkinson, et al. A multi-modal parcellation
338"
REFERENCES,0.8008849557522124,"of human cerebral cortex. Nature, 536(7615):171–178, 2016.
339"
REFERENCES,0.8030973451327433,"[18] Matthew F Glasser, Stamatios N Sotiropoulos, J Anthony Wilson, Timothy S Coalson, Bruce Fischl,
340"
REFERENCES,0.8053097345132744,"Jesper L Andersson, Junqian Xu, Saad Jbabdi, Matthew Webster, Jonathan R Polimeni, et al. The minimal
341"
REFERENCES,0.8075221238938053,"preprocessing pipelines for the human connectome project. Neuroimage, 80:105–124, 2013.
342"
REFERENCES,0.8097345132743363,"[19] Logan Grosenick, Stephanie Greer, and Brian Knutson. Interpretable classifiers for fmri improve prediction
343"
REFERENCES,0.8119469026548672,"of purchases. IEEE transactions on neural systems and rehabilitation engineering, 16(6):539–548, 2008.
344"
REFERENCES,0.8141592920353983,"[20] Ying Guo and Giuseppe Pagnoni. A unified framework for group independent component analysis for
345"
REFERENCES,0.8163716814159292,"multi-subject fmri data. NeuroImage, 42:1078–1093, 2008.
346"
REFERENCES,0.8185840707964602,"[21] Sukrit Gupta and Jagath Rajapakse. Iterative consensus spectral clustering improves detection of subject
347"
REFERENCES,0.8207964601769911,"and group level brain functional modules. Scientific Reports, 10, 2020.
348"
REFERENCES,0.8230088495575221,"[22] Jamie Haddock, Lara Kassab, Sixian Li, Alona Kryshchenko, Rachel Grotheer, Elena Sizikova, Chuntian
349"
REFERENCES,0.8252212389380531,"Wang, Thomas Merkh, R. W. M. A. Madushani, Miju Ahn, Deanna Needell, and Kathryn Leonard.
350"
REFERENCES,0.827433628318584,"Semi-supervised NMF models for topic modeling in learning tasks. CoRR, abs/2010.07956, 2020.
351"
REFERENCES,0.8296460176991151,"[23] Keith J Holyoak and Martin M Monti. Relational integration in the human brain: A review and synthesis.
352"
REFERENCES,0.831858407079646,"Journal of cognitive neuroscience, 33(3):341–356, 2021.
353"
REFERENCES,0.834070796460177,"[24] Aapo Hyvärinen and Erkki Oja. Independent component analysis: algorithms and applications. Neural
354"
REFERENCES,0.8362831858407079,"networks, 13(4-5):411–430, 2000.
355"
REFERENCES,0.838495575221239,"[25] Clifford R Jack Jr, Matt A Bernstein, Nick C Fox, Paul Thompson, Gene Alexander, Danielle Harvey,
356"
REFERENCES,0.8407079646017699,"Bret Borowski, Paula J Britson, Jennifer L. Whitwell, Chadwick Ward, et al. The alzheimer’s disease
357"
REFERENCES,0.8429203539823009,"neuroimaging initiative (adni): Mri methods. Journal of Magnetic Resonance Imaging: An Official Journal
358"
REFERENCES,0.8451327433628318,"of the International Society for Magnetic Resonance in Medicine, 27(4):685–691, 2008.
359"
REFERENCES,0.8473451327433629,"[26] Shailee Jain, Vy Vo, Shivangi Mahto, Amanda LeBel, Javier S Turek, and Alexander Huth. Interpretable
360"
REFERENCES,0.8495575221238938,"multi-timescale models for predicting fmri responses to continuous natural speech. Advances in Neural
361"
REFERENCES,0.8517699115044248,"Information Processing Systems, 33:13738–13749, 2020.
362"
REFERENCES,0.8539823008849557,"[27] Zhoufan Jiang, Yanming Wang, ChenWei Shi, Yueyang Wu, Rongjie Hu, Shishuo Chen, Sheng Hu, Xiaoxiao
363"
REFERENCES,0.8561946902654868,"Wang, and Bensheng Qiu. Attention module improves both performance and interpretability of 4d fmri
364"
REFERENCES,0.8584070796460177,"decoding neural network. arXiv preprint arXiv:2110.00920, 2021.
365"
REFERENCES,0.8606194690265486,"[28] JeYoung Jung and Matthew. A. Lambon Ralph. Distinct but cooperating brain networks supporting semantic
366"
REFERENCES,0.8628318584070797,"cognition. Cerebral Cortex (New York, NY), 33:2021 – 2036, 2021.
367"
REFERENCES,0.8650442477876106,"[29] Xuan Kan, Hejie Cui, Joshua Lukemire, Ying Guo, and Carl Yang. Fbnetgen: Task-aware gnn-based fmri
368"
REFERENCES,0.8672566371681416,"analysis via functional brain network generation. In International Conference on Medical Imaging with
369"
REFERENCES,0.8694690265486725,"Deep Learning, pages 618–637. PMLR, 2022.
370"
REFERENCES,0.8716814159292036,"[30] Seung-Jun Kim and Krishna Dontaraju. Joint fmri analysis and subject clustering using sparse dictionary
371"
REFERENCES,0.8738938053097345,"learning. In Optical Engineering + Applications, 2017.
372"
REFERENCES,0.8761061946902655,"[31] Daniel Lee and H. Sebastian Seung.
Algorithms for non-negative matrix factorization.
In T. Leen,
373"
REFERENCES,0.8783185840707964,"T. Dietterich, and V. Tresp, editors, Advances in Neural Information Processing Systems, volume 13. MIT
374"
REFERENCES,0.8805309734513275,"Press, 2000.
375"
REFERENCES,0.8827433628318584,"[32] Gen Li, Dan Yang, Andrew B. Nobel, and Haipeng Shen. Supervised singular value decomposition and
376"
REFERENCES,0.8849557522123894,"its asymptotic properties. Journal of Multivariate Analysis, 146:7–17, 2016. Special Issue on Statistical
377"
REFERENCES,0.8871681415929203,"Models and Methods for High or Infinite Dimensional Spaces.
378"
REFERENCES,0.8893805309734514,"[33] Xiaoxiao Li, Yuan Zhou, Nicha Dvornek, Muhan Zhang, Siyuan Gao, Juntang Zhuang, Dustin Scheinost,
379"
REFERENCES,0.8915929203539823,"Lawrence H Staib, Pamela Ventola, and James S Duncan. Braingnn: Interpretable brain graph neural
380"
REFERENCES,0.8938053097345132,"network for fmri analysis. Medical Image Analysis, 74:102233, 2021.
381"
REFERENCES,0.8960176991150443,"[34] Qiu-Hua Lin, Jingyu Liu, Yong-Rui Zheng, Hualou Liang, and Vince D Calhoun. Semiblind spatial ica
382"
REFERENCES,0.8982300884955752,"of fmri using spatial constraints. Human brain mapping, 31(7):1076–1088, 2010.
383"
REFERENCES,0.9004424778761062,"[35] Thomas J Littlejohns, Jo Holliday, Lorna M Gibson, Steve Garratt, Niels Oesingmann, Fidel Alfaro-
384"
REFERENCES,0.9026548672566371,"Almagro, Jimmy D Bell, Chris Boultwood, Rory Collins, Megan C Conroy, et al. The uk biobank imaging
385"
REFERENCES,0.9048672566371682,"enhancement of 100,000 participants: rationale, data collection, management and future directions. Nature
386"
REFERENCES,0.9070796460176991,"communications, 11(1):2624, 2020.
387"
REFERENCES,0.9092920353982301,"[36] Scott Makeig, Anthony Bell, Tzyy-Ping Jung, and Terrence J Sejnowski. Independent component analysis
388"
REFERENCES,0.911504424778761,"of electroencephalographic data. Advances in neural information processing systems, 8, 1995.
389"
REFERENCES,0.9137168141592921,"[37] Xenophon Papademetris, Marcel P Jackowski, Nallakkandi Rajeevan, Marcello DiStasio, Hirohito Okuda,
390"
REFERENCES,0.915929203539823,"R Todd Constable, and Lawrence H Staib. Bioimage suite: An integrated medical image analysis suite:
391"
REFERENCES,0.918141592920354,"An update. The insight journal, 2006:209, 2006.
392"
REFERENCES,0.9203539823008849,"[38] Vincent J. Schmithorst and Scott K Holland. Comparison of three methods for generating group statistical
393"
REFERENCES,0.922566371681416,"inferences from independent component analysis of functional magnetic resonance imaging data. Journal
394"
REFERENCES,0.9247787610619469,"of Magnetic Resonance Imaging, 19, 2004.
395"
REFERENCES,0.9269911504424779,"[39] Vimal Singh, Ahmed H. Tewfik, and David B. Ress. Under-sampled functional mri using low-rank plus
396"
REFERENCES,0.9292035398230089,"sparse matrix decomposition. 2015 IEEE International Conference on Acoustics, Speech and Signal
397"
REFERENCES,0.9314159292035398,"Processing (ICASSP), pages 897–901, 2015.
398"
REFERENCES,0.9336283185840708,"[40] K. A. Smitha, K. M. Arun, P.G. Rajesh, Bejoy Thomas, Ashalatha Radhakrishnan, Prabhakaran Sankara
399"
REFERENCES,0.9358407079646017,"Sarma, and C Kesavadas. Resting fmri as an alternative for task-based fmri for language lateralization
400"
REFERENCES,0.9380530973451328,"in temporal lobe epilepsy patients: a study using independent component analysis. Neuroradiology,
401"
REFERENCES,0.9402654867256637,"61:803–810, 2019.
402"
REFERENCES,0.9424778761061947,"[41] Xiuchao Sui, Shaohua Li, and Jagath Rajapakse. Locality regularized sparse subspace clustering with
403"
REFERENCES,0.9446902654867256,"application to cortex parcellation on resting fmri. 2016 IEEE 13th International Symposium on Biomedical
404"
REFERENCES,0.9469026548672567,"Imaging (ISBI), pages 1286–1290, 2016.
405"
REFERENCES,0.9491150442477876,"[42] Jason R Taylor, Nitin Williams, Rhodri Cusack, Tibor Auer, Meredith A Shafto, Marie Dixon, Lorraine K
406"
REFERENCES,0.9513274336283186,"Tyler, Richard N Henson, et al. The cambridge centre for ageing and neuroscience (cam-can) data repository:
407"
REFERENCES,0.9535398230088495,"Structural and functional mri, meg, and cognitive data from a cross-sectional adult lifespan sample.
408"
REFERENCES,0.9557522123893806,"neuroimage, 144:262–269, 2017.
409"
REFERENCES,0.9579646017699115,"[43] Xuan Vinh To, Viktor Vegh, and Fatima Ali Nasrallah. Towards data-driven group inferences of resting-state
410"
REFERENCES,0.9601769911504425,"fmri data in rodents: Comparison of group ica, gig-ica, and iva-gl. Journal of Neuroscience Methods, 366,
411"
REFERENCES,0.9623893805309734,"2021.
412"
REFERENCES,0.9646017699115044,"[44] Wei Tu, Fangfang Fu, Linglong Kong, Bei Jiang, Dana Cobzas, and Chao Huang. Low-rank plus sparse
413"
REFERENCES,0.9668141592920354,"decomposition of fmri data with application to alzheimer’s disease. Frontiers in Neuroscience, 16, 2022.
414"
REFERENCES,0.9690265486725663,"[45] Eneko Uruñuela, Stefano Moia, and César Caballero-Gaudes. A low rank and sparse paradigm free mapping
415"
REFERENCES,0.9712389380530974,"algorithm for deconvolution of fmri data. 2021 IEEE 18th International Symposium on Biomedical Imaging
416"
REFERENCES,0.9734513274336283,"(ISBI), pages 1726–1729, 2021.
417"
REFERENCES,0.9756637168141593,"[46] David C Van Essen, Stephen M Smith, Deanna M Barch, Timothy EJ Behrens, Essa Yacoub, Kamil Ugurbil,
418"
REFERENCES,0.9778761061946902,"Wu-Minn HCP Consortium, et al. The wu-minn human connectome project: an overview. Neuroimage,
419"
REFERENCES,0.9800884955752213,"80:62–79, 2013.
420"
REFERENCES,0.9823008849557522,"[47] Zhirong Yang, He Zhang, Zhijian Yuan, and Erkki Oja. Kullback-leibler divergence for nonnegative matrix
421"
REFERENCES,0.9845132743362832,"factorization. In Timo Honkela, Włodzisław Duch, Mark Girolami, and Samuel Kaski, editors, Artificial
422"
REFERENCES,0.9867256637168141,"Neural Networks and Machine Learning – ICANN 2011, pages 250–257, Berlin, Heidelberg, 2011. Springer
423"
REFERENCES,0.9889380530973452,"Berlin Heidelberg.
424"
REFERENCES,0.9911504424778761,"[48] Wei Zhang, Jinglei Lv, Xiang Li, Dajiang Zhu, Xi Jiang, Shu Zhang, Yu Zhao, Lei Guo, Jieping Ye, Dewen
425"
REFERENCES,0.9933628318584071,"Hu, and Tianming Liu. Experimental comparisons of sparse dictionary learning and independent component
426"
REFERENCES,0.995575221238938,"analysis for brain network inference from fmri data. IEEE Transactions on Biomedical Engineering,
427"
REFERENCES,0.9977876106194691,"66:289–299, 2019.
428"
