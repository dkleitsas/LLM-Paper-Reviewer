Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,"ABSTRACT
Recently, deep AUC maximization (DAM) has achieved great success in differ-
ent domains (e.g., medical image classiﬁcation). However, the end-to-end train-
ing for deep AUC maximization still remains a challenging problem. Previous
studies employ an ad-hoc two-stage approach that ﬁrst trains the network by op-
timizing a traditional loss (e.g., cross-entropy loss) and then ﬁnetunes the net-
work by optimizing an AUC loss. This is because that training a deep neural
network from scratch by maximizing an AUC loss usually does not yield a satis-
factory performance. This phenomenon can be attributed to the degraded feature
representations learned by maximizing the AUC loss from scratch. To address
this issue, we propose a novel compositional training framework for end-to-end
DAM, namely compositional DAM. The key idea of compositional training is
to minimize a compositional objective function, where the outer function corre-
sponds to an AUC loss and the inner function represents a gradient descent step
for minimizing a traditional loss, e.g., the cross-entropy (CE) loss. To optimize
the non-standard compositional objective, we propose an efﬁcient and provable
stochastic optimization algorithm. The proposed algorithm enhances the capabil-
ities of both robust feature learning and robust classiﬁer learning by alternatively
taking a gradient descent step for the CE loss and for the AUC loss in a systematic
way. We conduct extensive empirical studies on imbalanced benchmark and med-
ical image datasets, which unanimously verify the effectiveness of the proposed
method. Our results show that the compositional training approach dramatically
improves both the feature representations and the testing AUC score compared
with traditional deep learning approaches, and yields better performance than the
two-stage approaches for DAM as well. The proposed method is implemented in
our open-sourced library LibAUC (www.libauc.org) and code is available at
https://github.com/Optimization-AI/LibAUC."
INTRODUCTION,0.001658374792703151,"1
INTRODUCTION"
INTRODUCTION,0.003316749585406302,"Deep AUC maximization (DAM) represents a new learning paradigm for deep learning, which max-
imizes the area under ROC curve (AUC) on a training dataset for learning a deep neural network.
It has received increasing attention recently due to the advancement in large-scale non-convex opti-
mization algorithms for AUC maximization (Liu et al., 2019a; Yuan et al., 2021; Guo et al., 2020a;b)."
INTRODUCTION,0.004975124378109453,"Recently, DAM has been successfully applied to different domains with imbalanced data (Yuan
et al., 2020; Wang et al., 2021b). For example, Yuan et al. (2020) has employed DAM for a vari-
ety of medical image classiﬁcation tasks, e.g., classiﬁcation of X-ray images, skin lesion images,
mammograms, and microscopic images, and they observed great improvements with about 1%∼5%
AUC increase over traditional deep learning approaches by optimizing a standard loss function, e.g.,
the cross-entropy (CE) loss. These pioneering studies on DAM open a new direction for deep learn-
ing in the presence of imbalanced data but also raise many questions yet to be solved. A particular
question relates to how the network is trained by DAM. Existing studies employ a two-stage ap-
proach for DAM, in which the ﬁrst stage pretrains the network on the training data by optimizing a
traditional loss function (e.g. the CE loss) and the second stage ﬁnetunes the network by optimiz-
ing an AUC loss. It was conjectured in (Yuan et al., 2020) the feature extraction layers learned by
directly optimizing AUC from scratch are not as good as optimizing the standard CE loss, similarly
as optimizing a class-weighted loss for deep learning with imbalanced data (Cao et al., 2019)."
INTRODUCTION,0.006633499170812604,Published as a conference paper at ICLR 2022
INTRODUCTION,0.008291873963515755,"Figure 1: t-SNE visualization of feature representations of an imbalanced training set for the Catvs-
Dog visualized by tSNE learned by different methods (from left to right): optimizing CE loss, an
AUC loss, a linear combination of CE and AUC loss, and a compositional objective by our method."
INTRODUCTION,0.009950248756218905,"Although the ad-hoc two-stage method of DAM has achieved some success, this approach leads
to several undesirable consequences increasing the engineering costs in practice: (i) which layers
should we ﬁnetune in the second stage? Fine-tuning all layers increases the training costs but not
necessarily improves the ﬁnal performance (Jamal et al., 2020; Qi et al., 2020); (ii) when do we stop
the training for the ﬁrst-stage? A long training time for the ﬁrst-stage increases the overall training
costs but not necessarily increases the ﬁnal prediction performance, while a short training time for
the ﬁrst-stage could harm the prediction performance (Kang et al., 2019). Hence, the literature has
suggested different tricks for the two-stage approach, including the decoupling method that simply
optimizes the classiﬁer layer in the second-stage (Kang et al., 2019) and deferred re-weighting that
only dedicates the iterations with the largest step size to the CE loss (Cao et al., 2019), which could
be borrowed to DAM as well. However, an important question remains open regarding DAM:"
INTRODUCTION,0.011608623548922056,How can we conduct end-to-end training for deep AUC maximization?
INTRODUCTION,0.013266998341625208,"To answer this question, we have examined the learned feature representations by optimizing an
AUC loss directly from scratch and conﬁrmed the conjecture in (Yuan et al., 2020) that the learned
feature representations exhibit no advantage over optimizing the CE loss directly. In Figure 1 we
visualize the feature representations on an imbalanced training set for the CatvsDog classiﬁcation
learned by different methods and visualized by t-SNE (van der Maaten & Hinton, 2008).
We
can see that optimizing an AUC loss from scratch (2nd column) does not yield a cleaner feature
representations for the two classes of data than optimizing the CE loss. What makes end-to-end
deep learning successful is its superb feature learning capability, i.e., the lower layers capture the
low-level features and higher layers capture the high-level features. In terms of feature learning,
different examples roughly have equal weights regardless which classes they belong to. From this
perspective, we could understand why optimizing AUC loss alone bears worse feature learning
capability. The AUC loss assigns different weights to different examples from different classes for
more robust classiﬁer learning. In particular, the data in the positive class has a higher weight than
data in the negative class. These non-equal weights are important for learning a robust classiﬁer
given that feature representations have been learned well but are not readily helpful for learning
feature representations in an end-to-end fashion. Can we achieve both effects in a uniﬁed and
end-to-end learning framework, i.e., optimizing the CE loss with equal weights for robust feature
learning and optimizing an AUC loss with uneven weights for robust classiﬁer learning? A naive
approach is to simply optimize a linear combination of the CE loss and an AUC loss. However, this
approach has a trade-off, meaning that AUC is not necessarily maximized due to the presence of
the CE loss in the objective and the learned feature representations could be degraded by the AUC
loss (Figure 1, 3rd column)."
INTRODUCTION,0.014925373134328358,"In this paper, we propose a better and novel end-to-end training method that not only achieves both
beneﬁts of minimizing the CE loss for robust feature learning and minimizing an AUC loss for
robust classiﬁer learning, but also achieves the effect of “1+1>2"", i.e., achieves better performance
than the naive linear combination approach. The novel synthesis lies in how we composite the two
training steps corresponding to the CE loss and the AUC loss. The central idea is to minimize a
two-level compositional objective, where the outer function is an AUC loss, and the inner function
is a gradient descent step towards minimizing the CE loss, which represents a quick adaptation to the
solution to minimizing the CE loss. We propose a novel efﬁcient stochastic algorithm with provable
convergence for minimizing the compositional objective, which performs alternating gradient-based
updates that are ﬁrst based on the gradient of CE loss and then based on the gradient of an AUC loss
at the point obtained in the ﬁrst step. We summarize our contributions below.
• We propose a novel training framework for end-to-end deep AUC maximization, namely compo-
sitional DAM. The novel compositional objective enables not only the robust feature learning of"
INTRODUCTION,0.01658374792703151,Published as a conference paper at ICLR 2022
INTRODUCTION,0.01824212271973466,"lower layers from minimizing the standard loss function but also the robust learning of a classiﬁer
from minimizing an AUC loss.
• Theoretically, we propose an efﬁcient stochastic optimization algorithm for solving compositional
DAM, and establish the same convergence rate as standard SGD for optimizing a standard aver-
aged loss. Empirically, we conduct extensive studies on benchmark and medical image datasets,
and observe that the proposed method not only improves the baseline methods including the
naive linear combination approach but also improves ad-hoc two-stage approaches for DAM. The
learned feature representations of compositional DAM (e.g., Figure 1 right) are much better than
those learned by minimizing the CE loss or an AUC loss alone and their combination."
RELATED WORK,0.01990049751243781,"2
RELATED WORK"
RELATED WORK,0.02155887230514096,"Deep AUC Maximization. AUC maximization has a history of two decades. Most of the existing
studies revolve around the design of efﬁcient optimization algorithms. Earlier papers have focused
on full batch methods (Herbrich et al., 1999; Yan et al., 2003; Ferri et al., 2002; Freund et al., 2003;
Joachims, 2005; Herschtal & Raskutti, 2004; Rakotomamonjy, 2004; Zhang et al., 2012) and online
optimization methods (Zhao et al., 2011; Kar et al., 2014; 2013; Gao et al., 2013). Recently, stochas-
tic optimization for AUC maximization has become the dominating approach (Ying et al., 2016; Liu
et al., 2018; Natole et al., 2018; 2019). Ying et al. (2016) propose a milestone work for stochastic
optimization of AUC. They consider optimizing the pairwise square loss and propose an equivalent
min-max formulation that transforms the original non-decomposable objective into a decomposable
one, which enables the design of efﬁcient stochastic methods based on mini-batch of data without
explicitly constructing the pairs. The min-max formulation also serves as the basis for recent works
on DAM (Liu et al., 2019a; Yuan et al., 2021; Guo et al., 2020a;b). (Liu et al., 2019a) is the ﬁrst work
that explicitly considers DAM and develops the ﬁrst practical and provable stochastic algorithms for
DAM based on the min-max formulation of the pairwise square loss function. However, this work
only focuses on optimization and experiments are done on simple benchmark datasets. Later, Yuan
et al. (2020) propose a new robust loss in the min-max form for DAM and evaluates the performance
of DAM on various medical image classiﬁcation tasks, which demonstrates great success of DAM.
However, none of these works have addressed the problem of end-to-end training for DAM."
RELATED WORK,0.02321724709784411,"Deep Learning with Imbalanced data. Deep learning in the presence of imbalanced data has
recently attracted tremendous attention (Cui et al., 2019; Johnson & Khoshgoftaar, 2019; Masko &
Hensman, 2015; Lee et al., 2016; Khan et al., 2017; Dablain et al., 2021; Ren et al., 2018; Jamal
et al., 2020; Qi et al., 2020; Lin et al., 2017; Cao et al., 2019; Kang et al., 2019; Liu et al., 2019b;
Zhu & Yang, 2020; Zhou et al., 2020; Xiang et al., 2020; Wang et al., 2021a; 2020; Menon et al.,
2021). Among these studies that are closely related to our work include (Lin et al., 2017; Cui
et al., 2019; Cao et al., 2019; Qi et al., 2020; Kang et al., 2019; Jamal et al., 2020), which focus on
optimizing different objectives from the standard CE loss, including class-weighted loss, focal loss,
individually weighted loss functions, etc. Nevertheless, these works are not directly comparable to
our method for maximizing AUC."
RELATED WORK,0.024875621890547265,"Two-stage Approaches. However, directly optimizing a weighted loss for training a deep neural
network from scratch does not work well (Cao et al., 2019; Kang et al., 2019; Jamal et al., 2020; Qi
et al., 2020; Yuan et al., 2020). This phenomenon was ﬁrst observed in (Cao et al., 2019), which
is attributed to the degraded feature representations. To tackle this issue, Cao et al. (2019) propose
a deferred re-weighting/re-sampling trick. It minimizes the standard average loss for the ﬁrst stage
and switches to minimizing the class-weighted loss or re-sampling method in the second stage. In
their paper, the ﬁrst stage is deﬁned as the training period from the beginning to the iteration that
the step size was reduced for the ﬁrst time in SGD or momentum methods. Kang et al. (2019)
investigate a decoupling approach, where the ﬁrst stage learns the feature representations (i.e., a
feature extraction network) by optimizing a standard loss with a large number of iterations, and the
second stage learns a robust classiﬁer (i.e. the classiﬁer layer). The authors show that the decoupling
approach can achieve better performance than the deferred re-weighting trick in (Cao et al., 2019).
However, the decoupling approaches do not necessarily yield the best performance. In particular,
some studies have found that ﬁne-tuning some higher layers besides the classiﬁer layer in the second
stage is beneﬁcial (Jamal et al., 2020; Qi et al., 2020). Recently, Yang & Xu (2020) propose to use
self-supervised learning for learning the feature representations for the ﬁrst stage and to switch to
re-weighting method in the second stage. Different from these studies, our work is to design an
elegant end-to-end training framework for deep learning with an AUC loss."
RELATED WORK,0.026533996683250415,Published as a conference paper at ICLR 2022
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.028192371475953566,"3
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.029850746268656716,"Notations. We use (x, y) to denote an example, where x ∈Rd0 denotes the input and y ∈Y denotes
its corresponding label. Let ∥· ∥denote the Euclidean norm of a vector, and let w ∈Rd denote
the weight parameters of a deep neural network. A function F(w) is called L-smooth if its gradient
is L-Lipschitz continuous, i.e., ∥∇F(w) −∇F(w′)∥≤L∥w −w′∥. Let f(w; x) denote the
prediction scores of a deep neural network parameterized by w on an input x, where f(w; x) ∈R
for binary classiﬁcation with Y = {1, −1}. Denote by D = {(x1, y1), . . . , (xn, yn)} a set of n
training examples. Let ℓ(w; x, y) denote a loss function on an individual data, e.g., cross-entropy
loss. We let L(w; S) denote an aggregate loss function deﬁned on a set of samples S ⊆D. When
S = D, we simply use the notation L(w) = L(w; D). Let ΠΩ[θ] denotes an Euclidean projection
on the set Ω. Denote by n+(n−) the number of positive (negative) examples."
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.03150912106135987,"A standard approach of deep learning is to minimize an averaged loss on training examples, i.e.,"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.03316749585406302,"min
w∈Rd LAVG(w) = 1 n n
X"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.03482587064676617,"i=1
ℓ(w; xi, yi).
(1)"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.03648424543946932,"AUC losses. AUC (area under the ROC curve) is a commonly used measure for evaluating classi-
ﬁers for binary classiﬁcation with imbalanced data. Recently, there emerge voluminous studies on
optimizing AUC score for learning a predictive model (e.g., a deep neural network). The idea is to
optimize a surrogate loss for the AUC score. A special surrogate loss is the AUC square loss (Gao
& Zhou, 2015), which is deﬁned as:"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.03814262023217247,"min
w
1
n+n− X yi=1 X"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.03980099502487562,"yj=−1
(c −(f(w; xi) −f(w; xj)))2,"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.04145936981757877,"where c is a margin parameter (e.g., 1). Since directly optimizing the above pairwise loss is com-
putationally expensive, existing works transform the above problem into an equivalent min-max
optimization (Liu et al., 2019a), which is decomposable over individual examples:"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.04311774461028192,"min
w,a,b max
θ∈ΩΦ (w, a, b, θ) := 1 n n
X"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.04477611940298507,"i=1
φ (w, a, b, θ; xi, yi) ,
where
(2)"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.04643449419568822,"φ(w, a, b, θ; xi, yi) = (1 −p) (f(w; xi) −a)2 I[yi=1] + p(f(w; xi) −b)2I[yi=−1]
(3)"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.04809286898839138,"−p(1 −p)θ2 + 2θ
 
p(1 −p)c + pf(w; xi)I[yi=−1] −(1 −p)f(w; xi)I[yi=1]

,
Ω= R and p = n+/n. From the above objective function φ, we can see that each example xi also
has a class-level weight for their contributed loss, i.e., the data from the positive class is weighted
by 1 −p and the data from the negative class is weighted by p."
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.04975124378109453,"It was recently shown that the AUC square loss is sensitive to noisy data and also has adverse
effect when trained with easy data. Hence, Yuan et al. (2020) proposed the min-max AUC margin
(AUCM) loss, whose optimization problem is (2) with Ω= {0 ≤θ ≤u} for some u. Let us deﬁne
LAUC(w) = mina,b maxθ∈ΩΦ (w, a, b, θ) as the AUC loss function."
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.05140961857379768,"3.1
COMPOSITIONAL DAM: A COMPOSITIONAL TRAINING METHOD FOR DAM"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.05306799336650083,"In this section, we present the proposed compositional training for DAM. Our proposed objective
for end-to-end deep learning is given by
min
w∈Rd LAUC(w −α∇LAVG(w)),
(4)"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.05472636815920398,"where α is hyper-parameter. Different from LAUC(w), the above objective is a compositional func-
tion, where the inner component w −α∇LAVG(w) is another function of w. We refer to the above
objective as the compositional objective and a method for minimizing the above compositional ob-
jective as compositional training."
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.05638474295190713,"To understand the compositional objective (4), we take the second-order Taylor expansion of the
compositional objective, which include three terms:
LAUC(w −α∇LAVG(w)) ≈LAUC(w) −α∇LAUC(w)⊤∇LAVG(w) + Cα2/2∥∇LAVG(w)∥2, (5)
where C represents the Lipchitz continuity constant of ∇LAUC(·). In order to understand how the
three terms play their roles and evolve in the optimization process by our proposed algorithm pre-
sented in next subsection (Algorithm 1), we conduct some empirical studies on several benchmark"
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.05804311774461028,Published as a conference paper at ICLR 2022
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.05970149253731343,"Figure 2: Evolution of different terms in (5) computed in the process of our optimization algorithm
(Algorithm 1) on the CatvsDog data. LAVG is the averaged CE loss. Please refer to Appendix A.6
for more details of the calculations."
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.06135986733001658,"datasets reported in Appendix A.6. Here, we explain the result of the CatvsDog classiﬁcation shown
in Figure 2. Initially, the ﬁrst term LAUC(w) dominates the objective and the algorithm will fo-
cus on pushing this term to be smaller (1st column), once it reaches the same level of the third
term the algorithm will shift its focus to push ∥∇LAVG(w)∥smaller (2nd column) while keeping
∇LAUC(w)⊤∇LAVG(w) to be positive (3rd column). This process will continue by alternating be-
tween the efforts of pushing LAUC(w) smaller and of pushing ∥∇LAVG(w)∥2 to be smaller while
keeping ∇LAUC(w)⊤∇LAVG(w) to be non-negative. We also notice that the ﬁnal AUC loss is close
to zero. The same phenomena are also observed on other datasets."
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.06301824212271974,"To further understand the compositional training intuitively, let us take a thought experiment by
using a gradient descent method to optimize the compositional objective. First, we evaluate the
inner function by u = w −α∇LAVG(w). We can see that u is computed by a gradient descent step
for minimizing the averaged loss LAVG(w), which facilitates the learning of lower layers for feature
extraction due to equal weights of all examples. Then, we take a gradient descent step to update w
for minimizing the outer function LAUC(·) by using the gradient ∇LAUC(u) instead of ∇LAUC(w).
Because u is better than w in terms of feature extraction layers, taking a gradient descent step using
∇LAUC(u) would be better than using ∇LAUC(w). In addition, taking a gradient descent step for
the outer function LAUC(·) will make the classiﬁer more robust to the minority class due to the
higher weights of examples from the minority class. Overall, we have two alternating conceptual
steps, i.e., the inner gradient descent step u = w −α∇LAVG(w) acts as a feature puriﬁcation
step, and the outer gradient descent step w −η(I −α∇2LAVG(w))∇LAUC(u) acts as a classiﬁer
robustiﬁcation step, where η is a step size."
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.06467661691542288,"VS. linear combination approach.
It is notable that minimizing the compositional objective
LAUC(w −α∇LAVG(w)) is different from minimizing a linear combination of an AUC loss and
the averaged loss, i.e., LAUC(w)+cLAVG(w), where c > 0 is a combination weight. First, minimiz-
ing the latter objective will push ∇LAUC(w) + c∇LAVG(w) = 0. This makes ∇LAUC(w) to have
an opposite direction from ∇LAVG(w) at the optimal solution, which is different from minimizing
the compositional objective in light of the three terms in (5). Second, if we take a gradient descent
method for minimizing this objective, the update of w is given by w−η(∇LAUC(w)+c∇LAVG(w)).
This update is fundamentally different from the two alternating steps of compositional training that
use gradients of the AUC loss and the average loss at different points. Third, minimizing the linear
combination has a trade-off, meaning that the AUC score is not necessarily maximized due to the
presence of the CE loss in the objective and the learned feature representations are degraded due to
the presence of AUC loss."
COMPOSITIONAL TRAINING FOR DEEP AUC MAXIMIZATION,0.06633499170812604,"More discussions. Finally, we note that the inner gradient descent step w −α∇LAVG(w) is sim-
ilar to the idea used in model-agnostic meta learning (MAML) (Finn et al., 2017). However, our
compositional objective works fundamentally different from that for MAML. In MAML, the outer
loss function and the loss function for the inner gradient descent step is the same. In contrast, the
two loss functions in our objective are different. But similar to MAML approaches, we can also run
multiple gradient descent steps for the inner function, i.e, the inner function w −α∇LAVG(w) can
be replaced by multiple gradient descent steps. In our experiments, we also found this trick to be
helpful for improving the performance."
STOCHASTIC OPTIMIZATION ALGORITHMS,0.06799336650082918,"3.2
STOCHASTIC OPTIMIZATION ALGORITHMS
In this subsection, we develop efﬁcient stochastic optimization algorithms for optimizing the compo-
sitional objective (4) for DAM. First, we argue the necessity for such development. (i) the problem is
a min-max form and the objective is a compositional function, which makes computing an unbiased
stochastic gradient of the objective LAUC(w −α∇LAVG(w)) impossible. Existing algorithms of"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.06965174129353234,Published as a conference paper at ICLR 2022
STOCHASTIC OPTIMIZATION ALGORITHMS,0.07131011608623548,Algorithm 1 Primal-Dual Stochastic Compositional Adaptive (PDSCA) method for solving (6)
STOCHASTIC OPTIMIZATION ALGORITHMS,0.07296849087893864,"1: Require Parameters: β0, β1, α, G0, η1, η2
2: Initialization: ¯w0 = (w0; a0; b0) ∈Rd+2, θ0, u0 ∈Rd+2"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.07462686567164178,"3: for t = 0, 1, ..., T do
4:
Sample two sets of examples denoted by S1, S2
5:
ut+1 = (1 −β0)ut + β0h( ¯wt; S1)
6:
Ot = ∇¯wh( ¯wt; S1)⊤[∇ug1(ut+1; S2) + θt∇ug2(ut+1; S2)]
7:
zt+1 = (1 −β1)zt + β1Ot
8:
z2,t+1 = ht({Oj, j = 0, . . . , t)}
⋄ht can be implemented by that in Appendix B
9:
¯wt+1 = ¯wt −η1
zt+1
√z2,t+1+G0
⋄with the simplest form ht = 1"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.07628524046434494,"10:
θt+1 = ΠΩ[θt + η2(g2(ut+1; S1 ∪S2) −∇g3(θt))]
11: end for"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.0779436152570481,"non-convex min-max optimization for DAM that focus on minimizing LAUC(w) (Liu et al., 2019a;
Yuan et al., 2021; Guo et al., 2020a;b) are not applicable due to the presence of inner function
w −α∇LAVG(w). (ii) Our objective is also different from that of MAML due to that LAUC(·) is a
min-max form, which renders existing algorithms for MAML (Finn et al., 2017; Fallah et al., 2020)
not applicable. Hence, below we propose an efﬁcient stochastic algorithm for solving the compo-
sitional training for DAM whose objective is of the min-max compositional form, and establish its
convergence rate similar to that of standard SGD for minimizing the standard averaged loss."
STOCHASTIC OPTIMIZATION ALGORITHMS,0.07960199004975124,"In particular, for the considered AUC loss, the compositional objective becomes:"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.0812603648424544,"min
w,a,b max
θ∈ΩΦ (w −α∇LAVG(w), a, b, θ) = 1 n n
X"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.08291873963515754,"i=1
φ (w −α∇LAVG(w), a, b, θ; xi, yi) .
(6)"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.0845771144278607,"We denote by a tuple ¯w = (w; a; b). For simplicity of presentation, we write φ(w, a, b, θ, xi, yi) as
φ( ¯w, θ; xi, yi) = g1( ¯w; xi, yi) + θg2( ¯w; xi, yi) −g3(θ),
where
g1( ¯w; xi, yi) =(1 −p) (f(w; xi) −a)2 I[yi=1] + p(f(w; xi) −b)2I[yi=−1]
+ 2pf(w; xi)I[yi=1] −2(1 −p)f(w; xi)I[yi=−1],
(7)"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.08623548922056384,"and g2( ¯w; xi, yi) = 2
 
pf(w; xi)I[yi=−1] −(1 −p)f(w; xi)I[yi=1]

and g3(θ) = p(1 −p)θ2."
STOCHASTIC OPTIMIZATION ALGORITHMS,0.087893864013267,"Denote by g1( ¯w; S)
=
1
|S|
P"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.08955223880597014,"i∈S g1( ¯w; xi, yi), g2( ¯w; S)
=
1
|S|
P"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.0912106135986733,"i∈S g2( ¯w; xi, yi).
Let
h( ¯w) = (w −α∇LAVG(w); a; b), ∇¯wh( ¯w) = (I −α∇2
wLAVG(w); 1; 1), and h( ¯w; S) =
(w −α∇LAVG(w; S); a; b)."
STOCHASTIC OPTIMIZATION ALGORITHMS,0.09286898839137644,"We propose a primal-dual stochastic algorithm shown in Algorithm 1, which is referred to as
PDSCA. We provide some explanations of our algorithmic design. First, the step 5 of updating
ut+1 corresponds to feature puriﬁcation step. We use a moving average technique to update ut+1
that takes all historical updates into account, which is inspired by existing stochastic algorithms for
optimizing compositional functions (Wang et al., 2017). This is important for us to prove the con-
vergence rate of O(1/
√"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.0945273631840796,"T) without using a large batch size at each iteration. If we simply using
ut+1 = h( ¯wt; S1) (i.e., setting β0 = 1) to estimate h( ¯wt), there will be a large error in estimating
the gradient ∇ug1(ut+1; S2) and ∇ug2(ut+1; S2) in step 6. Second, the step 6 is to estimate the
gradient of the outer function. We use two independent mini-batches S1, S2 to ensure that Ot is an
unbiased estimator of ∇h( ¯wt)⊤∇¯wφ(ut+1, θ). Using two independent mini-batches is also help-
ful for improving generalization as demonstrated in experiments. Third, the steps 7 - 9 are similar
to the momentum and adaptive methods for updating the model parameter. The step 8 is used for
computing the adaptive step size 1/√z2,t+1 + ϵ0, which is similar to adaptive methods used for
deep learning, such as Adam, AMSGrad, AdaBound (Kingma & Ba, 2015; Reddi et al., 2018; Luo
et al., 2019). We use a general function ht in the algorithm, which can be implemented by different
methods corresponding to different adaptive step size choices. We present different ht in the Ap-
pendix B. The simplest one ht = 1 corresponds to that we do not use adaptive step size and only
use the momentum update. Fourth, the step 10 is for updating the dual variable θ using a stochastic
gradient ascent method. Finally, we point out that PDSCA is similar to some existing non-convex
strongly-concave min-max optimization algorithms (Guo et al., 2021) but with additional care on
the inner gradient descent step w −α∇LAVG(w). We present an informal convergence of PDSCA
below."
STOCHASTIC OPTIMIZATION ALGORITHMS,0.09618573797678276,Published as a conference paper at ICLR 2022
STOCHASTIC OPTIMIZATION ALGORITHMS,0.0978441127694859,"Theorem 1. (Informal) Under appropriate conditions on the functions LAVG, g1, g2 and a boundness
condition on θt, wt, ∇ℓ(wt; x, y), ∇2ℓ(wt; x, y), with β0, β1 = O(1/
√"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.09950248756218906,"T), η1, η2 = O(1/
√ T)"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.1011608623548922,"and a small constant τ, Algorithm 1 ensures that E
h
1
T +1
PT
t=0 ∥∇F( ¯wt)∥2i
≤O( 1
√"
STOCHASTIC OPTIMIZATION ALGORITHMS,0.10281923714759536,T ). where
STOCHASTIC OPTIMIZATION ALGORITHMS,0.1044776119402985,"F( ¯w) = maxθ∈ΩΦ (w −α∇LAVG(w), a, b, θ)."
STOCHASTIC OPTIMIZATION ALGORITHMS,0.10613598673300166,"Remark: We will present the detailed conditions in the supplement when proving the above the-
orem due to limit of space. The above theorem indicates that we can optimize the compositional
objective (6) with the same convergence rate as optimizing the averaged loss (1) for deep learning."
STOCHASTIC OPTIMIZATION ALGORITHMS,0.1077943615257048,"Practical Implementations. It is notable that ∇h( ¯w, S1) = (I −α∇2L(w; S1); 1, 1) (step 6)
involves the Hessian matrix ∇2L(w; S1). Indeed, we only need to compute the Hessian vector
product involving in step 6. Similar computation occurs in the meta learning algorithms (Finn et al.,
2017; Fallah et al., 2020). Inspired by practical implementations of MAML (Finn et al., 2017) that
simply ignore the second-order term, we use the same trick in our experiments. An additional useful
trick inspired by MAML is that we can take k ≥1 gradient descent steps for the inner function,
correspondingly we maintain and update several u variables similar to step 5, i.e., using h( ¯wt, S1)
for updating the ﬁrst u(1)
t+1, and using h(u(1)
t+1; S1) for updating second u(2)
t+1, and so on so forth. In
our experiments, we found that tuning k ∈{1, 2, 3} is useful."
STOCHASTIC OPTIMIZATION ALGORITHMS,0.10945273631840796,"Finally, it is notable that although we focus on optimizing AUC loss for binary classiﬁcation in this
work, our compositional training method can be also extended to optimize other weighted losses in
an end-to-end fashion, and we include some discussion and results in the Appendix D."
EXPERIMENTS,0.1111111111111111,"4
EXPERIMENTS"
EXPERIMENTS,0.11276948590381426,"In this section, we present some experimental results. We choose ﬁve baselines: optimizing the
AUC loss from scratch (AUCsc), optimizing the CE loss (CE), optimizing a linear combination of
the AUC loss and the CE loss with a tuned weight (AUC-CE), the two-stage method with deferred
re-weighting trick (Cao et al., 2019) (TS-DRW), the two-stage method by decoupling the learning of
feature network by minimizing CE loss and the learning of a classiﬁer by minimizing the AUC loss
(TS-DEC) (Kang et al., 2019). We denote our method by CT (AUC). For AUC loss, we use AUCM
loss with the margin parameter ﬁxed to be 1 (Yuan et al., 2020). We conduct experiments on four
benchmark datasetes and four medical image datasets. The statistics of these datasets are included
in the Appendix A.1. More training conﬁgurations can be found in Appendix A.2."
EXPERIMENTS,0.11442786069651742,"Benchmark datasets. We choose four benchmark image classiﬁcation datasets, namely CatvsDog,
CIFAR10 (C10), CIFAR100 (C100), and STL10 (S10). For AUC maximization, we construct im-
balanced binary versions of these datasets by varying the imbalanced ratios (the ratio of positive
examples to the total number of training examples) similar to (Yuan et al., 2020). We use ResNet20
as the prediction network. The weight decay is set to 1e-4 for all experiments. For algorithms to
maximize AUC, we use a batch size = 128 and train a total of 100 epochs, and we use step size 0.1
and decrease it by 10 times at 50% and 75% of total training time. We tune the beta parameters of
our method in a range [0.1, 0.99] with a grid search and ﬁnd that good values are around 0.9. For
linear combination methods, we tune the weight c of two losses in {0.25, 0.5, 0.75}. We tune the
number of inner gradient steps for CT in k ∈{1, 2, 3} with α = 0.1. For all benchmark data, we
run three times for different random seeds and compute the mean and standard deviations."
EXPERIMENTS,0.11608623548922056,"Medical image datasets. We also conduct experiments on naturally imbalanced medical datasets.
We choose four medical image datasets, namely Melanoma data, CheXpert, DDSM+, and PatchCam
data. The Melanoma dataset is from the Kaggle 2020 competition (Rotemberg et al., 2021), which
contains 33,126 labeled images in training set, including 584 positive samples and 32,542 negative
samples. We manually construct training, validation and testing datasets following 70/10/20 split.
For this dataset, we use the images with 256x256 resolution in the experiments. CheXpert is a large-
scale chest X-ray dataset (Irvin et al., 2019), which has 224,316 images with 224 x 224 resolution.
The dataset contains 5 binary classiﬁcation tasks corresponding to 5 diseases, i.e., Cardiomegaly
(C0), Edema , Consolidation, Atelectasis, Pleural Effusion. We evaluate the performance on the
ofﬁcial validation set consisting of 200 patient studies and report the averaged AUC scores of all
5 diseases. The DDSM+ data is a combination of two datasets namely DDSM and CBIS-DDSM
(Lee et al., 2017; Bowyer et al., 1996; Heath et al., 1998), which consists of 55,890 mammographic
training images (224×224) with an imratio of 13% and 15,364 images for testing with an imra-
tio of 13%. The PatchCamelyon dataset consists of 294,912 color images (96×96) extracted from"
EXPERIMENTS,0.11774461028192372,Published as a conference paper at ICLR 2022
EXPERIMENTS,0.11940298507462686,"Table 1: Testing performance on benchmark datasets and medical datasets. The percentage number
is the second row denotes the imbalanced ratio (cf the text)."
EXPERIMENTS,0.12106135986733002,"Datasets
For AUC Maximization
imratio
1%
10%
30%"
EXPERIMENTS,0.12271973466003316,CATvsDOG
EXPERIMENTS,0.12437810945273632,"CE
0.742±0.003
0.917±0.006
0.957±0.001
AUCsc
0.753±0.003
0.915±0.002
0.964±0.003
AUC-CE
0.770±0.007
0.939±0.004
0.974±0.003
TS-DRW
0.750±0.009
0.914±0.003
0.961±0.001
TS-DEC
0.754±0.010
0.918±0.003
0.963±0.001
CT (AUC)
0.789±0.008
0.946±0.002
0.977±0.001"
EXPERIMENTS,0.12603648424543948,CIFAR10
EXPERIMENTS,0.12769485903814262,"CE
0.689±0.003
0.901±0.002
0.944±0.001
AUCsc
0.728±0.002
0.905±0.002
0.946±0.001
AUC-CE
0.735±0.003
0.928±0.001
0.957±0.001
TS-DRW
0.708±0.002
0.896±0.002
0.946±0.003
TS-DEC
0.707±0.002
0.897±0.002
0.944±0.001
CT (AUC)
0.739±0.004
0.935±0.001
0.964±0.001 STL10"
EXPERIMENTS,0.12935323383084577,"CE
0.655±0.005
0.819±0.004
0.885±0.004
AUCsc
0.665±0.005
0.805±0.017
0.887±0.007
AUC-CE
0.668±0.007
0.836±0.006
0.905±0.001
TS-DRW
0.655±0.004
0.803±0.013
0.887±0.002
TS-DEC
0.661±0.002
0.816±0.007
0.882±0.007
CT (AUC)
0.673±0.010
0.837±0.006
0.906±0.001"
EXPERIMENTS,0.1310116086235489,CIFAR100
EXPERIMENTS,0.13266998341625208,"CE
0.586±0.001
0.691±0.005
0.758±0.004
AUCsc
0.606±0.004
0.705±0.003
0.779±0.003
AUC-CE
0.605±0.004
0.716±0.003
0.795±0.001
TS-DRW
0.588±0.003
0.691±0.004
0.762±0.001
TS-DEC
0.587±0.001
0.692±0.003
0.762±0.002
CT (AUC)
0.609±0.002
0.725±0.001
0.809±0.002"
EXPERIMENTS,0.13432835820895522,"Datasets
For AUC Maximization
Method
AUC"
EXPERIMENTS,0.13598673300165837,Melanoma
EXPERIMENTS,0.13764510779436154,"CE
0.879±0.008
AUCsc
0.868±0.006
AUC-CE
0.880±0.005
TS-DRW
0.878±0.007
TS-DEC
0.877±0.005
CT (AUC)
0.900±0.002"
EXPERIMENTS,0.13930348258706468,CheXpert
EXPERIMENTS,0.14096185737976782,"CE
0.892±0.001
AUCsc
0.899±0.002
AUC-CE
0.902±0.002
TS-DRW
0.900±0.002
TS-DEC
0.897±0.001
CT (AUC)
0.909±0.003 DDSM+"
EXPERIMENTS,0.14262023217247097,"CE
0.949±0.001
AUCsc
0.929±0.001
AUC-CE
0.957±0.001
TS-DRW
0.942±0.003
TS-DEC
0.941±0.001
CT (AUC)
0.981±0.001"
EXPERIMENTS,0.14427860696517414,PatchCam
EXPERIMENTS,0.14593698175787728,"CE
0.869±0.007
AUCsc
0.868±0.006
AUC-CE
0.868±0.005
TS-DRW
0.867±0.006
TS-DEC
0.869±0.009
CT (AUC)
0.891±0.003"
EXPERIMENTS,0.14759535655058043,"histopathologic scans of lymph node section for training and 32,768 images for testing with bal-
anced class ratio (Veeling et al., 2018; Bejnordi et al., 2017). For PathCamelyon, we manually
construct an imbalanced training dataset with an imratio of 1% and keep the testing set balanced.
For Melanoma data, we adopt a EfﬁcientNetV2-S (Tan & Le, 2021) as the network structure, and for
CheXpert, DDSM+, PatchCam, we use DenseNet121 (Huang et al., 2017). We tune the number of
inner gradient steps for CT in k ∈{1, 2, 3} and also tune α in {0.1, 0.05, 0.01} for the inner steps."
EXPERIMENTS,0.14925373134328357,"Results. The testing AUC results are reported in Table 1. We can see that the proposed composition
training method outperforms all baselines on all datasets for maximizing AUC. In addition, we have
the following observations: (i) optimizing an AUC loss from scratch does not necessarily yield a
better performance than minimizing the standard CE loss; (ii) the CT (AUC) method dramatically
improves the performance of optimizing the AUC loss from scratch, with about 2%∼5% improve-
ment on difﬁcult medical classiﬁcation tasks; (iii) the CT (AUC) method is generally better than the
linear combination approach (AUC-CE), especially on the more difﬁcult medical image datasets. It
is notable that the reported results on some medical datasets are not comparable with that in (Yuan
et al., 2020) because (i) we report the performance on ofﬁcial CheXpert validation data instead of
the ofﬁcial testing data; (ii) we use a smaller resolution on Melanoma data; (ii) we do not tune the
margin parameter in the AUCM loss. We also plot the learned feature representations of training
data of different datasets visualized by t-SNE in Figure 3. We can see that the proposed CT (AUC)
method obtains better feature representations than the baseline approaches of optimizing CE or AUC
alone and the naive linear combination approach."
ABLATION STUDY,0.15091210613598674,"4.1
ABLATION STUDY
We conduct some ablation study including (i) the comparison of convergence curves and the running
time analysis of different methods; (ii) the veriﬁcation of our algorithmic design."
ABLATION STUDY,0.15257048092868988,"Convergence Curve.
Below, we compare the convergence speed of our CT (AUC) approach
with other end-to-end learning baselines, i.e., CE, AUC, AUC-CE, with results on four benchmark
datasets plotted in Figure 4. The results indicate that our algorithm enjoys even faster convergence in
terms of number of epochs. The convergence curves of testing AUC are included in Appendix A.4."
ABLATION STUDY,0.15422885572139303,"Runtime analysis. We notice our method has larger running time per-iteration than minimizing the
CE and the AUC loss alone because of several backpropagations, but with a reward of faster con-
vergence in epochs and better testing performance. For fair comparison, we have run the baselines
with the same amount of time as our method and observed they are still worse than our method (cf
Appendix A.5). For example, on CIFAR10 (10%), CT (AUC) can achieve an AUC of 0.944 with a
running time of 1000s, in contrast, the baselines CE, AUC, AUC-CE, TS-DRW, and TS-DEC use
same running time and achieve AUC scores of 0.925, 0.915, 0.943, 0.917, 0.917, respectively."
ABLATION STUDY,0.1558872305140962,Published as a conference paper at ICLR 2022
ABLATION STUDY,0.15754560530679934,"Figure 3: t-SNE visualization of training data (• is positive and • is negative) by (from top to bottom)
optimizing the CE loss, an AUC loss from scratch, a linear combined loss, and our CT method."
ABLATION STUDY,0.15920398009950248,Figure 4: Convergence curves on four benchmark datasets with an imbalance ratio of 10%.
ABLATION STUDY,0.16086235489220563,"Veriﬁcation of Algorithmic Design. We validate three algorithmic choices. (i) Using two inde-
pendent mini-batches S1 ̸= S2 is generally better than using the same mini-batch. (ii) Using the
momentum update for ut+1 (i.e., β0 < 1) is better than without using momentum update (β0 = 1).
(iii) tuning the number of inner gradient steps k ∈{1, 2, 3} is helpful for improving the perfor-
mance. The results are demonstrated in Table 2, where all results are averaged over three trials."
ABLATION STUDY,0.1625207296849088,"Table 2: Left: S1 ̸= S2 vs S1 = S2, right: β0 = 1 vs β0 < 1 in Algorithm 1. Note that we tune
k ∈{1, 2, 3} for for the left table and ﬁx k = 1 for the right table. left (S1 ̸= S2) vs right (β0 ≤1)
veriﬁes that tuning k is helpful."
ABLATION STUDY,0.16417910447761194,"Dataset
Method
Imbalance Ratio
1%
10%
30%"
ABLATION STUDY,0.16583747927031509,"CATvsDOG
S1 = S2
0.784±0.007
0.941±0.002
0.975±0.001
S1 ̸= S2
0.789±0.008
0.946±0.002
0.977±0.001"
ABLATION STUDY,0.16749585406301823,"CIFAR10
S1 = S2
0.738±0.005
0.931±0.002
0.959±0.000
S1 ̸= S2
0.740±0.004
0.935±0.001
0.964±0.001"
ABLATION STUDY,0.1691542288557214,"STL10
S1 = S2
0.671±0.007
0.820±0.025
0.902±0.003
S1 ̸= S2
0.681±0.005
0.839±0.004
0.907±0.001"
ABLATION STUDY,0.17081260364842454,"CIFAR100
S1 = S2
0.608±0.004
0.709±0.002
0.788±0.005
S1 ̸= S2
0.609±0.002
0.725±0.000
0.809±0.002"
ABLATION STUDY,0.1724709784411277,"Method
Imbalance Ratio
1%
10%
30%
β0 = 1
0.765±0.005
0.937±0.004
0.971±0.002
β0 < 1
0.769±0.007
0.939±0.004
0.975±0.006
β0 = 1
0.724±0.006
0.928±0.004
0.957±0.001
β0 < 1
0.725±0.011
0.929±0.002
0.960±0.001
β0 = 1
0.663±0.012
0.819±0.018
0.895±0.004
β0 < 1
0.666±0.006
0.832±0.008
0.900±0.002
β0 = 1
0.590±0.014
0.714±0.004
0.791±0.004
β0 < 1
0.598±0.002
0.714±0.003
0.801±0.001"
CONCLUSIONS,0.17412935323383086,"5
CONCLUSIONS
In this paper, we have proposed a novel end-to-end compositional training framework for deep AUC
maximization by optimizing a compositional objective. We also proposed an efﬁcient stochastic
optimization method for compositional training of deep AUC maximization. We demonstrated the
effectiveness of compositional training on multiple benchmark datasets and medical datasets for
maximizing AUC. In future work, we will investigate compositional training for other imbalanced
loss functions more extensively."
CONCLUSIONS,0.175787728026534,Published as a conference paper at ICLR 2022
CONCLUSIONS,0.17744610281923714,"ACKNOWLEDGEMENTS
We thank anonymous reviewers for their valuable comments. This work was partially supported by
NSF Career Award #1844403, NSF Award #2110545, NSF Award #1933212."
REFERENCES,0.1791044776119403,REFERENCES
REFERENCES,0.18076285240464346,"Babak Ehteshami Bejnordi, Mitko Veta, Paul Johannes Van Diest, Bram Van Ginneken, Nico
Karssemeijer, Geert Litjens, Jeroen AWM Van Der Laak, Meyke Hermsen, Quirine F Manson,
Maschenka Balkenhol, et al. Diagnostic assessment of deep learning algorithms for detection of
lymph node metastases in women with breast cancer. Jama, 318(22):2199–2210, 2017."
REFERENCES,0.1824212271973466,"K Bowyer, D Kopans, WP Kegelmeyer, R Moore, M Sallam, K Chang, and K Woods. The digital
database for screening mammography. In Third international workshop on digital mammography,
volume 58, pp. 27, 1996."
REFERENCES,0.18407960199004975,"Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma. Learning imbalanced
datasets with label-distribution-aware margin loss. In Advances in Neural Information Processing
Systems, pp. 1567–1578, 2019."
REFERENCES,0.1857379767827529,"Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. Class-balanced loss based on
effective number of samples. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pp. 9268–9277, 2019."
REFERENCES,0.18739635157545606,"Damien Dablain, Bartosz Krawczyk, and Nitesh V. Chawla. Deepsmote: Fusing deep learning and
SMOTE for imbalanced data. CoRR, abs/2105.02340, 2021. URL https://arxiv.org/
abs/2105.02340."
REFERENCES,0.1890547263681592,"Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. On the convergence theory of gradient-
based model-agnostic meta-learning algorithms. In International Conference on Artiﬁcial Intelli-
gence and Statistics, pp. 1082–1092. PMLR, 2020."
REFERENCES,0.19071310116086235,"C Ferri, PA Flach, and J Hernández-Orallo. Learning decision trees using the area under the roc
curve. In Claude Sammut and Achim Hoffmann (eds.), Proceedings of the 19th International
Conference on Machine Learning, pp. 139 – 146. Morgan Kaufmann, 2002. ISBN 1558608737."
REFERENCES,0.19237147595356552,"Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation
of deep networks. In Doina Precup and Yee Whye Teh (eds.), Proceedings of the 34th Interna-
tional Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017,
volume 70 of Proceedings of Machine Learning Research, pp. 1126–1135. PMLR, 2017. URL
http://proceedings.mlr.press/v70/finn17a.html."
REFERENCES,0.19402985074626866,"Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram Singer. An efﬁcient boosting algorithm for
combining preferences. J. Mach. Learn. Res., 4(null):933–969, December 2003. ISSN 1532-
4435."
REFERENCES,0.1956882255389718,"Lawrence Fulton, Alex McLeod, Diane Dolezel, Nathaniel Bastian, and Christopher P Fulton. Deep
vision for breast cancer classiﬁcation and segmentation. Cancers, 13(21):5384, 2021."
REFERENCES,0.19734660033167495,"Wei Gao and Zhi-Hua Zhou. On the consistency of AUC pairwise optimization. In Qiang Yang and
Michael J. Wooldridge (eds.), Proceedings of the Twenty-Fourth International Joint Conference
on Artiﬁcial Intelligence, IJCAI 2015, Buenos Aires, Argentina, July 25-31, 2015, pp. 939–945.
AAAI Press, 2015. URL http://ijcai.org/Abstract/15/137."
REFERENCES,0.19900497512437812,"Wei Gao, Rong Jin, Shenghuo Zhu, and Zhi-Hua Zhou. One-pass auc optimization. In International
conference on machine learning, pp. 906–914, 2013."
REFERENCES,0.20066334991708126,"Saeed Ghadimi and Mengdi Wang. Approximation methods for bilevel programming. arXiv preprint
arXiv:1802.02246, 2018."
REFERENCES,0.2023217247097844,"Saeed Ghadimi, Andrzej Ruszczynski, and Mengdi Wang. A single timescale stochastic approxi-
mation method for nested stochastic optimization. SIAM J. Optim., 30(1):960–979, 2020. doi:
10.1137/18M1230542. URL https://doi.org/10.1137/18M1230542."
REFERENCES,0.20398009950248755,Published as a conference paper at ICLR 2022
REFERENCES,0.20563847429519072,"Zhishuai Guo, Mingrui Liu, Zhuoning Yuan, Li Shen, Wei Liu, and Tianbao Yang. Communication-
efﬁcient distributed stochastic AUC maximization with deep neural networks. In Proceedings of
the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual
Event, volume 119 of Proceedings of Machine Learning Research, pp. 3864–3874. PMLR, 2020a.
URL http://proceedings.mlr.press/v119/guo20f.html."
REFERENCES,0.20729684908789386,"Zhishuai Guo, Zhuoning Yuan, Yan Yan, and Tianbao Yang. Fast objective and duality gap conver-
gence for non-convex strongly-concave min-max problems. CoRR, abs/2006.06889, 2020b. URL
https://arxiv.org/abs/2006.06889."
REFERENCES,0.208955223880597,"Zhishuai Guo, Yi Xu, Wotao Yin, Rong Jin, and Tianbao Yang. On stochastic moving-average
estimators for non-convex optimization. CoRR, abs/2104.14840, 2021. URL https://arxiv.
org/abs/2104.14840."
REFERENCES,0.21061359867330018,"Michael Heath, Kevin Bowyer, Daniel Kopans, Philip Kegelmeyer, Richard Moore, Kyong Chang,
and S Munishkumaran. Current status of the digital database for screening mammography. In
Digital mammography, pp. 457–460. Springer, 1998."
REFERENCES,0.21227197346600332,"Ralf Herbrich, Thore Graepel, and Klause Obermayer. Large Margin Rank Boundaries for Ordinal
Regression. In Advances in Large Margin Classiﬁers, chapter 7, pp. 115–132. The MIT Press,
1999. URL http://www.herbrich.me/papers/nips98_ordinal.pdf."
REFERENCES,0.21393034825870647,"Alan Herschtal and Bhavani Raskutti. Optimising area under the ROC curve using gradient de-
scent. In Carla E. Brodley (ed.), Machine Learning, Proceedings of the Twenty-ﬁrst International
Conference (ICML 2004), Banff, Alberta, Canada, July 4-8, 2004, volume 69 of ACM Inter-
national Conference Proceeding Series. ACM, 2004.
doi: 10.1145/1015330.1015366.
URL
https://doi.org/10.1145/1015330.1015366."
REFERENCES,0.2155887230514096,"Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected
convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pp. 4700–4708, 2017."
REFERENCES,0.21724709784411278,"Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute, Henrik
Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, et al.
Chexpert: A large chest
radiograph dataset with uncertainty labels and expert comparison. In Proceedings of the AAAI
Conference on Artiﬁcial Intelligence, volume 33, pp. 590–597, 2019."
REFERENCES,0.21890547263681592,"Muhammad Abdullah Jamal, Matthew Brown, Ming-Hsuan Yang, Liqiang Wang, and Boqing Gong.
Rethinking class-balanced methods for long-tailed visual recognition from a domain adaptation
perspective. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recog-
nition, pp. 7610–7619, 2020."
REFERENCES,0.22056384742951907,"Thorsten Joachims.
A support vector method for multivariate performance measures.
In Pro-
ceedings of the 22nd International Conference on Machine Learning, ICML ’05, pp. 377–384,
New York, NY, USA, 2005. Association for Computing Machinery. ISBN 1595931805. doi:
10.1145/1102351.1102399. URL https://doi.org/10.1145/1102351.1102399."
REFERENCES,0.2222222222222222,"Justin M Johnson and Taghi M Khoshgoftaar. Survey on deep learning with class imbalance. Journal
of Big Data, 6(1):27, 2019."
REFERENCES,0.22388059701492538,"Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi Feng, and Yannis
Kalantidis. Decoupling representation and classiﬁer for long-tailed recognition. arXiv preprint
arXiv:1910.09217, 2019."
REFERENCES,0.22553897180762852,"Purushottam Kar, Bharath Sriperumbudur, Prateek Jain, and Harish Karnick. On the generalization
ability of online learning algorithms for pairwise loss functions. In Sanjoy Dasgupta and David
McAllester (eds.), Proceedings of the 30th International Conference on Machine Learning, vol-
ume 28 of Proceedings of Machine Learning Research, pp. 441–449, Atlanta, Georgia, USA, 17–
19 Jun 2013. PMLR. URL https://proceedings.mlr.press/v28/kar13.html."
REFERENCES,0.22719734660033167,"Purushottam Kar, Harikrishna Narasimhan, and Prateek Jain. Online and stochastic gradient meth-
ods for non-decomposable loss functions. In Proceedings of the 27th International Conference
on Neural Information Processing Systems - Volume 1, NIPS’14, pp. 694–702, Cambridge, MA,
USA, 2014. MIT Press."
REFERENCES,0.22885572139303484,Published as a conference paper at ICLR 2022
REFERENCES,0.23051409618573798,"Salman H Khan, Munawar Hayat, Mohammed Bennamoun, Ferdous A Sohel, and Roberto Togneri.
Cost-sensitive learning of deep feature representations from imbalanced data. IEEE transactions
on neural networks and learning systems, 29(8):3573–3587, 2017."
REFERENCES,0.23217247097844113,"Diederik Kingma and Jimmy Ba.
Adam: A method for stochastic optimization.
International
Conference on Learning Representations, 2015."
REFERENCES,0.23383084577114427,"Hansang Lee, Minseok Park, and Junmo Kim. Plankton classiﬁcation on imbalanced large scale
database via convolutional neural networks with transfer learning. In 2016 IEEE international
conference on image processing (ICIP), pp. 3713–3717. IEEE, 2016."
REFERENCES,0.23548922056384744,"Rebecca Sawyer Lee, Francisco Gimenez, Assaf Hoogi, Kanae Kawai Miyake, Mia Gorovoy, and
Daniel L Rubin.
A curated mammography data set for use in computer-aided detection and
diagnosis research. Scientiﬁc data, 4(1):1–9, 2017."
REFERENCES,0.23714759535655058,"Tianyi Lin, Chi Jin, and Michael I Jordan.
On gradient descent ascent for nonconvex-concave
minimax problems. arXiv preprint arXiv:1906.00331, 2019."
REFERENCES,0.23880597014925373,"Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár. Focal loss for dense
object detection. In Proceedings of the IEEE international conference on computer vision, pp.
2980–2988, 2017."
REFERENCES,0.24046434494195687,"Mingrui Liu, Xiaoxuan Zhang, Zaiyi Chen, Xiaoyu Wang, and Tianbao Yang. Fast stochastic auc
maximization with o (1/n)-convergence rate. In International Conference on Machine Learning,
pp. 3195–3203, 2018."
REFERENCES,0.24212271973466004,"Mingrui Liu, Zhuoning Yuan, Yiming Ying, and Tianbao Yang. Stochastic auc maximization with
deep neural networks. arXiv preprint arXiv:1908.10831, 2019a."
REFERENCES,0.24378109452736318,"Ziwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang, Boqing Gong, and Stella X. Yu. Large-
scale long-tailed recognition in an open world. In IEEE Conference on Computer Vision and
Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019, pp. 2537–2546.
Computer Vision Foundation / IEEE, 2019b. doi: 10.1109/CVPR.2019.00264. URL http:
//openaccess.thecvf.com/content_CVPR_2019/html/Liu_Large-Scale_
Long-Tailed_Recognition_in_an_Open_World_CVPR_2019_paper.html."
REFERENCES,0.24543946932006633,"Liangchen Luo, Yuanhao Xiong, Yan Liu, and Xu Sun. Adaptive gradient methods with dynamic
bound of learning rate. In 7th International Conference on Learning Representations (ICLR),
2019."
REFERENCES,0.2470978441127695,"David Masko and Paulina Hensman. The impact of imbalanced training data for convolutional
neural networks, 2015."
REFERENCES,0.24875621890547264,"Aditya Krishna Menon, Sadeep Jayasumana, Ankit Singh Rawat, Himanshu Jain, Andreas Veit, and
Sanjiv Kumar. Long-tail learning via logit adjustment. In International Conference on Learning
Representations, 2021. URL https://openreview.net/forum?id=37nvvqkCo5."
REFERENCES,0.2504145936981758,"Michael Natole, Yiming Ying, and Siwei Lyu. Stochastic proximal algorithms for auc maximization.
In International Conference on Machine Learning, pp. 3707–3716, 2018."
REFERENCES,0.25207296849087896,"Michael Natole, Yiming Ying, and Siwei Lyu. Stochastic auc optimization algorithms with linear
convergence. Frontiers in Applied Mathematics and Statistics, 5, 2019."
REFERENCES,0.2537313432835821,"Qi Qi, Yi Xu, Rong Jin, Wotao Yin, and Tianbao Yang. Attentional biased stochastic gradient for
imbalanced classiﬁcation. CoRR, abs/2012.06951, 2020. URL https://arxiv.org/abs/
2012.06951."
REFERENCES,0.25538971807628524,"Alain Rakotomamonjy. Support vector machines and area under roc curves. Technical report, 2004."
REFERENCES,0.2570480928689884,"Sashank J. Reddi, Satyen Kale, and Sanjiv Kumar. On the convergence of adam and beyond. In 6th
International Conference on Learning Representations (ICLR), 2018."
REFERENCES,0.25870646766169153,"Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples for
robust deep learning. arXiv preprint arXiv:1803.09050, 2018."
REFERENCES,0.2603648424543947,Published as a conference paper at ICLR 2022
REFERENCES,0.2620232172470978,"Veronica Rotemberg, Nicholas Kurtansky, Brigid Betz-Stablein, Liam Caffery, Emmanouil
Chousakos, Noel Codella, Marc Combalia, Stephen Dusza, Pascale Guitera, David Gutman, et al.
A patient-centric dataset of images and metadata for identifying melanomas using clinical context.
Scientiﬁc data, 8(1):1–8, 2021."
REFERENCES,0.263681592039801,"Eric Scuccimarra. Ddsm mammography: tfrecords ﬁles of scans from the ddsm dataset. Online,
2021. URL https://www.kaggle.com/skooch/ddsm-mammography."
REFERENCES,0.26533996683250416,"Mingxing Tan and Quoc V Le. Efﬁcientnetv2: Smaller models and faster training. arXiv preprint
arXiv:2104.00298, 2021."
REFERENCES,0.2669983416252073,"Laurens van der Maaten and Geoffrey E. Hinton. Visualizing high-dimensional data using t-sne.
Journal of Machine Learning Research, 9:2579–2605, 2008."
REFERENCES,0.26865671641791045,"Bastiaan S Veeling, Jasper Linmans, Jim Winkens, Taco Cohen, and Max Welling. Rotation equiv-
ariant cnns for digital pathology. In International Conference on Medical image computing and
computer-assisted intervention, pp. 210–218. Springer, 2018."
REFERENCES,0.2703150912106136,"Mengdi Wang, Ethan X Fang, and Han Liu. Stochastic compositional gradient descent: algorithms
for minimizing compositions of expected-value functions. Mathematical Programming, 161(1-2):
419–449, 2017."
REFERENCES,0.27197346600331673,"Xudong Wang, Long Lian, Zhongqi Miao, Ziwei Liu, and Stella X. Yu. Long-tailed recognition
by routing diverse distribution-aware experts.
CoRR, abs/2010.01809, 2020.
URL https:
//arxiv.org/abs/2010.01809."
REFERENCES,0.2736318407960199,"Xudong Wang, Long Lian, Zhongqi Miao, Ziwei Liu, and Stella Yu. Long-tailed recognition by
routing diverse distribution-aware experts. In International Conference on Learning Representa-
tions, 2021a. URL https://openreview.net/forum?id=D9I3drBz4UC."
REFERENCES,0.2752902155887231,"Zhengyang Wang, Meng Liu, Youzhi Luo, Zhao Xu, Yaochen Xie, Limei Wang, Lei Cai, Qi Qi,
Zhuoning Yuan, Tianbao Yang, and Shuiwang Ji. Advanced graph and sequence neural networks
for molecular property prediction and drug discovery, 2021b."
REFERENCES,0.2769485903814262,"Liuyu Xiang, Guiguang Ding, and Jungong Han.
Learning from multiple experts: Self-paced
knowledge distillation for long-tailed classiﬁcation. In Andrea Vedaldi, Horst Bischof, Thomas
Brox, and Jan-Michael Frahm (eds.), Computer Vision - ECCV 2020 - 16th European Confer-
ence, Glasgow, UK, August 23-28, 2020, Proceedings, Part V, volume 12350 of Lecture Notes
in Computer Science, pp. 247–263. Springer, 2020. doi: 10.1007/978-3-030-58558-7\_15. URL
https://doi.org/10.1007/978-3-030-58558-7_15."
REFERENCES,0.27860696517412936,"Lian Yan, Robert Dodier, Michael C. Mozer, and Richard Wolniewicz. Optimizing classiﬁer perfor-
mance via an approximation to the wilcoxon-mann-whitney statistic. In Proceedings of the Twen-
tieth International Conference on International Conference on Machine Learning, ICML’03, pp.
848–855. AAAI Press, 2003. ISBN 1577351894."
REFERENCES,0.2802653399668325,"Yuzhe Yang and Zhi Xu. Rethinking the value of labels for improving class-imbalanced learn-
ing.
In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (eds.), Ad-
vances in Neural Information Processing Systems, volume 33, pp. 19290–19301. Curran As-
sociates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/
e025b6279c1b88d3ec0eca6fcb6e6280-Paper.pdf."
REFERENCES,0.28192371475953565,"Yiming Ying, Longyin Wen, and Siwei Lyu. Stochastic online auc maximization. In Advances in
neural information processing systems, pp. 451–459, 2016."
REFERENCES,0.2835820895522388,"Zhuoning Yuan, Yan Yan, Milan Sonka, and Tianbao Yang. Robust deep AUC maximization: A
new surrogate loss and empirical studies on medical image classiﬁcation. CoRR, abs/2012.03173,
2020. URL https://arxiv.org/abs/2012.03173."
REFERENCES,0.28524046434494194,"Zhuoning Yuan, Zhishuai Guo, Yi Xu, Yiming Ying, and Tianbao Yang. Federated deep AUC max-
imization for hetergeneous data with a constant communication complexity. In Marina Meila
and Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning,
ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Re-
search, pp. 12219–12229. PMLR, 2021. URL http://proceedings.mlr.press/v139/
yuan21a.html."
REFERENCES,0.28689883913764513,Published as a conference paper at ICLR 2022
REFERENCES,0.2885572139303483,"Xinhua Zhang, Ankan Saha, and S. V. N. Vishwanathan. Smoothing multivariate performance mea-
sures. J. Mach. Learn. Res., 13(1):3623–3680, December 2012. ISSN 1532-4435."
REFERENCES,0.2902155887230514,"Peilin Zhao, Steven C. H. Hoi, Rong Jin, and Tianbao Yang. Online auc maximization. In ICML,
pp. 233–240, 2011."
REFERENCES,0.29187396351575456,"Yan Zheng, Yuchen Zheng, Daiki Suehiro, and Seiichi Uchida. Top-rank convolutional neural net-
work and its application to medical image-based diagnosis. Pattern Recognition, 120:108138,
2021."
REFERENCES,0.2935323383084577,"Boyan Zhou, Quan Cui, Xiu-Shen Wei, and Zhao-Min Chen. BBN: bilateral-branch network with
cumulative learning for long-tailed visual recognition. In 2020 IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition, CVPR 2020, Seattle, WA, USA, June 13-19, 2020, pp.
9716–9725. IEEE, 2020. doi: 10.1109/CVPR42600.2020.00974. URL https://doi.org/
10.1109/CVPR42600.2020.00974."
REFERENCES,0.29519071310116085,"Linchao Zhu and Yi Yang.
Inﬂated episodic memory with region self-attention for long-tailed
visual recognition. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recogni-
tion, CVPR 2020, Seattle, WA, USA, June 13-19, 2020, pp. 4343–4352. IEEE, 2020. doi: 10.
1109/CVPR42600.2020.00440. URL https://doi.org/10.1109/CVPR42600.2020.
00440."
REFERENCES,0.296849087893864,Published as a conference paper at ICLR 2022
REFERENCES,0.29850746268656714,"A
SUPPLEMENT OF EXPERIMENTAL SECTION"
REFERENCES,0.30016583747927034,"A.1
DATASET DESCRIPTIONS"
REFERENCES,0.3018242122719735,"The detailed statistics of different datasetse are reported in Table 3. Note that ”# of images” refers to
the number of samples for the original training set. ""LT"" denote long-tailed version of the datasets
for multi-class tasks. Imbalance ratio (imratio) of XXX (Binary) data means the ratio of number of
positive examples to number of all examples. Imbalance ratio (imratio) of XXX (LT) data means
ration of the size of smallest class to the size of largest class. The DDSM+ is slightly different from
the standard version of CBIS-DDSM or DDSM (Lee et al. (2017); Bowyer et al. (1996); Heath et al.
(1998)). We actually use the dataset from (Scuccimarra (2021)) constructed by Eric A. Scuccimarra,
which consists of 55k images for training and 15k images for testing. The details about the dataset
construction can be found here (Scuccimarra (2021); Zheng et al. (2021); Fulton et al. (2021)).
For constructing DDSM+, the positive samples (cancer cases) are from CBIS-DDSM and negative
samples (normal cases) are from DDSM. To increase the size of the training data, the author applies
ofﬂine data augmentation and adds multiple augmented copies to the dataset. In particular, each
image (ROI) is randomly cropped three times into 598x598 images, with random ﬂips and rotations,
and then the images are resized down to 299x299. For the testing set, the same augmentation is also
applied and thus the imbalance ratios remain the same as the training set. The imbalance ratio is
about 13% in both training and testing sets. The train/test split in terms of patient ID follows the
CBIS-DDSM split, which do not have any overlap. We will add these references in the revision and
also correct the citation for CBIS-DDSM. Please also note that this dataset (DDSM+) has also been
used for some recent works (Zheng et al. (2021); Fulton et al. (2021))."
REFERENCES,0.3034825870646766,"Table 3: Description of datasets for classiﬁcation tasks.
Dataset
# of images
# of classes
Imbalance Ratio
CATvsDOG (binary)
20,000
2
1%, 10%, 30%
CIFAR10 (binary)
50,000
2
1%, 10%, 30%
CIFAR100 (binary)
50,000
2
1%, 10%, 30%
STL10 (binary)
5,000
2
1%, 10%, 30%
CheXpert
223,416
2
12.2%, 32.2%, 6.8%, 31.2%, 40.3%
Melanoma
33,126
2
1.76%
DDSM+
55,000
2
13%
PatchCam
294,912
2
1%
CIFAR10 (LT)
50,000
10
1%, 10%
CIFAR100 (LT)
50,000
100
1%, 10%
STL10 (LT)
5,000
10
1%, 10%
ImageNet (LT)
115,800
1000
0.39%"
REFERENCES,0.30514096185737977,"A.2
TRAINING CONFIGURATIONS"
REFERENCES,0.3067993366500829,"All benchmark datasets are experimented by NVIDIA GTX-2080Ti and four medical datasets,
i.e., CheXpert, Melanoma, DDSM+ and PatchCam, are experimented by NVIDIA V100. For the
datasets of binary classiﬁcation in Table 1, we use the dataloaders from (Yuan et al., 2020). For the
long-tailed datasets of multi-class classiﬁcation as in Section D, we uses the dataloaders from (Cui
et al., 2019). For TS-DRW, we train the models using cross-entropy loss at the ﬁrst stage and then
switch to imbalanced losses at the later stages. For TS-DEC, we ﬁrst conduct the regular training
using cross-entropy loss and same settings and then we discard the trained classiﬁers and ﬁnetune
the new classiﬁer for additional 10 epochs using imbalanced loss with the learning rate of 0.01. For
the proposed compositional training methods, we consider the non-adaptive version with ht(·) = 1
in all experiments. For all datasets, we use the train/val split to do cross-validation for parameter
tuning, except CheXpert as explained below. For the benchmark datasets, we use 19k/1k, 45k/5k,
45k/5k. 4k/1k training/validation split on CatvsDog, CIFAR10, CIFAR100, STL10, respectively.
For melanoma dataset, we use 70/10/20 split for train/val/test. For PatchCam, we use their ofﬁcial
validation set for tuning parameters, which includes about 37k images with balanced positive and
negative samples. For DDSM+, we tune the parameters on 10% data sampled from the training set.
For CheXpert, since the ofﬁcial testing set is not released and it will take a long time to evaluate all
methods on the ofﬁcial testing data, hence, we evaluate different methods only based on the ofﬁcial
validation set with parameters tuned according to this set. To make the experiment on Chexpert con-"
REFERENCES,0.30845771144278605,Published as a conference paper at ICLR 2022
REFERENCES,0.3101160862354892,"sistent with other datasets, we run experiments for all methods on CheXpert by following the same
cross-validation procedure, i.e., by sampling 10% training data based on patient ID as the validation
set to tune parameters and then we report the average scores of ﬁve diseases on the testing set (i.e.,
the ofﬁcial validation set as a testing set)."
REFERENCES,0.3117744610281924,"A.3
EVALUATIONS ON MEDICAL DATASET WITH MULTIPLE RUNS"
REFERENCES,0.31343283582089554,"For medical datasets, we run all experiments and report the average performance over three runs.
We use batch size of 32 except for PatchCam that is 64, initial learning rate of 0.1 and weight decay
of 1e-5. We train Melanoma for 12 epochs, CheXpert for 2 epochs, DDSM+ for 5 epochs and
PatchCam for 5 epochs. The learning rate is decayed at 50%, 75% of total training iterations by
10 times. For compositional training, we tune the number of inner gradient steps in k ∈{1, 2, 3}
and also tune α ∈{0.1, 0.05, 0.01} for the inner steps. The results are summarized in the following
table."
REFERENCES,0.3150912106135987,Table 4: Testing performance on medical datasets.
REFERENCES,0.3167495854063018,"Method
Melanoma
CheXpert
DDSM+
PatchCam
AUC
CE
0.879±0.008
0.892±0.001
0.949±0.001
0.869±0.007
AUC
0.868±0.006
0.899±0.002
0.929±0.001
0.868±0.006
AUC-CE
0.880±0.005
0.902±0.002
0.957±0.001
0.868±0.005
TS-DRW
0.878±0.007
0.900±0.002
0.942±0.003
0.867±0.006
TS-DEC
0.877±0.005
0.897±0.001
0.941±0.001
0.869±0.009
CT (AUC)
0.900±0.002
0.909±0.003
0.981±0.001
0.891±0.003"
REFERENCES,0.31840796019900497,"A.4
TESTING CONVERGENCE CURVES."
REFERENCES,0.3200663349917081,"The convergence curves of testing AUC on the benchmark datasets of different methods are plotted
in Figure 5."
REFERENCES,0.32172470978441126,"Figure 5: Convergence curves of testing AUC on four benchmark datasets with imbalance ratio of
10%."
REFERENCES,0.32338308457711445,"A.5
COMPARISON WITH THE SAME RUNTIME"
REFERENCES,0.3250414593698176,"To compare the performance with the same running time, we train ResNet20 on four benchmark
datasets with an imbalance ratio of 10% on a GTX-2080Ti. For each method, we train 1000 seconds
and report the best achieved testing AUC. The results are summarized in Table 5."
REFERENCES,0.32669983416252074,Table 5: Achieved testing AUC for each method after training ResNet20 for 1000 seconds.
REFERENCES,0.3283582089552239,"Dataset
CT (AUC)
CE
AUC
AUC-CE
TS-DRW
TS-DEC
CATvsDOG (10%)
0.944
0.925
0.915
0.943
0.917
0.917
CIFAR10 (10%)
0.936
0.900
0.905
0.928
0.897
0.898
STL10 (10%)
0.837
0.815
0.783
0.829
0.816
0.815
CIFAR100 (10%)
0.724
0.691
0.701
0.718
0.696
0.696"
REFERENCES,0.33001658374792703,"A.6
EVOLUTION OF DIFFERENT TERMS OF THE COMPOSITIONAL OBJECTIVE."
REFERENCES,0.33167495854063017,"To better understand the proposed compositional objective, we plot the evolution curves of each term
in the decomposition equation (5) and compare them with that of naive linear combination approach"
REFERENCES,0.3333333333333333,Published as a conference paper at ICLR 2022
REFERENCES,0.33499170812603646,"(Linear Comb.). We conduct experiments on CATvsDOG, CIFAR10, CIFAR100 and STL10 with
imbalance ratio of 10% using ResNet20. We start with initial learning rate of 0.1 and decay it at 50th,
75th epoch by 0.1. In Figure 6, we plot the values of LAUC(w), LAVG(w), ∇LAUC(w)⊤∇LAVG(w),
∥∇LAVG(w)∥2 v.s. the number of epochs on training set. For the calculations of LAUC(w), we
compute its values based on the optimal values of a, b, α according to (Yuan et al., 2020) for each
epoch. Regarding the calculations of w, we compute the mean values of all layers of models. We
defer results on other datasets to appendix. From the results, we observe that initially LAUC(w)
dominate the objective and keep decreasing at earlier iterations. When it reaches similar level of
the third term ∥∇LAVG(w)∥, the objective shifts its focus on third term and pushes it to smaller
while maintaining second term positive. Eventually, we can see that both AUC and CE losses of
CT method reach to a level close to zero. In addition, comparing CT with the linear combination
method, it is amazing to see that CT drives both the CE loss and the AUC loss decrease faster and
to a smaller level than the linear combination method."
REFERENCES,0.33665008291873966,"Figure 6: Evolution of each term of compositional objective function on CATvsDog, CIFAR10,
STL10 and CIFAR100 datasets (from top to bottom)."
REFERENCES,0.3383084577114428,"B
IMPLEMENTATION OF z2,t+1 = ht(O0, O1, . . . , Ot)"
REFERENCES,0.33996683250414594,"The ht is usually implemented by a recursion, where examples are given in Table 6. Similar to (Guo
et al., 2021), we make the following assumption for our analysis.
Assumption 1. For the Adam-style algorithms in Table 6, we assume that st = 1/(√z2,t+1 + G0)
is upper bounded and lower bounded, i.e., there exists 0 < cl < cu such that ∀i, cl ≤∥st,i∥≤cu,
where st,i denotes the i-th element of st."
REFERENCES,0.3416252072968491,Remark: Different implementations of ht that satisfy this assumption is presented in Table 6.
REFERENCES,0.34328358208955223,"We need the following lemma to tackle the variance recursion.
Lemma 1 (Lemma 2, Ghadimi & Wang (2018)). Consider a moving average sequence zt+1 = (1−
β)zt + βtOh(xt) for tracking h(xt), where E[Oh(xt)] = h(xt) and h is a L-Lipschitz continuous"
REFERENCES,0.3449419568822554,Published as a conference paper at ICLR 2022
REFERENCES,0.3466003316749585,"Table 6: Different Adam-style methods and their satisfactions of Assumption 1
method
update for ht
Additional assumption
cl and cu
SHB
ht(·) = 1, G = 0
-
cl = 1, cu = 1"
REFERENCES,0.3482587064676617,"Adam
z2,t+1 = (1 −β′
t)z2,t + β′
tO2
t
∥Ot∥∞≤G
cl =
1
G+G0 , cu =
1
G0"
REFERENCES,0.34991708126036486,"AMSGrad
z′
2,t+1 = (1 −β′
t)z′
2,t + β′
tO2
t
z2,t+1 = max(z2,t, z′
2,t+1)
∥Ot∥∞≤G
cl =
1
G+G0 , cu =
1
G0"
REFERENCES,0.351575456053068,"AdaFom
(AdaGrad)
z2,t+1 =
1
t+1
Pt
i=0 O2
t
∥Ot∥∞≤G
cl =
1
G+G0 , cu =
1
G0"
REFERENCES,0.35323383084577115,"Adabound
z′
2,t+1 = (1 −β′
t)z′
2,t + β′
tO2
t
z2,t+1 = Π[1/c2u,1/c2
l ][z′
2,t+1],
G0 = 0
-
cl = cl, cu = cu"
REFERENCES,0.3548922056384743,mapping. Then we have
REFERENCES,0.35655058043117743,"Et∥zt+1 −h(xt)∥2 ≤(1 −βt)∥zt −h(xt−1)∥2 + 2β2
t Et∥Oh(xt) −h(xt)∥2 + L2∥xt −xt−1∥2 βt
,"
REFERENCES,0.3582089552238806,"(8)
where Et denotes the expectation conditioned on all randomness before Oh(xt)."
REFERENCES,0.3598673300165838,"C
PROOF OF THEOREM 1"
REFERENCES,0.3615257048092869,"Denote ηt = η1st, where st = 1/(√z2,t+1 + G0). We make the following assumptions regarding
problem 6."
REFERENCES,0.36318407960199006,Assumption 2.
REFERENCES,0.3648424543946932,"• ∇LAVG(w) is CLAVG-Lipschitz continuous, g1( ¯w) is Cg1-Lipschitz continuous and g2( ¯w) is Cg2-
Lipschitz continuous."
REFERENCES,0.36650082918739635,"• ∇2LAVG(w) is LLAVG-Lipschitz continuous, ∇g1( ¯w) is Lg1-Lipschitz continuous, and ∇g2( ¯w) is
Lg2-Lipschitz continuous."
REFERENCES,0.3681592039800995,"• E∥α∇LAVG(w) −α∇LAVG(w; S)∥2
≤σ2, E∥α∇2LAVG(w) −α∇2LAVG(w; S)∥2
≤σ2,
E∥∇g1(w) −∇g1(w; S)∥2 ≤σ2, E∥g1(w) −g1(w; S)∥2 ≤σ2, E∥∇g2(w) −∇g2(w; S)∥2 ≤
σ2, E∥g2(w) −g2(w; S)∥2 ≤σ2."
REFERENCES,0.36981757877280264,• Ωis a bounded convex set with radius D.
REFERENCES,0.3714759535655058,"It is notable that the last assumption can be replaced by a condition that the dual variables θt are
bounded."
REFERENCES,0.373134328358209,"We also know that g3(θ) is λ := 2p(1 −p)-strongly convex and also Lg3 = λ-smooth. De-
note θ∗( ¯w) = arg max
θ∈ΩΦ( ¯w, θ). Based on Assumption 2, we have that h( ¯w) is (Ch := 1 +"
REFERENCES,0.3747927031509121,"αCLAVG)-Lipschitz continuous, ∇h( ¯w) is (Lh := 1 + αLLAVG)-Lipschitz continuous, E∥∇h( ¯w) −
∇h( ¯w; S)∥2 ≤(1 + D2)σ2, and E∥h( ¯w) −h( ¯w; S)∥2 ≤(1 + D2)σ2. We also know that F( ¯w) is"
REFERENCES,0.37645107794361526,"LF -smooth, where LF := (Lg1 + DLg2 + λ) +
(Lg1+DLg2+λ)2"
REFERENCES,0.3781094527363184,"λ
(Lemma 4.3 of (Lin et al., 2019))."
REFERENCES,0.37976782752902155,We present Theorem 1 formally in the following Theorem.
REFERENCES,0.3814262023217247,"Theorem 2. Assume F( ¯w0) −F∗≤∆F where F∗= min
¯w F( ¯w).
Suppose Assumptions 1"
REFERENCES,0.38308457711442784,"and 2 hold.
With β0 = O(1/
√"
REFERENCES,0.38474295190713104,"T), β1 = O(1/
√"
REFERENCES,0.3864013266998342,"T), β0 = O(1/
√"
REFERENCES,0.3880597014925373,"T), β1 = O(1/
√"
REFERENCES,0.38971807628524047,"T),
η1 ≤min{
q"
REFERENCES,0.3913764510779436,"cl
c3
uC3
β1"
REFERENCES,0.39303482587064675,"2 ,
cl
c3
u(C1λ2+512C2
g2)
β0λ
2Ch ,
cl
2c2
uLF }, and η2 = O(1/
√"
REFERENCES,0.3946932006633499,T) where C1 and C3 are
REFERENCES,0.3963515754560531,"proper constants speciﬁed in the proof, Algorithm 1 can ensure that E"
REFERENCES,0.39800995024875624,"""
1
T + 1 T
X"
REFERENCES,0.3996683250414594,"t=0
∥∇F( ¯wt)∥2
#"
REFERENCES,0.4013266998341625,"≤O( 1
√ T
)."
REFERENCES,0.40298507462686567,"To prove this theorem, we ﬁrst need a couple of lemmas."
REFERENCES,0.4046434494195688,Published as a conference paper at ICLR 2022
REFERENCES,0.40630182421227196,"Lemma 2. Suppose Assumption 1 and Assumption 2 hold. Considering the update in Algorithm 1,
we have
F( ¯wt+1) ≤F( ¯wt) + η1cu"
REFERENCES,0.4079601990049751,"2
∥[∇hg1(h( ¯wt)) + θ∗(h( ¯wt))∇hg2(h( ¯wt))] −zt+1∥2 −η1cl"
REFERENCES,0.4096185737976783,2 ∥∇F( ¯wt)∥2 −η1cl
REFERENCES,0.41127694859038144,"4 ∥zt+1∥2.
(9)"
REFERENCES,0.4129353233830846,"Proof of Lemma 2. Due to the smoothness of F, we can prove that under η1LF ≤cl/(2c2
u),"
REFERENCES,0.41459369817578773,F( ¯wt+1) ≤F( ¯wt) + ∇F( ¯wt)⊤( ¯wt+1 −¯wt) + LF
REFERENCES,0.41625207296849087,2 ∥¯wt+1 −¯wt∥2
REFERENCES,0.417910447761194,= F( ¯wt) −∇F( ¯wt)⊤(ηt ◦zt+1) + LF
REFERENCES,0.41956882255389716,2 ∥ηt ◦zt+1∥2
REFERENCES,0.42122719734660036,= F( ¯wt) + 1
REFERENCES,0.4228855721393035,2∥√ηt ◦(∇F( ¯wt) −zt+1)∥2 −1
REFERENCES,0.42454394693200664,2∥√ηt ◦∇F( ¯wt)∥2 + (LF
REFERENCES,0.4262023217247098,2 ∥ηt ◦zt+1∥2 −1
REFERENCES,0.42786069651741293,2∥√ηt ◦zt+1∥2)
REFERENCES,0.4295190713101161,≤F( ¯wt) + η1cu
REFERENCES,0.4311774461028192,"2
∥[∇hg1(h( ¯wt)) + θ∗(h( ¯wt))∇hg2(h( ¯wt))] −zt+1∥2 −η1cl"
REFERENCES,0.43283582089552236,"2 ∥∇F( ¯wt)∥2 + η2
1c2
uLF −η1cl"
REFERENCES,0.43449419568822556,"2
∥zt+1∥2"
REFERENCES,0.4361525704809287,≤F( ¯wt) + η1cu
REFERENCES,0.43781094527363185,"2
∥[∇hg1(h( ¯wt)) + θ∗(h( ¯wt))∇hg2(h( ¯wt))] −zt+1∥2 −η1cl"
REFERENCES,0.439469320066335,2 ∥∇F( ¯wt)∥2 −η1cl
REFERENCES,0.44112769485903813,4 ∥zt+1∥2.
REFERENCES,0.4427860696517413,"Lemma 3. Let θt+1 = ΠΩ[θt + η2(g2(ut+1; S1 ∪S2) −∇g3(θt))], we have"
REFERENCES,0.4444444444444444,∥θt+1 −θ∗(h( ¯wt+1))∥2 ≤(1 −η2λ
REFERENCES,0.4461028192371476,"2 )E∥θt −θ∗(h( ¯wt))∥2 + 2η2
2σ2"
REFERENCES,0.44776119402985076,+ 16η2
REFERENCES,0.4494195688225539,"λ
C2
g2E∥ut+1 −h( ¯wt)∥2 + 4L2
θ
η2λ E∥h( ¯wt) −h( ¯wt+1)∥2
(10)"
REFERENCES,0.45107794361525705,where Lθ := Cg2
REFERENCES,0.4527363184079602,"λ
is the Lipschitz continuous constant of θ∗(·)."
REFERENCES,0.45439469320066334,"Proof of Lemma 3. Since θ∗(h( ¯wt)) = ΠΩ[θ∗(h( ¯wt)) + η2(g2(h( ¯wt)) −∇g3(θ∗(h( ¯wt))))], we
have
E∥θt+1 −θ∗(h( ¯wt))∥2"
REFERENCES,0.4560530679933665,= E∥ΠΩ[θt + η2(g2(ut+1; S1 ∪S2) −∇g3(θt))] −ΠΩ[θ∗(h( ¯wt)) + η2(g2(h( ¯wt)) −∇g3(θ∗(h( ¯wt))))]∥2
REFERENCES,0.4577114427860697,≤E∥[θt + η2(g2(ut+1; S1 ∪S2) −∇g3(θt))] −[θ∗(h( ¯wt)) + η2(g2(h( ¯wt)) −∇g3(θ∗(h( ¯wt))))]∥2
REFERENCES,0.4593698175787728,"= E∥[θt + η2(g2(ut+1; S1 ∪S2) −∇g3(θt)) −η2g2(ut+1) + η2g2(ut+1)]
−[θ∗(h( ¯wt)) + η2(g2(h( ¯wt)) −∇g3(θ∗(h( ¯wt))))]∥"
REFERENCES,0.46102819237147596,≤E∥[θt + η2(g2(ut+1) −∇g3(θt))] −[θ∗(h( ¯wt)) + η2(g2(h( ¯wt)) −∇g3(θ∗(h( ¯wt))))]∥2
REFERENCES,0.4626865671641791,"+ η2
2E∥g2(ut+1; S1 ∪S2) −g2(ut+1)∥2"
REFERENCES,0.46434494195688225,"≤E∥[θt + η2(g2(ut+1) −∇g3(θt))] −[θ∗(h( ¯wt)) + η2(g2(h( ¯wt)) −∇g3(θ∗(h( ¯wt))))]∥2 + η2
2σ2,
(11)
where
E∥[θt + η2(g2(ut+1) −∇g3(θt))] −[θ∗(h( ¯wt)) + η2(g2(h( ¯wt)) −∇g3(θ∗(h( ¯wt))))]∥2"
REFERENCES,0.4660033167495854,"= E∥θt −θ∗(h( ¯wt))∥2 + η2
2E∥[g2(ut+1) −∇g3(θt)] −[g2(h( ¯wt)) −∇g3(θ∗(h( ¯wt)))]∥2"
REFERENCES,0.46766169154228854,"+ 2η2⟨θt −θ∗(h( ¯wt)), [g2(ut+1) −∇g3(θt)] −[g2(h( ¯wt)) −∇g3(θ∗(h( ¯wt)))]⟩"
REFERENCES,0.4693200663349917,"≤E∥θt −θ∗(h( ¯wt))∥2 + 2η2
2C2
g2E∥ut+1 −h( ¯wt)∥2 + 2η2
2L2
g3E∥θt −θ∗(h( ¯wt))∥2 + η2λ"
REFERENCES,0.4709784411276949,4 E∥θt −θ∗(h( ¯wt))∥2 + 4η2
REFERENCES,0.472636815920398,"λ C2
g2E∥ut+1 −h( ¯wt)∥2 −2η2λE∥θt −θ∗(h( ¯wt))∥2"
REFERENCES,0.47429519071310117,≤(1 −η2λ)E∥θt −θ∗(h( ¯wt))∥2 + 8η2
REFERENCES,0.4759535655058043,"λ C2
g2E∥ut+1 −h( ¯wt)∥2, (12)"
REFERENCES,0.47761194029850745,Published as a conference paper at ICLR 2022
REFERENCES,0.4792703150912106,"where the ﬁrst inequality uses strong monotone inequality as g3(·) is λ-strongly convex and the
second inequality uses η2 ≤min{
λ
8L2g3 , 2"
REFERENCES,0.48092868988391374,"λ}. Then,"
REFERENCES,0.48258706467661694,E∥θt+1 −θ∗(h( ¯wt+1))∥2
REFERENCES,0.4842454394693201,≤(1 + η2λ
REFERENCES,0.4859038142620232,"2 )E∥θt+1 −θ∗(h( ¯wt))∥2 + (1 +
2
η2λ)E∥θ∗(h( ¯wt)) −θ∗(h( ¯wt+1))∥2"
REFERENCES,0.48756218905472637,≤(1 + η2λ
REFERENCES,0.4892205638474295,2 )(1 −η2λ)E∥θt −θ∗(h( ¯wt))∥2 + (1 + η2λ
REFERENCES,0.49087893864013266,"2 )(η2
2σ2 + 8η2"
REFERENCES,0.4925373134328358,"λ C2
g2E∥ut+1 −h( ¯wt)∥2)"
REFERENCES,0.494195688225539,"+ (1 +
2
η2λ)E∥θ∗(h( ¯wt)) −θ∗(h( ¯wt+1))∥2"
REFERENCES,0.49585406301824214,≤(1 + η2λ
REFERENCES,0.4975124378109453,"2 )(1 −η2λ)E∥θt −θ∗(h( ¯wt))∥2 + 2η2
2σ2 + 16η2"
REFERENCES,0.49917081260364843,"λ
C2
g2E∥ut+1 −h( ¯wt)∥2"
REFERENCES,0.5008291873963516,"+ 4L2
θ
η2λ E∥h( ¯wt) −h( ¯wt+1)∥2"
REFERENCES,0.5024875621890548,≤(1 −η2λ
REFERENCES,0.5041459369817579,"2 )E∥θt −θ∗(h( ¯wt))∥2 + 2η2
2σ2 + 16η2"
REFERENCES,0.5058043117744611,"λ
C2
g2E∥ut+1 −h( ¯wt)∥2 + 4L2
θ
η2λ E∥h( ¯wt) −h( ¯wt+1)∥2,"
REFERENCES,0.5074626865671642,where the third inequality is because that θ∗(·) is Lθ = Cg2
REFERENCES,0.5091210613598673,λ -Lipschitz Lin et al. (2019).
REFERENCES,0.5107794361525705,"Proof of Theorem 2. Denote by g1(h( ¯wt))
=
Exi,yi[g1(h( ¯wt); xi, yi)] and g2(h( ¯wt))
=
Exi,yi[g2(h( ¯wt); xi, yi)]. Note that ∇hΦ(h( ¯wt), θt) = ∇hg1(h( ¯wt)) + θt∇hg2(h( ¯wt)). De-
note by ∆u,t = ∥ut+1 −h( ¯wt)∥2, ∆z,t = ∥zt+1 −∇¯wh( ¯wt)⊤∇hΦ(h( ¯wt), θt)∥2 = ∥zt+1 −
∇h( ¯wt)⊤[∇hg1(h( ¯wt)) + θt∇hg2(h( ¯wt))]∥2, and δt = ∥θt −θ∗(h( ¯wt))∥2."
REFERENCES,0.5124378109452736,"Applying Lemma 1 to ut, we have"
REFERENCES,0.5140961857379768,"E[∆u,t+1] ≤(1 −β0)∆u,t + 2β2
0σ2 + C2
h
β0
∥¯wt+1 −¯wt∥2.
(13)"
REFERENCES,0.5157545605306799,"Hence we have E "" T
X"
REFERENCES,0.5174129353233831,"t=0
∆u,t # ≤E "" T
X t=0"
REFERENCES,0.5190713101160862,"∆u,t −∆u,t+1"
REFERENCES,0.5207296849087893,"β0
+ 2β0σ2(T + 1) + T
X t=0"
REFERENCES,0.5223880597014925,"C2
hη2
1c2
u∥zt+1∥2 β2
0 #"
REFERENCES,0.5240464344941956,".
(14) and E"
REFERENCES,0.5257048092868989,"""T +1
X"
REFERENCES,0.527363184079602,"t=1
∆u,t # ≤E "" T
X t=0"
REFERENCES,0.5290215588723052,"∆u,t −∆u,t+1"
REFERENCES,0.5306799336650083,"β0
+ 2β0σ2(T + 1) + T
X t=0"
REFERENCES,0.5323383084577115,"C2
hη2
1c2
u∥zt+1∥2 β2
0 #"
REFERENCES,0.5339966832504146,".
(15)"
REFERENCES,0.5356550580431177,"Deﬁne
et = (1 −β1)(∇¯wh( ¯wt)⊤∇hΦ(h( ¯wt), θ∗(h( ¯wt))) −∇¯wh( ¯wt−1)⊤∇hΦ(h( ¯wt−1), θ∗( ¯wt−1)))."
REFERENCES,0.5373134328358209,"We have
∥et∥2 ≤2(1 −β1)2[(C2
g1 + D2C2
g2)C2
h + C2
h(L2
g1 + D2L2
g2)](∥¯wt −¯wt−1∥2 + ∥θ∗(h( ¯wt)) −θ∗(h( ¯wt−1))∥2)
and
E∥zt+1 −∇¯
wh( ¯wt)⊤∇hΦ(h( ¯wt), θ∗(h( ¯wt))) + et∥2"
REFERENCES,0.538971807628524,"≤E∥(1 −β1)[zt −∇¯
wh( ¯wt−1)⊤∇hΦ(h( ¯wt−1), θ∗(h( ¯wt−1)))]"
REFERENCES,0.5406301824212272,"+ β1[∇¯
wh( ¯wt; S1)∇uΦ(ut+1, θt; S2) −∇¯
wh( ¯wt)⊤∇hΦ(ut+1, θt)]"
REFERENCES,0.5422885572139303,"+ β1[∇¯
wh( ¯wt)⊤∇hΦ(ut+1, θt) −∇¯
wh( ¯wt)⊤∇hΦ(h( ¯wt), θ∗(h( ¯wt)))]∥2"
REFERENCES,0.5439469320066335,"≤E∥(1 −β1)[zt −∇¯
wh( ¯wt−1)⊤∇hΦ(h( ¯wt−1), θ∗(h( ¯wt−1)))]"
REFERENCES,0.5456053067993366,"+ β1[∇¯
wh( ¯wt)⊤∇hΦ(ut+1, θt) −∇¯
wh( ¯wt)⊤∇hΦ(h( ¯wt), θ∗(h( ¯wt)))]∥2"
REFERENCES,0.5472636815920398,"+ β2
1E∥∇¯
wh( ¯wt; S1)∇uΦ(ut+1, θt; S2) −∇¯
wh( ¯wt)⊤∇hΦ(ut+1, θt)∥2"
REFERENCES,0.548922056384743,≤(1 + β1
REFERENCES,0.5505804311774462,"2 )(1 −β1)2E∥zt −∇¯
wh( ¯wt−1)⊤∇hΦ(h( ¯wt−1), θ∗(h( ¯wt−1)))∥2"
REFERENCES,0.5522388059701493,+ (1 + 2
REFERENCES,0.5538971807628524,"β1 )2β2
1E∥∇¯
wh( ¯wt)⊤∇hΦ(ut+1, θt) −∇¯
wh( ¯wt)⊤∇hΦ(h( ¯wt), θt)∥2"
REFERENCES,0.5555555555555556,+ (1 + 2
REFERENCES,0.5572139303482587,"β1 )2β2
1E∥∇¯
wh( ¯wt)⊤∇hΦ(h( ¯wt), θt) −∇¯
wh( ¯wt)⊤∇hΦ(h( ¯wt), θ∗(h( ¯wt)))∥2"
REFERENCES,0.5588723051409619,"+ β2
1E∥∇¯
wh( ¯wt; S1)⊤∇uΦ(ut+1, θt; S2) −∇¯
wh( ¯wt)⊤∇hΦ(ut+1, θt)∥2, (16)"
REFERENCES,0.560530679933665,Published as a conference paper at ICLR 2022
REFERENCES,0.5621890547263682,"where the last three terms can be bounded as below. First,
E∥∇¯wh( ¯wt)⊤∇hΦ(ut+1, θt) −∇¯wh( ¯wt)⊤∇hΦ(h( ¯wt), θt)∥2"
REFERENCES,0.5638474295190713,"≤2C2
h(L2
g1 + L2
g2)E∥ut+1 −h( ¯wt)∥2.
(17)"
REFERENCES,0.5655058043117744,"Second,
E∥∇¯wh( ¯wt)⊤∇hΦ(h( ¯wt), θt) −∇¯wh( ¯wt)⊤∇hΦ(h( ¯wt), θ∗(h( ¯wt)))∥2"
REFERENCES,0.5671641791044776,"≤C2
hC2
g2E∥θt −θ∗(h( ¯wt))∥2.
(18)"
REFERENCES,0.5688225538971807,"Third,
E∥∇¯wh( ¯wt; S1)⊤∇uΦ(ut+1, θt; S2) −∇¯wh( ¯wt)⊤∇hΦ(ut+1, θt)∥2"
REFERENCES,0.5704809286898839,"≤8σ2(C2
h + D2C2
h + σ2) + 4C2
h(σ2 + D2σ2) = 4σ2(3C2
h + 3D2C2
h + 2σ2).
(19)"
REFERENCES,0.572139303482587,"It follows that
∥zt+1 −∇¯
wh( ¯wt)⊤∇hΦ(h( ¯wt), θ∗(h( ¯wt)))∥2"
REFERENCES,0.5737976782752903,≤(1 + β1
REFERENCES,0.5754560530679934,"2 )E∥zt+1 −∇¯
wh( ¯wt)⊤∇hΦ(h( ¯wt), θ∗(h( ¯wt))) + et∥2 + (1 + 2"
REFERENCES,0.5771144278606966,β1 )∥et∥2
REFERENCES,0.5787728026533997,≤(1 + β1
REFERENCES,0.5804311774461028,"2 )2(1 −β1)2E∥zt −∇¯
wh( ¯wt−1)∇hΦ(h( ¯wt−1), θt−1))∥2"
REFERENCES,0.582089552238806,"+ 32β1C2
h(L2
g1 + L2
g2)E∥ut+1 −h( ¯wt)∥2 + 16β1E∥θt −θ∗(h( ¯wt))∥2"
REFERENCES,0.5837479270315091,"+ 8β2
1σ2(3C2
h + 3D2C2
h + 2σ2) + 4"
REFERENCES,0.5854063018242123,β1 ∥et∥2
REFERENCES,0.5870646766169154,"≤(1 −β1)E∥zt −∇¯
wh( ¯wt−1)∇hΦ(h( ¯wt−1), θt−1))∥2 + β1C1E∥ut+1 −h( ¯wt)∥2"
REFERENCES,0.5887230514096186,"+ 16β1E∥θt −θ∗(h( ¯wt))∥2 + β2
1C2 + C3"
REFERENCES,0.5903814262023217,β1 E∥¯wt −¯wt−1∥2. (20)
REFERENCES,0.5920398009950248,"where C: = 32C2
h(L2
g1 +L2
g2), C2 := 8σ2(3C2
h+3D2C2
h+2σ2) and C3 := 8[(C2
g1 +D2C2
g2)C2
h+
C2
h(L2
g1 + D2L2
g2)]. Thus, E "" T
X"
REFERENCES,0.593698175787728,"t=0
∆z,t #"
REFERENCES,0.5953565505804311,"≤E
∆z,0"
REFERENCES,0.5970149253731343,"β1
+ C1"
REFERENCES,0.5986733001658375,"T +1
X"
REFERENCES,0.6003316749585407,"t=1
∆u,t + 16"
REFERENCES,0.6019900497512438,"T +1
X"
REFERENCES,0.603648424543947,"t=1
δt + β1C2(T + 1) + C3η2
1c2
u
β2
1 T
X"
REFERENCES,0.6053067993366501,"t=0
∥zt+1∥2.
"
REFERENCES,0.6069651741293532,"Using Lemma 3, we have T
X"
REFERENCES,0.6086235489220564,"t=0
δt ≤
2
η2λE∥θ0 −θ∗(h( ¯w0))∥2 + 4η2σ2(T + 1)"
REFERENCES,0.6102819237147595,"λ
+ 32"
REFERENCES,0.6119402985074627,"λ2 C2
g2 T
X"
REFERENCES,0.6135986733001658,"t=0
E[∆u,t] + 8L2
θC2
hη2
1c2
u
η2
2λ2 T
X"
REFERENCES,0.615257048092869,"t=0
E∥zt+1∥2,"
REFERENCES,0.6169154228855721,"and
T +1
X"
REFERENCES,0.6185737976782753,"t=1
δt ≤
2
η2λE∥θ0 −θ∗(h( ¯w0))∥2 + 4η2σ2(T + 1)"
REFERENCES,0.6202321724709784,"λ
+ 32"
REFERENCES,0.6218905472636815,"λ2 C2
g2 T
X"
REFERENCES,0.6235489220563848,"t=0
E[∆u,t] + 8L2
θC2
hη2
1c2
u
η2
2λ2 T
X"
REFERENCES,0.6252072968490879,"t=0
E∥zt+1∥2"
REFERENCES,0.6268656716417911,Combining the upper bound of P
REFERENCES,0.6285240464344942,"t ∆z,t, P"
REFERENCES,0.6301824212271974,"t ∆u,t, P"
REFERENCES,0.6318407960199005,"t δt and Lemma 2, we have"
REFERENCES,0.6334991708126037,"E

T
X"
REFERENCES,0.6351575456053068,"t=0
∥∇F( ¯wt)∥2

≤
2
η1cl T
X"
REFERENCES,0.6368159203980099,"t=0
E(F( ¯wt) −F( ¯wt+1)) + cu cl T
X"
REFERENCES,0.6384742951907131,"t=0
∆z,t −1 2 T
X"
REFERENCES,0.6401326699834162,"t=0
E∥zt+1∥2"
REFERENCES,0.6417910447761194,≤2E(F( ¯w0) −F∗)
REFERENCES,0.6434494195688225,"η1cl
−1 2 T
X"
REFERENCES,0.6451077943615257,"t=0
E∥zt+1∥2 + cu"
REFERENCES,0.6467661691542289,"cl E
∆z,0"
REFERENCES,0.648424543946932,"β1
+ C1"
REFERENCES,0.6500829187396352,"T +1
X"
REFERENCES,0.6517412935323383,"t=1
∆u,t + 16"
REFERENCES,0.6533996683250415,"T +1
X"
REFERENCES,0.6550580431177446,"t=1
δt + β1C2 + C3η2
1c2
u
β2
1 T
X"
REFERENCES,0.6567164179104478,"t=0
∥zt+1∥2
"
REFERENCES,0.6583747927031509,≤2E(F( ¯w0) −F∗)
REFERENCES,0.6600331674958541,"η1cl
+ cu"
REFERENCES,0.6616915422885572,"cl E
∆z,0"
REFERENCES,0.6633499170812603,"β1
+ 32"
REFERENCES,0.6650082918739635,η2λδ0 + β1C2(T + 1) + 64η2σ2(T + 1)
REFERENCES,0.6666666666666666,"λ
+ C1"
REFERENCES,0.6683250414593698,"T +1
X"
REFERENCES,0.6699834162520729,"t=1
∆u,t + 512"
REFERENCES,0.6716417910447762,"λ2 C2
g2 T
X"
REFERENCES,0.6733001658374793,"t=0
∆u,t  + T
X"
REFERENCES,0.6749585406301825,"t=0
E
cu"
REFERENCES,0.6766169154228856,"cl (C3η2
1c2
u
β2
1
) −1 2"
REFERENCES,0.6782752902155887,"
∥zt+1∥2
"
REFERENCES,0.6799336650082919,≤2E(F( ¯w0) −F∗)
REFERENCES,0.681592039800995,"η1cl
+ cu"
REFERENCES,0.6832504145936982,"cl E
∆z,0"
REFERENCES,0.6849087893864013,"β1
+ 32δ0"
REFERENCES,0.6865671641791045,"η2λ + (C1 + 512C2
g2
λ2
)∆u,0 β0 "
REFERENCES,0.6882255389718076,+ cu(T + 1)
REFERENCES,0.6898839137645107,"cl
E

β1C2 + 64η2σ2"
REFERENCES,0.6915422885572139,"λ
+ 2(C1 + 512C2
g2
λ2
)β0σ2
 + T
X"
REFERENCES,0.693200663349917,"t=0
E
cu"
REFERENCES,0.6948590381426202,"cl (C3η2
1c2
u
β2
1
+ (C1 + 512C2
g2
λ2
)C2
hη2
1c2
u
β2
0
) −1 2"
REFERENCES,0.6965174129353234,"
∥zt+1∥2
"
REFERENCES,0.6981757877280266,Published as a conference paper at ICLR 2022
REFERENCES,0.6998341625207297,Due to the setting
REFERENCES,0.7014925373134329,"η1 ≤min{
r
cl
c3uC3 β1"
REFERENCES,0.703150912106136,"2 ,
cl
c3u(C1λ2 + 512C2g2)
β0λ
2Ch
},
(21)"
REFERENCES,0.7048092868988391,"we have
cu"
REFERENCES,0.7064676616915423,"cl
(C3η2
1c2
u
β2
1
+ (C1 + 512C2
g2
λ2
)C2
hη2
1c2
u
β2
0
) −1 2"
REFERENCES,0.7081260364842454,"
≤0.
(22)"
REFERENCES,0.7097844112769486,"Hence, we have"
REFERENCES,0.7114427860696517,"1
T + 1E

T
X"
REFERENCES,0.7131011608623549,"t=0
∥∇F(xt)∥2

≤2E(F( ¯w0) −F∗)"
REFERENCES,0.714759535655058,"η1clT
+ cu"
REFERENCES,0.7164179104477612,"clT E
∆z,0"
REFERENCES,0.7180762852404643,"β1
+ 32δ0"
REFERENCES,0.7197346600331676,"η2λ + (C1 + 512C2
g2
λ2
)∆u,0 β0  + cu"
REFERENCES,0.7213930348258707,"cl E

β1C2 + 64η2σ2"
REFERENCES,0.7230514096185738,"λ
+ 2(C1 + 512C2
g2
λ2
)β0σ2

."
REFERENCES,0.724709784411277,"With β0 = O(1/
√"
REFERENCES,0.7263681592039801,"T), β1 = O(1/
√"
REFERENCES,0.7280265339966833,"T), and η2 = O(1/
√"
REFERENCES,0.7296849087893864,"T), we have"
REFERENCES,0.7313432835820896,"1
T + 1E

T
X"
REFERENCES,0.7330016583747927,"t=0
∥∇F(xt)∥2

≤O( 1
√ T
)."
REFERENCES,0.7346600331674958,"Table 7: Testing performance on benchmark datasets and ImageNet-LT. The percentage number is
the second row denotes the imbalanced ratio (cf the text). All experiments on benchmark datasets are
averaged over three runs with different random seeds. The network structure used in all experiments
is ResNet32."
REFERENCES,0.736318407960199,"Datasets
For Accuracy Maximization
Method
1%
10%
CE
0.713±0.001
0.876±0.002
LDAM [Cao et al. (2019)]
0.744±0.003
0.872±0.002
TS-DRW [Cao et al. (2019)]
0.780±0.003
0.879±0.000
TS-DEC [Kang et al. (2019)]
0.758±0.016
0.842±0.004"
REFERENCES,0.7379767827529021,CIFAR10 (LT)
REFERENCES,0.7396351575456053,"CT (CB-LDAM)
0.787±0.001
0.883±0.001
CE
0.396±0.002
0.572±0.000
LDAM [Cao et al. (2019)]
0.407±0.004
0.559±0.003
TS-DRW [Cao et al. (2019)]
0.427±0.006
0.579±0.001
TS-DEC [Kang et al. (2019)]
0.403±0.003
0.536±0.001"
REFERENCES,0.7412935323383084,CIFAR100 (LT)
REFERENCES,0.7429519071310116,"CT (CB-LDAM)
0.430±0.005
0.585±0.002
CE
0.441±0.017
0.639±0.009
LDAM [Cao et al. (2019)]
0.440±0.010
0.641±0.008
TS-DRW [Cao et al. (2019)]
0.458±0.006
0.651±0.017
TS-DEC [Kang et al. (2019)]
0.457±0.013
0.629±0.009"
REFERENCES,0.7446102819237148,STL10 (LT)
REFERENCES,0.746268656716418,"CT (CB-LDAM)
0.488±0.012
0.662±0.005
CE [Jamal et al. (2020)]
0.2526
CB-CE [Cui et al. (2019)]
0.2659
ImageNet (LT)"
REFERENCES,0.7479270315091211,"CT (CB-CE)
0.2661"
REFERENCES,0.7495854063018242,"D
COMPOSITIONAL TRAINING WITH CLASS WEIGHTED LOSS"
REFERENCES,0.7512437810945274,"In this section, we extend the compositional training method to deep learning with class weighted
loss. Let LCW(w) denote a class weighted loss written as:"
REFERENCES,0.7529021558872305,"LCW(w) = 1 n n
X"
REFERENCES,0.7545605306799337,"i=1
pyiℓ(w; xi, yi),
(23)"
REFERENCES,0.7562189054726368,"where pyi ∈(0, 1) denotes a weight assigned to the i-th example that depends on the class the data
belongs to. There are different methods for determining the class-level weight. A simple method
is to set pi according to the reciprocal of its corresponding class size, i.e., pyi = 1/nyi. Recently,
Cui et al. (2019) proposed an improved variant of class-weighted loss by using an effective number
of samples per-class instead of the class size to compute the individual weight, i.e., pyi =
1−γ
1−γnyi ,
where γ ∈(0, 1) is a hyper-parameter. We refer to the class weighted loss using these individual
weights as LCB(w) = 1/n Pn
i=1
1−γ
1−γnyi ℓ(w; xi, yi)."
REFERENCES,0.75787728026534,Published as a conference paper at ICLR 2022
REFERENCES,0.7595356550580431,"With Class-Weighted Losses. The corresponding compositional objective is a standard two-level
compositional function, i.e.,
min
w∈Rd F(w) = LCW(w −α∇LAVG(w)).
(24)"
REFERENCES,0.7611940298507462,"Assuming that the stochastic gradient of LCW can be easily computed, the optimization of the above
problem is easier than that for AUC loss."
REFERENCES,0.7628524046434494,"We present a simpliﬁed stochastic adaptive algorithm with an Adam-style adaptive step size in Algo-
rithm 2 referred to as SCA, where ht(O0, . . . , Ot) denotes an appropriate mapping function, which
can be implemented by using different methods, including Adam, AMSGrad, Adabound, etc. Notice
that when ht(·) = 1 Algorithm 2 becomes the NASA algorithm (Ghadimi et al., 2020) to stochastic
compositional optimization. We present an informal convergence of Algorithm 2 below.
Theorem 3. (Informal) Under appropriate conditions on the loss functions LAVG, LCW and
ℓ(w; x, y), with β0, β1, η = O(1/
√"
REFERENCES,0.7645107794361525,"T), Algorithm 2 ensures that E
h
1
T +1
PT
t=0 ∥∇F(wt)∥2i
≤"
REFERENCES,0.7661691542288557,"O( 1
√"
REFERENCES,0.7678275290215588,"T ).
Remark: The appropriate conditions include the Lipschitz continuous conditions on LAVG and
LCW and bounded variance conditions of ∇ℓ(w; xi, yi) and ∇2ℓ(w; xi, yi). We will present the
detailed conditions below when proving the above theorem. The above theorem indicates that we
can optimize the compositional objective (24) with the same convergence rate as optimizing the
averaged loss (1) for deep learning."
REFERENCES,0.7694859038142621,"D.1
EXPERIMENTS WITH MULTI-CLASS DATASETS"
REFERENCES,0.7711442786069652,"We conduct experiments on three benchmark multi-class image classiﬁcation datasets, namely CI-
FAR10, CIFAR100, and STL10. We construct imbalanced versions of these datasets by keep their
classes but making the class sizes follow a long-tailed (LT) distribution with two imbalanced ratios
(the ratio of the size of minority class to the size of majority class) similar to (Cui et al., 2019).
We use ResNet32 as the network stucture. The weight decay is set to 2e-4 for all experiments. For
algorithms, we train a total of 200 epochs with a batch size 128 and we use step size 0.1 and de-
crease it by 10 times at at 80% and 90% of total training time. We tune the beta parameters of our
methods in a range [0.1, 0.99] with a grid search and ﬁnd that good values are around 0.9. For the
class-weighted loss, we choose the class-weighted version of the LDAM loss (Cao et al., 2019). For
baselines, we compare with optimizing the CE loss (CE), optimizing the LDAM loss (LDAM), the
two-stage method with the deferred re-weighting that optimizes the class balanced LDAM loss in
the second stage (TS-DRW) (Cao et al., 2019), the two-stage method with the decoupling trick that
optimizes the class balanced LDAM loss in the second stage (TS-DEC) (Kang et al., 2019). The
results are shown in Table 7. We can see that the proposed CT method achieves the best accuracy
on all datasets. In addition, we conduct a large-scale experiment by following Jamal et al. (2020) on
ImageNet-LT with ResNet32. We use class-balanced loss (Cui et al., 2019) as outer loss function
of our compositional objective. We use an initial learning rate of 0.1 and run a total of 90 epochs
decaying learning rate every 35 epochs by a factor of 10. Eventually, we achieve the top1 accuracy
of 26.61%, which is better than two baselines, i.e., CE(25.26%) and CBCE(26.59%)."
REFERENCES,0.7728026533996684,"D.2
ANALYSIS OF THEOREM 3"
REFERENCES,0.7744610281923715,"In the section we analyze Algorithm 2. An algorithm utilizing the adaptive step size and moving
average for nonconvex optimization has been studied in (Guo et al., 2021). But here we have to
tailor the algorithm and analysis to the considered formulation with composition. Denote st =
1/(z2,t+1 + G0), ηt = ηst. We make the following assumptions regarding the problem 24.
Assumption 3."
REFERENCES,0.7761194029850746,"• LCW(u) is CLCW-Lipschitz continuous, ∇LAVG(w) is CLAVG-Lipschitz continuous."
REFERENCES,0.7777777777777778,"• ∇LCW(u) is LLCW-Lipschitz continuous, ∇2LAVG(w) is LLAVG-Lipschitz continuous."
REFERENCES,0.7794361525704809,"• The stochastic oracle satisﬁes E∥α∇LAVG(w) −α∇LAVG(w; S)∥2 ≤σ2, E∥α∇2LAVG(w) −
α∇2LAVG(w; S)∥2 ≤σ2, E∥∇LCW(u) −∇LCW(u; S)∥2 ≤σ2."
REFERENCES,0.7810945273631841,We formally present Theorem 3 as follows
REFERENCES,0.7827529021558872,Published as a conference paper at ICLR 2022
REFERENCES,0.7844112769485904,Algorithm 2 Stochastic Compositional Adaptive (SCA) method for solving (24)
REFERENCES,0.7860696517412935,"1: Require Parameters: β0, β1, α, G0, η
2: Initialization: w0 ∈Rd, z0, u0
3: for t = 0, 1, ..., T do
4:
Sample three sets of examples denoted by S1, S2
5:
ut+1 = (1 −β0)ut + β0(wt −α∇LAVG(wt; S1))
6:
Ot = (I −α∇2LAVG(wt; S1))∇LCW(ut+1; S2)
7:
zt+1 = (1 −β1)zt + β1Ot
8:
z2,t+1 = ht(O0, . . . , Ot)
⋄ht can be implemented by that in Appendix B,
9:
wt+1 = wt −η
zt+1
√z2,t+1+G0
⋄with the simplest form ht = 1"
REFERENCES,0.7877280265339967,10: end for
REFERENCES,0.7893864013266998,"Theorem 4. Assume F(x0) −F∗≤∆F where F∗= min
x F(x). Suppose Assumptions 1 and 3"
REFERENCES,0.7910447761194029,"hold. With η ≤

√clβ1
4LF√"
REFERENCES,0.7927031509121062,"c3u ,
√clβ0
4(1+αCLAVG)√"
REFERENCES,0.7943615257048093,"C5c3u ,
cl
2c2uLF"
REFERENCES,0.7960199004975125,"
, β0 = O( 1
√"
REFERENCES,0.7976782752902156,"T ), β1 ≤O( 1
√"
REFERENCES,0.7993366500829188,"T ), and constants"
REFERENCES,0.8009950248756219,"LF = 2LLCW(1 + αCLAVG)2 + 2CLCWαLLAVG, C5 = (4L2
LAVGC2
LCW + 2(1 + αL2
LAVG)LLCW), Algorithm
2 can ensure that E"
REFERENCES,0.802653399668325,"""
1
T + 1 T
X"
REFERENCES,0.8043117744610282,"t=0
∥∇F(wt)∥2
#"
REFERENCES,0.8059701492537313,"≤O( 1
√ T
)."
REFERENCES,0.8076285240464345,"Proof of Theorem 4. By Assumption 2, we know that F(w) is smooth with coefﬁcient LF :=
2LLCW(1 + αCLAVG)2 + 2CLCWαLLAVG. We can prove that under ηLF ≤cl/(2c2
u),"
REFERENCES,0.8092868988391376,F(wt+1) ≤F(wt) + ∇F(wt)⊤(wt+1 −wt) + LF
REFERENCES,0.8109452736318408,2 ∥wt+1 −wt∥2
REFERENCES,0.8126036484245439,= F(wt) −∇F(wt)⊤(ηt ◦zt+1) + LF
REFERENCES,0.814262023217247,2 ∥ηt ◦zt+1∥2
REFERENCES,0.8159203980099502,= F(wt) + 1
REFERENCES,0.8175787728026535,2∥√ηt ◦(∇F(wt) −zt+1)∥2 −1
REFERENCES,0.8192371475953566,2∥√ηt ◦∇F(wt)∥2 + (LF
REFERENCES,0.8208955223880597,2 ∥ηt ◦zt+1∥2 −1
REFERENCES,0.8225538971807629,2∥√ηt ◦zt+1∥2)
REFERENCES,0.824212271973466,≤F(wt) + ηcu
REFERENCES,0.8258706467661692,2 ∥∇F(wt) −zt+1∥2 −ηcl
REFERENCES,0.8275290215588723,"2 ∥∇F(wt)∥2 + η2c2
uLF −ηcl"
REFERENCES,0.8291873963515755,"2
∥zt+1∥2"
REFERENCES,0.8308457711442786,≤F(wt) + ηcu
REFERENCES,0.8325041459369817,2 ∥∇F(wt) −zt+1∥2 −ηcl
REFERENCES,0.8341625207296849,2 ∥∇F(wt)∥2 −ηcl
REFERENCES,0.835820895522388,4 ∥zt+1∥2. (25)
REFERENCES,0.8374792703150912,"Denote ∆z,t = ∥zt+1 −∇F(wt)∥= ∥zt+1 −(I −α∇2LAVG(wt))∇LCW(wt −α∇LAVG(wt))∥2"
REFERENCES,0.8391376451077943,"and ∆u,t = ∥ut+1 −(wt −α∇LAVG(wt))∥2."
REFERENCES,0.8407960199004975,"Applying Lemma 1 to ut, we have"
REFERENCES,0.8424543946932007,"E[∆u,t+1] ≤(1 −β0)∆u,t + 2β2
0σ2 + (1 + αCLAVG)2"
REFERENCES,0.8441127694859039,"β0
∥wt+1 −wt∥2.
(26)"
REFERENCES,0.845771144278607,"Hence we have E "" T
X"
REFERENCES,0.8474295190713101,"t=0
∆u,t # ≤E "" T
X t=0"
REFERENCES,0.8490878938640133,"∆u,t −∆u,t+1"
REFERENCES,0.8507462686567164,"β0
+ 2β0σ2(T + 1) + T
X t=0"
REFERENCES,0.8524046434494196,"(1 + αCLAVG)2η2c2
u∥zt+1∥2 β2
0 #"
REFERENCES,0.8540630182421227,".
(27)"
REFERENCES,0.8557213930348259,"Deﬁning
et =(1 −β1)(∇F(wt) −∇F(wt−1))"
REFERENCES,0.857379767827529,=(1 −β1)[(I −α∇2LAVG(wt))∇LCW(wt −∇LAVG(wt))
REFERENCES,0.8590381426202321,"−(I −α∇2LAVG(wt−1))∇LCW(wt−1 −∇LAVG(wt−1))], (28)"
REFERENCES,0.8606965174129353,"we get
∥et∥2 ≤(1 −β1)2L2
F ∥wt −wt−1∥2.
(29)"
REFERENCES,0.8623548922056384,Published as a conference paper at ICLR 2022
REFERENCES,0.8640132669983416,"It holds that
E∥zt+1 −∇F(wt) + et∥2 ≤E∥(1 −β1)(zt −∇F(wt−1)) + β1((I −α∇2LAVG(wt; S1))∇f(ut+1; S2) −F(wt))∥2"
REFERENCES,0.8656716417910447,= E∥(1 −β1)[zt −∇F(wt−1)]
REFERENCES,0.867330016583748,+ β1[(I −α∇2LAVG(wt; S1))∇LCW(ut+1; S2) −(I −α∇2LAVG(wt))∇LCW(ut+1)
REFERENCES,0.8689883913764511,+ (I −α∇2LAVG(wt))∇LCW(ut+1) −(I −α∇2LAVG(wt))∇LCW(wt −∇LAVG(wt))]∥2
REFERENCES,0.8706467661691543,= E[(1 −β1)2∥zt −∇F(wt−1)∥2]
REFERENCES,0.8723051409618574,"+ β2
1E∥(I −α∇2LAVG(wt; S1))∇LCW(ut+1; S2) −(I −α∇2LAVG(wt))∇LCW(ut+1)"
REFERENCES,0.8739635157545605,+ (I −α∇2LAVG(wt))∇LCW(ut+1) −(I −α∇2LAVG(wt))∇LCW(wt −∇LAVG(wt))∥2
REFERENCES,0.8756218905472637,+ 2(1 −β1)β1E[(zt −∇F(wt−1))⊤((I −α∇2LAVG(wt; S1))∇LCW(ut+1; S2) −(I −α∇2LAVG(wt))∇LCW(ut+1))]
REFERENCES,0.8772802653399668,+ 2(1 −β1)β1E[(zt −∇F(wt−1))⊤((I −α∇2LAVG(wt))∇LCW(ut+1) −(I −α∇2LAVG(wt))∇LCW(wt −α∇LAVG(wt)))]
REFERENCES,0.87893864013267,≤E[(1 −β1)2∥zt −∇F(wt−1)∥2]
REFERENCES,0.8805970149253731,"+ 2β2
1E∥(I −α∇2LAVG(wt; S1))∇LCW(ut+1; S2) −(I −α∇2LAVG(wt))∇LCW(ut+1)∥2"
REFERENCES,0.8822553897180763,"+ 2β2
1E∥(I −α∇2LAVG(wt))∇LCW(ut+1) −(I −α∇2LAVG(wt))∇LCW(wt −α∇LAVG(wt))∥2"
REFERENCES,0.8839137645107794,+ (1 −β1)2 β1
REFERENCES,0.8855721393034826,2 E∥zt −∇F(wt−1)∥2
REFERENCES,0.8872305140961857,+ 2β1E∥(I −α∇2LAVG(wt))∇LCW(ut+1) −(I −α∇2LAVG(wt))∇LCW(wt −α∇LAVG(wt))∥2
REFERENCES,0.8888888888888888,≤(1 −β1)2(1 + β1
REFERENCES,0.8905472636815921,"2 )E∥zt −∇F(wt−1)∥2 + 4((1 + αLLAVG)2 + σ2 + C2
LCW)β2
1σ2"
REFERENCES,0.8922056384742952,"+ 4β1(1 + αLLAVG)2L2
LCW∥ut+1 −(wt −αLCW(wt))∥2"
REFERENCES,0.8938640132669984,≤(1 −β1)(1 −β1
REFERENCES,0.8955223880597015,"2 )E∥zt −∇F(wt−1)∥2 + β2
1C4σ2 + β1C5∆u,t."
REFERENCES,0.8971807628524047,"where C4 := 4((1 + αLLAVG)2 + σ2 + C2
LCW), C5 := 4(1 + αLLAVG)2L2
LCW."
REFERENCES,0.8988391376451078,It follows that
REFERENCES,0.900497512437811,∥zt+1 −∇F(wt)∥2 ≤(1 + β1
REFERENCES,0.9021558872305141,2 )E∥zt+1 −∇F(wt) + et∥2 + (1 + 2
REFERENCES,0.9038142620232172,β1 )∥et∥2
REFERENCES,0.9054726368159204,≤(1 + β1
REFERENCES,0.9071310116086235,2 )(1 −β1)(1 −β1
REFERENCES,0.9087893864013267,2 )E∥zt −∇F(wt−1)∥2 + (1 + β1
REFERENCES,0.9104477611940298,"2 )C4β2
1σ2"
REFERENCES,0.912106135986733,+ (1 + β1
REFERENCES,0.9137645107794361,"2 )C5β1∆u,t + 4"
REFERENCES,0.9154228855721394,"β1 (1 −β1)2L2
F ∥wt −wt−1∥2"
REFERENCES,0.9170812603648425,"≤(1 −β1)E∥zt −∇F(wt−1)∥2 + 2C4β2
1σ2"
REFERENCES,0.9187396351575456,"+ 2C5β1∆u,t + 4"
REFERENCES,0.9203980099502488,"β1 L2
F ∥wt −wt−1∥2. (30) Thus, E "" T
X"
REFERENCES,0.9220563847429519,"t=0
∆z,t # ≤E ""
T
X t=0"
REFERENCES,0.9237147595356551,"∆z,t −∆z,t+1"
REFERENCES,0.9253731343283582,"β1
+ 2C4β1σ2(T + 1) + 4L2
F
β2
1
η2c2
u∥zt+1∥2 + 2C5 T
X"
REFERENCES,0.9270315091210614,"t=0
∆u,t # ≤E "" T
X t=0"
REFERENCES,0.9286898839137645,"∆z,t −∆z,t+1"
REFERENCES,0.9303482587064676,"β1
+ 2C4β1σ2(T + 1) + 4L2
F
β2
1
η2c2
u∥zt+1∥2 +2C5E "" T
X t=0"
REFERENCES,0.9320066334991708,"∆u,t −∆u,t+1"
REFERENCES,0.9336650082918739,"β0
+ 2β0σ2(T + 1) + T
X t=0"
REFERENCES,0.9353233830845771,"(1 + αCLAVG)2η2c2
u∥zt+1∥2 β2
0 ## . (31)"
REFERENCES,0.9369817578772802,Published as a conference paper at ICLR 2022
REFERENCES,0.9386401326699834,"Combining this with (25), we obtain ηcl"
E,0.9402985074626866,"2 E "" T
X"
E,0.9419568822553898,"t=0
∥∇F(wt)∥2
#"
E,0.9436152570480929,"≤F(w0) −F∗− T
X t=0 ηcl"
E,0.945273631840796,"4 ∥zt+1∥2 + T
X t=0 ηcu"
E,0.9469320066334992,"2 ∆z,t"
E,0.9485903814262023,"≤∆F + ηcu 2 T
X t=0"
E,0.9502487562189055,"∆z,t −∆z,t+1"
E,0.9519071310116086,"β1
+ 2C5
∆u,t −∆u,t+1 β0  + ηcu"
E,0.9535655058043118,2 [2C4β1 + 4C5β0]σ2(T + 1)
E,0.9552238805970149,"+
ηcu 2"
E,0.956882255389718,"4L2
F η2c2
u
β2
1
+ 2C5(1 + αCLAVG)2η2c2
u
β2
0"
E,0.9585406301824212,"
−ηcl 4 
T
X"
E,0.9601990049751243,"t=0
∥zt+1∥2. (32)"
E,0.9618573797678275,Due to the setting η ≤
E,0.9635157545605307,( √clβ1
"LF
P",0.9651741293532339,"4LF
p"
"LF
P",0.966832504145937,"c3u
,
√clβ0
4(1 + αCLAVG)
p C5c3u )"
"LF
P",0.9684908789386402,",
(33)"
"LF
P",0.9701492537313433,"we have
ηcu 2"
"LF
P",0.9718076285240465,"4L2
F η2c2
u
β2
1
+ 2C5(1 + αCLAVG)2η2c2
u
β2
0"
"LF
P",0.9734660033167496,"
−ηcl 4"
"LF
P",0.9751243781094527,"
≤0.
(34) Thus, E"
"LF
P",0.9767827529021559,"""
1
T + 1 T
X"
"LF
P",0.978441127694859,"t=0
∥∇F(wt)∥2
# ≤2∆F"
"LF
P",0.9800995024875622,ηclT + cu cl
"LF
P",0.9817578772802653,"E[∆z,0]"
"LF
P",0.9834162520729685,"β1T
+ 2C5
E[∆u,0] β0T"
"LF
P",0.9850746268656716,"
+ cu"
"LF
P",0.9867330016583747,"cl
[2C4β1 + 4C5β0]σ2."
"LF
P",0.988391376451078,"(35)
With β0 = O( 1
√"
"LF
P",0.9900497512437811,"T ), β1 = O( 1
√"
"LF
P",0.9917081260364843,"T ) and η = O( 1
√ T ), E"
"LF
P",0.9933665008291874,"""
1
T + 1 T
X"
"LF
P",0.9950248756218906,"t=0
∥∇F(wt)∥2
#"
"LF
P",0.9966832504145937,"≤O( 1
√"
"LF
P",0.9983416252072969,"T
).
(36)"
