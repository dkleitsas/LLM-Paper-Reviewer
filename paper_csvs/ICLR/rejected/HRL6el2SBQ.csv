Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0018083182640144665,"Deep neural networks have found widespread adoption in solving image recognition
and natural language processing tasks. However, they make conﬁdent mispredic-
tions when presented with data that does not belong to the training distribution, i.e.
out-of-distribution (OoD) samples. Inter-class mixup has been shown to improve
model calibration aiding OoD detection. However, we show that both empirical risk
minimization and inter-class mixup create large angular spread in latent representa-
tion. This reduces the separability of in-distribution data from OoD data. In this
paper we propose intra-class mixup supplemented with angular margin to improve
OoD detection. Angular margin is the angle between the decision boundary normal
and sample representation. We show that intra-class mixup forces the network to
learn representations with low angular spread in the latent space. This improves
the separability of OoD from in-distribution examples. Our approach when applied
to various existing OoD detection techniques shows an improvement of 4.68% and
6.08% in AUROC performance over empirical risk minimization and inter-class
mixup, respectively. Further, our approach aided with angular margin improves
AUROC performance by 7.36% and 9.10% over empirical risk minimization and
inter-class mixup, respectively."
INTRODUCTION,0.003616636528028933,"1
INTRODUCTION"
INTRODUCTION,0.0054249547920434,"Deep Learning has been employed by many state of the art machine learning models to effectively
solve image recognition (Krizhevsky et al., 2012; LeCun et al., 2015) and natural language processing
(Andor et al., 2016) tasks. Despite their effectiveness, recent research has shown the existence of
inputs (Goodfellow et al., 2015b; Nguyen et al., 2015) that lead these networks to make conﬁdent
mispredictions. Two classes of such inputs have emerged in literature. The ﬁrst class, adversarial
examples (Bruna et al., 2014; Goodfellow et al., 2015a; Kurakin et al., 2017), are speciﬁcally crafted
inputs with the intent of fooling deep neural nets. The second class dubbed Out-of-Distribution (OoD)
(Nguyen et al., 2015) examples are examples that do not belong to the underlying true distribution
that the training dataset is drawn from. High conﬁdence of the networks on such OoD examples
makes it difﬁcult to identify false classiﬁcations and poses a challenge to their deployment in safety
critical scenarios (Amodei et al., 2016), from medical diagnosis to self driving applications."
INTRODUCTION,0.007233273056057866,"To address this problem several methods have been proposed which aim to identify out-of-distribution
samples. In the context of deep learning, OoD detection methods can be broadly classiﬁed into two
categories, generative and discriminative methods. Generative methods use various techniques such
as Gaussian Discriminant Analysis (Lee et al., 2018b), Generative Adversarial Networks (GANs)
(Deecke et al., 2018; Lee et al., 2018a; Ren et al., 2019) or more generic generative methods (Wang
et al., 2017) to model the underlying distribution and separate in-distribution samples from OoD
samples. On the other hand, discriminative methods (Hendrycks & Gimpel, 2017; Hendrycks et al.,
2019; Hsu et al., 2020; Liang et al., 2018; Liu et al., 2020) detect OoD samples based on measures
such as softmax probability (Hendrycks & Gimpel, 2017; Hendrycks et al., 2019), energy scores (Liu
et al., 2020) or other metrics computed from the trained network. Most of these metrics are a proxy
for the distance of the sample representation from the decision boundary (l2 margin in Figure 1a).
Further, we show that existing techniques such as empirical risk minimization (ERM) and inter-class
mixup (Zhang et al., 2018) result in networks learning representations that have large spread. This
large spread creates broad overlapping representations for in-distribution and OoD data, making it
hard to separate in-distribution data from OoD data. Additionally, the use of metrics that are proxies"
INTRODUCTION,0.009041591320072333,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.0108499095840868,"for distance from decision boundary have a disadvantage when OoD points have similar margin as
in-distribution data. For example, consider point “(b) OoD” in Figure 1a where the OoD data point is
far from the class representation and has similar l2 margin as in-distribution data; this OoD point will
have similar OoD metric scores as in-distribution data. Using angular margin would help separate
OoD data in such a case. To account for these factors, we propose intra-class mixup supplemented
with angular margin (refer to Figure 1a) to improve OoD detection where angular margin is the angle
between the normal to the decision boundary and the sample representation."
INTRODUCTION,0.012658227848101266,"(a) Visualizing angular margin θ and l2 margin.
(b) Intra-class mixup."
INTRODUCTION,0.014466546112115732,"(c) Inter-class mixup.
(d) ERM."
INTRODUCTION,0.0162748643761302,"Figure 1: Visualizing improved OoD separability of intra-class mixup trained ResNet18 model.
SVHN was the in-distribution dataset and TinyImageNet was used as OoD dataset. For all the
representations un-mixed inputs were used."
INTRODUCTION,0.018083182640144666,"We show that the proposed intra-class mixup forces the network to learn latent representations
with low variance (i.e. small spread), thus improving in-distribution and OoD separability. This is
visualized in Figure 1, which plots the angular margin vs. l2 margin for in-distribution and OoD data
for ERM, inter-class mixup and intra-class mixup. Further, we show that intra-class mixup trained,
angular margin augmented OoD detector achieves on average 7.36% and 9.10% improvement in
AUROC performance over ERM and inter-class mixup, respectively."
INTRODUCTION,0.019891500904159132,In summary the contributions of this paper are as follows:
INTRODUCTION,0.0216998191681736,"• We propose intra-class mixup to improve OoD detection. We show that intra-class mixup
learnt latent space representations have lower angular spread when compared to ERM and
inter-class mixup, thus, improving separability of OoD examples. We attribute this to the
reduced input variance resulting from intra-class mixup."
INTRODUCTION,0.023508137432188065,"• We show existing discriminiative OoD detection methods that use proxies for distance from
the decision boundary beneﬁt from intra-class mixup when compared to ERM and inter-class
mixup."
INTRODUCTION,0.02531645569620253,"• We leverage better angular separability to improve OoD detection. We show that sup-
plementing angular margin with existing OoD detection scores improves OoD detection
performance on various existing techniques."
INTRODUCTION,0.027124773960216998,Under review as a conference paper at ICLR 2022
RELATED WORK,0.028933092224231464,"2
RELATED WORK"
RELATED WORK,0.03074141048824593,"In the context of deep-learning, the approaches to detect OoD examples can be broadly classiﬁed
into two categories discriminative and generative methods. Under discriminative methods recent
works (Hendrycks & Gimpel, 2017; Hendrycks et al., 2019; Hsu et al., 2020; Liang et al., 2018) have
leveraged softmax probability scores to detect anomalous examples. The authors of Hendrycks &
Gimpel (2017) presented their results on using softmax scores to detect OoD examples on several
machine learning tasks. The idea of utilizing softmax scores was further extended in Hendrycks et al.
(2019) by modifying the standard loss function used to train the classiﬁer. The network was trained
on an in-distribution dataset as well as an additional auxiliary or outlier dataset. The authors claim
that such outlier exposure enables the detector to generalize and detect unseen anomalies. Further, the
authors also observed characteristic properties of the auxiliary dataset which help improve detection
performance. Another approach that leverages softmax scores are the ODIN (Hsu et al., 2020; Liang
et al., 2018) techniques, which showed improvement to OoD detection without having to explicitly
tune the out-of-distribution dataset which the authors argue is generally hard to deﬁne a priori. The
authors proposed decomposing the conﬁdence score and modifying the input pre-processing method.
Other recent work under the discriminative techniques proposed the use of energy score (Liu et al.,
2020) instead of softmax scores arguing that softmax based approaches suffer from overconﬁdent
posterior distributions for out-of-distribution samples. They claim that energy scores are theoretically
aligned with the probability density of the inputs and is therefore less likely to result in overconﬁdent
predictions. Further, in a non deep learning context angular distance based approaches (Kriegel et al.,
2008) have been successfully used in literature to avoid the curse of dimensionality."
RELATED WORK,0.0325497287522604,"Generative methods attempt to model the underlying true distribution and hence, identify samples
outside the modelled distribution. The authors of Lee et al. (2018b) proposed a technique that
modelled a class conditional Gaussian distribution with respect to features of the deep network
and used a Mahalanobis distance based conﬁdence score calculated from the Gaussian model to
detect OoD examples. In Lee et al. (2018a) the authors proposed the use of Generative Adversarial
Networks (GANs) (Goodfellow et al., 2014) to generate OoD samples to improve OoD detector
training. They proposed two additional loss terms that were added to the original loss function. One
of the proposed terms forced the classiﬁer to be less conﬁdent on OoD samples while the other helped
generate more effective OoD examples. Another work that investigated a generative model based
approach for OoD detection was Ren et al. (2019) which proposed a likelihood ratio method which
corrected for background statistics and achieved competitive performance on vision and sequence
classiﬁcation tasks. Approaches under both categories have focused on networks trained using
Empirical Risk Minimization (ERM) which has been observed to result in undesirable behaviors
such as memorization (Zhang et al., 2016) and sensitivity outside the training examples (Bruna et al.,
2014). Inter-class mixup (Zhang et al., 2018) has been shown to be effective against such undesirable
behaviours (Zhang et al., 2018; Thulasidasan et al., 2019) and has been shown to improve calibration
and OoD performance (Thulasidasan et al., 2019). However, we show that inter-class mixup and
ERM trained networks learn representations with large variance (i.e. large spread), impacting their
OoD detection performance. To counter this effect, in this paper we propose intra-class mixup aided
with angular margin for improving OoD detection."
BACKGROUND,0.034358047016274866,"3
BACKGROUND"
BACKGROUND,0.03616636528028933,"In-distribution. The training and testing samples used for a machine learning task are drawn from
some underlying distribution, also called the true distribution. The samples from this underlying true
distribution are called in-distribution samples and are represented by Din in this work. However, in
most practical learning scenarios the true distribution is unknown a priori and hence, the training
distribution, Dtrain, is used as a proxy for Din."
BACKGROUND,0.0379746835443038,"Out-of-distribution. A sample is said to be Out-of-distribution (OoD) if it does not belong to the
underlying true distribution Din, and is denoted by Dout. Since we do not have access to the true
underlying distribution, for our experiments we use uniform noise, Gaussian noise and samples from
other datasets for similar tasks as a proxy for Out-of-distribution samples or Dout. This is common
practice in literature (Hendrycks & Gimpel, 2017; Hendrycks et al., 2019; Hsu et al., 2020; Lee et al.,
2018b; Liang et al., 2018)."
BACKGROUND,0.039783001808318265,Under review as a conference paper at ICLR 2022
BACKGROUND,0.04159132007233273,"Empirical Risk Minimization (ERM). The objective of learning algorithms, when the true underly-
ing distribution is known, is to learn an optimal mapping f(.) from the input x to an output y, where
(x, y) ∼Din. This objective is satisﬁed by learning a function f(.) that minimizes a loss function
L(f(x), y) over the entire distribution. We can compute the expectation of the loss function as shown
in Equation 1. This is know as expected risk."
BACKGROUND,0.0433996383363472,"Rexpected
= Ex,y∼Din[L(f(x), y)]
(1)"
BACKGROUND,0.045207956600361664,"As in most realistic scenarios, we do not have access to the true data distribution, and hence, it is
common to use available empirical data as proposed in Vapnik (1998) to approximate the expected
risk. This form of approximation, presented in Equation 2, is know as Empirical Risk Minimization
(ERM)."
BACKGROUND,0.04701627486437613,"Rempirical
= 1 Ne Ne
P"
BACKGROUND,0.048824593128390596,"i=1
L(f(xi), yi)
(2)"
BACKGROUND,0.05063291139240506,"where (xi, yi) ∼Dtrain and Ne is the number of training samples in Dtrain."
METHODOLOGY,0.05244122965641953,"4
METHODOLOGY"
ANGULAR MARGIN,0.054249547920433995,"4.1
ANGULAR MARGIN"
ANGULAR MARGIN,0.05605786618444846,"In this subsection we deﬁne angular margin. Angular margin θ can be described by the following
equations:"
ANGULAR MARGIN,0.05786618444846293,"n = W ˆy
c
|W ˆy
c |
(3)"
ANGULAR MARGIN,0.059674502712477394,"θ = arccos
 ainp"
ANGULAR MARGIN,0.06148282097649186,"|ainp| · n

(4)"
ANGULAR MARGIN,0.06329113924050633,"where W ˆy
c is the weight vector of the ﬁnal (classiﬁer) layer of the deep neural net (DNN) for the
predicted class ˆy, n is the unit vector orthogonal to the decision boundary1, ainp is the latent space
vector representation for the un-mixed input (i.e. activations of the penultimate layer of the DNN).
Further, we ignore the bias term when calculating the angular margin therefore W ˆy
c does not include
the bias term."
INTRA-CLASS MIXUP,0.0650994575045208,"4.2
INTRA-CLASS MIXUP"
INTRA-CLASS MIXUP,0.06690777576853527,"In this subsection we explore the properties of intra-class mixup trained deep neural nets and how
they can be leveraged to improve OoD detection performance. Inter-class mixup (Zhang et al., 2018)
is a technique that helps improve the generalization of a machine learning classiﬁer. Mixup trains a
neural net on a convex combinations of examples and their corresponding soft labels. Consider a
pair of training input, label tuples (xi, yi) and (xj, yj). Inter-class mixup obtains a new augmented
sample (ˆx, ˆy) for training the classiﬁer described by Equation 5."
INTRA-CLASS MIXUP,0.06871609403254973,"ˆx
= λ · xi + (1 −λ) · xj
ˆy
= λ · yi + (1 −λ) · yj
(5)"
INTRA-CLASS MIXUP,0.0705244122965642,"where, λ ∈[0, 1] represents the mixing parameter. In the same fashion as inter-class mixup (Zhang
et al., 2018) λ ∼Beta(α, α) and for our experiments we set α = 1. Such an augmentation scheme
forces the model to learn smooth interpolations between the samples of the training dataset. The
proposed technique of intra-class mixup imposes an additional constraint on Equation 5 such that
ˆy = yi = yj, forcing the training sample to be a convex combination of inputs within the same class.
It can be shown that the additional constraint on ˆy reduces the class conditional input variance (see
Appendix A.1)."
INTRA-CLASS MIXUP,0.07233273056057866,"1The unit vector is the decision boundary normal in case of binary classiﬁcation. In case of a multi-class
classiﬁcation, the interpretation depends on the training loss used."
INTRA-CLASS MIXUP,0.07414104882459313,Under review as a conference paper at ICLR 2022
INTRA-CLASS MIXUP,0.0759493670886076,"σ2
ˆ
X =
h
λ2 + (1 −λ)2i
σ2
X"
INTRA-CLASS MIXUP,0.07775768535262206,Since λ2 + (1 −λ)2 ≤1
INTRA-CLASS MIXUP,0.07956600361663653,"σ2
ˆ
X ≤σ2
X (6)"
INTRA-CLASS MIXUP,0.081374321880651,"where σ2
ˆ
X is the variance of the input after mixup and σ2
X is the variance of the input prior to mixup."
INTRA-CLASS MIXUP,0.08318264014466546,"Therefore intra-class mixup results in reduction of class conditional variance at the input. We observe
that deep neural nets trained on intra-class mixup learn to represent even unmixed images with lower
angular spread (i.e. reduction of the class conditional representation variance) compared to ERM or
inter-class mixup. The angular spread refers to the standard deviation of the angular margin for a
given dataset. This reduced angular spread increases the angular margin between in-distribution and
OoD samples improving OoD detection performance."
SUPPLEMENTING ANGULAR MARGIN,0.08499095840867993,"4.3
SUPPLEMENTING ANGULAR MARGIN"
SUPPLEMENTING ANGULAR MARGIN,0.0867992766726944,"In this subsection we describe how angular margin scores can be supplemented with various OoD
scores to improve detection performance. We observe from Figure 1, that traditional scores that use
the l2 margin can separate OoD data from in-distribution data. From Figure 1, this can be interpreted
as higher values along the y-axis are more likely to be OoD. But using only l2 ignores information in
the angular margin that can be used to separate in-distribution samples from OoD samples. From
Figure 1, we see that using angular margin improves separability (using two axes instead of one).
This is also observed in our experimental results (refer to Table 3 and 4). Therefore we propose
supplementing OoD score Js is given by"
SUPPLEMENTING ANGULAR MARGIN,0.08860759493670886,"Js = J + cos (θ)
(7)"
SUPPLEMENTING ANGULAR MARGIN,0.09041591320072333,"where J is the OoD score from a detector of choice, θ is the angular margin of the test sample
described in Equation 4. The OoD score J is different for different detection schemes. For MSP
(Hendrycks & Gimpel, 2017) J would be the softmax probability of the predicted class while J
would be the energy score (Liu et al., 2020) when using energy score detector, and so on. To complete
our analysis we also use “Vanilla cos (θ)” which is when Js = cos (θ). The following section details
various experiments to evaluate the performance of the proposed method."
EXPERIMENTS,0.0922242314647378,"5
EXPERIMENTS"
EXPERIMENTS,0.09403254972875226,"We perform experiments which aim to understand and show the role of intra-class mixup in improving
OoD detection performance. The experiments’ goals are summarized below"
EXPERIMENTS,0.09584086799276673,"• To show intra-class mixup trained networks learn representations that have lower angular
spread and improved angular separability (Section 5.1).
• To show intra-class mixup improves OoD detection on methods that use distance proxies
(Section 5.2).
• To show that supplemental use of angular margin improves OoD detection performance
(Section 5.3)."
SEPARABILITY,0.09764918625678119,"5.1
SEPARABILITY"
SEPARABILITY,0.09945750452079566,"In this section we provide evidence for improved OoD separability resulting from intra-class mixup.
To show that intra-class mixup improves OoD separability we evaluate the angular margin for in-
distribution and OoD examples. The improvement in separability resulting from intra-class mixup
can be observed using a separability metric S given by"
SEPARABILITY,0.10126582278481013,S = (θo −θi)2
SEPARABILITY,0.10307414104882459,"σ2o + σ2
i
(8)"
SEPARABILITY,0.10488245931283906,Under review as a conference paper at ICLR 2022
SEPARABILITY,0.10669077757685352,"where θo and θi are the angular margins for OoD data and in-distribution data respectively, σo and
σi are the angular scatter/spread (i.e. standard deviation) of the angular margin. The metric S is the
angular version of the Fisher’s criterion (Fisher et al., 1936)."
SEPARABILITY,0.10849909584086799,In-Dist
SEPARABILITY,0.11030741410488246,"Average OoD
Angular Margin (in rad)
θo ± σo"
SEPARABILITY,0.11211573236889692,"Average In-Dist.
Angular Margin (in rad)
θi ± σi"
SEPARABILITY,0.11392405063291139,"Angular Separability
(θo −θi)2"
SEPARABILITY,0.11573236889692586,"σ2o + σ2
i
ERM
Inter
Intra
ERM
Inter
Intra
ERM
Inter
Intra"
SEPARABILITY,0.11754068716094032,CIFAR-10
SEPARABILITY,0.11934900542495479,"1.4262
±
0.0587"
SEPARABILITY,0.12115732368896925,"1.2992
±
0.0585"
SEPARABILITY,0.12296564195298372,"1.4534
±
0.0478"
SEPARABILITY,0.12477396021699819,"1.2901
±
0.0779"
SEPARABILITY,0.12658227848101267,"1.1977
±
0.0480"
SEPARABILITY,0.12839059674502712,"1.3065
±
0.0730"
SEPARABILITY,0.1301989150090416,"1.9469
1.7991
2.8342"
SEPARABILITY,0.13200723327305605,CIFAR-100
SEPARABILITY,0.13381555153707053,"1.4481
±
0.0474"
SEPARABILITY,0.13562386980108498,"1.2991
±
0.0553"
SEPARABILITY,0.13743218806509946,"1.4819
±
0.0426"
SEPARABILITY,0.13924050632911392,"1.3817
±
0.0929"
SEPARABILITY,0.1410488245931284,"1.1942
±
0.1017"
SEPARABILITY,0.14285714285714285,"1.4012
±
0.0839"
SEPARABILITY,0.14466546112115733,"0.4053
0.8211
0.7355 SVHN"
SEPARABILITY,0.14647377938517178,"1.1810
±
0.1174"
SEPARABILITY,0.14828209764918626,"1.2351
±
0.0937"
SEPARABILITY,0.15009041591320071,"1.2626
±
0.0952"
SEPARABILITY,0.1518987341772152,"0.8815
±
0.1180"
SEPARABILITY,0.15370705244122965,"1.0501
±
0.0596"
SEPARABILITY,0.15551537070524413,"0.9748
±
0.1067"
SEPARABILITY,0.15732368896925858,"3.2375
2.7753
4.0507"
SEPARABILITY,0.15913200723327306,TinyImageNet
SEPARABILITY,0.1609403254972875,"1.1344
±
0.1008"
SEPARABILITY,0.162748643761302,"1.2990
±
0.0444"
SEPARABILITY,0.16455696202531644,"1.2322
±
0.0654"
SEPARABILITY,0.16636528028933092,"1.0931
±
0.1623"
SEPARABILITY,0.16817359855334538,"1.2952
±
0.0736"
SEPARABILITY,0.16998191681735986,"1.1955
±
0.1146"
SEPARABILITY,0.1717902350813743,"0.0467
0.0020
0.0774"
SEPARABILITY,0.1735985533453888,"Table 1: Separability of intra-class mixup, inter-class mixup and ERM trained models (averaged over
5 different seeds and OoD datasets) on various datasets. Intra-class mixup has better separability in
almost all cases."
SEPARABILITY,0.17540687160940324,"Table 1 shows the angular separability of empirical risk minimization (ERM), inter-class mixup
(Zhang et al., 2018) and the proposed intra-class mixup. From Table 1 we clearly see improved
OoD separability from intra-class mixup. For each in-distribution dataset in Table 1, the numbers
show the average angular margin and angular spread computed over 5 differently seeded ResNet18
networks evaluated on the test set of SVHN (Netzer et al., 2011), CIFAR-10, CIFAR-100 (Krizhevsky
et al., 2009), Places365 (Zhou et al., 2017), Textures (Cimpoi et al., 2014), LSUN (Yu et al., 2015),
TinyImageNet (Li et al.), Gaussian Noise and Uniform Noise as OoD datasets."
INTRA-CLASS MIXUP FOR OOD DETECTION,0.17721518987341772,"5.2
INTRA-CLASS MIXUP FOR OOD DETECTION"
INTRA-CLASS MIXUP FOR OOD DETECTION,0.17902350813743217,"We have seen in the previous subsection that intra-class mixup improves OoD separability. In this
subsection we provide evidence for improved OoD detection performance of intra-class mixup trained
DNNs. We present the results of applying intra-class mixup on a few unsupervised methods that
use proxies for distance from the decision boundary such as Maximum Softmax Probability (MSP)
detection (Hendrycks & Gimpel, 2017), ODIN (Liang et al., 2018) and Energy score detection (Liu
et al., 2020). To evaluate the performance of the detectors we use a variety of metrics which are
brieﬂy described in the following section."
INTRA-CLASS MIXUP FOR OOD DETECTION,0.18083182640144665,"Metrics. The performance of binary classiﬁcation algorithm can be evaluated using Recall or True
Positive Rate (TPR), False Positive Rate (FPR), Precision or a variety of other metrics. Recall (TPR),
FPR and Precision are deﬁned by equations (9), (10) and (11) respectively."
INTRA-CLASS MIXUP FOR OOD DETECTION,0.18264014466546113,"Recall = True Positive Rate (TPR)
=
TP
TP + FN
(9)"
INTRA-CLASS MIXUP FOR OOD DETECTION,0.1844484629294756,"False Positive Rate (FPR)
=
FP
FP + TN
(10)"
INTRA-CLASS MIXUP FOR OOD DETECTION,0.18625678119349007,"Precision
=
TP
TP + FP
(11)"
INTRA-CLASS MIXUP FOR OOD DETECTION,0.18806509945750452,"where, TP is True Positive, FP is False Positive, TN is True Negative and FN is False Negative.
Metrics commonly used in literature (Hendrycks & Gimpel, 2017; Hendrycks et al., 2019; Lee et al.,
2018b) to evaluate the performance of OoD detectors are:"
INTRA-CLASS MIXUP FOR OOD DETECTION,0.189873417721519,Under review as a conference paper at ICLR 2022
INTRA-CLASS MIXUP FOR OOD DETECTION,0.19168173598553345,"Dataset
Accuracy
ERM
Inter
Intra
CIFAR-10
92.90 ± 0.27
94.32 ± 0.29
93.90 ± 0.34
CIFAR-100
71.62 ± 0.18
76.51 ± 0.28
72.28 ± 0.48
SVHN
95.69 ± 0.16
96.42 ± 0.04
95.91 ± 0.11
TinyImageNet
32.80 ± 0.17
34.04 ± 0.68
34.63 ± 0.30"
INTRA-CLASS MIXUP FOR OOD DETECTION,0.19349005424954793,"Table 2: Baseline accuracies (mean ± std. averaged over 5 seeds) of ERM, inter-class and intra-class
mixup trained models on various datasets."
INTRA-CLASS MIXUP FOR OOD DETECTION,0.19529837251356238,"• AUROC: The Receiver Operating Characteristic (ROC), the plot of the True Positive Rate
(TPR) against the False Positive Rate (FPR). The area under the ROC is called Area Under
the Receiver Operating Characteristic (AUROC). AUROC of 1 denotes an ideal detection
scheme, since the ideal detection algorithm results in 0 false positive and false negative
samples."
INTRA-CLASS MIXUP FOR OOD DETECTION,0.19710669077757687,"• AUPRC: The Precision Recall Characteristic (PRC), the plot of the Precision against the
Recall. The area under the PR is called AUPRC and should similarly be 1 for a ideal
detection scheme."
INTRA-CLASS MIXUP FOR OOD DETECTION,0.19891500904159132,"• FPR at TPR of 95% (FPR95): denotes the FPR when the TPR is 95%. Lower value of
FPR at TPR of 95% indicates a better classiﬁer."
INTRA-CLASS MIXUP FOR OOD DETECTION,0.2007233273056058,"To evaluate the effect of intra-class mixup on existing OoD detection techniques, we trained 5
differently seeded models each with ERM, inter-class mixup and intra-class mixup. We trained
ResNet18 (He et al., 2016) networks on CIFAR-10, CIFAR-100, SVHN and TinyImageNet datasets
till convergence (baseline accuracies are presented in Table 2). The training procedure used the SGD
optimizer with a momentum of 0.9 and weight decay of 5 × 10−4. The training used a 90%-10%
training-validation split with the initial learning rate set to 10−2 and it was scaled down by a factor of
10 at 60% and 80% completion using a learning rate scheduler."
INTRA-CLASS MIXUP FOR OOD DETECTION,0.20253164556962025,"It is common practice in literature (Hendrycks & Gimpel, 2017; Lee et al., 2018b; Liang et al., 2018;
Ren et al., 2019) to use data from distributions other than the training set as OoD data. We follow the
same approach. For example, if a network is trained on CIFAR-10, datasets other than CIFAR-10
(SVHN, Places365, Textures, LSUN, TinyImageNet, Gaussian Noise and Uniform Noise) are used as
OoD data. Table 3 (which is a condensed version of Table 5, 6 and 7) reports AUROC, AUPR and
FPR95 results of applying MSP (Maximum Softmax Probability Detector (Hendrycks & Gimpel,
2017)), ODIN (Liang et al., 2018) and Energy Score (Liu et al., 2020) on ERM, inter-class mixup
and intra-class mixup trained models. The detection performance (AUROC, AUPR and FPR95)
was obtained by aggregating results from 5 differently seeded models and OoD datasets. We used
Gaussian Noise, Uniform Noise, SVHN, CIFAR-10, CIFAR-100, Places365, Textures, LSUN and
TinyImageNet as OoD datasets, excluding the corresponding in-distribution dataset."
INTRA-CLASS MIXUP FOR OOD DETECTION,0.20433996383363473,"We also compare the effect of using only cos (θ) as the OoD score, referred in Table 3 as to “Vanilla
cos (θ)”. Using only cos (θ) ignores information from the l2 margin, thus when existing techniques
are provided with angular information, we observe improved performance. Table 3 demonstrates that
using “Vanilla cos (θ)” performs better than MSP, ODIN and Energy score based detectors. Further,
in Table 4 we observe adding angular information to existing techniques enhances their performance."
INTRA-CLASS MIXUP FOR OOD DETECTION,0.20614828209764918,"On average we observe an improvement of 4.68%, 3.98% and 9.97% on AUROC, AUPR and FPR95
metrics respectively on unsupervised OoD detection schemes with the use of intra-class mixup over
empirical risk minimization. Further, we observe an improvement of 6.08%, and 21.63% on AUROC
and FPR95 metrics over inter-class mixup and near identical AUPR performance when compared to
inter-class mixup."
SUPPLEMENTING ANGULAR MARGIN,0.20795660036166366,"5.3
SUPPLEMENTING ANGULAR MARGIN"
SUPPLEMENTING ANGULAR MARGIN,0.20976491862567812,"In this subsection we present the performance results when the OoD detection score is supplemented
angular margin. We show that the use of the cosine of the angular margin as the OoD detection score"
SUPPLEMENTING ANGULAR MARGIN,0.2115732368896926,Under review as a conference paper at ICLR 2022
SUPPLEMENTING ANGULAR MARGIN,0.21338155515370705,"Tech.
In-Dist."
SUPPLEMENTING ANGULAR MARGIN,0.21518987341772153,"AUROC ↑
AUPR ↑
FPR95 ↓"
SUPPLEMENTING ANGULAR MARGIN,0.21699819168173598,"ERM
Inter
Intra
ERM
Inter
Intra
ERM
Inter
Intra MSP"
SUPPLEMENTING ANGULAR MARGIN,0.21880650994575046,"CF-10
0.823 ± 0.054
0.884 ± 0.042
0.884 ± 0.037
0.780 ± 0.111
0.859 ± 0.084
0.819 ± 0.113
0.608 ± 0.111
0.504 ± 0.244
0.303 ± 0.096"
SUPPLEMENTING ANGULAR MARGIN,0.2206148282097649,"CF-100
0.664 ± 0.168
0.773 ± 0.050
0.724 ± 0.020
0.620 ± 0.199
0.701 ± 0.162
0.651 ± 0.170
0.658 ± 0.130
0.555 ± 0.179
0.608 ± 0.109"
SUPPLEMENTING ANGULAR MARGIN,0.2224231464737794,"SVHN
0.923 ± 0.007
0.888 ± 0.062
0.900 ± 0.036
0.761 ± 0.109
0.783 ± 0.106
0.719 ± 0.126
0.266 ± 0.044
0.495 ± 0.197
0.338 ± 0.095"
SUPPLEMENTING ANGULAR MARGIN,0.22423146473779385,"TIN
0.551 ± 0.110
0.527 ± 0.083
0.581 ± 0.120
0.527 ± 0.199
0.514 ± 0.190
0.560 ± 0.206
0.826 ± 0.066
0.825 ± 0.050
0.809 ± 0.087"
SUPPLEMENTING ANGULAR MARGIN,0.22603978300180833,"Avg.
0.741 ± 0.177
0.768 ± 0.159
0.772 ± 0.146
0.672 ± 0.192
0.714 ± 0.191
0.688 ± 0.184
0.590 ± 0.224
0.595 ± 0.227
0.515 ± 0.228 ODIN"
SUPPLEMENTING ANGULAR MARGIN,0.22784810126582278,"CF-10
0.897 ± 0.017
0.772 ± 0.160
0.921 ± 0.031
0.852 ± 0.076
0.783 ± 0.150
0.878 ± 0.083
0.317 ± 0.086
0.594 ± 0.335
0.259 ± 0.116"
SUPPLEMENTING ANGULAR MARGIN,0.22965641952983726,"CF-100
0.731 ± 0.090
0.763 ± 0.128
0.798 ± 0.065
0.656 ± 0.177
0.742 ± 0.202
0.721 ± 0.172
0.602 ± 0.156
0.621 ± 0.347
0.515 ± 0.216"
SUPPLEMENTING ANGULAR MARGIN,0.2314647377938517,"SVHN
0.836 ± 0.167
0.868 ± 0.080
0.855 ± 0.122
0.693 ± 0.216
0.806 ± 0.115
0.709 ± 0.188
0.518 ± 0.210
0.626 ± 0.115
0.480 ± 0.160"
SUPPLEMENTING ANGULAR MARGIN,0.2332730560578662,"TIN
0.642 ± 0.134
0.553 ± 0.041
0.680 ± 0.145
0.614 ± 0.220
0.532 ± 0.181
0.648 ± 0.242
0.738 ± 0.229
0.793 ± 0.092
0.680 ± 0.264"
SUPPLEMENTING ANGULAR MARGIN,0.23508137432188064,"Avg.
0.776 ± 0.152
0.739 ± 0.160
0.814 ± 0.135
0.704 ± 0.203
0.716 ± 0.198
0.739 ± 0.200
0.544 ± 0.236
0.658 ± 0.264
0.484 ± 0.248"
SUPPLEMENTING ANGULAR MARGIN,0.23688969258589512,Energy Score
SUPPLEMENTING ANGULAR MARGIN,0.23869801084990958,"CF-10
0.880 ± 0.036
0.783 ± 0.164
0.903 ± 0.032
0.818 ± 0.096
0.812 ± 0.116
0.842 ± 0.087
0.322 ± 0.056
0.638 ± 0.344
0.276 ± 0.099"
SUPPLEMENTING ANGULAR MARGIN,0.24050632911392406,"CF-100
0.672 ± 0.171
0.721 ± 0.096
0.748 ± 0.048
0.614 ± 0.202
0.669 ± 0.176
0.656 ± 0.177
0.637 ± 0.132
0.646 ± 0.261
0.554 ± 0.154"
SUPPLEMENTING ANGULAR MARGIN,0.2423146473779385,"SVHN
0.914 ± 0.014
0.881 ± 0.034
0.881 ± 0.035
0.764 ± 0.104
0.819 ± 0.085
0.703 ± 0.130
0.360 ± 0.072
0.611 ± 0.123
0.449 ± 0.100"
SUPPLEMENTING ANGULAR MARGIN,0.244122965641953,"TIN
0.553 ± 0.097
0.533 ± 0.044
0.636 ± 0.135
0.523 ± 0.196
0.521 ± 0.179
0.597 ± 0.228
0.803 ± 0.084
0.801 ± 0.086
0.725 ± 0.180"
SUPPLEMENTING ANGULAR MARGIN,0.24593128390596744,"Avg.
0.753 ± 0.179
0.730 ± 0.163
0.792 ± 0.132
0.680 ± 0.197
0.705 ± 0.189
0.700 ± 0.187
0.530 ± 0.218
0.674 ± 0.240
0.501 ± 0.214"
SUPPLEMENTING ANGULAR MARGIN,0.24773960216998192,Vanilla cos (θ)
SUPPLEMENTING ANGULAR MARGIN,0.24954792043399637,"CF-10
0.712 ± 0.130
0.873 ± 0.061
0.930 ± 0.022
0.836 ± 0.082
0.868 ± 0.070
0.882 ± 0.066
0.296 ± 0.083
0.512 ± 0.262
0.219 ± 0.117"
SUPPLEMENTING ANGULAR MARGIN,0.2513562386980108,"CF-100
0.946 ± 0.007
0.796 ± 0.051
0.786 ± 0.051
0.638 ± 0.193
0.718 ± 0.163
0.694 ± 0.170
0.587 ± 0.146
0.501 ± 0.179
0.499 ± 0.194"
SUPPLEMENTING ANGULAR MARGIN,0.25316455696202533,"SVHN
0.939 ± 0.038
0.937 ± 0.040
0.958 ± 0.023
0.825 ± 0.084
0.854 ± 0.081
0.862 ± 0.080
0.196 ± 0.030
0.277 ± 0.138
0.152 ± 0.072"
SUPPLEMENTING ANGULAR MARGIN,0.2549728752260398,"TIN
0.564 ± 0.108
0.491 ± 0.101
0.583 ± 0.118
0.530 ± 0.198
0.489 ± 0.180
0.548 ± 0.202
0.796 ± 0.088
0.827 ± 0.073
0.773 ± 0.105"
SUPPLEMENTING ANGULAR MARGIN,0.25678119349005424,"Avg.
0.779 ± 0.174
0.774 ± 0.184
0.814 ± 0.163
0.707 ± 0.198
0.732 ± 0.202
0.747 ± 0.196
0.469 ± 0.256
0.529 ± 0.264
0.411 ± 0.278"
SUPPLEMENTING ANGULAR MARGIN,0.2585895117540687,"Table 3: Various unsupervised distance proxy based OoD detection techniques on ERM, inter-class
mixup and intra-class mixup trained models (averaged over 5 different seeds and OoD datasets) on
various datasets (mean ± std). Expanded version of this table is available in Appendix A.2. CF-10 is
CIFAR-10, CF-100 is CIFAR-100, TIN is TinyImageNet."
SUPPLEMENTING ANGULAR MARGIN,0.2603978300180832,"improves performance. The supplemented score is obtained by adding the OoD score to the cosine of
the angular margin as described in Equation 7."
SUPPLEMENTING ANGULAR MARGIN,0.26220614828209765,"Technique
In-Dataset"
SUPPLEMENTING ANGULAR MARGIN,0.2640144665461121,"AUROC ↑
AUPR ↑
FPR95 ↓"
SUPPLEMENTING ANGULAR MARGIN,0.26582278481012656,"Intra
Intra + Cos(θ)
Intra
Intra + Cos(θ)
Intra
Intra + Cos(θ) MSP"
SUPPLEMENTING ANGULAR MARGIN,0.26763110307414106,"CIFAR-10
0.884 ± 0.037
0.915 ± 0.020
0.819 ± 0.113
0.853 ± 0.089
0.303 ± 0.096
0.107 ± 0.030"
SUPPLEMENTING ANGULAR MARGIN,0.2694394213381555,"CIFAR-100
0.724 ± 0.020
0.747 ± 0.020
0.651 ± 0.170
0.666 ± 0.168
0.608 ± 0.109
0.557 ± 0.127"
SUPPLEMENTING ANGULAR MARGIN,0.27124773960216997,"SVHN
0.900 ± 0.036
0.939 ± 0.023
0.719 ± 0.126
0.786 ± 0.105
0.338 ± 0.095
0.177 ± 0.063"
SUPPLEMENTING ANGULAR MARGIN,0.2730560578661845,"TinyImageNet
0.581 ± 0.120
0.583 ± 0.121
0.560 ± 0.206
0.558 ± 0.205
0.809 ± 0.087
0.799 ± 0.090"
SUPPLEMENTING ANGULAR MARGIN,0.27486437613019893,"Average
0.772 ± 0.146
0.796 ± 0.157
0.714 ± 0.191
0.716 ± 0.187
0.514 ± 0.228
0.441 ± 0.271 ODIN"
SUPPLEMENTING ANGULAR MARGIN,0.2766726943942134,"CIFAR-10
0.921 ± 0.031
0.935 ± 0.027
0.878 ± 0.083
0.900 ± 0.072
0.259 ± 0.116
0.229 ± 0.118"
SUPPLEMENTING ANGULAR MARGIN,0.27848101265822783,"CIFAR-100
0.798 ± 0.065
0.828 ± 0.087
0.721 ± 0.172
0.764 ± 0.184
0.515 ± 0.216
0.462 ± 0.260"
SUPPLEMENTING ANGULAR MARGIN,0.28028933092224234,"SVHN
0.855 ± 0.122
0.933 ± 0.092
0.709 ± 0.188
0.840 ± 0.184
0.480 ± 0.160
0.221 ± 0.228"
SUPPLEMENTING ANGULAR MARGIN,0.2820976491862568,"TinyImageNet
0.680 ± 0.145
0.657 ± 0.150
0.648 ± 0.242
0.629 ± 0.237
0.680 ± 0.264
0.712 ± 0.221"
SUPPLEMENTING ANGULAR MARGIN,0.28390596745027125,"Average
0.814 ± 0.135
0.838 ± 0.150
0.739 ± 0.200
0.784 ± 0.206
0.483 ± 0.248
0.406 ± 0.293"
SUPPLEMENTING ANGULAR MARGIN,0.2857142857142857,Energy Score
SUPPLEMENTING ANGULAR MARGIN,0.2875226039783002,"CIFAR-10
0.903 ± 0.032
0.919 ± 0.017
0.842 ± 0.087
0.863 ± 0.071
0.276 ± 0.099
0.238 ± 0.094"
SUPPLEMENTING ANGULAR MARGIN,0.28933092224231466,"CIFAR-100
0.748 ± 0.048
0.763 ± 0.043
0.656 ± 0.177
0.700 ± 0.173
0.553 ± 0.154
0.532 ± 0.166"
SUPPLEMENTING ANGULAR MARGIN,0.2911392405063291,"SVHN
0.881 ± 0.035
0.927 ± 0.030
0.703 ± 0.130
0.798 ± 0.102
0.449 ± 0.100
0.279 ± 0.098"
SUPPLEMENTING ANGULAR MARGIN,0.29294755877034356,"TinyImageNet
0.635 ± 0.135
0.610 ± 0.125
0.597 ± 0.228
0.570 ± 0.214
0.725 ± 0.180
0.745 ± 0.143"
SUPPLEMENTING ANGULAR MARGIN,0.29475587703435807,"Average
0.792 ± 0.132
0.805 ± 0.147
0.700 ± 0.187
0.725 ± 0.189
0.501 ± 0.213
0.449 ± 0.242"
SUPPLEMENTING ANGULAR MARGIN,0.2965641952983725,"Table 4: Various unsupervised distance proxy OoD detection techniques on compared with and with
out angular margin (averaged over 5 different seeds and OoD datasets, expanded version of this table
is available in Appendix A.2) on various datasets (mean ± std)."
SUPPLEMENTING ANGULAR MARGIN,0.298372513562387,Under review as a conference paper at ICLR 2022
SUPPLEMENTING ANGULAR MARGIN,0.30018083182640143,"Figure 2: Comparison of average AUROC performance (averaged over in-dist and OoD datasets and
5 seeds) of methods that use distance proxies improved with the use of angular margin and intra-class
mixup. Please note that “Vanilla cos” by deﬁnition cannot use the additional angular margin term,
hence its not plotted."
SUPPLEMENTING ANGULAR MARGIN,0.30198915009041594,"Figure 2 and Table 4 compare the OoD detection performance of methods that use distance proxies
when used with intra-class mixup aided with angular margin. Table 4 reports mean and standard
deviation obtained by averaging 5 different seeds for each in-distribution dataset and averaged over
various OoD datasets as used for Table 3. We observe that on average the use of angular margin
with intra-class mixup improves OoD detection performance (AUROC) by 7.36% over empirical
risk minimization and 9.10% over inter-class mixup."
CONCLUSION,0.3037974683544304,"6
CONCLUSION"
CONCLUSION,0.30560578661844484,"There have been numerous approaches to tackle the problem of OoD detection. In this paper we
explore the use of intra-class mixup to train OoD detectors. We show that intra-class mixup reduces
the angular spread of the learnt latent space representation, improving the angular separability of
in-distribution and out-of-distribution data. We observe that the use of intra-class mixup on detection
techniques that use distance proxies improves AUROC performance by 4.68% and 6.08% over
empirical risk minimization and inter-class mixup trained models respectively. Further, the use of
the cosine of the angular margin to supplement detection scores improves AUROC performance by
7.36% over empirical risk minimization and 9.10% over inter-class mixup trained networks. Our
ﬁndings reveal that intra-class mixup can be an effective tool for training OoD detectors."
IMPACT STATEMENT,0.3074141048824593,"7
IMPACT STATEMENT"
IMPACT STATEMENT,0.3092224231464738,"The research presented in this paper focuses on improving the reliability of deep learning techniques
in detecting anomalies, reducing the barriers to the deployment of deep learning in safety critical
applications such as medical diagnosis, self driving cars etc. Hence it promises a positive impact
on the society. However, one must be aware of the limitations of the speciﬁc techniques applied in
conjunction with the technique proposed in the paper to ensure reliable and secure deployment in
safety critical applications. This paper does not utilize human-derived data and does not utilize any
datasets that have been discredited by the creators."
REFERENCES,0.31103074141048825,REFERENCES
REFERENCES,0.3128390596745027,"Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and Dan Mané.
Concrete problems in ai safety, 2016."
REFERENCES,0.31464737793851716,Under review as a conference paper at ICLR 2022
REFERENCES,0.31645569620253167,"Daniel Andor, Chris Alberti, David Weiss, Aliaksei Severyn, Alessandro Presta, Kuzman Ganchev,
Slav Petrov, and Michael Collins. Globally normalized transition-based neural networks. In
Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers), pp. 2442–2452, Berlin, Germany, August 2016. Association for Computational
Linguistics. doi: 10.18653/v1/P16-1231. URL https://www.aclweb.org/anthology/
P16-1231."
REFERENCES,0.3182640144665461,"Joan Bruna, Christian Szegedy, Ilya Sutskever, Ian Goodfellow, Wojciech Zaremba, Rob Fergus, and
Dumitru Erhan. Intriguing properties of neural networks. International Conference on Learning
Representation (ICLR), Poster, 2014."
REFERENCES,0.32007233273056057,"M. Cimpoi, S. Maji, I. Kokkinos, S. Mohamed, , and A. Vedaldi. Describing textures in the wild. In
Proceedings of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2014."
REFERENCES,0.321880650994575,"Lucas Deecke, Robert Vandermeulen, Lukas Ruff, Stephan Mandt, and Marius Kloft. Image anomaly
detection with generative adversarial networks. In Joint european conference on machine learning
and knowledge discovery in databases, pp. 3–17. Springer, 2018."
REFERENCES,0.32368896925858953,Ronald Aylmer Fisher et al. 138: The use of multiple measurements in taxonomic problems. 1936.
REFERENCES,0.325497287522604,"Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural informa-
tion processing systems, pp. 2672–2680, 2014."
REFERENCES,0.32730560578661844,"Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. International Conference on Learning Representation (ICLR), Poster, 2015a."
REFERENCES,0.3291139240506329,"Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples, 2015b."
REFERENCES,0.3309222423146474,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770–778, 2016."
REFERENCES,0.33273056057866185,"Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassiﬁed and out-of-distribution ex-
amples in neural networks. Proceedings of International Conference on Learning Representations,
2017."
REFERENCES,0.3345388788426763,"Dan Hendrycks, Mantas Mazeika, and Thomas Dietterich. Deep anomaly detection with outlier
exposure. Proceedings of the International Conference on Learning Representations, 2019."
REFERENCES,0.33634719710669075,"Yen-Chang Hsu, Yilin Shen, Hongxia Jin, and Zsolt Kira. Generalized odin: Detecting out-of-
distribution image without learning from out-of-distribution data. In IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR), June 2020."
REFERENCES,0.33815551537070526,"Hans-Peter Kriegel, Matthias Schubert, and Arthur Zimek. Angle-based outlier detection in high-
dimensional data. In Proceedings of the 14th ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pp. 444–452, 2008."
REFERENCES,0.3399638336347197,"Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009."
REFERENCES,0.34177215189873417,"Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep convo-
lutional neural networks. In F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger (eds.),
Advances in Neural Information Processing Systems 25, pp. 1097–1105. Curran Associates, Inc.,
2012. URL http://papers.nips.cc/paper/4824-imagenet-classification-
with-deep-convolutional-neural-networks.pdf."
REFERENCES,0.3435804701627486,"Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial examples in the physical world.
International Conference on Learning Representation (ICLR), Workshop Track, 2017. URL
https://openreview.net/forum?id=S1OufnIlx."
REFERENCES,0.3453887884267631,"Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436–444,
May 2015. ISSN 1476-4687. doi: 10.1038/nature14539. URL https://doi.org/10.1038/
nature14539."
REFERENCES,0.3471971066907776,Under review as a conference paper at ICLR 2022
REFERENCES,0.34900542495479203,"Kimin Lee, Honglak Lee, Kibok Lee, and Jinwoo Shin. Training conﬁdence-calibrated classiﬁers for
detecting out-of-distribution samples. In International Conference on Learning Representations,
2018a. URL https://openreview.net/forum?id=ryiAv2xAZ."
REFERENCES,0.3508137432188065,"Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple uniﬁed framework for detecting
out-of-distribution samples and adversarial attacks. In S. Bengio, H. Wallach, H. Larochelle,
K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing
Systems 31, pp. 7167–7177. Curran Associates, Inc., 2018b. URL http://papers.nips.cc/
paper/7947-a-simple-unified-framework-for-detecting-out-of-
distribution-samples-and-adversarial-attacks.pdf."
REFERENCES,0.352622061482821,"Fei-Fei Li, Andrej Karpathy, and Justin Johnson. Tiny imagenet visual recognition challenge."
REFERENCES,0.35443037974683544,"Shiyu Liang, Yixuan Li, and R. Srikant. Enhancing the reliability of out-of-distribution image
detection in neural networks. In International Conference on Learning Representations, 2018.
URL https://openreview.net/forum?id=H1VGkIxRZ."
REFERENCES,0.3562386980108499,"Weitang Liu, Xiaoyun Wang, John D. Owens, and Yixuan Li. Energy-based out-of-distribution
detection, 2020."
REFERENCES,0.35804701627486435,"Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y. Ng. Reading
digits in natural images with unsupervised feature learning. In NIPS Workshop on Deep Learn-
ing and Unsupervised Feature Learning 2011, 2011. URL http://ufldl.stanford.edu/
housenumbers/nips2011_housenumbers.pdf."
REFERENCES,0.35985533453887886,"A. Nguyen, J. Yosinski, and J. Clune. Deep neural networks are easily fooled: High conﬁdence
predictions for unrecognizable images. In 2015 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 427–436, 2015. doi: 10.1109/CVPR.2015.7298640."
REFERENCES,0.3616636528028933,"Jie Ren, Peter J Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark Depristo, Joshua Dillon, and
Balaji Lakshminarayanan. Likelihood ratios for out-of-distribution detection. In Advances in
Neural Information Processing Systems, pp. 14707–14718, 2019."
REFERENCES,0.36347197106690776,"Sunil Thulasidasan, Gopinath Chennupati, Jeff A Bilmes, Tanmoy Bhattacharya, and Sarah
Michalak. On mixup training: Improved calibration and predictive uncertainty for deep neu-
ral networks.
In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and
R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 32. Curran As-
sociates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/
36ad8b5f42db492827016448975cc22d-Paper.pdf."
REFERENCES,0.36528028933092227,"Vladimir N. Vapnik. Statistical Learning Theory. Wiley-Interscience, 1998."
REFERENCES,0.3670886075949367,"William Wang, Angelina Wang, Aviv Tamar, Xi Chen, and Pieter Abbeel. Safer classiﬁcation by
synthesis. arXiv preprint arXiv:1711.08534, 2017."
REFERENCES,0.3688969258589512,"Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong Xiao. Lsun:
Construction of a large-scale image dataset using deep learning with humans in the loop. arXiv
preprint arXiv:1506.03365, 2015."
REFERENCES,0.3707052441229656,"Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530, 2016."
REFERENCES,0.37251356238698013,"Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, and David Lopez-Paz. mixup: Beyond empirical
risk minimization. International Conference on Learning Representations, 2018. URL https:
//openreview.net/forum?id=r1Ddp1-Rb."
REFERENCES,0.3743218806509946,"Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba. Places: A 10
million image database for scene recognition. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 2017."
REFERENCES,0.37613019891500904,Under review as a conference paper at ICLR 2022
REFERENCES,0.3779385171790235,"A
APPENDIX"
REFERENCES,0.379746835443038,"A.1
VARIANCE OF INPUT DUE TO INTRA-CLASS MIXUP"
REFERENCES,0.38155515370705245,"Consider two random variables X0, X1 ∼X where X is a class conditional distribution for class
ˆy with mean µX and variance σ2
X. Then the variance of ˆX = a0X0 + a1X1 where a0 = λ and
a1 = 1 −λ is given by"
REFERENCES,0.3833634719710669,"σ2
ˆ
X = V ar( ˆX) = E

ˆX −µ ˆ
X
2"
REFERENCES,0.38517179023508136,"σ2
ˆ
X = E
P1
k=0 aiXi −P1
k=0 aiµX
2"
REFERENCES,0.38698010849909587,"σ2
ˆ
X = E
P1
k=0 ak(Xk −µX)
2"
REFERENCES,0.3887884267631103,"σ2
ˆ
X = E
hP1
k=0 ak(Xk −µX)
 P1
k=0 ak(Xk −µX)
i"
REFERENCES,0.39059674502712477,"σ2
ˆ
X = E
hP1
j=0
P1
k=0 akaj(Xk −µX)(Xj −µX)
i"
REFERENCES,0.3924050632911392,"σ2
ˆ
X = P1
j=0
P1
k=0 akajE [(Xk −µX)(Xj −µX)]"
REFERENCES,0.39421338155515373,"σ2
ˆ
X = P1
k=0 a2
kσ2
X + 2a0a1Cov(X0, X1)"
REFERENCES,0.3960216998191682,"The Cov(X0, X1) = 0 because X0 and X1 are drawn independently, therefore the equation is
reduces to"
REFERENCES,0.39783001808318263,"σ2
ˆ
X =
h
λ2 + (1 −λ)2i
σ2
X"
REFERENCES,0.3996383363471971,Since λ2 + (1 −λ)2 ≤1
REFERENCES,0.4014466546112116,"σ2
ˆ
X ≤σ2
X"
REFERENCES,0.40325497287522605,"A.2
EXPANDED RESULTS FOR VARIOUS DETECTION SCHEMES"
REFERENCES,0.4050632911392405,Under review as a conference paper at ICLR 2022
REFERENCES,0.40687160940325495,Maximum Softmax Probability Detector
REFERENCES,0.40867992766726946,"In-Dataset
OoD Dataset
AUROC
AUPR
FPR95"
REFERENCES,0.4104882459312839,"ERM
Inter
Intra
ERM
Inter
Intra
ERM
Inter
Intra"
REFERENCES,0.41229656419529837,CIFAR-10
REFERENCES,0.4141048824593128,"Gaussian Noise
0.6991 ± 0.2232
0.9470 ± 0.0471
0.8191 ± 0.0697
0.6451 ± 0.2250
0.9073 ± 0.0816
0.7118 ± 0.0975
0.6103 ± 0.3818
0.1290 ± 0.1128
0.3181 ± 0.0854"
REFERENCES,0.4159132007233273,"Uniform Noise
0.8722 ± 0.0308
0.9462 ± 0.0383
0.9452 ± 0.0310
0.8005 ± 0.0413
0.9059 ± 0.0621
0.9009 ± 0.0691
0.3513 ± 0.2029
0.1383 ± 0.0960
0.1194 ± 0.0347"
REFERENCES,0.4177215189873418,"SVHN
0.8111 ± 0.0901
0.8539 ± 0.0386
0.9175 ± 0.0105
0.9005 ± 0.0402
0.9263 ± 0.0167
0.9474 ± 0.0071
0.6102 ± 0.2288
0.6285 ± 0.1962
0.2135 ± 0.0230"
REFERENCES,0.41952983725135623,"Textures
0.8448 ± 0.0089
0.8471 ± 0.0144
0.8674 ± 0.0064
0.7311 ± 0.0058
0.7677 ± 0.0147
0.7407 ± 0.0084
0.6698 ± 0.1196
0.7438 ± 0.0782
0.4066 ± 0.0330"
REFERENCES,0.4213381555153707,"LSUN
0.8598 ± 0.0177
0.8888 ± 0.0063
0.8924 ± 0.0048
0.6262 ± 0.0203
0.7074 ± 0.0111
0.6447 ± 0.0069
0.6217 ± 0.1507
0.5010 ± 0.0439
0.3075 ± 0.0090"
REFERENCES,0.4231464737793852,"TinyImageNet
0.8344 ± 0.0143
0.8484 ± 0.0046
0.8743 ± 0.0014
0.8169 ± 0.0078
0.8456 ± 0.0052
0.8409 ± 0.0023
0.7070 ± 0.1248
0.6929 ± 0.0187
0.3862 ± 0.0141"
REFERENCES,0.42495479204339964,"Places365
0.8422 ± 0.0155
0.8546 ± 0.0055
0.8758 ± 0.0033
0.9418 ± 0.0040
0.9510 ± 0.0018
0.9497 ± 0.0015
0.6851 ± 0.1368
0.6920 ± 0.0307
0.3745 ± 0.0045"
REFERENCES,0.4267631103074141,"Average
0.8234 ± 0.0538
0.8837 ± 0.0419
0.8845 ± 0.0370
0.7803 ± 0.1113
0.8587 ± 0.0837
0.8194 ± 0.1126
0.6079 ± 0.1106
0.5037 ± 0.2445
0.3034 ± 0.0963"
REFERENCES,0.42857142857142855,CIFAR-100
REFERENCES,0.43037974683544306,"Gaussian Noise
0.2596 ± 0.0665
0.8916 ± 0.0579
0.7189 ± 0.1093
0.3647 ± 0.0181
0.7963 ± 0.0875
0.6211 ± 0.1069
0.8237 ± 0.0798
0.2005 ± 0.0778
0.4668 ± 0.1020"
REFERENCES,0.4321880650994575,"Uniform Noise
0.7941 ± 0.0627
0.7464 ± 0.2002
0.7159 ± 0.0908
0.6889 ± 0.0805
0.6705 ± 0.1818
0.6048 ± 0.0977
0.3759 ± 0.0618
0.3751 ± 0.2218
0.4384 ± 0.0742"
REFERENCES,0.43399638336347196,"SVHN
0.7426 ± 0.0273
0.7460 ± 0.0302
0.7501 ± 0.0355
0.8507 ± 0.0173
0.8423 ± 0.0150
0.8560 ± 0.0211
0.6120 ± 0.0456
0.6137 ± 0.0796
0.5912 ± 0.0570"
REFERENCES,0.4358047016274864,"Textures
0.6948 ± 0.0038
0.7454 ± 0.0030
0.6879 ± 0.0031
0.5075 ± 0.0046
0.5502 ± 0.0047
0.5031 ± 0.0046
0.7322 ± 0.0079
0.6451 ± 0.0133
0.7566 ± 0.0110"
REFERENCES,0.4376130198915009,"LSUN
0.7020 ± 0.0051
0.7417 ± 0.0037
0.7138 ± 0.0018
0.3591 ± 0.0061
0.4014 ± 0.0076
0.3746 ± 0.0031
0.7094 ± 0.0059
0.7162 ± 0.0130
0.6931 ± 0.0059"
REFERENCES,0.4394213381555154,"TinyImageNet
0.7382 ± 0.0026
0.7857 ± 0.0023
0.7494 ± 0.0032
0.6900 ± 0.0042
0.7447 ± 0.0022
0.7069 ± 0.0042
0.6518 ± 0.0025
0.6305 ± 0.0133
0.6393 ± 0.0037"
REFERENCES,0.4412296564195298,"Places365
0.7201 ± 0.0040
0.7560 ± 0.0019
0.7326 ± 0.0029
0.8818 ± 0.0022
0.8989 ± 0.0011
0.8885 ± 0.0018
0.6992 ± 0.0066
0.7035 ± 0.0043
0.6720 ± 0.0035"
REFERENCES,0.4430379746835443,"Average
0.6645 ± 0.1680
0.7733 ± 0.0503
0.7241 ± 0.0203
0.6204 ± 0.1990
0.7006 ± 0.1619
0.6507 ± 0.1702
0.6577 ± 0.1304
0.5549 ± 0.1786
0.6083 ± 0.1090 SVHN"
REFERENCES,0.4448462929475588,"Gaussian Noise
0.9218 ± 0.0141
0.8198 ± 0.1368
0.8606 ± 0.0710
0.7770 ± 0.0298
0.6935 ± 0.2014
0.6570 ± 0.1413
0.2575 ± 0.0560
0.6185 ± 0.4020
0.4203 ± 0.1965"
REFERENCES,0.44665461121157324,"Uniform Noise
0.9247 ± 0.0061
0.7706 ± 0.1228
0.8336 ± 0.0760
0.7845 ± 0.0061
0.6385 ± 0.1586
0.6170 ± 0.1391
0.2494 ± 0.0335
0.7598 ± 0.3313
0.4974 ± 0.1963"
REFERENCES,0.4484629294755877,"CIFAR-100
0.9267 ± 0.0042
0.9340 ± 0.0071
0.9285 ± 0.0031
0.7993 ± 0.0067
0.8672 ± 0.0108
0.8072 ± 0.0085
0.2552 ± 0.0257
0.3282 ± 0.0841
0.2549 ± 0.0112"
REFERENCES,0.45027124773960214,"Textures
0.9066 ± 0.0059
0.8851 ± 0.0253
0.9019 ± 0.0142
0.6651 ± 0.0154
0.7391 ± 0.0417
0.6643 ± 0.0299
0.3723 ± 0.0364
0.7703 ± 0.1736
0.4037 ± 0.0827"
REFERENCES,0.45207956600361665,"LSUN
0.9258 ± 0.0051
0.9353 ± 0.0110
0.9176 ± 0.0063
0.5614 ± 0.0133
0.7183 ± 0.0313
0.5419 ± 0.0200
0.2534 ± 0.0260
0.3332 ± 0.1233
0.2964 ± 0.0263"
REFERENCES,0.4538878842676311,"TinyImageNet
0.9308 ± 0.0037
0.9354 ± 0.0105
0.9339 ± 0.0035
0.8071 ± 0.0066
0.8732 ± 0.0176
0.8160 ± 0.0091
0.2306 ± 0.0221
0.3254 ± 0.1094
0.2300 ± 0.0146"
REFERENCES,0.45569620253164556,"Places365
0.9281 ± 0.0047
0.9355 ± 0.0133
0.9266 ± 0.0052
0.9324 ± 0.0034
0.9540 ± 0.0087
0.9325 ± 0.0047
0.2436 ± 0.0256
0.3307 ± 0.1388
0.2607 ± 0.0220"
REFERENCES,0.45750452079566006,"Average
0.9235 ± 0.0074
0.8880 ± 0.0624
0.9003 ± 0.0360
0.7610 ± 0.1088
0.7834 ± 0.1065
0.7194 ± 0.1261
0.2660 ± 0.0442
0.4952 ± 0.1967
0.3377 ± 0.0948"
REFERENCES,0.4593128390596745,TinyImageNet
REFERENCES,0.46112115732368897,"Gaussian Noise
0.5506 ± 0.1104
0.4041 ± 0.1878
0.7082 ± 0.1253
0.4911 ± 0.0665
0.4355 ± 0.1123
0.6584 ± 0.1311
0.7374 ± 0.1040
0.7842 ± 0.1274
0.6326 ± 0.1357"
REFERENCES,0.4629294755877034,"Uniform Noise
0.2977 ± 0.0686
0.3944 ± 0.1244
0.3135 ± 0.1295
0.3726 ± 0.0220
0.4104 ± 0.0488
0.3842 ± 0.0420
0.9064 ± 0.0255
0.7805 ± 0.1021
0.8873 ± 0.0470"
REFERENCES,0.46473779385171793,"SVHN
0.6747 ± 0.0258
0.6042 ± 0.0915
0.6870 ± 0.0422
0.7956 ± 0.0237
0.7473 ± 0.0607
0.8233 ± 0.0262
0.7187 ± 0.0201
0.7458 ± 0.0843
0.7290 ± 0.0445"
REFERENCES,0.4665461121157324,"CIFAR-100
0.5774 ± 0.0034
0.5680 ± 0.0098
0.5934 ± 0.0033
0.5491 ± 0.0038
0.5423 ± 0.0095
0.5644 ± 0.0040
0.8718 ± 0.0035
0.8819 ± 0.0034
0.8622 ± 0.0031"
REFERENCES,0.46835443037974683,"Textures
0.5555 ± 0.0078
0.5435 ± 0.0143
0.5610 ± 0.0109
0.3801 ± 0.0099
0.3756 ± 0.0091
0.3913 ± 0.0093
0.8702 ± 0.0056
0.8786 ± 0.0094
0.8809 ± 0.0058"
REFERENCES,0.4701627486437613,"LSUN
0.5897 ± 0.0051
0.5727 ± 0.0263
0.5892 ± 0.0047
0.2709 ± 0.0041
0.2615 ± 0.0186
0.2690 ± 0.0044
0.8451 ± 0.0044
0.8639 ± 0.0185
0.8426 ± 0.0057"
REFERENCES,0.4719710669077758,"Places365
0.6117 ± 0.0045
0.6032 ± 0.0106
0.6137 ± 0.0029
0.8309 ± 0.0014
0.8270 ± 0.0061
0.8316 ± 0.0013
0.8334 ± 0.0042
0.8424 ± 0.0070
0.8271 ± 0.0025"
REFERENCES,0.47377938517179025,"Average
0.5510 ± 0.1104
0.5272 ± 0.0832
0.5808 ± 0.1199
0.5272 ± 0.1990
0.5142 ± 0.1901
0.5603 ± 0.2059
0.8261 ± 0.0658
0.8253 ± 0.0505
0.8088 ± 0.0871"
REFERENCES,0.4755877034358047,"Average
0.7406 ± 0.1771
0.7680 ± 0.1588
0.7725 ± 0.1461
0.6722 ± 0.1915
0.7142 ± 0.1914
0.6875 ± 0.1843
0.5895 ± 0.2243
0.5948 ± 0.2269
0.5145 ± 0.2285"
REFERENCES,0.47739602169981915,Table 5: Expanded results for Maximum Softmax Probability Detector. ODIN
REFERENCES,0.47920433996383366,"In-Dataset
OoD Dataset
AUROC
AUPR
FPR95"
REFERENCES,0.4810126582278481,"ERM
Inter
Intra
ERM
Inter
Intra
ERM
Inter
Intra"
REFERENCES,0.48282097649186256,CIFAR-10
REFERENCES,0.484629294755877,"Gaussian Noise
0.9059 ± 0.0866
0.9942 ± 0.0109
0.8898 ± 0.0665
0.8378 ± 0.1369
0.9935 ± 0.0121
0.8038 ± 0.1183
0.1691 ± 0.1213
0.0282 ± 0.0544
0.2091 ± 0.1046"
REFERENCES,0.4864376130198915,"Uniform Noise
0.8624 ± 0.0585
0.9576 ± 0.0370
0.9738 ± 0.0105
0.7709 ± 0.0863
0.9335 ± 0.0620
0.9453 ± 0.0287
0.2807 ± 0.1075
0.1214 ± 0.0857
0.0581 ± 0.0173"
REFERENCES,0.488245931283906,"SVHN
0.9127 ± 0.0441
0.4742 ± 0.0900
0.9598 ± 0.0116
0.9490 ± 0.0260
0.7191 ± 0.0595
0.9801 ± 0.0057
0.2489 ± 0.1176
0.9100 ± 0.0368
0.1498 ± 0.0388"
REFERENCES,0.49005424954792043,"Textures
0.8993 ± 0.0202
0.7156 ± 0.0405
0.8927 ± 0.0128
0.8237 ± 0.0266
0.6403 ± 0.0381
0.8078 ± 0.0188
0.3650 ± 0.0836
0.8312 ± 0.0517
0.3799 ± 0.0437"
REFERENCES,0.4918625678119349,"LSUN
0.9151 ± 0.0049
0.7959 ± 0.0193
0.9243 ± 0.0051
0.7474 ± 0.0074
0.5633 ± 0.0372
0.7552 ± 0.0123
0.3184 ± 0.0258
0.6734 ± 0.0249
0.2745 ± 0.0233"
REFERENCES,0.4936708860759494,"TinyImageNet
0.8840 ± 0.0130
0.7257 ± 0.0129
0.9010 ± 0.0068
0.8696 ± 0.0123
0.7264 ± 0.0137
0.8867 ± 0.0074
0.4406 ± 0.0560
0.8021 ± 0.0123
0.3857 ± 0.0302"
REFERENCES,0.49547920433996384,"Places365
0.8987 ± 0.0081
0.7429 ± 0.0175
0.9086 ± 0.0004
0.9642 ± 0.0028
0.9085 ± 0.0078
0.9672 ± 0.0004
0.3942 ± 0.0390
0.7878 ± 0.0188
0.3533 ± 0.0036"
REFERENCES,0.4972875226039783,"Average
0.8969 ± 0.0170
0.7723 ± 0.1600
0.9214 ± 0.0308
0.8518 ± 0.0764
0.7835 ± 0.1505
0.8780 ± 0.0832
0.3167 ± 0.0857
0.5935 ± 0.3352
0.2587 ± 0.1162"
REFERENCES,0.49909584086799275,CIFAR-100
REFERENCES,0.5009041591320073,"Gaussian Noise
0.5267 ± 0.0759
0.9988 ± 0.0015
0.9365 ± 0.0374
0.4631 ± 0.0373
0.9979 ± 0.0026
0.8727 ± 0.0757
0.5671 ± 0.0788
0.0038 ± 0.0051
0.1305 ± 0.0661"
REFERENCES,0.5027124773960217,"Uniform Noise
0.8447 ± 0.0539
0.9187 ± 0.1022
0.8070 ± 0.1008
0.7173 ± 0.0776
0.8686 ± 0.1521
0.6811 ± 0.1122
0.2490 ± 0.0735
0.1534 ± 0.1610
0.2741 ± 0.1211"
REFERENCES,0.5045207956600362,"SVHN
0.7614 ± 0.0249
0.7258 ± 0.0377
0.8147 ± 0.0247
0.8480 ± 0.0182
0.8599 ± 0.0256
0.8859 ± 0.0201
0.5813 ± 0.0369
0.7577 ± 0.0412
0.4685 ± 0.0363"
REFERENCES,0.5063291139240507,"Textures
0.7347 ± 0.0060
0.6878 ± 0.0074
0.7080 ± 0.0094
0.5533 ± 0.0068
0.5830 ± 0.0066
0.5214 ± 0.0095
0.7023 ± 0.0105
0.8855 ± 0.0086
0.7478 ± 0.0202"
REFERENCES,0.5081374321880651,"LSUN
0.7323 ± 0.0069
0.6783 ± 0.0065
0.7625 ± 0.0024
0.3957 ± 0.0093
0.3754 ± 0.0095
0.4376 ± 0.0036
0.7386 ± 0.0127
0.8414 ± 0.0045
0.6831 ± 0.0113"
REFERENCES,0.5099457504520796,"TinyImageNet
0.7635 ± 0.0033
0.6510 ± 0.0059
0.7790 ± 0.0012
0.7197 ± 0.0051
0.6329 ± 0.0062
0.7376 ± 0.0016
0.6707 ± 0.0064
0.8698 ± 0.0032
0.6370 ± 0.0050"
REFERENCES,0.5117540687160941,"Places365
0.7515 ± 0.0062
0.6780 ± 0.0025
0.7778 ± 0.0028
0.8972 ± 0.0032
0.8735 ± 0.0013
0.9104 ± 0.0015
0.7064 ± 0.0097
0.8328 ± 0.0074
0.6624 ± 0.0059"
REFERENCES,0.5135623869801085,"Average
0.7307 ± 0.0903
0.7626 ± 0.1275
0.7979 ± 0.0651
0.6563 ± 0.1766
0.7416 ± 0.2015
0.7210 ± 0.1724
0.6022 ± 0.1561
0.6206 ± 0.3472
0.5148 ± 0.2162 SVHN"
REFERENCES,0.515370705244123,"Gaussian Noise
0.8929 ± 0.0257
0.8318 ± 0.1540
0.8902 ± 0.0627
0.7453 ± 0.0509
0.7685 ± 0.1972
0.7592 ± 0.1302
0.4429 ± 0.1016
0.5501 ± 0.3915
0.4052 ± 0.2158"
REFERENCES,0.5171790235081374,"Uniform Noise
0.4328 ± 0.0662
0.6939 ± 0.1668
0.5604 ± 0.1762
0.2320 ± 0.0232
0.5804 ± 0.1992
0.3311 ± 0.1563
0.9430 ± 0.0224
0.7344 ± 0.3006
0.7954 ± 0.2306"
REFERENCES,0.5189873417721519,"CIFAR-100
0.9216 ± 0.0105
0.9217 ± 0.0129
0.9264 ± 0.0098
0.8360 ± 0.0145
0.8877 ± 0.0149
0.8444 ± 0.0178
0.3803 ± 0.0717
0.5923 ± 0.0875
0.3507 ± 0.0491"
REFERENCES,0.5207956600361664,"Textures
0.8375 ± 0.0083
0.8494 ± 0.0382
0.8539 ± 0.0330
0.6088 ± 0.0133
0.7524 ± 0.0522
0.6394 ± 0.0548
0.7294 ± 0.0526
0.8615 ± 0.0566
0.6461 ± 0.1253"
REFERENCES,0.5226039783001808,"LSUN
0.9216 ± 0.0122
0.9283 ± 0.0171
0.9081 ± 0.0180
0.6500 ± 0.0331
0.8052 ± 0.0318
0.6110 ± 0.0497
0.3831 ± 0.0715
0.5483 ± 0.1222
0.4339 ± 0.0754"
REFERENCES,0.5244122965641953,"TinyImageNet
0.9251 ± 0.0091
0.9262 ± 0.0173
0.9276 ± 0.0117
0.8422 ± 0.0142
0.8953 ± 0.0210
0.8451 ± 0.0213
0.3628 ± 0.0570
0.5571 ± 0.1221
0.3414 ± 0.0593"
REFERENCES,0.5262206148282098,"Places365
0.9201 ± 0.0111
0.9255 ± 0.0212
0.9168 ± 0.0160
0.9386 ± 0.0076
0.9559 ± 0.0121
0.9355 ± 0.0121
0.3843 ± 0.0656
0.5415 ± 0.1555
0.3873 ± 0.0763"
REFERENCES,0.5280289330922242,"Average
0.8359 ± 0.1671
0.8681 ± 0.0803
0.8548 ± 0.1225
0.6933 ± 0.2162
0.8065 ± 0.1148
0.7094 ± 0.1882
0.5180 ± 0.2105
0.6265 ± 0.1147
0.4800 ± 0.1601"
REFERENCES,0.5298372513562387,TinyImageNet
REFERENCES,0.5316455696202531,"Gaussian Noise
0.9353 ± 0.0691
0.5092 ± 0.2553
0.9772 ± 0.0219
0.9130 ± 0.0960
0.5169 ± 0.2044
0.9737 ± 0.0263
0.1958 ± 0.1672
0.6574 ± 0.2351
0.0943 ± 0.0854"
REFERENCES,0.5334538878842676,"Uniform Noise
0.4737 ± 0.0700
0.4829 ± 0.1432
0.5562 ± 0.1663
0.4421 ± 0.0348
0.4541 ± 0.0796
0.5037 ± 0.0968
0.7836 ± 0.0461
0.6827 ± 0.1446
0.6776 ± 0.1424"
REFERENCES,0.5352622061482821,"SVHN
0.6754 ± 0.0380
0.5840 ± 0.1369
0.8180 ± 0.0125
0.8018 ± 0.0315
0.7332 ± 0.0748
0.9070 ± 0.0054
0.7237 ± 0.0281
0.7344 ± 0.1257
0.5611 ± 0.0282"
REFERENCES,0.5370705244122965,"CIFAR-100
0.6016 ± 0.0034
0.5700 ± 0.0141
0.6162 ± 0.0032
0.5805 ± 0.0037
0.5461 ± 0.0124
0.5940 ± 0.0032
0.8754 ± 0.0051
0.8861 ± 0.0128
0.8576 ± 0.0048"
REFERENCES,0.538878842676311,"Textures
0.5576 ± 0.0067
0.5436 ± 0.0295
0.5700 ± 0.0098
0.4226 ± 0.0084
0.3808 ± 0.0177
0.4415 ± 0.0132
0.9145 ± 0.0032
0.8840 ± 0.0391
0.9140 ± 0.0050"
REFERENCES,0.5406871609403255,"LSUN
0.6252 ± 0.0052
0.5714 ± 0.0381
0.6045 ± 0.0052
0.3022 ± 0.0056
0.2641 ± 0.0298
0.2803 ± 0.0051
0.8381 ± 0.0056
0.8672 ± 0.0258
0.8350 ± 0.0061"
REFERENCES,0.5424954792043399,"Places365
0.6251 ± 0.0033
0.6077 ± 0.0181
0.6216 ± 0.0030
0.8388 ± 0.0020
0.8297 ± 0.0089
0.8344 ± 0.0016
0.8373 ± 0.0046
0.8413 ± 0.0241
0.8232 ± 0.0041"
REFERENCES,0.5443037974683544,"Average
0.6420 ± 0.1335
0.5527 ± 0.0406
0.6805 ± 0.1454
0.6144 ± 0.2203
0.5321 ± 0.1814
0.6478 ± 0.2419
0.7383 ± 0.2287
0.7933 ± 0.0916
0.6804 ± 0.2641"
REFERENCES,0.546112115732369,"Average
0.7764 ± 0.1520
0.7389 ± 0.1605
0.8137 ± 0.1347
0.7040 ± 0.2028
0.7159 ± 0.1978
0.7390 ± 0.1996
0.5438 ± 0.2355
0.6585 ± 0.2642
0.4835 ± 0.2479"
REFERENCES,0.5479204339963833,Table 6: Expanded results for ODIN.
REFERENCES,0.5497287522603979,Under review as a conference paper at ICLR 2022
REFERENCES,0.5515370705244123,Energy Score
REFERENCES,0.5533453887884268,"In-Dataset
OoD Dataset
AUROC
AUPR
FPR95"
REFERENCES,0.5551537070524413,"ERM
Inter
Intra
ERM
Inter
Intra
ERM
Inter
Intra"
REFERENCES,0.5569620253164557,CIFAR-10
REFERENCES,0.5587703435804702,"Gaussian Noise
0.7997 ± 0.1342
0.9694 ± 0.0422
0.8390 ± 0.0910
0.6885 ± 0.1384
0.9496 ± 0.0658
0.7318 ± 0.1090
0.2975 ± 0.1625
0.0966 ± 0.1382
0.2829 ± 0.1262"
REFERENCES,0.5605786618444847,"Uniform Noise
0.8719 ± 0.0356
0.9645 ± 0.0197
0.9249 ± 0.0402
0.7576 ± 0.0457
0.9294 ± 0.0330
0.8322 ± 0.0862
0.2446 ± 0.0688
0.1060 ± 0.0700
0.1192 ± 0.0544"
REFERENCES,0.5623869801084991,"SVHN
0.8880 ± 0.0354
0.4423 ± 0.0759
0.9266 ± 0.0111
0.9268 ± 0.0191
0.7171 ± 0.0385
0.9422 ± 0.0088
0.2773 ± 0.0891
0.9542 ± 0.0316
0.1839 ± 0.0294"
REFERENCES,0.5641952983725136,"Textures
0.8849 ± 0.0114
0.7291 ± 0.0382
0.8742 ± 0.0099
0.7669 ± 0.0132
0.6743 ± 0.0357
0.7548 ± 0.0152
0.3722 ± 0.0541
0.8883 ± 0.0343
0.4320 ± 0.0437"
REFERENCES,0.566003616636528,"LSUN
0.9201 ± 0.0041
0.8262 ± 0.0181
0.9346 ± 0.0052
0.7494 ± 0.0104
0.6769 ± 0.0252
0.7747 ± 0.0169
0.2860 ± 0.0119
0.7493 ± 0.0224
0.2343 ± 0.0136"
REFERENCES,0.5678119349005425,"TinyImageNet
0.8899 ± 0.0072
0.7721 ± 0.0096
0.9057 ± 0.0044
0.8724 ± 0.0071
0.8021 ± 0.0087
0.8898 ± 0.0049
0.4086 ± 0.0326
0.8286 ± 0.0081
0.3584 ± 0.0197"
REFERENCES,0.569620253164557,"Places365
0.9030 ± 0.0059
0.7793 ± 0.0128
0.9156 ± 0.0040
0.9650 ± 0.0021
0.9318 ± 0.0042
0.9693 ± 0.0016
0.3693 ± 0.0225
0.8419 ± 0.0152
0.3225 ± 0.0126"
REFERENCES,0.5714285714285714,"Average
0.8796 ± 0.0355
0.7833 ± 0.1642
0.9029 ± 0.0319
0.8181 ± 0.0957
0.8116 ± 0.1155
0.8421 ± 0.0870
0.3222 ± 0.0562
0.6379 ± 0.3441
0.2762 ± 0.0987"
REFERENCES,0.5732368896925859,CIFAR-100
REFERENCES,0.5750452079566004,"Gaussian Noise
0.2613 ± 0.0566
0.9158 ± 0.0781
0.8128 ± 0.0815
0.3657 ± 0.0169
0.8444 ± 0.1359
0.6856 ± 0.0920
0.8050 ± 0.0531
0.1430 ± 0.1170
0.2883 ± 0.0914"
REFERENCES,0.5768535262206148,"Uniform Noise
0.7004 ± 0.0573
0.7754 ± 0.2019
0.6778 ± 0.0991
0.5664 ± 0.0464
0.7035 ± 0.1933
0.5565 ± 0.0740
0.3918 ± 0.0625
0.3473 ± 0.2581
0.4136 ± 0.1134"
REFERENCES,0.5786618444846293,"SVHN
0.7763 ± 0.0206
0.5954 ± 0.0330
0.7686 ± 0.0230
0.8414 ± 0.0158
0.7434 ± 0.0234
0.8269 ± 0.0137
0.5026 ± 0.0291
0.8058 ± 0.0457
0.4757 ± 0.0466"
REFERENCES,0.5804701627486437,"Textures
0.7045 ± 0.0072
0.6451 ± 0.0029
0.6860 ± 0.0087
0.5062 ± 0.0065
0.4727 ± 0.0065
0.4850 ± 0.0068
0.7266 ± 0.0132
0.8539 ± 0.0122
0.7586 ± 0.0162"
REFERENCES,0.5822784810126582,"LSUN
0.7195 ± 0.0057
0.6886 ± 0.0082
0.7295 ± 0.0038
0.3714 ± 0.0073
0.3550 ± 0.0104
0.3775 ± 0.0054
0.7125 ± 0.0101
0.8057 ± 0.0094
0.6662 ± 0.0075"
REFERENCES,0.5840867992766727,"TinyImageNet
0.7855 ± 0.0024
0.7350 ± 0.0047
0.7942 ± 0.0010
0.7478 ± 0.0033
0.6916 ± 0.0071
0.7594 ± 0.0027
0.6305 ± 0.0018
0.7495 ± 0.0058
0.6150 ± 0.0039"
REFERENCES,0.5858951175406871,"Places365
0.7569 ± 0.0040
0.6909 ± 0.0006
0.7665 ± 0.0041
0.9009 ± 0.0020
0.8720 ± 0.0008
0.9043 ± 0.0025
0.6873 ± 0.0055
0.8165 ± 0.0103
0.6574 ± 0.0082"
REFERENCES,0.5877034358047016,"Average
0.6721 ± 0.1706
0.7209 ± 0.0961
0.7479 ± 0.0481
0.6143 ± 0.2022
0.6689 ± 0.1758
0.6565 ± 0.1769
0.6366 ± 0.1324
0.6460 ± 0.2609
0.5535 ± 0.1537 SVHN"
REFERENCES,0.5895117540687161,"Gaussian Noise
0.9150 ± 0.0220
0.8192 ± 0.1718
0.8406 ± 0.0894
0.7778 ± 0.0484
0.7466 ± 0.2167
0.6500 ± 0.1680
0.3248 ± 0.0859
0.5670 ± 0.4085
0.4952 ± 0.2378"
REFERENCES,0.5913200723327305,"Uniform Noise
0.9007 ± 0.0148
0.7946 ± 0.1221
0.8251 ± 0.0875
0.7371 ± 0.0478
0.7089 ± 0.1539
0.6260 ± 0.1636
0.3753 ± 0.0504
0.6984 ± 0.3347
0.5352 ± 0.2273"
REFERENCES,0.593128390596745,"CIFAR-100
0.9229 ± 0.0072
0.9218 ± 0.0121
0.9122 ± 0.0101
0.8174 ± 0.0136
0.8807 ± 0.0148
0.7858 ± 0.0208
0.3321 ± 0.0450
0.5889 ± 0.0847
0.3605 ± 0.0459"
REFERENCES,0.5949367088607594,"Textures
0.8862 ± 0.0080
0.8616 ± 0.0343
0.8639 ± 0.0245
0.6555 ± 0.0267
0.7611 ± 0.0505
0.6281 ± 0.0447
0.5292 ± 0.0311
0.8726 ± 0.0616
0.6217 ± 0.1184"
REFERENCES,0.596745027124774,"LSUN
0.9203 ± 0.0100
0.9293 ± 0.0170
0.8928 ± 0.0210
0.5992 ± 0.0367
0.7856 ± 0.0333
0.5053 ± 0.0525
0.3448 ± 0.0522
0.5317 ± 0.1322
0.4416 ± 0.0824"
REFERENCES,0.5985533453887885,"TinyImageNet
0.9283 ± 0.0067
0.9308 ± 0.0147
0.9197 ± 0.0117
0.8266 ± 0.0155
0.8942 ± 0.0196
0.7994 ± 0.0244
0.2979 ± 0.0351
0.5233 ± 0.1276
0.3210 ± 0.0475"
REFERENCES,0.6003616636528029,"Places365
0.9243 ± 0.0086
0.9309 ± 0.0196
0.9111 ± 0.0164
0.9363 ± 0.0076
0.9574 ± 0.0114
0.9235 ± 0.0134
0.3179 ± 0.0443
0.4968 ± 0.1675
0.3668 ± 0.0740"
REFERENCES,0.6021699819168174,"Average
0.9140 ± 0.0140
0.8840 ± 0.0542
0.8808 ± 0.0350
0.7643 ± 0.1044
0.8192 ± 0.0849
0.7026 ± 0.1300
0.3603 ± 0.0724
0.6113 ± 0.1228
0.4489 ± 0.1003"
REFERENCES,0.6039783001808319,TinyImageNet
REFERENCES,0.6057866184448463,"Gaussian Noise
0.5227 ± 0.1378
0.4536 ± 0.2639
0.8491 ± 0.1009
0.4717 ± 0.0648
0.4843 ± 0.1818
0.7936 ± 0.1324
0.6961 ± 0.1173
0.6887 ± 0.2240
0.3730 ± 0.1908"
REFERENCES,0.6075949367088608,"Uniform Noise
0.3399 ± 0.0730
0.4879 ± 0.1808
0.4347 ± 0.1476
0.3868 ± 0.0259
0.4730 ± 0.1057
0.4313 ± 0.0622
0.8750 ± 0.0345
0.6881 ± 0.1671
0.7789 ± 0.1042"
REFERENCES,0.6094032549728752,"SVHN
0.6734 ± 0.0499
0.5505 ± 0.1357
0.8127 ± 0.0385
0.7781 ± 0.0410
0.7066 ± 0.0674
0.8950 ± 0.0267
0.6508 ± 0.0418
0.7373 ± 0.1069
0.5301 ± 0.0585"
REFERENCES,0.6112115732368897,"CIFAR-100
0.5778 ± 0.0041
0.5522 ± 0.0167
0.5958 ± 0.0032
0.5500 ± 0.0031
0.5287 ± 0.0136
0.5691 ± 0.0028
0.8775 ± 0.0042
0.8945 ± 0.0112
0.8663 ± 0.0029"
REFERENCES,0.6130198915009042,"Textures
0.5620 ± 0.0187
0.5396 ± 0.0378
0.5874 ± 0.0114
0.3813 ± 0.0185
0.3839 ± 0.0279
0.4200 ± 0.0131
0.8539 ± 0.0055
0.8886 ± 0.0234
0.8650 ± 0.0120"
REFERENCES,0.6148282097649186,"LSUN
0.5810 ± 0.0081
0.5489 ± 0.0454
0.5598 ± 0.0069
0.2612 ± 0.0063
0.2487 ± 0.0306
0.2461 ± 0.0048
0.8436 ± 0.0051
0.8699 ± 0.0274
0.8457 ± 0.0085"
REFERENCES,0.6166365280289331,"Places365
0.6135 ± 0.0038
0.5972 ± 0.0276
0.6087 ± 0.0037
0.8287 ± 0.0019
0.8241 ± 0.0129
0.8265 ± 0.0016
0.8212 ± 0.0038
0.8411 ± 0.0292
0.8189 ± 0.0045"
REFERENCES,0.6184448462929476,"Average
0.5529 ± 0.0971
0.5328 ± 0.0438
0.6355 ± 0.1350
0.5226 ± 0.1961
0.5213 ± 0.1785
0.5974 ± 0.2277
0.8026 ± 0.0845
0.8012 ± 0.0863
0.7254 ± 0.1804"
REFERENCES,0.620253164556962,"Average
0.7546 ± 0.1792
0.7303 ± 0.1632
0.7918 ± 0.1318
0.6798 ± 0.1966
0.7053 ± 0.1889
0.6996 ± 0.1872
0.5304 ± 0.2184
0.6741 ± 0.2404
0.5010 ± 0.2135"
REFERENCES,0.6220614828209765,Table 7: Expanded results for Energy Score.
REFERENCES,0.6238698010849909,Under review as a conference paper at ICLR 2022
REFERENCES,0.6256781193490054,Maximum Softmax Probability Detector
REFERENCES,0.6274864376130199,"In-Dataset
OoD Dataset
AUROC
AUPR
FPR95"
REFERENCES,0.6292947558770343,"Intra
Intra + Cos(θ)
Intra
Intra + Cos(θ)
Intra
Intra + Cos(θ)"
REFERENCES,0.6311030741410488,CIFAR-10
REFERENCES,0.6329113924050633,"Gaussian Noise
0.8191 ± 0.0697
0.9207 ± 0.0195
0.7116 ± 0.0969
0.8191 ± 0.0463
0.3168 ± 0.0862
0.1070 ± 0.0294"
REFERENCES,0.6347197106690777,"Uniform Noise
0.9452 ± 0.0310
0.9549 ± 0.0229
0.9007 ± 0.0698
0.9105 ± 0.0599
0.1188 ± 0.0341
0.0894 ± 0.0186"
REFERENCES,0.6365280289330922,"SVHN
0.9175 ± 0.0105
0.9209 ± 0.0101
0.9474 ± 0.0071
0.9486 ± 0.0068
0.2135 ± 0.0230
0.2023 ± 0.0344"
REFERENCES,0.6383363471971067,"Textures
0.8674 ± 0.0064
0.9049 ± 0.0098
0.7407 ± 0.0084
0.7806 ± 0.0116
0.4066 ± 0.0330
0.2613 ± 0.0472"
REFERENCES,0.6401446654611211,"LSUN
0.8924 ± 0.0048
0.9166 ± 0.0033
0.6447 ± 0.0069
0.6952 ± 0.0044
0.3075 ± 0.0090
0.2381 ± 0.0174"
REFERENCES,0.6419529837251357,"TinyImageNet
0.8743 ± 0.0014
0.8885 ± 0.0034
0.8409 ± 0.0023
0.8597 ± 0.0027
0.3862 ± 0.0141
0.3964 ± 0.0256"
REFERENCES,0.64376130198915,"Places365
0.8758 ± 0.0033
0.8989 ± 0.0037
0.9497 ± 0.0015
0.9587 ± 0.0008
0.3745 ± 0.0045
0.3299 ± 0.0246"
REFERENCES,0.6455696202531646,"Average
0.8845 ± 0.0370
0.9150 ± 0.0197
0.8194 ± 0.1126
0.8532 ± 0.0886
0.3034 ± 0.0963
0.2321 ± 0.1030"
REFERENCES,0.6473779385171791,CIFAR-100
REFERENCES,0.6491862567811935,"Gaussian Noise
0.7191 ± 0.1088
0.7714 ± 0.0756
0.6208 ± 0.1057
0.6593 ± 0.0951
0.4667 ± 0.1039
0.3616 ± 0.0481"
REFERENCES,0.650994575045208,"Uniform Noise
0.7160 ± 0.0911
0.7453 ± 0.0772
0.6050 ± 0.0981
0.6239 ± 0.0891
0.4393 ± 0.0741
0.3772 ± 0.0528"
REFERENCES,0.6528028933092225,"SVHN
0.7501 ± 0.0355
0.7659 ± 0.0302
0.8560 ± 0.0211
0.8595 ± 0.0189
0.5912 ± 0.0570
0.5370 ± 0.0398"
REFERENCES,0.6546112115732369,"Textures
0.6879 ± 0.0031
0.7176 ± 0.0029
0.5031 ± 0.0046
0.5205 ± 0.0048
0.7566 ± 0.0110
0.6385 ± 0.0068"
REFERENCES,0.6564195298372514,"LSUN
0.7138 ± 0.0018
0.7212 ± 0.0018
0.3746 ± 0.0031
0.3804 ± 0.0038
0.6931 ± 0.0059
0.6876 ± 0.0041"
REFERENCES,0.6582278481012658,"TinyImageNet
0.7494 ± 0.0032
0.7660 ± 0.0029
0.7069 ± 0.0042
0.7238 ± 0.0041
0.6393 ± 0.0037
0.6166 ± 0.0082"
REFERENCES,0.6600361663652803,"Places365
0.7326 ± 0.0029
0.7434 ± 0.0035
0.8885 ± 0.0018
0.8938 ± 0.0020
0.6720 ± 0.0035
0.6782 ± 0.0096"
REFERENCES,0.6618444846292948,"Average
0.7242 ± 0.0203
0.7473 ± 0.0202
0.6507 ± 0.1702
0.6659 ± 0.1679
0.6083 ± 0.1090
0.5566 ± 0.1270 SVHN"
REFERENCES,0.6636528028933092,"Gaussian Noise
0.8602 ± 0.0706
0.9279 ± 0.0285
0.6567 ± 0.1414
0.7550 ± 0.0983
0.4207 ± 0.1935
0.1750 ± 0.0543"
REFERENCES,0.6654611211573237,"Uniform Noise
0.8330 ± 0.0759
0.8903 ± 0.0401
0.6174 ± 0.1388
0.6862 ± 0.1053
0.4974 ± 0.1963
0.3064 ± 0.0954"
REFERENCES,0.6672694394213382,"CIFAR-100
0.9285 ± 0.0031
0.9567 ± 0.0015
0.8072 ± 0.0085
0.8648 ± 0.0053
0.2549 ± 0.0112
0.1302 ± 0.0051"
REFERENCES,0.6690777576853526,"Textures
0.9019 ± 0.0142
0.9319 ± 0.0093
0.6643 ± 0.0299
0.7248 ± 0.0256
0.4037 ± 0.0827
0.2299 ± 0.0444"
REFERENCES,0.6708860759493671,"LSUN
0.9176 ± 0.0063
0.9521 ± 0.0023
0.5419 ± 0.0200
0.6445 ± 0.0172
0.2964 ± 0.0263
0.1401 ± 0.0070"
REFERENCES,0.6726943942133815,"TinyImageNet
0.9339 ± 0.0035
0.9589 ± 0.0016
0.8160 ± 0.0091
0.8711 ± 0.0058
0.2300 ± 0.0146
0.1234 ± 0.0051"
REFERENCES,0.674502712477396,"Places365
0.9266 ± 0.0052
0.9560 ± 0.0022
0.9325 ± 0.0047
0.9565 ± 0.0025
0.2607 ± 0.0220
0.1323 ± 0.0056"
REFERENCES,0.6763110307414105,"Average
0.9003 ± 0.0360
0.9391 ± 0.0230
0.7194 ± 0.1261
0.7861 ± 0.1050
0.3377 ± 0.0948
0.1768 ± 0.0632"
REFERENCES,0.6781193490054249,TinyImageNet
REFERENCES,0.6799276672694394,"Gaussian Noise
0.7089 ± 0.1240
0.7103 ± 0.1186
0.6584 ± 0.1297
0.6510 ± 0.1217
0.6331 ± 0.1384
0.6200 ± 0.1347"
REFERENCES,0.6817359855334539,"Uniform Noise
0.3133 ± 0.1290
0.3151 ± 0.1270
0.3841 ± 0.0419
0.3840 ± 0.0409
0.8869 ± 0.0472
0.8792 ± 0.0479"
REFERENCES,0.6835443037974683,"SVHN
0.6870 ± 0.0422
0.6939 ± 0.0414
0.8233 ± 0.0262
0.8203 ± 0.0269
0.7291 ± 0.0445
0.7066 ± 0.0428"
REFERENCES,0.6853526220614828,"CIFAR-100
0.5934 ± 0.0033
0.5937 ± 0.0031
0.5644 ± 0.0040
0.5634 ± 0.0037
0.8622 ± 0.0031
0.8629 ± 0.0035"
REFERENCES,0.6871609403254972,"Textures
0.5610 ± 0.0109
0.5651 ± 0.0106
0.3913 ± 0.0093
0.3898 ± 0.0089
0.8809 ± 0.0058
0.8645 ± 0.0034"
REFERENCES,0.6889692585895117,"LSUN
0.5892 ± 0.0047
0.5907 ± 0.0052
0.2690 ± 0.0044
0.2671 ± 0.0041
0.8426 ± 0.0057
0.8374 ± 0.0063"
REFERENCES,0.6907775768535263,"Places365
0.6137 ± 0.0029
0.6152 ± 0.0033
0.8316 ± 0.0013
0.8304 ± 0.0014
0.8271 ± 0.0025
0.8210 ± 0.0022"
REFERENCES,0.6925858951175407,"Average
0.5809 ± 0.1201
0.5834 ± 0.1206
0.5603 ± 0.2060
0.5580 ± 0.2053
0.8088 ± 0.0869
0.7988 ± 0.0905"
REFERENCES,0.6943942133815552,"Average
0.7725 ± 0.1461
0.7962 ± 0.1566
0.6875 ± 0.1843
0.7158 ± 0.1874
0.5146 ± 0.2285
0.4411 ± 0.2710"
REFERENCES,0.6962025316455697,"Table 8: Expanded results for Maximum Softmax Probability detector comparing Intra-class mixup
and Intra-class mixup with angular margin."
REFERENCES,0.6980108499095841,Under review as a conference paper at ICLR 2022 ODIN
REFERENCES,0.6998191681735986,"In-Dataset
OoD Dataset
AUROC
AUPR
FPR95"
REFERENCES,0.701627486437613,"Intra
Intra + Cos(θ)
Intra
Intra + Cos(θ)
Intra
Intra + Cos(θ)"
REFERENCES,0.7034358047016275,CIFAR-10
REFERENCES,0.705244122965642,"Gaussian Noise
0.8898 ± 0.0665
0.9435 ± 0.0385
0.8038 ± 0.1183
0.8910 ± 0.0764
0.2091 ± 0.1046
0.1194 ± 0.0705"
REFERENCES,0.7070524412296564,"Uniform Noise
0.9738 ± 0.0105
0.9842 ± 0.0097
0.9453 ± 0.0287
0.9640 ± 0.0249
0.0581 ± 0.0173
0.0367 ± 0.0196"
REFERENCES,0.7088607594936709,"SVHN
0.9598 ± 0.0116
0.9572 ± 0.0153
0.9801 ± 0.0057
0.9785 ± 0.0073
0.1498 ± 0.0388
0.1560 ± 0.0524"
REFERENCES,0.7106690777576854,"Textures
0.8927 ± 0.0128
0.9098 ± 0.0102
0.8078 ± 0.0188
0.8336 ± 0.0145
0.3799 ± 0.0437
0.3296 ± 0.0407"
REFERENCES,0.7124773960216998,"LSUN
0.9243 ± 0.0051
0.9309 ± 0.0047
0.7552 ± 0.0123
0.7715 ± 0.0121
0.2745 ± 0.0233
0.2541 ± 0.0180"
REFERENCES,0.7142857142857143,"TinyImageNet
0.9010 ± 0.0068
0.9036 ± 0.0076
0.8867 ± 0.0074
0.8898 ± 0.0079
0.3857 ± 0.0302
0.3750 ± 0.0308"
REFERENCES,0.7160940325497287,"Places365
0.9086 ± 0.0004
0.9139 ± 0.0019
0.9672 ± 0.0004
0.9691 ± 0.0009
0.3533 ± 0.0036
0.3329 ± 0.0060"
REFERENCES,0.7179023508137432,"Average
0.9214 ± 0.0308
0.9347 ± 0.0269
0.8780 ± 0.0832
0.8996 ± 0.0719
0.2587 ± 0.1162
0.2291 ± 0.1178"
REFERENCES,0.7197106690777577,CIFAR-100
REFERENCES,0.7215189873417721,"Gaussian Noise
0.9365 ± 0.0374
0.9878 ± 0.0087
0.8727 ± 0.0757
0.9738 ± 0.0226
0.1305 ± 0.0661
0.0298 ± 0.0179"
REFERENCES,0.7233273056057866,"Uniform Noise
0.8070 ± 0.1008
0.9357 ± 0.0335
0.6811 ± 0.1122
0.8518 ± 0.0701
0.2741 ± 0.1211
0.1055 ± 0.0479"
REFERENCES,0.7251356238698011,"SVHN
0.8147 ± 0.0247
0.8135 ± 0.0188
0.8859 ± 0.0201
0.8781 ± 0.0175
0.4685 ± 0.0363
0.4592 ± 0.0292"
REFERENCES,0.7269439421338155,"Textures
0.7080 ± 0.0094
0.7679 ± 0.0070
0.5214 ± 0.0095
0.5908 ± 0.0082
0.7478 ± 0.0202
0.6369 ± 0.0209"
REFERENCES,0.72875226039783,"LSUN
0.7625 ± 0.0024
0.7478 ± 0.0040
0.4376 ± 0.0036
0.4138 ± 0.0063
0.6831 ± 0.0113
0.6883 ± 0.0078"
REFERENCES,0.7305605786618445,"TinyImageNet
0.7790 ± 0.0012
0.7804 ± 0.0008
0.7376 ± 0.0016
0.7393 ± 0.0006
0.6370 ± 0.0050
0.6343 ± 0.0076"
REFERENCES,0.7323688969258589,"Places365
0.7778 ± 0.0028
0.7658 ± 0.0043
0.9104 ± 0.0015
0.9048 ± 0.0022
0.6624 ± 0.0059
0.6788 ± 0.0091"
REFERENCES,0.7341772151898734,"Average
0.7979 ± 0.0651
0.8284 ± 0.0874
0.7210 ± 0.1724
0.7646 ± 0.1843
0.5148 ± 0.2162
0.4618 ± 0.2598 SVHN"
REFERENCES,0.7359855334538878,"Gaussian Noise
0.8902 ± 0.0627
0.9764 ± 0.0115
0.7592 ± 0.1302
0.9265 ± 0.0353
0.4052 ± 0.2158
0.0897 ± 0.0411"
REFERENCES,0.7377938517179023,"Uniform Noise
0.5604 ± 0.1762
0.7152 ± 0.0749
0.3311 ± 0.1563
0.4173 ± 0.0785
0.7954 ± 0.2306
0.6907 ± 0.1181"
REFERENCES,0.7396021699819169,"CIFAR-100
0.9264 ± 0.0098
0.9815 ± 0.0016
0.8444 ± 0.0178
0.9531 ± 0.0037
0.3507 ± 0.0491
0.0784 ± 0.0078"
REFERENCES,0.7414104882459313,"Textures
0.8539 ± 0.0330
0.9167 ± 0.0139
0.6394 ± 0.0548
0.7835 ± 0.0252
0.6461 ± 0.1253
0.4404 ± 0.0766"
REFERENCES,0.7432188065099458,"LSUN
0.9081 ± 0.0180
0.9819 ± 0.0015
0.6110 ± 0.0497
0.8683 ± 0.0112
0.4339 ± 0.0754
0.0781 ± 0.0091"
REFERENCES,0.7450271247739603,"TinyImageNet
0.9276 ± 0.0117
0.9810 ± 0.0018
0.8451 ± 0.0213
0.9523 ± 0.0041
0.3414 ± 0.0593
0.0798 ± 0.0074"
REFERENCES,0.7468354430379747,"Places365
0.9168 ± 0.0160
0.9794 ± 0.0019
0.9355 ± 0.0121
0.9831 ± 0.0016
0.3873 ± 0.0763
0.0881 ± 0.0089"
REFERENCES,0.7486437613019892,"Average
0.8548 ± 0.1225
0.9331 ± 0.0916
0.7094 ± 0.1882
0.8406 ± 0.1836
0.4800 ± 0.1601
0.2208 ± 0.2281"
REFERENCES,0.7504520795660036,TinyImageNet
REFERENCES,0.7522603978300181,"Gaussian Noise
0.9772 ± 0.0219
0.9462 ± 0.0364
0.9737 ± 0.0263
0.9386 ± 0.0448
0.0943 ± 0.0854
0.2069 ± 0.0996"
REFERENCES,0.7540687160940326,"Uniform Noise
0.5562 ± 0.1663
0.4426 ± 0.1369
0.5037 ± 0.0968
0.4370 ± 0.0609
0.6776 ± 0.1424
0.7706 ± 0.0794"
REFERENCES,0.755877034358047,"SVHN
0.8180 ± 0.0125
0.7840 ± 0.0230
0.9070 ± 0.0054
0.8864 ± 0.0117
0.5611 ± 0.0282
0.6242 ± 0.0485"
REFERENCES,0.7576853526220615,"CIFAR-100
0.6162 ± 0.0032
0.6059 ± 0.0018
0.5940 ± 0.0032
0.5830 ± 0.0030
0.8576 ± 0.0048
0.8621 ± 0.0035"
REFERENCES,0.759493670886076,"Textures
0.5700 ± 0.0098
0.5789 ± 0.0065
0.4415 ± 0.0132
0.4387 ± 0.0094
0.9140 ± 0.0050
0.8929 ± 0.0054"
REFERENCES,0.7613019891500904,"LSUN
0.6045 ± 0.0052
0.6225 ± 0.0076
0.2803 ± 0.0051
0.2896 ± 0.0050
0.8350 ± 0.0061
0.8032 ± 0.0062"
REFERENCES,0.7631103074141049,"Places365
0.6216 ± 0.0030
0.6158 ± 0.0050
0.8344 ± 0.0016
0.8302 ± 0.0025
0.8232 ± 0.0041
0.8217 ± 0.0026"
REFERENCES,0.7649186256781193,"Average
0.6805 ± 0.1454
0.6566 ± 0.1499
0.6478 ± 0.2419
0.6291 ± 0.2370
0.6804 ± 0.2641
0.7116 ± 0.2210"
REFERENCES,0.7667269439421338,"Average
0.8137 ± 0.1347
0.8382 ± 0.1505
0.7390 ± 0.1996
0.7835 ± 0.2061
0.4835 ± 0.2479
0.4058 ± 0.2934"
REFERENCES,0.7685352622061483,"Table 9: Expanded results for ODIN comparing Intra-class mixup and Intra-class mixup with angular
margin."
REFERENCES,0.7703435804701627,Under review as a conference paper at ICLR 2022
REFERENCES,0.7721518987341772,Energy Score
REFERENCES,0.7739602169981917,"In-Dataset
OoD Dataset
AUROC
AUPR
FPR95"
REFERENCES,0.7757685352622061,"Intra
Intra + Cos(θ)
Intra
Intra + Cos(θ)
Intra
Intra + Cos(θ)"
REFERENCES,0.7775768535262206,CIFAR-10
REFERENCES,0.779385171790235,"Gaussian Noise
0.8390 ± 0.0910
0.9076 ± 0.0591
0.7318 ± 0.1090
0.8164 ± 0.0887
0.2829 ± 0.1262
0.1654 ± 0.0900"
REFERENCES,0.7811934900542495,"Uniform Noise
0.9249 ± 0.0402
0.9472 ± 0.0299
0.8322 ± 0.0862
0.8710 ± 0.0696
0.1192 ± 0.0544
0.0864 ± 0.0416"
REFERENCES,0.783001808318264,"SVHN
0.9266 ± 0.0111
0.9272 ± 0.0116
0.9422 ± 0.0088
0.9432 ± 0.0096
0.1839 ± 0.0294
0.1812 ± 0.0286"
REFERENCES,0.7848101265822784,"Textures
0.8742 ± 0.0099
0.8961 ± 0.0083
0.7548 ± 0.0152
0.7807 ± 0.0170
0.4320 ± 0.0437
0.3380 ± 0.0353"
REFERENCES,0.786618444846293,"LSUN
0.9346 ± 0.0052
0.9356 ± 0.0054
0.7747 ± 0.0169
0.7740 ± 0.0159
0.2343 ± 0.0136
0.2273 ± 0.0162"
REFERENCES,0.7884267631103075,"TinyImageNet
0.9057 ± 0.0044
0.9060 ± 0.0039
0.8898 ± 0.0049
0.8898 ± 0.0043
0.3584 ± 0.0197
0.3581 ± 0.0233"
REFERENCES,0.7902350813743219,"Places365
0.9156 ± 0.0040
0.9166 ± 0.0043
0.9693 ± 0.0016
0.9693 ± 0.0016
0.3225 ± 0.0126
0.3128 ± 0.0176"
REFERENCES,0.7920433996383364,"Average
0.9029 ± 0.0319
0.9195 ± 0.0168
0.8421 ± 0.0870
0.8635 ± 0.0711
0.2762 ± 0.0987
0.2384 ± 0.0938"
REFERENCES,0.7938517179023508,CIFAR-100
REFERENCES,0.7956600361663653,"Gaussian Noise
0.8128 ± 0.0815
0.8435 ± 0.0692
0.6856 ± 0.0920
0.7199 ± 0.0879
0.2883 ± 0.0914
0.2450 ± 0.0788"
REFERENCES,0.7974683544303798,"Uniform Noise
0.6778 ± 0.0991
0.7311 ± 0.0811
0.5565 ± 0.0740
0.5951 ± 0.0717
0.4136 ± 0.1134
0.3513 ± 0.0946"
REFERENCES,0.7992766726943942,"SVHN
0.7686 ± 0.0230
0.7724 ± 0.0240
0.8269 ± 0.0137
0.8312 ± 0.0146
0.4757 ± 0.0466
0.4729 ± 0.0481"
REFERENCES,0.8010849909584087,"Textures
0.6860 ± 0.0087
0.7078 ± 0.0068
0.4850 ± 0.0068
0.5022 ± 0.0061
0.7586 ± 0.0162
0.7043 ± 0.0102"
REFERENCES,0.8028933092224232,"LSUN
0.7295 ± 0.0038
0.7278 ± 0.0040
0.3775 ± 0.0054
0.3771 ± 0.0054
0.6662 ± 0.0075
0.6719 ± 0.0072"
REFERENCES,0.8047016274864376,"TinyImageNet
0.7942 ± 0.0010
0.7942 ± 0.0011
0.7594 ± 0.0027
0.7593 ± 0.0028
0.6150 ± 0.0039
0.6171 ± 0.0050"
REFERENCES,0.8065099457504521,"Places365
0.7665 ± 0.0041
0.7644 ± 0.0041
0.9043 ± 0.0025
0.9037 ± 0.0026
0.6574 ± 0.0082
0.6643 ± 0.0087"
REFERENCES,0.8083182640144665,"Average
0.7479 ± 0.0481
0.7630 ± 0.0428
0.6565 ± 0.1769
0.6698 ± 0.1735
0.5535 ± 0.1537
0.5324 ± 0.1658 SVHN"
REFERENCES,0.810126582278481,"Gaussian Noise
0.8406 ± 0.0894
0.9078 ± 0.0500
0.6500 ± 0.1680
0.7647 ± 0.1187
0.4952 ± 0.2378
0.3170 ± 0.1596"
REFERENCES,0.8119349005424955,"Uniform Noise
0.8251 ± 0.0875
0.8685 ± 0.0614
0.6260 ± 0.1636
0.6893 ± 0.1276
0.5352 ± 0.2273
0.4348 ± 0.1837"
REFERENCES,0.8137432188065099,"CIFAR-100
0.9122 ± 0.0101
0.9521 ± 0.0039
0.7858 ± 0.0208
0.8773 ± 0.0085
0.3605 ± 0.0459
0.1918 ± 0.0143"
REFERENCES,0.8155515370705244,"Textures
0.8639 ± 0.0245
0.9126 ± 0.0158
0.6281 ± 0.0447
0.7269 ± 0.0341
0.6217 ± 0.1184
0.3978 ± 0.0896"
REFERENCES,0.8173598553345389,"LSUN
0.8928 ± 0.0210
0.9423 ± 0.0092
0.5053 ± 0.0525
0.6789 ± 0.0357
0.4416 ± 0.0824
0.2412 ± 0.0371"
REFERENCES,0.8191681735985533,"TinyImageNet
0.9197 ± 0.0117
0.9563 ± 0.0048
0.7994 ± 0.0244
0.8862 ± 0.0107
0.3210 ± 0.0475
0.1729 ± 0.0183"
REFERENCES,0.8209764918625678,"Places365
0.9111 ± 0.0164
0.9513 ± 0.0072
0.9235 ± 0.0134
0.9590 ± 0.0058
0.3668 ± 0.0740
0.1980 ± 0.0310"
REFERENCES,0.8227848101265823,"Average
0.8808 ± 0.0350
0.9273 ± 0.0300
0.7026 ± 0.1300
0.7975 ± 0.1015
0.4489 ± 0.1003
0.2791 ± 0.0976"
REFERENCES,0.8245931283905967,TinyImageNet
REFERENCES,0.8264014466546112,"Gaussian Noise
0.8491 ± 0.1009
0.7804 ± 0.1048
0.7936 ± 0.1324
0.7042 ± 0.1267
0.3730 ± 0.1908
0.4802 ± 0.1457"
REFERENCES,0.8282097649186256,"Uniform Noise
0.4347 ± 0.1476
0.3757 ± 0.1311
0.4313 ± 0.0622
0.4043 ± 0.0469
0.7789 ± 0.1042
0.8095 ± 0.0831"
REFERENCES,0.8300180831826401,"SVHN
0.8127 ± 0.0385
0.7603 ± 0.0384
0.8950 ± 0.0267
0.8500 ± 0.0286
0.5301 ± 0.0585
0.5699 ± 0.0509"
REFERENCES,0.8318264014466547,"CIFAR-100
0.5958 ± 0.0032
0.5929 ± 0.0029
0.5691 ± 0.0028
0.5631 ± 0.0032
0.8663 ± 0.0029
0.8642 ± 0.0041"
REFERENCES,0.833634719710669,"Textures
0.5874 ± 0.0114
0.5757 ± 0.0106
0.4200 ± 0.0131
0.3936 ± 0.0099
0.8650 ± 0.0120
0.8494 ± 0.0083"
REFERENCES,0.8354430379746836,"LSUN
0.5598 ± 0.0069
0.5736 ± 0.0066
0.2461 ± 0.0048
0.2525 ± 0.0044
0.8457 ± 0.0085
0.8335 ± 0.0084"
REFERENCES,0.8372513562386981,"Places365
0.6087 ± 0.0037
0.6105 ± 0.0039
0.8265 ± 0.0016
0.8257 ± 0.0017
0.8189 ± 0.0045
0.8113 ± 0.0040"
REFERENCES,0.8390596745027125,"Average
0.6355 ± 0.1350
0.6099 ± 0.1250
0.5974 ± 0.2277
0.5705 ± 0.2142
0.7254 ± 0.1804
0.7454 ± 0.1426"
REFERENCES,0.840867992766727,"Average
0.7918 ± 0.1318
0.8049 ± 0.1471
0.6996 ± 0.1872
0.7253 ± 0.1889
0.5010 ± 0.2135
0.4488 ± 0.2420"
REFERENCES,0.8426763110307414,"Table 10: Expanded results for Energy Score comparing Intra-class mixup and Intra-class mixup with
angular margin."
REFERENCES,0.8444846292947559,"In-Dist
AUROC
AUPR
FPR95"
REFERENCES,0.8462929475587704,"ERM
Inter
Intra
ERM
Inter
Intra
ERM
Inter
Intra"
REFERENCES,0.8481012658227848,"CIFAR-10
0.8370 ± 0.0166
0.8785 ± 0.0031
0.8478 ± 0.0054
0.8145 ± 0.0082
0.8407 ± 0.0032
0.8386 ± 0.0066
0.6734 ± 0.1512
0.3558 ± 0.0092
0.6792 ± 0.0000"
REFERENCES,0.8499095840867993,"Table 11: CIFAR-10 (In-Dist) vs CIFAR-100 (OoD) detection results for Maximum Softmax Proba-
bility detector."
REFERENCES,0.8517179023508138,Under review as a conference paper at ICLR 2022
REFERENCES,0.8535262206148282,Maximum Softmax Probability Detector with Supplemental Angular Margin trained with ERM
REFERENCES,0.8553345388788427,"In-Dataset
OoD Dataset
AUROC
AUPR
FPR95"
REFERENCES,0.8571428571428571,"ERM
ERM + cos (θ)
ERM
ERM + cos (θ)
ERM
ERM + cos (θ)"
REFERENCES,0.8589511754068716,CIFAR-10
REFERENCES,0.8607594936708861,"Gaussian Noise
0.6991 ± 0.2232
0.8546 ± 0.0843
0.6451 ± 0.2250
0.7479 ± 0.1313
0.6103 ± 0.3818
0.2192 ± 0.1015"
REFERENCES,0.8625678119349005,"Uniform Noise
0.8722 ± 0.0308
0.8925 ± 0.0268
0.8005 ± 0.0413
0.8066 ± 0.0473
0.3513 ± 0.2029
0.2015 ± 0.0560"
REFERENCES,0.864376130198915,"SVHN
0.8111 ± 0.0901
0.8961 ± 0.0249
0.9005 ± 0.0402
0.9300 ± 0.0185
0.6102 ± 0.2288
0.2339 ± 0.0399"
REFERENCES,0.8661844484629295,"Textures
0.8448 ± 0.0089
0.8994 ± 0.0101
0.7311 ± 0.0058
0.7754 ± 0.0091
0.6698 ± 0.1196
0.2940 ± 0.0399"
REFERENCES,0.8679927667269439,"LSUN
0.8598 ± 0.0177
0.9050 ± 0.0041
0.6262 ± 0.0203
0.6821 ± 0.0117
0.6217 ± 0.1507
0.3098 ± 0.0216"
REFERENCES,0.8698010849909584,"TinyImageNet
0.8344 ± 0.0143
0.8778 ± 0.0041
0.8169 ± 0.0078
0.8471 ± 0.0044
0.7070 ± 0.1248
0.4295 ± 0.0077"
REFERENCES,0.8716094032549728,"Places365
0.8422 ± 0.0155
0.8879 ± 0.0041
0.9418 ± 0.0040
0.9554 ± 0.0013
0.6851 ± 0.1368
0.3935 ± 0.0210"
REFERENCES,0.8734177215189873,"Average
0.8234 ± 0.0538
0.8876 ± 0.0157
0.7803 ± 0.1113
0.8206 ± 0.0907
0.6079 ± 0.1106
0.2974 ± 0.0812"
REFERENCES,0.8752260397830018,CIFAR-100
REFERENCES,0.8770343580470162,"Gaussian Noise
0.2596 ± 0.0665
0.3761 ± 0.0693
0.3647 ± 0.0181
0.4026 ± 0.0242
0.8237 ± 0.0798
0.6752 ± 0.0729"
REFERENCES,0.8788426763110307,"Uniform Noise
0.7941 ± 0.0627
0.8030 ± 0.0547
0.6889 ± 0.0805
0.6894 ± 0.0709
0.3759 ± 0.0618
0.3441 ± 0.0441"
REFERENCES,0.8806509945750453,"SVHN
0.7426 ± 0.0273
0.7686 ± 0.0187
0.8507 ± 0.0173
0.8597 ± 0.0144
0.6120 ± 0.0456
0.5155 ± 0.0118"
REFERENCES,0.8824593128390597,"Textures
0.6948 ± 0.0038
0.7200 ± 0.0046
0.5075 ± 0.0046
0.5242 ± 0.0048
0.7322 ± 0.0079
0.6472 ± 0.0105"
REFERENCES,0.8842676311030742,"LSUN
0.7020 ± 0.0051
0.7101 ± 0.0048
0.3591 ± 0.0061
0.3666 ± 0.0058
0.7094 ± 0.0059
0.7182 ± 0.0063"
REFERENCES,0.8860759493670886,"TinyImageNet
0.7382 ± 0.0026
0.7577 ± 0.0023
0.6900 ± 0.0042
0.7092 ± 0.0038
0.6518 ± 0.0025
0.6239 ± 0.0047"
REFERENCES,0.8878842676311031,"Places365
0.7201 ± 0.0040
0.7327 ± 0.0035
0.8818 ± 0.0022
0.8881 ± 0.0020
0.6992 ± 0.0066
0.7068 ± 0.0036"
REFERENCES,0.8896925858951176,"Average
0.6645 ± 0.1680
0.6955 ± 0.1336
0.6204 ± 0.1990
0.6343 ± 0.1932
0.6577 ± 0.1304
0.6044 ± 0.1233 SVHN"
REFERENCES,0.891500904159132,"Gaussian Noise
0.9218 ± 0.0141
0.9376 ± 0.0102
0.7770 ± 0.0298
0.8058 ± 0.0263
0.2575 ± 0.0560
0.1884 ± 0.0338"
REFERENCES,0.8933092224231465,"Uniform Noise
0.9247 ± 0.0061
0.9391 ± 0.0038
0.7845 ± 0.0061
0.8097 ± 0.0065
0.2494 ± 0.0335
0.1863 ± 0.0186"
REFERENCES,0.895117540687161,"CIFAR-100
0.9267 ± 0.0042
0.9416 ± 0.0023
0.7993 ± 0.0067
0.8303 ± 0.0050
0.2552 ± 0.0257
0.1919 ± 0.0114"
REFERENCES,0.8969258589511754,"Textures
0.9066 ± 0.0059
0.9250 ± 0.0053
0.6651 ± 0.0154
0.7068 ± 0.0150
0.3723 ± 0.0364
0.2685 ± 0.0310"
REFERENCES,0.8987341772151899,"LSUN
0.9258 ± 0.0051
0.9409 ± 0.0033
0.5614 ± 0.0133
0.6108 ± 0.0136
0.2534 ± 0.0260
0.1912 ± 0.0155"
REFERENCES,0.9005424954792043,"TinyImageNet
0.9308 ± 0.0037
0.9453 ± 0.0022
0.8071 ± 0.0066
0.8392 ± 0.0050
0.2306 ± 0.0221
0.1738 ± 0.0121"
REFERENCES,0.9023508137432188,"Places365
0.9281 ± 0.0047
0.9442 ± 0.0030
0.9324 ± 0.0034
0.9460 ± 0.0026
0.2436 ± 0.0256
0.1781 ± 0.0138"
REFERENCES,0.9041591320072333,"Average
0.9235 ± 0.0074
0.9391 ± 0.0063
0.7610 ± 0.1088
0.7927 ± 0.0986
0.2660 ± 0.0442
0.1969 ± 0.0299"
REFERENCES,0.9059674502712477,TinyImageNet
REFERENCES,0.9077757685352622,"Gaussian Noise
0.5506 ± 0.1104
0.5598 ± 0.1041
0.4911 ± 0.0665
0.4941 ± 0.0638
0.7374 ± 0.1040
0.7174 ± 0.1011"
REFERENCES,0.9095840867992767,"Uniform Noise
0.2977 ± 0.0686
0.3028 ± 0.0708
0.3726 ± 0.0220
0.3743 ± 0.0230
0.9064 ± 0.0255
0.8966 ± 0.0242"
REFERENCES,0.9113924050632911,"SVHN
0.6747 ± 0.0258
0.6806 ± 0.0269
0.7956 ± 0.0237
0.7955 ± 0.0240
0.7187 ± 0.0201
0.7025 ± 0.0201"
REFERENCES,0.9132007233273056,"CIFAR-100
0.5774 ± 0.0034
0.5775 ± 0.0035
0.5491 ± 0.0038
0.5486 ± 0.0040
0.8718 ± 0.0035
0.8730 ± 0.0032"
REFERENCES,0.9150090415913201,"Textures
0.5555 ± 0.0078
0.5609 ± 0.0078
0.3801 ± 0.0099
0.3818 ± 0.0092
0.8702 ± 0.0056
0.8580 ± 0.0046"
REFERENCES,0.9168173598553345,"LSUN
0.5897 ± 0.0051
0.5901 ± 0.0048
0.2709 ± 0.0041
0.2697 ± 0.0042
0.8451 ± 0.0044
0.8437 ± 0.0051"
REFERENCES,0.918625678119349,"Places365
0.6117 ± 0.0045
0.6134 ± 0.0037
0.8309 ± 0.0014
0.8308 ± 0.0015
0.8334 ± 0.0042
0.8288 ± 0.0041"
REFERENCES,0.9204339963833634,"Average
0.5510 ± 0.1104
0.5550 ± 0.1099
0.5272 ± 0.1990
0.5278 ± 0.1987
0.8261 ± 0.0658
0.8171 ± 0.0708"
REFERENCES,0.9222423146473779,"Average
0.7406 ± 0.1771
0.7693 ± 0.1764
0.6722 ± 0.1915
0.6939 ± 0.1948
0.5895 ± 0.2243
0.4789 ± 0.2600"
REFERENCES,0.9240506329113924,"Table 12: Expanded results for Maximum Softmax Probability Detector with Supplemental Angular
Margin trained with ERM."
REFERENCES,0.9258589511754068,Under review as a conference paper at ICLR 2022
REFERENCES,0.9276672694394213,Maximum Softmax Probability Detector with Supplemental Angular Margin trained with Inter-class Mixup
REFERENCES,0.9294755877034359,"In-Dataset
OoD Dataset
AUROC
AUPR
FPR95"
REFERENCES,0.9312839059674503,"Inter
Inter + cos (θ)
Inter
Inter + cos (θ)
Inter
Inter + cos (θ)"
REFERENCES,0.9330922242314648,CIFAR-10
REFERENCES,0.9349005424954792,"Gaussian Noise
0.9470 ± 0.0471
0.9573 ± 0.0448
0.9073 ± 0.0816
0.9260 ± 0.0777
0.1290 ± 0.1128
0.1077 ± 0.1152"
REFERENCES,0.9367088607594937,"Uniform Noise
0.9462 ± 0.0383
0.9477 ± 0.0433
0.9059 ± 0.0621
0.9116 ± 0.0633
0.1383 ± 0.0960
0.1492 ± 0.1395"
REFERENCES,0.9385171790235082,"SVHN
0.8539 ± 0.0386
0.8523 ± 0.0405
0.9263 ± 0.0167
0.9245 ± 0.0179
0.6285 ± 0.1962
0.6131 ± 0.1681"
REFERENCES,0.9403254972875226,"Textures
0.8471 ± 0.0144
0.8472 ± 0.0113
0.7677 ± 0.0147
0.7782 ± 0.0117
0.7438 ± 0.0782
0.7583 ± 0.0652"
REFERENCES,0.9421338155515371,"LSUN
0.8888 ± 0.0063
0.9064 ± 0.0061
0.7074 ± 0.0111
0.7446 ± 0.0122
0.5010 ± 0.0439
0.4107 ± 0.0451"
REFERENCES,0.9439421338155516,"TinyImageNet
0.8484 ± 0.0046
0.8441 ± 0.0021
0.8456 ± 0.0052
0.8496 ± 0.0038
0.6929 ± 0.0187
0.7481 ± 0.0022"
REFERENCES,0.945750452079566,"Places365
0.8546 ± 0.0055
0.8713 ± 0.0060
0.9510 ± 0.0018
0.9570 ± 0.0019
0.6920 ± 0.0307
0.6163 ± 0.0425"
REFERENCES,0.9475587703435805,"Average
0.8837 ± 0.0419
0.8895 ± 0.0445
0.8587 ± 0.0837
0.8702 ± 0.0756
0.5037 ± 0.2445
0.4862 ± 0.2502"
REFERENCES,0.9493670886075949,CIFAR-100
REFERENCES,0.9511754068716094,"Gaussian Noise
0.8916 ± 0.0579
0.9012 ± 0.0502
0.7963 ± 0.0875
0.8070 ± 0.0810
0.2005 ± 0.0778
0.1832 ± 0.0712"
REFERENCES,0.9529837251356239,"Uniform Noise
0.7464 ± 0.2002
0.7559 ± 0.1863
0.6705 ± 0.1818
0.6708 ± 0.1714
0.3751 ± 0.2218
0.3527 ± 0.2003"
REFERENCES,0.9547920433996383,"SVHN
0.7460 ± 0.0302
0.7569 ± 0.0315
0.8423 ± 0.0150
0.8488 ± 0.0159
0.6137 ± 0.0796
0.5830 ± 0.0761"
REFERENCES,0.9566003616636528,"Textures
0.7454 ± 0.0030
0.7571 ± 0.0030
0.5502 ± 0.0047
0.5622 ± 0.0039
0.6451 ± 0.0133
0.6032 ± 0.0118"
REFERENCES,0.9584086799276673,"LSUN
0.7417 ± 0.0037
0.7479 ± 0.0034
0.4014 ± 0.0076
0.4065 ± 0.0078
0.7162 ± 0.0130
0.6871 ± 0.0113"
REFERENCES,0.9602169981916817,"TinyImageNet
0.7857 ± 0.0023
0.7958 ± 0.0022
0.7447 ± 0.0022
0.7573 ± 0.0023
0.6305 ± 0.0133
0.6047 ± 0.0109"
REFERENCES,0.9620253164556962,"Places365
0.7560 ± 0.0019
0.7645 ± 0.0016
0.8989 ± 0.0011
0.9026 ± 0.0011
0.7035 ± 0.0043
0.6716 ± 0.0037"
REFERENCES,0.9638336347197106,"Average
0.7733 ± 0.0503
0.7828 ± 0.0504
0.7006 ± 0.1619
0.7079 ± 0.1619
0.5549 ± 0.1786
0.5265 ± 0.1732 SVHN"
REFERENCES,0.9656419529837251,"Gaussian Noise
0.8198 ± 0.1368
0.8921 ± 0.0841
0.6935 ± 0.2014
0.7639 ± 0.1620
0.6185 ± 0.4020
0.4099 ± 0.2984"
REFERENCES,0.9674502712477396,"Uniform Noise
0.7706 ± 0.1228
0.8136 ± 0.1033
0.6385 ± 0.1586
0.6726 ± 0.1441
0.7598 ± 0.3313
0.6637 ± 0.2931"
REFERENCES,0.969258589511754,"CIFAR-100
0.9340 ± 0.0071
0.9481 ± 0.0044
0.8672 ± 0.0108
0.8875 ± 0.0075
0.3282 ± 0.0841
0.2184 ± 0.0385"
REFERENCES,0.9710669077757685,"Textures
0.8851 ± 0.0253
0.9136 ± 0.0181
0.7391 ± 0.0417
0.7728 ± 0.0336
0.7703 ± 0.1736
0.5329 ± 0.1445"
REFERENCES,0.972875226039783,"LSUN
0.9353 ± 0.0110
0.9529 ± 0.0066
0.7183 ± 0.0313
0.7612 ± 0.0241
0.3332 ± 0.1233
0.1886 ± 0.0421"
REFERENCES,0.9746835443037974,"TinyImageNet
0.9354 ± 0.0105
0.9509 ± 0.0062
0.8732 ± 0.0176
0.8952 ± 0.0123
0.3254 ± 0.1094
0.2036 ± 0.0478"
REFERENCES,0.976491862567812,"Places365
0.9355 ± 0.0133
0.9521 ± 0.0083
0.9540 ± 0.0087
0.9642 ± 0.0059
0.3307 ± 0.1388
0.1968 ± 0.0607"
REFERENCES,0.9783001808318263,"Average
0.8880 ± 0.0624
0.9176 ± 0.0477
0.7834 ± 0.1065
0.8168 ± 0.0937
0.4952 ± 0.1967
0.3448 ± 0.1787"
REFERENCES,0.9801084990958409,TinyImageNet
REFERENCES,0.9819168173598554,"Gaussian Noise
0.4041 ± 0.1878
0.4063 ± 0.1324
0.4355 ± 0.1123
0.4176 ± 0.0562
0.7842 ± 0.1274
0.7800 ± 0.0989"
REFERENCES,0.9837251356238698,"Uniform Noise
0.3944 ± 0.1244
0.3678 ± 0.1272
0.4104 ± 0.0488
0.4008 ± 0.0469
0.7805 ± 0.1021
0.7911 ± 0.1043"
REFERENCES,0.9855334538878843,"SVHN
0.6042 ± 0.0915
0.5479 ± 0.0750
0.7473 ± 0.0607
0.7004 ± 0.0417
0.7458 ± 0.0843
0.7622 ± 0.0695"
REFERENCES,0.9873417721518988,"CIFAR-100
0.5680 ± 0.0098
0.5671 ± 0.0094
0.5423 ± 0.0095
0.5393 ± 0.0096
0.8819 ± 0.0034
0.8818 ± 0.0023"
REFERENCES,0.9891500904159132,"Textures
0.5435 ± 0.0143
0.5195 ± 0.0093
0.3756 ± 0.0091
0.3506 ± 0.0062
0.8786 ± 0.0094
0.8793 ± 0.0089"
REFERENCES,0.9909584086799277,"LSUN
0.5727 ± 0.0263
0.5750 ± 0.0195
0.2615 ± 0.0186
0.2598 ± 0.0112
0.8639 ± 0.0185
0.8581 ± 0.0188"
REFERENCES,0.9927667269439421,"Places365
0.6032 ± 0.0106
0.6040 ± 0.0148
0.8270 ± 0.0061
0.8258 ± 0.0088
0.8424 ± 0.0070
0.8377 ± 0.0085"
REFERENCES,0.9945750452079566,"Average
0.5272 ± 0.0832
0.5125 ± 0.0835
0.5142 ± 0.1901
0.4992 ± 0.1869
0.8253 ± 0.0505
0.8271 ± 0.0455"
REFERENCES,0.9963833634719711,"Average
0.7680 ± 0.1588
0.7693 ± 0.1764
0.7142 ± 0.1914
0.7235 ± 0.1977
0.5895 ± 0.2243
0.5462 ± 0.2500"
REFERENCES,0.9981916817359855,"Table 13: Expanded results for Maximum Softmax Probability Detector with Supplemental Angular
Margin trained with Inter-class Mixup."
