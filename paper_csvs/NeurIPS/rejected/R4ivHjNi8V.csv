Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.002188183807439825,"The tensor nuclear norm represents the low-rank property of tensor slices under
1"
ABSTRACT,0.00437636761487965,"a transformation. Finding a good transformation is crucial for the tensor nuclear
2"
ABSTRACT,0.006564551422319475,"norm. However, existing transformations are either ﬁxed and not adaptable to
3"
ABSTRACT,0.0087527352297593,"the data, leading to ineffective results, or they are nonlinear and non-invertible,
4"
ABSTRACT,0.010940919037199124,"which prevents theoretical guarantees for the transformed tensor nuclear norm.
5"
ABSTRACT,0.01312910284463895,"Besides, some transformations are too complex and computationally expensive. To
6"
ABSTRACT,0.015317286652078774,"address these issues, this paper ﬁrst proposes a fast data-adaptive and learnable
7"
ABSTRACT,0.0175054704595186,"column-orthogonal transformation learning framework with an exact recoverable
8"
ABSTRACT,0.019693654266958426,"theoretical guarantee. Extensive experiments have validated the effectiveness of
9"
ABSTRACT,0.02188183807439825,"the proposed models and theories.
10"
INTRODUCTION,0.024070021881838075,"1
Introduction
11"
INTRODUCTION,0.0262582056892779,"In real-life scenarios, many high-dimensional tensor data, such as hyperspectral images (HSIs),
12"
INTRODUCTION,0.028446389496717725,"multispectral images (MSIs), and multi-frame videos, exhibit strong low-rank properties. Leveraging
13"
INTRODUCTION,0.030634573304157548,"such low-rank structures of tensor data is crucial for solving tensor data restoration tasks, including
14"
INTRODUCTION,0.03282275711159737,"but not limited to tensor completion (TC) [1, 2] and tensor robust principal component analysis
15"
INTRODUCTION,0.0350109409190372,"(TRPCA) [3, 4]. Numerous methods have achieved outstanding results in practical applications by
16"
INTRODUCTION,0.037199124726477024,"exploiting the low-rank property of tensors, such as video processing [5, 6], hyperspectral denoising
17"
INTRODUCTION,0.03938730853391685,"[7, 8, 9], classiﬁcation [10, 11].
18"
INTRODUCTION,0.04157549234135667,"There are various deﬁnitions of tensor rank, which differ from the rank used for matrices [12, 1].
19"
INTRODUCTION,0.0437636761487965,"Two well-known types of tensor decomposition are based on the CANDECOMP/PARAFAC (CP)
20"
INTRODUCTION,0.045951859956236324,"and Tucker decompositions, which deﬁne the CP rank and Tucker rank, respectively [12]. These
21"
INTRODUCTION,0.04814004376367615,"decompositions have been widely studied and have demonstrated competitive performance in low-
22"
INTRODUCTION,0.05032822757111598,"rank tensor recovery. Computing the CP rank is known to be NP-hard, and a clear convex surrogate for
23"
INTRODUCTION,0.0525164113785558,"this rank has not been established. On the other hand, computing the Tucker rank involves unfolding
24"
INTRODUCTION,0.05470459518599562,"tensors along each mode into matrices, which may result in the loss of intrinsic high-order interactive
25"
INTRODUCTION,0.05689277899343545,"information. In addition to these two ranks, the tensor tubal rank is also commonly used for tensor
26"
INTRODUCTION,0.05908096280087528,"decomposition [13]. This rank is computed via tensor singular value decomposition (t-SVD), which
27"
INTRODUCTION,0.061269146608315096,"was initially derived from a novel deﬁnition of the tensor-tensor (t-t) product [14]. Unlike other
28"
INTRODUCTION,0.06345733041575492,"methods, t-SVD can operate on an integral third-order tensor without reshaping it into matrices, by
29"
INTRODUCTION,0.06564551422319474,"using the discrete Fourier transform (DFT). For a third-order tensor A ∈Rn1×n2×n3, assuming that
30"
INTRODUCTION,0.06783369803063458,"its third mode has a low-rank property, the transformed tensor A can be obtained as follows:
31"
INTRODUCTION,0.0700218818380744,"A = A ×3 L,
(1)"
INTRODUCTION,0.07221006564551423,"where ×3 denotes mode-3 tensor product [12], and L ∈Rn3×n3 is corresponding DFT matrix which
32"
INTRODUCTION,0.07439824945295405,"satisﬁes LLT = LT L = n3I. Then the deﬁnition of the tensor tubal rank of A is rankt(A) =
33"
INTRODUCTION,0.07658643326039387,Table 1: The characteristics of different transformed TNN.
INTRODUCTION,0.0787746170678337,"Methods
TNN
DCTNN
UTNN
WTNN
CTNN
FTNN
S2NTNN
Q-rank
SALTS
Ours
[2]
[28]
[30]
[29]
[32]
[31]
[23]
[24]
[25]
Transform
FFT
DCT
Unitary
Wavelet
Couple
Framelet
DNN
Unitary
Unitary
COM
Learnable?
%
%
%
%
%
%
""
""
""
""
Theory?
""
""
""
""
%
%
%
""
%
""
Speed
Moderate
Moderate
Moderate
Moderate
Slow
Slow
Fast
Very slow
Very slow
Fast
Pn3
i=1 rank(A(:, :, i)), where A(:, :, i) is the frontal slice of A. Since the minimization of the tubal
34"
INTRODUCTION,0.08096280087527352,"rank is an NP-hard problem. Zhang et al. [15] built a convex surrogate of the tensor tubal rank,
35"
INTRODUCTION,0.08315098468271334,"named the tensor nuclear norm (TNN) by summing the matrix nuclear norm of each frontal slice
36"
INTRODUCTION,0.08533916849015317,"under DFT. Thus the DFT-transformed TNN is deﬁned as:
37 ∥A∥∗= n3
X"
INTRODUCTION,0.087527352297593,"i=1
∥A(:, :, i)∥∗= n3
X"
INTRODUCTION,0.08971553610503283,"i=1
∥A
(k)∥∗.
(2)"
INTRODUCTION,0.09190371991247265,"Based on the DFT transformed TNN, Zhang and Aeron [2] and Lu et al. [3] give the exact recovery
38"
INTRODUCTION,0.09409190371991247,"theorem for TC and TRPCA task by minimizing the TNN norm, respectively. Since then, many
39"
INTRODUCTION,0.0962800875273523,"variants of DFT transformed TNN are proposed, such as weight TNN [16], partial sum of TNN
40"
INTRODUCTION,0.09846827133479212,"(PSTNN) [17], Schatten-p norm TNN [18], p-shrinkage TNN [19], and many others [20, 21, 22].
41"
INTRODUCTION,0.10065645514223195,"Referring to Eq. (1), if we substitute the DFT matrix with another transform matrix/operator L,
42"
INTRODUCTION,0.10284463894967177,"we can obtain a transformed tensor and corresponding induced TNN norms that differ from those
43"
INTRODUCTION,0.1050328227571116,"obtained using DFT. Hence, a crucial question arises: what type of transform matrix/operator is
44"
INTRODUCTION,0.10722100656455143,"appropriate? Intuitively, a suitable transform operator should satisfy the following three criteria:
45"
INTRODUCTION,0.10940919037199125,"1) Data adaptation. The design of transform operators must depend on the data to better
46"
INTRODUCTION,0.11159737417943107,"utilize its characteristics, which is a recent viewpoint. Works such as S2NTNN [23], Q-rank
47"
INTRODUCTION,0.1137855579868709,"[24], and SALTS [25] have employed various methods to learn transform matrices from
48"
INTRODUCTION,0.11597374179431072,"data. S2NTNN uses deep neural networks, Q-rank introduces a new algebraic deﬁnition,
49"
INTRODUCTION,0.11816192560175055,"and SALTS uses SVD decomposition. Although only Q-rank has theoretical guarantees,
50"
INTRODUCTION,0.12035010940919037,"updating the transform matrix and tensor recovery are independent processes that take a
51"
INTRODUCTION,0.12253829321663019,"long time, making it impractical for real-world tasks.
52"
INTRODUCTION,0.12472647702407003,"2) Theoretical guarantee Theoretical guarantees are crucial for both models and algorithms.
53"
INTRODUCTION,0.12691466083150985,"Currently, the exact recoverable guarantees are based on ﬁxed linear invertible transforms,
54"
INTRODUCTION,0.12910284463894967,"such as DFT, discrete cosine transform (DCT) [26, 27, 28], wavelet transformation [29], and
55"
INTRODUCTION,0.13129102844638948,"unitary transformation [30], but they lack adaptability to data. In addition, there are ﬁxed
56"
INTRODUCTION,0.13347921225382933,"complex transforms that do not have recoverable theoretical guarantees, such as framelet
57"
INTRODUCTION,0.13566739606126915,"transform [31], and coupe transform [32].
58"
INTRODUCTION,0.13785557986870897,"3) Good Performance Good transforms should improve restoration performance.
59"
INTRODUCTION,0.1400437636761488,"To achieve these objectives, this paper leverages the tensor structure and exploits the low-rank
60"
INTRODUCTION,0.1422319474835886,"property of the third mode of the tensor to learn an adaptive column-orthogonal matrix (COM)
61"
INTRODUCTION,0.14442013129102846,"transform for each data instance. Speciﬁcally, we model the low-rank tensor to be restored as the
62"
INTRODUCTION,0.14660831509846828,"product of a smaller-sized factor tensor and a COM. This modeling approach effectively captures the
63"
INTRODUCTION,0.1487964989059081,"low-rank structure of the tensor and facilitates the learning of the COM transform. Moreover, due to
64"
INTRODUCTION,0.15098468271334792,"the reduced size of the factor tensor compared to the original tensor, our proposed model achieves
65"
INTRODUCTION,0.15317286652078774,"accelerated computation. Additionally, we provide theoretical guarantees for the recoverability of
66"
INTRODUCTION,0.15536105032822758,"our proposed model. To facilitate comparison, we present some classical transform-based tensor
67"
INTRODUCTION,0.1575492341356674,"nuclear norm (TNN) approaches in Table 1. It can be observed from the table that only our modeling
68"
INTRODUCTION,0.15973741794310722,"approach can stand out by simultaneously considering data adaptability, theoretical guarantees, and
69"
INTRODUCTION,0.16192560175054704,"computational efﬁciency. In summary, this article ﬁrst presents an efﬁcient learnable transformed
70"
INTRODUCTION,0.16411378555798686,"tensor nuclear norm (TNN) model with recoverable theoretical guarantees.
71"
NOTATIONS AND PRELIMINARIES,0.16630196936542668,"2
Notations and Preliminaries
72"
NOTATIONS,0.16849015317286653,"2.1
Notations
73"
NOTATIONS,0.17067833698030635,"In this paper, we denote tensors by boldface Euler script letters, e.g., A. Matrices are denoted
74"
NOTATIONS,0.17286652078774617,"by boldface capital letters, e.g., A; vectors are denoted by boldface lowercase letters, e.g., a, and
75"
NOTATIONS,0.175054704595186,"scalars are denoted by lowercase letters, e.g., a. We denote In as the n × n identity matrix. For a
76"
NOTATIONS,0.1772428884026258,"3-order tensor A ∈Rn1×n2×n3, the frontal slice A(:, :, i) is denoted compactly as A(i). The tube
77"
NOTATIONS,0.17943107221006566,"is denoted as A(i, j, :). The mode-n unfolding matrix of A is denoted as A(n) = unfoldn(A), and
78"
NOTATIONS,0.18161925601750548,"foldn(A(n)) = A, where foldn is the inverse of unfolding operator. The mode-n product of a tensor
79"
NOTATIONS,0.1838074398249453,"X ∈RI1×I2×I3 and a matrix A ∈RJn×In is denoted as Y := X ×n A (see deﬁnition in [12]).
80"
NOTATIONS,0.18599562363238512,"Some norms of vector, matrix and tensor are used. We denote the ∥A∥1 = P"
NOTATIONS,0.18818380743982493,"ijk |aijk|, the inﬁnity
81"
NOTATIONS,0.19037199124726478,"norm as ∥A∥∞= maxijk |aijk| and the Frobenius norm as ∥A∥F =
qP
ijk |aijk|2, respectively.
82"
ADAPTIVE TRANSFORMATION,0.1925601750547046,"2.2
Adaptive Transformation
83"
ADAPTIVE TRANSFORMATION,0.19474835886214442,"For a third-order tensor A ∈Rn1×n2×n3, assuming that its third mode has low-rank property, it can
84"
ADAPTIVE TRANSFORMATION,0.19693654266958424,"be factorized as
85"
ADAPTIVE TRANSFORMATION,0.19912472647702406,"A = U ×3 V,
(3)
where ×3 denotes mode-3 tensor product, U ∈Rn1×n2×r3, V ∈Rn3×r3(r3 ≤n3) satisfying
86"
ADAPTIVE TRANSFORMATION,0.2013129102844639,"VT V = I and r3 = Rank(A(3)). According to low-rank tensor decomposition (3), we have.
87"
ADAPTIVE TRANSFORMATION,0.20350109409190373,"U = A ×3 VT ⇐⇒U(3) = U(3)VT V = A(3)V.
(4)"
ADAPTIVE TRANSFORMATION,0.20568927789934355,"Therefore, if we regard U as a transformed tensor A, then VT can be regarded as the transform
88"
ADAPTIVE TRANSFORMATION,0.20787746170678337,"matrix L, and V is the inverse transform of VT . Then we denote the TNN under the COM learned
89"
ADAPTIVE TRANSFORMATION,0.2100656455142232,"from the data as the Adaptive TNN (ATNN), which can be reformulated as:
90 ∥A∥∗= r3
X"
ADAPTIVE TRANSFORMATION,0.212253829321663,"k=1
∥A
(k)∥∗= R
X"
ADAPTIVE TRANSFORMATION,0.21444201312910285,"k=1
∥(A ×3 LT )(k)∥∗, s.t. A = A ×3 LT ×3 L.
(5) 91"
ADAPTIVE TRANSFORMATION,0.21663019693654267,"Remark 1 It should be noted that comparing Eq. (5) and Eq. (2), it can be seen that ATNN has faster
92"
ADAPTIVE TRANSFORMATION,0.2188183807439825,"solution efﬁciency than DFT-transformed TNN since the transformed tensor under COM transform
93"
ADAPTIVE TRANSFORMATION,0.2210065645514223,"has fewer slices. The stronger the low rank of the tensor, that is, the lower the r3/n3 value, the
94"
ADAPTIVE TRANSFORMATION,0.22319474835886213,"higher the solution efﬁciency of ATNN can be obtained. However, since we want to ensure that the
95"
ADAPTIVE TRANSFORMATION,0.22538293216630198,"information of A with a rank of Rank(A(3)) before and after the transform will not be lost, i.e.,
96"
ADAPTIVE TRANSFORMATION,0.2275711159737418,"A = A ×3 LT ×3 L is established, the condition r3 ≥Rank(A(3)) must hold.
97"
T-PRODUCT AND T-SVD,0.22975929978118162,"2.3
T-product and T-SVD
98"
T-PRODUCT AND T-SVD,0.23194748358862144,"Here, we give the deﬁnitions of t-product and t-SVD based on COM transform.
99"
T-PRODUCT AND T-SVD,0.23413566739606126,"For A ∈Rn1×n2×n3, B ∈Rn2×n4×n3, the COM LT transformed tensor of A, B are A = A×LT ∈
100"
T-PRODUCT AND T-SVD,0.2363238512035011,"Rn1×n2×R, B = B × LT ∈Rn2×n4×R, respectively, via Eq. (1), then we deﬁne
101"
T-PRODUCT AND T-SVD,0.23851203501094093,"A = bdiag(A) =   A
(1) A
(2) ... A
(R) "
T-PRODUCT AND T-SVD,0.24070021881838075,"
, A = bfold
 "
T-PRODUCT AND T-SVD,0.24288840262582057,"A

.
(6) 102"
T-PRODUCT AND T-SVD,0.24507658643326038,"Deﬁnition 1 (T-product) Let A ∈Rn1×n2×n3, B ∈Rn2×n4×n3 and COM LT ∈Rr3×n3, (r3 ≤
103"
T-PRODUCT AND T-SVD,0.24726477024070023,"n3) satisfying LT L = IR, then the t-product under transform LT is deﬁned as
104"
T-PRODUCT AND T-SVD,0.24945295404814005,"C = A ∗L B = bfold(bdiag(A)bdiag(B)) ×3 L = bfold(A B) ×3 L ∈Rn1×n4×n3,
(7)"
T-PRODUCT AND T-SVD,0.25164113785557984,"where A = A ×3 LT ∈Rn1×n2×r3 and B = B ×3 LT ∈Rn2×n4×r3.
105"
T-PRODUCT AND T-SVD,0.2538293216630197,"According to the Deﬁnition 1, we have C = A ∗L B
⇐⇒C = A B since bfold(C) = C =
106"
T-PRODUCT AND T-SVD,0.25601750547045954,"C ×3 LT = bfold(A B) ×3 L ×3 LT = bfold(A B) ×3 (LT L) = bfold(A B).
107"
T-PRODUCT AND T-SVD,0.25820568927789933,"The t-product enjoys many similar properties to the matrix-matrix product. For example, the t-product
108"
T-PRODUCT AND T-SVD,0.2603938730853392,"is associate, i.e., A ∗(B ∗C) = (A ∗B) ∗C. We also need some other concepts on tensors.
109"
T-PRODUCT AND T-SVD,0.26258205689277897,"Deﬁnition 2 (Transpose) The transpose of a tensor A ∈Rn1×n2×n3 is the tensor AT
∈
110"
T-PRODUCT AND T-SVD,0.2647702407002188,"Rn2×n1×n3 obtained by transposing each of the frontal slices.
111"
T-PRODUCT AND T-SVD,0.26695842450765866,"Deﬁnition 3 (Identity tensor) A third-order tensor A ∈Rn×n×n3 is called identity tensor if it
112"
T-PRODUCT AND T-SVD,0.26914660831509846,"satisﬁes that each frontal slice is identity matrix, i.e., A(i) = I for all i = 1, · · · , n3.
113"
T-PRODUCT AND T-SVD,0.2713347921225383,"Deﬁnition 4 (Orthogonal tensor) A third-order tensor Q ∈Rn×n×n3 is called orthogonal tensor
114"
T-PRODUCT AND T-SVD,0.2735229759299781,"if it satisﬁes that QT ∗L Q = Q ∗L QT = I.
115"
T-PRODUCT AND T-SVD,0.27571115973741794,"Deﬁnition 5 (F-diagonal tensor) A tensor is called f-diagonal if each of its frontal slices is a diago-
116"
T-PRODUCT AND T-SVD,0.2778993435448578,"nal matrix.
117"
T-PRODUCT AND T-SVD,0.2800875273522976,"Theorem 1 (T-SVD) Let A ∈Rn1×n2×n3. Then it can be factorized as
118"
T-PRODUCT AND T-SVD,0.28227571115973743,"A = U ∗L S ∗L VT ,
(8)
where U ∈Rn1×n1×n3, V ∈Rn2×n2×n3 are orthogonal, and S ∈Rn1×n2×n3 is f-diagonal.
119"
T-PRODUCT AND T-SVD,0.2844638949671772,"By replacing DFT transform with COM transform LT , we can prove the above Theorem [3].
120"
T-PRODUCT AND T-SVD,0.28665207877461707,"Deﬁnition 6 (Tensor tubal rank [14] & TNN [3]) For A ∈Rn1×n2×n3, the tensor tubal rank,
121"
T-PRODUCT AND T-SVD,0.2888402625820569,"denoted as rankt(A), is deﬁned as the number of nonzero singular tubes of S, where S is from the
122"
T-PRODUCT AND T-SVD,0.2910284463894967,"t-SVD of A = U ∗L S ∗L VT . We can write
123"
T-PRODUCT AND T-SVD,0.29321663019693656,"rankt(A) = #{i, S(i, i, :) ̸= 0}.
(9)
And its tensor nuclear norm (TNN) is deﬁned as
124"
T-PRODUCT AND T-SVD,0.29540481400437635,"∥A∥∗=
X"
T-PRODUCT AND T-SVD,0.2975929978118162,"i
∥S(i, i, :)∥1 = ∥S∥1.
(10)"
T-PRODUCT AND T-SVD,0.29978118161925604,"Using the t-product deﬁnition, we can get A = U ∗L S ∗L VT ⇐⇒A = U S VT , thus we have
125"
T-PRODUCT AND T-SVD,0.30196936542669583,"∥A∥∗= ∥S∥1 = ∥S∥∗= ∥A∥∗= ∥A∥∗
(11)
by combing Eq. (5), Eq. (6) and Eq. (10).
126"
TENSOR RECOVERY VIA ATNN MINIMIZATION,0.3041575492341357,"3
Tensor Recovery via ATNN Minimization
127"
MODELS,0.3063457330415755,"3.1
Models
128"
MODELS,0.3085339168490153,"The observed tensor and the tensor that needs to be recovered are denoted as Y and X 0, respectively.
129"
MODELS,0.31072210065645517,"For the tensor completion (TC), the observation Y has the support set Ω∼Ber(ρ), i.e., PΩ(Y) =
130"
MODELS,0.31291028446389496,"PΩ(X 0). For the tensor robust principal component analysis (TRPCA), the observation Y is
131"
MODELS,0.3150984682713348,"corrupted with a sparse component E0 (which may represent foreground and sparse noise), denoted
132"
MODELS,0.3172866520787746,"as Y = X 0 + E0.
133"
MODELS,0.31947483588621445,"If the COM LT satisfying Eq. (5) is known, we can obtain the following two models:
134"
MODELS,0.32166301969365424,"(TRPCA) : max
X,S ∥X ×3 LT ∥∗+ λ∥S∥1, s.t. Y = X + E,"
MODELS,0.3238512035010941,"(TC) : max
X
∥X ×3 LT ∥∗, s.t. PΩ(Y) = PΩ(X).
(12)"
MODELS,0.32603938730853393,"Actually, it is often not possible to obtain LT that satisﬁes Eq. (5) in advance. Recall Eq. (5), where
135"
MODELS,0.3282275711159737,"the constraint A = A ×3 LT ×3 L shows that the information of A after the change and inverse
136"
MODELS,0.3304157549234136,"change will not be lost, as long as L is obtained from the SVD decomposition of X, Eq. (5) can be
137"
MODELS,0.33260393873085337,"satisﬁed. Hence, we can learn a suitable COM L from the data. By decomposing X as X = M×3 L
138"
MODELS,0.3347921225382932,"and setting M = X ×3 LT , we can obtain the following alternative model to Eq. (12):
139"
MODELS,0.33698030634573306,(TRPCA) : max
MODELS,0.33916849015317285,"M,S,L
∥M∥∗+ λ∥E∥1, s.t. Y = M ×3 L + E, LT L = I,"
MODELS,0.3413566739606127,(TC) : max
MODELS,0.3435448577680525,"M,L
∥M∥∗, s.t. PΩ(Y) = PΩ(M ×3 L), LT L = I.
(13)"
INCOHERENCE CONDITIONS,0.34573304157549234,"3.2
Incoherence Conditions
140"
INCOHERENCE CONDITIONS,0.3479212253829322,"The incoherence condition is one of the most vital theoretical tools in low-rank recovery [33, 3, 4].
141"
INCOHERENCE CONDITIONS,0.350109409190372,"Below, we deﬁne˚ei as the tensor column basis and the tensor incoherence conditions similar to [3].
142"
INCOHERENCE CONDITIONS,0.3522975929978118,"Deﬁnition 7 (Tensor Incoherence Conditions) For X 0 ∈Rn1×n2×n3 with t-SVD rank R, it has
143"
INCOHERENCE CONDITIONS,0.3544857768052516,"the skinny t-SVD X 0 = U ∗L S ∗L VT . Then X 0 is said to satisfy the tensor incoherence conditions
144"
INCOHERENCE CONDITIONS,0.35667396061269147,"with parameter µ if
145"
INCOHERENCE CONDITIONS,0.3588621444201313,"max
i∈[1,n1] ∥UT ∗L˚ei∥F ≤ r µR"
INCOHERENCE CONDITIONS,0.3610503282275711,"n1
, max
j∈[1,n2] ∥VT ∗L˚ej∥F ≤ r µR"
INCOHERENCE CONDITIONS,0.36323851203501095,"n2
, ∥U ∗L VT ∥F ≤ r"
INCOHERENCE CONDITIONS,0.36542669584245074,"µR
n1n2
.
(14)"
INCOHERENCE CONDITIONS,0.3676148796498906,Algorithm 1 ADMM for solving ATNN-RPCA model (13)
INCOHERENCE CONDITIONS,0.36980306345733044,"Input: Observation Y ∈Rn1×n2×n3, λ = 1/
p"
INCOHERENCE CONDITIONS,0.37199124726477023,"max(n1, n2),µ = 1/∥Y∥∗, ρ = 1.25, µm = 1e7µ,
and the column number of learnable COM matrix r3.
1: Initialize Λ = E = O, M = bdiag(U) and L = V, where U, V is the low-rank tensor
decomposition of among mode-3, i.e., unfold3(Y) = (U) ×3 L
2: while not convergence do
3: Update M := SVD1/µ((Y −E + Λ/µ) ×3 LT ).
4: Update L := BDT , where [B, C, D] = svd(unfold3(Y −E + Λ/µ)T unfold3(bfold(U))).
5: Update X := M ×3 L
6: Update E := Sλ/µ(Y −X + Λ/µ).
7: Update multipliers Λ := Λ + µ(Y −X −E) ;
8: Let µ = min{ρµ, µm}.
9: end while
Output: recovered tensors X = M ×3 L and E."
MAIN RESULTS,0.3741794310722101,"3.3
Main results
146"
MAIN RESULTS,0.37636761487964987,"We now demonstrate that both the model (12) and (13) possess exact recovery capability.
147"
MAIN RESULTS,0.3785557986870897,"Theorem 2 (TRPCA Theorem) Consider ATNN-based TRPCA model (12) and (13). Suppose that
148"
MAIN RESULTS,0.38074398249452956,"X 0 ∈Rn×n×n3 obeys the tensor incoherence conditions (14) and E0’s support set, denoted as Ω0, is
149"
MAIN RESULTS,0.38293216630196936,"uniformly distributed among all sets of cardinality m. Then, there exist universal constants c1, c2 > 0
150"
MAIN RESULTS,0.3851203501094092,"such that (X 0, E0) is the unique solution to model (12) and (13) when λ = 1/√n with probability at
151"
MAIN RESULTS,0.387308533916849,"least 1 −c1(nn3)−c2, provided that
152"
MAIN RESULTS,0.38949671772428884,"rankt(X 0) ≤ρrµ−1n log−2(n) and m ≤ρsn2n3,
(15)"
MAIN RESULTS,0.3916849015317287,"where ρr, ρs > 0 are some numerical constants.
153"
MAIN RESULTS,0.3938730853391685,"Theorem 3 (TC Theorem) Consider ATNN-based TC model (12) and (13). Suppose that X 0 ∈
154"
MAIN RESULTS,0.39606126914660833,"Rn×n×n3 obeys the tensor incoherence conditions (14) and Ω∼Ber(p). Then, there exist universal
155"
MAIN RESULTS,0.3982494529540481,"constants c0, c1, c2 > 0 such that X 0 is the unique solution to model model (12) and (13) with
156"
MAIN RESULTS,0.40043763676148797,"probability at least 1 −c1(nn3)−c2, provided that
157"
MAIN RESULTS,0.4026258205689278,"p ≥c0µRn−1 log2(n).
(16)"
MAIN RESULTS,0.4048140043763676,"Remark 2 It should be noted that although the model (12) and (13) are slightly different, they are the
158"
MAIN RESULTS,0.40700218818380746,"same in the proof of the exact recoverable theory. Assume that the optimal values of models (12) and
159"
MAIN RESULTS,0.40919037199124725,"(13) are ( ˆX, ˆE) and ( ˆ
M, ˆL, ˆE), respectively. A recoverable theory of model (12) requires proving
160"
MAIN RESULTS,0.4113785557986871,"( ˆX, ˆE) = (X 0, E0) under the given L in advance. A recoverable theory of model (13) requires
161"
MAIN RESULTS,0.4135667396061269,"proving ( ˆ
M ×3 ˆL, ˆE) = (X 0, E0) under the ﬁnal learned ˆL.
162"
SOLVING ALGORITHM,0.41575492341356673,"3.4
Solving Algorithm
163"
SOLVING ALGORITHM,0.4179431072210066,"This subsection derives efﬁcient algorithms for solving the ATNN-based TRPCA and TC problem
164"
SOLVING ALGORITHM,0.4201312910284464,"via the Alternating Direction Method of Multipliers (ADMM) framework [34].
165"
SOLVING ALGORITHM,0.4223194748358862,"We ﬁrst write the augmented Lagrangian function of the TRPCA problem in Eq. (13) as:
166"
SOLVING ALGORITHM,0.424507658643326,"min
M,E,Λ,LT L=I
∥M∥∗+ λ∥E∥1 + µ"
SOLVING ALGORITHM,0.42669584245076586,"2 ∥Y −M ×3 L −E + Λ/µ∥2
F ,
(17)"
SOLVING ALGORITHM,0.4288840262582057,"where µ is the penalty parameter and Λ is the lagrange multiplier.
167"
SOLVING ALGORITHM,0.4310722100656455,"Due to page limitation, we provide Algorithm 1 for solving Eq. (17) using the soft-thresholding
168"
SOLVING ALGORITHM,0.43326039387308535,"operator Sτ(·) [35] and the singular value soft-thresholding operator SVDτ(·) [36]. Additionally, for
169"
SOLVING ALGORITHM,0.43544857768052514,"the ATNN-TC model (13), we provide Algorithm 2 directly. For more detailed information, please
170"
SOLVING ALGORITHM,0.437636761487965,"refer to the supplementary material.
171"
SOLVING ALGORITHM,0.43982494529540483,Algorithm 2 ADMM for solving ATNN-TC model (13)
SOLVING ALGORITHM,0.4420131291028446,"Input: Observation Y ∈Rn1×n2×n3 with support set Ω, µ = 0.1, ρ = 1.05, µm = 1e7µ, and the
column number of learnable COM matrix r3.
1: Similar initialization with Algorithm 1.
2: while not convergence do
3: Update M, L, X, Λ via the similar way in Algorithm 1.
4: Update E := PΩ(Y −X + Λ/µ), where PΩis projection operator.
5: Let µ = min{ρµ, µm}.
6: end while
Output: recovered tensors X = M ×3 L."
COMPUTATIONAL COMPLEXITY ANALYSIS,0.4442013129102845,"3.5
Computational Complexity Analysis
172"
COMPUTATIONAL COMPLEXITY ANALYSIS,0.44638949671772427,"As depicted in Algorithm 1 and 2, each iteration of the algorithm involves updating M through small-
173"
COMPUTATIONAL COMPLEXITY ANALYSIS,0.4485776805251641,"scale SVD computations, updating L through small-scale SVD computation, updating E through soft
174"
COMPUTATIONAL COMPLEXITY ANALYSIS,0.45076586433260396,"thresholding operations, and some matrix multiplications. For a third-order tensor X ∈Rn1×n2×n3,
175"
COMPUTATIONAL COMPLEXITY ANALYSIS,0.45295404814004375,"the time complexity of the soft threshold operator is O(n1n2n3), the time complexity of solving L is
176"
COMPUTATIONAL COMPLEXITY ANALYSIS,0.4551422319474836,"O(n3r2
3), and the time complexity of solving M is O(r3n1n2
2). Thus, the overall time complexity of
177"
COMPUTATIONAL COMPLEXITY ANALYSIS,0.4573304157549234,"Algorithm 1 and 2 is O(r3n1n2
2 + n3r2
3 + n1n2n3). Similarly, for the DFT-transformed TRPCA and
178"
COMPUTATIONAL COMPLEXITY ANALYSIS,0.45951859956236324,"TC models, the time complexity is O(n3n1n2
2 + n1n2n3). By comparing the two time complexities
179"
COMPUTATIONAL COMPLEXITY ANALYSIS,0.4617067833698031,"mentioned above, it can be observed that their ratio is positively correlated with r3/n3. Therefore,
180"
COMPUTATIONAL COMPLEXITY ANALYSIS,0.4638949671772429,"as the low-rank property of the tensor in the third dimension becomes stronger, the acceleration
181"
COMPUTATIONAL COMPLEXITY ANALYSIS,0.4660831509846827,"capability of the proposed algorithm in this paper also becomes stronger.
182"
EXPERIMENTS,0.4682713347921225,"4
Experiments
183"
EXPERIMENTS,0.47045951859956237,"In this section, we present numerical experiments to validate the main results stated in Theorems 2
184"
EXPERIMENTS,0.4726477024070022,"and 3. Following the suggestion of Theorem 2, we set λ = 1/
p"
EXPERIMENTS,0.474835886214442,"max{n1, n2} for the TRPCA task in
185"
EXPERIMENTS,0.47702407002188185,"all experiments. However, it should be noted that further performance improvements can be achieved
186"
EXPERIMENTS,0.47921225382932164,"by carefully tuning the value of λ. The suggested value in the theory provides a useful guideline in
187"
EXPERIMENTS,0.4814004376367615,"practical applications. All simulations were conducted on a PC equipped with an Intel(R) Core(TM)
188"
EXPERIMENTS,0.48358862144420134,"i5-10600KF 4.10GHz CPU, 32 GB memory, and a GeForce RTX 3080 GPU with 10 GB memory.
189"
SIMULATED EXPERIMENTS,0.48577680525164113,"4.1
Simulated Experiments
190"
SIMULATED EXPERIMENTS,0.487964989059081,"In this section, we will verify the correct recovery guarantee of Theorem 2 and 3 on randomly
191"
SIMULATED EXPERIMENTS,0.49015317286652077,"generated problems. We generate a tensor with tubal rank R as a product X 0 = P ∗L QT , where P
192"
SIMULATED EXPERIMENTS,0.4923413566739606,"and Q are n × R × n tensors with entries independently sampled from N(0, 1/n) distribution and
193"
SIMULATED EXPERIMENTS,0.49452954048140046,"the COM L ∈Rr3×n is generated by orthogonalizing the random matrix with entries independently
194"
SIMULATED EXPERIMENTS,0.49671772428884026,"sampled from N(0, 1). For the TRPCA task, the support set Ω(with size m) of E0 with independent
195"
SIMULATED EXPERIMENTS,0.4989059080962801,"Bernoulli ±1 entries is chosen uniformly at random, and the observation tensor is set as: Y = X 0+E0.
196"
SIMULATED EXPERIMENTS,0.5010940919037199,"For the TC tasks, the observation Y is set as Y = PΩ(X 0).
197"
SIMULATED EXPERIMENTS,0.5032822757111597,"Next, we investigate how the tubal rank of X 0 and the sparsity of E0 (and missing ratio of X 0
198"
SIMULATED EXPERIMENTS,0.5054704595185996,") affect the performance of model (12) and (13). We consider n = 50 and two values of r3, i.e.,
199"
SIMULATED EXPERIMENTS,0.5076586433260394,"r3 = 5, 20. We vary the sparsity ρsof E0 as [0.01 : 0.01 : 0.5], the missing ratio ρ of X 0 as
200"
SIMULATED EXPERIMENTS,0.5098468271334792,"[0.01 : 0.02 : 0.99], and tubal rank of X 0 as [1 : 1 : 50], respectively. For each combination of
201"
SIMULATED EXPERIMENTS,0.5120350109409191,"(R, ρs) and (R, ρ), we perform 10 test instances and declare a trial successful if the recovered tensor
202"
SIMULATED EXPERIMENTS,0.5142231947483589,"ˆX satisﬁes ∥ˆX −X 0∥F /|X 0∥F ≤0.01. The fraction of successful recoveries are plotted in Figure
203"
SIMULATED EXPERIMENTS,0.5164113785557987,"1. From Figure 1, we observe that there is a signiﬁcant region where the recovery is correct for both
204"
SIMULATED EXPERIMENTS,0.5185995623632386,"models. Furthermore, two notable phenomena can be observed from the ﬁgure:
205"
SIMULATED EXPERIMENTS,0.5207877461706784,"1) The phase transition diagram in the ﬁrst row of Figure 1 closely resembles the second row,
206"
SIMULATED EXPERIMENTS,0.5229759299781181,"indicating that even if we don’t know the correct COM L in the model (12), we can learn
207"
SIMULATED EXPERIMENTS,0.5251641137855579,"the COM L through model (13).
208"
SIMULATED EXPERIMENTS,0.5273522975929978,"2) The phase transition diagram of r3 = 5 is much better than that of r3 = 20 for both TRPCA
209"
SIMULATED EXPERIMENTS,0.5295404814004376,"and TC tasks, which shows that it is necessary to consider the low-rank property of mode 3.
210"
SIMULATED EXPERIMENTS,0.5317286652078774,"Table 2: Quantitative comparison of all RPCA-based competing methods under salt-and-pepper noise
with the variance of 0.6. The best and second results are highlighted in bold italics and underline."
SIMULATED EXPERIMENTS,0.5339168490153173,"Methods
WDC
PaviaU
Beans
Cloth
PSNR
SSIM
Times
PSNR
SSIM
Times
PSNR
SSIM
Times
PSNR
SSIM
Times
RPCA
32.08
0.5223 28.99
24.98
0.8264
6.59
17.88
0.5920 17.92
18.47
0.5418 18.28
SNN
26.02
0.7178 136.2
31.34
0.9492 121.1
16.14
0.5238 176.2
16.77
0.5297 176.7
KBR
22.64
0.6438 167.2
20.91
0.4477 58.63
20.26
0.4162 252.1
20.91
0.5454 162.9
TNN
19.619 0.3728 419.2
17.09
0.2345 120.2
20.39
0.2572 322.4
15.51
0.1744 324.8
CTNN
17.21
0.2036 485.7
15.38
0.1163 130.7
15.64
0.1218 363.4
14.55
0.1162 353.9
CTV
33.85
0.9454 170.2
31.91
0.8872 41.85
29.35
0.7770 103.8
27.33
0.7721 102.2
TCTV
32.12
0.9090 815.2
29.62
0.8554 172.5
32.85
0.9204 641.3
27.36
0.7534 627.9
Ours
39.82
0.9913 21.34
35.31
0.9721
5.32
29.46
0.9108 29.22
27.53
0.8563 19.30"
SIMULATED EXPERIMENTS,0.5361050328227571,"Table 3: Quantitative comparison of all competing methods under missing ratio with 0.95. The best
and second results are highlighted in bold italics and underline, respectively."
SIMULATED EXPERIMENTS,0.5382932166301969,"Methods
WDC
PaviaU
Beans
Cloth
PSNR
SSIM
Times
PSNR
SSIM
Times
PSNR
SSIM
Times
PSNR
SSIM
Times
LRMC
18.53
0.4623 24.38
15.17
0.2834
2.93
15.96
0.3972
7.61
13.11
0.1902 10.95
HaLRTC
22.09
0.6676 54.37
18.87
0.3912 30.34
20.62
0.4542 64.48
19.01
0.3570 92.65
KBR
31.42
0.9022 1589
29.92
0.8591 725.7
26.06
0.7208 1253
24.14
0.6422 1292
TNN
30.01
0.8824 1019
26.43
0.7126 207.9
26.10
0.6712 419.2
23.46
0.6012 441.2
CTNN
33.36
0.9432 378.9
31.69
0.9172 114.4
27.61
0.8041 129.6
25.71
0.7362 136.2
UTNN
27.89
0.8652 487.6
21.80
0.5982 156.3
17.28
0.4131 116.6
16.27
0.3183 117.9
FTNN
34.87
0.5320 4376
32.56
0.9092 1263
28.48
0.8143 1587
25.25
0.7253 2054
OITNN
32.92
0.9396 838.2
28.46
0.8142 292.4
27.28
0.7442 448.6
24.06
0.6516 391.8
TCTV
33.33
0.9391 2116
31.81
0.8960 861.4
31.77
0.9143 1570
28.38
0.8442 1488
S2NTNN
37.36
0.9749 168.7
35.15
0.9431 40.78
27.44
0.7589 104.2
31.28
0.8679 113.2
Ours
38.06
0.9793 232.4
33.94
0.9293 58.34
28.83
0.8164 156.3
25.81
0.7146 142.4"
SIMULATED EXPERIMENTS,0.5404814004376368,"0.01
0.1
0.2
0.3
0.4
0.5
sparsity 1 10 20 30 40 50"
SIMULATED EXPERIMENTS,0.5426695842450766,tubal rank R 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
SIMULATED EXPERIMENTS,0.5448577680525164,"0.01
0.1
0.2
0.3
0.4
0.5
sparsity 1 10 20 30 40 50"
SIMULATED EXPERIMENTS,0.5470459518599562,tubal rank R 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
SIMULATED EXPERIMENTS,0.5492341356673961,"0.01
0.2
0.4
0.6
0.8
0.99
missing ratio 1 10 20 30 40 50"
SIMULATED EXPERIMENTS,0.5514223194748359,tubal rank R 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
SIMULATED EXPERIMENTS,0.5536105032822757,"0.01
0.2
0.4
0.6
0.8
0.99
missing ratio 1 10 20 30 40 50"
SIMULATED EXPERIMENTS,0.5557986870897156,tubal rank R 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
SIMULATED EXPERIMENTS,0.5579868708971554,"TRPCA under r3 = 5
TRPCA under r3 = 20
TC under r3 = 5
TC under r3 = 20"
SIMULATED EXPERIMENTS,0.5601750547045952,"0.01
0.1
0.2
0.3
0.4
0.5
sparsity 1 10 20 30 40 50"
SIMULATED EXPERIMENTS,0.562363238512035,tubal rank R 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
SIMULATED EXPERIMENTS,0.5645514223194749,"0.01
0.1
0.2
0.3
0.4
0.5
sparsity 1 10 20 30 40 50"
SIMULATED EXPERIMENTS,0.5667396061269147,tubal rank R 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
SIMULATED EXPERIMENTS,0.5689277899343544,"0.01
0.2
0.4
0.6
0.8
0.99
missing ratio 1 10 20 30 40 50"
SIMULATED EXPERIMENTS,0.5711159737417943,tubal rank R 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
SIMULATED EXPERIMENTS,0.5733041575492341,"0.01
0.2
0.4
0.6
0.8
0.99
missing ratio 1 10 20 30 40 50"
SIMULATED EXPERIMENTS,0.5754923413566739,tubal rank R 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
SIMULATED EXPERIMENTS,0.5776805251641138,"TRPCA under r3 = 5
TRPCA under r3 = 20
TC under r3 = 5
TC under r3 = 20
Figure 1: TRPCA and TC phase transition diagrams for varying tubal ranks of X 0 and sparsities of
E0 or missing ratio of X 0. The ﬁrst and second rows show the phase transition diagrams based on
models (13) and (12), respectively, under different r3 settings."
REAL EXPERIMENTS,0.5798687089715536,"4.2
Real Experiments
211"
REAL EXPERIMENTS,0.5820568927789934,"To validate the effectiveness of the proposed ATNN model in tensor recovery task, we conducted
212"
REAL EXPERIMENTS,0.5842450765864332,"experiments on various datasets, including hyperspectral images (HSI), multispectral images (MSI),
213"
REAL EXPERIMENTS,0.5864332603938731,"color video images, and surveillance videos. Due to page limitations, we have included the results of
214"
REAL EXPERIMENTS,0.5886214442013129,"robustness analysis, parameter settings for robustness, convergence veriﬁcation, and more detailed
215"
REAL EXPERIMENTS,0.5908096280087527,"experimental outcomes in the Supplementary Material.
216"
REAL EXPERIMENTS,0.5929978118161926,"For comprehensive comparison, we have included additional state-of-the-art methods except those
217"
REAL EXPERIMENTS,0.5951859956236324,"listed in Table 1. These methods include CTV [42] and TCTV [4] for the TRPCA task, LRMC [33],
218"
REAL EXPERIMENTS,0.5973741794310722,"HaLRTC [1], UTNN [29], and OITNN [43] for the TC task, and GODEC [37], DECOLOR [38],
219"
REAL EXPERIMENTS,0.5995623632385121,"OMoGMF [39], RegL1 [40], and PRMF [41] for background modeling. Before conducting this
220"
REAL EXPERIMENTS,0.6017505470459519,"experiment, the gray value of each band was normalized into [0, 1] via the max-min formula.
221"
REAL EXPERIMENTS,0.6039387308533917,"Table 4: AUC comparison of all competing methods on all video sequences in the Li dataset. The best
and second results in each video sequence are highlighted in bold italics and underline, respectively."
REAL EXPERIMENTS,0.6061269146608315,"Methods
data
Time /s
airp.
boot.
shop.
lobb.
esca.
curt.
camp.
wate.
foun.
Average
RPCA [33]
0.8721 0.9168 0.9445 0.9130 0.9050 0.8722 0.8917 0.8345 0.9418
0.8991
2.37
GODEC [37]
0.9001 0.9046 0.9187 0.8556 0.9125 0.9131 0.8693 0.9370 0.9099
0.9023
0.64
DECOLOR [38]
0.8627 0.8910 0.9462 0.9241 0.9077 0.8864 0.8945 0.8000 0.9443
0.8952
8.29
OMoGMF [39]
0.9143 0.9238 0.9478 0.9252 0.9112 0.9049 0.8877 0.8958 0.9419
0.9170
3.92
RegL1 [40]
0.8977 0.9249 0.9423 0.8819 0.4159 0.8899 0.8871 0.8920 0.9194
0.8501
10.74
PRMF [41]
0.8905 0.9218 0.9415 0.8818 0.9065 0.8806 0.8865 0.8799 0.9166
0.9006
13.68
CTV [42]
0.9178 0.9107 0.9541 0.9337 0.9148 0.8710 0.8814 0.9386 0.9383
0.9180
10.28
TNN [2]
0.5218 0.5694 0.6605 0.6311 0.5981 0.5823 0.5464 0.6642 0.5781
0.5947
16.87
CTNN [28]
0.6859 0.6176 0.6835 0.6613 0.6582 0.6988 0.5881 0.5272 0.5450
0.6295
17.39
ATNN
0.9185 0.9227 0.9484 0.9362 0.9158 0.9162 0.8912 0.9152 0.9456
0.9233
2.32"
REAL EXPERIMENTS,0.6083150984682714,"Table 5: Quantitative comparison of all competing methods on color video under missing ratio with
0.95. The best and second results are highlighted in bold italics and underline, respectively."
REAL EXPERIMENTS,0.6105032822757112,"Methods
Akiyo
Foreman
Carphone
News
PSNR
SSIM
Times
PSNR
SSIM
Times
PSNR
SSIM
Times
PSNR
SSIM
Times
LRMC
10.81
0.2626
8.06
8.79
0.1192
7.21
11.57
0.2713
6.92
13.27
0.3660 13.41
HaLRTC
17.66
0.5327 61.04
15.55
0.3336 44.87
14.20
0.3448 42.46
16.43
0.4890 87.63
KBR
29.76
0.9118 689.2
23.97
0.7193 668.2
26.49
0.8164 798.2
26.42
0.8480 1043
TNN
31.94
0.9343 217.5
23.15
0.6052 181.5
26.27
0.7658 493.6
28.56
0.8660 249.6
CTNN
28.63
0.8463 192.0
22.13
0.5779 152.7
25.06
0.7263 196.2
25.59
0.7740 174.7
UTNN
21.72
0.7237 172.4
16.51
0.2587 167.6
20.24
0.5394 202.7
21.21
0.7060 162.6
FTNN
30.74
0.9252 1258
22.97
0.6781 1123
25.43
0.7778 1335
28.77
0.8770 1494
OITNN
32.68
0.9533 397.5
23.89
0.7206 296.7
27.14
0.8340 472.3
29.43
0.9010 322.3
TCTV
33.41
0.9542 874.8
26.69
0.8071 821.4
29.10
0.8747 1103
30.65
0.9170 772.2
S2NTNN
33.16
0.9520 168.7
23.57
0.6091 83.98
27.33
0.8093 100.7
29.11
0.8872 90.61
Ours
33.74
0.9574 95.89
24.16
0.6252 78.21
27.44
0.7773 80.11
29.72
0.9021 78.94"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.612691466083151,"4.2.1
Hyperspectral and Multispectral Image Recovery
222"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6148796498905909,"Two HSI images, i.e., WDC 1 and PaviaU 2 datasets are used. The sizes of the two data are
223"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6170678336980306,"256 × 256 × 191 and 256 × 256 × 93, respectively. Two MSI images in CAVE dataset 3, i.e., Cloth
224"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6192560175054704,"and Beans are used. The size of the two data is 512 × 512 × 31.
225"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6214442013129103,"For the TRPCA task, we conducted experiments with six different levels of salt and pepper noise
226"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6236323851203501,"variance: 0.1, 0.2, 0.3, 0.4, 0.5, and 0.6. Table 2 reports the performance metrics of each method
227"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6258205689277899,"under a variance of 0.6, demonstrating that our ATNN outperforms all competing methods. Notably,
228"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6280087527352297,"our method achieves superior performance despite only utilizing the low-rank property of tensors,
229"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6301969365426696,"surpassing the performance of CTV and TCTV, which additionally exploit the local smoothness and
230"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6323851203501094,"low-rank property of images. Furthermore, our method exhibits comparable computational efﬁciency
231"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6345733041575492,"to RPCA, indicating that the introduction of the learnable COM matrix effectively reduces the time
232"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6367614879649891,"complexity of the model. To better visualize the comparison, we choose three bands of HSI to form a
233"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6389496717724289,"pseudo-color image to show four representative competing methods’ visual restoration performance,
234"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6411378555798687,"as shown in Figure 2. From the images, it is evident that our proposed ATNN model can effectively
235"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6433260393873085,"remove noise and preserve more detailed information.
236"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6455142231947484,"For the TC task, since all the methods achieve very accurate recovery results when the sample ratio
237"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6477024070021882,"(SR) is high, we test four different SRs: 0.01, 0.05, 0.1 and 0.2. The metric of each tested algorithm
238"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.649890590809628,"under an SR of 0.05 is placed in Table 3. As can be seen from the metrics in the table, our proposed
239"
HYPERSPECTRAL AND MULTISPECTRAL IMAGE RECOVERY,0.6520787746170679,"method excels in recovery performance and running time.
240"
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6542669584245077,"4.2.2
Background Modeling from Surveillance Video
241"
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6564551422319475,"The aim of this task is to separate the background and foreground from Surveillance Video. We
242"
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6586433260393874,"choose nine video sequences in Li dataset 4 with the known foreground of size 144 × 176 × 20 for
243"
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6608315098468271,"testing, as shown in Table 4. It can be seen from the table that our proposed model is far ahead in
244"
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6630196936542669,"1https://engineering.purdue.edu/~biehl/MultiSpec/
2https://www.ehu.eus/ccwintco/index.php/
3https://www.cs.columbia.edu/CAVE/databases/multispectral/
4http://perception.i2r.a-star.edu.sg/bkmodel/bkindex.html"
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6652078774617067,"Clean: PSNR/SSIM
Noisy: 6.43/0.021
RPCA: 29.64/0.932
TNN: 19.85/0.355
CTV: 33.57/0.943
ATNN: 37.47/0.985
Figure 2: Denoised images of all competing methods with bands 58-27-9 as R-G-B under sparse
noise with missing percent is 0.6 on simulated WDC dataset."
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6673960612691466,"Clean: PSNR/SSIM
Observed: 6.24/0.014
TNN: 31.66/0.935
OITNN: 32.60/0.958 S2NTNN: 35.27/0.966
ATNN: 35.52/0.971
Figure 3: Recovered images of all competing methods under sample ratio of 0.05 on the 10th frame
of Akiyo data."
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6695842450765864,"terms of evaluation metrics and running time. Even compared to the CTV model that simultaneously
245"
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6717724288840262,"utilizes local smoothness and low-rank priors, our method outperforms it. It is worth noting that
246"
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6739606126914661,"although tensor-based models have a higher performance ceiling than matrix-based models due to
247"
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6761487964989059,"their ability to capture more complex structures, for TNN regularization, if the variation matrix is not
248"
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6783369803063457,"well deﬁned, the results can even be worse than matrix-based methods. This further highlights the
249"
BACKGROUND MODELING FROM SURVEILLANCE VIDEO,0.6805251641137856,"necessity of learning the transform matrix.
250"
COLOR VIDEO COMPLETION,0.6827133479212254,"4.2.3
Color Video Completion
251"
COLOR VIDEO COMPLETION,0.6849015317286652,"We selected four color video sequences, namely Akiyo, Foreman, Carphone, and Mobile, from the
252"
COLOR VIDEO COMPLETION,0.687089715536105,"open-source YUV video dataset5. To ensure efﬁcient comparison, we considered the ﬁrst 100 frames
253"
COLOR VIDEO COMPLETION,0.6892778993435449,"of each color video sequence. As the color video is represented as a fourth-order tensor in RGB
254"
COLOR VIDEO COMPLETION,0.6914660831509847,"format with dimensions 144×176×3×100, we reshaped it into a tensor of size 144×176×300. We
255"
COLOR VIDEO COMPLETION,0.6936542669584245,"adopted similar sample ratio (SR) settings as mentioned in Subsection 4.2.1. The performance metrics
256"
COLOR VIDEO COMPLETION,0.6958424507658644,"of all competing methods are presented in Table 5. It is evident that our proposed model consistently
257"
COLOR VIDEO COMPLETION,0.6980306345733042,"ranks within the top three, outperforming TCTV even under the Akiyo dataset. In comparison to
258"
COLOR VIDEO COMPLETION,0.700218818380744,"other TNN models with ﬁxed transform matrices, our model exhibits superior performance and
259"
COLOR VIDEO COMPLETION,0.7024070021881839,"remarkable computational efﬁciency. Furthermore, we provided the recovered images of some
260"
COLOR VIDEO COMPLETION,0.7045951859956237,"competing methods in Figure 3 for better visual comparison. For the convenience of observation, we
261"
COLOR VIDEO COMPLETION,0.7067833698030634,"have enlarged a part of the picture and placed the repair indicator below the picture. It can be seen
262"
COLOR VIDEO COMPLETION,0.7089715536105032,"that our proposed ATNN model has a strong ability to preserve the local information of the data.
263"
CONCLUSION,0.7111597374179431,"5
Conclusion
264"
CONCLUSION,0.7133479212253829,"In this paper, we introduce an efﬁcient and learnable transformed tensor nuclear norm (TNN) model
265"
CONCLUSION,0.7155361050328227,"with a provable recovery guarantee. Our approach leverages the low-rank property of the third
266"
CONCLUSION,0.7177242888402626,"mode of the tensor to represent the tensor to be repaired as a combination of a small-sized tensor
267"
CONCLUSION,0.7199124726477024,"and a column-orthogonal matrix. The column-orthogonal matrix serves as an adaptively learned
268"
CONCLUSION,0.7221006564551422,"transform matrix derived from the data. By employing the nuclear norm on the small-sized tensor,
269"
CONCLUSION,0.7242888402625821,"our model achieves higher computational efﬁciency compared to existing methods. Additionally,
270"
CONCLUSION,0.7264770240700219,"we provide a theoretical framework that guarantees exact recovery for our proposed model with a
271"
CONCLUSION,0.7286652078774617,"column-orthogonal transform matrix. Extensive experimental results demonstrate the effectiveness of
272"
CONCLUSION,0.7308533916849015,"our approach and the validity of our theoretical ﬁndings.
273"
CONCLUSION,0.7330415754923414,"Limitations There are two shortcomings in our work. Firstly, the recoverable theory does not
274"
CONCLUSION,0.7352297592997812,"explain how the low-rank property of the third dimension of the tensor affects the model’s restoration
275"
CONCLUSION,0.737417943107221,"performance. Secondly, the ATNN model only learns the low-rank property of the tensor, without
276"
CONCLUSION,0.7396061269146609,"incorporating image priors. These two points will be the focus of our future research.
277"
CONCLUSION,0.7417943107221007,5http://trace.eas.asu.edu/yuv/
REFERENCES,0.7439824945295405,"References
278"
REFERENCES,0.7461706783369803,"[1] Ji Liu, Przemyslaw Musialski, Peter Wonka, and Jieping Ye. Tensor completion for estimating
279"
REFERENCES,0.7483588621444202,"missing values in visual data. IEEE transactions on pattern analysis and machine intelligence,
280"
REFERENCES,0.75054704595186,"35(1):208–220, 2012.
281"
REFERENCES,0.7527352297592997,"[2] Zemin Zhang and Shuchin Aeron. Exact tensor completion using t-svd. IEEE Transactions on
282"
REFERENCES,0.7549234135667396,"Signal Processing, 65(6):1511–1526, 2016.
283"
REFERENCES,0.7571115973741794,"[3] Canyi Lu, Jiashi Feng, Yudong Chen, Wei Liu, Zhouchen Lin, and Shuicheng Yan. Tensor
284"
REFERENCES,0.7592997811816192,"robust principal component analysis with a new tensor nuclear norm. IEEE transactions on
285"
REFERENCES,0.7614879649890591,"pattern analysis and machine intelligence, 42(4):925–938, 2019.
286"
REFERENCES,0.7636761487964989,"[4] Hailin Wang, Jiangjun Peng, Wenjin Qin, Jianjun Wang, and Deyu Meng. Guaranteed tensor
287"
REFERENCES,0.7658643326039387,"recovery fused low-rankness and smoothness. IEEE Transactions on Pattern Analysis and
288"
REFERENCES,0.7680525164113785,"Machine Intelligence, 2023.
289"
REFERENCES,0.7702407002188184,"[5] Johann A Bengua, Ho N Phien, Hoang Duong Tuan, and Minh N Do. Efﬁcient tensor completion
290"
REFERENCES,0.7724288840262582,"for color image and video recovery: Low-rank tensor train. IEEE Transactions on Image
291"
REFERENCES,0.774617067833698,"Processing, 26(5):2466–2479, 2017.
292"
REFERENCES,0.7768052516411379,"[6] Wenrui Hu, Dacheng Tao, Wensheng Zhang, Yuan Xie, and Yehui Yang. The twist tensor
293"
REFERENCES,0.7789934354485777,"nuclear norm for video completion. IEEE transactions on neural networks and learning systems,
294"
REFERENCES,0.7811816192560175,"28(12):2961–2973, 2016.
295"
REFERENCES,0.7833698030634574,"[7] Yao Wang, Jiangjun Peng, Qian Zhao, Yee Leung, Xile Zhao, and Deyu Meng. Hyperspectral
296"
REFERENCES,0.7855579868708972,"image restoration via total variation regularized low-rank tensor decomposition. IEEE Journal
297"
REFERENCES,0.787746170678337,"of Selected Topics in Applied Earth Observations and Remote Sensing, 11(4):1227–1243, 2017.
298"
REFERENCES,0.7899343544857768,"[8] Hongyan Zhang, Lu Liu, Wei He, and Liangpei Zhang. Hyperspectral image denoising with
299"
REFERENCES,0.7921225382932167,"total variation regularization and nonlocal low-rank tensor decomposition. IEEE Transactions
300"
REFERENCES,0.7943107221006565,"on Geoscience and Remote Sensing, 58(5):3071–3084, 2019.
301"
REFERENCES,0.7964989059080962,"[9] Jiangjun Peng, Qi Xie, Qian Zhao, Yao Wang, Leung Yee, and Deyu Meng. Enhanced 3dtv
302"
REFERENCES,0.7986870897155361,"regularization and its applications on hsi denoising and compressed sensing. IEEE Transactions
303"
REFERENCES,0.8008752735229759,"on Image Processing, 29:7889–7903, 2020.
304"
REFERENCES,0.8030634573304157,"[10] Pan Zhou, Canyi Lu, Jiashi Feng, Zhouchen Lin, and Shuicheng Yan. Tensor low-rank repre-
305"
REFERENCES,0.8052516411378556,"sentation for data recovery and clustering. IEEE transactions on pattern analysis and machine
306"
REFERENCES,0.8074398249452954,"intelligence, 43(5):1718–1732, 2019.
307"
REFERENCES,0.8096280087527352,"[11] Jianlong Wu, Zhouchen Lin, and Hongbin Zha. Essential tensor learning for multi-view spectral
308"
REFERENCES,0.811816192560175,"clustering. IEEE Transactions on Image Processing, 28(12):5910–5922, 2019.
309"
REFERENCES,0.8140043763676149,"[12] Tamara G Kolda and Brett W Bader. Tensor decompositions and applications. SIAM review,
310"
REFERENCES,0.8161925601750547,"51(3):455–500, 2009.
311"
REFERENCES,0.8183807439824945,"[13] Canyi Lu, Jiashi Feng, Zhouchen Lin, and Shuicheng Yan. Exact low tubal rank tensor recovery
312"
REFERENCES,0.8205689277899344,"from gaussian measurements. arXiv preprint arXiv:1806.02511, 2018.
313"
REFERENCES,0.8227571115973742,"[14] Misha E Kilmer, Karen Braman, Ning Hao, and Randy C Hoover. Third-order tensors as
314"
REFERENCES,0.824945295404814,"operators on matrices: A theoretical and computational framework with applications in imaging.
315"
REFERENCES,0.8271334792122538,"SIAM Journal on Matrix Analysis and Applications, 34(1):148–172, 2013.
316"
REFERENCES,0.8293216630196937,"[15] Zemin Zhang, Gregory Ely, Shuchin Aeron, Ning Hao, and Misha Kilmer. Novel methods for
317"
REFERENCES,0.8315098468271335,"multilinear data completion and de-noising based on tensor-svd. In Proceedings of the IEEE
318"
REFERENCES,0.8336980306345733,"conference on computer vision and pattern recognition, pages 3842–3849, 2014.
319"
REFERENCES,0.8358862144420132,"[16] Yang Mu, Ping Wang, Liangfu Lu, Xuyun Zhang, and Lianyong Qi. Weighted tensor nuclear
320"
REFERENCES,0.838074398249453,"norm minimization for tensor completion using tensor-svd. Pattern Recognition Letters, 130:4–
321"
REFERENCES,0.8402625820568927,"11, 2020.
322"
REFERENCES,0.8424507658643327,"[17] Taixiang Jiang, Tingzhu Huang, Xile Zhao, and Liangjian Deng. Multi-dimensional imaging
323"
REFERENCES,0.8446389496717724,"data recovery via minimizing the partial sum of tubal nuclear norm. Journal of Computational
324"
REFERENCES,0.8468271334792122,"and Applied Mathematics, 372:112680, 2020.
325"
REFERENCES,0.849015317286652,"[18] Hao Kong, Xingyu Xie, and Zhouchen Lin. t-schatten-p norm for low-rank tensor recovery.
326"
REFERENCES,0.8512035010940919,"IEEE Journal of Selected Topics in Signal Processing, 12(6):1405–1419, 2018.
327"
REFERENCES,0.8533916849015317,"[19] Chunsheng Liu, Hong Shan, and Chunlei Chen. Tensor p-shrinkage nuclear norm for low-rank
328"
REFERENCES,0.8555798687089715,"tensor completion. Neurocomputing, 387:255–267, 2020.
329"
REFERENCES,0.8577680525164114,"[20] Yang Zhou and YiuMing Cheung. Bayesian low-tubal-rank robust tensor factorization with
330"
REFERENCES,0.8599562363238512,"multi-rank determination. IEEE Transactions on Pattern Analysis and Machine Intelligence,
331"
REFERENCES,0.862144420131291,"43(1):62–76, 2019.
332"
REFERENCES,0.8643326039387309,"[21] Jian Lou and YiuMing Cheung. Robust low-rank tensor minimization via a new tensor spectral
333"
REFERENCES,0.8665207877461707,"k-support norm. IEEE Transactions on Image Processing, 29:2314–2327, 2019.
334"
REFERENCES,0.8687089715536105,"[22] Hailin Wang, Feng Zhang, Jianjun Wang, Tingwen Huang, Jianwen Huang, and Xinling Liu.
335"
REFERENCES,0.8708971553610503,"Generalized nonconvex approach for low-tubal-rank tensor recovery. IEEE Transactions on
336"
REFERENCES,0.8730853391684902,"Neural Networks and Learning Systems, 33(8):3305–3319, 2021.
337"
REFERENCES,0.87527352297593,"[23] Yisi Luo, Xile Zhao, Taixiang Jiang, Yi Chang, Michael K Ng, and Chao Li. Self-supervised
338"
REFERENCES,0.8774617067833698,"nonlinear transform-based tensor nuclear norm for multi-dimensional image recovery. IEEE
339"
REFERENCES,0.8796498905908097,"Transactions on Image Processing, 31:3793–3808, 2022.
340"
REFERENCES,0.8818380743982495,"[24] Hao Kong, Canyi Lu, and Zhouchen Lin. Tensor q-rank: new data dependent deﬁnition of
341"
REFERENCES,0.8840262582056893,"tensor rank. Machine Learning, 110(7):1867–1900, 2021.
342"
REFERENCES,0.8862144420131292,"[25] Tongle Wu, Bin Gao, Jicong Fan, Jize Xue, and Wai Lok Woo. Low-rank tensor completion
343"
REFERENCES,0.888402625820569,"based on self-adaptive learnable transforms. IEEE Transactions on Neural Networks and
344"
REFERENCES,0.8905908096280087,"Learning Systems, 2022.
345"
REFERENCES,0.8927789934354485,"[26] Wenhao Xu, Xile Zhao, and Michael Ng. A fast algorithm for cosine transform based tensor
346"
REFERENCES,0.8949671772428884,"singular value decomposition. arXiv preprint arXiv:1902.03070, 2019.
347"
REFERENCES,0.8971553610503282,"[27] Baburaj Madathil and Sudhish N George. Dct based weighted adaptive multi-linear data
348"
REFERENCES,0.899343544857768,"completion and denoising. Neurocomputing, 318:120–136, 2018.
349"
REFERENCES,0.9015317286652079,"[28] Canyi Lu, Xi Peng, and Yunchao Wei. Low-rank tensor completion with a new tensor nuclear
350"
REFERENCES,0.9037199124726477,"norm induced by invertible linear transforms. In Proceedings of the IEEE/CVF conference on
351"
REFERENCES,0.9059080962800875,"computer vision and pattern recognition, pages 5996–6004, 2019.
352"
REFERENCES,0.9080962800875274,"[29] Michael K Ng, Xiongjun Zhang, and Xile Zhao. Patched-tube unitary transform for robust
353"
REFERENCES,0.9102844638949672,"tensor completion. Pattern Recognition, 100:107181, 2020.
354"
REFERENCES,0.912472647702407,"[30] Guangjing Song, Michael K Ng, and Xiongjun Zhang. Robust tensor completion using trans-
355"
REFERENCES,0.9146608315098468,"formed tensor singular value decomposition. Numerical Linear Algebra with Applications,
356"
REFERENCES,0.9168490153172867,"27(3):e2299, 2020.
357"
REFERENCES,0.9190371991247265,"[31] Taixiang Jiang, Michael K Ng, Xile Zhao, and Tingzhu Huang. Framelet representation of
358"
REFERENCES,0.9212253829321663,"tensor nuclear norm for third-order tensor completion. IEEE Transactions on Image Processing,
359"
REFERENCES,0.9234135667396062,"29:7233–7244, 2020.
360"
REFERENCES,0.925601750547046,"[32] Jianli Wang, Tingzhu Huang, Xile Zhao, Taixiang Jiang, and Michael K Ng. Multi-dimensional
361"
REFERENCES,0.9277899343544858,"visual data completion via low-rank tensor representation under coupled transform. IEEE
362"
REFERENCES,0.9299781181619255,"Transactions on Image Processing, 30:3581–3596, 2021.
363"
REFERENCES,0.9321663019693655,"[33] Emmanuel J Candès, Xiaodong Li, Yi Ma, and John Wright. Robust principal component
364"
REFERENCES,0.9343544857768052,"analysis? Journal of the ACM (JACM), 58(3):1–37, 2011.
365"
REFERENCES,0.936542669584245,"[34] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, Jonathan Eckstein, et al. Distributed opti-
366"
REFERENCES,0.9387308533916849,"mization and statistical learning via the alternating direction method of multipliers. Foundations
367"
REFERENCES,0.9409190371991247,"and Trends R⃝in Machine learning, 3(1):1–122, 2011.
368"
REFERENCES,0.9431072210065645,"[35] David L Donoho. De-noising by soft-thresholding. IEEE transactions on information theory,
369"
REFERENCES,0.9452954048140044,"41(3):613–627, 1995.
370"
REFERENCES,0.9474835886214442,"[36] Jianfeng Cai, Emmanuel J Candès, and Zuowei Shen. A singular value thresholding algorithm
371"
REFERENCES,0.949671772428884,"for matrix completion. SIAM Journal on optimization, 20(4):1956–1982, 2010.
372"
REFERENCES,0.9518599562363238,"[37] Tianyi Zhou and Dacheng Tao. Godec: Randomized low-rank & sparse matrix decomposition
373"
REFERENCES,0.9540481400437637,"in noisy case. In Proceedings of the 28th International Conference on Machine Learning, ICML
374"
REFERENCES,0.9562363238512035,"2011, 2011.
375"
REFERENCES,0.9584245076586433,"[38] Xiaowei Zhou, Can Yang, and Weichuan Yu. Moving object detection by detecting contiguous
376"
REFERENCES,0.9606126914660832,"outliers in the low-rank representation. IEEE transactions on pattern analysis and machine
377"
REFERENCES,0.962800875273523,"intelligence, 35(3):597–610, 2012.
378"
REFERENCES,0.9649890590809628,"[39] Hongwei Yong, Deyu Meng, Wangmeng Zuo, and Lei Zhang. Robust online matrix factorization
379"
REFERENCES,0.9671772428884027,"for dynamic background subtraction. IEEE transactions on pattern analysis and machine
380"
REFERENCES,0.9693654266958425,"intelligence, 40(7):1726–1740, 2017.
381"
REFERENCES,0.9715536105032823,"[40] Yinqiang Zheng, Guangcan Liu, Shigeki Sugimoto, Shuicheng Yan, and Masatoshi Okutomi.
382"
REFERENCES,0.973741794310722,"Practical low-rank matrix approximation under robust l 1-norm. In 2012 IEEE Conference on
383"
REFERENCES,0.975929978118162,"Computer Vision and Pattern Recognition, pages 1410–1417. IEEE, 2012.
384"
REFERENCES,0.9781181619256017,"[41] Naiyan Wang, Tiansheng Yao, Jingdong Wang, and Dit-Yan Yeung. A probabilistic approach to
385"
REFERENCES,0.9803063457330415,"robust matrix factorization. In Computer Vision–ECCV 2012: 12th European Conference on
386"
REFERENCES,0.9824945295404814,"Computer Vision, Florence, Italy, October 7-13, 2012, Proceedings, Part VII 12, pages 126–139.
387"
REFERENCES,0.9846827133479212,"Springer, 2012.
388"
REFERENCES,0.986870897155361,"[42] Jiangjun Peng, Yao Wang, Hongying Zhang, Jianjun Wang, and Deyu Meng. Exact decomposi-
389"
REFERENCES,0.9890590809628009,"tion of joint low rankness and local smoothness plus sparse matrices. IEEE Transactions on
390"
REFERENCES,0.9912472647702407,"Pattern Analysis and Machine Intelligence, 2022.
391"
REFERENCES,0.9934354485776805,"[43] Andong Wang, QiBin Zhao, Zhong Jin, Chao Li, and GuoXu Zhou. Robust tensor decomposition
392"
REFERENCES,0.9956236323851203,"via orientation invariant tubal nuclear norms. Science China Technological Sciences, 65(6):1300–
393"
REFERENCES,0.9978118161925602,"1317, 2022.
394"
