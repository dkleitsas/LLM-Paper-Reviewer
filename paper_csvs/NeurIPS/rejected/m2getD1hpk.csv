Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0021008403361344537,"In this paper, we introduce FITS, a lightweight yet powerful model for time series
1"
ABSTRACT,0.004201680672268907,"analysis. Unlike existing models that directly process raw time-domain data, FITS
2"
ABSTRACT,0.0063025210084033615,"operates on the principle that time series can be manipulated through interpolation
3"
ABSTRACT,0.008403361344537815,"in the complex frequency domain. By discarding high-frequency components with
4"
ABSTRACT,0.01050420168067227,"negligible impact on time series data, FITS achieves performance comparable to
5"
ABSTRACT,0.012605042016806723,"state-of-the-art models for time series forecasting and anomaly detection tasks,
6"
ABSTRACT,0.014705882352941176,"while having a remarkably compact size of only approximately 10k parameters.
7"
ABSTRACT,0.01680672268907563,"Such a lightweight model can be easily trained and deployed in edge devices,
8"
ABSTRACT,0.018907563025210083,"creating opportunities for various applications. The anonymous code repo is
9"
ABSTRACT,0.02100840336134454,"available in: https://anonymous.4open.science/r/FITS
10"
INTRODUCTION,0.023109243697478993,"1
Introduction
11"
INTRODUCTION,0.025210084033613446,"Time series analysis plays a crucial role in numerous domains, including finance, energy, weather
12"
INTRODUCTION,0.0273109243697479,"forecasting, and signal processing, where understanding and predicting temporal patterns are essential.
13"
INTRODUCTION,0.029411764705882353,"Existing time series analysis methods primarily focus on extracting features in the time domain (Zhou
14"
INTRODUCTION,0.031512605042016806,"et al., 2021; Liu et al., 2022; Zeng et al., 2022; Nie et al., 2023; Zhang et al., 2022). However, due to
15"
INTRODUCTION,0.03361344537815126,"the inherent complexity and dynamic nature of time series data, the information contained in the time
16"
INTRODUCTION,0.03571428571428571,"domain tends to be sparse and dispersed. Consequently, researchers design intricate methodologies
17"
INTRODUCTION,0.037815126050420166,"and complex models to capture and exploit this information, often relying on approaches such as
18"
INTRODUCTION,0.03991596638655462,"transformer architectures (Zhou et al., 2021; Wu et al., 2021; Zhou et al., 2022a). However, these
19"
INTRODUCTION,0.04201680672268908,"sophisticated techniques often lead to the proliferation of large-scale and computationally demanding
20"
INTRODUCTION,0.04411764705882353,"models, posing challenges in terms of efficiency and scalability.
21"
INTRODUCTION,0.046218487394957986,"Conversely, the frequency domain representation of time series data offers a more concise and
22"
INTRODUCTION,0.04831932773109244,"compact representation of its underlying information. Recognizing this potential, previous studies
23"
INTRODUCTION,0.05042016806722689,"have explored the utilization of frequency domain information in time series analysis. For instance,
24"
INTRODUCTION,0.052521008403361345,"FEDformer (Zhou et al., 2022a) incorporates spectral information as a supplementary feature, en-
25"
INTRODUCTION,0.0546218487394958,"hancing the modeling capabilities of transformer-based time series models. Another approach,
26"
INTRODUCTION,0.05672268907563025,"FNet (Lee-Thorp et al., 2022), leverages frequency domain multiplication to replace convolution
27"
INTRODUCTION,0.058823529411764705,"operations, thereby reducing computational overhead. Moreover, LTSF-Linear (Zeng et al., 2022)
28"
INTRODUCTION,0.06092436974789916,"has demonstrated that highly accurate predictions can be achieved by solely learning the dominant
29"
INTRODUCTION,0.06302521008403361,"periodicity. Similarly, methods like TimesNet (Wu et al., 2023) segment the time series based on
30"
INTRODUCTION,0.06512605042016807,"frequencies with high amplitude and employ CNNs for multi-periodicity feature extraction.
31"
INTRODUCTION,0.06722689075630252,"However, existing methodologies often overlook the fundamental nature of the frequency domain
32"
INTRODUCTION,0.06932773109243698,"representation, which utilizes complex numbers to express both amplitude and phase information.
33"
INTRODUCTION,0.07142857142857142,"Motivated by the fact that longer time series segments provide a higher-resolution frequency rep-
34"
INTRODUCTION,0.07352941176470588,"resentation, we propose FITS (Frequency Interpolation Time Series Analysis Baseline). The core
35"
INTRODUCTION,0.07563025210084033,"component of FITS is a complex-valued linear layer that can explicitly learn amplitude scaling and
36"
INTRODUCTION,0.07773109243697479,"phase shift to perform interpolation in the complex frequency domain. Although FITS conducts
37"
INTRODUCTION,0.07983193277310924,"interpolation in the frequency domain, it remains an end-to-end time domain model incorporating
38"
INTRODUCTION,0.0819327731092437,"the rFFT (Brigham & Morrow, 1967). Specifically, we project the input segment to the complex
39"
INTRODUCTION,0.08403361344537816,"frequency domain for frequency interpolation using rFFT. We then project the interpolated frequency
40"
INTRODUCTION,0.0861344537815126,"representation back to the time domain as a longer segment for supervision. This end-to-end design
41"
INTRODUCTION,0.08823529411764706,"enables FITS to adapt to various downstream tasks with commonly-used time domain supervision,
42"
INTRODUCTION,0.09033613445378151,"such as forecasting and reconstruction.
43"
INTRODUCTION,0.09243697478991597,"Additionally, FITS incorporates a low-pass filter to obtain a compact representation with minimal
44"
INTRODUCTION,0.09453781512605042,"information loss, resulting in small model volume and minimal computational overhead while
45"
INTRODUCTION,0.09663865546218488,"maintaining state-of-the-art (SOTA) performance. Notably, under most settings, FITS achieves
46"
INTRODUCTION,0.09873949579831932,"SOTA performance with under 10k parameters, which is 50 times smaller than the lightweight
47"
INTRODUCTION,0.10084033613445378,"temporal linear model DLinear (Zeng et al., 2022) and approximately 10,000 times smaller than
48"
INTRODUCTION,0.10294117647058823,"other mainstream models. The low memory and computation overhead make FITS suitable for
49"
INTRODUCTION,0.10504201680672269,"deploying or even training on edge devices for forecasting or anomaly detection.
50"
INTRODUCTION,0.10714285714285714,"To summarize, our contributions are twofold:
51"
INTRODUCTION,0.1092436974789916,"• We introduce FITS, a lightweight model containing merely 5k∼10k parameters for time
52"
INTRODUCTION,0.11134453781512606,"series analysis. Despite its compact size which is several orders of magnitude smaller than
53"
INTRODUCTION,0.1134453781512605,"mainstream models, FITS delivers exceptional performance in various tasks, including
54"
INTRODUCTION,0.11554621848739496,"long-term forecasting and anomaly detection, achieving state-of-the-art performance in
55"
INTRODUCTION,0.11764705882352941,"several datasets.
56"
INTRODUCTION,0.11974789915966387,"• FITS employs the complex-valued neural network for time series analysis, which provides a
57"
INTRODUCTION,0.12184873949579832,"novel perspective that simultaneously captures amplitude and phase information, leading to
58"
INTRODUCTION,0.12394957983193278,"more comprehensive and efficient modeling of time series data.
59"
RELATED WORK AND MOTIVATION,0.12605042016806722,"2
Related Work and Motivation
60"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.12815126050420167,"2.1
Frequency-aware Time Series Analysis Models
61"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.13025210084033614,"Recent advancements in time series analysis have witnessed the utilization of frequency domain
62"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.1323529411764706,"information to capture and interpret underlying patterns. FNet (Lee-Thorp et al., 2022) leverages a
63"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.13445378151260504,"pure attention-based architecture to efficiently capture temporal dependencies and patterns solely in
64"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.13655462184873948,"the frequency domain, eliminating the need for convolutional or recurrent layers. On the other hand,
65"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.13865546218487396,"FEDFormer (Zhou et al., 2022a) and FiLM (Zhou et al., 2022b) incorporate frequency information as
66"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.1407563025210084,"supplementary features to enhance the model’s capability in capturing long-term periodic patterns
67"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.14285714285714285,"and speed up computation.
68"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.14495798319327732,"The other line of work aims to capture the periodicity inherent in the data. For instance, DLinear (Zeng
69"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.14705882352941177,"et al., 2022) adopts a single linear layer to extract the dominant periodicity from the temporal domain
70"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.14915966386554622,"and surpasses a range of deep feature extraction-based methods. More recently, TimesNet (Wu et al.,
71"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.15126050420168066,"2023) achieves state-of-the-art results by identifying several dominant frequencies instead of relying
72"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.15336134453781514,"on a single dominant periodicity. Specifically, they use the Fast Fourier Transform (FFT) to find the
73"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.15546218487394958,"frequencies with the largest energy and reshape the original 1D time series into 2D images according
74"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.15756302521008403,"to their periods.
75"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.15966386554621848,"However, these approaches still rely on feature engineering to identify the dominant period set.
76"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.16176470588235295,"Selecting this set based on energy may only consider the dominant period and its harmonics, limiting
77"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.1638655462184874,"the information captured. Moreover, these methodologies are still considered inefficient and prone to
78"
FREQUENCY-AWARE TIME SERIES ANALYSIS MODELS,0.16596638655462184,"overfitting.
79"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.16806722689075632,"2.2
Divide and Conquer the Frequency Components
80"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.17016806722689076,"Treating a time series as a signal allows us to break it down into a linear combination of sinusoidal
81"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.1722689075630252,"components without any information loss. Each component possesses a unique frequency, initial
82"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.17436974789915966,"phase, and amplitude. Forecasting directly on the original time series can be challenging, but
83"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.17647058823529413,"forecasting each frequency component is comparatively straightforward, as we only need to apply a
84"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.17857142857142858,"phase bias to the sinusoidal wave based on the time shift. Subsequently, we linearly combine these
85"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.18067226890756302,"shifted sinusoidal waves to obtain the forecasting result.
86"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.18277310924369747,"This approach effectively preserves the frequency characteristics of the given look-back window
87"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.18487394957983194,"while maintaining semantic consistency between the look-back window and the forecasting horizon.
88"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.1869747899159664,"Specifically, the resulting forecasted values maintain the frequency features of the original time series
89"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.18907563025210083,"with a reasonable time shift, ensuring that semantic consistency is maintained.
90"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.19117647058823528,"However, forecasting each sinusoidal component in the time domain can be cumbersome, as the
91"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.19327731092436976,"sinusoidal components are treated as a sequence of data points. To address this, we propose conducting
92"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.1953781512605042,"this manipulation in the complex frequency domain, which offers a more compact and information-
93"
DIVIDE AND CONQUER THE FREQUENCY COMPONENTS,0.19747899159663865,"rich representation, as described below.
94"
METHOD,0.19957983193277312,"3
Method
95"
METHOD,0.20168067226890757,"3.1
Preliminary: FFT and Complex Frequency Domain
96"
METHOD,0.20378151260504201,"The Fast Fourier Transform (FFT, (Brigham & Morrow, 1967)) is a widely used algorithm for
97"
METHOD,0.20588235294117646,"efficiently computing the Discrete Fourier Transform (DFT) of a sequence of complex numbers. The
98"
METHOD,0.20798319327731093,"DFT is a mathematical operation that converts a discrete-time signal from the time domain to the
99"
METHOD,0.21008403361344538,"complex frequency domain. In cases where the input signal is real, such as in time series analysis,
100"
METHOD,0.21218487394957983,"the Real FFT (rFFT) is commonly used to obtain a compact representation. With an input of N real
101"
METHOD,0.21428571428571427,"numbers, the rFFT produces a sequence of N/2 + 1 complex numbers that represent the signal in the
102"
METHOD,0.21638655462184875,"complex frequency domain.
103"
METHOD,0.2184873949579832,"Complex Frequency Domain
104"
METHOD,0.22058823529411764,"In Fourier analysis, the complex frequency domain is a representation of a signal in which each
105"
METHOD,0.22268907563025211,"frequency component is characterized by a complex number. This complex number captures both
106"
METHOD,0.22478991596638656,"the amplitude and phase of the component, providing a comprehensive description. The amplitude
107"
METHOD,0.226890756302521,"of a frequency component represents the magnitude or strength of that component in the original
108"
METHOD,0.22899159663865545,"time-domain signal. In contrast, the phase represents the temporal shift or delay introduced by that
109"
METHOD,0.23109243697478993,"component. Mathematically, the complex number associated with a frequency component can be
110"
METHOD,0.23319327731092437,"represented as a complex exponential element with a given amplitude and phase:
111"
METHOD,0.23529411764705882,"X(f) = |X(f)|ejθ(f),"
METHOD,0.23739495798319327,"where X(f) is the complex number associated with the frequency component at frequency f, |X(f)|
112"
METHOD,0.23949579831932774,"is the amplitude of the component, and θ(f) is the phase of the component. As shown in Fig. 1(a), in
113"
METHOD,0.2415966386554622,"the complex plane, the complex exponential element can be visualized as a vector with a length equal
114"
METHOD,0.24369747899159663,"to the amplitude and angle equal to the phase:
115"
METHOD,0.24579831932773108,X(f) = |X(f)|(cos θ(f) + j sin θ(f))
METHOD,0.24789915966386555,"Therefore, the complex number in the complex frequency domain provides a concise and elegant
116"
METHOD,0.25,"means of representing the amplitude and phase of each frequency component in the Fourier transform.
117"
METHOD,0.25210084033613445,Imaginary Real
METHOD,0.2542016806722689,𝑋= 𝑋𝑐𝑜𝑠𝜃+ 𝑗𝑋𝑠𝑖𝑛𝜃|
METHOD,0.25630252100840334,= 𝑋𝑒௝ఏ 𝜃 𝑋𝑐𝑜𝑠𝜃 𝑋𝑠𝑖𝑛𝜃 |𝑋|
METHOD,0.25840336134453784,(a) Complex number on the complex plane
METHOD,0.2605042016806723,Imaginary Real
METHOD,0.26260504201680673,𝑋ଵ= |𝑋ଵ|𝑒௝ఏభ
METHOD,0.2647058823529412,"𝑋ᇱ= ( 𝑋ଵ⋅|𝑋ଶ|)𝑒௝(ఏభାఏమ) 𝜃ଵ
𝜃ଶ"
METHOD,0.2668067226890756,(b) Complex number multiplication
METHOD,0.2689075630252101,Figure 1: Illustration of Complex Number Visualization and Multiplication
METHOD,0.2710084033613445,"Time Shift and Phase Shift. The time shift of a signal corresponds to the phase shift in the frequency
118"
METHOD,0.27310924369747897,"domain. Especially in the complex frequency domain, we can express such phase shift by multiplying
119"
METHOD,0.27521008403361347,"a unit complex exponential element with the corresponding phase. Mathematically, if we shift a
120"
METHOD,0.2773109243697479,"signal x(t) forward in time by a constant amount τ, resulting in the signal x(t −τ), the Fourier
121"
METHOD,0.27941176470588236,"transform is given by:
122"
METHOD,0.2815126050420168,Xτ(f) = e−j2πfτX(f) = |X(f)|ej(θ(f)−2πfτ) = [cos(−2πfτ) + jsin(−2πfτ)]X(f)
METHOD,0.28361344537815125,"The shifted signal still has an amplitude of |X(f)|, while the phase θτ(f) = θ(f) −2πfτ shows a
123"
METHOD,0.2857142857142857,"shift which is linear to the time shift.
124"
METHOD,0.28781512605042014,"In summary, the amplitude scaling and phase shifting can be simultaneously expressed as the
125"
METHOD,0.28991596638655465,"multiplication of complex numbers, as shown in Fig. 1(b).
126"
FITS PIPELINE,0.2920168067226891,"3.2
FITS Pipeline
127"
FITS PIPELINE,0.29411764705882354,"Motivated by the fact that a longer time series provides a higher frequency resolution in its frequency
128"
FITS PIPELINE,0.296218487394958,"representation, we train FITS to generate an extended time series segment by interpolating the
129"
FITS PIPELINE,0.29831932773109243,"frequency representation of the input time series segment. We use a complex-valued linear layer to
130"
FITS PIPELINE,0.3004201680672269,"learn such interpolation. According to the fact that the amplitude scaling and phase shifting can be
131"
FITS PIPELINE,0.3025210084033613,"conveniently expressed as the multiplication of complex numbers, such complex linear combination
132"
FITS PIPELINE,0.30462184873949577,"allows FITS to effectively incorporate both the amplitude scaling and phase shift of frequency
133"
FITS PIPELINE,0.3067226890756303,"components during the interpolation process. As shown in Fig. 2, we use rFFT to project time series
134"
FITS PIPELINE,0.3088235294117647,"segments to the complex frequency domain. After the interpolation, the frequency representation is
135"
FITS PIPELINE,0.31092436974789917,"projected back with inverse rFFT (irFFT).
136 RIN 𝑋෨ Amp. 𝑋′෡ 𝑥 Value Time Amp."
FITS PIPELINE,0.3130252100840336,"0
Freq."
FITS PIPELINE,0.31512605042016806,Base Freq.
FITS PIPELINE,0.3172268907563025,2nd Harmo. 𝑋෨′ Freq. COF Amp.
FITS PIPELINE,0.31932773109243695,"Freq.
Freq. Amp."
FITS PIPELINE,0.32142857142857145,"0
0 0
𝑋෠
𝑥ො௟௕௪ Value Time 𝑥ො௛"
FITS PIPELINE,0.3235294117647059,"rFFT
LPF iRIN"
FITS PIPELINE,0.32563025210084034,"irFFT
0 Padding"
FITS PIPELINE,0.3277310924369748,Complex-valued
FITS PIPELINE,0.32983193277310924,Linear Layer
FITS PIPELINE,0.3319327731092437,"Figure 2: Pipeline of FITS, with a focus on the forecasting task. The reconstruction task follows the
same pipeline, except for the reconstruction supervision loss."
FITS PIPELINE,0.33403361344537813,"However, we cannot directly use the frequency representation of the original input time series segment
137"
FITS PIPELINE,0.33613445378151263,"because the mean of such segments will result in a very large 0-frequency component in its complex
138"
FITS PIPELINE,0.3382352941176471,"frequency representation. To eliminate the 0-frequency component, we pass it through reversible
139"
FITS PIPELINE,0.3403361344537815,"instance-wise normalization (RIN) (Kim et al., 2022) to obtain a zero-mean instance. As a result,
140"
FITS PIPELINE,0.34243697478991597,"the normalized complex frequency representation now has a length of N/2, where N represents the
141"
FITS PIPELINE,0.3445378151260504,"original length of the time series.
142"
FITS PIPELINE,0.34663865546218486,"Furthermore, we incorporate a low-pass filter (LPF) into the FITS model to further reduce its size.
143"
FITS PIPELINE,0.3487394957983193,"The LPF removes high-frequency components above a specified cutoff frequency, resulting in a more
144"
FITS PIPELINE,0.35084033613445376,"compact model representation while retaining the important information of the time series. The
145"
FITS PIPELINE,0.35294117647058826,"rationale behind this design will be elaborated in the subsequent section. Despite operating in the
146"
FITS PIPELINE,0.3550420168067227,"frequency domain, FITS is supervised in the time domain using common loss functions such as Mean
147"
FITS PIPELINE,0.35714285714285715,"Squared Error (MSE) after the irFFT, allowing for diverse supervision tailored to different time series
148"
FITS PIPELINE,0.3592436974789916,"downstream tasks.
149"
FITS PIPELINE,0.36134453781512604,"In the case of forecasting tasks, we generate the look-back window along with the horizon as shown
150"
FITS PIPELINE,0.3634453781512605,"in Fig. 2. This allows us to provide supervision for forecasting and backcasting, where the model
151"
FITS PIPELINE,0.36554621848739494,"is encouraged to accurately reconstruct the look-back window. Our ablation study reveals that
152"
FITS PIPELINE,0.36764705882352944,"combining backcast and forecast supervision can yield improved performance in certain scenarios.
153"
FITS PIPELINE,0.3697478991596639,"For reconstruction tasks, we downsample the original time series segment based on a specific
154"
FITS PIPELINE,0.37184873949579833,"downsampling rate. Subsequently, FITS is employed to perform frequency interpolation, enabling
155"
FITS PIPELINE,0.3739495798319328,"the reconstruction of the downsampled segment back to its original form. Thus, direct supervision
156"
FITS PIPELINE,0.3760504201680672,"is applied using reconstruction loss to ensure faithful reconstruction. The reconstruction tasks also
157"
FITS PIPELINE,0.37815126050420167,"follow the pipeline in Fig. 2 with the supervision replaced with reconstruction loss.
158"
KEY MECHANISMS OF FITS,0.3802521008403361,"3.3
Key Mechanisms of FITS
159"
KEY MECHANISMS OF FITS,0.38235294117647056,"Complex Frequency Linear Interpolation. To control the output length of the model, we introduce
160"
KEY MECHANISMS OF FITS,0.38445378151260506,"an interpolation rate denoted as η, which represents the ratio of the model’s output length Lo to its
161"
KEY MECHANISMS OF FITS,0.3865546218487395,"corresponding input length Li.
162"
KEY MECHANISMS OF FITS,0.38865546218487396,"It is worth noting that frequency interpolation operates on the normalized complex frequency repre-
163"
KEY MECHANISMS OF FITS,0.3907563025210084,"sentation, which has half the length of the original time series. Importantly, this interpolation rate can
164"
KEY MECHANISMS OF FITS,0.39285714285714285,"also be applied to the frequency domain, as indicated by the equation:
165"
KEY MECHANISMS OF FITS,0.3949579831932773,ηfreq = Lo/2
KEY MECHANISMS OF FITS,0.39705882352941174,Li/2 = Lo
KEY MECHANISMS OF FITS,0.39915966386554624,"Li
= η"
KEY MECHANISMS OF FITS,0.4012605042016807,"Based on this formula, with an arbitrary frequency f, the frequency band 1 ∼f in the original
166"
KEY MECHANISMS OF FITS,0.40336134453781514,"signal is linearly projected to the frequency band 1 ∼ηf in the output signal. As a result, we define
167"
KEY MECHANISMS OF FITS,0.4054621848739496,"the input length of our complex-valued linear layer as L and the interpolated output length as ηL.
168"
KEY MECHANISMS OF FITS,0.40756302521008403,"Notably, when applying the Low Pass Filter (LPF), the value of L corresponds to the cutoff frequency
169"
KEY MECHANISMS OF FITS,0.4096638655462185,"(COF) of the LPF. After performing frequency interpolation, the complex frequency representation is
170"
KEY MECHANISMS OF FITS,0.4117647058823529,"zero-padded to a length of Lo/2, where Lo represents the desired output length. Prior to applying the
171"
KEY MECHANISMS OF FITS,0.41386554621848737,"irFFT, an additional zero is introduced as the representation’s zero-frequency component.
172"
KEY MECHANISMS OF FITS,0.41596638655462187,"Low Pass Filter (LPF). The primary objective of incorporating the LPF within FITS is to compress
173"
KEY MECHANISMS OF FITS,0.4180672268907563,"the model’s volume while preserving essential information. The LPF achieves this by discarding
174"
KEY MECHANISMS OF FITS,0.42016806722689076,"frequency components above a specified cutoff frequency (COF), resulting in a more concise fre-
175"
KEY MECHANISMS OF FITS,0.4222689075630252,"quency domain representation. The LPF retains the relevant information in the time series while
176"
KEY MECHANISMS OF FITS,0.42436974789915966,"discarding components beyond the model’s learning capability. This ensures that a significant portion
177"
KEY MECHANISMS OF FITS,0.4264705882352941,"of the original time series’ meaningful content is preserved. As demonstrated in Fig. 3, the filtered
178"
KEY MECHANISMS OF FITS,0.42857142857142855,"waveform exhibits minimal distortion even when only preserving a quarter of the original frequency
179"
KEY MECHANISMS OF FITS,0.43067226890756305,"domain representation. Furthermore, the high-frequency components filtered out by the LPF typically
180"
KEY MECHANISMS OF FITS,0.4327731092436975,"comprise noise and trends, which are inherently irrelevant for effective time series modeling."
KEY MECHANISMS OF FITS,0.43487394957983194,"0
200
400 15 20 25 30"
KEY MECHANISMS OF FITS,0.4369747899159664,"0
100
200 0 200 400"
KEY MECHANISMS OF FITS,0.43907563025210083,No Filter MSE: 0.0000
KEY MECHANISMS OF FITS,0.4411764705882353,(a) Original
KEY MECHANISMS OF FITS,0.4432773109243697,"0
200
400 15 20 25 30"
KEY MECHANISMS OF FITS,0.44537815126050423,"0
100
200 0 200 400 COF"
KEY MECHANISMS OF FITS,0.4474789915966387,COF: 120 MSE: 0.0727
KEY MECHANISMS OF FITS,0.4495798319327731,(b) COF at 6th harmonic
KEY MECHANISMS OF FITS,0.45168067226890757,"0
200
400 15 20 25 30"
KEY MECHANISMS OF FITS,0.453781512605042,"0
100
200 0 200 400 COF"
KEY MECHANISMS OF FITS,0.45588235294117646,COF: 60 MSE: 0.1660
KEY MECHANISMS OF FITS,0.4579831932773109,(c) COF at 3rd harmonic
KEY MECHANISMS OF FITS,0.46008403361344535,"0
200
400 15 20 25 30"
KEY MECHANISMS OF FITS,0.46218487394957986,"0
100
200 0 200 400 COF"
KEY MECHANISMS OF FITS,0.4642857142857143,COF: 40 MSE: 0.4296
KEY MECHANISMS OF FITS,0.46638655462184875,(d) COF at 2nd harmonic
KEY MECHANISMS OF FITS,0.4684873949579832,"Figure 3: Waveform (1st row) and amplitude spectrum (2nd row) of a time series segment selected
from the ’OT’ channel of the ETTh1 dataset, spanning from the 1500th to the 1980th data point. The
segment has a length of 480, and its dominant periodicity is 24, corresponding to a base frequency of
20. The blue lines represent the waveform/spectrum with no applied filter, while the orange lines
represent the waveform/spectrum with the filter applied. The filter cutoff frequency is chosen based
on a harmonic of the original time series. 181"
KEY MECHANISMS OF FITS,0.47058823529411764,"Selecting an appropriate cutoff frequency (COF) remains a nontrivial challenge. To address this,
182"
KEY MECHANISMS OF FITS,0.4726890756302521,"we propose a method based on the harmonic content of the dominant frequency. Harmonics, which
183"
KEY MECHANISMS OF FITS,0.47478991596638653,"are integer multiples of the dominant frequency, play a significant role in shaping the waveform of
184"
KEY MECHANISMS OF FITS,0.47689075630252103,"a time series. By aligning the cutoff frequency with these harmonics, we keep relevant frequency
185"
KEY MECHANISMS OF FITS,0.4789915966386555,"components associated with the signal’s structure and periodicity. This approach leverages the
186"
KEY MECHANISMS OF FITS,0.4810924369747899,"inherent relationship between frequencies to extract meaningful information while suppressing noise
187"
KEY MECHANISMS OF FITS,0.4831932773109244,"and irrelevant high-frequency components. The impact of COF on different harmonics’ waveforms is
188"
KEY MECHANISMS OF FITS,0.4852941176470588,"shown in Fig. 3. We further elaborate on the impact of COF in our experimental results.
189"
EXPERIMENTS FOR FORECASTING,0.48739495798319327,"4
Experiments for Forecasting
190"
FORECASTING AS FREQUENCY INTERPOLATION,0.4894957983193277,"4.1
Forecasting as Frequency Interpolation
191"
FORECASTING AS FREQUENCY INTERPOLATION,0.49159663865546216,"Typically, the forecasting horizon is shorter than the given look-back window, rendering direct
192"
FORECASTING AS FREQUENCY INTERPOLATION,0.49369747899159666,"interpolation unsuitable. Instead, we formulate the forecasting task as the interpolation of a look-back
193"
FORECASTING AS FREQUENCY INTERPOLATION,0.4957983193277311,"window, with length L, to a combination of the look-back window and forecasting horizon, with
194"
FORECASTING AS FREQUENCY INTERPOLATION,0.49789915966386555,"length L+H. This design enables us to provide more supervision during training. With this approach,
195"
FORECASTING AS FREQUENCY INTERPOLATION,0.5,"we can supervise not only the forecasting horizon but also the backcast task on the look-back window.
196"
FORECASTING AS FREQUENCY INTERPOLATION,0.5021008403361344,"Our experimental results demonstrate that this unique training strategy contributes to the improved
197"
FORECASTING AS FREQUENCY INTERPOLATION,0.5042016806722689,"performance of FITS. The interpolation rate of the forecasting task is calculated by:
198"
FORECASTING AS FREQUENCY INTERPOLATION,0.5063025210084033,"ηF ore = 1 + H L ,"
FORECASTING AS FREQUENCY INTERPOLATION,0.5084033613445378,"where L represents the length of the look-back window and H represents the length of the forecasting
199"
FORECASTING AS FREQUENCY INTERPOLATION,0.5105042016806722,"horizon.
200"
EXPERIMENT SETTINGS,0.5126050420168067,"4.2
Experiment Settings
201"
EXPERIMENT SETTINGS,0.5147058823529411,"Datasets. All datasets used in our experiments are widely-used and publicly available real-world
202"
EXPERIMENT SETTINGS,0.5168067226890757,"datasets, including, Traffic, Electricity, Weather, ETT (Zhou et al., 2021). We summarize the
203"
EXPERIMENT SETTINGS,0.5189075630252101,"characteristics of these datasets in Tab. 1. Apart from these datasets for long-term time series
204"
EXPERIMENT SETTINGS,0.5210084033613446,"forecasting, we also use the M4 dataset to test the short-term forecasting performance.
205"
EXPERIMENT SETTINGS,0.523109243697479,Table 1: The statistics of the seven used forecasting datasets.
EXPERIMENT SETTINGS,0.5252100840336135,"Dataset
Traffic
Electricity
Weather
ETTh1&ETTh2
ETTm1 &ETTm2"
EXPERIMENT SETTINGS,0.5273109243697479,"Channels
862
321
21
7
7
Sampling Rate
1hour
1hour
10min
1hour
15min
Total Timesteps
17,544
26,304
52,696
17,420
69,680"
EXPERIMENT SETTINGS,0.5294117647058824,"Baselines. To evaluate the performance of FITS in comparison to state-of-the-art time series forecast-
206"
EXPERIMENT SETTINGS,0.5315126050420168,"ing models, including PatchTST (Nie et al., 2023), TimesNet (Wu et al., 2023), FEDFormer (Zhou
207"
EXPERIMENT SETTINGS,0.5336134453781513,"et al., 2022a), FiLM (Zhou et al., 2022b) and LTSF-Linear (Zeng et al., 2023), we directly refer to
208"
EXPERIMENT SETTINGS,0.5357142857142857,"the reported results in the original papers under the same settings. We report the comparison with
209"
EXPERIMENT SETTINGS,0.5378151260504201,"other transformer-based methods in the appendix.
210"
EXPERIMENT SETTINGS,0.5399159663865546,"Evaluation metrics. We follow the previous works (Zhou et al., 2022a; Zeng et al., 2022; Zhang
211"
EXPERIMENT SETTINGS,0.542016806722689,"et al., 2022) to compare forecasting performance using Mean Squared Error (MSE) as the core
212"
EXPERIMENT SETTINGS,0.5441176470588235,"metrics. Moreover, to evaluate the short-term forecasting, we symmetric Mean Absolute Percentage
213"
EXPERIMENT SETTINGS,0.5462184873949579,"Error (SMAPE) following TimesNet (Wu et al., 2023).
214"
EXPERIMENT SETTINGS,0.5483193277310925,"Implementation details. Following the settings of LTSF-Linear (Zeng et al., 2023), we set the
215"
EXPERIMENT SETTINGS,0.5504201680672269,"look-back window of FITS as 720 for any forecasting horizon. Further experiments also show that a
216"
EXPERIMENT SETTINGS,0.5525210084033614,"longer look-back window can result in better performance. To avoid information leakage, We choose
217"
EXPERIMENT SETTINGS,0.5546218487394958,"the hyper-parameter based on the performance of the validation set.
218"
COMPARISONS WITH SOTAS,0.5567226890756303,"4.3
Comparisons with SOTAs
219"
COMPARISONS WITH SOTAS,0.5588235294117647,"Competitive Performance with High Efficiency
220"
COMPARISONS WITH SOTAS,0.5609243697478992,"We present the results of our experiments on long-term forecasting in Tab. 2 and Tab. 3. The results
221"
COMPARISONS WITH SOTAS,0.5630252100840336,"for short-term forecasting on the M4 dataset are provided in the Appendix. Remarkably, our FITS
222"
COMPARISONS WITH SOTAS,0.5651260504201681,"consistently achieves comparable or even superior performance across all experiments.
223"
COMPARISONS WITH SOTAS,0.5672268907563025,"Tab. 4 presents the number of trainable parameters for various TSF models using a look-back window
224"
COMPARISONS WITH SOTAS,0.569327731092437,"of 96 and a forecasting horizon of 720 on the Electricity dataset. The table clearly demonstrates the
225"
COMPARISONS WITH SOTAS,0.5714285714285714,"exceptional efficiency of FITS compared to other models.
226"
COMPARISONS WITH SOTAS,0.5735294117647058,"Among the listed models, the parameter counts range from millions down to thousands. Notably,
227"
COMPARISONS WITH SOTAS,0.5756302521008403,"large models such as TimesNet and Pyraformer require a staggering number of parameters, with
228"
COMPARISONS WITH SOTAS,0.5777310924369747,"Table 2: Long-term forecasting results on ETT dataset in MSE. The best result is highlighted in bold,
and the second best is highlighted with underline. IMP is the improvement between FITS and the
second best/ best result, where a larger value indicates a better improvement."
COMPARISONS WITH SOTAS,0.5798319327731093,"Dataset
ETTh1
ETTh2
ETTm1
ETTm2
Horizon
96
192
336
720
96
192
336
720
96
192
336
720
96
192
336
720"
COMPARISONS WITH SOTAS,0.5819327731092437,"PatchTST
0.370
0.413
0.422
0.447
0.274
0.341
0.329
0.379
0.293
0.333
0.369
0.416
0.166
0.223
0.274
0.362
TimesNet
0.384
0.436
0.491
0.521
0.340
0.402
0.452
0.462
0.338
0.374
0.410
0.478
0.187
0.249
0.321
0.408
FEDFormer
0.376
0.420
0.459
0.506
0.346
0.429
0.496
0.463
0.379
0.426
0.445
0.543
0.203
0.269
0.325
0.421
FiLM
0.371
0.414
0.442
0.465
0.284
0.357
0.377
0.439
0.302
0.338
0.373
0.420
0.165
0.222
0.277
0.371
Dlinear
0.374
0.405
0.429
0.440
0.338
0.381
0.400
0.436
0.299
0.335
0.369
0.425
0.167
0.221
0.274
0.368
FITS
0.375
0.408
0.429
0.427
0.274
0.333
0.340
0.374
0.305
0.339
0.367
0.418
0.164
0.217
0.269
0.347
IMP
-0.005
-0.003
-0.007
0.013
0
0.008
-0.011
0.005
-0.012
-0.006
0.002
-0.002
0.002
0.004
0.005
0.015"
COMPARISONS WITH SOTAS,0.5840336134453782,"Table 3: Long-term forecasting results on three popular datasets in MSE. The best result is highlighted
in bold and the second best is highlighted with underline. IMP is the improvement between FITS
and the second best/ best result, where a larger value indicates a better improvement."
COMPARISONS WITH SOTAS,0.5861344537815126,"Dataset
Electricity
Traffic
Weather
Horizon
96
192
336
720
96
192
336
720
96
192
336
720"
COMPARISONS WITH SOTAS,0.5882352941176471,"PatchTST
0.129
0.147
0.163
0.197
0.360
0.379
0.392
0.432
0.149
0.194
0.245
0.314
TimesNet
0.168
0.184
0.198
0.220
0.593
0.617
0.629
0.640
0.172
0.219
0.280
0.365
FEDFormer
0.193
0.201
0.214
0.246
0.587
0.604
0.621
0.626
0.217
0.276
0.339
0.403
FiLM
0.154
0.164
0.188
0.236
0.416
0.408
0.425
0.520
0.199
0.228
0.267
0.319
Dlinear
0.140
0.153
0.169
0.203
0.410
0.423
0.435
0.464
0.176
0.218
0.262
0.323
FITS
0.138
0.152
0.166
0.205
0.401
0.407
0.420
0.456
0.145
0.188
0.236
0.308
IMP
-0.009
-0.005
-0.003
-0.008
-0.041
-0.028
-0.028
-0.024
0.004
0.006
0.009
0.006"
COMPARISONS WITH SOTAS,0.5903361344537815,"300.6M and 241.4M, respectively. Similarly, popular models like Transformer, Informer, Autoformer,
229"
COMPARISONS WITH SOTAS,0.592436974789916,"and FEDformer have parameter counts in the range of 13.61M to 20.68M. Even the lightweight yet
230"
COMPARISONS WITH SOTAS,0.5945378151260504,"state-of-the-art model PatchTST has a parameter count of over 1 million.
231"
COMPARISONS WITH SOTAS,0.5966386554621849,"Table 4: Number of trainable parameters
and MACs of TSF models under look-
back window=96 and forecasting hori-
zon=720 on the Electricity dataset."
COMPARISONS WITH SOTAS,0.5987394957983193,"Model
Parameters
MACs"
COMPARISONS WITH SOTAS,0.6008403361344538,"TimesNet
301.7M
1226.49G
Pyraformer
241.4M
0.80G
Transformer
13.61M
4.03G
Informer
14.38M
3.93G
Autoformer
14.91M
4.41G
FiLM
14.91M
5.97G
FEDformer
20.68M
4.41G
PatchTST
1.5M
5.07G"
COMPARISONS WITH SOTAS,0.6029411764705882,"DLinear
139.7K
40M
FITS (Ours)
4.5K∼10K
1.6M∼8.9M"
COMPARISONS WITH SOTAS,0.6050420168067226,"In contrast, FITS stands out as a highly efficient model
232"
COMPARISONS WITH SOTAS,0.6071428571428571,"with an impressively low parameter count. With only 4.5K
233"
COMPARISONS WITH SOTAS,0.6092436974789915,"to 16K parameters, FITS achieves comparable or even
234"
COMPARISONS WITH SOTAS,0.6113445378151261,"superior performance compared to these larger models.
235"
COMPARISONS WITH SOTAS,0.6134453781512605,"It is worth highlighting that FITS requires significantly
236"
COMPARISONS WITH SOTAS,0.615546218487395,"fewer parameters compared to the next smallest model,
237"
COMPARISONS WITH SOTAS,0.6176470588235294,"Dlinear, which has 139.7K parameters. For instance, when
238"
COMPARISONS WITH SOTAS,0.6197478991596639,"considering a 720 look-back window and a 720 forecast-
239"
COMPARISONS WITH SOTAS,0.6218487394957983,"ing horizon, the Dlinear model requires over 1 million
240"
COMPARISONS WITH SOTAS,0.6239495798319328,"parameters, whereas FITS achieves similar performance
241"
COMPARISONS WITH SOTAS,0.6260504201680672,"with only 10k-50k parameters.
242"
COMPARISONS WITH SOTAS,0.6281512605042017,"This analysis showcases the remarkable efficiency of FITS.
243"
COMPARISONS WITH SOTAS,0.6302521008403361,"Despite its small size, FITS consistently achieves compet-
244"
COMPARISONS WITH SOTAS,0.6323529411764706,"itive results, making it an attractive option for time series
245"
COMPARISONS WITH SOTAS,0.634453781512605,"analysis tasks. FITS demonstrates that achieving state-of-
246"
COMPARISONS WITH SOTAS,0.6365546218487395,"the-art or close to state-of-the-art performance with a considerably reduced parameter footprint is
247"
COMPARISONS WITH SOTAS,0.6386554621848739,"possible, making it an ideal choice for resource-constrained environments.
248"
COMPARISONS WITH SOTAS,0.6407563025210085,"Case Study on ETTh2 Dataset
249"
COMPARISONS WITH SOTAS,0.6428571428571429,"We conduct a comprehensive case study on the performance of FITS using the ETTh2 dataset, which
250"
COMPARISONS WITH SOTAS,0.6449579831932774,"further highlights the impact of the look-back window and cutoff frequency on model performance.
251"
COMPARISONS WITH SOTAS,0.6470588235294118,"We provide a case study on other datasets in the Appendix. In our experiments, we observe that
252"
COMPARISONS WITH SOTAS,0.6491596638655462,"increasing the look-back window generally leads to improved performance, while the effect of
253"
COMPARISONS WITH SOTAS,0.6512605042016807,"increasing the cutoff frequency is minor.
254"
COMPARISONS WITH SOTAS,0.6533613445378151,"Tab. 5 showcases the performance results obtained with different look-back window sizes and cutoff
255"
COMPARISONS WITH SOTAS,0.6554621848739496,"frequencies. Larger look-back windows tend to yield better performance across the board. On the
256"
COMPARISONS WITH SOTAS,0.657563025210084,"other hand, increasing the cutoff frequency only results in marginal performance improvements.
257"
COMPARISONS WITH SOTAS,0.6596638655462185,"However, it is important to note that higher cutoff frequencies come at the expense of increased
258"
COMPARISONS WITH SOTAS,0.6617647058823529,"computational resources, as illustrated in Tab. 6.
259"
COMPARISONS WITH SOTAS,0.6638655462184874,"Table 5: The results on the ETTh2 dataset. Values are visualized with a green background, where
darker background indicates worse performance. The top-5 best results are highlighted with a red
background, and the absolute best result is highlighted with red bold font. F represents supervision
on the forecasting task, while B+F represents supervision on backcasting and forecasting tasks."
COMPARISONS WITH SOTAS,0.6659663865546218,"Look-back Window
90
180
360
720
Horizon
COF/nth Harmonic
F
B+F
F
B+F
F
B+F
F
B+F"
COMPARISONS WITH SOTAS,0.6680672268907563,"2
0.297687
0.296042
0.291606
0.289387
0.278644
0.278403
0.277708
0.27696
3
0.297796
0.297377
0.290061
0.288239
0.277512
0.277746
0.276537
0.277068
4
0.297106
0.295624
0.290725
0.287993
0.27624
0.27693
0.274207
0.274498
96"
COMPARISONS WITH SOTAS,0.6701680672268907,"5
0.296168
0.296698
0.288518
0.287375
0.276367
0.277935
0.275989
0.275636"
COMPARISONS WITH SOTAS,0.6722689075630253,"2
0.380163
0.379868
0.360591
0.359769
0.336552
0.337976
0.334854
0.335887
3
0.37983
0.381802
0.359088
0.359498
0.336384
0.336358
0.334666
0.335507
4
0.379657
0.380439
0.359087
0.358536
0.334803
0.349995
0.333522
0.333382
192"
COMPARISONS WITH SOTAS,0.6743697478991597,"5
0.378556
0.379883
0.358809
0.359376
0.335451
0.343227
0.33384
0.335053"
COMPARISONS WITH SOTAS,0.6764705882352942,"2
0.402706
0.404805
0.373257
0.374678
0.344241
0.344414
0.341869
0.342549
3
0.403238
0.404878
0.372231
0.373948
0.345578
0.344976
0.341436
0.342793
4
0.402702
0.407712
0.376199
0.374435
0.343004
0.344167
0.340795
0.342245
336"
COMPARISONS WITH SOTAS,0.6785714285714286,"5
0.403484
0.409516
0.375102
0.37462
0.344333
0.342731
0.341043
0.342214"
COMPARISONS WITH SOTAS,0.680672268907563,"2
0.420072
0.424272
0.403985
0.407392
0.379822
0.38519
0.376871
0.37677
3
0.418323
0.420538
0.400986
0.40686
0.379638
0.386397
0.376236
0.376004
4
0.417485
0.420982
0.399987
0.408128
0.379096
0.386409
0.375865
0.375637
720"
COMPARISONS WITH SOTAS,0.6827731092436975,"5
0.419122
0.420355
0.400776
0.407871
0.378665
0.390754
0.377138
0.374586"
COMPARISONS WITH SOTAS,0.6848739495798319,"Table 6: The number of parameters under different
settings on ETTh1 & ETTh2 dataset."
COMPARISONS WITH SOTAS,0.6869747899159664,"Look-back Window
Horizon
COF/nth Harmonic
90
180
360
720 96"
COMPARISONS WITH SOTAS,0.6890756302521008,"2
703
1053
2279
5913
3
1035
1820
4307
12064
4
1431
2752
6975
20385
5
1922
3876
10374
31042 192"
COMPARISONS WITH SOTAS,0.6911764705882353,"2
1064
1431
2752
6643
3
1564
2450
5192
13520
4
2187
3698
8475
22815
5
2914
5253
12558
34694 336"
COMPARISONS WITH SOTAS,0.6932773109243697,"2
1615
1998
3483
7665
3
2392
3395
6608
15704
4
3321
5160
10725
26460
5
4402
7293
15834
40006 720"
COMPARISONS WITH SOTAS,0.6953781512605042,"2
3078
3510
5418
10512
3
4554
5950
10266
21424
4
6318
9030
16650
36180
5
8370
12750
24570
54780"
COMPARISONS WITH SOTAS,0.6974789915966386,"Considering these observations, we find utiliz-
260"
COMPARISONS WITH SOTAS,0.6995798319327731,"ing a longer look-back window in combination
261"
COMPARISONS WITH SOTAS,0.7016806722689075,"with a low cutoff frequency to achieve near
262"
COMPARISONS WITH SOTAS,0.7037815126050421,"state-of-the-art performance with minimal com-
263"
COMPARISONS WITH SOTAS,0.7058823529411765,"putational cost. For instance, FITS surpasses
264"
COMPARISONS WITH SOTAS,0.707983193277311,"other methods when employing a 720 look-back
265"
COMPARISONS WITH SOTAS,0.7100840336134454,"window and setting the cutoff frequency to the
266"
COMPARISONS WITH SOTAS,0.7121848739495799,"second harmonic. Remarkably, FITS achieves
267"
COMPARISONS WITH SOTAS,0.7142857142857143,"state-of-the-art performance with a parameter
268"
COMPARISONS WITH SOTAS,0.7163865546218487,"count of only around 10k. Moreover, by reduc-
269"
COMPARISONS WITH SOTAS,0.7184873949579832,"ing the look-back window to 360, FITS already
270"
COMPARISONS WITH SOTAS,0.7205882352941176,"achieves close-to-state-of-the-art performance
271"
COMPARISONS WITH SOTAS,0.7226890756302521,"by setting the cutoff frequency to the second
272"
COMPARISONS WITH SOTAS,0.7247899159663865,"harmonic, resulting in a further reduction of the
273"
COMPARISONS WITH SOTAS,0.726890756302521,"model’s parameter count to under 5k (as shown
274"
COMPARISONS WITH SOTAS,0.7289915966386554,"in Tab. 6).
275"
COMPARISONS WITH SOTAS,0.7310924369747899,"These results emphasize the lightweight nature
276"
COMPARISONS WITH SOTAS,0.7331932773109243,"of FITS, making it highly suitable for deploy-
277"
COMPARISONS WITH SOTAS,0.7352941176470589,"ment and training on edge devices with limited
278"
COMPARISONS WITH SOTAS,0.7373949579831933,"computational resources. By carefully selecting the look-back window and cutoff frequency, FITS can
279"
COMPARISONS WITH SOTAS,0.7394957983193278,"achieve excellent performance while maintaining computational efficiency, making it an appealing
280"
COMPARISONS WITH SOTAS,0.7415966386554622,"choice for real-world applications.
281"
EXPERIMENT FOR ANOMALY DETECTION,0.7436974789915967,"5
Experiment for Anomaly Detection
282"
RECONSTRUCTION AS FREQUENCY INTERPOLATION,0.7457983193277311,"5.1
Reconstruction as Frequency Interpolation
283"
RECONSTRUCTION AS FREQUENCY INTERPOLATION,0.7478991596638656,"As discussed before, we tackle the anomaly detection tasks in the self-supervised reconstructing
284"
RECONSTRUCTION AS FREQUENCY INTERPOLATION,0.75,"approach. Specifically, we make a N time down-sampling on the input and train a FITS network with
285"
RECONSTRUCTION AS FREQUENCY INTERPOLATION,0.7521008403361344,"an interpolation rate of ηRec = N to up-sample it.
286"
EXPERIMENT SETTINGS,0.7542016806722689,"5.2
Experiment Settings
287"
EXPERIMENT SETTINGS,0.7563025210084033,"Datasets. We use five commonly used benchmark datasets: SMD (Server Machine Dataset (Su et al.,
288"
EXPERIMENT SETTINGS,0.7584033613445378,"2019)), PSM (Polled Server Metrics (Abdulaal et al., 2021)), SWaT (Secure Water Treatment (Mathur
289"
EXPERIMENT SETTINGS,0.7605042016806722,"& Tippenhauer, 2016)), MSL (Mars Science Laboratory rover), and SMAP (Soil Moisture Active
290"
EXPERIMENT SETTINGS,0.7626050420168067,"Passive satellite) (Hundman et al., 2018).
291"
EXPERIMENT SETTINGS,0.7647058823529411,"Baselines. We compare FITS with models such as TimesNet (Wu et al., 2023), Anomaly Trans-
292"
EXPERIMENT SETTINGS,0.7668067226890757,"former (Xu et al., 2022), THOC (Shen et al., 2020), Omnianomaly (Su et al., 2019). Following
293"
EXPERIMENT SETTINGS,0.7689075630252101,"TimesNet (Wu et al., 2023), we also compare the anomaly detection performance with other mod-
294"
EXPERIMENT SETTINGS,0.7710084033613446,"els (Zeng et al., 2023; Zhang et al., 2022; Woo et al., 2022; Zhou et al., 2022a).
295"
EXPERIMENT SETTINGS,0.773109243697479,"Evaluation metrics. Following the previous works (Xu et al., 2022; Shen et al., 2020; Wu et al.,
296"
EXPERIMENT SETTINGS,0.7752100840336135,"2023), we use Precision, Recall, and F1-score as metrics.
297"
EXPERIMENT SETTINGS,0.7773109243697479,"Implementation details. We use a window size of 200 and downsample the time series segment by a
298"
EXPERIMENT SETTINGS,0.7794117647058824,"factor of 4 to match the original segment during training with the FITS model. Anomaly detection
299"
EXPERIMENT SETTINGS,0.7815126050420168,"follows the methodology of the Anomaly Transformer (Xu et al., 2022), where time points exceeding
300"
EXPERIMENT SETTINGS,0.7836134453781513,"a certain reconstruction loss threshold are classified as anomalies. The threshold is selected based
301"
EXPERIMENT SETTINGS,0.7857142857142857,"on the highest F1 score achieved on the validation set. To handle consecutive abnormal segments,
302"
EXPERIMENT SETTINGS,0.7878151260504201,"we adopt a widely-used adjustment strategy (Su et al., 2019; Xu et al., 2018; Shen et al., 2020),
303"
EXPERIMENT SETTINGS,0.7899159663865546,"considering all anomalies within a specific successive abnormal segment as correctly detected when
304"
EXPERIMENT SETTINGS,0.792016806722689,"one anomalous time point is identified. This approach aligns with real-world applications, where an
305"
EXPERIMENT SETTINGS,0.7941176470588235,"abnormal time point often triggers the attention to the entire segment.
306"
EXPERIMENT SETTINGS,0.7962184873949579,"Table 7: Anomaly detection result of F1-scores on 5 datasets. The best result is highlighted in bold,
and the second best is highlighted with underline. Full results are reported in the Appendix."
EXPERIMENT SETTINGS,0.7983193277310925,"Models
FITS
TimesNet
Anomaly
Transformer
THOC
Omni
Anomaly
Stationary
Transformer
LightTS
Dlinear
IMP"
EXPERIMENT SETTINGS,0.8004201680672269,"SMD
99.95
85.81
92.33
84.99
85.22
84.72
82.53
77.1
7.62
PSM
93.96
97.47
97.89
98.54
80.83
97.29
97.15
93.55
-3.93
SWaT
98.9
91.74
94.07
85.13
82.83
79.88
93.33
87.52
4.83
SMAP
70.74
71.52
96.69
90.68
86.92
71.09
69.21
69.26
-25.95
MSL
78.12
85.15
93.59
89.69
87.67
77.5
78.95
84.88
-15.47"
COMPARISONS WITH SOTAS,0.8025210084033614,"5.3
Comparisons with SOTAs
307"
COMPARISONS WITH SOTAS,0.8046218487394958,"As shown in Tab. 7, FITS achieves remarkable results on several datasets. Notably, on the SMD and
308"
COMPARISONS WITH SOTAS,0.8067226890756303,"SWaT datasets, FITS exhibits exceptional performance with F1-scores almost reaching perfection
309"
COMPARISONS WITH SOTAS,0.8088235294117647,"at around 99.95% and 98.9%, respectively. This demonstrates FITS’ ability to accurately detect
310"
COMPARISONS WITH SOTAS,0.8109243697478992,"anomalies and classify them correctly. In comparison, other models, such as TimesNet, Anomaly
311"
COMPARISONS WITH SOTAS,0.8130252100840336,"Transformer, and Stationary Transformer, struggle to match FITS’ performance on these datasets.
312"
COMPARISONS WITH SOTAS,0.8151260504201681,"However, FITS shows comparatively lower performance on the SMAP and MSL datasets. These
313"
COMPARISONS WITH SOTAS,0.8172268907563025,"datasets present a challenge due to their binary event data nature, which may not be effectively
314"
COMPARISONS WITH SOTAS,0.819327731092437,"captured by FITS’ frequency domain representation. While models specifically designed for anomaly
315"
COMPARISONS WITH SOTAS,0.8214285714285714,"detection, such as THOC and Omni Anomaly, achieve higher F1-scores on these datasets.
316"
COMPARISONS WITH SOTAS,0.8235294117647058,"For a more comprehensive evaluation, waveform visualizations and detailed analysis can be found
317"
COMPARISONS WITH SOTAS,0.8256302521008403,"in the appendix, providing deeper insights into FITS’ strengths and limitations in different anomaly
318"
COMPARISONS WITH SOTAS,0.8277310924369747,"detection scenarios. It is important to note that the reported results are achieved with a parameter
319"
COMPARISONS WITH SOTAS,0.8298319327731093,"range of 1-4K and MACs (Multiply-Accumulate Operations) of 10-137K, which will be further
320"
COMPARISONS WITH SOTAS,0.8319327731092437,"detailed in the appendix.
321"
CONCLUSIONS AND DISCUSSION,0.8340336134453782,"6
Conclusions and Discussion
322"
CONCLUSIONS AND DISCUSSION,0.8361344537815126,"In this paper, we propose FITS for time series analysis, a low-cost model with 10k parameters that can
323"
CONCLUSIONS AND DISCUSSION,0.8382352941176471,"achieve performance comparable to state-of-the-art models that are often several orders of magnitude
324"
CONCLUSIONS AND DISCUSSION,0.8403361344537815,"larger. As a frequency-domain modeling technique, FITS has difficulty handling binary-valued time
325"
CONCLUSIONS AND DISCUSSION,0.842436974789916,"series and time series with missing data. For the former category, time-domain modeling is preferable
326"
CONCLUSIONS AND DISCUSSION,0.8445378151260504,"as the raw data format is sufficiently compact. For the latter category, we could first employ simple
327"
CONCLUSIONS AND DISCUSSION,0.8466386554621849,"yet effective time-domain imputation techniques and then apply FITS for efficient analysis.
328"
REFERENCES,0.8487394957983193,"References
329"
REFERENCES,0.8508403361344538,"Ahmed Abdulaal, Zhuanghua Liu, and Tomer Lancewicki. Practical approach to asynchronous
330"
REFERENCES,0.8529411764705882,"multivariate time series anomaly detection and localization. In Proceedings of the 27th ACM
331"
REFERENCES,0.8550420168067226,"SIGKDD Conference on Knowledge Discovery; Data Mining, KDD ’21, pp. 2485–2494, New
332"
REFERENCES,0.8571428571428571,"York, NY, USA, 2021. Association for Computing Machinery. ISBN 9781450383325. doi:
333"
REFERENCES,0.8592436974789915,"10.1145/3447548.3467174. URL https://doi.org/10.1145/3447548.3467174.
334"
REFERENCES,0.8613445378151261,"E. O. Brigham and R. E. Morrow. The fast fourier transform. IEEE Spectrum, 4(12):63–70, 1967.
335"
REFERENCES,0.8634453781512605,"doi: 10.1109/MSPEC.1967.5217220.
336"
REFERENCES,0.865546218487395,"Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, and Tom Soder-
337"
REFERENCES,0.8676470588235294,"strom. Detecting spacecraft anomalies using LSTMs and nonparametric dynamic threshold-
338"
REFERENCES,0.8697478991596639,"ing. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Dis-
339"
REFERENCES,0.8718487394957983,"covery &amp Data Mining. ACM, jul 2018. doi: 10.1145/3219819.3219845. URL https:
340"
REFERENCES,0.8739495798319328,"//doi.org/10.11452F3219819.3219845.
341"
REFERENCES,0.8760504201680672,"Taesung Kim, Jinhee Kim, Yunwon Tae, Cheonbok Park, Jang-Ho Choi, and Jaegul Choo. Re-
342"
REFERENCES,0.8781512605042017,"versible instance normalization for accurate time-series forecasting against distribution shift. In
343"
REFERENCES,0.8802521008403361,"International Conference on Learning Representations, 2022. URL https://openreview.net/
344"
REFERENCES,0.8823529411764706,"forum?id=cGDAkQo1C0p.
345"
REFERENCES,0.884453781512605,"James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, and Santiago Ontanon. Fnet: Mixing tokens with
346"
REFERENCES,0.8865546218487395,"fourier transforms, 2022.
347"
REFERENCES,0.8886554621848739,"Minhao Liu, Ailing Zeng, Muxi Chen, Zhijian Xu, Qiuxia Lai, Lingna Ma, and Qiang Xu. Scinet:
348"
REFERENCES,0.8907563025210085,"Time series modeling and forecasting with sample convolution and interaction. In Advances in
349"
REFERENCES,0.8928571428571429,"Neural Information Processing Systems, 2022.
350"
REFERENCES,0.8949579831932774,"Aditya P. Mathur and Nils Ole Tippenhauer. Swat: a water treatment testbed for research and training
351"
REFERENCES,0.8970588235294118,"on ics security. In 2016 International Workshop on Cyber-physical Systems for Smart Water
352"
REFERENCES,0.8991596638655462,"Networks (CySWater), pp. 31–36, 2016. doi: 10.1109/CySWater.2016.7469060.
353"
REFERENCES,0.9012605042016807,"Yuqi Nie, Nam H. Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. A time series is worth
354"
REFERENCES,0.9033613445378151,"64 words: Long-term forecasting with transformers. In International Conference on Learning
355"
REFERENCES,0.9054621848739496,"Representations, 2023.
356"
REFERENCES,0.907563025210084,"Lifeng Shen, Zhuocong Li, and James Kwok. Timeseries anomaly detection using temporal hier-
357"
REFERENCES,0.9096638655462185,"archical one-class network. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin
358"
REFERENCES,0.9117647058823529,"(eds.), Advances in Neural Information Processing Systems, volume 33, pp. 13016–13026. Cur-
359"
REFERENCES,0.9138655462184874,"ran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper_files/paper/
360"
REFERENCES,0.9159663865546218,"2020/file/97e401a02082021fd24957f852e0e475-Paper.pdf.
361"
REFERENCES,0.9180672268907563,"Ya Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, and Dan Pei. Robust anomaly detection
362"
REFERENCES,0.9201680672268907,"for multivariate time series through stochastic recurrent neural network. In Proceedings of the
363"
REFERENCES,0.9222689075630253,"25th ACM SIGKDD International Conference on Knowledge Discovery; Data Mining, KDD
364"
REFERENCES,0.9243697478991597,"’19, pp. 2828–2837, New York, NY, USA, 2019. Association for Computing Machinery. ISBN
365"
REFERENCES,0.9264705882352942,"9781450362016. doi: 10.1145/3292500.3330672. URL https://doi.org/10.1145/3292500.
366"
REFERENCES,0.9285714285714286,"3330672.
367"
REFERENCES,0.930672268907563,"Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, and Steven Hoi. Etsformer: Exponential
368"
REFERENCES,0.9327731092436975,"smoothing transformers for time-series forecasting, 2022.
369"
REFERENCES,0.9348739495798319,"Haixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. Autoformer: Decomposition transformers
370"
REFERENCES,0.9369747899159664,"with auto-correlation for long-term series forecasting. Advances in Neural Information Processing
371"
REFERENCES,0.9390756302521008,"Systems, 34:22419–22430, 2021.
372"
REFERENCES,0.9411764705882353,"Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, and Mingsheng Long. Timesnet:
373"
REFERENCES,0.9432773109243697,"Temporal 2d-variation modeling for general time series analysis. In International Conference on
374"
REFERENCES,0.9453781512605042,"Learning Representations, 2023.
375"
REFERENCES,0.9474789915966386,"Haowen Xu, Yang Feng, Jie Chen, Zhaogang Wang, Honglin Qiao, Wenxiao Chen, Nengwen Zhao,
376"
REFERENCES,0.9495798319327731,"Zeyan Li, Jiahao Bu, Zhihan Li, Ying Liu, Youjian Zhao, and Dan Pei. Unsupervised anomaly
377"
REFERENCES,0.9516806722689075,"detection via variational auto-encoder for seasonal KPIs in web applications. In Proceedings of
378"
REFERENCES,0.9537815126050421,"the 2018 World Wide Web Conference on World Wide Web - WWW '18. ACM Press, 2018. doi:
379"
REFERENCES,0.9558823529411765,"10.1145/3178876.3185996. URL https://doi.org/10.1145/2F3178876.3185996.
380"
REFERENCES,0.957983193277311,"Jiehui Xu, Haixu Wu, Jianmin Wang, and Mingsheng Long. Anomaly transformer: Time series
381"
REFERENCES,0.9600840336134454,"anomaly detection with association discrepancy, 2022.
382"
REFERENCES,0.9621848739495799,"Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. Are transformers effective for time series
383"
REFERENCES,0.9642857142857143,"forecasting? arXiv preprint arXiv:2205.13504, 2022.
384"
REFERENCES,0.9663865546218487,"Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. Are transformers effective for time series
385"
REFERENCES,0.9684873949579832,"forecasting? 2023.
386"
REFERENCES,0.9705882352941176,"Tianping Zhang, Yizhuo Zhang, Wei Cao, Jiang Bian, Xiaohan Yi, Shun Zheng, and Jian Li. Less is
387"
REFERENCES,0.9726890756302521,"more: Fast multivariate time series forecasting with light sampling-oriented mlp structures. arXiv
388"
REFERENCES,0.9747899159663865,"preprint arXiv:2207.01186, 2022.
389"
REFERENCES,0.976890756302521,"Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.
390"
REFERENCES,0.9789915966386554,"Informer: Beyond efficient transformer for long sequence time-series forecasting. In Proceedings
391"
REFERENCES,0.9810924369747899,"of the AAAI Conference on Artificial Intelligence, volume 35, pp. 11106–11115, 2021.
392"
REFERENCES,0.9831932773109243,"Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin. Fedformer: Frequency
393"
REFERENCES,0.9852941176470589,"enhanced decomposed transformer for long-term series forecasting. In International Conference
394"
REFERENCES,0.9873949579831933,"on Machine Learning, 2022a.
395"
REFERENCES,0.9894957983193278,"Tian Zhou, Ziqing Ma, xue wang, Qingsong Wen, Liang Sun, Tao Yao, Wotao Yin, and Rong
396"
REFERENCES,0.9915966386554622,"Jin. FiLM: Frequency improved legendre memory model for long-term time series forecasting.
397"
REFERENCES,0.9936974789915967,"In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in
398"
REFERENCES,0.9957983193277311,"Neural Information Processing Systems, 2022b. URL https://openreview.net/forum?id=
399"
REFERENCES,0.9978991596638656,"zTQdHSQUQWc.
400"
