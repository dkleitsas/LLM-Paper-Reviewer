Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0005219206680584551,"Federatedd learning (FL) aims to minimize the communication complexity of
training a model over heterogeneous data distributed across many clients. A
common approach is local update methods, where clients take multiple optimization
steps over local data before communicating with the server (e.g., FedAvg). Local
update methods can exploit similarity between clients’ data. However, in existing
analyses, this comes at the cost of slow convergence in terms of the dependence
on the number of communication rounds R. On the other hand, global update
methods, where clients simply return a gradient vector in each round (e.g., SGD),
converge faster in terms of R but fail to exploit the similarity between clients even
when clients are homogeneous. We propose FedChain, an algorithmic framework
that combines the strengths of local update methods and global update methods to
achieve fast convergence in terms of R while leveraging the similarity between
clients. Using FedChain, we instantiate algorithms that improve upon previously
known rates in the general convex and PL settings, and are near-optimal (via an
algorithm-independent lower bound that we show) for problems that satisfy strong
convexity. Empirical results support this theoretical gain over existing methods."
INTRODUCTION,0.0010438413361169101,"1
INTRODUCTION"
INTRODUCTION,0.0015657620041753654,"In federated learning (FL) (McMahan et al., 2017; Kairouz et al., 2019; Li et al., 2020), distributed
clients interact with a central server to jointly train a single model without directly sharing their data
with the server. The training objective is to solve the following minimization problem: min
x"
INTRODUCTION,0.0020876826722338203,"h
F(x) = 1 N N
X"
INTRODUCTION,0.0026096033402922755,"i=1
Fi(x)
i
(1)"
INTRODUCTION,0.003131524008350731,"where variable x is the model parameter, i indexes the clients (or devices), N is the number of
clients, and Fi(x) is a loss that only depends on that client’s data. Typical FL deployments have two
properties that make optimizing Eq. (1) challenging: (i) Data heterogeneity: We want to minimize
the average of the expected losses Fi(x) = Ezi∼Di[f(x; zi)] for some loss function f evaluated on
client data zi drawn from a client-speciﬁc distribution Di. The convergence rate of the optimization
depends on the heterogeneity of the local data distributions, {Di}N
i=1, and this dependence is captured
by a popular notion of client heterogeneity, ζ2, deﬁned as follows:"
INTRODUCTION,0.0036534446764091857,"ζ2 := max
i∈[N] sup
x ∥∇F(x) −∇Fi(x)∥2 .
(2)"
INTRODUCTION,0.0041753653444676405,Published as a conference paper at ICLR 2022
INTRODUCTION,0.004697286012526096,"This captures the maximum difference between a local gradient and the global gradient, and is a
standard measure of heterogeneity used in the literature (Woodworth et al., 2020a; Gorbunov et al.,
2020; Deng et al., 2020; Woodworth et al., 2020a; Gorbunov et al., 2020; Yuan et al., 2020; Deng et al.,
2021; Deng & Mahdavi, 2021). (ii) Communication cost: In many FL deployments, communication
is costly because clients have limited bandwidths. Due to these two challenges, most federated
optimization algorithms alternate between local rounds of computation, where each client locally
processes only their own data to save communication, and global rounds, where clients synchronize
with the central server to resolve disagreements due to heterogeneity in the locally updated models."
INTRODUCTION,0.005219206680584551,"Several federated algorithms navigate this trade-off between reducing communication and resolving
data heterogeneity by modifying the amount and nature of local and global computation (McMahan
et al., 2017; Li et al., 2018; Wang et al., 2019b;a; Li et al., 2019; Karimireddy et al., 2020b;a;
Al-Shedivat et al., 2020; Reddi et al., 2020; Charles & Koneˇcn`y, 2020; Mitra et al., 2021; Woodworth
et al., 2020a). These ﬁrst-order federated optimization algorithms largely fall into one of two camps:
(i) clients in local update methods send updated models after performing multiple steps of model
updates, and (ii) clients in global update methods send gradients and do not perform any model
updates locally. Examples of (i) include FedAvg (McMahan et al., 2017), SCAFFOLD (Karimireddy
et al., 2020b), and FedProx (Li et al., 2018). Examples of (ii) include SGD and Accelerated SGD
(ASG), where in each round r the server collects from the clients gradients evaluated on local data at
the current iterate x(r) and then performs a (possibly Nesterov-accelerated) model update."
INTRODUCTION,0.005741127348643006,"As an illustrating example, consider the scenario when Fi’s are µ-strongly convex and β-smooth such
that the condition number is κ = β/µ as summarized in Table 1, and also assume for simplicity that
all clients participate in each communication round (i.e., full participation). Existing convergence
analyses show that local update methods have a favorable dependence on the heterogeneity ζ. For
example, Woodworth et al. (2020a) show that FedAvg achieves an error bound of ˜O((κζ2/µ)R−2)
after R rounds of communication. Hence FedAvg achieves theoretically faster convergence for
smaller heterogeneity levels ζ by using local updates. However, this favorable dependency on ζ
comes at the cost of slow convergence in R. On the other hand, global update methods converge
faster in R, with error rate decaying as ˜O(∆exp(−R/√κ)) (for the case of ASG), where ∆is the
initial function value gap to the (unique) optimal solution. This is an exponentially faster rate in R,
but it does not take advantage of small heterogeneity even when client data is fully homogeneous."
INTRODUCTION,0.006263048016701462,"Our main contribution is to design a novel family of algorithms that combines the strengths of local
and global methods to achieve a faster convergence while maintaining the favorable dependence on
the heterogeneity, thus achieving an error rate of ˜O((ζ2/µ) exp(−R/√κ)) in the strongly convex
scenario. By adaptively switching between this novel algorithm and the existing best global method,
we can achieve an error rate of ˜O(min{∆, ζ2/µ} exp(−R/√κ)). We further show that this is near-
optimal by providing a matching lower bound in Thm. 5.4. This lower bound tightens an existing
one from (Woodworth et al., 2020a) by considering a smaller class of algorithms that includes those
presented in this paper."
INTRODUCTION,0.006784968684759917,"We propose FedChain, a unifying chaining framework for federated optimization that enjoys the
beneﬁts of both local update methods and global update methods. For a given total number of rounds
R, FedChain ﬁrst uses a local-update method for a constant fraction of rounds and then switches
to a global-update method for the remaining rounds. The ﬁrst phase exploits client homogeneity
when possible, providing fast convergence when heterogeneity is small. The second phase uses the
unbiased stochastic gradients of global update methods to achieve a faster convergence rate in the
heterogeneous setting. The second phase inherits the beneﬁts of the ﬁrst phase through the iterate
output by the local-update method. An instantiation of FedChain consists of a combination of a
speciﬁc local-update method and global-update method (e.g., FedAvg →SGD)."
INTRODUCTION,0.007306889352818371,"Contributions. We propose the FedChain framework and analyze various instantiations under
strongly convex, general convex, and nonconvex objectives that satisfy the PL condition.1 Achievable
rates are summarized in Tables 1, 2 and 4. In the strongly convex setting, these rates nearly match the
algorithm-independent lower bounds we introduce in Theorem 5.4, which shows the near-optimality of
FedChain. For strongly convex functions, chaining is optimal up to a factor that decays exponentially
in the condition number κ. For convex functions, it is optimal in the high-heterogeneity regime, when"
INTRODUCTION,0.007828810020876827,1F satisﬁes the µ-PL condition if 2µ(F(x) −F(x∗)) ≤∥∇F(x)∥2.
INTRODUCTION,0.008350730688935281,Published as a conference paper at ICLR 2022
INTRODUCTION,0.008872651356993737,Algorithm 1 Federated Chaining (FedChain)
INTRODUCTION,0.009394572025052192,"Input: Alocal local update algorithm, Aglobal centralized algorithm, initial point ˆx0, K, rounds R
▷Run Alocal for R/2 rounds"
INTRODUCTION,0.009916492693110648,"ˆx1/2 ←Alocal(ˆx0)
▷Choose the better point between ˆx0 and ˆx1/2
Sample S clients S ⊆[N]
Draw ˆzi,k ∼Di, i ∈S, k ∈{0, . . . , K −1}"
INTRODUCTION,0.010438413361169102,"ˆx1 ←arg minx∈{ˆx0,ˆx1/2}
1
SK
P
i∈S
PK−1
k=0 f(x; ˆzi,k)
▷Finish convergence with Aglobal for R/2 rounds"
INTRODUCTION,0.010960334029227558,"ˆx2 ←Aglobal(ˆx1)
Return ˆx2"
INTRODUCTION,0.011482254697286013,"ζ > βDR1/2. For nonconvex PL functions, it is optimal for constant condition number κ. In all
three settings, FedChain instantiations improve upon previously known worst-case rates in certain
regimes of ζ. We further demonstrate the empirical gains of our chaining framework in the convex
case (logistic regression on MNIST) and in the nonconvex case (ConvNet classiﬁcation on EMNIST
(Cohen et al., 2017) and ResNet-18 classiﬁcation on CIFAR-100 (Krizhevsky, 2009))."
RELATED WORK,0.012004175365344467,"1.1
RELATED WORK"
RELATED WORK,0.012526096033402923,"The convergence of FedAvg in convex optimization has been the subject of much interest in the
machine learning community, particularly as federated learning (Kairouz et al., 2019) has increased in
popularity. The convergence of FedAvg for convex minimization was ﬁrst studied in the homogeneous
client setting (Stich, 2018; Wang & Joshi, 2018; Woodworth et al., 2020b). These rates were
later extended to the heterogeneous client setting (Khaled et al., 2020; Karimireddy et al., 2020b;
Woodworth et al., 2020a; Koloskova et al., 2020), including a lower bound (Woodworth et al., 2020a).
The only current known analysis for FedAvg that shows that FedAvg can improve on SGD/ASG
in the heterogeneous data case is that of Woodworth et al. (2020a), which has been used to prove
slightly tighter bounds in subsequent work Gorbunov et al. (2020)."
RELATED WORK,0.013048016701461378,"Many new federated optimization algorithms have been proposed to improve on FedAvg and
SGD/ASG, such as SCAFFOLD (Karimireddy et al., 2020b), S-Local-SVRG (Gorbunov et al.,
2020), FedAdam (Reddi et al., 2020), FedLin (Mitra et al., 2021), FedProx (Li et al., 2018). However,
under full participation (where all clients participate in a communication round; otherwise the setting
is partial participation) existing analyses for these algorithms have not demonstrated any improve-
ment over SGD (under partial participation, SAGA (Defazio et al., 2014)). In the smooth nonconvex
full participation setting, MimeMVR (Karimireddy et al., 2020a) was recently proposed, which
improves over SGD in the low-heterogeneity setting. Currently MimeMVR and SGD are the two best
algorithms for worst-case smooth nonconvex optimization with respect to communication efﬁciency,
depending on client heterogeneity. In partial participation, MimeMVR and SAGA are the two best
algorithms for worst-case smooth nonconvex optimization, depending on client heterogeneity."
RELATED WORK,0.013569937369519834,"Lin et al. (2018) proposed a scheme, post-local SGD, opposite ours by switching from a global-
update method to a local-update method (as opposed to our proposal of switching from local-update
method to global-update method). They evaluate the setting where ζ = 0. The authors found that
while post-local SGD has a training accuracy worse than SGD, the test accuracy can be better (an
improvement of 1% test accuracy on ResNet-20 CIFAR-10 classiﬁcation), though theoretical analysis
was not provided. Wang & Joshi (2019) decrease the number (K) of local updates to transition from
FedAvg to SGD in the homogeneous setting. This is conceptually similar to FedChain, but they do
not show order-wise convergence rate improvements. Indeed, in the homogeneous setting, a simple
variant of ASG achieves the optimal worst-case convergence rate (Woodworth et al., 2021)."
SETTING,0.014091858037578288,"2
SETTING"
SETTING,0.014613778705636743,"Federated optimization proceeds in rounds. We consider the partial participation setting, where at the
beginning of each round, S ∈Z+ out of total N clients are sampled uniformly at random without"
SETTING,0.015135699373695199,Published as a conference paper at ICLR 2022
SETTING,0.015657620041753653,"replacement. Between each global communication round, the sampled clients each access either (i)
their own stochastic gradient oracle K times, update their local models, and return the updated model,
or (ii) their own stochastic function value oracle K times and return the average value to the server.
The server aggregates the received information and performs a model update. For each baseline
optimization algorithm, we analyze the sub-optimality error after R rounds of communication between
the clients and the server. Suboptimality is measured in terms of the function value EF(ˆx) −F(x∗),
where ˆx is the solution estimate after R rounds and x∗= arg minx F(x) is a (possibly non-unique)
optimum of F. We let the estimate for the initial suboptimality gap be ∆(Assumption B.9), and the
initial distance to a (not necessarily unique) optimum be D (Assumption B.10). If applicable, ϵ is the
target expected function value suboptimality."
SETTING,0.016179540709812108,"We study three settings: strongly convex Fi’s, convex Fi’s and µ-PL F; for formal deﬁnitions, refer
to App. B. Throughout this paper, we assume that the Fi’s are β-smooth (Assumption B.4). If Fi’s
are µ-strongly convex (Assumption B.1) or F is µ-PL (Assumption B.3), we denote κ = β/µ as the
condition number. Di is the data distribution of client i. We deﬁne the heterogeneity of the problem
as ζ2 := maxi∈[N] supx ∥∇F(x) −∇Fi(x)∥2 in Assumption B.5. We assume unless otherwise
speciﬁed that ζ2 > 0, i.e., that the problem is heterogeneous. We assume that the client gradient
variance is upper bounded by σ2 (Assumption B.6). We also deﬁne the analogous quantities for
function value oracle queries: ζ2
F Assumption B.8, σ2
F Assumption B.7. We use the notation ˜O, ˜Ωto
hide polylogarithmic factors, and O, Ωif we are only hiding constant factors."
SETTING,0.016701461377870562,"3
FEDERATED CHAINING (FEDCHAIN) FRAMEWORK"
SETTING,0.01722338204592902,"Figure 1: A toy example illustrating FedChain. We
have two client objectives: F1(x) and F2(x). F(x)
is their average. The top plot displays the objec-
tives and the bottom plot displays the gradients. In
regions where client gradients agree in direction,
i.e. (−∞, −1] ∪[1, ∞) it may be better to use an
algorithm with local steps (like FedAvg), and in
the region where the gradient disagree in direction,
i.e. (−1, 1) it may be better to use an algorithm
without local steps (like SGD)."
SETTING,0.017745302713987474,"We start with a toy example (Fig. 1) to illus-
trate FedChain.
Consider two strongly con-
vex client objectives: F1(x) = (1/2)(x −1)2
and F2(x) = (x + 1)2. The global objective
F(x) = (F1(x) + F2(x))/2 is their average.
Fig. 1 (top) plots the objectives, and Fig. 1 (bot-
tom) displays their gradients. Far from the op-
timum, due to strong convexity, all client gradi-
ents point towards the optimal solution; speciﬁ-
cally, this occurs when x ∈(−∞, −1]∪[1, ∞).
In this regime, clients can use local steps (e.g.,
FedAvg) to reduce communication without sacri-
ﬁcing the consistency of per-client local updates.
On the other hand, close to the optimum, i.e.,
when x ∈(−1, 1), some client gradients may
point away from the optimum. This suggests
that clients should not take local steps to avoid
driving the global estimate away from the op-
timum. Therefore, when we are close to the
optimum, we use an algorithm without local
steps (e.g. SGD), which is less affected by client
gradient disagreement."
SETTING,0.01826722338204593,"This intuition seems to carry over to the non-
convex setting: Charles et al. (2021) show that
over the course of FedAvg execution on neural
network StackOverﬂow next word prediction,
client gradients become more orthogonal."
SETTING,0.018789144050104383,"FedChain: To exploit the strengths of both local
and global update methods, we propose the fed-
erated chaining (FedChain) framework in Alg. 1.
There are three steps: (1) Run a local-update
method Alocal, like FedAvg. (2) Choose the bet-
ter point between the output of Alocal (which we denote ˆx1/2), and the initial point ˆx0 to initialize (3)
a global-update method Aglobal like SGD. Note that when heterogeneity is large, Alocal can actually"
SETTING,0.019311064718162838,Published as a conference paper at ICLR 2022
SETTING,0.019832985386221295,Table 1: Rates for the strongly convex case. ♣Rate requires R ≥N/S. ♠Rate requires S = N.
SETTING,0.02035490605427975,"Method/Analysis
EF(ˆx) −F(x∗) ≤˜O(·)"
SETTING,0.020876826722338204,Centralized Algorithms SGD ASG
SETTING,0.02139874739039666,∆exp(−κ−1R) + (1 −S
SETTING,0.021920668058455117,N ) ζ2
SETTING,0.02244258872651357,"µSR
∆exp(−κ−1"
SETTING,0.022964509394572025,2 R) + (1 −S
SETTING,0.02348643006263048,N ) ζ2
SETTING,0.024008350730688934,"µSR
Federated Algorithms"
SETTING,0.024530271398747392,"FedAvg (Karimireddy et al., 2020b)"
SETTING,0.025052192066805846,"FedAvg (Woodworth et al., 2020a)"
SETTING,0.0255741127348643,"SCAFFOLD (Karimireddy et al., 2020b)"
SETTING,0.026096033402922755,∆exp(−κ−1R) + κ( ζ2
SETTING,0.02661795407098121,µ )R−2 κ( ζ2
SETTING,0.027139874739039668,µ )R−2♠
SETTING,0.027661795407098122,"∆exp(−min{κ−1, S"
SETTING,0.028183716075156576,N }R)♣
SETTING,0.02870563674321503,This paper
SETTING,0.029227557411273485,FedAvg →SGD (Thm. 4.1)
SETTING,0.029749478079331943,FedAvg →SAGA (Thm. 4.3)
SETTING,0.030271398747390398,FedAvg →ASG (Thm. 4.2)
SETTING,0.030793319415448852,FedAvg →SSNM (Thm. 4.4)
SETTING,0.031315240083507306,Algo.-independent LB (Thm. 5.4)
SETTING,0.031837160751565764,"min{∆, ζ2"
SETTING,0.032359081419624215,µ } exp(−κ−1R) + (1 −S
SETTING,0.03288100208768267,N ) ζ2
SETTING,0.033402922755741124,"µSR
min{∆, ζ2"
SETTING,0.03392484342379958,"µ } exp(−min{κ−1, S"
SETTING,0.03444676409185804,N }R)♣
SETTING,0.03496868475991649,"min{∆, ζ2"
SETTING,0.03549060542797495,µ } exp(−κ−1
SETTING,0.0360125260960334,2 R) + (1 −S
SETTING,0.03653444676409186,N ) ζ2
SETTING,0.037056367432150315,"µSR
κ min{∆, ζ2"
SETTING,0.037578288100208766,"µ } exp(−min{
q"
SETTING,0.038100208768267224,"S
Nκ, S"
SETTING,0.038622129436325675,N }R)♣
SETTING,0.03914405010438413,"min{∆, κ−3"
SETTING,0.03966597077244259,2 ( ζ2
SETTING,0.04018789144050104,β )} exp(−κ−1 2 R)
SETTING,0.0407098121085595,"output an iterate with higher suboptimality gap than ˆx0. Hence, selecting the point (between ˆx0
and ˆx1/2) with a smaller F allows us to adapt to the problem’s heterogeneity, and initialize Aglobal
appropriately to achieve good convergence rates. To compare ˆx1/2 and the initial point ˆx0, we
approximate F(ˆx0) and F(ˆx1/2) by averaging; we compute
1
SK
P"
SETTING,0.04123173277661795,"i∈S,k∈[K] f(x; ˆzi,k) for ˆx1/2, ˆx0,
where K is also the number of local steps per client per round in Alocal, and S is a sample of S
clients. In practice, one might consider adaptively selecting how many rounds of Alocal to run, which
can potentially improve the convergence by a constant factor. Our experiments in App. J.1 show
signiﬁcant improvement when using only 1 round of Alocal with a large enough K for convex losses."
CONVERGENCE OF FEDCHAIN,0.04175365344467641,"4
CONVERGENCE OF FEDCHAIN"
CONVERGENCE OF FEDCHAIN,0.042275574112734866,"We ﬁrst analyze FedChain (Algo. 1) when Alocal is FedAvg and Aglobal is (Nesterov accelerated) SGD.
The ﬁrst theorem is without Nesterov acceleration and the second with Nesterov acceleration."
CONVERGENCE OF FEDCHAIN,0.04279749478079332,"Theorem 4.1 (FedAvg →SGD). Suppose that client objectives Fi’s and their gradient queries
satisfy Assumptions B.4, B.5, B.6, B.7 and B.8. Then running FedChain (Algo. 1) with Alocal as
FedAvg (Algo. 4) with the parameter choices of Thm. E.1, and Aglobal as SGD (Algo. 2) with the
parameter choices of Thm. D.1, we get the following rates 2:"
CONVERGENCE OF FEDCHAIN,0.043319415448851775,"• Strongly convex: If Fi’s satisfy Assumption B.1 for some µ > 0 then there exists a ﬁ-
nite K above which we get, EF(ˆx2) −F(x∗) ≤˜O(min{∆, ζ2/µ} exp(−R/κ) + (1 −
S/N)ζ2/(µSR)) ."
CONVERGENCE OF FEDCHAIN,0.04384133611691023,"• General convex:
If Fi’s satisfy Assumption B.2, then there exists a ﬁnite K
above which we get the rate EF(ˆx2) −F(x∗) ≤
˜O(min{βD2/R,
p"
CONVERGENCE OF FEDCHAIN,0.044363256784968684,"βζD3/
√"
CONVERGENCE OF FEDCHAIN,0.04488517745302714,"R} +
( 4p"
CONVERGENCE OF FEDCHAIN,0.04540709812108559,"1 −S/N)(
p"
CONVERGENCE OF FEDCHAIN,0.04592901878914405,"βζD3/
4√"
CONVERGENCE OF FEDCHAIN,0.04645093945720251,SR)) .
CONVERGENCE OF FEDCHAIN,0.04697286012526096,"• PL condition: If Fi’s satisfy Assumption B.3 for µ > 0, then there exists a ﬁnite K above
which we get the rate the rate EF(ˆx2) −F(x∗) ≤˜O(min{∆, ζ2/µ} exp(−R/κ) + (1 −
S/N)(κζ2/µSR)) ."
CONVERGENCE OF FEDCHAIN,0.04749478079331942,"2We ignore variance terms and ζ2
F = maxi∈[N] supx(Fi(x) −F(x))2 as the former can be made negligible
by increasing K and the latter can be made zero by running the better of FedAvg →SGD and SGD instead of
choosing the better of ˆx1/2 and ˆx0 as in Algo. 1. Furthermore, ζ2
F terms are similar to the ζ2 terms. The rest of
the theorems in the main paper will also be stated this way. To see the formal statements, see App. F."
CONVERGENCE OF FEDCHAIN,0.04801670146137787,Published as a conference paper at ICLR 2022
CONVERGENCE OF FEDCHAIN,0.048538622129436326,Table 2: Rates for the general convex case. ♣Rate requires R ≥N
CONVERGENCE OF FEDCHAIN,0.049060542797494784,"S . ♠Rate requires S = N. ♦
Analysis from Karimireddy et al. (2020b)."
CONVERGENCE OF FEDCHAIN,0.049582463465553235,"Method/Analysis
EF(ˆx) −F(x∗) ≤˜O(·)"
CONVERGENCE OF FEDCHAIN,0.05010438413361169,"Centralized Algorithms SGD ASG βD2 R
+
q 1 −S"
CONVERGENCE OF FEDCHAIN,0.050626304801670144,"N
ζD
√"
CONVERGENCE OF FEDCHAIN,0.0511482254697286,"SR
βD2"
CONVERGENCE OF FEDCHAIN,0.05167014613778706,"R2 +
q 1 −S"
CONVERGENCE OF FEDCHAIN,0.05219206680584551,"N
ζD
√"
CONVERGENCE OF FEDCHAIN,0.05271398747390397,"SR
Federated Algorithms"
CONVERGENCE OF FEDCHAIN,0.05323590814196242,FedAvg♦
CONVERGENCE OF FEDCHAIN,0.05375782881002088,"FedAvg (Woodworth et al., 2020a)"
CONVERGENCE OF FEDCHAIN,0.054279749478079335,SCAFFOLD♦ βD2
CONVERGENCE OF FEDCHAIN,0.054801670146137786,"R
+
3q βζ2D4"
CONVERGENCE OF FEDCHAIN,0.055323590814196244,"R2
+
q 1 −S"
CONVERGENCE OF FEDCHAIN,0.055845511482254695,"N
ζD
√ SR"
Q,0.05636743215031315,"3q βζ2D4 R2
q N S
βD2 R
♣"
Q,0.05688935281837161,This paper
Q,0.05741127348643006,FedAvg →SGD (Thm. 4.1)
Q,0.05793319415448852,FedAvg →ASG (Thm. 4.2)
Q,0.05845511482254697,Algo.-independent LB (Thm. 5.4)
Q,0.05897703549060543,"min{ βD2 R ,
√"
Q,0.059498956158663886,"βζD3
√"
Q,0.06002087682672234,"R
} +
4q 1 −S N √ βζD3 4√"
Q,0.060542797494780795,"SR
min{ βD2"
Q,0.061064718162839246,"R2 ,
√ βζD3"
Q,0.061586638830897704,"R
} +
4q 1 −S N √ βζD3 4√"
Q,0.06210855949895616,"SR
+
q 1 −S"
Q,0.06263048016701461,"N
ζD
√"
Q,0.06315240083507306,"SR
min{ βD2"
Q,0.06367432150313153,"R2 ,
ζD
√ R5 }"
Q,0.06419624217118998,"For the formal statement, see Thm. F.1."
Q,0.06471816283924843,"Theorem 4.2 (FedAvg →ASG). Under the hypotheses of Thm. 4.1 with a choice of Aglobal as ASG
(Algo. 3) and the parameter choices of Thm. D.3, we get the following guarantees:"
Q,0.0652400835073069,"• Strongly convex: If Fi’s satisfy Assumption B.1 for µ > 0 then there exists a ﬁnite K
above which we get the rate, EF(ˆx2) −F(x∗) ≤˜O(min{∆, ζ2/µ} exp(−R/√κ) + (1 −
S/N)ζ2/µSR)."
Q,0.06576200417536535,"• General convex:
If Fi’s satisfy Assumption B.2 then there exists a ﬁnite K
above which we get the rate, EF(ˆx2) −F(x∗) ≤
˜O(min{βD2/R2,
p"
Q,0.0662839248434238,"βζD3/R} +
p"
Q,0.06680584551148225,"1 −S/N(ζD/
√"
Q,0.06732776617954071,"SR) +
4p"
Q,0.06784968684759916,"1 −S/N(
p"
Q,0.06837160751565761,"βζD3/
4√"
Q,0.06889352818371608,SR) ).
Q,0.06941544885177453,"For the formal statement, see Thm. F.2. We show and discuss the near-optimality of FedAvg →
ASG under strongly convex and PL conditions (and under full participation) in Section 5, where
we introduce matching lower bounds. Under strong-convexity shown in Table 1, FedAvg →ASG,
when compared to ASG, converts the ∆exp(−R/√κ) term into a min{∆, ζ2/µ} exp(−R/√κ)
term, improving over ASG when heterogeneity moderately small: ζ2/µ < ∆. It also signiﬁcantly
improves over FedAvg, as min{∆, ζ2/µ} exp(−R/√κ) is exponentially faster than κ(ζ2/µ)R−2.
Under the PL condition (which is not necessarily convex) the story is similar (Table 4), except we use
FedAvg →SGD as our representative algorithm, as Nesterov acceleration is not known to improve
under non-convex settings."
Q,0.06993736951983298,"In the general convex case (Table 2), let β = D = 1 for the purpose of comparisons. Then FedAvg →
ASG’s convergence rate is min{1/R2, ζ1/2/R} +
p"
Q,0.07045929018789145,"1 −S/N(ζ/
√"
Q,0.0709812108559499,"SR) +
4p"
Q,0.07150313152400835,"1 −S/N√ζ/
4√"
Q,0.0720250521920668,"SR.
If ζ <
1
R2 , then ζ1/2/R < 1/R2 and if ζ <
p"
Q,0.07254697286012526,"S/R7, then
4p"
Q,0.07306889352818371,"1 −S/N√ζ/
4√"
Q,0.07359081419624217,"SR < 1/R2, so the
FedAvg →ASG convergence rate is better than the convergence rate of ASG under the regime
ζ < min{1/R2,
p"
Q,0.07411273486430063,"S/R7}. The rate of Karimireddy et al. (2020b) for FedAvg (which does not
require S = N) is strictly worse than ASG, and so has a worse convergence rate than FedAvg
→ASG if ζ < min{1/R2,
p"
Q,0.07463465553235908,"S/R7}. Altogether, if ζ < min{1/R2,
p"
Q,0.07515657620041753,"S/R7}, FedAvg →ASG
achieves the best known worst-case rate. Finally, in the S = N case, FedAvg →ASG does not have a
regime in ζ where it improves over both ASG and FedAvg (the analysis of Woodworth et al. (2020a),
which requires S = N) at the same time. It is unclear if this is due to looseness in the analysis."
Q,0.075678496868476,"Next, we analyze variance reduced methods that improve convergence when a random subset of the
clients participate in each round (i.e., partial participation)."
Q,0.07620041753653445,Published as a conference paper at ICLR 2022
Q,0.0767223382045929,"Figure 2: Plot titles denote data homogeneity (§ 6). “X→Y” denotes a FedChain instantiation with X
as Alocal and Y as Aglobal, circle markers denote stepsize decay events and plusses denote switching
from Alocal to Aglobal. Across all heterogeneity levels, the multistage algorithms perform the best.
Stepsize decayed baselines are left out to simplify the plots; we display them in App. J.2."
Q,0.07724425887265135,"Theorem 4.3 (FedAvg →SAGA). Suppose that client objectives Fi’s and their gradient queries
satisfy Assumptions B.4, B.5, B.6, B.7 and B.8. Then running FedChain (Algo. 1) with Alocal as
FedAvg (Algo. 4 ) with the parameter choices of Thm. E.1, and Aglobal as SAGA (Algo. 5) with the
parameter choices of Thm. D.4, we get the following guarantees as long as R ≥Ω( N S ):"
Q,0.07776617954070981,"• Strongly convex: If Fi’s satisfy Assumption B.1 for µ > 0, then there exists a ﬁnite K above
which we get the rate EF(ˆx2) −F(x∗) ≤˜O(min{∆, ζ2/µ} exp(−min{S/N, 1/κ}R)) ."
Q,0.07828810020876827,"• PL condition: If Fi’s satisfy Assumption B.3 for µ > 0, then there exists a ﬁnite K above
which we get the rate EF(ˆx2) −F(x∗) ≤˜O(min{∆, ζ2/µ} exp(−(S/N)
2
3 R/κ)) ."
Q,0.07881002087682672,"For the formal statement, see Thm. F.3."
Q,0.07933194154488518,"Theorem 4.4 (FedAvg →SSNM). Suppose that client objectives Fi’s and their gradient queries
satisfy Assumptions B.4, B.5, B.6 and B.8. Then running FedChain (Algo. 1) with Alocal as FedAvg
(Algo. 4) with the parameter choices of Thm. E.1, and Aglobal as SSNM (Algo. 6) with the parameter
choices of Thm. D.5, we get the following guarantees as long as R ≥Ω( N S ):"
Q,0.07985386221294363,"• Strongly convex: If Fi’s satisfy Assumption B.1 for µ > 0, then there exists a ﬁnite
K (same as in FedAvg →SGD) above which we get the rate EF(ˆx2) −F(x∗) ≤
˜O(min{∆, ζ2/µ} exp(−min{S/N,
p"
Q,0.08037578288100208,S/(Nκ)}R)) .
Q,0.08089770354906055,"For the formal statement, see Thm. F.4. SSNM (Zhou et al., 2019) is the Nesterov accelerated version
of SAGA (Defazio et al., 2014)."
Q,0.081419624217119,"The main contribution of using variance reduced methods in Aglobal is the removal of the sam-
pling error (the terms depending on the sampling heterogeneity error (1 −S/N)(ζ2/S)) from
the convergence rates, in exchange for requiring a round complexity of at least N/S.
To il-
lustrate this, observe that in the strongly convex case, FedAvg →SGD has convergence rate
min{∆, ζ2/µ} exp(−R/κ)+(1−S/N)(ζ2/SR) and FedAvg →SAGA (FedAvg →SGD’s variance-
reduced counterpart) has convergence rate min{∆, ζ2/µ} exp(−min{1/κ, S/N}R), dropping the
(1 −S/N)(ζ2/µSR) sampling heterogeneity error term in exchange for harming the rate of linear
convergence from 1/κ to min{1/κ, S/N}."
Q,0.08194154488517745,"This same tradeoff occurs in ﬁnite sum optimization (the problem minx(1/n) Pn
i=1 ψi(x), where
ψi’s (typically) represent losses on data points and the main concern is computation cost), which is
what variance reduction is designed for. In ﬁnite sum optimization, variance reduction methods such
as SVRG (Johnson & Zhang, 2013) and SAGA (Defazio et al., 2014; Reddi et al., 2016) achieve
linear rates of convergence (given strong convexity of ψi’s) in exchange for requiring at least N/S
updates. Because we can treat FL as an instance of ﬁnite-sum optimization (by viewing Eq. (1) as a
ﬁnite sum of objectives and ζ2 as the variance between Fi’s), these results from variance-reduced
ﬁnite sum optimization can be extended to federated learning. This is the idea behind SCAFFOLD
(Karimireddy et al., 2020b)."
Q,0.0824634655532359,"It is not always the case that variance reduction in Aglobal achieves better rates. In the strongly convex
case if (1 −S/N)(ζ2/µSϵ) > N/S, then variance reduction gets gain, otherwise not."
Q,0.08298538622129437,Published as a conference paper at ICLR 2022
LOWER BOUNDS,0.08350730688935282,"5
LOWER BOUNDS"
LOWER BOUNDS,0.08402922755741127,"Our lower bound allows full participation. It assumes deterministic gradients and the following class
from (Woodworth et al., 2020a; Woodworth, 2021; Carmon et al., 2020):"
LOWER BOUNDS,0.08455114822546973,"Deﬁnition 5.1. For a v ∈Rd, let supp(v) = {i ∈[d] : vi ̸= 0}. An algorithm is distributed
zero-respecting if for any i, k, r, the k-th iterate on the i-th client in the r-th round x(r)
i,k satisfy"
LOWER BOUNDS,0.08507306889352818,"supp(x(r)
i,k) ⊆
["
LOWER BOUNDS,0.08559498956158663,"0≤k′<k
supp(∇Fi(x(r)
i,k′))
["
LOWER BOUNDS,0.0861169102296451,"i′∈[N],0≤k′≤K−1,0≤r′<r
supp(∇Fi′(x(r′)
i′,k′))
(3)"
LOWER BOUNDS,0.08663883089770355,"Distributed zero-respecting algorithms’ iterates have components in coordinates that they have any
information on. As discussed in (Woodworth et al., 2020a), this means that algorithms which are not
distributed zero-respecting are just “wild guessing”. Algorithms that are distributed zero-respecting
include SGD, ASG, and FedAvg. We assume the following class of algorithms in order to bound the
heterogeneity of our construction for the lower bound proof."
LOWER BOUNDS,0.087160751565762,"Deﬁnition 5.2. We say that an algorithm is distributed distance-conserving if for any i, k, r, we have
for the k-th iterate on the i-th client in the r-th round x(r)
i,k satisﬁes ∥x(r)
i,k −x∗∥2 ≤(c/2)[∥xinit −"
LOWER BOUNDS,0.08768267223382047,"x∗∥2 + PN
i=1 ∥xinit −x∗
i ∥2], where x∗
j := arg minx Fj(x) and x∗:= arg minx F(x) and xinit is the
initial iterate, and c is some scalar parameter."
LOWER BOUNDS,0.08820459290187892,"Algorithms which do not satisfy Deﬁnition 5.2 with c at most logarithmic in problem parameters (see
§ 2) are those that move substantially far away from x∗, even farther than the x∗
i ’s are from x∗. With
this deﬁnition in mind, we slightly overload the usual deﬁnition of heterogeneity for the lower bound:"
LOWER BOUNDS,0.08872651356993737,"Deﬁnition
5.3.
A
distributed
optimization
problem
is
(ζ, c)-heterogeneous
if
maxi∈[N] supx∈A ∥∇Fi(x) −∇F(x)∥2 ≤ζ2, where we deﬁne A := {x : ∥x −x∗∥2 ≤
(c/2)(∥xinit −x∗∥2 + PN
i=1 ∥xinit −x∗∥2)} for some scalar parameter c."
LOWER BOUNDS,0.08924843423799582,"Those achievable convergence rates in FL that assume Eq. (2) can be readily extended to account for
Deﬁnition 5.3 as long as the algorithm satisﬁes Deﬁnition 5.2. We show that the chaining algorithms
we propose satisfy Deﬁnition 5.3 in Thm. D.1, Thm. D.3, and Thm. E.1 for c at most polylogarithmic
in the problem parameters deﬁned in § 2. 3. Other FL algorithms also satisfy Deﬁnition 5.2, notably
FedAvg analyzed in Woodworth et al. (2020a) for c an absolute constant, which is the current tightest
known analysis of FedAvg in the full participation setting."
LOWER BOUNDS,0.08977035490605428,"Theorem 5.4. For any number of rounds R, number of local steps per-round K, and (ζ, c)-
heterogeneity (Deﬁnition 5.3), there exists a global objective F which is the average of two β-smooth
(Assumption B.4) and µ(≥0)-strongly convex (Assumption B.1) quadratic client objectives F1 and
F2 with an initial sub-optimality gap of ∆, such that the output ˆx of any distributed zero-respecting
(Deﬁnition 5.1) and distance-conserving algorithm (Deﬁnition 5.2) satisﬁes"
LOWER BOUNDS,0.09029227557411273,"• Strongly convex: F(ˆx) −F(x∗) ≥Ω(min{∆, 1/(cκ3/2)(ζ2/β)} exp(−R/√κ).) when
µ > 0, and"
LOWER BOUNDS,0.09081419624217119,"• General Convex F(ˆx) −F(x∗) ≥Ω(min{βD2/R2, ζD/(c1/2√"
LOWER BOUNDS,0.09133611691022965,R5)}) when µ = 0.
LOWER BOUNDS,0.0918580375782881,"Corollary 5.5. Under the hypotheses of Theorem 5.4, there exists a global objective F which is µ-PL
and satisﬁes F(ˆx) −F(x∗) ≥Ω(min{∆, 1/(cκ3/2)(ζ2/β)} exp(−R/√κ))."
LOWER BOUNDS,0.09237995824634655,"A proof of the lower bound is in App. G, and the corollary follows immediately from the fact that
µ-strong convexity implies µ-PL. This result tightens the lower bound in Woodworth et al. (2020a),
which proves a similar lower bound but in terms of a much larger class of functions with heterogeneity
bounded in ζ∗= (1/N) PN
i=1 ∥∇Fi(x∗)∥2. To the best of our knowledge, all achievable rates that
can take advantage of heterogeneity require (ζ, c)-heterogeneity (which is a smaller class than ζ∗-
heterogeneity), which are incomparable with the existing lower bound from (Woodworth et al., 2020a)
that requires ζ∗-heterogeneity. By introducing the class of distributed distance-conserving algorithms"
LOWER BOUNDS,0.09290187891440502,"3We do not formally show it for SAGA and SSNM, as the algorithms are functionally the same as SGD and
ASG under full participation."
LOWER BOUNDS,0.09342379958246347,Published as a conference paper at ICLR 2022
LOWER BOUNDS,0.09394572025052192,"Table 3: Test accuracies (↑). “Constant” means the stepsize does not change during optimization,
while “w/ Decay” means the stepsize decays during optimization. Left: Comparison among algo-
rithms in the EMNIST task. Right: Comparison among algorithms in the CIFAR-100 task. “SCA.”
abbreviates SCAFFOLD."
LOWER BOUNDS,0.09446764091858037,"Algorithm
Constant
w/ Decay
Baselines"
LOWER BOUNDS,0.09498956158663883,"SGD
FedAvg
SCAFFOLD"
LOWER BOUNDS,0.09551148225469729,"0.7842
0.8314
0.8157"
LOWER BOUNDS,0.09603340292275574,"0.7998
0.8224
0.8174
FedChain"
LOWER BOUNDS,0.0965553235908142,"FedAvg →SGD
SCA. →SGD
0.8501
0.8508
0.8355
0.8392"
LOWER BOUNDS,0.09707724425887265,"Algorithm
Constant
w/ Decay
Baselines"
LOWER BOUNDS,0.0975991649269311,"SGD
FedAvg
SCAFFOLD"
LOWER BOUNDS,0.09812108559498957,"0.1987
0.4944
–"
LOWER BOUNDS,0.09864300626304802,"0.1968
0.5059
–
FedChain"
LOWER BOUNDS,0.09916492693110647,"FedAvg →SGD
SCA. →SGD
0.5134
–
0.5167
–"
LOWER BOUNDS,0.09968684759916492,"(which includes most of the algorithms we are interested in), Thm. 5.4 allows us, for the ﬁrst time, to
identify the optimality of the achievable rates as shown in Tables 1, 2, and 4."
LOWER BOUNDS,0.10020876826722339,"Note that this lower bound allows full participation and should be compared to the achievable rates
with S = N; comparisons with variance reduced methods like FedAvg →SAGA and FedAvg →
SSNM are unnecessary. Our lower bound proves that FedAvg →ASG is optimal up to condition
number factors shrinking exponentially in √κ among algorithms satisfying Deﬁnition 5.2 and
Deﬁnition 5.3. Under the PL-condition, the situation is similar, except FedAvg →SGD loses √κ in
the exponential versus the lower bound. On the other hand, there remains a substantial gap between
FedAvg →ASG and the lower bound in the general convex case. Meaningful progress in closing the
gap in the general convex case is an important future direction."
EXPERIMENTS,0.10073068893528184,"6
EXPERIMENTS"
EXPERIMENTS,0.10125260960334029,"We evaluate the utility of our framework on strongly convex and nonconvex settings. We compare the
communication round complexities of four baselines: FedAvg, SGD, ASG, and SCAFFOLD, the
stepsize decaying variants of these algorithms (which are preﬁxed by M- in plots) and the various
instantiations of FedChain (Algo. 1)."
EXPERIMENTS,0.10177453027139875,"Convex Optimization (Logistic Regression)
We ﬁrst study federated regularized logistic regres-
sion, which is strongly convex (objective function in App. I.1). In this experiment, we use the MNIST
dataset of handwritten digits (LeCun et al., 2010). We (roughly) control client heterogeneity by
creating “clients” through shufﬂing samples across different digit classes. The details of this shufﬂing
process are described in App. I.1; if a dataset is more shufﬂed (more homogeneous), it roughly
corresponds to a lower heterogeneity dataset. All clients participate in each round."
EXPERIMENTS,0.1022964509394572,"Fig. 2 compares the convergence of chained and non-chained algorithms in the stochastic gradient
setting (minibatches are 1% of a client’s data), over R = 100 rounds (tuning details in App. I.1).
We observe that in all heterogeneity levels, FedChain instantiations (whether two or more stages)
outperform other baselines. We also observe that SCAFFOLD→SGD outperforms all other curves,
including SCAFFOLD→ASG. This can be explained by the fact that acceleration increases the effect
of noise, which can contribute to error if one does not take K large enough (we set K = 20 in the
convex experiments). The effect of large K is elaborated upon in App. J.1."
EXPERIMENTS,0.10281837160751565,"Nonconvex Optimization (Neural Networks)
We also evaluated nonconvex image classiﬁcation
tasks with convolutional neural networks. In all experiments, we consider client sampling with
S = 10. We started with digit classiﬁcation over EMNIST (Cohen et al., 2017) (tuning details in
App. I.2.1), where handwritten characters are partitioned by author. Table 3 (Left) displays test
accuracies on the task. Overall, FedChain instantiations perform better than baselines."
EXPERIMENTS,0.10334029227557412,"We also considered image classiﬁcation with ResNet-18 on CIFAR-100 (Krizhevsky, 2009) (tuning
details in App. I.2.2). Table 3 (Right) displays the test accuracies on CIFAR-100; SCAFFOLD is not
included due to memory constraints. FedChain instantiations again perform the best."
EXPERIMENTS,0.10386221294363257,Published as a conference paper at ICLR 2022
EXPERIMENTS,0.10438413361169102,ACKNOWLEDGMENTS
EXPERIMENTS,0.10490605427974947,"This work is supported by Google faculty research award, JP Morgan Chase, Siemens, the Sloan
Foundation, Intel, NSF grants CNS-2002664, CA-2040675, IIS-1929955, DMS-2134012, CCF-
2019844 as a part of NSF Institute for Foundations of Machine Learning (IFML), and CNS-2112471
as a part of NSF AI Institute for Future Edge Networks and Distributed Intelligence (AI-EDGE).
Most of this work was done prior to the second author joining Amazon, and it does not relate to his
current position there."
REFERENCES,0.10542797494780794,REFERENCES
REFERENCES,0.10594989561586639,"Maruan Al-Shedivat, Jennifer Gillenwater, Eric Xing, and Afshin Rostamizadeh.
Federated
learning via posterior averaging: A new perspective and practical algorithms. arXiv preprint
arXiv:2010.05273, 2020."
REFERENCES,0.10647181628392484,"Yossi Arjevani and Ohad Shamir. Communication complexity of distributed convex learning and
optimization. arXiv preprint arXiv:1506.01900, 2015."
REFERENCES,0.1069937369519833,"Necdet Serhat Aybat, Alireza Fallah, Mert Gurbuzbalaban, and Asuman Ozdaglar. A universally
optimal multistage accelerated stochastic gradient method. arXiv preprint arXiv:1901.08022, 2019."
REFERENCES,0.10751565762004175,"Yair Carmon, John C Duchi, Oliver Hinder, and Aaron Sidford. Lower bounds for ﬁnding stationary
points i. Mathematical Programming, 184(1):71–120, 2020."
REFERENCES,0.1080375782881002,"Zachary Charles and Jakub Koneˇcn`y. On the outsized importance of learning rates in local update
methods. arXiv preprint arXiv:2007.00878, 2020."
REFERENCES,0.10855949895615867,"Zachary Charles, Zachary Garrett, Zhouyuan Huo, Sergei Shmulyian, and Virginia Smith. On
large-cohort training for federated learning. arXiv preprint arXiv:2106.07820, 2021."
REFERENCES,0.10908141962421712,"Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre Van Schaik. Emnist: Extending mnist
to handwritten letters. In 2017 International Joint Conference on Neural Networks (IJCNN), pp.
2921–2926. IEEE, 2017."
REFERENCES,0.10960334029227557,"Aaron Defazio, Francis Bach, and Simon Lacoste-Julien. Saga: A fast incremental gradient method
with support for non-strongly convex composite objectives. Advances in neural information
processing systems, 27, 2014."
REFERENCES,0.11012526096033402,"Yuyang Deng and Mehrdad Mahdavi. Local stochastic gradient descent ascent: Convergence analysis
and communication efﬁciency. In International Conference on Artiﬁcial Intelligence and Statistics,
pp. 1387–1395. PMLR, 2021."
REFERENCES,0.11064718162839249,"Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Adaptive personalized federated
learning. arXiv preprint arXiv:2003.13461, 2020."
REFERENCES,0.11116910229645094,"Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Distributionally robust federated
averaging. arXiv preprint arXiv:2102.12660, 2021."
REFERENCES,0.11169102296450939,"Alireza Fallah, Asuman Ozdaglar, and Sarath Pattathil. An optimal multistage stochastic gradient
method for minimax problems. In 2020 59th IEEE Conference on Decision and Control (CDC),
pp. 3573–3579. IEEE, 2020."
REFERENCES,0.11221294363256785,"Saeed Ghadimi and Guanghui Lan. Optimal stochastic approximation algorithms for strongly
convex stochastic composite optimization i: A generic algorithmic framework. SIAM Journal on
Optimization, 22(4):1469–1492, 2012."
REFERENCES,0.1127348643006263,"Saeed Ghadimi and Guanghui Lan. Optimal stochastic approximation algorithms for strongly convex
stochastic composite optimization, ii: shrinking procedures and optimal algorithms. SIAM Journal
on Optimization, 23(4):2061–2089, 2013."
REFERENCES,0.11325678496868476,"Eduard Gorbunov, Filip Hanzely, and Peter Richt´arik. Local sgd: Uniﬁed theory and new efﬁcient
methods. arXiv preprint arXiv:2011.02828, 2020."
REFERENCES,0.11377870563674322,Published as a conference paper at ICLR 2022
REFERENCES,0.11430062630480167,"Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance
reduction. Advances in neural information processing systems, 26:315–323, 2013."
REFERENCES,0.11482254697286012,"Peter Kairouz, H Brendan McMahan, Brendan Avent, Aur´elien Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances
and open problems in federated learning. arXiv preprint arXiv:1912.04977, 2019."
REFERENCES,0.11534446764091857,"Sai Praneeth Karimireddy, Martin Jaggi, Satyen Kale, Mehryar Mohri, Sashank J Reddi, Sebastian U
Stich, and Ananda Theertha Suresh. Mime: Mimicking centralized stochastic algorithms in
federated learning. arXiv preprint arXiv:2008.03606, 2020a."
REFERENCES,0.11586638830897704,"Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In
International Conference on Machine Learning, pp. 5132–5143. PMLR, 2020b."
REFERENCES,0.11638830897703549,"Ahmed Khaled, Konstantin Mishchenko, and Peter Richt´arik. Tighter theory for local sgd on identical
and heterogeneous data. In International Conference on Artiﬁcial Intelligence and Statistics, pp.
4519–4529. PMLR, 2020."
REFERENCES,0.11691022964509394,"Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian Stich. A uniﬁed
theory of decentralized sgd with changing topology and local updates. In International Conference
on Machine Learning, pp. 5381–5393. PMLR, 2020."
REFERENCES,0.1174321503131524,"Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, ., 2009."
REFERENCES,0.11795407098121086,"Yann LeCun, Corinna Cortes, and CJ Burges. Mnist handwritten digit database. ATT Labs [Online].
Available: http://yann.lecun.com/exdb/mnist, 2, 2010."
REFERENCES,0.11847599164926931,"Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127, 2018."
REFERENCES,0.11899791231732777,"Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smithy.
Feddane: A federated newton-type method. In 2019 53rd Asilomar Conference on Signals, Systems,
and Computers, pp. 1227–1231. IEEE, 2019."
REFERENCES,0.11951983298538622,"Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges,
methods, and future directions. IEEE Signal Processing Magazine, 37(3):50–60, 2020."
REFERENCES,0.12004175365344467,"Tao Lin, Sebastian U Stich, Kumar Kshitij Patel, and Martin Jaggi. Don’t use large mini-batches, use
local sgd. arXiv preprint arXiv:1808.07217, 2018."
REFERENCES,0.12056367432150313,"Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efﬁcient learning of deep networks from decentralized data. In Artiﬁcial Intelli-
gence and Statistics, pp. 1273–1282. PMLR, 2017."
REFERENCES,0.12108559498956159,"Aritra Mitra, Rayana Jaafar, George J. Pappas, and Hamed Hassani.
Linear Convergence in
Federated Learning: Tackling Client Heterogeneity and Sparse Gradients. arXiv e-prints, art.
arXiv:2102.07053, February 2021."
REFERENCES,0.12160751565762004,"Yurii Nesterov. Introductory lectures on convex optimization: A basic course, volume 87. Springer
Science & Business Media, 2003."
REFERENCES,0.12212943632567849,"Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Koneˇcn`y,
Sanjiv Kumar, and H Brendan McMahan. Adaptive federated optimization. arXiv preprint
arXiv:2003.00295, 2020."
REFERENCES,0.12265135699373696,"Sashank J Reddi, Suvrit Sra, Barnab´as P´oczos, and Alex Smola. Fast incremental method for
nonconvex optimization. arXiv preprint arXiv:1603.06159, 2016."
REFERENCES,0.12317327766179541,"Sebastian U Stich. Local sgd converges fast and communicates little. arXiv preprint arXiv:1805.09767,
2018."
REFERENCES,0.12369519832985386,"Jianyu Wang and Gauri Joshi. Cooperative sgd: A uniﬁed framework for the design and analysis of
communication-efﬁcient sgd algorithms. arXiv preprint arXiv:1808.07576, 2018."
REFERENCES,0.12421711899791232,Published as a conference paper at ICLR 2022
REFERENCES,0.12473903966597077,"Jianyu Wang and Gauri Joshi. Adaptive communication strategies to achieve the best error-runtime
trade-off in local-update sgd. In SysML, 2019."
REFERENCES,0.12526096033402923,"Jianyu Wang, Anit Kumar Sahu, Zhouyi Yang, Gauri Joshi, and Soummya Kar. Matcha: Speeding up
decentralized sgd via matching decomposition sampling. In 2019 Sixth Indian Control Conference
(ICC), pp. 299–300. IEEE, 2019a."
REFERENCES,0.12578288100208768,"Jianyu Wang, Vinayak Tantia, Nicolas Ballas, and Michael Rabbat.
Slowmo:
Improving
communication-efﬁcient distributed sgd with slow momentum. arXiv preprint arXiv:1910.00643,
2019b."
REFERENCES,0.12630480167014613,"Blake Woodworth.
The minimax complexity of distributed optimization.
arXiv preprint
arXiv:2109.00534, 2021."
REFERENCES,0.1268267223382046,"Blake Woodworth, Kumar Kshitij Patel, and Nathan Srebro. Minibatch vs local sgd for heterogeneous
distributed learning. arXiv preprint arXiv:2006.04735, 2020a."
REFERENCES,0.12734864300626306,"Blake Woodworth, Kumar Kshitij Patel, Sebastian Stich, Zhen Dai, Brian Bullins, Brendan Mcmahan,
Ohad Shamir, and Nathan Srebro. Is local sgd better than minibatch sgd?
In International
Conference on Machine Learning, pp. 10334–10343. PMLR, 2020b."
REFERENCES,0.1278705636743215,"Blake Woodworth, Brian Bullins, Ohad Shamir, and Nathan Srebro. The min-max complexity
of distributed stochastic convex optimization with intermittent communication. arXiv preprint
arXiv:2102.01583, 2021."
REFERENCES,0.12839248434237996,"Honglin Yuan and Tengyu Ma. Federated accelerated stochastic gradient descent. arXiv preprint
arXiv:2006.08950, 2020."
REFERENCES,0.1289144050104384,"Honglin Yuan, Manzil Zaheer, and Sashank Reddi. Federated composite optimization. arXiv preprint
arXiv:2011.08474, 2020."
REFERENCES,0.12943632567849686,"Kaiwen Zhou, Qinghua Ding, Fanhua Shang, James Cheng, Danli Li, and Zhi-Quan Luo. Direct
acceleration of saga using sampled negative momentum. In The 22nd International Conference on
Artiﬁcial Intelligence and Statistics, pp. 1602–1610. PMLR, 2019."
REFERENCES,0.1299582463465553,Published as a conference paper at ICLR 2022
REFERENCES,0.1304801670146138,Appendices
REFERENCES,0.13100208768267224,"A Additional Related Work
14"
REFERENCES,0.1315240083507307,"B
Deﬁnitions
14"
REFERENCES,0.13204592901878914,"C Omitted Algorithm Deﬁnitions
15"
REFERENCES,0.1325678496868476,"D Proofs for global update methods
17"
REFERENCES,0.13308977035490605,"D.1
SGD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17"
REFERENCES,0.1336116910229645,"D.2
ASG . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21"
REFERENCES,0.13413361169102297,"D.3
SAGA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24"
REFERENCES,0.13465553235908143,"D.4
SSNM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29"
REFERENCES,0.13517745302713988,"E
Proofs for local update methods
34"
REFERENCES,0.13569937369519833,"E.1
FedAvg
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34"
REFERENCES,0.13622129436325678,"F
Proofs for FedChain
37"
REFERENCES,0.13674321503131523,"F.1
FedAvg →SGD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37"
REFERENCES,0.1372651356993737,"F.2
FedAvg →ASG . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38"
REFERENCES,0.13778705636743216,"F.3
FedAvg →SAGA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39"
REFERENCES,0.1383089770354906,"F.4
FedAvg →SSNM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39"
REFERENCES,0.13883089770354906,"G Lower Bound
39"
REFERENCES,0.1393528183716075,"G.1
Strong convexity and smoothness of F, F1, F2 . . . . . . . . . . . . . . . . . . . .
41"
REFERENCES,0.13987473903966596,"G.2
The solutions of F, F1, F2
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41"
REFERENCES,0.1403966597077244,"G.3
Initial suboptimality gap
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41"
REFERENCES,0.1409185803757829,"G.4
Suboptimality gap after R rounds of communication
. . . . . . . . . . . . . . . .
41"
REFERENCES,0.14144050104384134,"G.5
Computation of ζ2
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41"
REFERENCES,0.1419624217118998,"G.6
Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42"
REFERENCES,0.14248434237995825,"H Technical Lemmas
44"
REFERENCES,0.1430062630480167,"I
Experimental Setup Details
47"
REFERENCES,0.14352818371607515,"I.1
Convex Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47"
REFERENCES,0.1440501043841336,"I.2
Nonconvex Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47"
REFERENCES,0.14457202505219208,"J
Additional Convex Experiments
48"
REFERENCES,0.14509394572025053,"J.1
Verifying the effect of increased K and R = 1 . . . . . . . . . . . . . . . . . . . .
48"
REFERENCES,0.14561586638830898,"J.2
Including Stepsize Decay Baselines
. . . . . . . . . . . . . . . . . . . . . . . . .
49"
REFERENCES,0.14613778705636743,Published as a conference paper at ICLR 2022
REFERENCES,0.14665970772442588,Table 4: Rates under the PL condition. ♣Rate requires R ≥N S .
REFERENCES,0.14718162839248433,"Method/Analysis
EF(ˆx) −F(x∗) ≤˜O(·)"
REFERENCES,0.1477035490605428,Centralized Algorithms
REFERENCES,0.14822546972860126,"SGD
∆exp(−κ−1R) + (1 −S"
REFERENCES,0.1487473903966597,N ) κζ2
REFERENCES,0.14926931106471816,"µSR
Federated Algorithms"
REFERENCES,0.14979123173277661,"FedAvg (Karimireddy et al., 2020a)
κ∆exp(−κ−1R) + κ2ζ2"
REFERENCES,0.15031315240083507,"µR2
This paper"
REFERENCES,0.15083507306889352,FedAvg →SGD (Thm. 4.1)
REFERENCES,0.151356993736952,FedAvg →SAGA (Thm. 4.3)
REFERENCES,0.15187891440501045,Algo.-independent LB (Corollary 5.5)
REFERENCES,0.1524008350730689,"min{∆, ζ2"
REFERENCES,0.15292275574112735,µ } exp(−κ−1R) + (1 −S
REFERENCES,0.1534446764091858,N ) κζ2
REFERENCES,0.15396659707724425,"µSR
min{∆, ζ2"
REFERENCES,0.1544885177453027,µ } exp(−(( N
REFERENCES,0.15501043841336118,"S )
2
3 κ)−1R)♣"
REFERENCES,0.15553235908141963,"min{∆, κ−3"
REFERENCES,0.15605427974947808,2 ( ζ2
REFERENCES,0.15657620041753653,β )} exp(−κ−1 2 R)
REFERENCES,0.15709812108559498,"A
ADDITIONAL RELATED WORK"
REFERENCES,0.15762004175365343,"Multistage algorithms. Our chaining framework has similarities in analysis to multistage algorithms
which have been employed in the classical convex optimization setting (Aybat et al., 2019; Fallah
et al., 2020; Ghadimi & Lan, 2012; Woodworth et al., 2020a). The idea behind multistage algorithms
is to manage stepsize decay to balance fast progress in “bias” error terms while controlling variance
error. However chaining differs from multistage algorithms in a few ways: (1) We do not necessarily
decay stepsize (2) In the heterogeneous FL setting, we have to accomodate error due to client drift
(Reddi et al., 2020; Karimireddy et al., 2020b), which is not analyzed in prior multistage literature.
(3) Our goal is to minimize commuincation rounds rather than iteration complexity."
REFERENCES,0.1581419624217119,"B
DEFINITIONS"
REFERENCES,0.15866388308977036,"Assumption B.1. Fi’s are µ-strongly convex for µ > 0, i.e."
REFERENCES,0.15918580375782881,"⟨∇Fi(x), y −x⟩≤−(Fi(x) −Fi(y) + µ"
REFERENCES,0.15970772442588727,"2 ∥x −y∥2)
(4)"
REFERENCES,0.16022964509394572,"for any i, x, y.
Assumption B.2. Fi’s are general convex, i.e."
REFERENCES,0.16075156576200417,"⟨∇Fi(x), y −x⟩≤−(Fi(x) −Fi(y))
(5)"
REFERENCES,0.16127348643006262,"for any i, x, y.
Assumption B.3. F is µ-PL for µ > 0, i.e."
REFERENCES,0.1617954070981211,"2µ(F(x) −F(x∗)) ≤∥∇F(x)∥2
(6)"
REFERENCES,0.16231732776617955,"for any x.
Assumption B.4. Fi’s are β-smooth where"
REFERENCES,0.162839248434238,"∥∇Fi(x) −∇Fi(y)∥≤β∥x −y∥
(7)"
REFERENCES,0.16336116910229645,"for any i, x, y.
Assumption B.5. Fi’s are ζ2-heterogeneous, deﬁned as"
REFERENCES,0.1638830897703549,"ζ2 := sup
x max
i∈[N] ∥∇F(x) −∇Fi(x)∥2
(8)"
REFERENCES,0.16440501043841335,"Assumption B.6. Gradient queries within a client have a uniform upper bound on variance and are
also unbiased."
REFERENCES,0.1649269311064718,"Ezi∼Di∥∇f(x; zi) −∇Fi(x)∥2 ≤σ2,
Ezi∼Di[∇f(x; zi)] = ∇Fi(x)
(9)"
REFERENCES,0.16544885177453028,"Assumption B.7. Cost queries within a client have a uniform upper bound on variance and are also
unbiased."
REFERENCES,0.16597077244258873,"Ezi∼Di(f(x; zi) −Fi(x))2 ≤σ2
F ,
Ezi∼Dif(x; zi) = Fi(x)
(10)"
REFERENCES,0.16649269311064718,Published as a conference paper at ICLR 2022
REFERENCES,0.16701461377870563,Assumption B.8. Cost queries within a client have an absolute deviation.
REFERENCES,0.16753653444676408,"ζ2
F = sup
x max
i∈[N](F(x) −Fi(x))2
(11)"
REFERENCES,0.16805845511482254,"Assumption B.9. The initial suboptimality gap is upper bounded by ∆, where x0 is the initial
feasible iterate and x∗is the global minimizer."
REFERENCES,0.16858037578288101,"EF(x0) −F(x∗) ≤∆
(12)"
REFERENCES,0.16910229645093947,"Assumption B.10. The expected initial distance from the optimum is upper bounded by D, where
x0 is the initial feasible iterate and x∗is one of the global minimizers:"
REFERENCES,0.16962421711899792,"E∥x0 −x∗∥2 ≤D2
(13)"
REFERENCES,0.17014613778705637,"C
OMITTED ALGORITHM DEFINITIONS"
REFERENCES,0.17066805845511482,Algorithm 2 SGD
REFERENCES,0.17118997912317327,"Input: initial point x(0), stepsize η, loss f
for r = 0, . . . , R −1 do"
REFERENCES,0.17171189979123172,"▷Run a step of SGD
Sample S clients Sr ⊆[1, . . . , N]
Send x(r) to all clients in Sr
Receive {g(r)
i
}i∈Sr = Grad(x(r), Sr, z(r)) (Algo. 7)
g(r) = 1 S
P"
REFERENCES,0.1722338204592902,"i∈Sr g(r)
i
x(r+1) = x(r) −η · g(r)
end for"
REFERENCES,0.17275574112734865,Algorithm 3 ASG
REFERENCES,0.1732776617954071,"Input: initial point x(0) = x(0)
ag , {αr}1≤r≤R, {γr}1≤r≤R, loss f
for r = 1, . . . , R do"
REFERENCES,0.17379958246346555,"▷Run a step of ASG
Sample S clients Sr ⊆[1, . . . , N]
Send x(r) to all clients in Sr
x(r)
md = (1−αr)(µ+γr)"
REFERENCES,0.174321503131524,"γr+(1−α2r)µ x(r−1)
ag
+ αr[(1−αr)µ+γr]"
REFERENCES,0.17484342379958245,"γr+(1−α2r)µ
x(r−1)"
REFERENCES,0.17536534446764093,"Receive {g(r)
i
}i∈Sr = Grad(x(r)
md , Sr, z(r)) (Algo. 7)
g(r) = 1 S
P"
REFERENCES,0.17588726513569938,"i∈Sr g(r)
i
x(r) = arg minx{αr[⟨g(r), x⟩+ µ"
REFERENCES,0.17640918580375783,"2 ∥x(r)
md −x∥2] + [(1 −αr) µ"
REFERENCES,0.17693110647181629,2 + γr
REFERENCES,0.17745302713987474,"2 ∥x(r−1) −x∥2]}
x(r)
ag = αrx(r) + (1 −αr)x(r−1)
ag
end for"
REFERENCES,0.1779749478079332,Published as a conference paper at ICLR 2022
REFERENCES,0.17849686847599164,Algorithm 4 FedAvg
REFERENCES,0.17901878914405012,"Input: Stepsize η, initial point x(0)
for r = 0, . . . , R −1 do"
REFERENCES,0.17954070981210857,"Sample S clients Sr ⊆[1, . . . , N]
Send x(r) to all clients in Sr, all clients set x(r)
i,0 = x(r)"
REFERENCES,0.18006263048016702,for client i ∈Sr in parallel do
REFERENCES,0.18058455114822547,"for k = 0, ...,
√"
REFERENCES,0.18110647181628392,"K −1 do
Client samples g(r)
i,k =
1
√ K
P√"
REFERENCES,0.18162839248434237,"K−1
k′=0
∇f(x(r)
i,k; z(r)
i,k
√"
REFERENCES,0.18215031315240082,"K+k′) where z(r)
i,k
√"
REFERENCES,0.1826722338204593,K+k′ ∼Di
REFERENCES,0.18319415448851775,"x(r)
i,k+1 = x(r)
i,k −η · g(r)
i,k
end for
Receive g(r)
i
= P√"
REFERENCES,0.1837160751565762,"K−1
k=0
g(r)
i,k from client
end for
g(r) = 1 S
P"
REFERENCES,0.18423799582463465,"i∈Sr g(r)
i
x(r+1) ←x(r) −η · g(r)
end for"
REFERENCES,0.1847599164926931,Algorithm 5 SAGA
REFERENCES,0.18528183716075156,"Input: stepsize η, loss f, initial point x(0)"
REFERENCES,0.18580375782881003,"Send φ(0)
i
= x(0) to all clients i
Receive c(0)
i
= 1"
REFERENCES,0.18632567849686849,"K
PK−1
k=0 ∇f(φ(0)
i ; z(−1)
i,k ), z(−1)
i,k
∼Di from all clients, c(0) = 1"
REFERENCES,0.18684759916492694,"N
PN
i=1 c(0)
i
for r = 0, . . . , R −1 do"
REFERENCES,0.1873695198329854,"Sample S clients Sr ⊆[1, . . . , N]
Send x(r) to all clients in Sr, Receive {g(r)
i
}i∈Sr = Grad(x(r), Sr, z(r)) (Algo. 7)
g(r) = 1 S
P"
REFERENCES,0.18789144050104384,"i∈Sr g(r)
i
−1 S
P"
REFERENCES,0.1884133611691023,"i∈Sr c(r)
i
+ c(r)"
REFERENCES,0.18893528183716074,x(r+1) = x(r) −η · g(r)
REFERENCES,0.18945720250521922,"Option I: Set c(r+1)
i
= g(r)
i
, φ(r+1)
i
= x(r) for i ∈Sr
Option II: New independent sample of clients S′
r, send x(r) to all clients in S′
r, receive
{˜g(r)
i
}i∈S′r = Grad(x(r), S′
r, ˜z(r)), set c(r+1)
i
= ˜g(r)
i
, φ(r+1)
i
= x(r) for i ∈S′
r"
REFERENCES,0.18997912317327767,"c(r+1)
i
= c(r)
i
and φ(r+1)
i
= φ(r)
i
for any i not yet updated
c(r+1) = 1"
REFERENCES,0.19050104384133612,"N
PN
i=1 c(r+1)
i
end for"
REFERENCES,0.19102296450939457,Published as a conference paper at ICLR 2022
REFERENCES,0.19154488517745302,Algorithm 6 SSNM
REFERENCES,0.19206680584551147,"Input: stepsize η, momentum τ, client losses are Fi(x) = Ezi∼Di[f(x; zi)]+h(x) = ˜Fi(x)+h(x)
where ˜Fi can be general convex and h(x) is µ-strongly convex, initial point x(0)"
REFERENCES,0.19258872651356992,"Send φ(0)
i
= x(0) to all clients i
Receive c(0)
i
= 1"
REFERENCES,0.1931106471816284,"K
PK−1
k=0 ∇f(φ(0)
i ; z(−1)
i,k ), z(−1)
i,k
∼Di from all clients c(0) = 1"
REFERENCES,0.19363256784968685,"N
PN
i=1 c(0)
i
for r = 0, . . . , R −1 do"
REFERENCES,0.1941544885177453,"Sample S clients Sr ⊆[1, . . . , N]
Send x(r) to all clients in Sr, y(r)
ir = τx(r) + (1 −τ)φ(r)
ir for ir ∈Sr
Receive g(r)
ir = 1"
REFERENCES,0.19467640918580376,"K
PK−1
k=0 ∇f(y(r)
ir ; z(r)
ir,k) for ir ∈Sr, z(r)
ir,k ∼Di
g(r) = 1 S
P"
REFERENCES,0.1951983298538622,"ir∈Sr g(r)
ir −1 S
P"
REFERENCES,0.19572025052192066,"ir∈Sr c(r)
ir + c(r)"
REFERENCES,0.19624217118997914,"x(r+1) = arg minx{h(x) + ⟨g(r), x⟩+
1
2η∥x(r) −x∥2}
Sample new independent sample of S clients S′
r ⊆[1, . . . , N]
Send x(r) to all clients in S′
r, φ(r+1)
Ir
= τx(r+1) + (1 −τ)φ(r)
Ir for Ir ∈S′
r
Receive g(r)
Ir = 1"
REFERENCES,0.1967640918580376,"K
PK−1
k=0 ∇f(φ(r+1)
Ir
; ˜z(r)
Ir,k) for Ir ∈S′
r, ˜z(r)
Ir,k ∼Di
c(r+1)
i
= g(r)
Ir for Ir ∈S′
r
c(r+1)
i
= c(r)
i
and φ(r+1)
i
= φ(r)
i
for any i not yet updated
c(r+1) = 1"
REFERENCES,0.19728601252609604,"N
PN
i=1 c(r+1)
i
end for"
REFERENCES,0.1978079331941545,"Algorithm 7 Grad(x, S, z)"
REFERENCES,0.19832985386221294,for client i ∈S in parallel do
REFERENCES,0.1988517745302714,"Client samples g(r)
i,k = ∇f(x(r); z(r)
i,k ) where z(r)
i,k ∼Di, k ∈{0, . . . , K −1}"
REFERENCES,0.19937369519832984,"g(r)
i
= 1"
REFERENCES,0.19989561586638832,"K
PK−1
k=0 g(r)
i,k
end for
return {g(r)
i
}i∈Sr"
REFERENCES,0.20041753653444677,"D
PROOFS FOR GLOBAL UPDATE METHODS"
REFERENCES,0.20093945720250522,"D.1
SGD"
REFERENCES,0.20146137787056367,"Theorem D.1. Suppose that client objectives Fi’s and their gradient queries satisfy Assumption B.4
and Assumption B.6. Then running Algo. 2 gives the following for returned iterate ˆx:"
REFERENCES,0.20198329853862212,"• Strongly convex: Fi’s satisfy Assumption B.1 for µ > 0. If we return ˆx =
1
WR
PR
r=0 wrx(r)"
REFERENCES,0.20250521920668058,"with wr = (1 −ηµ)1−(r+1) and WR = PR
r=0 wr, η = ˜O(min{ 1"
REFERENCES,0.20302713987473903,"β ,
1
µR}), and R > κ,"
REFERENCES,0.2035490605427975,EF(ˆx) −F(x∗) ≤˜O(∆exp(−R
REFERENCES,0.20407098121085596,"κ ) +
σ2"
REFERENCES,0.2045929018789144,µSKR + (1 −S
REFERENCES,0.20511482254697286,N ) ζ2 µSR)
REFERENCES,0.2056367432150313,E∥x(r) −x∗∥2 ≤˜O(D2) for any 0 ≤r ≤R
REFERENCES,0.20615866388308976,"• General convex (grad norm): Fi’s satisfy Assumption B.2. If we return the average iterate
ˆx = 1"
REFERENCES,0.20668058455114824,"R
PR
r=1 x(r), and η = min{ 1"
REFERENCES,0.2072025052192067,"β , ( ∆"
REFERENCES,0.20772442588726514,βcR)1/2} where c is the update variance
REFERENCES,0.2082463465553236,E∥∇F(ˆx)∥2 ≤˜O(β∆
REFERENCES,0.20876826722338204,"R +
βσD
√ SKR
+ r 1 −S"
REFERENCES,0.2092901878914405,"N
βζD
√ SR
)"
REFERENCES,0.20981210855949894,E∥x(r) −x∗∥2 ≤O(D2) for any 0 ≤r ≤R
REFERENCES,0.21033402922755742,Published as a conference paper at ICLR 2022
REFERENCES,0.21085594989561587,"• PL condition: Fi’s satisfy Assumption B.3. If we return the ﬁnal iterate ˆx = x(R), set
η = ˜O(min{ 1"
REFERENCES,0.21137787056367432,"β ,
1
µR}), then"
REFERENCES,0.21189979123173278,EF(x(R)) −F(x∗) ≤˜O(∆exp(−R
REFERENCES,0.21242171189979123,"κ ) +
κσ2"
REFERENCES,0.21294363256784968,µSKR + (1 −S
REFERENCES,0.21346555323590813,N ) κζ2 µSR)
REFERENCES,0.2139874739039666,"Lemma D.2 (Update variance). For SGD, we have that"
REFERENCES,0.21450939457202506,Er∥g(r)∥2 ≤∥∇F(x(r))∥2 + σ2
REFERENCES,0.2150313152400835,SK + (1 −S −1
REFERENCES,0.21555323590814196,N −1)ζ2
REFERENCES,0.2160751565762004,"S
(14)"
REFERENCES,0.21659707724425886,Proof. Observing that
REFERENCES,0.21711899791231734,"Er∥g(r)∥2 = Er∥g(r) −∇F(x(r))∥2 + ∥∇F(x(r))∥2
(15)"
REFERENCES,0.2176409185803758,"and using Lemma H.1, we have"
REFERENCES,0.21816283924843424,Er∥g(r) −∇F(x(r))∥2 ≤σ2
REFERENCES,0.2186847599164927,SK + (1 −S −1
REFERENCES,0.21920668058455114,N −1)ζ2
REFERENCES,0.2197286012526096,"S
(16)"
REFERENCES,0.22025052192066805,"D.1.1
CONVERGENCE OF SGD FOR STRONGLY CONVEX FUNCTIONS"
REFERENCES,0.22077244258872653,"Proof. Using the update of SGD,"
REFERENCES,0.22129436325678498,"∥x(r+1) −x∗∥2 ≤∥x(r) −x∗∥2 −2η⟨g(r), x(r) −x∗⟩+ η2∥g(r)∥2
(17)"
REFERENCES,0.22181628392484343,Taking expectation up to the r-th round
REFERENCES,0.22233820459290188,"Er∥x(r+1) −x∗∥2 ≤∥x(r) −x∗∥2 −2η⟨∇F(x(r)), x(r) −x∗⟩+ η2Er∥g(r)∥2
(18)"
REFERENCES,0.22286012526096033,"By Assumption B.1,"
REFERENCES,0.22338204592901878,"−2η⟨∇F(x(r)), x(r) −x∗⟩≤−2η(F(x(r)) −F(x∗)) −ηµ∥x(r) −x∗∥2
(19)"
REFERENCES,0.22390396659707723,"Using Lemma D.2, Assumption B.4, and setting η ≤
1
2β ,"
REFERENCES,0.2244258872651357,"Er∥x(r+1) −x∗∥2
(20)"
REFERENCES,0.22494780793319416,≤(1 −ηµ)∥x(r) −x∗∥2 −η(F(x(r)) −F(x∗)) + η2( σ2
REFERENCES,0.2254697286012526,SK + (1 −S −1
REFERENCES,0.22599164926931106,N −1)ζ2
REFERENCES,0.2265135699373695,"S )
(21)"
REFERENCES,0.22703549060542796,"Rearranging and taking full expectation,"
REFERENCES,0.22755741127348644,EF(x(r)) −F(x∗) ≤(1 −ηµ)E∥x(r) −x∗∥2 −E∥x(r+1) −x∗∥2
REFERENCES,0.2280793319415449,"η
+ η( σ2"
REFERENCES,0.22860125260960334,SK + (1 −S −1
REFERENCES,0.2291231732776618,N −1)ζ2 S ) (22)
REFERENCES,0.22964509394572025,"letting wr = (1 −µη)1−(r+1), WR = PR
r=0, ˆx =
1
WR
PR
r=0 x(r), then"
REFERENCES,0.2301670146137787,EF(ˆx) −F(x∗) ≤E∥x(0) −x∗∥2
REFERENCES,0.23068893528183715,"ηWR
+ η( σ2"
REFERENCES,0.23121085594989563,SK + (1 −S −1
REFERENCES,0.23173277661795408,N −1)ζ2
REFERENCES,0.23225469728601253,"S )
(23)"
REFERENCES,0.23277661795407098,"From (Karimireddy et al., 2020b) Lemma 1, if R > κ and η = min{ 1"
REFERENCES,0.23329853862212943,"2β , log(max(1,µ2RD2/c))"
REFERENCES,0.23382045929018788,"µR
} where"
REFERENCES,0.23434237995824633,"c =
σ2
NK + (1 −S−1"
REFERENCES,0.2348643006263048,"N−1) ζ2 S ,"
REFERENCES,0.23538622129436326,EF(ˆx) −F(x∗) ≤˜O(∆exp(−R
REFERENCES,0.2359081419624217,"κ ) +
σ2"
REFERENCES,0.23643006263048016,µSKR + (1 −S
REFERENCES,0.23695198329853862,N ) ζ2
REFERENCES,0.23747390396659707,"µSR)
(24)"
REFERENCES,0.23799582463465555,"Which ﬁnishes our work on the convergence rate. Next we consider the distance bound. Returning to
the recurrence"
REFERENCES,0.238517745302714,"Er∥x(r+1) −x∗∥2
(25)"
REFERENCES,0.23903966597077245,≤(1 −ηµ)∥x(r) −x∗∥2 −η(F(x(r)) −F(x∗)) + η2( σ2
REFERENCES,0.2395615866388309,SK + (1 −S −1
REFERENCES,0.24008350730688935,N −1)ζ2
REFERENCES,0.2406054279749478,"S )
(26)"
REFERENCES,0.24112734864300625,Published as a conference paper at ICLR 2022
REFERENCES,0.24164926931106473,"Taking full expectation and unrolling,"
REFERENCES,0.24217118997912318,"E∥x(r) −x∗∥2
(27)"
REFERENCES,0.24269311064718163,≤E∥x(0) −x∗∥2 exp(−ηµr) + η µ( σ2
REFERENCES,0.24321503131524008,SK + (1 −S −1
REFERENCES,0.24373695198329853,N −1)ζ2
REFERENCES,0.24425887265135698,"S )
(28)"
REFERENCES,0.24478079331941544,Note that Karimireddy et al. (2020b) chose η so that η( σ2
REFERENCES,0.2453027139874739,SK + (1 −S−1
REFERENCES,0.24582463465553236,N−1) ζ2
REFERENCES,0.24634655532359082,"S ) ≤˜O(µD2 exp(−µηR))
And so"
REFERENCES,0.24686847599164927,"E∥x(r) −x∗∥2 ≤˜O(D2)
(29)"
REFERENCES,0.24739039665970772,"D.1.2
CONVERGENCE OF SGD FOR GENERAL CONVEX FUNCTIONS"
REFERENCES,0.24791231732776617,"Proof. By smoothness (Assumption B.4), we have that"
REFERENCES,0.24843423799582465,"F(x(r+1)) −F(x(r)) ≤−η⟨∇F(x(r)), g(r)⟩+ βη2"
REFERENCES,0.2489561586638831,"2 ∥g(r)∥2
(30)"
REFERENCES,0.24947807933194155,"Taking expectation conditioned up to r and using Lemma D.2,"
REFERENCES,0.25,ErF(x(r+1)) −F(x(r)) ≤−(η −βη2
REFERENCES,0.25052192066805845,2 )∥∇F(x(r))∥2 + βη2
REFERENCES,0.2510438413361169,2 ( σ2
REFERENCES,0.25156576200417535,SK + (1 −S −1
REFERENCES,0.2520876826722338,N −1)ζ2
REFERENCES,0.25260960334029225,"S )
(31)"
REFERENCES,0.2531315240083507,"If η ≤1 β ,"
REFERENCES,0.2536534446764092,ErF(x(r+1)) −F(x(r)) ≤−η
REFERENCES,0.25417536534446766,2∥∇F(x(r))∥2 + βη2
REFERENCES,0.2546972860125261,2 ( σ2
REFERENCES,0.25521920668058456,SK + (1 −S −1
REFERENCES,0.255741127348643,N −1)ζ2
REFERENCES,0.25626304801670147,"S )
(32)"
REFERENCES,0.2567849686847599,"Taking full expectation and rearranging,"
REFERENCES,0.25730688935281837,"1
2E∥∇F(x(r))∥2 ≤EF(x(r+1)) −EF(x(r))"
REFERENCES,0.2578288100208768,"η
+ βη"
REFERENCES,0.25835073068893527,2 ( σ2
REFERENCES,0.2588726513569937,SK + (1 −S −1
REFERENCES,0.2593945720250522,N −1)ζ2
REFERENCES,0.2599164926931106,"S )
(33)"
REFERENCES,0.26043841336116913,"Summing both sides over r and averaging,"
REFERENCES,0.2609603340292276,"1
2
1
R R−1
X"
REFERENCES,0.26148225469728603,"r=0
E∥∇F(x(r))∥2 ≤EF(x(0)) −EF(x(R))"
REFERENCES,0.2620041753653445,"ηR
+ βη"
REFERENCES,0.26252609603340293,2 ( σ2
REFERENCES,0.2630480167014614,SK + (1 −S −1
REFERENCES,0.26356993736951984,N −1)ζ2
REFERENCES,0.2640918580375783,"S )
(34)"
REFERENCES,0.26461377870563674,"Letting ˆx be an average of all the x(r)’s, noting that EF(x(0)) −EF(x(R)) ≤∆, ∆≤βD2, and
choosing η = min{ 1"
REFERENCES,0.2651356993736952,"β , ( ∆"
REFERENCES,0.26565762004175364,"βcR)1/2} where c =
σ2
SK + (1 −S−1"
REFERENCES,0.2661795407098121,"N−1) ζ2 S ,"
REFERENCES,0.26670146137787054,E∥∇F(ˆx)∥2 ≤˜O(β∆
REFERENCES,0.267223382045929,"R +
βσD
√ SKR
+ r 1 −S"
REFERENCES,0.2677453027139875,"N
βζD
√"
REFERENCES,0.26826722338204595,"SR
)
(35)"
REFERENCES,0.2687891440501044,"So we have our convergence rate. Next, for the distance bound,"
REFERENCES,0.26931106471816285,"∥x(r+1) −x∗∥2 = ∥x(r) −x∗∥2 −2η⟨g(r), x(r) −x∗⟩+ η2∥g(r)∥2
(36)"
REFERENCES,0.2698329853862213,"Taking expectation up to r, we know from Lemma D.2,"
REFERENCES,0.27035490605427975,"Er∥x(r+1) −x∗∥2
(37)"
REFERENCES,0.2708768267223382,"≤∥x(r) −x∗∥2 −2η⟨g(r), x(r) −x∗⟩+ η2∥∇F(x(r))∥2 + η2( σ2"
REFERENCES,0.27139874739039666,SK + (1 −S N )ζ2
REFERENCES,0.2719206680584551,"S )
(38)"
REFERENCES,0.27244258872651356,"By Assumption B.2 and Assumption B.4,"
REFERENCES,0.272964509394572,"Er∥x(r+1) −x∗∥2
(39)"
REFERENCES,0.27348643006263046,≤∥x(r) −x∗∥2 −2η(1 −βη)(F(x(r)) −F(x∗)) + η2( σ2
REFERENCES,0.2740083507306889,SK + (1 −S N )ζ2
REFERENCES,0.2745302713987474,"S )
(40)"
REFERENCES,0.27505219206680587,Published as a conference paper at ICLR 2022
REFERENCES,0.2755741127348643,"And with η ≤1 β ,"
REFERENCES,0.27609603340292277,Er∥x(r+1) −x∗∥2 ≤∥x(r) −x∗∥2 + η2( σ2
REFERENCES,0.2766179540709812,SK + (1 −S N )ζ2
REFERENCES,0.27713987473903967,"S )
(41)"
REFERENCES,0.2776617954070981,"Unrolling and taking full expectation,"
REFERENCES,0.2781837160751566,E∥x(r) −x∗∥2 ≤E∥x(0) −x∗∥2 + η2R( σ2
REFERENCES,0.278705636743215,SK + (1 −S N )ζ2
REFERENCES,0.2792275574112735,"S )
(42)"
REFERENCES,0.2797494780793319,We chose η so that βη( σ2
REFERENCES,0.2802713987473904,SK + (1 −S
REFERENCES,0.2807933194154488,N ) ζ2
REFERENCES,0.28131524008350733,"S ) ≤
∆
ηR. Therefore"
REFERENCES,0.2818371607515658,E∥x(r) −x∗∥2 ≤E∥x(0) −x∗∥2 + ∆
REFERENCES,0.28235908141962424,"β ≤2D2
(43)"
REFERENCES,0.2828810020876827,"D.1.3
CONVERGENCE OF SGD UNDER THE PL-CONDITION"
REFERENCES,0.28340292275574114,Proof. Using Assumption B.4 we have that
REFERENCES,0.2839248434237996,"F(x(r+1)) −F(x(r)) ≤−η⟨∇F(x(r)), g(r)⟩+ βη2"
REFERENCES,0.28444676409185804,"2 ∥g(r)∥2
(44)"
REFERENCES,0.2849686847599165,"Taking expectations of both sides conditioned on the r-th step,"
REFERENCES,0.28549060542797494,ErF(x(r+1)) −F(x(r)) ≤−η∥F(x(r))∥2 + βη2
REFERENCES,0.2860125260960334,"2 Er∥g(r)∥2
(45)"
REFERENCES,0.28653444676409184,"Using Lemma D.2,"
REFERENCES,0.2870563674321503,ErF(x(r+1)) −F(x(r)) ≤−η
REFERENCES,0.28757828810020875,2∥F(x(r))∥2 + βη2
REFERENCES,0.2881002087682672,2 ( σ2
REFERENCES,0.2886221294363257,SK + (1 −S −1
REFERENCES,0.28914405010438415,N −1)ζ2
REFERENCES,0.2896659707724426,"S )
(46)"
REFERENCES,0.29018789144050106,"Using Assumption B.3, we have that"
REFERENCES,0.2907098121085595,ErF(x(r+1)) −F(x(r)) ≤−ηµ(F(x(r)) −F(x∗)) + βη2
REFERENCES,0.29123173277661796,2 ( σ2
REFERENCES,0.2917536534446764,SK + (1 −S −1
REFERENCES,0.29227557411273486,N −1)ζ2
REFERENCES,0.2927974947807933,"S )
(47)"
REFERENCES,0.29331941544885176,"Rearranging,"
REFERENCES,0.2938413361169102,ErF(x(r+1)) −F(x∗) ≤(1 −ηµ)(F(x(r)) −F(x∗)) + βη2
REFERENCES,0.29436325678496866,2 ( σ2
REFERENCES,0.2948851774530271,SK + (1 −S −1
REFERENCES,0.2954070981210856,N −1)ζ2
REFERENCES,0.29592901878914407,"S )
(48)"
REFERENCES,0.2964509394572025,"Letting c =
σ2
SK + (1 −S−1"
REFERENCES,0.296972860125261,N−1) ζ2
REFERENCES,0.2974947807933194,S and subtracting βcη
REFERENCES,0.2980167014613779,"2µ from both sides,"
REFERENCES,0.2985386221294363,ErF(x(r+1)) −F(x∗) −βcη
REFERENCES,0.2990605427974948,2µ ≤(1 −ηµ)(F(x(r)) −F(x∗) −βcη
REFERENCES,0.29958246346555323,"2µ )
(49)"
REFERENCES,0.3001043841336117,"Which, upon unrolling the recursion, gives us"
REFERENCES,0.30062630480167013,EF(x(R)) −F(x∗) ≤∆exp(−ηµR) + βcη
REFERENCES,0.3011482254697286,"2µ
(50)"
REFERENCES,0.30167014613778703,"Now, if we choose stepsize"
REFERENCES,0.30219206680584554,η = min{ 1
REFERENCES,0.302713987473904,"β ,
log(max{e, µ2∆R βc })"
REFERENCES,0.30323590814196244,"µR
}
(51)"
REFERENCES,0.3037578288100209,Then the ﬁnal convergence rate is
REFERENCES,0.30427974947807934,EF(x(R)) −F(x∗) ≤˜O(∆exp(−R
REFERENCES,0.3048016701461378,"κ ) +
κσ2"
REFERENCES,0.30532359081419624,µSKR + (1 −S
REFERENCES,0.3058455114822547,N ) κζ2
REFERENCES,0.30636743215031315,"µSR)
(52)"
REFERENCES,0.3068893528183716,Published as a conference paper at ICLR 2022
REFERENCES,0.30741127348643005,"D.2
ASG"
REFERENCES,0.3079331941544885,"The precise form of accelerated stochastic gradient we run is AC-SA(Ghadimi & Lan, 2012; 2013).
The following speciﬁcation is taken from Woodworth et al. (2020a):"
REFERENCES,0.30845511482254695,"We run Algo. 3 for Rs iterations using x(0) = ps−1, {αt}t≥1 and {γt}t≥1, with deﬁnitions"
REFERENCES,0.3089770354906054,"• Rs = ⌈max{4
q 4β"
REFERENCES,0.3094989561586639,"µ ,
128c
3µ∆2−(s+1) }⌉"
REFERENCES,0.31002087682672236,"• αr =
2
r+1, γr =
4φs
r(r+1),"
REFERENCES,0.3105427974947808,"• φs = max{2β, [
µc
3∆2−(s−1)Rs(Rs+1)(Rs+2)]1/2}"
REFERENCES,0.31106471816283926,"Where c =
σ2
SK + (1 −S−1"
REFERENCES,0.3115866388308977,N−1) ζ2
REFERENCES,0.31210855949895616,"S . Set ps = x(Rs)
ag
where x(Rs)
ag
is the solution obtained in the previous
step.
Theorem D.3. Suppose that client objectives Fi’s and their gradient queries satisfy Assumption B.4
and Assumption B.6. Then running Algo. 3 gives the following for returned iterate ˆx:"
REFERENCES,0.3126304801670146,"• Strongly convex: Fi’s satisfy Assumption B.1 for µ > 0. If we return ˆx = x(Rs)
ag
after R
rounds of the multistage AC-SA speciﬁed above,"
REFERENCES,0.31315240083507306,"EF(ˆx) −F(x∗) ≤O(∆exp(−R
√κ) +
σ2"
REFERENCES,0.3136743215031315,µSKR + (1 −S
REFERENCES,0.31419624217118997,N ) ζ2 µSR)
REFERENCES,0.3147181628392484,"E∥ˆx −x∗∥2 ≤O(κE∥x(0) −x∗∥2 exp(−R
√κ) +
σ2"
REFERENCES,0.31524008350730687,µ2SKR + (1 −S
REFERENCES,0.3157620041753653,"N )
ζ2 µ2SR)"
REFERENCES,0.3162839248434238,"And given no randomness, for any 0 ≤r ≤R"
REFERENCES,0.3168058455114823,∥x(r) −x∗∥2 ≤∥x(0) −x∗∥2
REFERENCES,0.3173277661795407,"∥x(r)
ag −x∗∥2 ≤∥x(0) −x∗∥2"
REFERENCES,0.3178496868475992,and for any 1 ≤r ≤R
REFERENCES,0.31837160751565763,"∥x(r)
md −x∗∥2 ≤∥x(0) −x∗∥2"
REFERENCES,0.3188935281837161,"• General convex (grad norm): Fi’s satisfy Assumption B.2. If we return ˆx = x(Rs)
ag
after
R rounds of the multistage AC-SA speciﬁed above on the regularized objective Fµ(x) ="
REFERENCES,0.31941544885177453,F(x) + µ
REFERENCES,0.319937369519833,2 ∥x(0) −x∥2 with µ = max{ 2β
REFERENCES,0.32045929018789143,"R2 log2(e2 + R2),
q"
REFERENCES,0.3209812108559499,"βσ2
∆SKR,
q (1−S"
REFERENCES,0.32150313152400833,N )βζ2
REFERENCES,0.3220250521920668,"∆SR
}, we have"
REFERENCES,0.32254697286012524,E∥∇F(ˆx)∥2 ≤˜O(β∆
REFERENCES,0.32306889352818374,"R2 +
σ2"
REFERENCES,0.3235908141962422,SKR + (1 −S
REFERENCES,0.32411273486430064,N ) ζ2
REFERENCES,0.3246346555323591,"SR +
βσD
√ SKR
+ r 1 −S"
REFERENCES,0.32515657620041755,"N
ζD
√ SR
)"
REFERENCES,0.325678496868476,E∥ˆx −x∗∥2 ≤˜O(D2)
REFERENCES,0.32620041753653445,"D.2.1
CONVERGENCE OF ASG FOR STRONGLY CONVEX FUNCTIONS"
REFERENCES,0.3267223382045929,"Proof. The convergence rate proof comes from Woodworth et al. (2020a) Lemma 5. What remains is
to show the distance bound."
REFERENCES,0.32724425887265135,"From Proposition 5, (Eq. 3.25, 4.25) of Ghadimi & Lan (2012), we have that the generic (non-
multistage) AC-SA satisﬁes (together with Lemma H.1)"
REFERENCES,0.3277661795407098,"EF(x(r)
ag ) + µE∥x(r) −x∗∥2 −F(x)
(53) ≤Γr r
X τ=1"
REFERENCES,0.32828810020876825,"γτ
Γτ
[E∥x(τ−1) −x∗∥2 −E∥x(τ) −x∗∥2] + Γr
4r"
REFERENCES,0.3288100208768267,µ ( σ2
REFERENCES,0.32933194154488515,SK + (1 −S N )ζ2
REFERENCES,0.3298538622129436,"S )
(54)"
REFERENCES,0.3303757828810021,Published as a conference paper at ICLR 2022
REFERENCES,0.33089770354906056,"Where Γr =
1, r = 1
(1 −αr)Γr−1 r ≥2
Notice that Γr r
X τ=1"
REFERENCES,0.331419624217119,"γτ
Γτ
[E∥x(τ−1) −x∗∥2 −E∥x(τ) −x∗∥2] = Γtγ1[∥x(0) −x∗∥2 −∥x(r) −x∗∥2]
(55) So"
REFERENCES,0.33194154488517746,"(µ + Γtγ1)E∥x(r) −x∗∥2 ≤Γtγ1E∥x(0) −x∗∥2 + Γr
4r"
REFERENCES,0.3324634655532359,µ ( σ2
REFERENCES,0.33298538622129437,SK + (1 −S N )ζ2
REFERENCES,0.3335073068893528,"S )
(56)"
REFERENCES,0.33402922755741127,Which implies
REFERENCES,0.3345511482254697,"E∥x(r) −x∗∥2 ≤E∥x(0) −x∗∥2 + Γr
4r
µ2 ( σ2"
REFERENCES,0.33507306889352817,SK + (1 −S N )ζ2
REFERENCES,0.3355949895615866,"S )
(57)"
REFERENCES,0.33611691022964507,"Furthermore, Γr =
2
r(r+1) so"
REFERENCES,0.3366388308977035,"E∥x(r) −x∗∥2 ≤E∥x(0) −x∗∥2 +
8
µ2(r + 1)( σ2"
REFERENCES,0.33716075156576203,SK + (1 −S N )ζ2
REFERENCES,0.3376826722338205,"S )
(58)"
REFERENCES,0.33820459290187893,"If there is no gradient variance or sampling,"
REFERENCES,0.3387265135699374,"∥x(r) −x∗∥2 ≤∥x(0) −x∗∥2
(59)"
REFERENCES,0.33924843423799583,"Next, we show the above two conclusions hold for x(r)
md and x(r)
ag ."
REFERENCES,0.3397703549060543,"For x(r)
ag , we show by induction:"
REFERENCES,0.34029227557411273,"Base case: x(r)
ag = x(0), so it is true"
REFERENCES,0.3408141962421712,"Inductive case: x(r)
ag is a convex combination of x(r) and x(r−1)
ag
, so the above statements hold for
x(r)
ag as well."
REFERENCES,0.34133611691022964,"For x(r)
md , note it is a convex combination of x(r−1)
ag
and x(r−1), so the above statements on distance
also hold for x(r)
md ."
REFERENCES,0.3418580375782881,"For the distance bound on the returned solution, use strong convexity on the convergence rate:"
REFERENCES,0.34237995824634654,"E∥ˆx −x∗∥2 ≤O(κE∥x(0) −x∗∥2 exp(−R
√κ) +
c
µ2R)
(60)"
REFERENCES,0.342901878914405,"D.2.2
CONVERGENCE OF ASG FOR GENERAL CONVEX FUNCTIONS"
REFERENCES,0.34342379958246344,"For the general convex case, we use Nesterov smoothing. Concretely, we will run Algo. 3 assuming
strong convexity by optimizing instead a modiﬁed objective"
REFERENCES,0.34394572025052195,Fµ(x) = F(x) + µ
REFERENCES,0.3444676409185804,"2 ∥x(0) −x∥2
(61)"
REFERENCES,0.34498956158663885,"Deﬁne x∗
µ = arg minx Fµ(x) and ∆µ = EFµ(x(0)) −F(x∗
µ). We will choose µ carefully to balance
the error introduced by the regularization term and the better convergence properties of having larger
µ."
REFERENCES,0.3455114822546973,Proof. Observe that
REFERENCES,0.34603340292275575,"E∥∇F(ˆx)∥2 = E∥∇Fµ(ˆx) −µ(ˆx −x(0))∥2 ≤2E∥∇Fµ(ˆx)∥2 + 2µ2E∥ˆx −x(0)∥2
(62)"
REFERENCES,0.3465553235908142,"We evaluate the second term ﬁrst. We know that from the theorem statement on strongly convex
functions and letting κ′ = β+µ"
REFERENCES,0.34707724425887265,"µ
and κ = β"
REFERENCES,0.3475991649269311,"µ because F is now β + µ-smooth,"
REFERENCES,0.34812108559498955,"EFµ(ˆx) −Fµ(x∗
µ) ≤O((EFµ(x(0)) −Fµ(x∗
µ)) exp(−R
√"
REFERENCES,0.348643006263048,"κ′ ) +
σ2"
REFERENCES,0.34916492693110646,µSKR + (1 −S
REFERENCES,0.3496868475991649,N ) ζ2
REFERENCES,0.35020876826722336,µSR) (63)
REFERENCES,0.35073068893528186,Published as a conference paper at ICLR 2022
REFERENCES,0.3512526096033403,Which implies
REFERENCES,0.35177453027139877,"EFµ(ˆx) ≤O(EFµ(x(0)) +
σ2"
REFERENCES,0.3522964509394572,µSKR + (1 −S
REFERENCES,0.35281837160751567,N ) ζ2
REFERENCES,0.3533402922755741,"µSR)
(64)"
REFERENCES,0.35386221294363257,"= O(EF(x(0)) +
σ2"
REFERENCES,0.354384133611691,µSKR + (1 −S
REFERENCES,0.35490605427974947,N ) ζ2
REFERENCES,0.3554279749478079,"µSR)
(65)"
REFERENCES,0.3559498956158664,So it is true that
REFERENCES,0.3564718162839248,EFµ(ˆx) = E[F(ˆx) + µ
REFERENCES,0.3569937369519833,"2 ∥ˆx −x(0)∥2]
(66)"
REFERENCES,0.3575156576200417,"= O(EF(x(0)) +
σ2"
REFERENCES,0.35803757828810023,µSKR + (1 −S
REFERENCES,0.3585594989561587,N ) ζ2
REFERENCES,0.35908141962421714,"µSR)
(67)"
REFERENCES,0.3596033402922756,"If we rearrange, µ"
REFERENCES,0.36012526096033404,"2 E∥ˆx −x(0)∥2 ≤O(EF(x(0)) −F(ˆx) +
σ2"
REFERENCES,0.3606471816283925,µSKR + (1 −S
REFERENCES,0.36116910229645094,N ) ζ2
REFERENCES,0.3616910229645094,"µSR)
(68)"
REFERENCES,0.36221294363256784,"≤O(EF(x(0)) −F(x∗) +
σ2"
REFERENCES,0.3627348643006263,µSKR + (1 −S
REFERENCES,0.36325678496868474,N ) ζ2
REFERENCES,0.3637787056367432,"µSR)
(69)"
REFERENCES,0.36430062630480164,"≤O(∆+
σ2"
REFERENCES,0.36482254697286015,µSKR + (1 −S
REFERENCES,0.3653444676409186,N ) ζ2
REFERENCES,0.36586638830897705,"µSR)
(70)"
REFERENCES,0.3663883089770355,"Next we evaluate 2E∥∇Fµ(ˆx)∥2. Observe that the smoothness of Fµ is β + µ. Returning to the
convergence rate,"
REFERENCES,0.36691022964509395,"EFµ(ˆx) −Fµ(x∗
µ) ≤O(∆µ exp(−R
√"
REFERENCES,0.3674321503131524,"κ′ ) +
σ2"
REFERENCES,0.36795407098121086,µSKR + (1 −S
REFERENCES,0.3684759916492693,N ) ζ2
REFERENCES,0.36899791231732776,"µSR)
(71)"
REFERENCES,0.3695198329853862,We have that
REFERENCES,0.37004175365344466,"Fµ(x(0)) −Fµ(x∗
µ) = F(x(0)) −F(x∗
µ) −µ"
REFERENCES,0.3705636743215031,"2 ∥x(0) −x∗
µ∥2 ≤F(x(0)) −F(x∗)
(72)"
REFERENCES,0.37108559498956156,"So ∆µ ≤∆. By Assumption B.4,"
REFERENCES,0.37160751565762007,"E∥∇Fµ(ˆx)∥2 ≤(β + µ)O(∆exp(−R
√"
REFERENCES,0.3721294363256785,"κ′ ) +
σ2"
REFERENCES,0.37265135699373697,µSKR + (1 −S
REFERENCES,0.3731732776617954,N ) ζ2
REFERENCES,0.3736951983298539,"µSR)
(73)"
REFERENCES,0.3742171189979123,"≤O(β∆exp(−R
√"
REFERENCES,0.3747390396659708,"κ′ ) + µ∆+
βσ2"
REFERENCES,0.3752609603340292,"µSKR +
σ2"
REFERENCES,0.3757828810020877,SKR + (1 −S
REFERENCES,0.3763048016701461,N ) ζ2
REFERENCES,0.3768267223382046,SR + (1 −S
REFERENCES,0.37734864300626303,N ) βζ2 µSR) (74)
REFERENCES,0.3778705636743215,"So altogether,"
REFERENCES,0.37839248434237993,"E∥∇F(ˆx)∥2 ≤O(β∆exp(−R
√"
REFERENCES,0.37891440501043844,κ′ ) + (1 + κ) σ2
REFERENCES,0.3794363256784969,SKR + (1 + κ)(1 −S
REFERENCES,0.37995824634655534,N ) ζ2
REFERENCES,0.3804801670146138,"SR + µ∆)
(75)"
REFERENCES,0.38100208768267224,Choose µ = max{ 2β
REFERENCES,0.3815240083507307,"R2 log2(e2 + R2),
q"
REFERENCES,0.38204592901878914,"βσ2
∆SKR,
q (1−S"
REFERENCES,0.3825678496868476,N )βζ2
REFERENCES,0.38308977035490605,"∆SR
}. By Theorem E.1’s proof in Yuan &
Ma (2020),"
REFERENCES,0.3836116910229645,E∥∇F(ˆx)∥2 ≤˜O(β∆
REFERENCES,0.38413361169102295,"R2 +
σ2"
REFERENCES,0.3846555323590814,SKR + (1 −S
REFERENCES,0.38517745302713985,N ) ζ2
REFERENCES,0.38569937369519836,"SR +
βσD
√ SKR
+ r 1 −S"
REFERENCES,0.3862212943632568,"N
ζD
√"
REFERENCES,0.38674321503131526,"SR
)
(76)"
REFERENCES,0.3872651356993737,"Next we evaluate the distance bound for the returned iterate. Observe that from the distance bound in
the strongly convex case,"
REFERENCES,0.38778705636743216,"E∥ˆx −x∗
µ∥2 ≤O(β + µ"
REFERENCES,0.3883089770354906,"µ
E∥x(0) −x∗
µ∥2 exp(−R
√κ) +
σ2"
REFERENCES,0.38883089770354906,µ2SKR + (1 −S
REFERENCES,0.3893528183716075,"N )
ζ2"
REFERENCES,0.38987473903966596,"µ2SR)
(77)"
REFERENCES,0.3903966597077244,Given that µ = max{ 2β
REFERENCES,0.39091858037578286,"R2 log2(e2 + R2),
q"
REFERENCES,0.3914405010438413,"βσ2
∆SKR,
q (1−S"
REFERENCES,0.39196242171189977,N )βζ2
REFERENCES,0.3924843423799583,"∆SR
},"
REFERENCES,0.3930062630480167,"E∥ˆx −x∗
µ∥2 ≤O(E∥x(0) −x∗
µ∥2 + ∥ˆx −x∗
µ∥2)
(78)"
REFERENCES,0.3935281837160752,"≤˜O(E∥x(0) −x∗
µ∥2)
(79)"
REFERENCES,0.3940501043841336,Published as a conference paper at ICLR 2022
REFERENCES,0.3945720250521921,Now we look at the actual distance we want to bound:
REFERENCES,0.39509394572025053,"E∥ˆx −x∗∥2 ≤˜O(E∥ˆx −x∗
µ∥2 + E∥x∗
µ −x(0)∥2 + E∥x∗−x(0)∥2)
(80) (81)"
REFERENCES,0.395615866388309,Observe that
REFERENCES,0.39613778705636743,"Fµ(x∗
µ) = F(x∗
µ) + ∥x(0) −x∗
µ∥2 ≤F(x∗) + ∥x(0) −x∗∥2 = Fµ(x∗)
(82)"
REFERENCES,0.3966597077244259,which implies that
REFERENCES,0.39718162839248433,"∥x(0) −x∗
µ∥2 ≤∥x(0) −x∗∥2
(83)"
REFERENCES,0.3977035490605428,So altogether
REFERENCES,0.39822546972860123,"E∥ˆx −x∗∥2 ≤˜O(D2)
(84)"
REFERENCES,0.3987473903966597,"D.3
SAGA"
REFERENCES,0.39926931106471814,"Theorem D.4. Suppose that client objectives Fi’s and their gradient queries satisfy Assumption B.4
and Assumption B.6. Then running Algo. 5 gives the following for returned iterate ˆx:"
REFERENCES,0.39979123173277664,"• Strongly convex: Fi’s satisfy Assumption B.1 for µ > 0. If we return ˆx =
1
WR
PR
r=0 wrx(r)"
REFERENCES,0.4003131524008351,"with wr = (1 −ηµ)1−(r+1) and WR = PR
r=0 wr, η = ˜O(min{ 1"
REFERENCES,0.40083507306889354,"β ,
1
µR}), R > κ, and we
use Option I,"
REFERENCES,0.401356993736952,"EF(ˆx) −F(x∗) ≤˜O(∆exp(−min{µ β , S"
REFERENCES,0.40187891440501045,"N }R) +
σ2"
REFERENCES,0.4024008350730689,µRKS )
REFERENCES,0.40292275574112735,"• PL condition: Fi’s satisfy Assumption B.3. If we set η =
1
3β(N/S)2/3 , use Option II in a
multistage manner (details speciﬁed in proof), and return a uniformly sampled iterate from
the ﬁnal stage,"
REFERENCES,0.4034446764091858,"EF(ˆx) −F(x∗) ≤O(∆exp(−
R
κ(N/S)2/3 ) +
σ2"
REFERENCES,0.40396659707724425,"µSK )
(85)"
REFERENCES,0.4044885177453027,"D.3.1
CONVERGENCE OF SAGA FOR STRONGLY CONVEX FUNCTIONS"
REFERENCES,0.40501043841336115,"The proof of this is similar to that of Karimireddy et al. (2020b, Theorem VII)."
REFERENCES,0.4055323590814196,"Proof. Following the standard analysis,"
REFERENCES,0.40605427974947805,"Er∥x(r+1) −x∗∥2
(86)"
REFERENCES,0.40657620041753656,"= ∥x(r) −x∗∥2 −2ηEr⟨g(r), x(r) −x∗⟩+ Er∥ηg(r)∥2
(87)
(88)"
REFERENCES,0.407098121085595,We treat each of these terms separately.
REFERENCES,0.40762004175365346,Second term: Observe ﬁrst that
REFERENCES,0.4081419624217119,Erg(r) = Er( 1 S X
REFERENCES,0.40866388308977036,"i∈Sr
[ 1 K K−1
X"
REFERENCES,0.4091858037578288,"k=0
∇f(x(r); z(r)
i,k ) −c(r)
i ] + c(r))
(89)"
REFERENCES,0.40970772442588727,"= ∇F(x(r))
(90)"
REFERENCES,0.4102296450939457,"And so the middle term has, by (strong) convexity,"
REFERENCES,0.41075156576200417,"−2ηEr⟨g(r), x(r) −x∗⟩= −2η⟨∇F(x(r)), x(r) −x∗⟩
(91)"
REFERENCES,0.4112734864300626,≤−2η(F(x(r)) −F(x∗) + µ
REFERENCES,0.41179540709812107,"2 ∥x(r) −x∗∥2)
(92)"
REFERENCES,0.4123173277661795,Published as a conference paper at ICLR 2022
REFERENCES,0.41283924843423797,Third term:
REFERENCES,0.4133611691022965,"Er∥ηg(r)∥2
(93)"
REFERENCES,0.41388308977035493,= Er∥η( 1 S X
REFERENCES,0.4144050104384134,"i∈Sr
[ 1 K K−1
X"
REFERENCES,0.41492693110647183,"k=0
∇f(x(r); z(r)
i,k ) −c(r)
i ] + c(r))∥2
(94)"
REFERENCES,0.4154488517745303,= η2Er∥1 KS X
REFERENCES,0.41597077244258873,"k,i∈Sr
∇f(x(r); z(r)
i,k ) −c(r)
i
+ c(r)∥2
(95)"
REFERENCES,0.4164926931106472,≤4η2Er∥1 KS X
REFERENCES,0.41701461377870563,"k,i∈Sr
∇f(x(r); z(r)
i,k ) −∇Fi(x(r))∥2 + 4η2Er∥c(r)∥2
(96)"
REFERENCES,0.4175365344467641,+ 4η2Er∥1 KS X
REFERENCES,0.41805845511482254,"k,i∈Sr
∇Fi(x∗) −c(r)
i ∥2 + 4η2Er∥1 KS X"
REFERENCES,0.418580375782881,"k,i∈Sr
∇Fi(x(r)) −∇Fi(x∗)∥2
(97) (98)"
REFERENCES,0.41910229645093944,"Where the last inequality comes from the relaxed triangle inequality. Then, by using Assumption B.6,
Assumption B.4, and Assumption B.2,"
REFERENCES,0.4196242171189979,"Er∥ηg(r)∥2
(99)"
REFERENCES,0.4201461377870564,≤4η2Er∥c(r)∥2 + 4η2Er∥1 KS X
REFERENCES,0.42066805845511485,"k,i∈Sr
∇Fi(x∗) −c(r)
i ∥2 + 8βη2[F(x(r)) −F(x∗)] + 4η2σ2 KS (100)"
REFERENCES,0.4211899791231733,"Taking full expectation and separating out the variance of the control variates,"
REFERENCES,0.42171189979123175,"E∥ηg(r)∥2
(101)"
REFERENCES,0.4222338204592902,≤4η2∥Ec(r)∥2 + 4η2∥1 KS X
REFERENCES,0.42275574112734865,"k,i∈Sr
∇Fi(x∗) −Ec(r)
i ∥2 + 8βη2E[F(x(r)) −F(x∗)] + 12η2σ2 KS (102)"
REFERENCES,0.4232776617954071,Now observe that because c(r) = 1
REFERENCES,0.42379958246346555,"N
PN
i=1 c(r)
i ,"
REFERENCES,0.424321503131524,"E∥ηg(r)∥2 ≤8η2 N N
X"
REFERENCES,0.42484342379958245,"i=1
∥∇Fi(x∗) −Ec(r)
i ∥2 + 8βη2E[F(x(r)) −F(x∗)] + 12η2σ2"
REFERENCES,0.4253653444676409,"KS
(103)"
REFERENCES,0.42588726513569936,≤8η2Cr + 8βη2E[F(x(r)) −F(x∗)] + 12η2σ2
REFERENCES,0.4264091858037578,"KS
(104)"
REFERENCES,0.42693110647181626,Bounding the control lag:
REFERENCES,0.42745302713987476,Recall that
REFERENCES,0.4279749478079332,"c(r+1)
i
="
REFERENCES,0.42849686847599167,"(
c(r)
i
w.p. 1 −S"
REFERENCES,0.4290187891440501,"N
1
K
PK−1
k=0 ∇f(x(r); z(r)
i,k ) w.p. S"
REFERENCES,0.42954070981210857,"N
(105)"
REFERENCES,0.430062630480167,Therefore
REFERENCES,0.43058455114822547,"Ec(r+1)
i
= (1 −S"
REFERENCES,0.4311064718162839,"N )E[c(r)
i ] + S"
REFERENCES,0.43162839248434237,"N E∇Fi(x(r))
(106)"
REFERENCES,0.4321503131524008,"Returning to the deﬁnition of Cr+1,"
REFERENCES,0.4326722338204593,"Cr+1 = 1 N N
X"
REFERENCES,0.4331941544885177,"i=1
E∥E[c(r+1)
i
] −∇Fi(x∗)∥2
(107) = 1 N N
X"
REFERENCES,0.4337160751565762,"i=1
E∥(1 −S"
REFERENCES,0.4342379958246347,"N )(E[c(r)
i ] −∇Fi(x∗)) + S"
REFERENCES,0.43475991649269313,"N (E∇Fi(x(r)) −∇Fi(x∗))∥2
(108)"
REFERENCES,0.4352818371607516,≤(1 −S
REFERENCES,0.43580375782881003,"N )Cr + S N 2 N
X"
REFERENCES,0.4363256784968685,"i=1
E∥∇Fi(x(r)) −∇Fi(x∗)∥2
(109)"
REFERENCES,0.43684759916492694,Published as a conference paper at ICLR 2022
REFERENCES,0.4373695198329854,"where in the last inequality we applied Jensen’s inequality twice. By smoothness of Fi’s (Assump-
tion B.4),"
REFERENCES,0.43789144050104384,Cr+1 ≤(1 −S
REFERENCES,0.4384133611691023,N )Cr + 2βS
REFERENCES,0.43893528183716074,"N [EF(x(r)) −F(x∗)]
(110)"
REFERENCES,0.4394572025052192,Putting it together:
REFERENCES,0.43997912317327764,"So putting it all together, we have"
REFERENCES,0.4405010438413361,"E∥x(r+1) −x∗∥2
(111)"
REFERENCES,0.4410229645093946,≤(1 −ηµ)E∥x(r) −x∗∥2 −η(2 −8βη)(EF(x(r)) −F(x∗)) + 8η2Cr + 12η2σ2
REFERENCES,0.44154488517745305,"KS
(112)"
REFERENCES,0.4420668058455115,"From our bound on the control lag,
9η2N"
REFERENCES,0.44258872651356995,"S
Cr+1 ≤9η2N"
REFERENCES,0.4431106471816284,"S
(1 −S"
REFERENCES,0.44363256784968685,"N )Cr + 18βη2[EF(x(r)) −F(x∗)]
(113)"
REFERENCES,0.4441544885177453,= (1 −ηµ)9η2N
REFERENCES,0.44467640918580376,"S
Cr + 9η2(ηµN"
REFERENCES,0.4451983298538622,"S
−1)Cr + 18βη2[EF(x(r)) −F(x∗)]
(114)"
REFERENCES,0.44572025052192066,"Adding both inequalities, we have"
REFERENCES,0.4462421711899791,E∥x(r+1) −x∗∥2 + 9η2N
REFERENCES,0.44676409185803756,"S
Cr+1
(115)"
REFERENCES,0.447286012526096,≤(1 −ηµ)[E∥x(r) −x∗∥2 + 9η2N
REFERENCES,0.44780793319415446,"S
Cr] −η(2 −26βη)(EF(x(r)) −F(x∗))
(116)"
REFERENCES,0.44832985386221297,+ η2(9ηµN
REFERENCES,0.4488517745302714,"S
−1)Cr + 12η2σ2"
REFERENCES,0.44937369519832987,"KS
(117)"
REFERENCES,0.4498956158663883,"Let η ≤
1
26β , η ≤
S
9µN , then"
REFERENCES,0.45041753653444677,E∥x(r+1) −x∗∥2 + 9η2N
REFERENCES,0.4509394572025052,"S
Cr+1
(118)"
REFERENCES,0.4514613778705637,≤(1 −ηµ)[E∥x(r) −x∗∥2 + 9η2N
REFERENCES,0.4519832985386221,"S
Cr] −η(EF(x(r)) −F(x∗)) + 12η2σ2"
REFERENCES,0.4525052192066806,"KS
(119)"
REFERENCES,0.453027139874739,"Then by using Lemma 1 in (Karimireddy et al., 2020b), setting ηmax = min{
1
26β ,
S
9µN }, R ≥
1
2ηmaxµ,"
REFERENCES,0.4535490605427975,"and choosing η = min{ log(max(1,µ2Rd0/c))"
REFERENCES,0.45407098121085593,"µR
, ηmax} where d0 = E∥x(0) −x∗∥2 + 9Nη2"
REFERENCES,0.4545929018789144,"S
C0 and"
REFERENCES,0.4551148225469729,"c =
12σ2"
REFERENCES,0.45563674321503134,"KS , we have that by outputting ˆx =
1
WR
PR
r=0 wrx(r) with WR = PR
r=0 wr and wr =
(1 −µη)1−r, we have"
REFERENCES,0.4561586638830898,"EF(ˆx) −F(x∗) ≤˜O(µd0 exp(−µηmaxR) +
c
µR)
(120)"
REFERENCES,0.45668058455114824,"= ˜O(µd0 exp(−µηmaxR) +
c
µR)
(121)"
REFERENCES,0.4572025052192067,= ˜O(µ[E∥x(0) −x∗∥2 + Nη2
REFERENCES,0.45772442588726514,"S C0] exp(−µηmaxR) +
σ2"
REFERENCES,0.4582463465553236,"µRKS )
(122)"
REFERENCES,0.45876826722338204,We use a warm-start strategy to initialize all control variates in the ﬁrst N/S rounds such that
REFERENCES,0.4592901878914405,"c(0)
i
= 1 K K−1
X"
REFERENCES,0.45981210855949894,"k=0
∇f(x(0); z(−1)
i,k )"
REFERENCES,0.4603340292275574,"By smoothness of Fi’s (Assumption B.4),"
REFERENCES,0.46085594989561585,"C0 = 1 N N
X"
REFERENCES,0.4613778705636743,"i=1
E∥Ec(0)
i
−∇Fi(x∗)∥2
(123) = 1 N N
X"
REFERENCES,0.4618997912317328,"i=1
E∥∇Fi(x(0)) −∇Fi(x∗)∥2
(124)"
REFERENCES,0.46242171189979125,"≤βE(F(x(0)) −F(x∗))
(125)"
REFERENCES,0.4629436325678497,Published as a conference paper at ICLR 2022
REFERENCES,0.46346555323590816,"And recalling that η ≤min{
1
26β ,
S
9µN }, we know that 9Nη2"
REFERENCES,0.4639874739039666,"S
C0 ≤9Nη2"
REFERENCES,0.46450939457202506,"S
βE(F(x(0)) −F(x∗)) ≤ηβ"
REFERENCES,0.4650313152400835,µ (F(x(0)) −F(x∗)) ≤1
REFERENCES,0.46555323590814196,"µ∆
(126)"
REFERENCES,0.4660751565762004,"So altogether,"
REFERENCES,0.46659707724425886,"EF(ˆx) −F(x∗) ≤˜O(∆exp(−µηmaxR) +
σ2"
REFERENCES,0.4671189979123173,"µRKS )
(127)"
REFERENCES,0.46764091858037576,"D.3.2
CONVERGENCE OF SAGA UNDER THE PL CONDITION"
REFERENCES,0.4681628392484342,This proof follows Reddi et al. (2016).
REFERENCES,0.46868475991649267,Proof. We start with Assumption B.4
REFERENCES,0.4692066805845512,"EF(x(r+1)) ≤E[F(x(r)) + ⟨∇F(x(r)), x(r+1) −x(t)⟩+ β"
REFERENCES,0.4697286012526096,"2 ∥x(r+1) −x(r)∥2]
(128)"
REFERENCES,0.4702505219206681,"Using the fact that g(r) is unbiased,"
REFERENCES,0.4707724425887265,EF(x(r+1)) ≤E[F(x(r)) −η∥∇F(x(r))∥2 + βη2
REFERENCES,0.471294363256785,"2 ∥g(r)∥2]
(129)"
REFERENCES,0.4718162839248434,Now we consider the Lyapunov function
REFERENCES,0.4723382045929019,"Lr = E[F(x(r)) + cr N N
X"
REFERENCES,0.47286012526096033,"i=1
∥x(r) −φ(r)
i ∥2]
(130)"
REFERENCES,0.4733820459290188,We bound Lr+1 using
N,0.47390396659707723,"1
N N
X"
N,0.4744258872651357,"i=1
E∥x(r+1) −φ(r+1)
i
∥2
(131) = 1 N N
X"
N,0.47494780793319413,"i=1
[ S"
N,0.4754697286012526,N E∥x(r+1) −x(r)∥2 + N −S
N,0.4759916492693111,"N
E∥x(r+1) −φ(r)
i ∥2]
(132)"
N,0.47651356993736954,"Where the equality comes from how φ(r+1)
i
= x(r) with probability S/N and is φ(r)
i
otherwise.
Observe that we can bound"
N,0.477035490605428,"E∥x(r+1) −φ(r)
i ∥2
(133)"
N,0.47755741127348644,"= E[∥x(r+1) −x(r)∥2 + ∥x(r) −φ(r)
i ∥2 + 2⟨x(r+1) −x(r), x(r) −φ(r)
i ⟩]
(134)"
N,0.4780793319415449,"≤E[∥x(r+1) −x(r)∥2 + ∥x(r) −φ(r)
i ∥2] + 2ηE[ 1"
N,0.47860125260960334,2b∥∇F(x(r))∥2 + 1
N,0.4791231732776618,"2b∥x(r) −φ(r)
i ∥2]
(135)"
N,0.47964509394572025,"Where we used unbiasedness of g(r) and Fenchel-Young inequality. Plugging this into Lr+1,"
N,0.4801670146137787,Lr+1 ≤E[F(x(r)) −η∥∇F(x(r))∥2 + βη2
N,0.48068893528183715,"2 ∥g(r)∥2]
(136)"
N,0.4812108559498956,"+ E[cr+1∥x(r+1) −x(r)∥2 + cr+1
N −S N 2 N
X"
N,0.48173277661795405,"i=1
∥x(r) −φ(r)
i ∥2]
(137)"
N,0.4822546972860125,"+ 2(N −S)cr+1η N 2 N
X"
N,0.482776617954071,"i=1
E[ 1"
N,0.48329853862212946,2b∥∇F(x(r))∥2 + 1
N,0.4838204592901879,"2b∥x(r) −φ(r)
i ∥2]
(138)"
N,0.48434237995824636,≤E[F(x(r)) −(η −cr+1η(N −S)
N,0.4848643006263048,"bN
)∥∇F(x(r))∥2 + (βη2"
N,0.48538622129436326,"2
+ cr+1η2)E∥g(r)∥2]
(139)"
N,0.4859081419624217,+ (N −S
N,0.48643006263048016,"N
cr+1 + cr+1ηb(N −S) N
) 1 N N
X"
N,0.4869519832985386,"i=1
E∥x(r) −φ(r)
i ∥2
(140)"
N,0.48747390396659707,Published as a conference paper at ICLR 2022
N,0.4879958246346555,Now we must bound E∥g(r)∥2. E∥( 1 S X
N,0.48851774530271397,"i∈Sr
[ 1 K K−1
X"
N,0.4890396659707724,"k=0
∇f(x(r); z(r)
i,k ) −∇f(φ(r)
i ; ˜z(r)
i,k )] +
1
NK N
X"
N,0.48956158663883087,"i=1
∇f(φ(r)
i ; ˜z(r)
i,k ))∥2
(141)"
N,0.4900835073068894,≤2E∥( 1 S X
N,0.4906054279749478,"i∈Sr
[ 1 K K−1
X"
N,0.4911273486430063,"k=0
∇f(x(r); z(r)
i,k ) −∇f(φ(r)
i ; ˜z(r)
i,k )]
(142)"
N,0.49164926931106473,"−
1
NK N
X"
N,0.4921711899791232,"i=1
[∇f(x(r); z(r)
i,k ) −∇f(φ(r)
i ; ˜z(r)
i,k ))]∥2 + 2E∥1 NK N
X"
N,0.49269311064718163,"i=1
∇f(x(r); z(r)
i,k )∥2
(143) ≤2E∥1 S X"
N,0.4932150313152401,"i∈Sr
∇Fi(x(r)) −∇Fi(φ(r)
i )∥2 + 2E∥∇F(x(r))∥2 + νσ2"
N,0.49373695198329853,"SK
(144)"
N,0.494258872651357,"Where the second to last inequality is an application of Var(X) ≤E[X2], and separating out the
variance (taking advantage of the fact that ˜z’s and z’s are independent), and ν is some constant."
N,0.49478079331941544,We use Assumption B.4 and take expectation over sampled clients to get
N,0.4953027139874739,"E∥g(r)∥2 ≤2β2 N N
X"
N,0.49582463465553234,"i=1
E∥x(t) −φ(r)
i ∥2 + 2E∥∇F(x(r))∥2 + νσ2"
N,0.4963465553235908,"SK
(145)"
N,0.4968684759916493,"Returning to our bound on Lr+1,"
N,0.49739039665970775,Lr+1 ≤EF(x(r)) −(η −cr+1η(N −S)
N,0.4979123173277662,"bN
−η2β −2cr+1η2)E∥∇F(x(r))∥2
(146)"
N,0.49843423799582465,+ (cr+1(N −S
N,0.4989561586638831,"N
+ ηb(N −S)"
N,0.49947807933194155,"N
+ 2η2β2) + η2β3) 1 N N
X"
N,0.5,"i=1
E∥x(r) −φ(r)
i ∥2
(147)"
N,0.5005219206680585,+ νη2σ2
N,0.5010438413361169,SK (cr+1 + β
N,0.5015657620041754,"2 )
(148)"
N,0.5020876826722338,We set cr = cr+1( N−S
N,0.5026096033402923,"N
+ ηb(N−S)"
N,0.5031315240083507,"N
+ 2η2β2) + η2β3, which results in"
N,0.5036534446764092,"Lr+1
(149)"
N,0.5041753653444676,≤Lr −(η −cr+1η(N −S)
N,0.5046972860125261,"bN
−η2β −2cr+1η2)E∥∇F(x(r))∥2 + νη2σ2"
N,0.5052192066805845,SK (cr+1 + β
N,0.505741127348643,"2 )
(150)"
N,0.5062630480167014,Let Γr = η −cr+1η(N−S)
N,0.5067849686847599,"bN
−η2β −2cr+1η2. Then by rearranging"
N,0.5073068893528184,ΓrE∥∇F(x(r))∥2 ≤Lr −Lr+1 + νη2σ2
N,0.5078288100208769,SK (cr+1 + β
N,0.5083507306889353,"2 )
(151)"
N,0.5088726513569938,"Letting γn = min0≤r≤R−1 Γr, γn R−1
X"
N,0.5093945720250522,"r=0
E∥∇F(x(r))∥2 ≤ R−1
X"
N,0.5099164926931107,"r=0
ΓrE∥∇F(x(r))∥2
(152)"
N,0.5104384133611691,"≤L0 −LR + R−1
X r=0 νη2σ2"
N,0.5109603340292276,SK (cr+1 + β
N,0.511482254697286,"2 )
(153)"
N,0.5120041753653445,"Implying R−1
X"
N,0.5125260960334029,"r=0
E∥∇F(x(r))∥2 ≤∆"
N,0.5130480167014614,"γn
+ 1 γn R−1
X r=0 νη2σ2"
N,0.5135699373695198,SK (cr+1 + β
N,0.5140918580375783,"2 )
(154)"
N,0.5146137787056367,"Therefore, if we take a uniform sample from all the x(r), denoted ¯xR,"
N,0.5151356993736952,"E∥∇F(¯x(R))∥2 ≤
∆
γnR +
1
γnR R−1
X r=0 νη2σ2"
N,0.5156576200417536,SK (cr+1 + β
N,0.5161795407098121,"2 )
(155)"
N,0.5167014613778705,Published as a conference paper at ICLR 2022
N,0.517223382045929,"We start by bounding cr. Take η =
1
3β ( S"
N,0.5177453027139874,N )2/3 and b = β( S
N,0.5182672233820459,"N )1/3. Let θ =
S
N −ηb(N−S)"
N,0.5187891440501043,"N
−
2η2β2. Observe that θ < 1 and θ >
4
9
S
N . Then cr = cr+1(1 −θ) + η2β3, which implies"
N,0.5193110647181628,cr = η2β3 1−(1−θ)R−r
N,0.5198329853862212,"θ
≤η2β3 θ
≤β 4 ( S"
N,0.5203549060542797,N )1/3
N,0.5208768267223383,So we can conclude that
N,0.5213987473903967,"γn = min
r (η −cr+1η"
N,0.5219206680584552,"β
−η2β −2cr+1η2) ≥
1
12β ( S"
N,0.5224425887265136,"N )2/3
(156)"
N,0.5229645093945721,"So altogether,"
N,0.5234864300626305,"E∥∇F(¯x(R))∥2 ≤12β∆ R
(N"
N,0.524008350730689,S )2/3 + νη2βσ2
N,0.5245302713987474,"SK
(
1
12β(N/S)2/3 )
(157)"
N,0.5250521920668059,"= 12β∆ R
(N"
N,0.5255741127348643,S )2/3 + νβσ2
N,0.5260960334029228,"SK (12β(N/S)2/3)(
1
9β2(N/S)4/3 )
(158) ≤12β∆ R
(N"
N,0.5266179540709812,S )2/3 + 2νσ2
N,0.5271398747390397,"SK
(159)"
N,0.5276617954070981,"Now we run Algo. 5 in a repeated fashion, as follows:"
N,0.5281837160751566,1. Set x(0) = ps−1
N,0.528705636743215,2. Run Algo. 5 for Rs iterations
N,0.5292275574112735,3. Set ps to the result of Algo. 5
N,0.5297494780793319,Repeat for s stages. Let p0 be the initial point. Letting Rs = ⌈24κ( N
N,0.5302713987473904,S )2/3⌉this implies that
N,0.5307933194154488,2µ(EF(ps) −F(x∗)) ≤E∥∇F(ps)∥2 ≤µ(EF(ps−1) −F(x∗))
N,0.5313152400835073,"2
+ 2νσ2"
N,0.5318371607515657,"SK
(160)"
N,0.5323590814196242,Which gives
N,0.5328810020876826,"EF(ps) −F(x∗) ≤O(∆exp(−s) +
σ2"
N,0.5334029227557411,"µSK )
(161)"
N,0.5339248434237995,"If the total number of rounds is R, then"
N,0.534446764091858,EF(ˆx) −F(x∗) ≤O(∆exp(−R
N,0.5349686847599165,"κ ) +
σ2"
N,0.535490605427975,"µSK )
(162)"
N,0.5360125260960334,"D.4
SSNM"
N,0.5365344467640919,"Note that our usual assumption Fi(x) is µ-strongly convex can be straightforwardly converted into
the assumption that our losses are Fi(x) = ˜Fi(x) + h(x) where ˜Fi(x) is merely convex and h(x) is
µ-strongly convex (see (Zhou et al., 2019) section 4.2)."
N,0.5370563674321504,"Theorem D.5. Suppose that client objectives Fi’s and their gradient queries satisfy Assumption B.4
and Assumption B.6. Then running Algo. 6 gives the following for returned iterate ˆx:"
N,0.5375782881002088,"• Strongly convex: Fi’s satisfy Assumption B.1 for µ > 0. If we return the ﬁnal iterate
and set η =
1
2µ(N/S), τ = (N/S)ηµ"
N,0.5381002087682673,"1+ηµ
if (N/S) κ
> 3"
N,0.5386221294363257,"4 and η =
q"
N,0.5391440501043842,"1
3µ(N/S)β , τ = (N/S)ηµ"
N,0.5396659707724426,"1+ηµ
if (N/S) κ
≤3 4,"
N,0.5401878914405011,"EF(x(R)) −F(x∗) ≤O(κ∆exp(−min{ S N , r"
N,0.5407098121085595,"S
Nκ}R) + κσ2 µKS )"
N,0.541231732776618,Published as a conference paper at ICLR 2022
N,0.5417536534446764,"D.4.1
CONVERGENCE OF SSNM ON STRONGLY CONVEX FUNCTIONS"
N,0.5422755741127349,"Most of this proof follows that of (Zhou et al., 2019) Theorem 1."
N,0.5427974947807933,"First, we compute the variance of the update g(r)."
N,0.5433194154488518,"E[∥g(r) −1 N N
X"
N,0.5438413361169102,"i=1
∇˜Fi(y(r)
ir )∥2]
(163) ≤E∥1 S X"
N,0.5443632567849687,"ir∈Sr
∇˜Fir(y(r)
ir ) −∇˜Fir(φ(r)
ir ) −1 N N
X"
N,0.5448851774530271,"i=1
(∇˜Fi(y(r)
i
) −∇˜Fi(φ(r)
i ))∥2 + νσ2"
N,0.5454070981210856,"KS
(164) ≤E∥1 S X"
N,0.545929018789144,"ir∈Sr
∇˜Fir(y(r)
ir ) −∇˜Fir(φ(r)
ir )∥2 + νσ2"
N,0.5464509394572025,"KS
(165)"
N,0.5469728601252609,≤2βE[ 1 S X ir∈Sr
N,0.5474947807933194,"˜Fir(φ(r)
ir ) −˜Fir(y(r)
ir ) −⟨∇˜Fir(y(r)
ir ), φ(r)
ir −y(r)
ir ⟩] + νσ2"
N,0.5480167014613778,"KS
(166)"
N,0.5485386221294363,"= 2β[ 1 N N
X"
N,0.5490605427974948,"i=1
˜Fi(φ(r)
i ) −˜Fi(y(r)
i
) −1 N N
X"
N,0.5495824634655533,"i=1
⟨∇˜Fi(y(r)
i
), φ(r)
i
−y(r)
i
⟩] + νσ2"
N,0.5501043841336117,"KS
(167)"
N,0.5506263048016702,"For some constant ν. In the ﬁrst inequality we separated out the gradient variance, second inequality
we use the fact that Var(X) ≤E[X2], third inequality used Assumption B.4, and fourth we took
expectation with respect to the sampled clients. From convexity we have that"
N,0.5511482254697286,"˜Fir(y(r)
ir ) −˜Fir(x∗)
(168)"
N,0.5516701461377871,"≤⟨∇˜Fir(y(r)
ir ), y(r)
ir −x∗⟩
(169)"
N,0.5521920668058455,= 1 −τ
N,0.552713987473904,"τ
⟨∇˜Fir(y(r)
ir ), φ(r)
ir −y(r)
ir ⟩+ ⟨∇˜Fir(y(r)
ir ), x(r) −x∗⟩
(170)"
N,0.5532359081419624,= 1 −τ
N,0.5537578288100209,"τ
⟨∇˜Fir(y(r)
ir ), φ(r)
ir −y(r)
ir ⟩+ ⟨∇˜Fir(y(r)
ir ) −g(r), x(r) −x∗⟩
(171)"
N,0.5542797494780793,"+ ⟨g(r), x(r) −x(r+1)⟩+ ⟨g(r), x(r+1) −x∗⟩
(172)"
N,0.5548016701461378,"where the second to last inequality comes from the deﬁnition that y(r)
ir = τx(r) + (1 −τ)φ(r)
ir . Taking
expectation with respect to the sampled clients, we have"
N,0.5553235908141962,"1
N N
X"
N,0.5558455114822547,"i=1
˜Fi(y(r)
i
) −˜F(x∗) ≤1 −τ τN N
X"
N,0.5563674321503131,"i=1
⟨∇˜Fi(y(r)
i
), φ(r)
i
−y(r)
i
⟩+ ESr⟨g(r), x(r) −x(r+1)⟩(173)"
N,0.5568893528183716,"+ ESr⟨g(r), x(r+1) −x∗⟩
(174)"
N,0.55741127348643,"For ESr⟨g(r), x(r) −x(r+1)⟩, we can employ smoothness at (φ(r+1)
Ir
, y(r)
Ir ), which holds for any
Ir ∈S′
r:"
N,0.5579331941544885,"˜FIr(φ(r+1)
Ir
) −˜FIr(y(r)
Ir ) ≤⟨∇˜FIr(y(r)
Ir ), φ(r+1)
Ir
−y(r)
Ir ⟩+ β"
N,0.558455114822547,"2 ∥φ(r+1)
Ir
−y(r)
Ir ∥2
(175)"
N,0.5589770354906054,"using φ(r+1)
Ir
= τx(r+1) + (1 −τ)φ(r)
Ir and y(r)
Ir = τx(r) + (1 −τ)φ(r)
Ir (though the second is never
explicitly computed and only implicitly exists)"
N,0.5594989561586639,"˜FIr(φ(r+1)
Ir
) −˜FIr(y(r)
Ir ) ≤τ⟨∇˜FIr(y(r)
Ir ), x(r+1) −x(r)⟩+ βτ 2"
N,0.5600208768267223,"2 ∥x(r+1) −x(r)∥2
(176)"
N,0.5605427974947808,"Taking expectation over S′
r and using φ(r+1)
Ir
= τx(r+1)+(1−τ)φ(r)
Ir and y(r)
Ir = τx(r)+(1−τ)φ(r)
Ir
we see that"
N,0.5610647181628392,ES′r[ 1 S X
N,0.5615866388308977,Ir∈S′r
N,0.5621085594989561,"˜FIr(φ(r+1)
Ir
)] −1 N N
X"
N,0.5626304801670147,"i=1
˜Fi(y(r)
i
) ≤τ⟨1 N N
X"
N,0.5631524008350731,"i=1
∇˜Fi(y(r)
i
), x(r+1) −x(r)⟩
(177)"
N,0.5636743215031316,+ βτ 2
N,0.56419624217119,"2 ∥x(r+1) −x(r)∥2
(178)"
N,0.5647181628392485,Published as a conference paper at ICLR 2022
N,0.5652400835073069,"and rearranging,"
N,0.5657620041753654,"⟨g(r), x(r) −x(r+1)⟩
(179)"
N,0.5662839248434238,"≤
1
τN N
X"
N,0.5668058455114823,"i=1
˜Fi(y(r)
i
) −1"
N,0.5673277661795407,"τS ES′r[
X"
N,0.5678496868475992,Ir∈S′r
N,0.5683716075156576,"˜FIr(φ(r+1)
Ir
)]
(180) + ⟨1 N N
X"
N,0.5688935281837161,"i=1
∇˜Fi(y(r)
i
) −g(r), x(r+1) −x(r)⟩+ βτ"
N,0.5694154488517745,"2 ∥x(r+1) −x(r)∥2
(181)"
N,0.569937369519833,"Substituting this into Eq. (173) after taking expectation over Sr, and observing that from (Zhou et al.,
2019, Lemma 2) we have identity"
N,0.5704592901878914,"⟨g(r), x(r+1) −u⟩≤−1"
N,0.5709812108559499,2η ∥x(r+1) −x(r)∥2 + 1
N,0.5715031315240083,"2η ∥x(r) −u∥2
(182)"
N,0.5720250521920668,−1 + ηµ
N,0.5725469728601252,"2η
∥x(r+1) −u∥2 + h(u) −h(x(r+1))
(183)"
N,0.5730688935281837,"so with u = x∗, we get"
N,0.5735908141962421,"1
N N
X"
N,0.5741127348643006,"i=1
˜Fi(y(r)
i
) −˜F(x∗)
(184) ≤1 −τ τN N
X"
N,0.574634655532359,"i=1
⟨∇˜Fi(y(r)
i
), φ(r)
i
−y(r)
i
⟩+
1
τN N
X"
N,0.5751565762004175,"i=1
˜Fi(y(r)
i
)
(185) −1"
N,0.5756784968684759,"τS ESr,S′r[
X"
N,0.5762004175365344,Ir∈S′r
N,0.576722338204593,"˜FIr(φ(r+1)
Ir
)]
(186)"
N,0.5772442588726514,"+ ESr⟨1 N N
X"
N,0.5777661795407099,"i=1
∇˜Fi(y(r)
i
) −g(r), x(r+1) −x(r)⟩+ βτ"
N,0.5782881002087683,"2 ESr∥x(r+1) −x(r)∥2
(187) −1"
N,0.5788100208768268,2η ESr∥x(r+1) −x(r)∥2 + 1
N,0.5793319415448852,2η ∥x(r) −x∗∥2 −1 + ηµ
N,0.5798538622129437,"2η
ESr∥x(r+1) −x∗∥2
(188)"
N,0.5803757828810021,"+ h(x∗) −ESrh(x(r+1))
(189)"
N,0.5808977035490606,We use the constraint that βτ ≤1
N,0.581419624217119,"η −
βτ
1−τ plus Young’s inequality ⟨a, b⟩≤
1
2c∥a∥2 + c"
N,0.5819415448851775,2∥b∥2 with
N,0.5824634655532359,"c =
βτ
1−τ on ESr⟨1"
N,0.5829853862212944,"N
PN
i=1 ∇˜Fi(y(r)
i
) −g(r), x(r+1) −x(r)⟩to get"
N,0.5835073068893528,"1
N N
X"
N,0.5840292275574113,"i=1
˜Fi(y(r)
i
) −˜F(x∗)
(190) ≤1 −τ τN N
X"
N,0.5845511482254697,"i=1
⟨∇˜Fi(y(r)
i
), φ(r)
i
−y(r)
i
⟩
(191)"
N,0.5850730688935282,"+
1
τN N
X"
N,0.5855949895615866,"i=1
˜Fi(y(r)
i
) −1"
N,0.5861169102296451,"τS ESr,S′
r[
X"
N,0.5866388308977035,Ir∈S′r
N,0.587160751565762,"˜FIr(φ(r+1)
Ir
)]
(192)"
N,0.5876826722338204,+ 1 −τ
N,0.5882045929018789,"2βτ ESr∥1 N N
X"
N,0.5887265135699373,"i=1
∇˜Fi(y(r)
i
) −g(r)∥2 + 1"
N,0.5892484342379958,"2η ∥x(r) −x∗∥2
(193)"
N,0.5897703549060542,−1 + ηµ
N,0.5902922755741128,"2η
ESr∥x(r+1) −x∗∥2 + h(x∗) −ESrh(x(r+1))
(194)"
N,0.5908141962421712,Published as a conference paper at ICLR 2022
N,0.5913361169102297,"using the bound on variance, we get"
N,0.5918580375782881,"1
N N
X"
N,0.5923799582463466,"i=1
˜Fi(y(r)
i
) −˜F(x∗)
(195)"
N,0.592901878914405,"≤
1
τN N
X"
N,0.5934237995824635,"i=1
˜Fi(y(r)
i
) −1"
N,0.593945720250522,"τS ESr,S′r[
X"
N,0.5944676409185804,Ir∈S′r
N,0.5949895615866388,"˜FIr(φ(r+1)
Ir
)] + 1 −τ τN N
X"
N,0.5955114822546973,"i=1
˜Fi(φ(r)
i ) −˜Fi(y(r)
i
)
(196) + 1"
N,0.5960334029227558,2η ∥x(r) −x∗∥2 −1 + ηµ
N,0.5965553235908142,"2η
ESr∥x(r+1) −x∗∥2
(197)"
N,0.5970772442588727,+ h(x∗) −ESrh(x(r+1)) + (1 −τ)νσ2
N,0.5975991649269311,"2βτKS
(198)"
N,0.5981210855949896,"combining terms,
1
τS ESr,S′r[
X"
N,0.598643006263048,Ir∈S′r
N,0.5991649269311065,"˜FIr(φ(r+1)
Ir
)] −F(x∗)
(199) ≤1 −τ τN N
X"
N,0.5996868475991649,"i=1
˜Fi(φ(r)
i ) + 1"
N,0.6002087682672234,2η ∥x(r) −x∗∥2 −1 + ηµ
N,0.6007306889352818,"2η
ESr∥x(r+1) −x∗∥2
(200)"
N,0.6012526096033403,−ESrh(x(r+1)) + (1 −τ)νσ2
N,0.6017745302713987,"2βτKS
(201)"
N,0.6022964509394572,"Using convexity of h and φ(r+1)
Ik
= τx(r+1) + (1 −τ)φ(r)
Ik for Ik ∈S′
r,"
N,0.6028183716075156,"h(φ(r+1)
Ik
) ≤τh(x(r+1)) + (1 −τ)h(φ(r)
Ik )
(202)"
N,0.6033402922755741,"After taking expectation with respect to Sr and S′
r,"
N,0.6038622129436325,"−ESr[h(x(r+1))] ≤1 −τ τN N
X"
N,0.6043841336116911,"i=1
h(φ(r)
i ) −1"
N,0.6049060542797495,"τ ESr,S′r[ 1 S X"
N,0.605427974947808,"Ir∈S′r
h(φ(r+1)
Ik
)]
(203)"
N,0.6059498956158664,"and plugging this back in, multiplying by S/N on both sides, and adding both sides by
1
τN ES′r[P"
N,0.6064718162839249,"i/∈S′r(Fi(φ(r)
i ) −Fi(x∗))]"
N,0.6069937369519833,"1
τ ESr,S′r[ 1 N N
X"
N,0.6075156576200418,"i=1
Fi(φ(r+1)
i
) −Fi(x∗)]
(204)"
N,0.6080375782881002,≤(1 −τ)S
N,0.6085594989561587,"τN
( 1 N N
X"
N,0.6090814196242171,"i=1
Fi(φ(r)
i ) −Fi(x∗)) +
1
τN ES′r[
X"
N,0.6096033402922756,"i/∈S′r
(Fi(φ(r)
i ) −Fi(x∗))]
(205)"
N,0.610125260960334,"+
S
2ηN ∥x(r) −x∗∥2 −(1 + ηµ)S"
N,0.6106471816283925,"2ηN
ESr∥x(r+1) −x∗∥2 + (1 −τ)νσ2"
N,0.6111691022964509,"2βτKN
(206)"
N,0.6116910229645094,"Observe that the probability of choosing any client index happens with probability S/N, so"
N,0.6122129436325678,"1
τN ES′r[
X"
N,0.6127348643006263,"i/∈S′
r
(Fi(φ(r)
i ) −Fi(x∗))] = N −S"
N,0.6132567849686847,"τN
( 1 N N
X"
N,0.6137787056367432,"i=1
Fi(φ(r)
i ) −Fi(x∗))
(207)"
N,0.6143006263048016,which implies
N,0.6148225469728601,"1
τ ESr,S′r[ 1 N N
X"
N,0.6153444676409185,"i=1
Fi(φ(r+1)
i
) −Fi(x∗)]
(208)"
N,0.615866388308977,≤1 −τS
N,0.6163883089770354,"N
τ
( 1 N N
X"
N,0.6169102296450939,"i=1
Fi(φ(r)
i ) −Fi(x∗))
(209)"
N,0.6174321503131524,"+
S
2ηN ∥x(r) −x∗∥2 −(1 + ηµ)S"
N,0.6179540709812108,"2ηN
ESr∥x(r+1) −x∗∥2 + (1 −τ)νσ2"
N,0.6184759916492694,"2βτKN
(210)"
N,0.6189979123173278,Published as a conference paper at ICLR 2022
N,0.6195198329853863,"To complete our Lyapunov function so the potential is always positive, we need another term: −1 N N
X"
N,0.6200417536534447,"i=1
⟨∇Fi(x∗), φ(r+1)
i
−x∗⟩
(211) = −1 N X"
N,0.6205636743215032,"Ir∈S′r
⟨∇FIr(x∗), φ(r+1)
Ir
−x∗⟩−1 N X"
N,0.6210855949895616,"j /∈S′r
⟨∇Fj(x∗), φ(r)
j
−x∗⟩
(212) =
X"
N,0.6216075156576201,"Ir∈S′
r
−τ"
N,0.6221294363256785,"N ⟨∇FIr(x∗), x(r+1) −x∗⟩+ τ"
N,0.622651356993737,"N ⟨∇FIr(x∗), φ(r)
Ir −x∗⟩
(213) −1 N N
X"
N,0.6231732776617954,"i=1
⟨∇Fi(x∗), φ(r)
i
−x∗⟩
(214)"
N,0.6236951983298539,"Taking expectation with respect to Sr, S′
r,"
N,0.6242171189979123,"ESr,S′r[−1 N N
X"
N,0.6247390396659708,"i=1
⟨∇Fi(x∗), φ(r+1)
i
−x∗⟩] = −(1 −τS"
N,0.6252609603340292,"N )( 1 N N
X"
N,0.6257828810020877,"i=1
⟨∇Fi(x∗), φ(r)
i
−x∗⟩)
(215)"
N,0.6263048016701461,"Let Br :=
1
N
PN
i=1 Fi(φ(r)
i ) −F(x∗) −1"
N,0.6268267223382046,"N
PN
i=1⟨∇Fi(x∗), φ(r)
i
−x∗⟩and Pr := ∥x(r) −x∗∥2,
then we can write
1
τ ESr,S′r[Br+1] + (1 + ηµ)S"
N,0.627348643006263,"2ηN
ESr[Pr+1] ≤1 −τS"
N,0.6278705636743215,"N
τ
Br +
S
2ηN Pr + (1 −τ)νσ2"
N,0.6283924843423799,"2βτKN
(216)"
N,0.6289144050104384,"Case 1: Suppose that (N/S) κ
≤3"
N,0.6294363256784968,"4, then choosing η =
q"
N,0.6299582463465553,"1
3µ(N/S)β , τ = (N/S)ηµ"
N,0.6304801670146137,"1+ηµ
= q (N/S)"
N,0.6310020876826722,"3κ
1+
q"
N,0.6315240083507306,"1
3(N/S)κ
< 1 2,"
N,0.6320459290187892,we evaluate the parameter constraint βτ ≤1
N,0.6325678496868476,"η −
βτ
1−τ : βτ ≤1"
N,0.6330897703549061,"η −
βτ
1 −τ =⇒(1 +
1
1 −τ )τ ≤1"
N,0.6336116910229646,"βη =⇒2 −τ 1 −τ q (N/S) 3κ 1 +
q"
N,0.634133611691023,"1
3(N/S)κ
≤ r"
N,0.6346555323590815,3(N/S)
N,0.6351774530271399,"κ
(217)"
N,0.6356993736951984,"which shows our constraint is satisﬁed. We also know that
1
τ(1 + ηµ) = 1 −τS"
N,0.6362212943632568,"N
τ
=
1
(N/S)ηµ
(218)"
N,0.6367432150313153,"So we can write
1
(N/S)ηµESr,S′r[Br+1] +
1
2η(N/S)ESr[Pr+1]
(219)"
N,0.6372651356993737,"≤(1 + ηµ)−1(
1
(N/S)ηµBr +
1
2η(N/S)Pr) + (1 −τ)νσ2"
N,0.6377870563674322,"2βτKN
(220)"
N,0.6383089770354906,"Telescoping the contraction and taking expectation with respect to all randomness, we have
1
(N/S)ηµE[BR] +
1
2η(N/S)E[PR]
(221)"
N,0.6388308977035491,"≤(1 + ηµ)−R(
1
(N/S)ηµEB0 +
1
2η(N/S)EP0) + (1 −τ)νσ2"
N,0.6393528183716075,"2βτKN
(1 + ηµ"
N,0.639874739039666,"ηµ
)
(222)"
N,0.6403966597077244,"B0 = F(x(0)) −F(x∗) and EBR ≥0 based on convexity. Next, we calculate the coefﬁcient of the
variance term.
1 −τ"
N,0.6409185803757829,"τ
1 + ηµ"
N,0.6414405010438413,"ηµ
= (1"
N,0.6419624217118998,τ −1)(1 + 1
N,0.6424843423799582,ηµ) = ( S
N,0.6430062630480167,N (1 + 1
N,0.6435281837160751,ηµ) −1)(1 + 1
N,0.6440501043841336,"ηµ)
(223)"
N,0.644572025052192,= O(( S
N,0.6450939457202505,N (1 + √κ( r N
N,0.6456158663883089,S )) −1)(1 + √κ( r N
N,0.6461377870563675,"S )))
(224)"
N,0.6466597077244259,= O(( S
N,0.6471816283924844,N + √κ( S
N,0.6477035490605428,N )1/2 −1)(1 + √κ(N
N,0.6482254697286013,"S )1/2))
(225)"
N,0.6487473903966597,"= O(κ)
(226)"
N,0.6492693110647182,Published as a conference paper at ICLR 2022
N,0.6497912317327766,"Substituting the parameter choices and using strong convexity,"
N,0.6503131524008351,E∥x(R) −x∗∥2 ≤(1 + s
N,0.6508350730688935,"1
3(N/S)κ)−R( 2"
N,0.651356993736952,"µ∆+ D2) + O(
σ2"
N,0.6518789144050104,"µ2KN )
(227)"
N,0.6524008350730689,"Case 2: On the other hand, we can have (N/S) κ
> 3"
N,0.6529227557411273,"4 and choose η =
1
2µ(N/S), τ = (N/S)ηµ"
N,0.6534446764091858,"1+ηµ
="
N,0.6539665970772442,"(1/2)
1+
1
2(N/S) < 1"
N,0.6544885177453027,2. One can check that the constraint βτ ≤1
N,0.6550104384133612,"η −
βτ
1−τ is satisﬁed."
N,0.6555323590814196,"After telescoping and taking expectation,"
N,0.656054279749478,"2E[BR] +
1
2η(N/S)E[PR]
(228)"
N,0.6565762004175365,"≤(1 + ηµ)−R(2EB0 +
1
2η(N/S)EP0) + (1 −τ)νσ2"
N,0.657098121085595,"2βτKN
(1 + ηµ"
N,0.6576200417536534,"ηµ
)
(229)"
N,0.6581419624217119,"Next, we calculate the coefﬁcient of the variance term.
1 −τ"
N,0.6586638830897703,"τ
1 + ηµ"
N,0.6591858037578288,"ηµ
= (1"
N,0.6597077244258872,τ −1)(1 + 1
N,0.6602296450939458,ηµ) = ( S
N,0.6607515657620042,N (1 + 1
N,0.6612734864300627,ηµ) −1)(1 + 1
N,0.6617954070981211,"ηµ)
(230)"
N,0.6623173277661796,= O(( S
N,0.662839248434238,N (1 + N
N,0.6633611691022965,S ) −1)(1 + N
N,0.6638830897703549,"S ))
(231) = O(N"
N,0.6644050104384134,"S )
(232)"
N,0.6649269311064718,which gives us
N,0.6654488517745303,"E∥x(R) −x∗∥2 ≤(1 +
1
2(N/S))−R( 2"
N,0.6659707724425887,"µ∆+ D2) + O(
σ2"
N,0.6664926931106472,"βµKS )
(233)"
N,0.6670146137787056,"Altogether, supposing we choose our parameters as stated in the two cases, we have:"
N,0.6675365344467641,"EF(x(R)) −F(x∗) ≤O(κ∆exp(−min{ S N , r"
N,0.6680584551148225,"S
Nκ}R) + κσ2"
N,0.668580375782881,"µKS )
(234)"
N,0.6691022964509394,"E
PROOFS FOR LOCAL UPDATE METHODS"
N,0.6696242171189979,"E.1
FEDAVG"
N,0.6701461377870563,"Theorem E.1. Suppose that client objectives Fi’s and their gradient queries satisfy Assumption B.4
and Assumption B.6. Then running Algo. 4 gives the following for returned iterate ˆx:"
N,0.6706680584551148,"• Strongly convex: Fi’s satisfy Assumption B.1 for µ > 0. If we return the ﬁnal iterate, set
η = 1"
N,0.6711899791231732,"β , and sample S clients per round arbitrarily,"
N,0.6717118997912317,"EF(x(R)) −F(x∗) ≤O(∆exp(−R
√"
N,0.6722338204592901,"K
κ
) + ζ2"
N,0.6727557411273486,"µ +
σ2 µ
√ K
)"
N,0.673277661795407,"Further, if there is no gradient variance and only one client i is sampled the entire algorithm,"
N,0.6737995824634656,"∥x(r) −x∗∥2 ≤O(∥x(0) −x∗∥2 + ∥x(0) −x∗
i ∥2) for any 0 ≤r ≤R"
N,0.6743215031315241,"• General convex: Fi’s satisfy Assumption B.2. If we return the last iterate after run-
ning the algorithm on Fµ(x) = F(x) + µ"
N,0.6748434237995825,2 ∥x(0) −x∥2 with µ = Θ(max{ β
N,0.675365344467641,"R2 log2(e2 +
R2), ζ"
N,0.6758872651356994,"D,
σ
DK1/4 }), and η =
1
β+µ,"
N,0.6764091858037579,EF(x(R)) −F(x∗) ≤˜O( βD2 √
N,0.6769311064718163,"KR
+ σD"
N,0.6774530271398748,K1/4 + ζD)
N,0.6779749478079332,"and for any 0 ≤r ≤R,"
N,0.6784968684759917,E∥x(r) −x∗∥2 ≤˜O(D2)
N,0.6790187891440501,Published as a conference paper at ICLR 2022
N,0.6795407098121086,"• PL condition: Fi’s satisfy Assumption B.3 for µ > 0. If we return the ﬁnal iterate, set
η = 1"
N,0.680062630480167,"β , and sample one client per round,"
N,0.6805845511482255,"EF(x(R)) −F(x∗) ≤O(∆exp(−R
√"
N,0.6811064718162839,"K
κ
) + ζ2"
N,0.6816283924843424,"2µ +
σ2 2µ
√ K
)"
N,0.6821503131524008,"E.1.1
CONVERGENCE OF FEDAVG FOR STRONGLY CONVEX FUNCTIONS"
N,0.6826722338204593,"Proof. By smoothness of F (Assumption B.4), we have for k ∈{0, . . . ,
√ K −1}"
N,0.6831941544885177,"F(x(r)
i,k+1) −F(x(r)
i,k) ≤−η⟨∇F(x(r)
i,k), g(r)
i,k ⟩+ βη2"
N,0.6837160751565762,"2 ∥g(r)
i,k ∥2
(235)"
N,0.6842379958246346,"Using the fact that for any a, b we have −2ab = (a −b)2 −a2 −b2,"
N,0.6847599164926931,"F(x(r)
i,k+1) −F(x(r)
i,k) ≤−η"
N,0.6852818371607515,"2∥∇F(x(r)
i,k)∥2 + βη2 −η"
N,0.68580375782881,"2
∥g(r)
i,k ∥2 + η"
N,0.6863256784968684,"2∥g(r)
i,k −∇F(x(r)
i,k)∥2
(236)"
N,0.6868475991649269,"Letting η ≤1 β ,"
N,0.6873695198329853,"F(x(r)
k+1) −F(x(r)
i,k) ≤−η"
N,0.6878914405010439,"2∥∇F(x(r)
i,k)∥2 + η"
N,0.6884133611691023,"2∥g(r)
i,k −∇F(x(r)
i,k)∥2
(237)"
N,0.6889352818371608,"Conditioning on everything up to the k-th step of the r-th round,"
N,0.6894572025052192,"Er,kF(x(r)
i,k+1) −F(x(r)
i,k) ≤−η"
N,0.6899791231732777,"2∥∇F(x(r)
i,k)∥2 + η"
N,0.6905010438413361,"2Er,k∥g(r)
i,k −∇F(x(r)
i,k)∥2
(238) ≤−η"
N,0.6910229645093946,"2∥∇F(x(r)
i,k)∥2 + ηζ2"
N,0.691544885177453,"2
+ ησ2 2
√"
N,0.6920668058455115,"K
(239)"
N,0.69258872651357,"Where the last step used the fact that E[X2] = Var(X) + E[X], the assumption on heterogeneity
(Assumption B.5), and the assumption on gradient variance (Assumption B.6) along with the fact
that g(r)
i,k is an average over
√"
N,0.6931106471816284,"K client gradient queries. Next, using µ-strong convexity of F
(Assumption B.1),"
N,0.6936325678496869,"Er,kF(x(r)
i,k+1) −F(x(r)
i,k) ≤−ηµ(F(x(r)
i,k) −F(x∗)) + ηζ2"
N,0.6941544885177453,"2
+ ησ2 2
√"
N,0.6946764091858038,"K
(240)"
N,0.6951983298538622,which after taking full expectation gives
N,0.6957202505219207,"EF(x(r)
i,k+1) −F(x∗) ≤(1 −ηµ)(EF(x(r)
i,k) −F(x∗)) + ηζ2"
N,0.6962421711899791,"2
+ ησ2 2
√"
N,0.6967640918580376,"K
(241)"
N,0.697286012526096,Unrolling the recursion over k we get
N,0.6978079331941545,"EF(x(r)
i,K) −F(x∗)
(242)"
N,0.6983298538622129,"≤(1 −ηµ)
√"
N,0.6988517745302714,"K(EF(x(r)
i,0) −F(x∗)) + (ηζ2"
N,0.6993736951983298,"2
+ ησ2 2
√ K
) √ K−1
X"
N,0.6998956158663883,"k=0
(1 −ηµ)k
(243)"
N,0.7004175365344467,Also note that x(r+1) = 1
N,0.7009394572025052,"S
P
i∈Sr x(r)
i,
√"
N,0.7014613778705637,"K. So by convexity of F,"
N,0.7019832985386222,"EF(x(r+1)) −F(x∗)
(244) ≤1 S X"
N,0.7025052192066806,"i∈Sr
EF(x(r)
i,
√"
N,0.7030271398747391,"K) −F(x∗)
(245)"
N,0.7035490605427975,"≤(1 −ηµ)
√"
N,0.704070981210856,K(EF(x(r)) −F(x∗)) + (ηζ2
N,0.7045929018789144,"2
+ ησ2 2
√ K
) √ K−1
X"
N,0.7051148225469729,"k=0
(1 −ηµ)k
(246)"
N,0.7056367432150313,"Unrolling the recursion over R, we get"
N,0.7061586638830898,"EF(x(r)) −F(x∗)
(247)"
N,0.7066805845511482,"≤(1 −ηµ)r
√"
N,0.7072025052192067,K(F(x(0)) −F(x∗)) + (ηζ2
N,0.7077244258872651,"2
+ ησ2 2
√ K
) r−1
X τ=0 √ K−1
X"
N,0.7082463465553236,"k=0
(1 −ηµ)τ
√"
N,0.708768267223382,"K+k
(248)"
N,0.7092901878914405,Published as a conference paper at ICLR 2022
N,0.7098121085594989,Which can be upper bounded as
N,0.7103340292275574,"EF(x(r)) −F(x∗) ≤(1 −ηµ)R
√"
N,0.7108559498956158,K(F(x(0)) −F(x∗)) + ζ2
N,0.7113778705636743,"2µ +
σ2 2µ
√"
N,0.7118997912317327,"K
(249)"
N,0.7124217118997912,"The ﬁnal statement comes from the fact that ∥x −η∇Fi(x) −x∗
i ∥≤∥x −x∗
i ∥because of η ≤1"
N,0.7129436325678496,"β
and applying triangle inequality."
N,0.7134655532359081,"E.1.2
CONVERGENCE OF FEDAVG FOR GENERAL CONVEX FUNCTIONS"
N,0.7139874739039666,"For the general convex case, we use Nesterov smoothing. Concretely, we will run Algo. 3 assuming
strong convexity by optimizing instead a modiﬁed objective"
N,0.714509394572025,Fµ(x) = F(x) + µ
N,0.7150313152400835,"2 ∥x(0) −x∥2
(250)"
N,0.715553235908142,"Deﬁne x∗
µ = arg minx Fµ(x) and ∆µ = EFµ(x(0)) −F(x∗
µ). We will choose µ carefully to balance
the error introduced by the regularization term and the better convergence properties of having larger
µ."
N,0.7160751565762005,"Proof. We know that running Algo. 4 with η =
1
β+µ gives (from the previous proof)"
N,0.7165970772442589,"EFµ(x(R)) −Fµ(x∗
µ) ≤∆µ exp(−R
√ K β+µ"
N,0.7171189979123174,"µ
) + ζ2"
N,0.7176409185803758,"2µ +
σ2 2µ
√"
N,0.7181628392484343,"K
(251)"
N,0.7186847599164927,"We have that by (Yuan & Ma, 2020, Proposition E.7)"
N,0.7192066805845512,"EF(x(R)) −F(x∗) ≤EFµ(x(R)) −Fµ(x∗
µ) + µ"
N,0.7197286012526096,"2 D2
(252)"
N,0.7202505219206681,"So we have (because ∆µ ≤∆as shown in Thm. D.3),"
N,0.7207724425887265,"EF(x(R)) −F(x∗) ≤∆exp(−R
√ K β+µ"
N,0.721294363256785,"µ
) + ζ2"
N,0.7218162839248434,"2µ +
σ2 2µ
√ K
+ µ"
N,0.7223382045929019,"2 D2
(253)"
N,0.7228601252609603,"Then if we choose µ ≥Θ(
β
√"
N,0.7233820459290188,"KR log2(e2 +
√"
N,0.7239039665970772,"KR)), µ ≥Θ( ζ"
N,0.7244258872651357,"D), and µ ≥Θ(
σ
DK1/4 ),"
N,0.7249478079331941,EF(x(R)) −F(x∗) ≤˜O( βD2 √
N,0.7254697286012526,"KR
+ σD"
N,0.725991649269311,"K1/4 + ζD)
(254)"
N,0.7265135699373695,Now we show the distance bound. Recall that
N,0.7270354906054279,"EFµ(x(R)) −Fµ(x∗
µ) ≤∆µ exp(−R
√ K β+µ"
N,0.7275574112734864,"µ
) + ζ2"
N,0.7280793319415448,"2µ +
σ2 2µ
√"
N,0.7286012526096033,"K
(255)"
N,0.7291231732776617,"By smoothness, strong convexity of Fµ, and the choice of µ (as we chose each term above divided by
µ to match D2 up to log factors), we have that"
N,0.7296450939457203,"E∥x(R) −x∗
µ∥2 ≤˜O(D2)
(256) So,"
N,0.7301670146137788,"E∥x(R) −x∗∥2 ≤3E∥x(R) −x∗
µ∥2 + 3E∥x(0) −x∗
µ∥2 + 3E∥x∗−x(0)∥2 ≤˜O(D2)
(257)"
N,0.7306889352818372,Where the last inequality follows because
N,0.7312108559498957,"F(x∗
µ) + µ"
N,0.7317327766179541,"2 ∥x(0) −x∗
µ∥2 ≤F(x∗) + µ"
N,0.7322546972860126,"2 ∥x(0) −x∗∥2
(258)"
N,0.732776617954071,"E.1.3
CONVERGENCE OF FEDAVG UNDER THE PL CONDITION"
N,0.7332985386221295,"Proof. The same proof follows as in the strongly convex case, except Eq. (244), where we avoid
having to use convexity by only sampling one client at a time. This follows previous work such as
Karimireddy et al. (2020a). Averaging when the functions are not convex can cause the error to blow
up, though in practice this is not seen (as mentioned in Karimireddy et al. (2020a))."
N,0.7338204592901879,Published as a conference paper at ICLR 2022
N,0.7343423799582464,"F
PROOFS FOR FEDCHAIN"
N,0.7348643006263048,"F.1
FEDAVG →SGD"
N,0.7353862212943633,"F.1.1
CONVERGENCE OF FEDAVG →SGD ON STRONGLY CONVEX FUNCTIONS"
N,0.7359081419624217,"Theorem F.1. Suppose that client objectives Fi’s and their gradient queries satisfy Assumption B.4,
Assumption B.6, Assumption B.7, Assumption B.5, Assumption B.8. Then running Algo. 1 where
Alocal is Algo. 4 in the setting of Thm. E.1 and Aglobal is Algo. 2 in the setting Thm. D.1:"
N,0.7364300626304802,"• Strongly convex: Fi’s satisfy Assumption B.1 for µ > 0. Then there exists a lower bound of
K such that we have the rate"
N,0.7369519832985386,˜O(min{ζ2
N,0.7374739039665971,"µ , ∆} exp(−R"
N,0.7379958246346555,"κ ) +
σ2"
N,0.738517745302714,µSKR + (1 −S
N,0.7390396659707724,N ) ζ2 µSR + r 1 −S
N,0.7395615866388309,"N
ζF
√ S
)"
N,0.7400835073068893,"• General convex: Fi’s satisfy Assumption B.2. Then there exists a lower bound of K such
that we have the rate"
N,0.7406054279749478,˜O( min{β1/2ζ1/2D3/2
N,0.7411273486430062,"R1/2
, βD2"
N,0.7416492693110647,R } + β1/2σ1/2D3/2
N,0.7421711899791231,(SKR)1/4
N,0.7426931106471816,+ (1 −S
N,0.7432150313152401,"N )1/4 β1/2ζ1/2
F
D
S1/4R1/2 + (1 −S"
N,0.7437369519832986,N )1/4 β1/2ζ1/2D3/2
N,0.744258872651357,"(SR)1/4
)"
N,0.7447807933194155,"• PL condition: Fi’s satisfy Assumption B.3 for µ > 0. Then there exists a lower bound of K
such that we have the rate"
N,0.7453027139874739,˜O(min{ζ2
N,0.7458246346555324,"µ , ∆} exp(−R"
N,0.7463465553235908,"κ ) +
κσ2"
N,0.7468684759916493,µNKR + (1 −S
N,0.7473903966597077,N ) κζ2 µSR + r 1 −S
N,0.7479123173277662,"N
ζF
√ S
)"
N,0.7484342379958246,"Proof. From Thm. E.1, we know that with K > max{ σ4"
N,0.7489561586638831,"ζ4 , κ2"
N,0.7494780793319415,R2 log2( ∆µ ζ2 )}
N,0.75,EF(ˆx1/2) −F(x∗) ≤O(ζ2
N,0.7505219206680585,"µ )
(259)"
N,0.7510438413361169,"From Lemma H.2, if K >
σ2
F
S min{∆, ζ2 µ }"
N,0.7515657620041754,EF(ˆx1) −F(x∗) ≤O(min{ζ2
N,0.7520876826722338,"µ , ∆} + r"
N,0.7526096033402923,1 −S −1
N,0.7531315240083507,"N −1
ζF
√"
N,0.7536534446764092,"S
)
(260)"
N,0.7541753653444676,"And so from Thm. D.1, we know that"
N,0.7546972860125261,"EF(ˆx2) −F(x∗)
(261)"
N,0.7552192066805845,≤˜O(min{ζ2
N,0.755741127348643,"µ , ∆} exp(−R"
N,0.7562630480167014,"κ ) +
σ2"
N,0.7567849686847599,µNKR + (1 −S
N,0.7573068893528184,N ) ζ2 µSR + r 1 −S
N,0.7578288100208769,"N
ζF
√"
N,0.7583507306889353,"S
))
(262)"
N,0.7588726513569938,"F.1.2
CONVERGENCE OF FEDAVG →SGD ON GENERAL CONVEX FUNCTIONS"
N,0.7593945720250522,"Proof. From Thm. E.1, we know that with K > max{ σ4"
N,0.7599164926931107,"ζ4 , β2D2 ζR }"
N,0.7604384133611691,EF(x(R)) −F(x∗) ≤˜O(ζD)
N,0.7609603340292276,"From Lemma H.2, if K >
σ2
F
S min{∆, ζ2 µ }"
N,0.761482254697286,"EF(ˆx1) −F(x∗) ≤˜O(min{ζD, ∆} + r"
N,0.7620041753653445,1 −S −1
N,0.7625260960334029,"N −1
ζF
√"
N,0.7630480167014614,"S
)
(263)"
N,0.7635699373695198,Published as a conference paper at ICLR 2022
N,0.7640918580375783,"And so from Thm. D.1, we know that"
N,0.7646137787056367,"E∥∇F(ˆx2)∥2 ≤˜O(β min{ζD, ∆} R
+ r 1 −S"
N,0.7651356993736952,"N
βζF
√"
N,0.7656576200417536,"SR
+
βσD
√ SKR
+ r 1 −S"
N,0.7661795407098121,"N
βζD
√"
N,0.7667014613778705,"SR
)
(264)"
N,0.767223382045929,"Next, using that E∥ˆx2 −x∗∥≤˜O(D2) from Thm. E.1 and Thm. D.1 as well as convexity,"
N,0.7677453027139874,"EF(ˆx2) −F(x∗)
(265) ≤
p"
N,0.7682672233820459,E∥∇F(ˆx2)∥2p
N,0.7687891440501043,"E∥ˆx2 −x∗∥2
(266)"
N,0.7693110647181628,"≤˜O(β1/2 min{ζ1/2D3/2, ∆1/2D}"
N,0.7698329853862212,"R1/2
(267)"
N,0.7703549060542797,+ β1/2σ1/2D3/2
N,0.7708768267223383,"(SKR)1/4
+ (1 −S"
N,0.7713987473903967,"N )1/4 β1/2ζ1/2
F
D
S1/4R1/2 + (1 −S"
N,0.7719206680584552,N )1/4 β1/2ζ1/2D3/2
N,0.7724425887265136,"(SR)1/4
)
(268)"
N,0.7729645093945721,"One can pre-run SGD before all of this for a constant fraction of rounds so that (Woodworth et al.,
2020a, Section 7):"
N,0.7734864300626305,∆≤˜O(βD2
N,0.774008350730689,"R
+
σD
√ SKR
+ r 1 −S"
N,0.7745302713987474,"N
ζD
√"
N,0.7750521920668059,"SR
)
(269)"
N,0.7755741127348643,"This likely not practically necessary § 6. Altogether,"
N,0.7760960334029228,"EF(ˆx2) −F(x∗)
(270) ≤
p"
N,0.7766179540709812,E∥∇F(ˆx2)∥2p
N,0.7771398747390397,"E∥ˆx2 −x∗∥2
(271)"
N,0.7776617954070981,≤˜O(min{β1/2ζ1/2D3/2
N,0.7781837160751566,"R1/2
, βD2"
N,0.778705636743215,"R }
(272)"
N,0.7792275574112735,+ β1/2σ1/2D3/2
N,0.7797494780793319,"(SKR)1/4
+ (1 −S"
N,0.7802713987473904,"N )1/4 β1/2ζ1/2
F
D
S1/4R1/2 + (1 −S"
N,0.7807933194154488,N )1/4 β1/2ζ1/2D3/2
N,0.7813152400835073,"(SR)1/4
)
(273)"
N,0.7818371607515657,"F.1.3
CONVERGENCE OF FEDAVG →SGD UNDER THE PL-CONDITION"
N,0.7823590814196242,Proof. The proof is the same as in the strongly convex case.
N,0.7828810020876826,"F.2
FEDAVG →ASG"
N,0.7834029227557411,"Theorem F.2. Suppose that client objectives Fi’s and their gradient queries satisfy Assumption B.4,
Assumption B.6, Assumption B.7, Assumption B.5, Assumption B.8. Then running Algo. 1 where
Alocal is Algo. 4 in the setting of Thm. E.1 and Aglobal is Algo. 3 in the setting Thm. D.1:"
N,0.7839248434237995,"• Strongly convex: Fi’s satisfy Assumption B.1 for µ > 0. Then there exists a lower bound of
K (same as in FedAvg →SGD) such that we have the rate"
N,0.784446764091858,˜O(min{ζ2
N,0.7849686847599165,"µ , ∆} exp(−R
√κ) +
σ2"
N,0.785490605427975,µSKR + (1 −S
N,0.7860125260960334,N ) ζ2 µSR + r 1 −S
N,0.7865344467640919,"N
ζF
√ S
)"
N,0.7870563674321504,"• General convex: Fi’s satisfy Assumption B.2. Then there exists a lower bound of K (same
as in FedAvg →SGD) such that we have the rate"
N,0.7875782881002088,˜O( min{β1/2ζ1/2D3/2
N,0.7881002087682673,"R
, βD2"
N,0.7886221294363257,R2 } + β1/2σ1/2D3/2
N,0.7891440501043842,"(SKR)1/4
+
σD
(SKR)1/2 + (1 −S"
N,0.7896659707724426,"N )1/2
ζD
(SR)1/2"
N,0.7901878914405011,+ (1 −S
N,0.7907098121085595,"N )1/4 β1/2ζ1/2
F
D
S1/4R1/2 + (1 −S"
N,0.791231732776618,N )1/4 β1/2ζ1/2D3/2
N,0.7917536534446764,"(SR)1/4
)"
N,0.7922755741127349,Proof follows those of FedAvg →SGD (Thm. F.1).
N,0.7927974947807933,Published as a conference paper at ICLR 2022
N,0.7933194154488518,"F.3
FEDAVG →SAGA"
N,0.7938413361169102,"Theorem F.3. Suppose that client objectives Fi’s and their gradient queries satisfy Assumption B.4,
Assumption B.6, Assumption B.7, Assumption B.5, Assumption B.8. Then running Algo. 1 where
Alocal is Algo. 4 in the setting of Thm. E.1 and Aglobal is Algo. 5 in the setting Thm. D.4:"
N,0.7943632567849687,"• Strongly convex: Fi’s satisfy Assumption B.1 for µ > 0. Then there exists a lower bound of
K (same as in FedAvg →SGD) such that we have the rate"
N,0.7948851774530271,˜O(min{ζ2
N,0.7954070981210856,"µ , ∆} exp(−max{N"
N,0.795929018789144,"S , κ}−1R) +
σ2 µSKR)"
N,0.7964509394572025,"• PL condition: Fi’s satisfy Assumption B.3 for µ > 0. Then there exists a lower bound of K
such that we have the rate"
N,0.7969728601252609,˜O(min{ζ2
N,0.7974947807933194,"µ , ∆} exp(−(κ(N"
N,0.7980167014613778,"S )2/3)−1R) +
σ2 µSK )"
N,0.7985386221294363,"Proof follows those of FedAvg →SGD (Thm. F.1) and using Lemma H.2 with S = N as the
algorithm already requires R > N S ."
N,0.7990605427974948,"F.4
FEDAVG →SSNM"
N,0.7995824634655533,"Theorem F.4. Suppose that client objectives Fi’s and their gradient queries satisfy Assumption B.4,
Assumption B.6, Assumption B.5, Assumption B.8. Then running Algo. 1 where Alocal is Algo. 4 in
the setting of Thm. E.1 and Aglobal is Algo. 6 in the setting Thm. D.5:"
N,0.8001043841336117,"• Strongly convex: Fi’s satisfy Assumption B.1 for µ > 0. Then there exists a lower bound of
K (same as in FedAvg →SGD) such that we have the rate"
N,0.8006263048016702,˜O(min{ζ2
N,0.8011482254697286,"µ , ∆} exp(−max{N S , r κ(N"
N,0.8016701461377871,S )}−1R) + κσ2 µKS )
N,0.8021920668058455,"Proof follows those of FedAvg →SGD (Thm. F.1) and using Lemma H.2 with S = N as the
algorithm already requires R > N S ."
N,0.802713987473904,"G
LOWER BOUND"
N,0.8032359081419624,"In this section we prove the lower bound. All gradients will be noiseless, and we will allow full
communication to all clients every round. There will be only two functions in this lower bound: F1
and F2. If N > 2, then F1 is assigned to the ﬁrst ⌊N/2⌋clients and F2 to the next ⌊N/2⌋clients. If
there is an odd number of machines we let the last machine be F3(x) = µ"
N,0.8037578288100209,"2 ∥x∥2. This only reduces
the lower bound by a factor of at most N−1"
N,0.8042797494780793,N . So we look at the case N = 2.
N,0.8048016701461378,"Let ℓ2, C, ˆζ be values to be chosen later. Let d be even. At a high level, ℓ2 essentially controls the
smoothness of F1 and F2, C is basically a constant, and ˆζ is a quantity that affects the heterogeneity,
initial suboptimality gap, and initial distance. We give the instance:"
N,0.8053235908141962,F1(x) = −ℓ2ˆζx1 + Cℓ2
N,0.8058455114822547,"2 x2
d + ℓ2 2"
N,0.8063674321503131,"d
2 −1
X"
N,0.8068893528183716,"i=1
(x2i+1 −x2i)2 + µ"
N,0.80741127348643,"2 ∥x∥2
(274)"
N,0.8079331941544885,"F2(x) = ℓ2 2 d/2
X"
N,0.808455114822547,"i=1
(x2i −x2i−1)2 + µ"
N,0.8089770354906054,"2 ∥x∥2
(275)"
N,0.8094989561586639,"Where F = F1+F2 2
."
N,0.8100208768267223,"These functions are the same as those used in (Woodworth et al., 2020a; Woodworth, 2021) for
lower bounds in distributed optimization. They are also similar to the instances used to prove convex"
N,0.8105427974947808,Published as a conference paper at ICLR 2022
N,0.8110647181628392,"optimization lower bounds (Nesterov, 2003) and distributed optimization lower bounds (Arjevani &
Shamir, 2015)."
N,0.8115866388308977,These two functions have the following property
N,0.8121085594989561,"xeven ∈span{e1, e2, . . . , e2i} =⇒
∇F1(xeven) ∈span{e1, e2, . . . , e2i+1}
∇F2(xeven) ∈span{e1, e2, . . . , e2i}
(276)"
N,0.8126304801670147,"xodd ∈span{e1, e2, . . . , e2i−1} =⇒
∇F1(xodd) ∈span{e1, e2, . . . , e2i−1}
∇F2(xodd) ∈span{e1, e2, . . . , e2i}
(277)"
N,0.8131524008350731,"What the property roughly says is the following. Suppose we so far have managed to turn an
even number of coordinates nonzero. Then we can only use gradient queries of F1 to access the
next coordinate. After client 1 queries the gradient of F1, it now has an odd number of unlocked
coordinates, and cannot unlock any more coordinates until a communication occurs. Similar is true if
the number of unlocked coordinates is odd. And so each round of communication can only unlock a
single new coordinate."
N,0.8136743215031316,We start by writing out the gradients of F1 and F2. Assume that d is even. Then:
N,0.81419624217119,"[∇F1(x)]1 = −ℓ2ˆζ + µx1
(278)
[∇F1(x)]d = Cℓ2xd + µxd
(279)
[∇F1(x)]i = ℓ2(xi −xi−1) + µxi i odd, 2 ≤i ≤d −1
[∇F1(x)]i = −ℓ2(xi+1 −xi) + µxi i even, 2 ≤i ≤d −1
(280) and"
N,0.8147181628392485,"[∇F2(x)]1 = −ℓ2(x2 −x1) + µx1
(281)
[∇F2(x)]d = ℓ2(xd −xd−1) + µxd
(282)
[∇F2(x)]i = −ℓ2(xi+1 −xi) + µxi i odd, 2 ≤i ≤d −1
[∇F2(x)]i = ℓ2(xi −xi−1) + µxi i even, 2 ≤i ≤d −1
(283)"
N,0.8152400835073069,"We deﬁne the class of functions that our lower bound will apply to. This deﬁnition follows (Wood-
worth et al., 2020a; Woodworth, 2021; Carmon et al., 2020):
Deﬁnition G.1 (Distributed zero-respecting algorithm). For a vector v, let supp(v) = {i ∈
{1, . . . , d} : vi ̸= 0}. We say that an optimization algorithm is distributed zero-respecting if
for any i, k, r, the k-th iterate on the i-th client in the r-th round x(r)
i,k satisfy"
N,0.8157620041753654,"supp(x(r)
i,k) ⊆
["
N,0.8162839248434238,"0≤k′<k
supp(∇Fi(x(r)
i,k′))
["
N,0.8168058455114823,"i′∈[N],0≤k′≤K−1,0≤r′<r
supp(∇Fi′(x(r′)
i′,k′))
(284)"
N,0.8173277661795407,"Broadly speaking, distributed zero-respecting algorithms are those whose iterates have components
in only dimensions that they can possibly have information on. As discussed in (Woodworth et al.,
2020a), this means that algorithms which are not distributed zero-respecting are just ”wild guessing”.
Algorithms that are distributed zero-respecting include SGD, ASG, FedAvg, SCAFFOLD, SAGA,
and SSNM."
N,0.8178496868475992,"Next, we deﬁne the next condition we require on algorithms for our lower bound.
Deﬁnition G.2. We say that an algorithm is distributed distance-conserving if for any i, k, r, we have
for the k-th iterate on the i-th client in the r-th round x(r)
i,k satisﬁes ∥x(r)
i,k −x∗∥2 ≤(c/2)[∥xinit −"
N,0.8183716075156576,"x∗∥2 + PN
i=1 ∥xinit −x∗
i ∥2], where x∗
j := arg minx Fj(x) and x∗:= arg minx F(x) and xinit is the
initial iterate, for some scalar parameter c."
N,0.8188935281837161,"Algorithms which do not satisfy Deﬁnition 5.2 for polylogarithmic c in problem parameters (see § 2)
are those that move substantially far away from x∗, even farther than the x∗
i ’s are from x∗. With this
deﬁnition in mind, we slightly overload the usual deﬁnition of heterogeneity for the lower bound:
Deﬁnition
G.3.
A
distributed
optimization
problem
is
(ζ, c)-heterogeneous
if
maxi∈[N] supx∈A ∥∇Fi(x) −∇F(x)∥2 ≤ζ2, where we deﬁne A := {x : ∥x −x∗∥2 ≤
(c/2)(∥xinit −x∗∥2 + PN
i=1 ∥xinit −x∗∥2)} for some scalar parameter c."
N,0.8194154488517745,Published as a conference paper at ICLR 2022
N,0.819937369519833,"While convergence rates in FL are usually proven under Assumption B.5, the proofs can be converted
to work under Deﬁnition G.3 as well, so long as one can prove all iterates stay within A as deﬁned
in Deﬁnition G.3. We show that our algorithms satisfy Deﬁnition G.3 as well as a result (Thm. E.1,
Thm. D.3, Thm. D.1)4. Other proofs of FL algorithms also satisfy this requirement, most notably the
proof of the convergence of FedAvg in Woodworth et al. (2020a)."
N,0.8204592901878914,"Following (Woodworth et al., 2020a), we start by making the argument that, given the algorithm is
distributed zero-respecting, we can only unlock one coordinate at a time. Let Ei = span{e1, . . . , ei},
and E0 be the null span. Then
Lemma G.4. Let ˆx be the output of a distributed zero-respecting algorithm optimizing F = 1"
N,0.8209812108559499,"2(F1 +
F2) after R rounds of communication. Then we have"
N,0.8215031315240083,"supp(ˆx) ∈ER
(285)"
N,0.8220250521920668,"Proof. A proof is in Woodworth et al. (2020a, Lemma 9)."
N,0.8225469728601252,We now compute various properties of this distributed optimization problem.
N,0.8230688935281837,"G.1
STRONG CONVEXITY AND SMOOTHNESS OF F, F1, F2"
N,0.8235908141962421,"From Woodworth (2021, Lemma 25), as long as ℓ2 ≤β−µ"
N,0.8241127348643006,"4 , we have that F, F1, F2 are β-smooth and
µ-strongly convex."
N,0.824634655532359,"G.2
THE SOLUTIONS OF F, F1, F2"
N,0.8251565762004175,"First, observe that from the gradient of F2 computed in Eq. (281), x∗
2 = arg minx F2(x) = ⃗0. Next
observe that from the gradient of F1 computed in Eq. (278), x∗
1 = arg minx F1(x) = ℓ2 ˆζ"
N,0.8256784968684759,µ e1. Thus
N,0.8262004175365344,"∥x∗
2∥2 = 0 and ∥x∗
1∥2 = ℓ2
2 ˆζ2 µ2 ."
N,0.826722338204593,"From Woodworth (2021, Lemma 25), if we let α =
q"
N,0.8272442588726514,1 + 2ℓ2
N,0.8277661795407099,"µ , q =
α−1
α+1, C = 1 −q, then"
N,0.8282881002087683,"∥x∗∥2 =
ˆζ2"
N,0.8288100208768268,"(1−q)2
Pd
i=1 q2i =
ˆζ2q2(1−q2d)
(1−q)2(1−q2)."
N,0.8293319415448852,"G.3
INITIAL SUBOPTIMALITY GAP"
N,0.8298538622129437,"From Woodworth (2021, Lemma 25), F(0) −F(x∗) ≤
qℓ2 ˆζ2"
N,0.8303757828810021,4(1−q).
N,0.8308977035490606,"G.4
SUBOPTIMALITY GAP AFTER R ROUNDS OF COMMUNICATION"
N,0.831419624217119,"From (Woodworth, 2021, Lemma 25), F(ˆx) −F(x∗) ≥
ˆζ2µq2"
N,0.8319415448851775,"16(1−q)2(1−q2)q2R, as long as d ≥R +"
N,0.8324634655532359,"log 2
2 log(1/q)."
N,0.8329853862212944,"G.5
COMPUTATION OF ζ2"
N,0.8335073068893528,"We start by writing out the difference between the gradient of F1 and F2, using Eq. (278) and
Eq. (281)."
N,0.8340292275574113,"∥∇F1(x) −∇F2(x)∥2 = ℓ2
2(−ˆζ + x2 −x1)2 + ℓ2
2(Cxd −xd + xd−1)2 + d−1
X"
N,0.8345511482254697,"i=2
ℓ2
2(xi+1 −xi−1)2 (286)"
N,0.8350730688935282,We upper bound each of the terms:
N,0.8355949895615866,"(xi+1 −xi−1)2 = x2
i+1 −2xi+1xi−1 + x2
i−1 ≤2x2
i+1 + 2x2
i−1
(287)"
N,0.8361169102296451,"4We do not formally show it for SAGA and SSNM, as the algorithms are functionally the same as SGD and
ASG under full participation."
N,0.8366388308977035,Published as a conference paper at ICLR 2022
N,0.837160751565762,"(−ˆζ + x2 −x1)2 = ˆζ2 + x2
2 + x2
1 −2ˆζx2 + 2ˆζx1 −2x2x1
(288)"
N,0.8376826722338204,"≤3ˆζ2 + 3x2
2 + 3x2
1
(289)"
N,0.8382045929018789,"(Cxd −xd + xd−1)2 = C2x2
d + x2
d + x2
d−1 −2Cx2
d + 2Cxdxd−1 −2xdxd−1
(290)"
N,0.8387265135699373,"≤C2x2
d + 2x2
d + 2x2
d−1 + 2Cx2
d−1
(291)"
N,0.8392484342379958,"So altogether, using the fact that C ≤1,"
N,0.8397703549060542,"1
ℓ2
2
∥∇F1(x) −∇F2(x)∥2
(292)"
N,0.8402922755741128,"≤3ˆζ2 + 3x2
2 + 3x2
1 + 3x2
d + 3x2
d−1 + d−1
X"
N,0.8408141962421712,"i=2
2x2
i+1 + 2x2
i−1
(293)"
N,0.8413361169102297,"≤3ˆζ2 + 7∥x∥2
(294)"
N,0.8418580375782881,"≤3ˆζ2 + 14∥x −x∗∥2 + 14∥x∗∥2
(295)"
N,0.8423799582463466,"≤5ˆζ2 + 28c
ˆζ2q2"
N,0.842901878914405,"(1 −q)2(1 −q2) + 28cℓ2
2ˆζ2"
N,0.8434237995824635,"µ2
(296)"
N,0.843945720250522,Next we use Deﬁnition G.2 which says that ∥x −x∗∥≤c
N,0.8444676409185804,"2[∥xinit −x∗∥2 + PN
i=1 ∥xinit −x∗
i ∥2]. For"
N,0.8449895615866388,"ease of calculation, we assume c ≥1. Recall that we calculated ∥x∗∥2 ≤
ˆζ2q2"
N,0.8455114822546973,(1−q)2(1−q2) (because
N,0.8460334029227558,"0 < q < 1), ∥x∗
2∥2 = 0, ∥x∗
1∥2 = ℓ2
2 ˆζ2 µ2 ."
N,0.8465553235908142,"1
ℓ2
2
∥∇F1(x) −∇F2(x)∥2 ≤3ˆζ2 + 24c∥x∗∥2 + 7c∥x∗
1∥2 + 7c∥x∗
2∥2
(297)"
N,0.8470772442588727,"≤3ˆζ2 +
24cˆζ2q2"
N,0.8475991649269311,"(1 −q)2(1 −q2) + 7cℓ2
2ˆζ2"
N,0.8481210855949896,"µ2
(298)"
N,0.848643006263048,"Altogether,"
N,0.8491649269311065,"∥∇F1(x) −∇F2(x)∥2 ≤3ℓ2
2ˆζ2 +
24cℓ2
2ˆζ2q2"
N,0.8496868475991649,"(1 −q)2(1 −q2) + 7cℓ4
2ˆζ2"
N,0.8502087682672234,"µ2
(299)"
N,0.8507306889352818,"G.6
THEOREM"
N,0.8512526096033403,"With all of the computations earlier, we are now prepared to prove the theorem.
Theorem G.5. For any number of rounds R, number of local steps per-round K, and (ζ, c)-
heterogeneity (Deﬁnition 5.3), there exists a global objective F which is the average of two β-smooth
(Assumption B.4) and µ(≥0)-strongly convex (Assumption B.1) quadratic client objectives F1 and
F2 with an initial sub-optimality gap of ∆, such that the output ˆx of any distributed zero-respecting
(Deﬁnition 5.1) and distance-conserving algorithm (Deﬁnition 5.2) satisﬁes"
N,0.8517745302713987,"• Strongly convex: F(ˆx) −F(x∗) ≥Ω(min{∆, 1/(cκ3/2)(ζ2/β)} exp(−R/√κ).) when
µ > 0, and"
N,0.8522964509394572,"• General Convex F(ˆx) −F(x∗) ≥Ω(min{βD2/R2, ζD/(c1/2√"
N,0.8528183716075156,R5)}) when µ = 0.
N,0.8533402922755741,"Proof. The convex case: By the previous computations, we know that after R rounds,"
N,0.8538622129436325,"F(ˆx) −F(x∗) ≥
µˆζ2q2"
N,0.8543841336116911,"16(1 −q)2(1 −q2)q2R
(300)"
N,0.8549060542797495,"∥x∗∥2 ≤
ˆζ2q2"
N,0.855427974947808,"(1 −q)2(1 −q2)
(301)"
N,0.8559498956158664,"∥∇F1(x) −∇F2(x)∥2 ≤3ℓ2
2ˆζ2 +
24cℓ2
2ˆζ2q2"
N,0.8564718162839249,"(1 −q)2(1 −q2) + 7cℓ4
2ˆζ2"
N,0.8569937369519833,"µ2
(302)"
N,0.8575156576200418,Published as a conference paper at ICLR 2022
N,0.8580375782881002,"To maintain the property that ∥x(0) −x∗∥= ∥x∗∥≤D and Deﬁnition G.3, Choose ˆζ s.t."
N,0.8585594989561587,ˆζ2 = ν min{ζ2
N,0.8590814196242171,"ℓ2
2
, (1 −q)2(1 −q2)ζ2"
N,0.8596033402922756,"cℓ2
2q2
, µ2ζ2"
N,0.860125260960334,"cℓ4
2
, (1 −q)2(1 −q2)D2"
N,0.8606471816283925,"q2
}
(303)"
N,0.8611691022964509,For an absolute constant ν.
N,0.8616910229645094,This leads to (throughout we use µ
N,0.8622129436325678,ℓ2 = (1−q)2
Q,0.8627348643006263,"2q
, (Woodworth, 2021, Eq 769))"
Q,0.8632567849686847,"F(ˆx) −F(x∗)
(304)"
Q,0.8637787056367432,"≥
µˆζ2q2"
Q,0.8643006263048016,"16(1 −q)2(1 −q2)q2R
(305)"
Q,0.8648225469728601,≥ν min{µζ2
Q,0.8653444676409185,"ℓ2
2
, µ(1 −q)2(1 −q2)ζ2"
Q,0.865866388308977,"cℓ2
2q2
, µ3ζ2"
Q,0.8663883089770354,"cℓ4
2
, µ(1 −q)2(1 −q2)D2"
Q,0.8669102296450939,"q2
}
q2"
Q,0.8674321503131524,16(1 −q)2(1 −q2)q2R (306)
Q,0.8679540709812108,≥ν min{(1 −q)2ζ2
Q,0.8684759916492694,"2ℓ2q
, µ(1 −q)2(1 −q2)ζ2"
Q,0.8689979123173278,"cℓ2
2q2
,
(307)"
Q,0.8695198329853863,µζ2(1 −q)4
Q,0.8700417536534447,"4cℓ2
2q2
, µ(1 −q)2(1 −q2)D2"
Q,0.8705636743215032,"q2
}
q2"
Q,0.8710855949895616,"16(1 −q)2(1 −q2)q2R
(308)"
Q,0.8716075156576201,"≥ν min{
ζ2q
32ℓ2(1 −q2), µζ2"
Q,0.8721294363256785,"16cℓ2
2
, µζ2(1 −q)"
Q,0.872651356993737,"64cℓ2
2(1 + q), µD2"
Q,0.8731732776617954,"16 }q2R
(309) (310)"
Q,0.8736951983298539,"We choose µ =
ℓ2
64R2 , which ensures α ≥2. So noting that (1 −q2) = (1 −q)(1 + q) ≤(1 + q),
1 + q =
2α
α+1, 1 −q =
2
α+1:"
Q,0.8742171189979123,"F(ˆx) −F(x∗)
(311)"
Q,0.8747390396659708,≥ν min{ ζ2
Q,0.8752609603340292,"32ℓ2
(α −1"
Q,0.8757828810020877,"α + 1
α + 1"
Q,0.8763048016701461,"2α ), µζ2"
Q,0.8768267223382046,"16cℓ2
2
, µζ2"
Q,0.877348643006263,"64cℓ2
2
(
2
α + 1
α + 1"
Q,0.8778705636743215,"2α ), µD2"
Q,0.8783924843423799,"16 }q2R
(312)"
Q,0.8789144050104384,≥ν min{ ζ2
Q,0.8794363256784968,"32ℓ2
(α −1"
Q,0.8799582463465553,"α + 1
α + 1"
Q,0.8804801670146137,"2α ), µζ2"
Q,0.8810020876826722,"16cℓ2
2
, µζ2"
Q,0.8815240083507306,"64cℓ2
2
(
2
α + 1
α + 1"
Q,0.8820459290187892,"2α ), µD2"
Q,0.8825678496868476,16 } exp(−2R log(α + 1
Q,0.8830897703549061,α −1)) (313)
Q,0.8836116910229646,≥ν min{ ζ2
Q,0.884133611691023,"64ℓ2
, µζ2"
Q,0.8846555323590815,"16cℓ2
2
, µζ2"
Q,0.8851774530271399,"64cℓ2
2
( 1"
Q,0.8856993736951984,"α), µD2"
Q,0.8862212943632568,16 } exp(−4R
Q,0.8867432150313153,"α −1)
(314) So,"
Q,0.8872651356993737,"F(ˆx) −F(x∗)
(315)"
Q,0.8877870563674322,≥ν min{ ζ2
Q,0.8883089770354906,"64ℓ2
, µζ2"
Q,0.8888308977035491,"16cℓ2
2
, µζ2"
Q,0.8893528183716075,"64cℓ2
2
( µ"
Q,0.889874739039666,"3ℓ2
)1/2, µD2"
Q,0.8903966597077244,"16 } exp(−8R√µ
√ℓ2
)
(316)"
Q,0.8909185803757829,≥Ω(min{ζ2
Q,0.8914405010438413,"ℓ2
,
ζ2"
Q,0.8919624217118998,"cℓ2R2 ,
ζ2"
Q,0.8924843423799582,"cℓ2R3 , ℓ2D2"
Q,0.8930062630480167,"R2 })
(317)"
Q,0.8935281837160751,"≥Ω(
ζ2"
Q,0.8940501043841336,"cℓ2R3 , ℓ2D2"
Q,0.894572025052192,"R2 })
(318) (319)"
Q,0.8950939457202505,"Where we used c > 1. Setting ℓ2 = Θ(min{β,
ζ
c1/2DR1/2 }) (which will ensure that ℓ2 ≤β−µ"
WITH,0.8956158663883089,"4
with
appropriate constants chosen), Which altogether gives us"
WITH,0.8961377870563675,"F(ˆx) −F(x∗) ≥Ω(min{
ζD
c1/2R5/2 , βD2"
WITH,0.8966597077244259,"R2 })
(320)"
WITH,0.8971816283924844,Strongly Convex Case:
WITH,0.8977035490605428,Published as a conference paper at ICLR 2022
WITH,0.8982254697286013,"By the previous computations, we know that after R rounds,"
WITH,0.8987473903966597,"F(ˆx) −F(x∗) ≥
µˆζ2q2"
WITH,0.8992693110647182,"16(1 −q)2(1 −q2)q2R
(321)"
WITH,0.8997912317327766,"F(ˆx) −F(x∗) ≤
qℓ2ˆζ2"
WITH,0.9003131524008351,"4(1 −q)
(322)"
WITH,0.9008350730688935,"∥∇F1(x) −∇F2(x)∥2 ≤3ℓ2
2ˆζ2 +
24cℓ2
2ˆζ2q2"
WITH,0.901356993736952,"(1 −q)2(1 −q2) + 7cℓ4
2ˆζ2"
WITH,0.9018789144050104,"µ2
(323)"
WITH,0.9024008350730689,"To maintain the property that F(ˆx) −F(x∗) ≤∆and that ∥∇F1(x) −∇F2(x)∥2 ≤ζ2 for all x
encountered during the execution of the algorithm,"
WITH,0.9029227557411273,Choose ˆζ s.t.
WITH,0.9034446764091858,ˆζ2 = ν min{ζ2
WITH,0.9039665970772442,"ℓ2
2
, (1 −q)2(1 −q2)ζ2"
WITH,0.9044885177453027,"cℓ2
2q2
, µ2ζ2"
WITH,0.9050104384133612,"cℓ4
2
, (1 −q)∆"
WITH,0.9055323590814196,"qℓ2
}
(324)"
WITH,0.906054279749478,For some constant ν.
WITH,0.9065762004175365,Again using µ
WITH,0.907098121085595,ℓ2 = (1−q)2
Q,0.9076200417536534,"2q
) and following the same calculations as in the convex case, we use the fact"
Q,0.9081419624217119,"that 9µ ≤β, and that it is possible to choose ℓ2 s.t. 2µ ≤ℓ2 ≤β−µ"
Q,0.9086638830897703,"4 , which ensures β ≥2."
Q,0.9091858037578288,"F(ˆx) −F(x∗)
(325)"
Q,0.9097077244258872,"≥
µˆζ2q2"
Q,0.9102296450939458,"16(1 −q)2(1 −q2)q2R
(326)"
Q,0.9107515657620042,≥ν min{ ζ2
Q,0.9112734864300627,"64ℓ2
, µζ2"
Q,0.9117954070981211,"16cℓ2
2
, µζ2"
Q,0.9123173277661796,"64cℓ2
2
( 1 α), ∆"
Q,0.912839248434238,4 } exp(−4R
Q,0.9133611691022965,"α −1)
(327) (328)"
Q,0.9138830897703549,We use 9µ ≤β and because it is possible to choose ℓ2 such that 2µ ≤ℓ2 ≤β−µ
Q,0.9144050104384134,"4
(Woodworth, 2021,"
Q,0.9149269311064718,"Eq. 800), which ensures α ≥2 and 1 α ≥
q µ
3ℓ2"
Q,0.9154488517745303,"F(ˆx) −F(x∗)
(329)"
Q,0.9159707724425887,≥Ω(min{ζ2
Q,0.9164926931106472,"ℓ2
, µζ2"
Q,0.9170146137787056,"cℓ2
2
, µζ2"
Q,0.9175365344467641,"cℓ2
2
( µ"
Q,0.9180584551148225,"ℓ2
)1/2, ∆} exp(−8R√µ
√ℓ2
))
(330)"
Q,0.918580375782881,≥Ω(min{µζ2
Q,0.9191022964509394,"cℓ2
2
( µ"
Q,0.9196242171189979,"ℓ2
)1/2, ∆} exp(−8R√µ
√ℓ2
))
(331)"
Q,0.9201461377870563,Next we note that ℓ2 ≤β and ℓ2 ≥β
Q,0.9206680584551148,"5 (Woodworth, 2021, Eq 801), which gives us"
Q,0.9211899791231732,F(ˆx) −F(x∗) ≥Ω(min{µ3/2ζ2
Q,0.9217118997912317,"cβ5/2 , ∆} exp(−18R
√κ ))
(332)"
Q,0.9222338204592901,"H
TECHNICAL LEMMAS"
Q,0.9227557411273486,Lemma H.1. Let
Q,0.923277661795407,"g(r) :=
1
SK X i∈Sr K
X"
Q,0.9237995824634656,"k=1
g(r)
i,k
(333)"
Q,0.9243215031315241,"Given Assumption B.6, Assumption B.5, and uniformly sampled clients per round, E∥1 SK X i∈Sr K
X"
Q,0.9248434237995825,"k=1
g(r)
i,k −∇F(x(r))∥2 ≤σ2"
Q,0.925365344467641,SK + (1 −S −1
Q,0.9258872651356994,N −1)ζ2
Q,0.9264091858037579,"S
(334)"
Q,0.9269311064718163,Published as a conference paper at ICLR 2022
Q,0.9274530271398748,"If instead the clients are arbitrarily (possibly randomly) sampled and there is no gradient variance, ∥1 SK X i∈Sr K
X"
Q,0.9279749478079332,"k=1
g(r)
i,k −∇F(x(r))∥2 ≤ζ2
(335)"
Q,0.9284968684759917,"Proof. E∥1 SK X i∈Sr K
X"
Q,0.9290187891440501,"k=1
∇f(x; zi) −∇F(x)∥2
(336) = E∥1 S X"
Q,0.9295407098121086,"i∈Sr
∇Fi(x) −∇F(x)∥2 + ESr∥1 SK X i∈Sr K−1
X"
Q,0.930062630480167,"k=0
∇f(x; zi) −∇Fi(x)∥2
(337) ≤E∥1 S X"
Q,0.9305845511482255,"i∈Sr
∇Fi(x) −∇F(x)∥2 +
1
SK E∥∇f(x; zi) −∇Fi(x)∥2
(338) (339)"
Q,0.9311064718162839,"Where the ﬁrst inequality uses the fact that E[X2] = Var(X) + E[X]2, and the second equality
uses the fact that the variance is i.i.d across i and k. Note that E∥∇f(x; zi) −∇Fi(x)∥2 ≤σ2 by
Assumption B.6. On the other hand by Assumption B.5 E∥1 S X"
Q,0.9316283924843424,"i∈Sr
∇Fi(x) −∇F(x)∥2 ≤(1 −S −1"
Q,0.9321503131524008,N −1)E∥∇Fi(x) −∇F(x)∥2
Q,0.9326722338204593,"S
≤(1 −S −1"
Q,0.9331941544885177,N −1)ζ2 S (340)
Q,0.9337160751565762,"So altogether E∥1 SK X i∈Sr K
X"
Q,0.9342379958246346,"k=1
∇f(x; zi) −∇F(x)∥2 ≤σ2"
Q,0.9347599164926931,SK + (1 −S −1
Q,0.9352818371607515,N −1)ζ2
Q,0.93580375782881,"S
(341)"
Q,0.9363256784968684,The second conclusion follows by noting ∥1 S X
Q,0.9368475991649269,"i∈Sr
∇Fi(x) −∇F(x)∥2 ≤1 S X"
Q,0.9373695198329853,"i∈Sr
∥∇Fi(x) −∇F(x)∥2
(342)"
Q,0.9378914405010439,"Lemma
H.2.
Let
u, v
be
arbitrary
(possibly
random)
points.
Deﬁne
ˆF(x)
=
1
SK
P"
Q,0.9384133611691023,"i∈S
PK−1
k=0 f(x; ˆzi,k) where ˆzi,k ∼Di. Let"
Q,0.9389352818371608,"w = arg min
x∈{u,v}
ˆF(x) Then"
Q,0.9394572025052192,"E[F(w) −F(x∗)]
(343)"
Q,0.9399791231732777,"≤min{F(u) −F(x∗), F(v) −F(x∗)} + 4 σF
√"
Q,0.9405010438413361,"SK
+ 4 r"
Q,0.9410229645093946,1 −S −1
Q,0.941544885177453,"N −1
ζF
√"
Q,0.9420668058455115,"S
(344) and"
Q,0.94258872651357,"E[F(w) −F(x∗)]
(345)"
Q,0.9431106471816284,"≤min{EF(u) −F(x∗), EF(v) −F(x∗)} + 4 σF
√"
Q,0.9436325678496869,"SK
+ 4 r"
Q,0.9441544885177453,1 −S −1
Q,0.9446764091858038,"N −1
ζF
√"
Q,0.9451983298538622,"S
(346)"
Q,0.9457202505219207,"Proof. Suppose that F(u) + 2a = F(v), where a ≥0. Then,"
Q,0.9462421711899791,"E[F(w) −F(x∗)] = P(w = u)(F(u) −F(x∗)) + P(w = v)(F(v) −F(x∗))
(347)"
Q,0.9467640918580376,Published as a conference paper at ICLR 2022
Q,0.947286012526096,"Substituting F(v) = F(u) + 2a,
E[F(w) −F(x∗)] = P(w = u)(F(u) −F(x∗)) + P(w = v)(F(u) + 2a −F(x∗))
(348)
≤F(u) −F(x∗) + 2a
(349)"
Q,0.9478079331941545,"Observe that E( ˆF(x) −F(x))2 ≤σ2
F
SK + (1 −S−1"
Q,0.9483298538622129,"N−1) ζ2
F
S by Assumption B.7 and Assumption B.8.
Therefore by Chebyshev’s inequality,"
Q,0.9488517745302714,P(| ˆF(x) −F(x)| ≥a) ≤1
Q,0.9493736951983298,"a2 ( σ2
F
SK + (1 −S −1"
Q,0.9498956158663883,"N −1)ζ2
F
S )
(350)"
Q,0.9504175365344467,"Observe that
P(w = v) ≤P( ˆF(u) > F(u) + a) + P( ˆF(v) < F(v) −a)
(351) ≤2"
Q,0.9509394572025052,"a2 ( σ2
F
SK + (1 −S −1"
Q,0.9514613778705637,"N −1)ζ2
F
S )
(352)"
Q,0.9519832985386222,"And so it is also true that
E[F(w) −F(x∗)] = F(u) −F(x∗) + 2aP(w = v)
(353)"
Q,0.9525052192066806,≤F(u) −F(x∗) + 2a( 2
Q,0.9530271398747391,"a2 ( σ2
F
SK + (1 −S −1"
Q,0.9535490605427975,"N −1)ζ2
F
S ))
(354)"
Q,0.954070981210856,= F(u) −F(x∗) + 4
Q,0.9545929018789144,"a( σ2
F
SK + (1 −S −1"
Q,0.9551148225469729,"N −1)ζ2
F
S )
(355)"
Q,0.9556367432150313,Therefore altogether we have that
Q,0.9561586638830898,"E[F(w) −F(x∗)] ≤F(u) −F(x∗) + max
a
min{4"
Q,0.9566805845511482,"a( σ2
F
SK + (1 −S −1"
Q,0.9572025052192067,"N −1)ζ2
F
S ), 2a}
(356)"
Q,0.9577244258872651,So by maximizing for a
Q,0.9582463465553236,"4
a( σ2
F
SK + (1 −S −1"
Q,0.958768267223382,"N −1)ζ2
F
S ) = 2a =⇒a = s"
Q,0.9592901878914405,"2( σ2
F
SK + (1 −S −1"
Q,0.9598121085594989,"N −1)ζ2
F
S )
(357)"
Q,0.9603340292275574,which gives us
Q,0.9608559498956158,"E[F(w) −F(x∗)] ≤F(u) −F(x∗) + 4 σF
√"
Q,0.9613778705636743,"SK
+ 4 r"
Q,0.9618997912317327,1 −S −1
Q,0.9624217118997912,"N −1
ζF
√"
Q,0.9629436325678496,"S
(358)"
Q,0.9634655532359081,"Then proof also holds if we switch the roles of u and v, and so altogether we have that: if F(u) <
F(v),"
Q,0.9639874739039666,"E[F(w) −F(x∗)] ≤F(u) −F(x∗) + 4 σF
√"
Q,0.964509394572025,"SK
+ 4 r"
Q,0.9650313152400835,1 −S −1
Q,0.965553235908142,"N −1
ζF
√"
Q,0.9660751565762005,"S
(359)"
Q,0.9665970772442589,"if F(u) > F(v),"
Q,0.9671189979123174,"E[F(w) −F(x∗)] ≤F(v) −F(x∗) + 4 σF
√"
Q,0.9676409185803758,"SK
+ 4 r"
Q,0.9681628392484343,1 −S −1
Q,0.9686847599164927,"N −1
ζF
√"
Q,0.9692066805845512,"S
(360)"
Q,0.9697286012526096,implying the ﬁrst part of the theorem.
Q,0.9702505219206681,"E[F(w) −F(x∗)] ≤min{F(u) −F(x∗), F(v) −F(x∗)} + 4 σF
√"
Q,0.9707724425887265,"SK
+ 4 r"
Q,0.971294363256785,1 −S −1
Q,0.9718162839248434,"N −1
ζF
√"
Q,0.9723382045929019,"S
(361)
For the second part,"
Q,0.9728601252609603,"E[min{F(u) −F(x∗), F(v) −F(x∗)}|v] =
Z"
Q,0.9733820459290188,"F (u)≤F (v)
F(u) −F(x∗)
(362)"
Q,0.9739039665970772,"≤min{EF(u) −F(x∗), F(v) −F(x∗)}
(363)
and then"
Q,0.9744258872651357,"E[min{EF(u) −F(x∗), F(v) −F(x∗)}] =
Z"
Q,0.9749478079331941,"F (v)≤EF (u)
F(u) −F(x∗)
(364)"
Q,0.9754697286012526,"≤min{EF(u) −F(x∗), EF(v) −F(x∗)}
(365)"
Q,0.975991649269311,Published as a conference paper at ICLR 2022
Q,0.9765135699373695,"I
EXPERIMENTAL SETUP DETAILS"
Q,0.9770354906054279,"I.1
CONVEX OPTIMIZATION"
Q,0.9775574112734864,"We empirically evaluate FedChain on federated regularized logistic regression. Let (xi,j, yi,j) be the
jth datapoint of the ith client and ni is the number of datapoints for the i-th client. We minimize
Eq. (1) where"
Q,0.9780793319415448,"Fi(w) = 1 ni
( ni
X"
Q,0.9786012526096033,"j=1
−yi,j log(w⊤xi,j) −(1 −yi,j) log(1 −w⊤xi,j))) + µ"
Q,0.9791231732776617,2 ∥w∥2.
Q,0.9796450939457203,"Dataset. We use the MNIST dataset of handwritten digits (LeCun et al., 2010). We model a federated
setting with ﬁve clients by partitioning the data into groups. First, we take 500 images from each
digit class (total 5,000). Each client’s local data is a mixture of data drawn from two digit classes
(leading to heterogeneity), and data sampled uniformly from all classes."
Q,0.9801670146137788,"We call a federated dataset X% homogeneous if the ﬁrst X% of each class’s 500 images is shufﬂed
and evenly partitioned to each client. The remaining (100 −X)% is partitioned as follows: client
i ∈{1, . . . , 5} receives the remaining non-shufﬂed data from classes 2i −2 and 2i −1. For example,
in a 50% homogeneous setup, client 3 has 250 samples from digit 4, 250 samples from digit 5, and
500 samples drawn uniformly from all classes. Note that 100% homogeneity is not the same thing as
setting heterogeneity ζ = 0 due to sampling randomness; we use this technique for lack of a better
control over ζ. To model binary classiﬁcation, we let even classes represent 0’s and odd classes
represent 1’s, and set K = 20. All clients participate per round."
Q,0.9806889352818372,"Hyperparameters. All experiments initialize iterates at 0 with regularization µ = 0.1. We ﬁx the
total number of rounds R (differs across experiments). For algorithms without stepsize decay, the
tuning process is as follows."
Q,0.9812108559498957,We tune all stepsizes η in the range below:
Q,0.9817327766179541,"{10−3, 10−2.5, 10−2, 10−1.5, 10−1}
(366)"
Q,0.9822546972860126,We tune the percentage of rounds before switching from Alocal to Aglobal (if applicable) as
Q,0.982776617954071,"{10−2, 10−1.625, 10−1.25, 10−0.875, 10−0.5}
(367)"
Q,0.9832985386221295,"For algorithms with acceleration, we run experiments using the more easily implementable (but less
mathematically tractable for our analysis) version in Aybat et al. (2019) as opposed to Algo. 3."
Q,0.9838204592901879,"For algorithms with stepsize decay, we instead use the range Eq. (367) to decide the percentage
of rounds to wait before decreasing the stepsize by half–denote this number of rounds as Rdecay.
Subsequently, every factor of 2 times Rdecay we decrease the stepsize by half."
Q,0.9843423799582464,"We use the heuristic that when the stepsize decreases to η/K, we switch to Aglobal and begin the
stepsize decay process again. All algorithms are tuned to the best ﬁnal gradient norm averaged over
1000 runs."
Q,0.9848643006263048,"I.2
NONCONVEX OPTIMIZATION"
Q,0.9853862212943633,"I.2.1
EMNIST"
Q,0.9859081419624217,"In this section we detail how we use the EMNIST (Cohen et al., 2017) dataset for our nonconvex
experiments, where the handwritten characters are partitioned by their author. In this dataset, there
are 3400 clients, with 671,585 images in the train set and 77,483 in the test set. The task is to train a
convolutional network with two convolutional layers, max-pooling, dropout, and two dense layers as
in the Federated Learning task suite from (Reddi et al., 2020)."
Q,0.9864300626304802,"Hyperparameters. We set R = 500, and rather than ﬁxing the number of local steps, we ﬁx the
number of local client epochs (the number of times a client performs gradient descent over its own
dataset) to 20. The number of clients sampled per round is 10. These changes were made in light of
the imbalanced dataset sizes across clients, and is standard for this dataset-task (Reddi et al., 2020;
Charles & Koneˇcn`y, 2020; Charles et al., 2021). For all algorithms aside from (M-SGD), we tune"
Q,0.9869519832985386,Published as a conference paper at ICLR 2022
Q,0.9874739039665971,"η in the range {0.05, 0.1, 0.15, 0.2, 0.25}. We tune the percentage of rounds before switching from
Alocal to Aglobal in {0.1, 0.3, 0.5, 0.7, 0.9}, where applicable."
Q,0.9879958246346555,"We next detail the way algorithms with stepsize decay are run.
We tune the stepsize η in
{0.1, 0.2, 0.3, 0.4, 0.5}. Let Rdecay be the number of rounds before the ﬁrst decay event. We
tune Rdecay ∈⌈{0.1R, 0.275R, 0.45R}⌉. Whenever the number of passed rounds is a power of
2 of Rdecay, we halve the stepsize/ After R′ rounds have passed, we enter Aglobal, where we tune
R′ ∈⌈{0.5R, 0.7R, 0.9R}⌉. We restart the decay process upon entering Aglobal."
Q,0.988517745302714,"For M-SGD we tune
η ∈{0.1, 0.2, 0.3, 0.4, 0.5}"
Q,0.9890396659707724,"and
Rdecay ∈⌈{10−2R, 10−1.625R, 10−1.25R, 10−0.875R, 10−0.5R}⌉"
Q,0.9895615866388309,"For stepsize decaying SCAFFOLD and FedAvg, we tune η ∈{0.1, 0.2, 0.3, 0.4, 0.5} and Rdecay ∈
⌈{0.1R, 0.275R, 0.45R}⌉. When evaluating a particular metric the algorithms are tuned according
to the mean of the last 5 evaluated iterates of that particular metric. Reported accuracies are also the
mean of the last 5 evaluated iterates, as the values mostly stabilized during training."
Q,0.9900835073068893,"I.2.2
CIFAR-100"
Q,0.9906054279749478,"For the CIFAR-100 experiments, we use the CIFAR-100 (Krizhevsky, 2009) dataset, where the
handwritten characters are partitioned via the method proposed in (Reddi et al., 2020). In this dataset,
there are 500 train clients, with a total of 50,000 images in the train set. There are 100 test clients and
10,000 images in the test set. The task is to train a ResNet-18, replacing batch normalization layers
with group normalization as in the Federated Learning task suite from (Reddi et al., 2020). We leave
out SCAFFOLD in all experiments because of out of memory issues."
Q,0.9911273486430062,"Hyperparameters.
We set R = 5000, and rather than ﬁxing the number of local steps, we ﬁx
the number of local client epochs (the number of times a client performs gradient descent over its
own dataset) to 20. The number of clients sampled per round is 10. These changes were made
in light of the imbalanced dataset sizes across clients, and is standard for this dataset-task (Reddi
et al., 2020; Charles & Koneˇcn`y, 2020; Charles et al., 2021). For all algorithms we tune η in
{0.1, 0.2, 0.3, 0.4, 0.5}. Algorithms without stepsize decay tune the percentage of rounds before
switching to Aglobal in {0.1, 0.3, 0.5, 0.7, 0.9}. Algorithms with stepsize decay (aside from M-SGD)
tune the number of rounds before the ﬁrst decay event in {0.1, 0.275, 0.45} (and for every power of 2
of that percentage, the stepsize decays in half), and the number of rounds before swapping to Aglobal
in {0.5, 0.7, 0.9} if applicable (stepsize decay process restarts after swapping). M-SGD tunes the
number of rounds before the ﬁrst decay event in {0.01, 0.0237, 0.0562, 0.1334, 0.3162}. We tune for
and return the test accuracy of the last iterate, as accuracy was still improving as we trained."
Q,0.9916492693110647,"J
ADDITIONAL CONVEX EXPERIMENTS"
Q,0.9921711899791231,"In this section, we give supplemental experimental results to verify the following claims:"
Q,0.9926931106471816,"1. Higher K allows (1) accelerated algorithms to perform better than non-accelerated algo-
rithms, and furthermore (2) allows us to run Alocal for one round to get satisfactory results."
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.9932150313152401,2. Our FedChain instantiations outperform stepsize decaying baselines
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.9937369519832986,"J.1
VERIFYING THE EFFECT OF INCREASED K AND R = 1"
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.994258872651357,"Our proofs of FedChain all also work if we run Alocal for only one communication round, so long as
K is sufﬁciently large (exact number is in the formal theorem proofs). In this section we verify the
effect of large K in conjunction with running Alocal for only one round. The setup is the same as in
App. I.1, except we tune the stepsize η in a larger grid:"
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.9947807933194155,"η ∈{10−3, 10−2.5, 10−2, 10−1.5, 10−1, 10−0.5, 100}
(368)"
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.9953027139874739,"The plots are in Fig. 3. For algorithms that are “1-X→Y”, we run algorithm X for one round and
algorithm Y for the rest of the rounds. These algorithms are tuned in the following way. Algorithm X"
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.9958246346555324,Published as a conference paper at ICLR 2022
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.9963465553235908,"Figure 3: We investigate the effect of high K (K = 100). “1-X→Y” denotes a chained algorithm
with X run for one round and Y run for the rest of the rounds. Chained algorithms, even with one
round allocated to Alocal, perform the best. Furthermore, accelerated algorithms outperform their
non-accelerated counterparts."
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.9968684759916493,"Figure 4: The same as Fig. 2, except we include stepsize decay for baseline algorithms. Chained
algorithms still perform the best."
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.9973903966597077,"has its stepsize tuned in Eq. (368), and Algorithm Y independently has its stepsize tuned in Eq. (368).
We require these to be tuned separately because local update algorithms and centralized algorithms
have stepsizes that depend on K differently if K is large (see, for example, Thm. D.1 and Thm. E.1).
The baselines have a single stepsize tuned in Eq. (368). These are tuned for the lowest ﬁnal gradient
norm averaged over 1000 runs."
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.9979123173277662,"Overall, we see that in the large K regime, algorithms that start with a local update algorithm and
then ﬁnish with an accelerated centralized algorithm have the best communication complexity. This
is because larger K means the error due to variance decreases, for example as seen in Thm. F.2.
Acceleration increases instability (if one does not perform a carefully calibrated stepsize decay,
as we do not in the experiments), so decreasing variance helps accelerated algorithms the most.
Furthermore, a single round for Alocal sufﬁces to see large improvement as seen in Fig. 3. This is
expected, because both the “bias” term (the ∆exp(−R
√"
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.9984342379958246,"K
κ
) term in Thm. E.1) and the variance term
become negligible, leaving just the heterogeneity term as desired."
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.9989561586638831,"J.2
INCLUDING STEPSIZE DECAY BASELINES"
OUR FEDCHAIN INSTANTIATIONS OUTPERFORM STEPSIZE DECAYING BASELINES,0.9994780793319415,"In this section, we compare the performance of the algorithms against learning rate decayed SGD,
FedAvg, ASG, and SCAFFOLD. We use the same setting as App. I.1 for the decay process and
the stepsize. In this case, we still see that the chained methods outperform their non-chained
counterparts."
