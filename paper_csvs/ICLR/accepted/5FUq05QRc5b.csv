Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0012315270935960591,"Multiple views of data, both naturally acquired (e.g., image and audio) and arti-
ficially produced (e.g., via adding different noise to data samples), have proven
useful in enhancing representation learning. Natural views are often handled by
multiview analysis tools, e.g., (deep) canonical correlation analysis [(D)CCA],
while the artificial ones are frequently used in self-supervised learning (SSL)
paradigms, e.g., BYOL and Barlow Twins. Both types of approaches often
involve learning neural feature extractors such that the embeddings of data exhibit
high cross-view correlations. Although intuitive, the effectiveness of correlation-
based neural embedding is mostly empirically validated. This work aims to under-
stand latent correlation maximization-based deep multiview learning from a latent
component identification viewpoint. An intuitive generative model of multiview
data is adopted, where the views are different nonlinear mixtures of shared and
private components. Since the shared components are view/distortion-invariant,
representing the data using such components is believed to reveal the identity of
the samples effectively and robustly. Under this model, latent correlation max-
imization is shown to guarantee the extraction of the shared components across
views (up to certain ambiguities). In addition, it is further shown that the pri-
vate information in each view can be provably disentangled from the shared using
proper regularization design. A finite sample analysis, which has been rare in non-
linear mixture identifiability study, is also presented. The theoretical results and
newly designed regularization are tested on a series of tasks."
INTRODUCTION,0.0024630541871921183,"1
INTRODUCTION"
INTRODUCTION,0.003694581280788177,"One pillar of unsupervised representation learning is multiview learning. Extracting shared infor-
mation from multiple “views” (e.g., image and audio) of data entities has been considered a major
means to fend against noise and data scarcity. A key computational tool for multiview learning is
canonical correlation analysis (CCA) (Hotelling, 1936). The classic CCA seeks linear transforma-
tion matrices such that transformed views are maximally correlated. A number of works studied
nonlinear extensions of CCA; see kernel CCA in (Lai & Fyfe, 2000) and deep learning-based CCA
(DCCA) in (Andrew et al., 2013; Wang et al., 2015). DCCA and its variants were shown to largely
outperform the classical linear CCA in many tasks."
INTRODUCTION,0.0049261083743842365,"In recent years, a series of self-supervised learning (SSL) paradigms were proposed. These SSL
approaches exhibit a lot of similarities with DCCA approaches, except that the “views” are noisy
data “augmenented” from the original clean data. To be specific, different views are generated by
distorting data—e.g., using rotating, cropping, and/or adding noise to data samples (Dosovitskiy
et al., 2015; Gidaris et al., 2018; Chen et al., 2020; Grill et al., 2020). Then, neural encoders are
employed to map these artificial views to embeddings that are highly correlated across views. This
genre—which will be referred to as artificial multiview SSL (AM-SSL)—includes some empirically
successful frameworks, e.g., BYOL (Grill et al., 2020) and Barlow Twins (Zbontar et al., 2021)."
INTRODUCTION,0.006157635467980296,"∗Contact information: Q. Lyu and X. Fu: {lyuqi,xiao.fu}@oregonstate.edu.
W. Wang:
weiranwang@ttic.edu. S. Lu: songtao@ibm.com."
INTRODUCTION,0.007389162561576354,Published as a conference paper at ICLR 2022
INTRODUCTION,0.008620689655172414,"Notably, many DCCA and AM-SSL approaches involve (explicitly or implicitly) searching for
highly correlated representations from multiple views, using neural feature extractors (encoders).
The empirical success of DCCA and AM-SSL bears an important research question: How to under-
stand the role of cross-view correlation in deep multiview learning? Furthermore, how to use such
understanding to design theory-backed learning criteria to serve various purposes?"
INTRODUCTION,0.009852216748768473,"Intuitively, it makes sense that many DCCA and AM-SSL paradigms involve latent correlation max-
imization in their loss functions, as such loss functions lead to similar/identical representations
from different views—which identifies view-invariant essential information that is often identity-
revealing. However, beyond intuition, theoretical support of latent correlation-based deep multiview
learning had been less studied, until recent works started exploring this direction in both nonlinear
CCA and AM-SSL (see, e.g., (Lyu & Fu, 2020; Von K¨ugelgen et al., 2021; Zimmermann et al.,
2021; Tian et al., 2021; Saunshi et al., 2019; Tosh et al., 2021)), but more insights and theoretical
underpinnings remain to be discovered under more realistic and challenging settings. In this work,
we offer an understanding to the role of latent correlation maximization that is seen in a number of
DCCA and AM-SSL systems from a nonlinear mixture learning viewpoint—and use such under-
standing to assist various learning tasks, e.g., clustering, cross-view translation, and cross-sample
generation. Our detailed contributions are:"
INTRODUCTION,0.011083743842364532,"(i) Understanding Latent Correlation Maximization - Shared Component Identification. We
start with a concept that has been advocated in many multiview learning works. In particular, the
views are nonlinear mixtures of shared and private latent components; see, e.g., (Huang et al.,
2018; Lee et al., 2018; Wang et al., 2016). The shared components are distortion/view invariant
and identity-revealing. The private components and view-specific nonlinear mixing processes de-
termine the different appearances of the views. By assuming independence between the shared
and private components and invertibility of the data generating process, we show that maximizing
the correlation of latent representations extracted from different views leads to identification of the
ground-truth shared components up to invertible transformations."
INTRODUCTION,0.012315270935960592,"(ii) Imposing Additional Constraints - Private Component Identification. Using the understand-
ing to latent correlation maximization-type loss functions in DCCA and AM-SSL, we take a step
further. We show that with carefully imposed constraints, the private components in the views can
also be identified, under reasonable assumptions. Learning private components can facilitate tasks
such as cross-view and cross-sample data generation (Huang et al., 2018; Lee et al., 2018)."
INTRODUCTION,0.013546798029556651,"(iii) Finite-Sample Analysis. Most existing unsupervised nonlinear mixture identification works,
e.g., those from the nonlinear independent component analysis (ICA) literature (Hyvarinen &
Morioka, 2016; 2017; Hyvarinen et al., 2019; Khemakhem et al., 2020; Locatello et al., 2020; Gre-
sele et al., 2020), are based on infinite data. This is perhaps because finite sample analysis for
unsupervised learning is generally much more challenging relative to supervised cases—and there
is no existing “universal” analytical tools. In this work, we provide sample complexity analysis for
the proposed unsupervised multiview learning criterion. We come up with a success metric for char-
acterizing the performance of latent component extraction, and integrate generalization analysis and
numerical differentiation to quantify this metric. To our best knowledge, this is the first finite-sample
analysis of nonlinear mixture model-based multiview unsupervised learning."
INTRODUCTION,0.014778325123152709,"(iv) Practical Implementation.
Based on the theoretical understanding, we propose a latent
correlation-maximization based multiview learning criterion for extracting both the shared com-
ponents and private components. To realize the criterion, a notable innovation is a minimax neural
regularizer that serves for extracting the private components. The regularizer shares the same pur-
pose of some known independence promoters (e.g., Hilbert-Schmidt Independence Criterion (HSIC)
(Gretton et al., 2007)) but is arguably easier to implement using stochastic gradient algorithms."
INTRODUCTION,0.01600985221674877,Notation. The notations used in this work are summarized in the supplementary material.
INTRODUCTION,0.017241379310344827,"2
BACKGROUND: LATENT CORRELATION IN DCCA AND AM-SSL"
INTRODUCTION,0.01847290640394089,"In this section, we briefly review some deep multiview learning paradigms that use latent correlation
maximization and its close relatives."
INTRODUCTION,0.019704433497536946,Published as a conference paper at ICLR 2022
LATENT CORRELATION MAXIMIZATION IN DCCA,0.020935960591133004,"2.1
LATENT CORRELATION MAXIMIZATION IN DCCA"
LATENT CORRELATION MAXIMIZATION IN DCCA,0.022167487684729065,"DCCA methods aim at extracting common information from multiple views of data samples. Such
information is expected to be informative and essential in representing the data."
LATENT CORRELATION MAXIMIZATION IN DCCA,0.023399014778325122,"• DCCA. The objective of DCCA can be summarized as follows (Andrew et al., 2013):"
LATENT CORRELATION MAXIMIZATION IN DCCA,0.024630541871921183,"maximize
f (1),f (2)
Tr

E

f (1) 
x(1)
f (2) 
x(2)⊤
,
s.t. E

f (q) 
x(q)
f (q) 
x(q)⊤
= I,
(1)"
LATENT CORRELATION MAXIMIZATION IN DCCA,0.02586206896551724,"where x(q) ∈RMq ∼Dq is a data sample from view q for q = 1, 2, Dq is the underlying distribution
of the qth view, f (1) : RM1 →RD and f (2) : RM2 →RD are two neural networks. CCA was found
particularly useful in fending against unknown and strong view-specific (private) interference (see
theoretical supports in (Bach & Jordan, 2005; Ibrahim & Sidiropoulos, 2020)). Such properties were
also observed in DCCA research (Wang et al., 2015), while theoretical analysis is mostly elusive."
LATENT CORRELATION MAXIMIZATION IN DCCA,0.027093596059113302,An equivalent representation of (1) is as follows
LATENT CORRELATION MAXIMIZATION IN DCCA,0.02832512315270936,"minimize
f (1),f (2) E
f (1)(x(1)) −f (2)(x(2))

2 2"
LATENT CORRELATION MAXIMIZATION IN DCCA,0.029556650246305417,"
,
s.t. E

f (q) 
x(q)
f (q) 
x(q)⊤
= I,
(2)"
LATENT CORRELATION MAXIMIZATION IN DCCA,0.03078817733990148,"which is expressed from latent component matching perspective. Both the correlation maximization
form in (1) and the component matching form in (2) are widely used in the literature. As we will
see in our proofs, although the former is popular in the literature (Andrew et al., 2013; Wang et al.,
2015; Chen et al., 2020), the latter is handier for theoretical analysis."
LATENT CORRELATION MAXIMIZATION IN DCCA,0.03201970443349754,"• Slack Variable-Based DCCA. In (Benton et al., 2017) and (Lyu & Fu, 2020), a deep multiview
learning criterion is used:"
LATENT CORRELATION MAXIMIZATION IN DCCA,0.0332512315270936,"minimize
f (q)"
X,0.034482758620689655,"2
X"
X,0.03571428571428571,"q=1
E
f (q)(x(q)) −g

2
, s.t. E[|gi|2] = 1, E[gigj] = 0.
(3)"
X,0.03694581280788178,"The slack variable g represents the common latent embedding learned from the two views. Con-
ceptually, this is also latent correlation maximization (or latent component matching).
To see
this, assume that there exists f (q)(x(q)) = g for all x(q).
The criterion amounts to learning
[f (1)(x(1))]k = [f (2)(x(2))]k—which has the maximally attainable correlation."
X,0.038177339901477834,"2.2
LATENT CORRELATION MAXIMIZATION/COMPONENT MATCHING IN AM-SSL"
X,0.03940886699507389,"Similar to DCCA, the goal of AM-SSL is also to find identity-revealing embeddings of data samples
without using labels. The idea is often realized via intentionally distorting the data to create multiple
artificial views. Then, the encoders are require to produce highly correlated (or closely matched)
embeddings from such views. In AM-SSL, the views x(1) and x(2) are different augmentations
(e.g., by adding noise, cropping, and rotation) of the sample x."
X,0.04064039408866995,"• Barlow Twins. The most recent development, namely, the Barlow Twins network (Zbon-
tar et al., 2021) is appealing since it entails a succinct implementation. Specifically, the Barlow
Twins network aims to learn a single encoder f : RM →RD for two distorted views. The cost
function is as follows:"
X,0.04187192118226601,"minimize
f D
X"
X,0.04310344827586207,"i=1
(1 −Cii)2 + λ D
X i=1 D
X"
X,0.04433497536945813,"j̸=i
C2
ij, where Cij =
E

[f(x(1))]i[f(x(2))]j
 p"
X,0.04556650246305419,"E[[f(x(1))]2
i ]
q"
X,0.046798029556650245,"E[[f(x(2))]2
j]
."
X,0.0480295566502463,"When the learned embeddings are constrained to have zero mean, i.e., E

f(x(q))

= 0, Cij is the
cross-correlation between f(x(1)) and f(x(2)). Note that the normalized representation of cross-
correlation in Cij is equivalent to the objective in (1) with the orthogonality constraints."
X,0.04926108374384237,"• BYOL. The BYOL method (Grill et al., 2020) uses a cross-view matching criterion that can be
distilled as follows:"
X,0.050492610837438424,"minimize
f (1),f (2) E
f
(1)(x(1)) −f
(2)(x(2))

2 2 
(4)"
X,0.05172413793103448,Published as a conference paper at ICLR 2022
X,0.05295566502463054,"where f
(q)(·) means that the output of the network is normalized. In BYOL, the networks are
constructed in a special way (e.g., part of f (2)’s weights are moving averages of the correspond part
of f (1)’s weights). Nonetheless, the cross-view matching perspective is still very similar to that in
latent component matching in (2)."
X,0.054187192118226604,"• SimSiam. The loss function of SimSiam (Chen & He, 2021) has a similar structure as that of
BYOL, but with a Siamese network, which, essentially, is also latent component matching."
UNDERSTANDING LATENT CORRELATION MAXIMIZATION,0.05541871921182266,"3
UNDERSTANDING LATENT CORRELATION MAXIMIZATION"
UNDERSTANDING LATENT CORRELATION MAXIMIZATION,0.05665024630541872,"In this section, we offer understandings to latent correlation maximization (and latent component
matching) from an unsupervised nonlinear multiview mixture identification viewpoint. We will
also show that such understanding can help improve multiview learning criteria to serve different
purposes, e.g., cross-view and cross-sample data generation."
MULTIVIEW AS NONLINEAR MIXTURES OF PRIVATE AND SHARED COMPONENTS,0.05788177339901478,"3.1
MULTIVIEW AS NONLINEAR MIXTURES OF PRIVATE AND SHARED COMPONENTS"
MULTIVIEW AS NONLINEAR MIXTURES OF PRIVATE AND SHARED COMPONENTS,0.059113300492610835,We consider the following multiview generative model:
MULTIVIEW AS NONLINEAR MIXTURES OF PRIVATE AND SHARED COMPONENTS,0.0603448275862069,"x(1)
ℓ
= g(1)
 zℓ
c(1)
ℓ"
MULTIVIEW AS NONLINEAR MIXTURES OF PRIVATE AND SHARED COMPONENTS,0.06157635467980296,"
, x(2)
ℓ
= g(2)
 zℓ
c(2)
ℓ"
MULTIVIEW AS NONLINEAR MIXTURES OF PRIVATE AND SHARED COMPONENTS,0.06280788177339902,"
,
(5)"
MULTIVIEW AS NONLINEAR MIXTURES OF PRIVATE AND SHARED COMPONENTS,0.06403940886699508,"where x(q)
ℓ
∈RMq is the ℓth sample of the qth view for q = 1, 2, zℓ∈RD is the shared component
across views, and c(q)
ℓ
∈RDq represents the private information of the qth view—which are the ℓth
samples of continuous random variables denoted by z ∈RD, c(q) ∈RDq, respectively. In addition,
g(q)(·) : RD+Dq →RMq is an invertible and smooth nonlinear transformation, which is unknown.
Additional notes on (5) and the shared-private component-based modeling idea in the literature can
be found in the supplementary materials (Appendix H). We will use the following assumption:"
MULTIVIEW AS NONLINEAR MIXTURES OF PRIVATE AND SHARED COMPONENTS,0.06527093596059114,"Assumption 1 (Group Independence) Under (5), the samples zℓand c(q)
ℓ
are realizations of con-
tinuous latent random variables z, c(q) for q = 1, 2, whose joint distributions satisfy the following:"
MULTIVIEW AS NONLINEAR MIXTURES OF PRIVATE AND SHARED COMPONENTS,0.0665024630541872,"z ∼p(z), c(q) ∼p(c(q)), z ∈Z, c(q) ∈Cq,
p(z, c(1), c(2)) = p(z)p(c(1))p(c(2)),
(6)"
MULTIVIEW AS NONLINEAR MIXTURES OF PRIVATE AND SHARED COMPONENTS,0.06773399014778325,"where Z ⊆RD, Cq ⊆RDq are the continuous supports of p(z) and p(c(q)), respectively."
MULTIVIEW AS NONLINEAR MIXTURES OF PRIVATE AND SHARED COMPONENTS,0.06896551724137931,"Assumption 1 is considered reasonable under both AM-SSL and DCCA settings. For AM-SSL,
the private information can be understood as random data augmentation noise-induced components,
and thus it makes sense to assume that such noise is independent with the shared information (which
corresponds to the identity-revealing components of the data sample). In DCCA problems, the pri-
vate style information can change drastically from view to view (e.g., audio, text, video) without
changing the shared content information (e.g., identity of the entity)—which also shows indepen-
dence between the two parts. In our analysis, we will assume that D and Dq are known to facilitate
exposition. In practice, these parameters are often selected using a validation set."
MULTIVIEW AS NONLINEAR MIXTURES OF PRIVATE AND SHARED COMPONENTS,0.07019704433497537,"Learning Goals. Our interest lies in extracting zℓand c(q)
ℓ
(up to certain ambiguities) from the
views in an unsupervised manner. In particular, we hope to answer under what conditions these
latent components can be identified—and to what extent. As mentioned, zℓis view/distortion-
invariant and thus should be identity-revealing. The ability of extracting it may explain DCCA and
AM-SSL’s effectiveness. In addition, the identification of c(q)
ℓ
and the mixing processes may help
generate data in different views."
A LATENT CORRELATION-BASED LEARNING CRITERION,0.07142857142857142,"3.2
A LATENT CORRELATION-BASED LEARNING CRITERION"
A LATENT CORRELATION-BASED LEARNING CRITERION,0.07266009852216748,"Given observations from both views {x(1)
ℓ, x(2)
ℓ}N
ℓ=1 generated from (5), we aim to understand how
latent correlation maximization (or latent component matching) helps with our learning goals. To"
A LATENT CORRELATION-BASED LEARNING CRITERION,0.07389162561576355,Published as a conference paper at ICLR 2022
A LATENT CORRELATION-BASED LEARNING CRITERION,0.07512315270935961,"this end, we consider the following problem criterion:"
A LATENT CORRELATION-BASED LEARNING CRITERION,0.07635467980295567,"maximize
f (1),f (2) Tr"
N,0.07758620689655173,"1
N N
X"
N,0.07881773399014778,"ℓ=1
f (1)
S

x(1)
ℓ

f (2)
S

x(2)
ℓ
⊤
! (7a)"
N,0.08004926108374384,"subject to f (q) for q = 1, 2 are invertible,
(7b)"
N,0.0812807881773399,"1
N N
X"
N,0.08251231527093596,"ℓ=1
f (q)
S

x(q)
ℓ

f (q)
S

x(q)
ℓ
⊤
= I, 1 N N
X"
N,0.08374384236453201,"ℓ=1
f (q)
S

x(q)
ℓ

= 0, q = 1, 2,
(7c)"
N,0.08497536945812807,"f (q)
S

x(q)
ℓ

⊥⊥f (q)
P

x(q)
ℓ

, q = 1, 2,
(7d)"
N,0.08620689655172414,"where f (q) : RMq →RD+Dq for q = 1, 2 are the feature extractors of view q. We use the notations"
N,0.0874384236453202,"f (q)
S

x(q)
ℓ

=
h
f (q) 
x(q)
ℓ
i"
N,0.08866995073891626,"1:D , f (q)
P

x(q)
ℓ

=
h
f (q) 
x(q)
ℓ
i"
N,0.08990147783251232,"D+1:D+Dq
, q = 1, 2,"
N,0.09113300492610837,"to denote the encoder-extracted shared and private components for each view, respectively. Note
that designating the first D dimensions of the encoder outputs to represent the shared information is
without loss of generality, since the permutation ambiguity is intrinsic."
N,0.09236453201970443,"The correlation maximization objective is reminiscent of the criteria of learning paradigms such as
DCCA and Barlow Twins. In addition, under the constraints in (7), the objective function is also
equivalent to shared component matching that is similar to those used by BYOL and SimSiam, i.e.,"
N,0.09359605911330049,"max
f (q) Tr"
N,0.09482758620689655,"1
N N
X"
N,0.0960591133004926,"ℓ=1
f (1)
S

x(1)
ℓ

f (2)
S

x(2)
ℓ
⊤
!"
N,0.09729064039408868,"⇐⇒min
f (q)
1
N N
X ℓ=1"
N,0.09852216748768473,"f (1)
S

x(1)
ℓ

−f (2)
S

x(2)
ℓ

2 2 ."
N,0.09975369458128079,"To explain the criterion, note that we have a couple of goals that we hope to achieve with f (q)
S
and
f (q)
P . First, the objective function aims to maximize the latent correlation of the learned shared
components, i.e., f (q)
S . This is similar to those in DCCA and AM-SSL, and is based on the belief
that the shared information should be identical across views. Second, in (7d), we ask f (q)
S
and f (q)
P
to be statistically independent for q = 1, 2. This promotes the disentanglement of the shared and
private parts of each encoder, following in Assumption 1. Third, the invertibility constraint in (7b)
is to ensure that the latent and the ambient data can be constructed from each other—which is often
important in unsupervised learning, for avoiding trivial solutions; see, e.g., (Hyvarinen et al., 2019;
Von K¨ugelgen et al., 2021). The orthogonality and zero-mean constraints in (7c) are used to make
the correlation metric meaningful. In particular, if the learned components are not zero-mean, the
learned embeddings may not capture “co-variations” but dominated by some constant terms."
THEORETICAL UNDERSTANDING,0.10098522167487685,"3.3
THEORETICAL UNDERSTANDING"
THEORETICAL UNDERSTANDING,0.1022167487684729,We have the following theorem in terms of learning the shared components:
THEORETICAL UNDERSTANDING,0.10344827586206896,"Theorem 1 (Shared Component Extraction) Under the generative model in (5) and Assumption 1,
consider the population form in (7) (i.e., N = ∞). Assume that the considered constraints hold over
all x(q) ∈Xq for q = 1, 2, where Xq = {x(q)|x(q) = g(q)([z⊤, (c(q))⊤]⊤), ∀z ∈Z, ∀c(q) ∈Cq}.
Denote b
f (q) as any solution of (7). Also assume that the first-order derivative of b
f (q) ◦g(q) exists.
Then, we have bz = b
f (q)
S
 
x(q)
= γ(z) no matter if (7d) is enforced or not, where γ(·) : RD →RD
is an unknown invertible function."
THEORETICAL UNDERSTANDING,0.10467980295566502,"A remark is that bz = γ(z) has all the information of z due to the invertibility of γ(·). Theo-
rem 1 clearly indicates that latent correlation maximization/latent component matching can identify
the view/distortion-invariant information contained in multiple views under unknown nonlinear dis-
tortions. This result may explain the reason why many DCCA and AM-SSL schemes use latent
correlation maximization/latent component matching as part of their objectives. Theorem 1 also in-
dicates that if one only aims to extract z, the constraint in (7d) is not needed. In the next theorem, we
show that our designed constraint in (7d) can help disentangle the shared and private components:"
THEORETICAL UNDERSTANDING,0.10591133004926108,Published as a conference paper at ICLR 2022
THEORETICAL UNDERSTANDING,0.10714285714285714,"Theorem 2 (Private Component Extraction) Under the same conditions as in Theorem 1, also
assume that (7d) is enforced. Then, we further have bc(q) = b
f (q)
P
 
x(q)
= δ(q)  
c(q)
, where
δ(q)(·) : RDq →RDq is an unknown invertible function."
THEORETICAL UNDERSTANDING,0.10837438423645321,"Note that separating z and c(q) may be used for other tasks such as cross-view translation (Huang
et al., 2018; Lee et al., 2018) and content/style disentanglement."
THEORETICAL UNDERSTANDING,0.10960591133004927,"The above theorems are based on the so-called population case (with N = ∞and the Xq observed).
This is similar to the vast majority of provable nonlinear ICA/factor disentanglement literature; see
(Hyvarinen & Morioka, 2016; Hyvarinen et al., 2019; Locatello et al., 2020; Khemakhem et al.,
2020). It is of interest to study the finite sample case. In addition, most of these works assumed that
the learning function f (q) is a universal function approximator. In practice, considering f (q) ∈F,
where F is a certain restricted function class that may have mismatches with g(q)’s function class,
is meaningful. To proceed, we assume D1 = D2 and M = M1 = M2 for notation simplicity and:"
THEORETICAL UNDERSTANDING,0.11083743842364532,Assumption 2 Assume the following conditions hold:
THEORETICAL UNDERSTANDING,0.11206896551724138,"(a) We have g(q) ∈G and learn f (q) from F, where the function classes F and G are third-order
differentiable and bounded."
THEORETICAL UNDERSTANDING,0.11330049261083744,"(b) The Rademacher complexity (Bartlett & Mendelson, 2002) of F′ = {fd : RM →R|fd(x) =
[f(x)]d, f ∈F} is bounded by RN given N samples."
THEORETICAL UNDERSTANDING,0.1145320197044335,"(c) Define G−1 =

u : RM →RD+D1|uS(x) = γ(z), uS(x) = [u(x)]1:D
	
∀x ∈Xq and any
invertible γ(·). There exists f ∈F such that supx∈Xq ∥fS(x) −uS(x)∥2 ≤ν."
THEORETICAL UNDERSTANDING,0.11576354679802955,"(d) Any third-order partial derivative of [h(q)(x)]d = [f (q) ◦g(q)(x)]d resides in [−Cd, Cd] for all
x ∈Xq. In addition, [c(q)]j ∈[−Cp, Cp] with 0 < Cp < ∞for j ∈[Dq]."
THEORETICAL UNDERSTANDING,0.11699507389162561,"Assumption 2 specifies some conditions of the function class F where the learning functions are
chosen from. Specifically, (a) and (d) mean that the learning function is sufficiently smooth (i.e.,
with bounded third-order derivatives); (b) means that the learning function is not overly complex
(i.e., with a bounded Rademacher complexity); and (c) means that the learning function should be
expressive enough to approximate the inverse of the generative function ."
THEORETICAL UNDERSTANDING,0.11822660098522167,"Theorem 3 (Sample Complexity) Under the generative model in (5), Assumption 1 and the suite
of conditions in Assumption 2, assume that (x(1)
ℓ, x(2)
ℓ) for ℓ= 1, . . . , N are i.i.d. samples of
(x(1), x(2)). Denote b
f (q) as any solution of (7) with the invertibility constraint satisfied. Then, we
have the following holds with probability of at least 1 −δ: E  
D
X i=1 Dq
X j=1"
THEORETICAL UNDERSTANDING,0.11945812807881774," 
∂[ b
fS(x(q))]i/∂c(q)
j
2
"
THEORETICAL UNDERSTANDING,0.1206896551724138,"= O

DRN +
p"
THEORETICAL UNDERSTANDING,0.12192118226600986,"log(1/δ)/N + ν22/3
(8)"
THEORETICAL UNDERSTANDING,0.12315270935960591,"for any c(q) ∈Cq such that −Cp + κj ≤c(q)
j
≤Cp −κj for all j ∈[Dq] and all i ∈[D], where
κj = Ω((3/Cd)1/3(4Cf(2DRN + Cf
p"
THEORETICAL UNDERSTANDING,0.12438423645320197,log(1/δ)/2N) + 4ν2)1/6).
THEORETICAL UNDERSTANDING,0.12561576354679804,"If the metric on the left hand side of (8) is zero, then b
fS
 
x(q)
is disentangled from c(q). The
theorem indicates that with N samples, the metric is bounded by O(N −1/3). In addition, RN de-
creases when N increases; e.g., a fully connected neural network with bounded weights satisfies
RN = O(N −1/2) (Shalev-Shwartz & Ben-David, 2014). When RN increases (e.g., by using a more
complex neural network), the function mismatch ν often decreases (since F can be more expressive
with a higher RN). In other words, Theorem 3 indicates a tradeoff between the expressiveness of
the function class F and the sample complexity. If F comprises neural networks, the expressive-
ness is increased (or equivalently, the modeling error is reduced) by increasing the width or depth
of networks. But this in turn increases RN and requires more samples to reduce (8). This makes
sense—one hopes to use a sufficiently expressive learning function, but does not hope to use an
excessively expressive one, which is similar to the case in supervised learning."
THEORETICAL UNDERSTANDING,0.1268472906403941,Published as a conference paper at ICLR 2022
IMPLEMENTATION,0.12807881773399016,"4
IMPLEMENTATION"
IMPLEMENTATION,0.12931034482758622,"Enforcing Group Statistical Independence. A notable challenge is the statistical independence
constraint in (7d), whose enforcement is often an art. Early methods such as (Taleb & Jutten, 1999;
Hyv¨arinen & Oja, 2000) may be costly. The HSIC method in (Gretton et al., 2007) which measures
the correlation of two variables in a kernel space can be used in our framework, but kernels some-
times induce large memory overheads and are sensitive to parameter (e.g., kernel width) selection."
IMPLEMENTATION,0.13054187192118227,"In this work, we provide a simple alternative. Note that if two variables X and Y are statistically
independent, then we have p(X, Y ) = p(X)p(Y ) ⇐⇒E[ϕ(X)τ(Y )] = E[ϕ(X)]E[τ(Y )] for all
measurable functions ϕ(·) : R →R and τ(·) : R →R (Gretton et al., 2005). Hence, to enforce group
independence between variables bz(q) and bc(q), we propose to exhaust the space of all measurable
functions ϕ(q) : RD →R and τ (q) : RDq →R, such that"
IMPLEMENTATION,0.13177339901477833,"sup
ϕ(q),τ (q) R(q) =
sup
ϕ(q),τ (q)
|Cov[ϕ(q)(bz(q)),τ (q)(bc(q))]|/
q"
IMPLEMENTATION,0.1330049261083744,"V[ϕ(q)(bz(q))]
q"
IMPLEMENTATION,0.13423645320197045,"V[τ (q)(bc(q))] 
(9)"
IMPLEMENTATION,0.1354679802955665,is minimized. It is not hard to show the following (see the proof in the supplementary material):
IMPLEMENTATION,0.13669950738916256,"Proposition 1 In (9), if supϕ(q),τ (q) R(q) = 0 over all measurable functions ϕ(q) and τ (q), then,
any
bz(q)"
IMPLEMENTATION,0.13793103448275862,"i and
bc(q)"
IMPLEMENTATION,0.13916256157635468,j for i ∈[D] and j ∈[Dq] are statistically independent.
IMPLEMENTATION,0.14039408866995073,"In practice, we use two neural networks to represent ϕ(q) and τ (q), respectively, which blends well
with the neural encoders for algorithm design."
IMPLEMENTATION,0.1416256157635468,"Reformulation and Optimization. We use deep neural networks to serve as f (q). We introduce a
slack variable uℓand change the objective to minimizing Lℓ= P2
q=1 ∥uℓ−f (q)
S (x(q)
ℓ)∥2
2 like in
(3). The slack variable can also make orthogonality and zero-mean constraints easier to enforce. A
reconstruction loss Vℓ= P2
q=1 ∥x(q)
ℓ
−r(q)(f (q)(x(q)
ℓ))∥2
2 is employed to promote invertibility of
f (q), where r(q) is a reconstruction network. Let θ collect the parameters of f (q) and r(q), and η
the parameters of ϕ(q), τ (q). The overall formulation is:"
IMPLEMENTATION,0.14285714285714285,"min
U,θ max
η
L + βV + λR,
s.t. 1 N N
X"
IMPLEMENTATION,0.1440886699507389,"ℓ=1
uℓu⊤
ℓ= I, 1 N N
X"
IMPLEMENTATION,0.14532019704433496,"ℓ=1
uℓ= 0,
(10)"
IMPLEMENTATION,0.14655172413793102,"where L = 1/N PN
ℓ=1 Lℓ, V = 1/N PN
ℓ=1 Vℓ, U = [u1, · · · , uN] ∈RD×N, R = P2
q=1 R(q),
and β, λ ≥0. We design an algorithm for handling (10) with scalable updates; see the supple-
mentary materials for detailed implementation and complexity analysis.
We should mention that
using reconstruction to encourage invertibility is often seen in multiview learning; see, e.g., (Wang
et al., 2015). Nonetheless, this needs not to be the only invertibility-encouraging method. Other
realizations such as flow-based (e.g., (Kingma & Dhariwal, 2018)) and entropy regularization-based
approaches (e.g., (Von K¨ugelgen et al., 2021)) are also viable—see more in Appendix I."
RELATED WORK - NONLINEAR ICA AND LATENT DISENTANGLEMENT,0.1477832512315271,"5
RELATED WORK - NONLINEAR ICA AND LATENT DISENTANGLEMENT"
RELATED WORK - NONLINEAR ICA AND LATENT DISENTANGLEMENT,0.14901477832512317,"Other than the DCCA and AM-SSL works, our design for private and shared information separation
also draws insights from two topics in unsupervised representation learning, namely, nonlinear ICA
(nICA) (Hyvarinen & Morioka, 2016; 2017; Hyvarinen et al., 2019; Khemakhem et al., 2020) and
latent factor disentanglement (Higgins et al., 2017; Kim & Mnih, 2018; Chen et al., 2018; Zhao
et al., 2019; Lopez et al., 2018), which are recently offered a unifying perspective in (Khemakhem
et al., 2020). The nICA works aim to separate nonlinearly mixed latent components to an individual
component level, which is in general impossible unless additional information associated with each
sample (e.g., time frame labels (Hyvarinen & Morioka, 2016) and class labels (Hyvarinen et al.,
2019; Khemakhem et al., 2020)) is used. Multiple views are less studied in the context of nICA,
with the recent exception in (Locatello et al., 2020) and (Gresele et al., 2020). Nonetheless, their
models are different from ours and the approaches cannot extract the private information from views
with different nonlinear models. The concurrent work in (Von K¨ugelgen et al., 2021) worked on"
RELATED WORK - NONLINEAR ICA AND LATENT DISENTANGLEMENT,0.15024630541871922,Published as a conference paper at ICLR 2022
RELATED WORK - NONLINEAR ICA AND LATENT DISENTANGLEMENT,0.15147783251231528,"Figure 1: t-SNE of the results on multiview MNIST from (Wang et al., 2015). Baselines: DCCA
(Wang et al., 2015), Barlow Twins (Zbontar et al., 2021) and BYOL (Grill et al., 2020)."
RELATED WORK - NONLINEAR ICA AND LATENT DISENTANGLEMENT,0.15270935960591134,"content-style disentanglement under data augmented SSL settings and considered a similar genera-
tive model where both shared and private components are explicitly used. A key difference is that
their model uses an identical nonlinear generative function across the views (i.e., g(1) = g(2)), while
we consider two possibly different g(q)’s. In addition, our learning criterion is able to extract the
private information, while the work in (Von K¨ugelgen et al., 2021) did not consider this aspect.
None of the aforementioned works offered finite sample analysis. Our independence promoter is
reminiscent of (Gretton et al., 2005), with the extension to handle group variables."
EXPERIMENTS,0.1539408866995074,"6
EXPERIMENTS"
EXPERIMENTS,0.15517241379310345,Synthetic Data. We first use synthetic data for theory validation; see the supplementary materials.
EXPERIMENTS,0.1564039408866995,"6.1
VALIDATING THEOREM 1 - SHARED COMPONENT LEARNING"
EXPERIMENTS,0.15763546798029557,"In this subsection, we show that latent correlation maximization (or latent component matching)
leads to shared component extraction under the model in (5)—which can be used to explain the
effectiveness of a number of DCCA and AM-SSL formulations. This is also the objective of our
formulation (7) if the constraint in (7d) is not enforced."
EXPERIMENTS,0.15886699507389163,"Multiview MNIST Data. For proof-of-concept, we adopt a multiview MNIST dataset that was
used in (Wang et al., 2015). There, the “augmented” view of MNIST contains randomly rotated
digits and the other with additive Gaussian white noise (Wang et al., 2015); see Fig. 1. This is
similar to the data augmentation ideas in AM-SSL. Using this multiview data, we apply different
multiview learning paradigms that match the latent representations (or maximize the correlations
of learned representations) across views. The dataset has 70,000 samples that are 28×28 images
of handwritten digits. Note that without (7d), our method can be understood as a slight variant of
(3). To benchmark our method, we use a number of DCCA and AM-SSL approaches mentioned in
Sec. 2, namely, DCCA (Wang et al., 2015), Barlow Twins (Zbontar et al., 2021) and BYOL (Grill
et al., 2020). We set D = 10, D1 = 20 and D2 = 50 through a validation set. The detailed settings
of our neural networks can be found in the supplementary material."
EXPERIMENTS,0.16009852216748768,"Since we do not have ground-truth to evaluate the effectiveness of shared information extraction,
we follow the evaluation method in (Wang et al., 2015) and apply k-means to all the embeddings
bz(1)
ℓ
= f (1)
S (x(1)
ℓ) and compute the clustering accuracy on the test set (see the visualization of bz(2)
ℓ
in the supplementary materials). In Fig. 1, we show the t-SNE (Van der Maaten & Hinton, 2008)
visualizations of bz(1)
ℓ’s on a test set of 10,000 samples together with the clustering accuracy. All
results are averaged over 5 random initializations."
EXPERIMENTS,0.16133004926108374,"By Theorem 1, all the methods under test should output identity-revealing representations of the
data samples. The reason is that the two views share the same identity information of a sample.
Indeed, from Fig. 1, one can see that all latent correlation-maximization-based DCCA and AM-SSL
methods learn informative representations that are sufficiently distinguishable. The “shape” of the
clusters are different, which can be explained by the existence of the invertible function γ(·). These
results corroborate our analysis in Theorem 1."
EXPERIMENTS,0.1625615763546798,"CIFAR10 Data. We also observe similar results using the CIFAR10 data (Krizhevsky et al., 2009).
The results can be found in the supplementary materials, due to page limitations."
EXPERIMENTS,0.16379310344827586,Published as a conference paper at ICLR 2022
EXPERIMENTS,0.16502463054187191,Figure 2: Evaluation on Cars3D; rows in blue boxes are w/ R; rows in green boxes are w/o R.
EXPERIMENTS,0.16625615763546797,"6.2
VALIDATING THEOREM 2 - SHARED AND PRIVATE COMPONENT DISENTANGLEMENT"
EXPERIMENTS,0.16748768472906403,"We use data generation examples to support our claim in Theorem 2—i.e., with our designed regu-
larizer R in (10), one can provably disentangle the shared and private latent components."
EXPERIMENTS,0.1687192118226601,"Cars3D Data for Cross-sample Data Generation. We use the Cars3D dataset (Reed et al., 2015)
that contains different car CAD models. For each car image, there are three defining aspects (namely,
‘type’, ‘elevation’ and ‘azimuth’)."
EXPERIMENTS,0.16995073891625614,"We create two views as follows. We assume that given the car type that is captured by shared vari-
ables z and the azimuths that are captured by c(q), the generation mappings g(1) and g(2) produce
car images with low elevations and high elevations, respectively (so they must be different map-
pings). Under our setting, each view has N = 8, 784 car images. We model z with D = 10. For
c(q), we set D1 = D2 = 2. More details about our settings are in the supplementary material."
EXPERIMENTS,0.17118226600985223,"We use the idea of cross-sample data generation to evaluate the effectiveness of our method. To
be precise, we evaluate the learned b
f (q)’s by combining bz(q)
ℓ
= b
f (q)
S (x(q)
ℓ) and bc(q)
j
= b
f (q)
P (x(q)
j )"
EXPERIMENTS,0.1724137931034483,"and generating bx(q)
ℓ,j = br(q)([(bz(q)
ℓ)⊤, (c(q)
j )⊤]⊤), where br(q) is the learned reconstruction network [cf
Eq. (10)]. Under our model, if the shared components and private components are truly disentangled
in the latent domain, this generated sample bx(q)
ℓ,j should exhibit the same ‘type’ and ‘elevation’ as"
EXPERIMENTS,0.17364532019704434,"those of x(q)
ℓ
and the ‘azimuth’ of x(q)
j ."
EXPERIMENTS,0.1748768472906404,"Fig. 2 shows our experiment results. The proposed method’s outputs are as expected. For example,
on the left of Fig. 2, the z(1)
ℓ
is extracted from the red convertible, and the bc(1)
j ’s are extracted from"
EXPERIMENTS,0.17610837438423646,"the top row. One can see that the generated bx(1)
ℓ,j ’s under the proposed method with R are all red
convertibles with the same elevation, but using the azimuths of the corresponding cars from the top
row. Note that if R is not used, then the learned bc(q)
j
may still contain the ‘type’ or ‘elevation’
information; see the example highlighted with yellow background on the right of Fig. 2. More
results are in the supplementary material."
EXPERIMENTS,0.17733990147783252,"dSprites Data and MNIST Data for Cross-sample/Cross-view Data Generation. We offer two
extra sets of examples to validate our claim in Theorem 2. Please see the supplementary materials."
CONCLUSION,0.17857142857142858,"7
CONCLUSION"
CONCLUSION,0.17980295566502463,"In this work, we provided theoretical understandings to the role of latent correlation maximization
(latent component matching) that is often used in DCCA and AM-SSL methods from an unsuper-
vised nonlinear mixture learning viewpoint. In particular, we modeled multiview data as nonlinear
mixtures of shared and private components, and showed that latent correlation maximization en-
sures to extract the shared components—which are believed to be identity-revealing. In addition, we
showed that, with a carefully designed constraint (which is approximated by a neural regularizer),
one can further disentangle the shared and private information, under reasonable conditions. We also
analyzed the sample complexity for extracting the shared information, which has not been addressed
in nonlinear component analysis works, to our best knowledge. To realize our learning criterion, we
proposed a slack variable-assisted latent correlation maximization approach, with a novel minimax
neural regularizer for promoting group independence. We tested our method over synthetic and real
data. The results corroborated our design goals and theoretical analyses."
CONCLUSION,0.1810344827586207,Published as a conference paper at ICLR 2022
CONCLUSION,0.18226600985221675,"Acknowledgement. This work is supported in part by the National Science Foundation (NSF) under
Project NSF ECCS-1808159, and in part by the Army Research Office (ARO) under Project ARO
W911NF-21-1-0227."
ETHICS STATEMENT,0.1834975369458128,"Ethics Statement. This paper focuses on theoretical analysis and provable guarantees of learning
criteria. It does not involve human subjects or other ethics-related concerns."
REPRODUCIBILITY STATEMENT,0.18472906403940886,"Reproducibility Statement. The authors strive to make the research in this work reproducible.
The supplementary materials contain rich details of the algorithm implementation and experiment
settings. The source code of our Python-implemented algorithm and two demos with real data are
uploaded as supplementary materials. The details of the proofs of our theoretical claims are also
included in the supplementary materials."
REFERENCES,0.18596059113300492,REFERENCES
REFERENCES,0.18719211822660098,"Galen Andrew, Raman Arora, Jeff Bilmes, and Karen Livescu. Deep canonical correlation analysis.
In International Conference on Machine Learning, pp. 1247–1255. PMLR, 2013."
REFERENCES,0.18842364532019704,"Raman Arora and Karen Livescu. Multi-view cca-based acoustic features for phonetic recognition
across speakers and domains. In 2013 IEEE International Conference on Acoustics, Speech and
Signal Processing, pp. 7135–7139. IEEE, 2013."
REFERENCES,0.1896551724137931,"Francis R Bach and Michael I Jordan. A probabilistic interpretation of canonical correlation analysis.
2005."
REFERENCES,0.19088669950738915,"Peter L Bartlett and Shahar Mendelson. Rademacher and Gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463–482, 2002."
REFERENCES,0.1921182266009852,"Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeshwar, Sherjil Ozair, Yoshua Bengio, Aaron
Courville, and Devon Hjelm. MINE: Mutual information neural estimation. In International
Conference on Machine Learning, volume 80, pp. 531–540. PMLR, 10–15 Jul 2018."
REFERENCES,0.1933497536945813,"Adrian Benton, Huda Khayrallah, Biman Gujral, Drew Reisinger, Shenmin Zhang, and Raman
Arora. Deep generalized canonical correlation analysis. In RepL4NLP at ACL, 2017."
REFERENCES,0.19458128078817735,"J Douglas Carroll. Generalization of canonical correlation analysis to three or more sets of vari-
ables. In Proceedings of the 76th annual convention of the American Psychological Association,
volume 3, pp. 227–228, 1968."
REFERENCES,0.1958128078817734,"Ricky TQ Chen, Xuechen Li, Roger B Grosse, and David K Duvenaud. Isolating sources of disen-
tanglement in variational autoencoders. In Advances in Neural Information Processing Systems,
pp. 2610–2620, 2018."
REFERENCES,0.19704433497536947,"Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for
contrastive learning of visual representations. In International Conference on Machine Learning,
pp. 1597–1607. PMLR, 2020."
REFERENCES,0.19827586206896552,"Xinlei Chen and Kaiming He. Exploring simple Siamese representation learning. In Proceedings of
Conference on Computer Vision and Pattern Recognition, pp. 15750–15758, 2021."
REFERENCES,0.19950738916256158,"Thomas M Cover. Elements of information theory. John Wiley & Sons, 1999."
REFERENCES,0.20073891625615764,"G Darmois. Analyse des liaisons de probabilit´e. In Proc. Int. Stat. Conferences 1947, pp. 231, 1951."
REFERENCES,0.2019704433497537,"Richard A Davis, Keh-Shin Lii, and Dimitris N Politis. Remarks on some nonparametric estimates
of a density function. In Selected Works of Murray Rosenblatt, pp. 95–100. Springer, 2011."
REFERENCES,0.20320197044334976,"Paramveer Dhillon, Jordan Rodu, Dean Foster, and Lyle Ungar.
Two Step CCA: A new spec-
tral method for estimating vector models of words. In Proceedings of the 29th International
Conference on Machine Learning (ICML-12), pp. 1551–1558, New York, NY, USA, July 2012.
Omnipress."
REFERENCES,0.2044334975369458,"Alexey Dosovitskiy, Philipp Fischer, Jost Tobias Springenberg, Martin Riedmiller, and Thomas
Brox. Discriminative unsupervised feature learning with exemplar convolutional neural networks.
IEEE Trans. Pattern Anal. Mach. Intell., 38(9):1734–1747, 2015."
REFERENCES,0.20566502463054187,Published as a conference paper at ICLR 2022
REFERENCES,0.20689655172413793,"John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and
stochastic optimization. Journal of Machine Learning Research, 12(Jul):2121–2159, 2011."
REFERENCES,0.20812807881773399,"Ronald A Fisher. Frequency distribution of the values of the correlation coefficient in samples from
an indefinitely large population. Biometrika, 10(4):507–521, 1915."
REFERENCES,0.20935960591133004,"Spyros Gidaris, Praveer Singh, and Nikos Komodakis. Unsupervised representation learning by
predicting image rotations. In International Conference on Learning Representations, 2018."
REFERENCES,0.2105911330049261,"Yunchao Gong, Qifa Ke, Michael Isard, and Svetlana Lazebnik. A multi-view embedding space for
modeling internet images, tags, and their semantics. International Journal of Computer Vision,
106(2):210–233, 2014."
REFERENCES,0.21182266009852216,"Luigi Gresele, Paul K Rubenstein, Arash Mehrjou, Francesco Locatello, and Bernhard Sch¨olkopf.
The incomplete Rosetta stone problem: Identifiability results for multi-view nonlinear ICA. In
Proceedings of UAI 2020, pp. 217–227, 2020."
REFERENCES,0.21305418719211822,"Arthur Gretton, Alexander J Smola, Olivier Bousquet, Ralf Herbrich, Andrei Belitski, Mark Augath,
Yusuke Murayama, Jon Pauls, Bernhard Sch¨olkopf, and Nikos K Logothetis. Kernel constrained
covariance for dependence measurement. In International Conference on Artificial Intelligence
and Statistics, volume 10, pp. 112–119. Citeseer, 2005."
REFERENCES,0.21428571428571427,"Arthur Gretton, Kenji Fukumizu, Choon Teo, Le Song, Bernhard Sch¨olkopf, and Alex Smola. A
kernel statistical test of independence. Advances in Neural Information Processing Systems, 20,
2007."
REFERENCES,0.21551724137931033,"Jean-Bastien Grill, Florian Strub, Florent Altch´e, Corentin Tallec, Pierre Richemond, Elena
Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar,
Bilal Piot, Koray Kavukcuoglu, Remi Munos, and Michal Valko. Bootstrap your own latent - a
new approach to self-supervised learning. In Advances in Neural Information Processing Systems,
volume 33, pp. 21271–21284, 2020."
REFERENCES,0.21674876847290642,"Gregory Gundersen, Bianca Dumitrascu, Jordan T Ash, and Barbara E Engelhardt. End-to-end
training of deep probabilistic CCA on paired biomedical observations. In Uncertainty in Artificial
Intelligence, 2019."
REFERENCES,0.21798029556650247,"Michael Gutmann and Aapo Hyv¨arinen. Noise-contrastive estimation: A new estimation principle
for unnormalized statistical models.
In Proceedings of the 13th International Conference on
Artificial Intelligence and Statistics, pp. 297–304. JMLR Workshop and Conference Proceedings,
2010."
REFERENCES,0.21921182266009853,"Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick,
Shakir Mohamed, and Alexander Lerchner. Beta-VAE: Learning basic visual concepts with a
constrained variational framework. In International Conference on Learning Representations,
2017."
REFERENCES,0.2204433497536946,"Harold Hotelling. Relations between two sets of variates. Biometrika, 28(3/4):321–377, 1936."
REFERENCES,0.22167487684729065,"Xun Huang, Ming-Yu Liu, Serge Belongie, and Jan Kautz. Multimodal unsupervised image-to-
image translation. In Proceedings of the European Conference on Computer Vision, pp. 172–189,
2018."
REFERENCES,0.2229064039408867,"Aapo Hyvarinen and Hiroshi Morioka. Unsupervised feature extraction by time-contrastive learning
and nonlinear ICA. In Advances in Neural Information Processing Systems, volume 29, 2016."
REFERENCES,0.22413793103448276,"Aapo Hyvarinen and Hiroshi Morioka. Nonlinear ICA of temporally dependent stationary sources.
In International Conference on Artificial Intelligence and Statistics, volume 54, pp. 460–469,
20–22 Apr 2017."
REFERENCES,0.22536945812807882,"Aapo Hyv¨arinen and Erkki Oja. Independent component analysis: Algorithms and applications.
Neural Networks, 13(4-5):411–430, 2000."
REFERENCES,0.22660098522167488,Published as a conference paper at ICLR 2022
REFERENCES,0.22783251231527094,"Aapo Hyvarinen, Hiroaki Sasaki, and Richard Turner. Nonlinear ICA using auxiliary variables
and generalized contrastive learning. In International Conference on Artificial Intelligence and
Statistics, pp. 859–868, 2019."
REFERENCES,0.229064039408867,"Mohamed Salah Ibrahim and Nicholas D Sidiropoulos. Reliable detection of unknown cell-edge
users via canonical correlation analysis. IEEE Trans. Wireless Commun., 19(6):4170–4182, 2020."
REFERENCES,0.23029556650246305,"Jon R Kettenring. Canonical analysis of several sets of variables. Biometrika, 58(3):433–451, 1971."
REFERENCES,0.2315270935960591,"Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen. Variational autoen-
coders and nonlinear ICA: A unifying framework. In International Conference on Artificial In-
telligence and Statistics, pp. 2207–2217. PMLR, 2020."
REFERENCES,0.23275862068965517,"Hyunjik Kim and Andriy Mnih.
Disentangling by factorising.
In International Conference on
Machine Learning, volume 80, pp. 2649–2658. PMLR, 10–15 Jul 2018."
REFERENCES,0.23399014778325122,"Diederick P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International
Conference on Learning Representations, 2015."
REFERENCES,0.23522167487684728,"Durk P Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions.
Advances in Neural Information Processing Systems, 31, 2018."
REFERENCES,0.23645320197044334,"Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
2009."
REFERENCES,0.2376847290640394,"Pei Ling Lai and Colin Fyfe. Kernel and nonlinear canonical correlation analysis. International
Journal of Neural Systems, 10(05):365–377, 2000."
REFERENCES,0.23891625615763548,"Christian Ledig, Lucas Theis, Ferenc Husz´ar, Jose Caballero, Andrew Cunningham, Alejandro
Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et al. Photo-realistic sin-
gle image super-resolution using a generative adversarial network. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, pp. 4681–4690, 2017."
REFERENCES,0.24014778325123154,"Hsin-Ying Lee, Hung-Yu Tseng, Jia-Bin Huang, Maneesh Singh, and Ming-Hsuan Yang. Diverse
image-to-image translation via disentangled representations.
In Proceedings of the European
Conference on Computer Vision, pp. 35–51, 2018."
REFERENCES,0.2413793103448276,"Francesco Locatello, Ben Poole, Gunnar R¨atsch, Bernhard Sch¨olkopf, Olivier Bachem, and Michael
Tschannen. Weakly-supervised disentanglement without compromises. In International Confer-
ence on Machine Learning, pp. 6348–6359. PMLR, 2020."
REFERENCES,0.24261083743842365,"Romain Lopez, Jeffrey Regier, Michael I Jordan, and Nir Yosef. Information constraints on auto-
encoding variational Bayes. Advances in Neural Information Processing Systems, 31:6114–6125,
2018."
REFERENCES,0.2438423645320197,"Qi Lyu and Xiao Fu.
Nonlinear multiview analysis: Identifiability and neural network-assisted
implementation. IEEE Trans. Signal Process., 68:2697–2712, 2020."
REFERENCES,0.24507389162561577,"Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of Machine Learning.
MIT press, 2018."
REFERENCES,0.24630541871921183,"Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predic-
tive coding. arXiv preprint arXiv:1807.03748, 2018."
REFERENCES,0.24753694581280788,"Pushpendre Rastogi, Benjamin Van Durme, and Raman Arora. Multiview LSA: Representation
learning via generalized CCA. In Proceedings of the 2015 conference of the North American
chapter of the Association for Computational Linguistics: Human Language Technologies, pp.
556–566, 2015."
REFERENCES,0.24876847290640394,"Scott E Reed, Yi Zhang, Yuting Zhang, and Honglak Lee. Deep visual analogy-making. Advances
in Neural Information Processing Systems, 28:1252–1260, 2015."
REFERENCES,0.25,Published as a conference paper at ICLR 2022
REFERENCES,0.2512315270935961,"Nikunj Saunshi, Orestis Plevrakis, Sanjeev Arora, Mikhail Khodak, and Hrishikesh Khandeparkar.
A theoretical analysis of contrastive unsupervised representation learning.
In Proceedings of
the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine
Learning Research, pp. 5628–5637. PMLR, 09–15 Jun 2019."
REFERENCES,0.2524630541871921,"Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From theory to algo-
rithms. Cambridge university press, 2014."
REFERENCES,0.2536945812807882,"Richard Socher and Li Fei-Fei. Connecting modalities: Semi-supervised segmentation and anno-
tation of images using unaligned text corpora. In 2010 IEEE Computer Society Conference on
Computer Vision and Pattern Recognition, pp. 966–973. IEEE, 2010."
REFERENCES,0.25492610837438423,"Anisse Taleb and Christian Jutten. Source separation in post-nonlinear mixtures. IEEE Trans. Signal
Process., 47(10):2807–2820, 1999."
REFERENCES,0.2561576354679803,"Yuandong Tian, Xinlei Chen, and Surya Ganguli. Understanding self-supervised learning dynam-
ics without contrastive pairs. In Proceedings of the 38th International Conference on Machine
Learning, volume 139 of Proceedings of Machine Learning Research, pp. 10268–10278. PMLR,
18–24 Jul 2021."
REFERENCES,0.25738916256157635,"Christopher Tosh, Akshay Krishnamurthy, and Daniel Hsu. Contrastive learning, multi-view redun-
dancy, and linear models. In Algorithmic Learning Theory, pp. 1179–1206. PMLR, 2021."
REFERENCES,0.25862068965517243,"Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. Journal of Machine
Learning Research, 9(11), 2008."
REFERENCES,0.25985221674876846,"Julius Von K¨ugelgen, Yash Sharma, Luigi Gresele, Wieland Brendel, Bernhard Sch¨olkopf, Michel
Besserve, and Francesco Locatello. Self-supervised learning with data augmentations provably
isolates content from style. Advances in Neural Information Processing Systems, 34, 2021."
REFERENCES,0.26108374384236455,"Tongzhou Wang and Phillip Isola. Understanding contrastive representation learning through align-
ment and uniformity on the hypersphere. In International Conference on Machine Learning, pp.
9929–9939. PMLR, 2020."
REFERENCES,0.2623152709359606,"Weiran Wang, Raman Arora, Karen Livescu, and Jeff Bilmes. On deep multi-view representation
learning. In International Conference on Machine Learning, pp. 1083–1092, 2015."
REFERENCES,0.26354679802955666,"Weiran Wang, Xinchen Yan, Honglak Lee, and Karen Livescu. Deep variational canonical correla-
tion analysis. arXiv preprint arXiv:1610.03454, 2016."
REFERENCES,0.2647783251231527,"Ka Yee Yeung and Walter L Ruzzo. Details of the Adjusted Rand Index and clustering algorithms,
supplement to the paper an empirical study on Principal Component Analysis for clustering gene
expression data. Bioinformatics, 17(9):763–774, 2001."
REFERENCES,0.2660098522167488,"Jure Zbontar, Li Jing, Ishan Misra, Yann Lecun, and Stephane Deny. Barlow Twins: Self-supervised
learning via redundancy reduction. In Proceedings of the 38th International Conference on Ma-
chine Learning, volume 139 of Proceedings of Machine Learning Research, pp. 12310–12320.
PMLR, 18–24 Jul 2021."
REFERENCES,0.2672413793103448,"Shengjia Zhao, Jiaming Song, and Stefano Ermon. InfoVAE: Balancing learning and inference in
variational autoencoders. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01):
5885–5892, Jul. 2019."
REFERENCES,0.2684729064039409,"Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation
using cycle-consistent adversarial networks. In Proceedings of the IEEE International Conference
on Computer Vision, pp. 2223–2232, 2017."
REFERENCES,0.2697044334975369,"Roland S. Zimmermann, Yash Sharma, Steffen Schneider, Matthias Bethge, and Wieland Brendel.
Contrastive learning inverts the data generating process. In Proceedings of the 38th International
Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research,
pp. 12979–12990. PMLR, 18–24 Jul 2021."
REFERENCES,0.270935960591133,Published as a conference paper at ICLR 2022
REFERENCES,0.27216748768472904,Supplementary Materials
REFERENCES,0.2733990147783251,"A
NOTATION"
REFERENCES,0.2746305418719212,The notations used in this work are summarized in Table A.1.
REFERENCES,0.27586206896551724,"Table A.1: Definition of notations.
Notation
Definition
x, x, X
scalar, vector, and matrix
[x]i, xi
both represent the ith element of vector x
[X]ij
the ith row, jth column of matrix X
p(x)
probability density function of random variable x
x ⊥⊥y
x and y are statistically independent, i.e., p(x, y) = p(x)p(y)
x ⊥⊥y
xi ⊥⊥yj for all i, j
x⊤, X⊤
transpose of x, X
Jf
Jocobian matrix of a vector-valued function f
I
identity matrix with a proper size
f ◦g
function composition operation
detX
determinant of a square matrix X
E[·]
expectation
V[·]
variance
Cov[·, ·]
covariance
[N]
the integer set {1, 2, . . . , N}"
REFERENCES,0.2770935960591133,"B
PROOF OF THEOREM 1"
REFERENCES,0.27832512315270935,"Theorem 1. (Shared Component Extraction) Under the generative model in (5) and As-
sumption 1, consider the population form in (7) (i.e., N = ∞).
Assume that the con-
sidered constraints hold over all x(q) ∈Xq for q = 1, 2, where Xq = {x(q)|x(q) =
g(q)([z⊤, (c(q))⊤]⊤), ∀z ∈Z, ∀c(q) ∈Cq}. Denote b
f (q) as any solution of (7). Also assume
that the first-order derivative of b
f (q) ◦g(q) exists. Then, we have bz = b
f (q)
S
 
x(q)
= γ(z) no
matter if (7d) is enforced or not, where γ(·) : RD →RD is a certain invertible functions."
REFERENCES,0.27955665024630544,"We consider the formulation in (7) without (7d). When N = ∞and x(q) ∼Xq for q = 1, 2 are
all available, the sample average version of the formulation in (7) becomes the following expected
value version:"
REFERENCES,0.28078817733990147,"maximize
f (1),f (2) Tr

E

f (1)
S

x(1)
ℓ
 
f (2)
S

x(2)
ℓ
⊤
(B.1a)"
REFERENCES,0.28201970443349755,"subject to f (q) for q = 1, 2 are invertible,
(B.1b)"
REFERENCES,0.2832512315270936,"E

f (q)
S

x(q)
ℓ

f (q)
S

x(q)
ℓ
⊤
= I, E
h
fS

x(q)
ℓ
i
= 0, q = 1, 2
(B.1c)"
REFERENCES,0.28448275862068967,"First, note that under the generative model in (5), the maximum of the objective function in (7) is
D, which is obtained when every corresponding components of the learned solutions, i.e., b
f (1)
S
:
RM1 →RD and b
f (1)
S
: RM2 →RD, are perfectly correlated, i.e.,"
REFERENCES,0.2857142857142857,"b
f (1)
S

x(1)
= b
f (2)
S

x(2)
.
(B.2)"
REFERENCES,0.2869458128078818,Published as a conference paper at ICLR 2022
REFERENCES,0.2881773399014778,"Indeed, one may rewrite (B.1a) as"
REFERENCES,0.2894088669950739,"arg
min
f (1),f (2) −2Tr

E

f (1)
S

x(1)
ℓ
 
f (2)
S

x(2)
ℓ
⊤"
REFERENCES,0.29064039408866993,"= arg
min
f (1),f (2) I −2Tr

E

f (1)
S

x(1)
ℓ
 
f (2)
S

x(2)
ℓ
⊤
+ I"
REFERENCES,0.291871921182266,"= arg
min
f (1),f (2) E
f (1)
S

x(1)
ℓ

−f (2)
S

x(2)
ℓ

2 2"
REFERENCES,0.29310344827586204,"
(B.3)"
REFERENCES,0.29433497536945813,"where the second equality holds because the constraint in (B.1c). Note that the criterion in (B.3)
admits the optimal solution in (B.2) under our generative model."
REFERENCES,0.2955665024630542,Note that one solution to attain zero cost of (B.3) is
REFERENCES,0.29679802955665024,"b
f (q)
S

x(q)
= z, q = 1, 2."
REFERENCES,0.29802955665024633,"However, the question lies in “uniqueness”, i.e., can enforcing (B.2) always yield f (q)
S
 
x(q)
= z
(up to certain ambiguities)? This is central to learning criterion design, as the expressiveness of
function approximators like neural networks may attain zero cost of (B.3) with undesired solutions."
REFERENCES,0.29926108374384236,"Assume that a solution that satisfies (B.2) is found. Denote b
f (q) for q = 1, 2 as the solution.
Combine the solution with the generative model in (5). Then, following equality can be obtained:"
REFERENCES,0.30049261083743845,"h(1)
S"
REFERENCES,0.3017241379310345," z
c(1)"
REFERENCES,0.30295566502463056,"
= h(2)
S"
REFERENCES,0.3041871921182266," z
c(2)"
REFERENCES,0.3054187192118227,"
,
(B.4)"
REFERENCES,0.3066502463054187,where we have
REFERENCES,0.3078817733990148,"h(q)
S (ω(q)) =
h
b
f (q) ◦g(q) 
ω(q)i"
REFERENCES,0.3091133004926108,"1:D = b
f (q)
S
◦g(q) 
ω(q)
,"
REFERENCES,0.3103448275862069,in which
REFERENCES,0.31157635467980294,"ω(q) = [z⊤, (c(q))⊤]⊤."
REFERENCES,0.312807881773399,"We hope to show that h(1)
S
and h(2)
S
are functions of only z—i.e., the functions b
f (q)
S
for q = 1, 2
only extract the shared information."
REFERENCES,0.31403940886699505,"To show that h(1)
S
is a function of only z but not a function of c(1), we consider the first-order
partial derivatives of h(1)
S
w.r.t. z and c(1), respectively. Namely, we hope to show that the matrix
consisting of all the partial derivatives of h(1)
S
w.r.t. z is full rank while any partial derivatives of
h(1)
S
w.r.t. c(1) is zero."
REFERENCES,0.31527093596059114,"Therefore, we investigate the Jacobian of h(1) which fully characterizes all the first-order partial
derivatives of the function h(1)
S
and h(1)
P
w.r.t. z and c(1). Let us denote the outputs of h(1) =
b
f (1) ◦g(1)(ω(1)) as follows:
 bz
bc(1)"
REFERENCES,0.31650246305418717,"
= h(1)
 z
c(1)"
REFERENCES,0.31773399014778325,"
.
(B.5)"
REFERENCES,0.31896551724137934,The Jacobian of h(1) can be expressed using the following block form
REFERENCES,0.32019704433497537,J(1) =
REFERENCES,0.32142857142857145,"""
J(1)
11
J(1)
12
J(1)
21
J(1)
22 # ,"
REFERENCES,0.3226600985221675,Published as a conference paper at ICLR 2022
REFERENCES,0.32389162561576357,"where J(1)
11 ∈RD×D, J(1)
12 ∈RD×D1, J(1)
21 ∈RD1×D and J(1)
22 ∈RD1×D1 are Jacobian matrices
defined as follows"
REFERENCES,0.3251231527093596,"J(1)
11 =  "
REFERENCES,0.3263546798029557,"∂
h
h(1)
S (ω(1))
i"
REFERENCES,0.3275862068965517,"1
∂z1
· · ·
∂
h
h(1)
S (ω(1))
i"
REFERENCES,0.3288177339901478,"1
∂zD
...
...
..."
REFERENCES,0.33004926108374383,"∂
h
h(1)
S (ω(1))
i"
REFERENCES,0.3312807881773399,"D
∂z1
· · ·
∂
h
h(1)
S (ω(1))
i D
∂zD "
REFERENCES,0.33251231527093594,"
, J(1)
12 = "
REFERENCES,0.33374384236453203,
REFERENCES,0.33497536945812806,"∂
h
h(1)
S (ω(1))
i"
REFERENCES,0.33620689655172414,"1
∂c(1)
1
· · ·
∂
h
h(1)
S (ω(1))
i"
REFERENCES,0.3374384236453202,"1
∂c(1)
D1
...
...
..."
REFERENCES,0.33866995073891626,"∂
h
h(1)
S (ω(1))
i"
REFERENCES,0.3399014778325123,"D
∂c(1)
1
· · ·
∂
h
h(1)
S (ω(1))
i"
REFERENCES,0.3411330049261084,"D
∂c(1)
D1 "
REFERENCES,0.34236453201970446,"
,"
REFERENCES,0.3435960591133005,"J(1)
21 =  "
REFERENCES,0.3448275862068966,"∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.3460591133004926,"1
∂z1
· · ·
∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.3472906403940887,"1
∂zD
...
...
..."
REFERENCES,0.3485221674876847,"∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.3497536945812808,"D1
∂z1
· · ·
∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.35098522167487683,"D1
∂zD "
REFERENCES,0.3522167487684729,"
, J(1)
22 = "
REFERENCES,0.35344827586206895,
REFERENCES,0.35467980295566504,"∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.35591133004926107,"1
∂c(1)
1
· · ·
∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.35714285714285715,"1
∂c(1)
D1
...
...
..."
REFERENCES,0.3583743842364532,"∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.35960591133004927,"D1
∂c(1)
1
· · ·
∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.3608374384236453,"D1
∂c(1)
D1 "
REFERENCES,0.3620689655172414,"
."
REFERENCES,0.3633004926108374,"What we hope to show is that J(1)
12 is an all-zero matrix while the determinant of J(1)
11 is non-zero."
REFERENCES,0.3645320197044335,"We first show that J(1)
12 = 0. Note that (B.4) holds over the entire domain. Hence, we consider any
fixed z and c(2). Then for all c(1), the following equation holds:"
REFERENCES,0.3657635467980296,"h(1)
S"
REFERENCES,0.3669950738916256," z
c(1)"
REFERENCES,0.3682266009852217,"
= h(2)
S  z c(2)"
REFERENCES,0.3694581280788177,"
(B.6)"
REFERENCES,0.3706896551724138,for all c(1) ∈C1 with any fixed z and c(2).
REFERENCES,0.37192118226600984,"Let us define matrices H(1)
S
and H(2)
S , where"
REFERENCES,0.3731527093596059,"h
H(q)
S
i"
REFERENCES,0.37438423645320196,"i,j =
∂
h
h(q)
S
 
ω(q)i"
REFERENCES,0.37561576354679804,"i
∂c(1)
j
, i = 1, · · · , D, j = 1, · · · , D1."
REFERENCES,0.3768472906403941,"By taking partial derivatives of Eq. (B.6) w.r.t. c(1)
j
for j = 1, . . . , D1, we have the following
Jacobian:"
REFERENCES,0.37807881773399016,"H(1)
S

¯z,c(1) = H(2)
S

¯z,¯c(2)"
REFERENCES,0.3793103448275862,"(a)
=

Jh(2)
S"
REFERENCES,0.3805418719211823,"¯z,¯c(2)  "
REFERENCES,0.3817733990147783,
REFERENCES,0.3830049261083744,"∂z1
∂c(1)
1
· · ·
∂z1
∂c(1)
D1
...
...
...
∂zD
∂c(1)
1
· · ·
∂zD
∂c(1)
D1
∂c(2)
1
∂c(1)
1
· · ·
∂c(2)
1
∂c(1)
D1
...
...
..."
REFERENCES,0.3842364532019704,"∂c(2)
D2
∂c(1)
1
· · ·
∂c(2)
D2
∂c(1)
D1 "
REFERENCES,0.3854679802955665,
REFERENCES,0.3866995073891626,"(b)
=

Jh(2)
S"
REFERENCES,0.3879310344827586,"¯z,¯c(2)"
REFERENCES,0.3891625615763547," 
0D×D1
0D2×D1"
REFERENCES,0.39039408866995073,"
= 0D×D1, (B.7)"
REFERENCES,0.3916256157635468,"where Jh(2)
S
∈RD×(D+D2) is the Jacobian of h(2)
S , (a) is by the chain rules and (b) is because"
REFERENCES,0.39285714285714285,"we take derivatives of constants. The equation above holds for any z and c(2). Hence, the same
derivation holds for all z and c(2), which leads to the conclusion that the learned h(q)
S (ω(q)) is not
a function of c(1). Note that another possibility that could lead to (B.7) is that h(q)
S (ω(q)) always
outputs a constant. However, this is not possible because each h(q) = b
f (q) ◦g(q) is an invertible
function, which implies that any dimension of h(q)(ω(q)) cannot be a constant if ω(q) is not a
constant. To be more precise, note that x(q) is generated from ω(q) that has D + Dq dimensions. If
there are D dimensions (i.e., h(q)
S (ω(q)) ∈RD) that are constants (and thus no information) in the
learned generative domain, then x(q) cannot be reconstructed from that domain, which contradicts
invertibility."
REFERENCES,0.39408866995073893,Published as a conference paper at ICLR 2022
REFERENCES,0.39532019704433496,"Then, the Jacobian of h(1) can be re-expressed by (B.7)"
REFERENCES,0.39655172413793105,J(1) =
REFERENCES,0.3977832512315271,"""
J(1)
11
H(1)
S
J(1)
21
J(1)
22 # ="
REFERENCES,0.39901477832512317,"""
J(1)
11
0D×D1
J(1)
21
J(1)
22 # ."
REFERENCES,0.4002463054187192,"Next, we show that the determinant of J(1)
11 is non-zero. By the structure of the Jacobian J(1), one
can see that bz is a function of only z but not determined by c(1), where we denote as bz = γ(z).
Besides, since h(1) is invertible, we have
detJ(1) =
detJ(1)
11

detJ(1)
22
 ̸= 0"
REFERENCES,0.4014778325123153,"by the property of determinant for block matrix. It further indicates that
detJ(1)
11
 ̸= 0 (so does
detJ(1)
22
), which implies that γ(·) is an invertible function. This proves Theorem 1.
□"
REFERENCES,0.4027093596059113,"C
PROOF OF THEOREM 2"
REFERENCES,0.4039408866995074,"Theorem 2. (Private Component Extraction) Under the same conditions as in Theorem 1,
also assume that (7d) is enforced, we further have bc(q) = b
f (q)
P
 
x(q)
= δ(q)  
c(q)
, where
δ(q)(·) : RDq →RDq is a certain invertible function."
REFERENCES,0.4051724137931034,"Following the proof of Theorem 1, we further consider the expected value version with (7d), i.e.,"
REFERENCES,0.4064039408866995,"maximize
f (1),f (2) Tr

E

f (1)
S

x(1)
f (2)
S

x(2)⊤
(C.1a)"
REFERENCES,0.40763546798029554,"subject to f (q) for q = 1, 2 are invertible,
(C.1b)"
REFERENCES,0.4088669950738916,"E

f (q)
S

x(q)
f (q)
S

x(q)⊤
= I, E
h
f (q)
S

x(q)i
= 0, q = 1, 2,
(C.1c)"
REFERENCES,0.4100985221674877,"f (q)
S

x(q)
⊥⊥f (q)
P

x(q)
, q = 1, 2,
(C.1d)"
REFERENCES,0.41133004926108374,"Again, under our generative model, any optimal solution ( b
f (1), b
f (2)) satisfies"
REFERENCES,0.4125615763546798,"b
f (1)
S

x(1)
= b
f (2)
S

x(2)
."
REFERENCES,0.41379310344827586,We hope to further show that
REFERENCES,0.41502463054187194,"bc(1) = b
fP

x(1)
= h(1)
P"
REFERENCES,0.41625615763546797," z
c(1) "
REFERENCES,0.41748768472906406,"is an invertible function-transformed version of c(1), where"
REFERENCES,0.4187192118226601,"h(q)
P (ω(q)) =
h
b
f (q) ◦g(q) 
ω(q)i"
REFERENCES,0.41995073891625617,"D+1:D+Dq = b
f (q)
P
◦g(q) 
ω(q)
."
REFERENCES,0.4211822660098522,Recall that we have the following Jacobian matrix for function h(1)
REFERENCES,0.4224137931034483,J(1) =
REFERENCES,0.4236453201970443,"""
J(1)
11
0
J(1)
21
J(1)
22 # ,"
REFERENCES,0.4248768472906404,"where the second row corresponding to function h(1)
P ."
REFERENCES,0.42610837438423643,"Since we have shown that both
detJ(1)
11
 ̸= 0 and
detJ(1)
22
 ̸= 0 in Section B, we only need to show"
REFERENCES,0.4273399014778325,"that J(1)
21 is an all-zero matrix. To show this, we will use the condition (C.1d). First, it is not hard
to see that"
REFERENCES,0.42857142857142855,"J(1)
21 =  "
REFERENCES,0.42980295566502463,"∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.43103448275862066,"1
∂bz1
· · ·
∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.43226600985221675,"1
∂bzD
...
...
..."
REFERENCES,0.43349753694581283,"∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.43472906403940886,"D1
∂bz1
· · ·
∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.43596059113300495,"D1
∂bzD "
REFERENCES,0.437192118226601,"
J(1)
11 ,"
REFERENCES,0.43842364532019706,Published as a conference paper at ICLR 2022
REFERENCES,0.4396551724137931,"by chain rules where the first matrix on the right hand side is the Jacobian of bc(1) w.r.t. bz. By (C.1d),
we have bc(1) ⊥⊥bz, which means that we can observe fixed ˜c(1) = (bc(1)
1 , · · · , ci, · · · , bc(1)
D1) for any
fixed ci with any possible bz. Therefore, at any specific point of ˜c(1), the following always holds"
REFERENCES,0.4408866995073892,"∂
˜c(1)"
REFERENCES,0.4421182266009852,"i
∂bzj
= ∂ci"
REFERENCES,0.4433497536945813,"∂bzj
= 0,"
REFERENCES,0.4445812807881773,"since the numerator is a constant. Note that the above holds for any ˜c(1) with different ci for
i ∈[D1], which further means that we actually have
 "
REFERENCES,0.4458128078817734,"∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.44704433497536944,"1
∂bz1
· · ·
∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.4482758620689655,"1
∂bzD
...
...
..."
REFERENCES,0.44950738916256155,"∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.45073891625615764,"D1
∂bz1
· · ·
∂
h
h(1)
P (ω(1))
i"
REFERENCES,0.45197044334975367,"D1
∂bzD "
REFERENCES,0.45320197044334976,"
= 0"
REFERENCES,0.4544334975369458,"for all h(1)
P
 
ω(1)
and bz."
REFERENCES,0.45566502463054187,"Therefore, J(1)
21
= 0D1×DJ(1)
11
= 0D1×D. Consequently, we have the following block diagonal
form for J(1) by combing with Theorem 1, i.e.,"
REFERENCES,0.45689655172413796,J(1) =
REFERENCES,0.458128078817734,"""
J(1)
11
0D×D1
0D1×D
J(1)
22 # ."
REFERENCES,0.45935960591133007,"By invertibility of b
f (q) and g(q), we have
detJ(1) =
detJ(1)
11

detJ(1)
22
 ̸= 0,"
REFERENCES,0.4605911330049261,"which implies that bz = γ(z) and bc(1) = δ(1)  
c(1)
with invertible functions γ(·) and δ(1)(·),
respectively. The same proof technique applies to δ(2)(·).
□"
REFERENCES,0.4618226600985222,"D
PROOF OF THEOREM 3"
REFERENCES,0.4630541871921182,"Theorem 3.
Under the generative model in (5) and Assumptions 1 and 2, assume that
(x(1)
ℓ, x(2)
ℓ) for ℓ= 1, . . . , N are i.i.d. samples of (x(1), x(2)). Denote b
f (q) ∈F as any
solution of (7) with the invertibility constraint satisfied. Then, we have the following holds
with probability of at least 1 −δ: E  
D
X i=1 Dq
X j=1"
REFERENCES,0.4642857142857143," 
∂[ b
fS(x(q))]i/∂c(q)
j
2
"
REFERENCES,0.46551724137931033,"= O

DRN +
p"
REFERENCES,0.4667487684729064,"log(1/δ)/N + ν22/3
(D.1)"
REFERENCES,0.46798029556650245,"for any c(q) ∈Cq such that −Cp + κj ≤c(q)
j
≤Cp −κj for all j ∈[Dq] and all i ∈[D], where
κj = Ω((3/Cd)1/3(4Cf(2DRN + Cf
p"
REFERENCES,0.46921182266009853,log(1/δ)/2N) + 4ν2)1/6).
REFERENCES,0.47044334975369456,"D.1
A LEMMA ON RADEMACHER COMPLEXITY"
REFERENCES,0.47167487684729065,"To derive the Rademacher complexity of the loss function, we have the following lemma"
REFERENCES,0.4729064039408867,Lemma 1 Consider the following function class H = (
REFERENCES,0.47413793103448276,"l

x(1), x(2) l

x(1), x(2)
= D
X d=1"
REFERENCES,0.4753694581280788,"
f (1)
d

x(1)
−f (2)
d

x(2)2
)"
REFERENCES,0.4766009852216749,"where f (1)
d , f (2)
d
∈F′ are as defined in Assumption 2. Assume that
f (q)
d
 
x(q) ≤Cf for all"
REFERENCES,0.47783251231527096,"f (q)
d
∈F′, where Cf > 0. Then, the Rademacher complexity of class H is bounded by"
REFERENCES,0.479064039408867,RN(H) ≤4DCfRN.
REFERENCES,0.4802955665024631,Published as a conference paper at ICLR 2022
REFERENCES,0.4815270935960591,"Proof: First, we have the function
f (1)
d
 
x(1)
−f (2)
d
 
x(2) bounded within [0, 2Cf]. According
to the Lipschitz composition property of Rademacher complexity (Bartlett & Mendelson, 2002), we
have
RN(ϕ ◦F) ≤LϕRN(F)
where Lϕ is the Lipschitz constant of ϕ. Here ϕ(x) = x2 and Lϕ = 4Cf."
REFERENCES,0.4827586206896552,"Combining with the linearity property of the Rademacher complexity (Bartlett & Mendelson, 2002),
we have
RN(H) ≤4DCfRN
(D.2)"
REFERENCES,0.4839901477832512,"which completes the proof of the lemma. Note that (D.2) is derived by treating f (q)
d
for d ∈[D]
as individual functions. However, f (q)
d
for d ∈[D] are the first D outputs of the same function
f (q)—which means that many parameters of these D functions are constrained to be identical.
Nonetheless, this fact does not affect the inequality in (D.2) since adding confining constraints to
the function class H only reduces the Rademacher complexity (Bartlett & Mendelson, 2002).
□"
REFERENCES,0.4852216748768473,"D.2
PROOF OF THEOREM 3"
REFERENCES,0.48645320197044334,"First, we bound the true risk on the view matching loss. Consider the regression problem given

x(1)
ℓ, x(2)
ℓ

as samples, we have"
REFERENCES,0.4876847290640394,"minimize
f (1),f (2)
1
N N
X ℓ=1"
REFERENCES,0.48891625615763545,"f (1)
S

x(1)
ℓ

−f (2)
S

x(2)
ℓ

2 2 ."
REFERENCES,0.49014778325123154,"By Lemma 1 and (Mohri et al., 2018, Theorem 3.3), we have the following hold with probability at
least 1 −δ"
REFERENCES,0.49137931034482757,"E
f (1)
S

x(1)
ℓ

−f (2)
S

x(2)
ℓ

2 2 
≤1 N N
X ℓ=1"
REFERENCES,0.49261083743842365,"f (1)
S

x(1)
ℓ

−f (2)
S

x(2)
ℓ

2 2"
REFERENCES,0.4938423645320197,"+ 2RN(H) + 4C2
f r"
REFERENCES,0.49507389162561577,log(1/δ)
N,0.4963054187192118,"2N
."
N,0.4975369458128079,"By Assumption 2(c), the first term on the right hand side can be bounded as"
N,0.4987684729064039,"1
N N
X ℓ=1"
N,0.5,"f (1)
S

x(1)
ℓ

−f (2)
S

x(2)
ℓ

2 2 = 1 N N
X ℓ=1"
N,0.5012315270935961,"f (1)
S

x(1)
ℓ

−u(1)
S

x(1)
+ u(2)
S

x(2)
−f (2)
S

x(2)
ℓ

2 2 ≤1 N N
X"
N,0.5024630541871922,"ℓ=1
(ν + ν)2 = 4ν2."
N,0.5036945812807881,"where the first equality is because there exist u(1) ∈G−1 and u(2) ∈G−1 such that u(1)
S
 
x(1)
=
u(2)
S
 
x(2)
= γ(z) and the second inequality is by the triangle inequality."
N,0.5049261083743842,"Therefore, by plugging in RN(H) we have:"
N,0.5061576354679803,"E
f (1)
S

x(1)
ℓ

−f (2)
S

x(2)
ℓ

2 2 
≤ϵ"
N,0.5073891625615764,with the definition
N,0.5086206896551724,"ϵ := 4ν2 + 8DCfRN + 4C2
f r"
N,0.5098522167487685,log(1/δ)
N,0.5110837438423645,2N = 4Cf 
N,0.5123152709359606,2DRN + Cf r
N,0.5135467980295566,log(1/δ)
N,0.5147783251231527,2N !
N,0.5160098522167488,+ 4ν2.
N,0.5172413793103449,Published as a conference paper at ICLR 2022
N,0.5184729064039408,"Next, we use the bound of true risk to bound the energy of the entries of the Jacobian matrix on the
left hand side of Eq. (D.1). Denote h(q)
S
= f (q)
S
◦g(q). We define the error for any individual sample"
N,0.5197044334975369,"pair

x(1)
ℓ, x(2)
ℓ

∼p
 
x(1), x(2)
as"
N,0.520935960591133,"f (1)
S (x(1)
ℓ) −f (2)
S (x(2)
ℓ)

2"
N,0.5221674876847291,"2 = εℓ,"
N,0.5233990147783252,with E[εℓ] ≤ϵ.
N,0.5246305418719212,"Define another two pairs of samples, such that
h(1)
S"
N,0.5258620689655172,"
zℓ
c(1)
ℓ
+ ∆ej"
N,0.5270935960591133,"
−h(2)
S"
N,0.5283251231527094," zℓ
c(2)
ℓ  2"
N,0.5295566502463054,"2
= εbℓ,"
N,0.5307881773399015,"h(1)
S"
N,0.5320197044334976,"
zℓ
c(1)
ℓ
−∆ej"
N,0.5332512315270936,"
−h(2)
S"
N,0.5344827586206896," zℓ
c(2)
ℓ  2"
N,0.5357142857142857,"2
= ε˜ℓ,"
N,0.5369458128078818,"where ∆> 0 and ej is the unit vector in the c(1)
j
direction. Then by triangle inequality we have
h(1)
S"
N,0.5381773399014779,"
zℓ
c(1)
ℓ
+ ∆ej"
N,0.5394088669950738,"
−h(1)
S"
N,0.5406403940886699,"
zℓ
c(1)
ℓ
−∆ej"
N,0.541871921182266,"
2
≤√εbℓ+ √ε˜ℓ."
N,0.5431034482758621,Define
N,0.5443349753694581,"ψij

c(1)
j

:=

h(1)
S"
N,0.5455665024630542,"h
¯z⊤,

¯c(1)
1 , · · · , c(1)
j , · · · , ¯c(1)
D1 i⊤ i
,"
N,0.5467980295566502,"which is a scalar function of c(1)
j
with fixed ¯z and ¯c(1)
k
for k ̸= j."
N,0.5480295566502463,"Then the element
∂[ b
fS(x(1))]i"
N,0.5492610837438424,"∂c(1)
j
can be estimated using the central difference formula as "
N,0.5504926108374384,"∂
h
b
fS
 
x(1)i"
N,0.5517241379310345,"i
∂c(1)
j = "
N,0.5529556650246306,"
h(1)
S"
N,0.5541871921182266,"
zℓ
c(1)
ℓ
+ ∆ej"
N,0.5554187192118226,"
−h(1)
S"
N,0.5566502463054187,"
zℓ
c(1)
ℓ
−∆ej "
N,0.5578817733990148,"i
2∆
−∆2"
N,0.5591133004926109,"12
 
ψ′′′
ij (ξ1) + ψ′′′
ij (ξ2)
  ≤ "
N,0.5603448275862069,"
h(1)
S"
N,0.5615763546798029,"
zℓ
c(1)
ℓ
+ ∆ej"
N,0.562807881773399,"
−h(1)
S"
N,0.5640394088669951,"
zℓ
c(1)
ℓ
−∆ej  i "
N,0.5652709359605911,"2∆
+

∆2"
N,0.5665024630541872,"6 ψ′′′
ij (ξ′)
 ,"
N,0.5677339901477833,"where ξ1 ∈

c(1)
ℓ,j , c(1)
ℓ,j + ∆

, ξ2 ∈

c(1)
ℓ,j −∆, c(1)
ℓ,j

and by intermediate value theorem ξ′ ∈

c(1)
ℓ,j −∆, c(1)
ℓ,j + ∆

."
N,0.5689655172413793,"Since |xi| ≤∥x∥∞≤∥x∥2, we have"
N,0.5701970443349754,"∂
h
b
fS
 
x(1)i"
N,0.5714285714285714,"i
∂c(1)
j"
N,0.5726600985221675,"≤
√εbℓ+ √ε˜ℓ"
N,0.5738916256157636,"2∆
+

∆2"
N,0.5751231527093597,"6 ψ′′′
ij (ξ′)
 ."
N,0.5763546798029556,"By taking expectation, we have E   "
N,0.5775862068965517,"∂
h
b
fS
 
x(1)i"
N,0.5788177339901478,"i
∂c(1)
j  "
N,0.5800492610837439,"≤
E[√εbℓ] + E[√ε˜ℓ]"
N,0.5812807881773399,"2∆
+

∆2"
N,0.5825123152709359,"6 ψ′′′
ij (ξ′) ≤
√ϵ ∆+ ∆2"
N,0.583743842364532,"6 |ψ′′′
ij (ξ′)|,"
N,0.5849753694581281,where the second inequality is by Jensen’s inequality
N,0.5862068965517241,"E[√εℓ] ≤
p"
N,0.5874384236453202,"E[εℓ] ≤√ε,"
N,0.5886699507389163,Published as a conference paper at ICLR 2022
N,0.5899014778325123,due to the concavity of √x.
N,0.5911330049261084,"We aim to find the smallest upper bound, i.e.,"
N,0.5923645320197044,"inf
0<∆<min
n
Cp+c(1)
ℓ,j ,Cp−c(1)
ℓ,j
o √ϵ ∆+ ∆2"
N,0.5935960591133005,"6 |ψ′′′
ij (ξ′)|.
(D.3)"
N,0.5948275862068966,"Note that the function in (D.3) is convex and smooth. We have the minimizer ∆∗∈ 
 "
N,0.5960591133004927,"3√ϵ
|ψ′′′
ij (ξ′)| !1/3"
N,0.5972906403940886,", min
n
Cp + c(1)
ℓ,j , Cp −c(1)
ℓ,j
o

 ,"
N,0.5985221674876847,"which gives us the minimum inf
∆ √ϵ ∆+ ∆2"
N,0.5997536945812808,"6 |ψ′′′
ij (ξ′)| ≤min (
3
2"
N,0.6009852216748769,"|ψ′′′
ij (ξ′)| 3"
N,0.6022167487684729,"1/3
ϵ1/3,
√ϵ"
N,0.603448275862069,"κj
+ κ2
j
6 |ψ′′′
ij (ξ′)| ) ."
N,0.604679802955665,"where κj = min
n
Cp + c(1)
ℓ,j , Cp −c(1)
ℓ,j
o
."
N,0.6059113300492611,"If κj ≥

3√ϵ
|ψ′′′
ij (ξ′)|
1/3
, then we can bound E   "
N,0.6071428571428571,"∂
h
b
fS
 
x(1)i"
N,0.6083743842364532,"i
∂c(1)
j   ≤3 2"
N,0.6096059113300493,"|ψ′′′
ij (ξ′)| 3"
N,0.6108374384236454,"1/3
ϵ1/3."
N,0.6120689655172413,"With fixed N, one can choose ϵ = 4Cf"
N,0.6133004926108374,"
2DRN + Cf
q"
N,0.6145320197044335,log(1/δ)
N,0.6157635467980296,2N
N,0.6169950738916257,"
+4ν2, which gives the following bound E   "
N,0.6182266009852216,"∂
h
b
fS
 
x(1)i"
N,0.6194581280788177,"i
∂c(1)
j   ≤3 2 Cd 3 1/3"
CF,0.6206896551724138,4Cf 
CF,0.6219211822660099,2DRN + Cf r
CF,0.6231527093596059,log(1/δ)
N,0.624384236453202,2N !
N,0.625615763546798,"+ 4ν2
!1/3 ,"
N,0.6268472906403941,"if κj ≥

3
Cd"
N,0.6280788177339901,"1/3 
4Cf"
N,0.6293103448275862,"
2DRN + Cf
q"
N,0.6305418719211823,log(1/δ)
N,0.6317733990147784,2N
N,0.6330049261083743,"
+ 4ν2
1/6
."
N,0.6342364532019704,"Considering all i, j pairs, we have E  
D
X i=1 D1
X j=1 "
N,0.6354679802955665,"∂
h
b
fS
 
x(1)i"
N,0.6366995073891626,"i
∂c(1)
j   ≤3 2DD1 Cd 3 1/3"
CF,0.6379310344827587,4Cf 
CF,0.6391625615763546,2DRN + Cf r
CF,0.6403940886699507,log(1/δ)
N,0.6416256157635468,2N !
N,0.6428571428571429,"+ 4ν2
!1/3 ."
N,0.6440886699507389,"Since ∥· ∥2 is upper bounded by ∥· ∥1, we have E   D
X i=1 D1
X j=1 "
N,0.645320197044335,"
∂
h
b
fS
 
x(1)i"
N,0.646551724137931,"i
∂c(1)
j   2 ≤9"
N,0.6477832512315271,"4D2D2
1 Cd 3 2/3"
CF,0.6490147783251231,4Cf 
CF,0.6502463054187192,2DRN + Cf r
CF,0.6514778325123153,log(1/δ)
N,0.6527093596059114,2N !
N,0.6539408866995073,"+ 4ν2
!2/3 ,"
N,0.6551724137931034,which completes the proof. The same holds for q = 2 by role symmetry.
N,0.6564039408866995,"E
PROOF OF PROPOSITION 1"
N,0.6576354679802956,"The claim can be proved by contradiction. Take q = 1 for example. Suppose that there exists two
elements bz(1)
i
and bc(1)
j
that are dependent but (9) is 0. Let"
N,0.6588669950738916,"ϕ1 = e⊤
i,
τ1 = e⊤
j,"
N,0.6600985221674877,Published as a conference paper at ICLR 2022
N,0.6613300492610837,"which are valid choices. Then, we have"
N,0.6625615763546798,"Cov[ϕ1(bz(1)), τ1(bc(1))] = E[bz(1)
i
bc(1)
j ] −E[bz(1)
i
]E[bc(1)
j ].
Note that by definition of independence, we have"
N,0.6637931034482759,"E[bz(1)
i
bc(1)
j ] = E[bz(1)
i
]E[bc(1)
j ] ⇐⇒bz(1)
i
⊥⊥bc(1)
j ."
N,0.6650246305418719,"Hence, bz(1)
i
and bc(1)
j
being dependent means that"
N,0.666256157635468,"E[bz(1)
i
bc(1)
j ] −E[bz(1)
i
]E[bc(1)
j ] ̸= 0.
Consequently, one can see that"
N,0.6674876847290641,"sup
ϕ1,τ1
Cov[ϕ1(bz(1)), τ1(bc(1))] ≥Cov[ϕ1(bz(1)), τ1(bc(1))]|ϕ1=e⊤
i,τ1=e⊤
j = Cov[bz(1)
i
bc(1)
j ] ̸= 0."
N,0.6687192118226601,The above is a contradiction to our assumption that holds.
N,0.6699507389162561,"On the other hand, if bz(1)
i
and bc(1)
j
are independent for all i ∈[D] and j ∈[D1], then we have"
N,0.6711822660098522,"E[ϕ(bz(1)
i
)τ(bc(1)
j )] −E[ϕ(bzi)]E[τ(bc(1)
j )] = 0,"
N,0.6724137931034483,"for all i ∈[D] and j ∈[D1], for any ϕ : R →R and τ : R →R."
N,0.6736453201970444,"F
DETAILED ALGORITHM IMPLEMENTATION"
N,0.6748768472906403,Recall that the proposed criterion is
N,0.6761083743842364,"maximize
f (1),f (2) Tr"
N,0.6773399014778325,"1
N N
X"
N,0.6785714285714286,"ℓ=1
f (1)
S

x(1)
ℓ

f (2)
S

x(2)
ℓ
⊤
!"
N,0.6798029556650246,(F.1a)
N,0.6810344827586207,"subject to f (q) for q = 1, 2 are invertible,
(F.1b)"
N,0.6822660098522167,"1
N N
X"
N,0.6834975369458128,"ℓ=1
f (q)
S

x(q)
ℓ

f (q)
S

x(q)
ℓ
⊤
= I, 1 N N
X"
N,0.6847290640394089,"ℓ=1
f (q)
S

x(q)
ℓ

= 0, q = 1, 2,
(F.1c)"
N,0.6859605911330049,"f (q)
S

x(q)
ℓ

⊥⊥f (q)
P

x(q)
ℓ

, q = 1, 2,
(F.1d)"
N,0.687192118226601,"We will use neural networks to parameterize the functions that we aim to learn. To move forward,
first, as we have shown in the proof of Theorem 1, Eq. (F.1) is equivalent to the following:"
N,0.6884236453201971,"minimize
f (1),f (2)
1
N N
X ℓ=1"
N,0.6896551724137931,"f (1)
S

x(1)
ℓ

−f (2)
S

x(2)
ℓ

2"
N,0.6908866995073891,"2
(F.2a)"
N,0.6921182266009852,"subject to 1 N N
X"
N,0.6933497536945813,"ℓ=1
f (q)
S

x(q)
ℓ

f (q)
S

x(q)
ℓ
⊤
= I, 1 N N
X"
N,0.6945812807881774,"ℓ=1
f (q)
S

x(q)
ℓ

= 0, q = 1, 2
(F.2b)"
N,0.6958128078817734,"f (q) for q = 1, 2 are invertible,
(F.2c)"
N,0.6970443349753694,"f (q)
S

x(q)
ℓ

⊥⊥f (q)
P

x(q)
ℓ

, q = 1, 2,
(F.2d)"
N,0.6982758620689655,"Note that we have manifold constraints on both neural networks f (1)
S
and f (2)
S . Directly optimizing
over such manifold constraints may be costly and challenging. To reduce the difficulty of this con-
strained problem, we introduce a slack variable uℓand recast the formulation in (F.2) as follows:"
N,0.6995073891625616,"minimize
f (1),f (2),uℓ
L = 1 N N
X"
N,0.7007389162561576,"ℓ=1
Lℓ= 1 N N
X ℓ=1"
X,0.7019704433497537,"2
X q=1"
X,0.7032019704433498,"uℓ−f (q)
S (x(q)
ℓ)

2"
X,0.7044334975369458,"2
(F.3a)"
X,0.7056650246305419,"subject to 1 N N
X"
X,0.7068965517241379,"ℓ=1
uℓu⊤
ℓ= I, 1 N N
X"
X,0.708128078817734,"ℓ=1
uℓ= 0.
(F.3b)"
X,0.7093596059113301,"f (q) for q = 1, 2 are invertible,
(F.3c)"
X,0.7105911330049262,"f (q)
S

x(q)
ℓ

⊥⊥f (q)
P

x(q)
ℓ

, q = 1, 2,
(F.3d)"
X,0.7118226600985221,Published as a conference paper at ICLR 2022
X,0.7130541871921182,"Ideally, we hope that uℓ= γ(zℓ). Introducing uℓmakes the f (1) and f (2) subproblems uncon-
strained. This is a commonly used reformulation in neural network based multiview matching (see
(Benton et al., 2017; Lyu & Fu, 2020)), which is reminiscent of the MAX-VAR formulation of
CCA (Kettenring, 1971; Carroll, 1968; Rastogi et al., 2015). Such reformulations oftentimes make
algorithm design easier, since the constraints are simplified."
X,0.7142857142857143,"The inveritibility and independence constraints in (F.3c) and (F.3d) are also not straightforward to
enforce. Instead of directly enforcing the invertibility constraint in (F.3c), we design a regularization
term. Specifically, we use the idea of autoencoder that reconstructs the samples from their latent
representations f (q)(x(q)
ℓ). We define a regularizer V = 1 N N
X"
X,0.7155172413793104,"ℓ=1
Vℓ= 1 N N
X ℓ=1"
X,0.7167487684729064,"2
X q=1"
X,0.7179802955665024,"x(q)
ℓ
−r(q)(f (q)(x(q)
ℓ))

2"
X,0.7192118226600985,"2 ,
(F.4)"
X,0.7204433497536946,"as the reconstruction loss, where r(q)’s are the reconstruction neural networks. Note that the above
term being zero does not necessarily indicate that the function f (q) is invertible, since this term
is only imposed on limited number of samples. But in practice, this idea is effective in learning
invertible transformations—also see (Wang et al., 2015; Lyu & Fu, 2020)."
X,0.7216748768472906,"To promote the statistical independence constraint in (F.3d), we use the designed independence
regularizer, i.e.,"
X,0.7229064039408867,"sup
ϕ(q),τ (q) R(q) =
sup
ϕ(q),τ (q)"
X,0.7241379310344828,"Cov

ϕ(q)  bz(q)
, τ (q)  bc(q)
q"
X,0.7253694581280788,"V[ϕ(q)  bz(q)
]
q"
X,0.7266009852216748,"V

τ (q)  bc(q),
(F.5)"
X,0.7278325123152709,where ϕ(q) and τ (q) are again represented by neural networks.
X,0.729064039408867,"Let θ collect the parameters of f (q) and r(q), and η the parameters of ϕ(q) and τ (q). Putting all the
terms together, our working cost function is summarized as follows:"
X,0.7302955665024631,"min
U,θ max
η
1
N N
X"
X,0.7315270935960592,"ℓ=1
Lℓ(θ, U) + β 1 N N
X"
X,0.7327586206896551,"ℓ=1
Vℓ(θ) + λR(θ, η),
(F.6a)"
X,0.7339901477832512,"subject to 1 N N
X"
X,0.7352216748768473,"ℓ=1
UU ⊤= I, 1"
X,0.7364532019704434,"N U1 = 0,
(F.6b)"
X,0.7376847290640394,"where U = [u1, · · · , uN] ∈RD×N, and β and λ are nonnegative and R = P2
q=1 R(q)."
X,0.7389162561576355,"In terms of algorithm design, we propose to handle U, θ and η cyclically when the other two are
fixed, i.e., alternating optimization (AO)."
X,0.7401477832512315,"First, we use stochastic gradient descent and ascent for the unconstrained θ and η subproblems. To
proceed, we sample a batch of data indexed by B ⊆[N]. Then, θ and η can be updated by any
stochastic gradient based optimizers, e.g., the plain-vanilla stochastic gradient descent/ascent,"
X,0.7413793103448276,"θ ←θ −γ 1
|B| X"
X,0.7426108374384236,"ℓ∈B
(∇θLℓ(θ, U) + β∇θVℓ(θ)) + λb∇θR(θ, η) ! ,"
X,0.7438423645320197,"η ←η + δ

λb∇ηR(θ, η)

,"
X,0.7450738916256158,"where γ and δ are the step sizes for the updates of θ and η, respectively. The stochastic gradients of
L, V are defined as follows:"
X,0.7463054187192119,b∇θL := 1 |B| X
X,0.7475369458128078,"ℓ∈B
∇θLℓ(θ, U)
(F.7a)"
X,0.7487684729064039,b∇θV := 1 |B| X
X,0.75,"ℓ∈B
∇θVℓ(θ).
(F.7b)"
X,0.7512315270935961,Published as a conference paper at ICLR 2022
X,0.7524630541871922,"In addition, the terms b∇θR and b∇ηR are defined similarly. Taking the latter as an example. We
have b∇ηR = P2
q=1 b∇ηR(q), and b∇ηR(q) is estimated by taking gradient w.r.t. η of the following"
X,0.7536945812807881,batch-estimated R(q) (the same holds for b∇θR):
X,0.7549261083743842,"R(q)
B
:=
(F.8a)

1
|B|
P ℓ∈B"
X,0.7561576354679803,"
ϕ(q) 
bz(q)
ℓ

−
1
|B|
P"
X,0.7573891625615764,"ℓ∈B
ϕ(q) 
bz(q)
ℓ
 
τ (q) 
bc(q)
ℓ

−
1
|B|
P"
X,0.7586206896551724,"ℓ∈B
τ (q) 
bc(q)
ℓ

s"
X,0.7598522167487685,"1
|B|
P ℓ∈B"
X,0.7610837438423645,"
ϕ(q)

bz(q)
ℓ

−
1
|B|
P"
X,0.7623152709359606,"ℓ∈B
ϕ(q)

bz(q)
ℓ
2s"
X,0.7635467980295566,"1
|B|
P ℓ∈B"
X,0.7647783251231527,"
τ (q)

bc(q)
ℓ

−
1
|B|
P"
X,0.7660098522167488,"ℓ∈B
τ (q)

bc(q)
ℓ
2"
X,0.7672413793103449,"b∇ηR(q) := ∇ηR(q)
B
(F.8b)"
X,0.7684729064039408,"b∇θR(q) := ∇θR(q)
B .
(F.8c)"
X,0.7697044334975369,"It was shown in (Fisher, 1915) that the correlation coefficient is computed using random samples
of Gaussian variables, the estimator in (F.8a) for R(q) is asymptotically unbiased. For other distri-
butions, the estimation also works well in practice; see, e.g., DCCA based works in (Wang et al.,
2015)."
X,0.770935960591133,"Consider more general stochastic optimizers, e.g., Adam (Kingma & Ba, 2015) and Adagrad (Duchi
et al., 2011). Then, the updates can be summarized as follows:"
X,0.7721674876847291,"θ ←SGD optimizer

θ, b∇θL + β b∇θV + λb∇θR

(F.9)"
X,0.7733990147783252,"η ←SGD optimizer

η, −b∇ηR

.
(F.10)"
X,0.7746305418719212,"where (F.10) uses the negative stochastic gradient since it is an ascending step, while stochastic
optimizers are by default descending the objective function."
X,0.7758620689655172,"The U subproblem consists of (F.3a) and (F.3b). It can be re-expressed as follows by expanding
(F.3a):"
N,0.7770935960591133,"1
N N
X ℓ=1"
X,0.7783251231527094,"2
X q=1"
X,0.7795566502463054,"uℓ−f (q)
S (x(q)
ℓ)

2 2 = 1 N N
X"
X,0.7807881773399015,"ℓ=1
Tr "
X,0.7820197044334976,"2uℓu⊤
ℓ−2uℓ

f (1)
S

x(1)
ℓ

+ f (2)
S

x(2)
ℓ
⊤
+"
X,0.7832512315270936,"2
X"
X,0.7844827586206896,"q=1
f (q)
S

x(q)
ℓ

f (q)
S

x(q)
ℓ
⊤
! ."
X,0.7857142857142857,"Note that the first term is a constant by (F.3b) and the last term does not involve uℓ. Then, we rewrite
the uℓsubproblem as"
X,0.7869458128078818,"maximize
U
Tr

U

F (1) + F (2)
,
(F.11)"
X,0.7881773399014779,subject to 1
X,0.7894088669950738,"N UU ⊤= I, 1"
X,0.7906403940886699,"N U1 = 0,"
X,0.791871921182266,"where F (q) =
h
f (q)
S (x(q)
1 ), · · · , f (q)
S (x(q)
N )
i
. This is an orthogonal projection onto the set of row
zero-mean and orthogonal matrices. It is shown in (Lyu & Fu, 2020, Lemma 1) that such a projec-
tion problem, although nonconvex, can be solved to optimality via a mean-removed singular value
decomposition (SVD) procedure, i.e., U ←
√"
X,0.7931034482758621,"NST ⊤, with SDT ⊤= SVD

F (1) + F (2)
W

,
(F.12)"
X,0.7943349753694581,where W = IN −1
X,0.7955665024630542,"N 11⊤removes the mean of F (1) + F (2), D ∈RD×D holds the singular values,
S ∈RD×D and T ∈RN×D are the left and right orthogonal matrices in the SVD, respectively."
X,0.7967980295566502,"To summarize, an alternating optimization algorithm is summarized in Algorithm 1. Notice that
we use two different batch sizes (denoted as B1 and B2 in line 4 of Algorithm 1) to construct the
gradient estimations for b∇θL, b∇θV and b∇θR, b∇ηR, respectively. The reason is that accurately"
X,0.7980295566502463,Published as a conference paper at ICLR 2022
X,0.7992610837438424,Algorithm 1: Proposed Algorithm.
X,0.8004926108374384,"Data: x(q)
ℓ
for ℓ= 1, · · · , N and q = 1, 2
Result: f (q), r(q)"
WHILE STOPPING CRITERION IS NOT REACHED DO,0.8017241379310345,1 while stopping criterion is not reached do
WHILE STOPPING CRITERION IS NOT REACHED DO,0.8029556650246306,"2
U ←
√"
WHILE STOPPING CRITERION IS NOT REACHED DO,0.8041871921182266,"NST ⊤with SDT ⊤= SVD

F (1) + F (2)
W

;"
WHILE STOPPING CRITERION IS NOT REACHED DO,0.8054187192118226,"3
while stopping criterion is not reached do"
WHILE STOPPING CRITERION IS NOT REACHED DO,0.8066502463054187,"4
draw a random batch B1 and B2;
// use |B2| > |B1|"
WHILE STOPPING CRITERION IS NOT REACHED DO,0.8078817733990148,"5
b∇θL ←
1
|B1|
P"
WHILE STOPPING CRITERION IS NOT REACHED DO,0.8091133004926109,ℓ∈B1 ∇θLℓ;
WHILE STOPPING CRITERION IS NOT REACHED DO,0.8103448275862069,"6
b∇θV ←
1
|B1|
P"
WHILE STOPPING CRITERION IS NOT REACHED DO,0.8115763546798029,ℓ∈B1 ∇θVℓ;
WHILE STOPPING CRITERION IS NOT REACHED DO,0.812807881773399,"7
b∇ηR ←P2
q=1 ∇ηR(q)
B2 ;
// using B2 and (F.8a), (F.8b)"
WHILE STOPPING CRITERION IS NOT REACHED DO,0.8140394088669951,"8
b∇θR ←P2
q=1 ∇θR(q)
B2 ;
// using B2 and (F.8a), (F.8c)"
WHILE STOPPING CRITERION IS NOT REACHED DO,0.8152709359605911,"9
θ ←SGD optimizer

θ, b∇θL + β b∇θV + λb∇θR

;
// descent"
WHILE STOPPING CRITERION IS NOT REACHED DO,0.8165024630541872,"10
η ←SGD optimizer

η, −λb∇ηR

;
// ascent"
END,0.8177339901477833,"11
end"
END,0.8189655172413793,12 end
END,0.8201970443349754,"Table F.1: Computational complexity of the proposed algorithm in each iteration, where dθ and
dη denote the parameter dimensions of the encoder/reconstruction and the independence-promoting
networks, respectively."
END,0.8214285714285714,"Complexity (flops)
Line 2
O(ND2)
Line 5
O(|B1|dθ)
Line 6
O(|B1|dθ)
Line 7
O(|B2|dη)
Line 8
O(|B2|dθ)
Line 9
O(dθ)
Line 10
O(dη)
Overall
O
 
ND2 + (|B1| + |B2|)dθ + |B2|dη
"
END,0.8226600985221675,"estimating of R using (F.8a) often requires a relatively large batch size, while small batches may
suffice for the gradient estimations of L and V, according to our extensive simulations."
END,0.8238916256157636,"Computational Complexity.
Tab. F.1 summarizes the computational complexity of each step.
Specifically, line 2 requires computing a thin SVD, which requires O(ND2) flops. Note that this is
linear in the number of samples N, and D is the dimension of the shared component, which is often
relatively small in practice."
END,0.8251231527093597,"Inside the inner loop line 4-10, lines 5 and 6 construct the gradient estimations w.r.t. θ and η.
These two steps cost O(|B1|dθ) flops. Similarly, lines 7 and 8 use O(|B2|dη) and O(|B2|dθ) flops,
respectively. Note that we have used dθ and dη to denote the parameter dimensions of the en-
coder/reconstruction and the independence-promoting networks, respectively. Typically, |B1| and
|B2| are small numbers compared to N (e.g., |B1| = 128, |B2| = 512 while N could easily exceed
105). For line 9 and 10, when a first-order stochastic optimizer (e.g., plain-vanilla SGD, ADAM,
Adagrad) is used, this step has a computational complexity that is linear in terms of the network
size."
END,0.8263546798029556,"One can see that all the steps scale linearly with size of the neural networks or the sample size, which
makes the algorithm easy to run with large-scale data sets and large-size neural feature extractors."
END,0.8275862068965517,Published as a conference paper at ICLR 2022
END,0.8288177339901478,Figure G.1: Left: z; middle: t-SNE of x(1); right: t-SNE of x(2).
END,0.8300492610837439,"G
EXPERIMENTS: MORE DETAILS AND ADDITIONAL VALIDATIONS"
END,0.8312807881773399,"In this section, we show all the experiment results with greater details, e.g., results under more
metrics, more setting details, and more demonstrations. We also include more real data experiments
using the CIFAR10 (Krizhevsky et al., 2009) and dSprites data (Higgins et al., 2017)."
END,0.8325123152709359,"G.1
SYNTHETIC DATA - VALIDATING MAIN THEOREMS"
END,0.833743842364532,"In this subsection, we describe the synthetic data experiments. For synthetic data, we generate the
shared z ∈R2 that is uniformly drawn from the unit circle, with noise N(0, 0.022) added to each
dimension. The private components are scalars c(1) ∼N(0, 2.0) and c(2) ∼Laplace(0, 4.0). The
shared-to-private energy ratios for the two views are approximately -6 dB and -18 dB. The sample
size is N = 5, 000. And we use two different one-hidden-layer neural networks with 3 neurons
and softplus activation to represent the invertible g(q)’s. The network parameters are drawn from
standard normal distribution."
END,0.8349753694581281,"The shared component z and the t-SNE of x(1) and x(2) are shown in Fig. G.1. One can see
that by incorporating strong noise and nonlinear transformations, the shape of circle is hardly to be
identified in both views."
END,0.8362068965517241,"In our simulations, f (q) is represented by a three-hidden-layer multi-layer perceptrons (MLPs) with
256 neurons in each layer with ReLU activations. In addition, ϕ(q) and τ (q) are represented by two-
hidden-layer MLPs with 128 neurons in each layer. We set batch size to be 1000, β = 1.0, λ = 0.1.
We use the Adam optimizer (Kingma & Ba, 2015) with initial learning rate 0.001 for all the parame-
ters. Besides, we also regularize the network parameters using ∥η∥2
2 with a regularization parameter
0.1. This often helps improve numerical stability when optimizing cost functions involving neural
networks. We run lines 4-10 of Algorithm 1 for 10 epochs to update θ and η."
END,0.8374384236453202,"For ablation study, we test the methods with different combinations of L, R and V, i.e.,"
END,0.8386699507389163,"(i) the proposed method (L + V + R);
(ii) the proposed without independence regularization (L + V);
(iii) the proposed without reconstruction (L + R);"
END,0.8399014778325123,(iv) the proposed with only latent correlation maximization (L);
END,0.8411330049261084,"(v) we also test the performance with HSIC (Gretton et al., 2007) as the independence regular-
izer (L + V + HISC);"
END,0.8423645320197044,"All methods stop when the average matching loss L reaches 0.01. The learned components by the
proposed method are shown in Fig. G.2. One can see that the estimated shared components are
matched, while the second view exhibits relatively large noise level as expected. For the estimated
private components, one can see that both δ(1)(·) and δ(2)(·) are approximately invertible functions."
END,0.8435960591133005,"To evaluate the performance of the synthetic experiment, we compute mutual information (MI) be-
tween groups of random variables of interest (measured by the mutual information neural estimation"
END,0.8448275862068966,Published as a conference paper at ICLR 2022
END,0.8460591133004927,"Figure G.2: (a) Scatter plot of bz(1); (b) bc(1) as a function of c(1); (c) Scatter plot of bz(2); (d) bc(2) as
a function of c(2)."
END,0.8472906403940886,"(MINE) (Belghazi et al., 2018) and Gaussian kernel density estimation (KDE) (Davis et al., 2011)).
The results are averaged from 10 random trials."
END,0.8485221674876847,"One can see that all methods successfully extract the information about z in the sense that both
bz(q) = b
f (q)
S (x(q)) for q = 1, 2 have similarly high MIs with z. Besides, all methods output bz(q) and
bc(q) (c(q)) that have small MIs—meaning that they are not dependent."
END,0.8497536945812808,"Although most loss functions using latent correlation maximization extract the shared z’s informa-
tion well, the difference is articulated in extracting the private information. The proposed L+V +R
objective has the best performance on that regard. The method L+V +HSIC also works reasonably
well since HSIC serves the same purpose as R does—but with a kernel-based implementation."
END,0.8509852216748769,"Moreover, by looking at the last two columns, one can see that the methods with R and V perform
the best in removing the information of z from c(q). This corroborates our analysis that both (7b)
(invertibility) and (7d) (independence) are vital to achieve private-shared information disentangle-
ment."
END,0.8522167487684729,"Tab. G.1 shows the results, with all the entries averaged over 10 random trials. One can see that
the results via the Gaussian KDE are consistent with those under MINE. That is, the proposed
L + V + R exhibits the best performance in terms of extracting and disentangling the shared and
private information."
END,0.853448275862069,"G.2
SYNTHETIC DATA - ROBUSTNESS TO STRONG PRIVATE INTERFERENCE"
END,0.854679802955665,"In this subsection, we demonstrate the performance of the proposed method under different levels of
private component energy (which are often considered interference) (Ibrahim & Sidiropoulos, 2020;
Bach & Jordan, 2005; Lyu & Fu, 2020). First, we define the shared-to-private ratio (SPR) for the
q-th view as"
END,0.8559113300492611,SPR = 10 log10 
END,0.8571428571428571,"
1
DN
PN
ℓ=1 ∥zℓ∥2
2
1
DqN
PN
ℓ=1 ∥c(q)
ℓ∥2
2  dB."
END,0.8583743842364532,"For the experiment, we make both views have identical SPRs. We test the performance under SPR=-
10 dB, -20 dB and -30 dB, respectively."
END,0.8596059113300493,Published as a conference paper at ICLR 2022
END,0.8608374384236454,"Table G.1: Mutual information (MI) between groups of variables. “↑”: high score preferred; “↓”:
low score preferred; “n/a”: not applicable; bz(q) = b
f (q)
S
for q = 1, 2.
bz(1),z (↑)
bz(2),z (↑)
bz(1),c(1) (↓)
bz(2),c(2) (↓) bc(1),c(1) (↑) bc(2),c(2) (↑) bc(1),z (↓)
bc(2),z (↓)
Metric
MINE-based MI Estimation (Belghazi et al., 2018)
L
2.32±0.06 2.36±0.10
0.01±0.00
0.00±0.00
0.45±0.13 0.33±0.07 0.39±0.14 0.43±0.04
L + V
2.37±0.05 2.38±0.08
0.01±0.00
0.01±0.00
0.55±0.09 0.33±0.08 0.31±0.06 0.43±0.05
L + R
2.32±0.05 2.33±0.07
0.02±0.01
0.00±0.00
0.90±0.42 0.22±0.12 0.09±0.06 0.22±0.12
L + V + R
2.43±0.04 2.39±0.09
0.01±0.01
0.01±0.00
1.22± 0.33 0.85±0.23 0.04±0.02 0.11±0.03
L + V+HSIC 2.48±0.09 2.43±0.08
0.01±0.00
0.01±0.01
0.68±0.25 0.52±0.14 0.04±0.01 0.07±0.02
Metric
Gaussian kernel density estimate (KDE)-based MI Estimation
L
2.73±0.22 2.88±0.22
0.00±0.00
0.00
0.33±0.13 0.01±0.02 0.34±0.13 0.37±0.06
L + V
2.95±0.21 2.91±0.26
0.00±0.01
0.00
0.38±0.11 0.01±0.02 0.24±0.04 0.39±0.07
L + R
2.83±0.18 2.86±0.15
0.00
0.00
0.72±0.40 0.10±0.10 0.08±0.07 0.28±0.16
L + V + R
3.27±0.07 2.88±0.25
0.00±0.01
0.00
0.99±0.30 0.35±0.11 0.03±0.04 0.08±0.03
L + V+HSIC 3.35±0.16 2.95±0.33
0.00
0.00
0.78±0.22 0.06±0.06 0.05±0.02 0.02±0.01"
END,0.8620689655172413,"Table G.2: Mutual information (MI) between groups of variables under different SPR. “↑”: high
score preferred; “↓”: low score preferred; bz(q) = b
f (q)
S
for q = 1, 2.
bz(1),z (↑)
bz(2),z (↑)
bz(1),c(1) (↓)
bz(2),c(2) (↓)
bc(1),c(1) (↑)
bc(2),c(2) (↑)
bc(1),z (↓)
bc(2),z (↓)
SPR
MINE-based MI Estimation (Belghazi et al., 2018)
-10 dB
2.41±0.07
2.43±0.05
0.01±0.01
0.01±0.01
1.72±0.41
0.52±0.10
0.02±0.01
0.19±0.03
-20 dB
1.81±0.10
2.15±0.09
0.10±0.06
0.01±0.01
1.41±0.15
1.15±0.07
0.08±0.04
0.06±0.02
-30 dB
1.16±0.07
1.55±0.10
0.11±0.09
0.07±0.04
1.77±0.42
0.73±0.14
0.03±0.02
0.14±0.11"
END,0.8633004926108374,"Table G.3: Mutual information (MI) between groups of variables with different β (i.e. reconstruction
term). “↑”: high score preferred; “↓”: low score preferred; bz(q) = b
f (q)
S
for q = 1, 2.
bz(1),z (↑)
bz(2),z (↑)
bz(1),c(1) (↓)
bz(2),c(2) (↓)
bc(1),c(1) (↑)
bc(2),c(2) (↑)
bc(1),z (↓)
bc(2),z (↓)
λ = 1e−1
MINE-based MI Estimation (Belghazi et al., 2018)
β = 1e−2
2.13±0.26
2.11±0.33
0.01±0.01
0.01±0.00
0.77±0.03
0.48±0.18
0.13±0.02
0.17±0.07
β = 1e−1
2.16±0.23
2.12±0.21
0.01±0.01
0.01±0.00
1.09±0.37
0.70±0.20
0.10±0.06
0.16±0.07
β = 1e0
2.41±0.13
2.38±0.12
0.01±0.00
0.01±0.00
1.48±0.08
0.93±0.17
0.02±0.00
0.10±0.04
β = 1e1
2.34±0.19
2.28±0.08
0.04±0.04
0.02±0.02
0.86±0.40
0.41±0.21
0.15±0.10
0.52±0.26
β = 1e2
2.32±0.01
1.77±0.07
0.07±0.02
0.40±0.05
0.58±0.04
0.21±0.03
0.31±0.01
0.69±0.05"
END,0.8645320197044335,"Tab. G.2 shows the evaluation results averaged from 10 trials. One can see that as SPR decreases, the
MI between the extracted bz and z decreases—but only gracefully. The slight decline of performance
is because the matching of two views becomes harder when the private components get stronger.
However, even if SPR=-30 dB, the extraction and disentanglement of private and shared information
are still clearly achieved. Such robustness to strong private interference is considered a key feature
of linear CCA (Ibrahim & Sidiropoulos, 2020) and post-nonlinear CCA (Lyu & Fu, 2020). Our
analysis and evaluation in this work show that such resilience is also inherited by the proposed
approach."
END,0.8657635467980296,"G.3
SYNTHETIC DATA - SENSITIVITY TO HYPERPARAMETERS"
END,0.8669950738916257,"In this subsection, we investigate the sensitivity to the key hyperparameters β and λ. The results are
shown in Tab. G.3 and Tab. G.4, respectively. One can see that for the reconstruction regularization
parameter (i.e., β) does not affect the results too much unless it was set to be overly large (i.e., β = 1
or 100 in our simulation). This makes sense, since reconstruction is for preventing trivial degenerate
solutions, and giving this part too much attention may not really help the learning goals (e.g., shared
and private information extraction) reflected in the other parts of the loss function. From Tab. G.4,
one can see that the choice of λ affects the performance slightly more than β. It makes sense, since
λ reflects the attention that the algorithm puts on the private component extraction part. We should
mention that, for real data analysis with a downstream task (e.g., classification), one can choose
these hyperparameters using a validation set."
END,0.8682266009852216,Published as a conference paper at ICLR 2022
END,0.8694581280788177,"Table G.4: Mutual information (MI) between groups of variables with different λ (i.e. independence
regularizer). “↑”: high score preferred; “↓”: low score preferred; bz(q) = b
f (q)
S
for q = 1, 2.
bz(1),z (↑)
bz(2),z (↑)
bz(1),c(1) (↓)
bz(2),c(2) (↓)
bc(1),c(1) (↑)
bc(2),c(2) (↑)
bc(1),z (↓)
bc(2),z (↓)
β = 1e0
MINE-based MI Estimation (Belghazi et al., 2018)
λ = 1e−2
2.36±0.09
2.34±0.05
0.01±0.00
0.01±0.00
0.56±0.18
0.51±0.14
0.25±0.07
0.36±0.08
λ = 1e−1
2.41±0.13
2.38±0.12
0.01±0.00
0.01±0.00
1.48±0.08
0.93±0.17
0.02±0.01
0.10±0.04
λ = 1e0
2.04±0.12
2.00±0.11
0.04±0.01
0.02±0.00
0.71±0.17
0.37±0.10
0.15±0.06
0.22±0.03
λ = 1e1
1.49±0.18
1.55±0.11
0.17±0.07
0.17±0.10
0.61±0.04
0.17±0.07
0.23±0.02
0.16±0.05
λ = 1e2
0.80±0.23
0.96±0.36
0.46±0.13
0.28±0.07
0.18±0.08
0.22±0.06
0.75±0.37
0.57±0.18"
END,0.8706896551724138,Table G.5: Network structures for the MNIST experiment.
END,0.8719211822660099,"Encoders
Decoders"
END,0.8731527093596059,"input: x(q)
ℓ
∈R28×28×1
input: f (q)(x(q)
ℓ) ∈RD+Dq
4 × 4 Conv, 64 ReLU, stride 2
FC 256, ReLU
4 × 4 Conv, 32 ReLU, stride 2
FC 7 × 7 × 32, ReLU
FC 256, ReLU
4 × 4 Conv Trans, 64 ReLU, stride 2
FC D + Dq
4 × 4 Conv Trans, 1, stride 2"
END,0.874384236453202,"G.4
REAL DATA - MORE ON VALIDATING THEOREM 1"
END,0.875615763546798,"Multiview MNIST Data. In this subsection, we provide more details and evaluation results on the
MNIST experiment. The way of generating such two views (as shown in Fig. 1 of the main text) of
MNIST data is similar to the data augmentation ideas used in AM-SSL, e.g., rotation, adding noise,
cropping, flipping (Chen et al., 2020; Grill et al., 2020). We aim to match the two views and try
to learn the shared representations, which should encode the class label information. The dataset
has 70,000 samples that are 28×28 images of handwritten digits. For the latent dimension, we set
D = 10, D1 = 20 and D2 = 50. In particular, since the second view consists of large random noise
that are not of interest, we only add the independence regularizer R(1) on the first view (i.e., the
rotated digits) to learn the private component of x(1)
ℓ. The learned bc(1)
ℓ
was used to generate new
samples; see the illustration in our main text."
END,0.8768472906403941,"The network structure used for all methods is shown in Tab. G.5. The network structure for ϕ(q) and
τ (q) are MLPs with three hidden layers of 64 neurons. For hyperparameters, we set batch size to be
|B1| = 100 and |B2| = 1000, β = 1.0, λ = 100.0. For optimizer, we also use Adam (Kingma &
Ba, 2015) with initial learning rate 0.001 for θ and 1.0 for η. And we add squared ℓ2 regularization
for both θ and η, with different regularization parameters that are 0.0001 and 0.1, respectively. We
also run the SGD optimizer for 10 epochs to update θ and η."
END,0.8780788177339901,"In Tab. G.6, we show more evaluation results on the learned shared information across views. To
be specific, we feed the learned bz(1)
ℓ’s to a classifier and the k-means algorithm, to observe if the
learned representations improve the performance of supervised and unsupervised learning tasks. For
the classification task, we split the data as 50,000/10,000/10,000 for training/validation/test sets. We
train a linear support vector machine (SVM) using the training data. The performance is measured by
classification error (ERR). For the clustering task, we use the standard k-means to cluster on all the
data samples. After clustering, we report the performance on the test set. We use a number of metrics
to measure performance, namely, clustering accuracy (ACC), normalized mutual information (NMI),
and adjusted Rand index (ARI) (Yeung & Ruzzo, 2001). Among these metrics, ARI ranges from
−1 to +1, with 1 being the best and −1 the worst and NMI range from 0 to 1 with 1 being the best."
END,0.8793103448275862,"The “Baseline” denotes the results of simply applying SVM and k-means onto the raw data of
the first view, i.e., x(1)
ℓ
for ℓ= 1, . . . , N. All the results of algorithms that involve stochastic
methods are averaged over 5 random initializations. One can see that all methods have comparably
good results in terms of learning informative representations across views. The results empirically
validate our Theorem 1 that latent correlation maximization is a useful criterion to extract the shared
information with guarantees. In particular, Barlow Twins performs slightly better in terms of
benefiting downstream classification and clustering tasks. Nonetheless, the proposed method can"
END,0.8805418719211823,Published as a conference paper at ICLR 2022
END,0.8817733990147784,"Figure G.3: t-SNE of the results on multiview MNIST of the second view. Baselines: DCCA (Wang
et al., 2015), Barlow Twins (Zbontar et al., 2021) and BYOL (Grill et al., 2020) ."
END,0.8830049261083743,"Table G.6: The classification error (first row) and clustering results (rows 2 to 4) of the two-view
MNIST dataset. “↑”: high score preferred; “↓”: low score preferred."
END,0.8842364532019704,"Baseline
L + V + R
L + V
DCCA
DCCAE
Barlow Twins
BYOL
ERR (↓)
13.40%
2.81%±0.21%
2.95%±0.23%
2.87%±0.16%
2.85%±0.05%
2.05%±0.07%
2.67%±0.22%
ACC (↑)
37.35%
97.03%±0.13%
96.80%±0.40%
97.02%%±0.12%
96.95%±0.12%
98.06%±0.06%
95.56%±0.41%
NMI (↑)
0.337
0.922±0.003
0.923±0.007
0.922±0.003
0.920±0.003
0.947±0.002
0.895±0.023
ARI (↑)
0.216
0.936±0.003
0.931±0.009
0.935±0.003
0.934±0.002
0.958±0.001
0.904±0.047"
END,0.8854679802955665,"Table G.7: Augmentation Used for CIFAR10 to Generate Multiple Views.
Transformation
Value
Probability
ColorJitter
brightness=0.8, contrast=0.8, saturation=0.8, hue=0.2
0.8
GrayScale
-
0.2
RandomResizedCrop
scale=(0.2, 1.0), ratio=(0.75, 4/3)
-
HorizontalFlip
-
0.5
GaussianBlur
σ ∼U[0.1, 2]
0.5
Solarization
-
0.4
Normalization
-
-"
END,0.8866995073891626,"also guarantee extracting private information and facilitate cross-view image generation (see the
experiments in the main text), which is out the reach of Barlow Twins and BYOL."
END,0.8879310344827587,"In addition to showing the visualization of the learned embedding of the firs view in Fig. 1 of the
main paper, we also plot the t-SNE of the learned representation bz(2)
ℓ
of the second view (i.e., the
noisy digits). The results are shown in Fig. G.3. One can see that the visualization and clustering
accuracy are similar to those obtained from bz(1)
ℓ."
END,0.8891625615763546,"Augmented CIFAR10 Data for SSL. We also use the CIFAR10 dataset (Krizhevsky et al., 2009)
to validate Theorem 1. The CIFAR10 dataset contains 50,000 and 10,000 images of size 32×32 for
training and testing, respectively. There are 10 different classes. We use ResNet18 as the backbone
network for learning the representation. Since CIFAR10 images are small, we replace the first 7x7
Conv layer of stride 2 with 3x3 Conv layer of stride 1. We also remove the max pooling layer. We
follow the evaluation method in (Chen & He, 2021) to stop the algorithms after one hundred epochs.
In terms of data augmentation, we use the pipeline of different transformations in Tab. G.7. Note
that for the proposed method, we only impose constraint (7c) since our goal here in this task is to
extract essential shared information."
END,0.8903940886699507,"We evaluate the proposed method and two AM-SSL baselines as mentioned in the main text, namely,
Barlow Twins (Zbontar et al., 2021) and BYOL (Grill et al., 2020) by feeding the learned rep-
resentations to a linear classifier. We report both the Top-1 linear classification accuracy and the
KNN (with k = 5) accuracy. The results are shown in Tab. G.8. One can see that different methods
achieve comparable results. The proposed method and BYOL attain essentially the same accuracy.
The t-SNE (Van der Maaten & Hinton, 2008) visualizations of the test set is plotted in Fig. G.4.
One can see that all methods extract “identity-revealing” information to a certain extent, as in the
MNIST case."
END,0.8916256157635468,Published as a conference paper at ICLR 2022
END,0.8928571428571429,Table G.8: Evaluation using CIFAR10.
END,0.8940886699507389,"BYOL
Barlow Twins
Proposed
Classification Acc. (%)
84.2
82.8
84.2
KNN (k = 5) Acc. (%)
80.5
78.7
81.0"
END,0.895320197044335,Figure G.4: t-SNE of learned representations for CIFAR10.
END,0.896551724137931,Figure G.5: Samples of the lower elevations (view1) and higher elevations (view2).
END,0.8977832512315271,"Remark 1 We should remark that the experiment results suggest that latent correlation maximiza-
tion (or latent component matching) used in many AM-SSL and DCCA methods works towards the
same ultimate goal under our generative model in (5). However, this does not suggest that different
SSL and DCCA methods are essentially the same in practice—one should not expect that. In fact,
there are many factors that affect DCCA and AM-SSL methods’ results, e.g., model mismatches,
optimization procedure, network construction, and the detailed designs in their loss functions. The
difference between the methods normally are more articulated with larger data sets or more complex
problems. Nonetheless, our interest lies in theoretical understanding of their common properties,
other than the differences in practical implementations. From this perspective, the results in this
section support our theoretical analysis in Theorem 1."
END,0.8990147783251231,"G.5
REAL DATA - MORE ON VALIDATING THEOREM 2"
END,0.9002463054187192,"Cars3D Data for Cross-sample Generation. In this subsection, we provide more detailed settings
and results of the Cars3D experiment. To create a multiview dataset, we assume that given the car
type that is captured by shared variables z and the azimuths that are captured by c(q), the generation
mappings g(1) and g(2) produce car images with low elevations and high elevations, respectively (so
they must be different mappings)."
END,0.9014778325123153,"We split the car images as follows. We treat the same car model (e.g., a red convertible) with
lower and higher elevations as x(1)
ℓ
and x(2)
ℓ, respectively. The azimuths are randomly shuffled
with different pairs of x(1)
ℓ
and x(2)
ℓ. This way, if our generative model holds, z, c(q) and g(q) are
responsible for ‘type’, ‘azimuth’ and ‘elevation’, respectively. Some samples are shown in Fig. G.5."
END,0.9027093596059114,"Under our splitting, each view has 2×183×24 = 8784 RGB images that all have a size of 64×64×3.
We model the ‘type’ information z using D = 10 latent dimensions since many different factors
(e.g., color and shape) together give rise to a ‘type’. On the other hand, we set D1 = D2 = 2 to
model the ‘azimuth’ information."
END,0.9039408866995073,"Tab. G.9 shows network structures for the encoders and decoders of our formulation in (F.6). In the
table, FC denotes fully connected layer, Conv denotes convolutional layer and Conv Trans denotes
2D transposed convolutional layer. As before, the structures of ϕ(q) and τ (q) are MLPs with two-"
END,0.9051724137931034,Published as a conference paper at ICLR 2022
END,0.9064039408866995,Table G.9: Network structures for the Cars3D experiment.
END,0.9076354679802956,"Encoders
Decoders"
END,0.9088669950738916,"input: x(q)
ℓ
∈R64×64×3
input: f (q)(x(q)
ℓ) ∈R10+2
4 × 4 Conv, 32 ReLU, stride 2
FC 256, ReLU
4 × 4 Conv, 32 ReLU, stride 2
FC 4 × 4 × 64, ReLU
4 × 4 Conv, 64 ReLU, stride 2
4 × 4 Conv Trans, 64 ReLU, stride 2
4 × 4 Conv, 64 ReLU, stride 2
4 × 4 Conv Trans, 32 ReLU, stride 2
FC 256, ReLU
4 × 4 Conv Trans, 32 ReLU, stride 2
FC 10+2
4 × 4 Conv Trans, 3, stride 2"
END,0.9100985221674877,"Figure G.6: Generated samples by fixing bzℓand varying bc(q)
j ; rows in blue boxes are w/ R; rows in
green boxes are w/o R."
END,0.9113300492610837,"hidden-layer and 256 neurons for each layer. For hyperparameters, we set batch size to be |B1| =
100 and |B2| = 800, β = 0.1, λ = 1.0. For this real data experiment, we also use Adam (Kingma
& Ba, 2015) as the optimizer with initial learning rate 0.001 for θ and 1.0 for η. We add ∥η∥2
2 for
regularization with parameter 0.0001. We limit the inner loops for solving the θ and η subproblems
to 10 epochs as well."
END,0.9125615763546798,Figs. G.6 and G.7 show more results under the same setting as in Fig. 2 in the main text.
END,0.9137931034482759,"dSprites Data for Cross-sample data Generation. We present the results on an additional dataset,
i.e., dSprites (Higgins et al., 2017). In the dSprites dataset, 64 × 64 images are generated based on
five factors: 3 shapes (square, ellipse, heart), 6 scales, 40 orientations, and 32 different horizontal
and vertical coordinates."
END,0.9150246305418719,"In particular, we take a subset that contains squares and hearts as the two views of data. In this
subset, all the data samples are with the same scale. We assume the generating functions g(1)"
END,0.916256157635468,"and g(2) are responsible for the shape of square and heart, respectively. We treat the orientation
and horizontal positions as the shared information, i.e., z, and the vertical position as the private
information c(q). The vertical coordinates are random and not matched between different pairs of
x(1)
ℓ
and x(2)
ℓ. Overall, we have 40, 960 samples for each view. We set D = 2 and D1 = D2 = 1."
END,0.9174876847290641,"We use the same neural network structure as in Tab. G.9. The only differences lie in the input and
latent dimensions. The network structure for ϕ(q) and τ (q) are MLPs with two hidden layers of 128
neurons, and we set |B1| = 100, |B2| = 500, β = 0.1, and λ = 100.0. Similar as before, we use
the Adam (Kingma & Ba, 2015) optimizer with initial learning rate 0.001 for θ. As before, we add
a squared ℓ2 norm regularization on the network parameters η, and set the regularization parameter
to 0.1. We let the inner loop stochastic optimizers run for 10 epochs."
END,0.9187192118226601,Published as a conference paper at ICLR 2022
END,0.9199507389162561,"Figure G.7: Generated samples by fixing bc(q)
j
and varying bzl; rows in blue boxes are w/ R; rows in
green boxes are w/o R."
END,0.9211822660098522,"We conduct the same cross-sample data generation experiment as in the Cars3D case. Fig. G.8
shows the results. To be specific, we extract bz(q)
ℓ
=
b
fS(x(q)
ℓ) that represents the rotation and
horizontal coordinate information and bc(q)
j
=
b
fP(x(q)
ℓ). And we combine this information to-"
END,0.9224137931034483,"gether to generate synthetic samples bx(q)
ℓ,j with the learned reconstruction network r(q), i.e., bx(q)
ℓ,j ="
END,0.9236453201970444,"br(q)([(bz(q)
ℓ)⊤, (c(q)
j )⊤]⊤)."
END,0.9248768472906403,"The observations are similar to that in the Cars3D experiments. Ideally, the generated samples
should have the rotation and horizontal position of x(q)
ℓ
(contained in bz(q)
ℓ) while the vertical po-
sition of x(q)
j
(contained in bc(q)
j ). One can see that without using the independence regularizer R,"
END,0.9261083743842364,"the generated samples may have rotation change, shape deformation compared to x(q)
ℓ
or simply the
vertical position is not exactly replicated from the sample x(q)
j . However, with the R regularization,
the results are exactly what one expects to see. This again verifies our claim in Theorem 2."
END,0.9273399014778325,"Multiview MNIST Data for Cross-view Generation. Using the multiview MNIST data, we also
show the cross-view generation results in Fig. G.9. Here, we extract bz(2)
ℓ
= b
f (2)
S (x(2)
ℓ) from the
second view and bc(1)
j
= b
f (1)
P (x(1)
j ) from the first. Then, we generate bx(1)
ℓ,j = br(1)([(bz(2)
ℓ)⊤, (c(1)
j )⊤]⊤)
shown in the blue and green boxes. Ideally, the generated samples should have the digit information
of x(2)
ℓ
(contained in bz(2)
ℓ) while the style information of x(1)
j
(contained in bc(1)
j ). Clearly, using R
attains the desired results. Note that this dataset is challenging as the noise in view 2 is very high,
making it hard to achieve perfect matching and reconstruction—but our result is still plausible."
END,0.9285714285714286,"Remark 2 We would like to mention that multiview data and pertinent learning tasks are perva-
sive in the real world. For example, acoustic features and articulatory recordings are two views of
speech signals, and multiview based representation learning can be used to enhance speech recog-
nition (Arora & Livescu, 2013; Wang et al., 2015). Another example is cross-media information
retrieval (Gong et al., 2014). There, a data entity has a text view and an image view, and the task
is to retrieve one view from another. This task can be efficiently done in the learned shared do-
main. In natural language processing, multilingual word embedding can also be formulated as a
CCA-type shared information learning problem; see (Socher & Fei-Fei, 2010; Dhillon et al., 2012).
In computer vision, there are a number of important tasks such as image style translation (e.g.,
sketch to picture and picture to cartoon) (Zhu et al., 2017; Huang et al., 2018; Lee et al., 2018) and
super-resolution (Ledig et al., 2017) can be considered as multiview learning problems. In particu-
lar, image style translation will benefit from our method’s guaranteed shared (content) and private
(style) disentanglement."
END,0.9298029556650246,Published as a conference paper at ICLR 2022
END,0.9310344827586207,"Figure G.8: Generated samples by fixing bzℓ(rotation and horizontal position) and varying bc(q)
j
(vertical position). Top: the square view; bottom: the heart view; rows in blue boxes are w/ R; rows
in green boxes are w/o R."
END,0.9322660098522167,"Figure G.9: Cross-view generation from x(2)
ℓ
to x(1)
ℓ."
END,0.9334975369458128,"H
ADDITIONAL NOTES ON SHARED-PRIVATE MODELING"
END,0.9347290640394089,"Regarding the generative model in (5), some remarks are as follows. The intuition that multiview
data consists of shared and private components are widely used; see, e.g., (Huang et al., 2018; Lee
et al., 2018; Wang et al., 2016; Gundersen et al., 2019). However, explicit generative models were
only considered in limited theory-oriented works."
END,0.9359605911330049,Published as a conference paper at ICLR 2022
END,0.937192118226601,"The model in (5) can be understood as a nonlinear generalization of the linear CCA model in
(Ibrahim & Sidiropoulos, 2020), where the views are modeled as"
END,0.9384236453201971,"x(q)
ℓ
= A(q)[z⊤
ℓ, (c(q)
ℓ)⊤]⊤"
END,0.9396551724137931,"for q = 1, 2. In (Lyu & Fu, 2020), a special type of nonlinear model, namely, the post-nonlinear
mixture model, was analyzed. There, the model is"
END,0.9408866995073891,"x(q)
ℓ
= g(q)(A(q)[z⊤
ℓ, (c(q)
ℓ)⊤]⊤),"
END,0.9421182266009852,"where g(q)(y) applies a nonlinear distortion to each element of y individually. However, post-
nonlinear models are much less general compared to our model in (5)—where g(q)(y) nonlinearly
distorts all elements of y jointly in an unknown way. More recently, under the context of AM-SSL,
the work in (Von K¨ugelgen et al., 2021) considered a multiview generative model that is similar to
our model, but the views share the same generative nonlinear function, i.e.,"
END,0.9433497536945813,"x(q)
ℓ
= g([z⊤
ℓ, (c(q)
ℓ)⊤]⊤)."
END,0.9445812807881774,"This assumption restricts the applicability of the model to scenarios where the two views are gen-
erated using exactly the same nonlinear distortions, which may be less flexible. Our model in (5)
subsumes the models in (Ibrahim & Sidiropoulos, 2020; Lyu & Fu, 2020; Von K¨ugelgen et al., 2021)
as its special cases."
END,0.9458128078817734,"I
AVOIDING RECONSTRUCTION USING ENTROPY REGULARIZATION"
END,0.9470443349753694,"I.1
ENTROPY REGULARIZATION AND SHARED COMPONENT IDENTIFIABILITY"
END,0.9482758620689655,"If we ignore private information extraction, our formulation for shared information extraction is as
follows:"
END,0.9495073891625616,"minimize
f (1),f (2) E
f (1)
S

x(1)
−f (2)
S

x(2)
2
(I.1a)"
END,0.9507389162561576,"subject to f (q) for q = 1, 2 are invertible,
(I.1b)"
END,0.9519704433497537,"E

f (q)
S

x(q)
f (q)
S

x(q)⊤
= I, E
h
fS

x(q)i
= 0, q = 1, 2,
(I.1c)"
END,0.9532019704433498,with the latent variables satisfying:
END,0.9544334975369458,"p(z, c(1), c(2)) = p(z)p(c(1))p(c(2))."
END,0.9556650246305419,"We hope to encourage invertibility of f (q) without using a decoder reconstruction network. To this
end, we generalize the idea in Theorem 4.4 in (Von K¨ugelgen et al., 2021). Note that (Von K¨ugelgen
et al., 2021) deals with the case where only one f is learned (i.e., f (1) = f (2)). Here, we show that
this idea can be used under our case as well. To see this, let us consider the following formulation:"
END,0.9568965517241379,"minimize
f (1)
S
,f (2)
S
E
f (1)
S

x(1)
−f (2)
S

x(2)
2
−H

f (1)
S

x(1)
(I.2a)"
END,0.958128078817734,"subject to f (q)
S
: RMq →(0, 1)D.
(I.2b)"
END,0.9593596059113301,"where H(·) computes the differential entropy of its argument. The formulation still aims to match
the latent representations of the two views, but at the same time maximizes the entropy of the learned
features of a the first view. The proof of this case consists of three major steps."
END,0.9605911330049262,Step 1. It is straightforward to see that the optimal solution of (I.2) is
END,0.9618226600985221,"bz = f (1)
S (x(1)) = f (2)
S (x(2)), bz ∼Uniform(0, 1)D"
END,0.9630541871921182,"since the first term has optimal value 0 when two view are perfectly matched, and the differential en-
tropy of a random variable is maximized when the distribution on (0, 1)D is uniform (Cover, 1999).
Next, following the idea in (Von K¨ugelgen et al., 2021), by the Darmois construction (Darmois,"
END,0.9642857142857143,Published as a conference paper at ICLR 2022
END,0.9655172413793104,"1951), there exists d(·) : Z →(0, 1)D which maps the ground-truth z to a uniform random variable
on (0, 1)D. Thus, one can construct an optimal solution of (I.2) as:"
END,0.9667487684729064,"f (q)
S
= d ◦

g(q)−1 1:D"
END,0.9679802955665024,"where the first D dimensions of the output of
 
g(q)−1 are fed to d(·)."
END,0.9692118226600985,"Step 2. By using our proof technique in Theorem 1, employing the equation bz = f (1)
S (x(1)) =
f (2)
S (x(2)), it can be shown that bz only depends on the shared component z but does not depend
on either c(1) or c(2), which we denote as bz = γ(z). Note that the proof of this part holds since
it only uses the latent correlation maximization (or f (q)
S
matching). Using the same derivation as in
Theorem 1, we have the Jacobian of h(1) as follows:"
END,0.9704433497536946,J(1) =
END,0.9716748768472906,"""
J(1)
11
H(1)
S
J(1)
21
J(1)
22 # ="
END,0.9729064039408867,"""
J(1)
11
0D×D1
J(1)
21
J(1)
22 # ,"
END,0.9741379310344828,"which indicates that bz only depends on z but not c(1). The above also holds for the second view.
Note that the possibility of f (q)
S
being a trivial constant solution (and thus making H(1)
S
= 0) is
ruled out since f (q)
S ’s entropy is maximized."
END,0.9753694581280788,"Step 3. The last step in Theorem 1 is to use rank(J(1)) = D + D1 to show that J(1)
11 ∈RD×D"
END,0.9766009852216748,"has full rank. There, rank(J(1)) = D + D1 is natural since f (1) is constructed to be invertible
using an autoencoder (and thus f (1) ◦g(1) is also invertible). Here, we could not use this argument.
However, similar to Theorem 4.4 in (Von K¨ugelgen et al., 2021), by applying Proposition 5 of
(Zimmermann et al., 2021), one can show that bz = γ(z) where γ(·) is an invertible function, if
p(z) is a regular density, i.e., 0 < p(z) < ∞everywhere. Note that under our generative model,
f (1)(x(1)) = f (2)(x(2)) for all x(q). Hence, the above derivations can be repeated for f (2). This
concludes the proof."
END,0.9778325123152709,"I.2
REALIZATION AND CONNECTION TO CONTRASTIVE SSL"
END,0.979064039408867,"To implement the formulation (I.2), following the idea in (Von K¨ugelgen et al., 2021), one can use
the idea of InfoNCE (Gutmann & Hyv¨arinen, 2010; Oord et al., 2018), which it has interesting
connections to contrastive SSL (Wang & Isola, 2020). In particular, the formulation of InfoNCE is
as follows:"
END,0.9802955665024631,"E{x(1)
ℓ
,x(2)
ℓ
}K
ℓ=1∼p(x(1),x(2)) "" − K
X"
END,0.9815270935960592,"i=1
log
exp{sim(bzi, bz′
i)/τ}
PK
j=1 exp{sim(bzi, bz′
j)/τ} # (I.3)"
END,0.9827586206896551,"where bzℓand bz′
ℓare the learned representations of the two corresponding samples x(1)
ℓ
and x(2)
ℓ,
respectively, sim(a, b) computes the similarity of its arguments, τ is a temperature hyperparameter
and there are K samples of each batch where K −1 of them are negative."
END,0.9839901477832512,"Note that in (Von K¨ugelgen et al., 2021), only one generative function g(·) is considered. In their
implementation, given sample pairs {x(1)
ℓ, x(2)
ℓ}K
ℓ=1, the above InfoNCE objective can be rewritten
with τ = 1 and sim(a, b) = −∥a −b∥2
2 as"
END,0.9852216748768473,"E{x(1)
ℓ
,x(2)
ℓ
}K
ℓ=1∼p(x(1),x(2))  
K
X i=1 
 "
END,0.9864532019704434,"f(x(1)
i ) −f(x(2)
i )

2"
END,0.9876847290640394,"2 + log K
X"
END,0.9889162561576355,"j=1
exp

−
f(x(1)
i ) −f(x(2)
j )

2 2 
   . (I.4)"
END,0.9901477832512315,"The second term is a non-parametric entropy estimator of the representation as K →∞(Wang &
Isola, 2020). The above nicely connects AM-SSL with contrastive learning when g(1) = g(2) and
only one encoder is used, i.e., f (1) = f (2)."
END,0.9913793103448276,Published as a conference paper at ICLR 2022
END,0.9926108374384236,"However, in our problem the generative functions are different in each view. Hence, the formulation
above is not directly applicable. Nonetheless, one can use the slack variable based design as in (10).
Then, the problem can be reformulated as"
END,0.9938423645320197,"E{x(1)
ℓ
,x(2)
ℓ
}K
ℓ=1∼p(x(1),x(2))  
K
X i=1 
 "
X,0.9950738916256158,"2
X q=1"
X,0.9963054187192119,"ui −f (q)(x(q)
i )

2
+ log K
X"
X,0.9975369458128078,"j=1
exp{−∥ui −uj∥2
2} 
   . (I.5)"
X,0.9987684729064039,"Note that the entropy regularization is imposed on the slack variable u—which indirectly promotes
high entropy of f (q)’s. This way, one can handle Q views with different generative functions g(q)’s."
