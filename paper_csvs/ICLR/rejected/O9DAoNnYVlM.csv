Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0015772870662460567,"Federated learning allows collaborative workers to solve a machine learning prob-
lem while preserving data privacy.
Recent studies have tackled various chal-
lenges in federated learning, but the joint optimization of communication over-
head, learning reliability, and deployment efﬁciency is still an open problem.
To this end, we propose a new scheme named federated learning via plurality
vote (FedVote). In each communication round of FedVote, workers transmit bi-
nary or ternary weights to the server with low communication overhead. The
model parameters are aggregated via weighted voting to enhance the resilience
against Byzantine attacks. When deployed for inference, the model with binary
or ternary weights is resource-friendly to edge devices. We show that our pro-
posed method can reduce quantization error and converges faster compared to the
methods directly quantizing the model updates."
INTRODUCTION,0.0031545741324921135,"1
INTRODUCTION"
INTRODUCTION,0.00473186119873817,"Federated learning enables multiple workers to solve a machine learning problem under the coor-
dination of a central server (Kairouz et al., 2021). Throughout the training stage, client data will
be kept locally and only model weights or model updates will be shared with the server. Fed-
erated averaging (FedAvg) (McMahan et al., 2017) was proposed as a generic federated learning
solution. Although FedAvg takes advantage of distributed client data while maintaining their pri-
vacy, it leaves the following two challenges unsolved. First, transmitting high-dimensional messages
between a client and the server for multiple rounds can incur signiﬁcant communication overhead.
Quantization has been incorporated into federated learning in recent studies (Reisizadeh et al., 2020;
Haddadpour et al., 2021). However, directly quantizing the gradient vector may not provide the op-
timal trade-off between communication efﬁciency and model accuracy 1. Second, the aggregation
rule in FedAvg is vulnerable to Byzantine attacks (Blanchard et al., 2017). Prior works tackled this
issue by using robust statistics such as coordinate-wise median and geometric median in the aggre-
gation step (Blanchard et al., 2017; Yin et al., 2018). Another strategy is to detect and reject updates
from malicious attackers (Mu˜noz-Gonz´alez et al., 2019; Sattler et al., 2020). The robustness of the
algorithm is enhanced at the cost of additional computation and increased complexity of algorithms."
INTRODUCTION,0.006309148264984227,"In this paper, we propose a new method called federated learning via plurality vote (FedVote). We
train a neural network at each worker with a range normalization function applied to model param-
eters. After local updating, binary/ternary weight vectors are obtained via stochastic rounding and
sent to the server. The global model is updated by a voting procedure, and the voting results are sent
back to each worker for further optimization in the next round. The contributions of the paper are
summarized as follows."
WE PRESENT FEDVOTE AS A NOVEL FEDERATED LEARNING SOLUTION TO JOINTLY OPTIMIZE THE COMMU-,0.007886435331230283,"1. We present FedVote as a novel federated learning solution to jointly optimize the commu-
nication overhead, learning reliability, and deployment efﬁciency."
WE PRESENT FEDVOTE AS A NOVEL FEDERATED LEARNING SOLUTION TO JOINTLY OPTIMIZE THE COMMU-,0.00946372239747634,"2. We theoretically and experimentally verify the effectiveness of our FedVote design.
In bandwidth-limited scenarios, FedVote is particularly advantageous in simultaneously
achieving a high compression ratio and good test accuracy. Given a ﬁxed communica-
tion cost, FedVote improves model accuracy on the CIFAR-10 dataset by 5–10%, 15–20%,"
WE PRESENT FEDVOTE AS A NOVEL FEDERATED LEARNING SOLUTION TO JOINTLY OPTIMIZE THE COMMU-,0.011041009463722398,"1Predictive coding in video and image compression (Li et al., 2015; Gonzalez & Woods, 2014) is an example
that directly quantizing the raw signal we intend to transmit does not provide the best trade-off between the
coding efﬁciency and the utility/bitrate."
WE PRESENT FEDVOTE AS A NOVEL FEDERATED LEARNING SOLUTION TO JOINTLY OPTIMIZE THE COMMU-,0.012618296529968454,Under review as a conference paper at ICLR 2022
WE PRESENT FEDVOTE AS A NOVEL FEDERATED LEARNING SOLUTION TO JOINTLY OPTIMIZE THE COMMU-,0.014195583596214511,"and 25–30% compared with FedPAQ (Reisizadeh et al., 2020), signSGD (Bernstein et al.,
2018), and FedAvg, respectively."
WE PRESENT FEDVOTE AS A NOVEL FEDERATED LEARNING SOLUTION TO JOINTLY OPTIMIZE THE COMMU-,0.015772870662460567,"3. We extend FedVote to incorporate reputation-based voting.
The proposed method,
Byzantine-FedVote, exhibits much better resilience to Byzantine attacks in the presence
of close to half attackers without incurring excessive computation compared with existing
algorithms."
RELATED WORK,0.017350157728706624,"2
RELATED WORK"
RELATED WORK,0.01892744479495268,"Communication-Efﬁcient Federated Learning.
In the prior study of federated learning, various
strategies have been proposed to reduce communication cost. One research direction is to reduce the
size of messages in each round. For example, Bernstein et al. (2018) showed that sign-based gradient
descent schemes can converge well in the homogeneous data distribution scenario, while Chen et al.
(2020); Jin et al. (2020); Safaryan & Richtarik (2021) extended it to the heterogeneous data distri-
bution setting. In parallel, FedAvg adopts a periodic averaging scheme and targets at reducing the
number of communication rounds (McMahan et al., 2017). Hybrid methods consider simultaneous
local updates and accumulative gradient compression (Reisizadeh et al., 2020; Haddadpour et al.,
2021). In this work, we improve communication efﬁciency by employing binary/ternary weights in
the neural network."
RELATED WORK,0.02050473186119874,"Quantized Neural Networks.
Quantized neural networks aim to approximate the full-precision
networks using quantized weights while keeping their generalizability. As a special case, binary
neural networks (BNNs) are gaining popularity in recent years. By restricting model weight values
to {−1, +1}, BNNs can reduce computational cost, memory requirement, and energy consumption.
Hubara et al. (2016) introduced real-valued latent weights and used the sign operator for binarization.
In contrast, Shayer et al. (2018) let the neural network learn the distribution of the binary or ternary
weights. Gong et al. (2019) added a soft quantization function to the real-valued weights, thus
avoiding the gradient mismatch between the forward and the backward passes. A more thorough
survey on BNN optimization can be found in Qin et al. (2020a)."
RELATED WORK,0.022082018927444796,"Distributed Optimization of Quantized Neural Networks.
A few recent works have explored
BNN optimization in a distributed setting, which is more relevant to our work. Lin et al. (2020)
conducted the case study of 1-bit quantized local models aggregated via ensemble distillation. The
aggregation becomes complicated due to the separate optimization stage of knowledge distillation,
especially when the distillation algorithm does not converge well in practice. In addition, their
BNN optimization is not tailored to the federated learning setting. Hou et al. (2019) theoretically
analyzed the convergence of distributed quantized neural networks, which was later implemented in
the application of intrusion detection (Qin et al., 2020b). In comparison, FedVote is presented as
a new algorithm by leveraging client local updates to accelerate the training. Different from Hou
et al. (2019), we do not assume a convex and twice differentiable objective function and bounded
gradients. Therefore, the analyses in Hou et al. (2019) cannot be directly applied to our study."
RELATED WORK,0.02365930599369085,"Byzantine Resilience in Federated Learning.
An attack is Byzantine if arbitrary outputs are
produced due to the adversary (Kairouz et al., 2021). Blanchard et al. (2017) showed that FedAvg
cannot tolerate a single Byzantine attacker. They proposed an aggregation-rule-based remedy using
the similarity of local updates. Similarly, Yin et al. (2018) took the advantage of coordinatewise
median and trimmed-mean to robustify the aggregation. Mu˜noz-Gonz´alez et al. (2019) and Sattler
et al. (2020) detected the adversaries and ﬁltered out their model updates. In this paper, we propose
a reputation-based voting strategy for FedVote that is shown to have good convergence performance
in the Byzantine setting."
PRELIMINARIES,0.025236593059936908,"3
PRELIMINARIES"
PRELIMINARIES,0.026813880126182965,"Symbol conventions are as follows. Bold lower cases of letters such as vm denote column vectors,
and vm,i is used to denote its ith entry. For a scalar function, it applies elementwise operation when
a vector input is given. 1 = [1, . . . , 1]⊤denotes a vector with all entries equal to 1."
PRELIMINARIES,0.028391167192429023,Under review as a conference paper at ICLR 2022
FEDERATED LEARNING,0.02996845425867508,"3.1
FEDERATED LEARNING"
FEDERATED LEARNING,0.031545741324921134,"The goal of federated learning is to build a machine learning model based on the training data
distributed among multiple workers. To facilitate the learning procedure, a server will coordinate
the training without seeing the raw data (Kairouz et al., 2021). In a supervised learning scenario, let
Dm = {(xm,j, ym,j)}nm
j=1 denote the training dataset on the mth worker, with the input xm,j ∈Rd1"
FEDERATED LEARNING,0.033123028391167195,"and the label ym,j ∈Rd2 in each training pair. The local objective function fm with a model weight
vector θ ∈Rd is given by"
FEDERATED LEARNING,0.03470031545741325,"fm(θ) ≜fm(θ; Dm) =
1
nm nm
X"
FEDERATED LEARNING,0.03627760252365931,"j=1
ℓ(θ; (xm,j, ym,j)),
(1)"
FEDERATED LEARNING,0.03785488958990536,"where ℓis a loss function quantifying the error of model θ predicting the label ym,j for an input
xm,j. A global objective function may be formulated as"
FEDERATED LEARNING,0.03943217665615142,"min
θ∈Rd f(θ) = 1 M M
X"
FEDERATED LEARNING,0.04100946372239748,"m=1
fm(θ).
(2)"
QUANTIZED NEURAL NETWORKS,0.04258675078864353,"3.2
QUANTIZED NEURAL NETWORKS"
QUANTIZED NEURAL NETWORKS,0.04416403785488959,"Consider a neural network g with the weight vector θ ∈Rd. A forward pass for an input x ∈Rd1
and a prediction ˆy ∈Rd2 can be written as ˆy = g(θ, x). In quantized neural networks, the real-
valued θ is replaced by w ∈Dd
n, where Dn is a discrete set with a number n of quantization levels.
For example, we may have D2 = {−1, 1} for a binary neural network. For a given training set
{(xj, yj)}N
j=1 and the loss function ℓ, the goal is to ﬁnd an optimal w∗such that the averaged loss
is minimized over a search space of quantized weight vectors:"
QUANTIZED NEURAL NETWORKS,0.04574132492113565,"w⋆= argmin
w∈Ddn"
N,0.0473186119873817,"1
N N
X"
N,0.04889589905362776,"j=1
ℓ(w; (xj, yj)).
(3)"
N,0.050473186119873815,"Prior studies tried to solve (3) by optimizing a real-valued latent weight vector h ∈Rd (Hubara
et al., 2016; Shayer et al., 2018; Gong et al., 2019). The interpretations of the latent weight vary
when viewed from different perspectives. Hubara et al. (2016) used the sign operation to quantize
the latent weight into two levels during the forward pass. The binary weights can be viewed as an ap-
proximation of their latent real-valued counterparts. Shayer et al. (2018) trained a stochastic binary
neural network, and the normalized latent parameters are interpreted as the Bernoulli distribution
parameter ϑi:
ϑi ≜bP(wi = 1) = S(hi),
wi ∈{0, 1},
(4)
where S : R →(0, 1) is the sigmoid function. In the forward pass, instead of using the binary vector
w, its expected value,"
N,0.052050473186119876,"ewsto-bnn ≜E[w] = −1×[1−S(h)] + 1×S(h) = 2 S(h) −1,
(5)
will participate in the actual convolution or matrix multiplication operations. In other words, the
neural network function becomes ˆy = g(ewsto-bnn, x). Likewise, Gong et al. (2019) normalized
the latent weight but interpreted it from a different viewpoint. They approximated the staircase
quantization function with a differentiable soft quantization (DSQ) function, i.e.,"
N,0.05362776025236593,"ewdsq ≜tanh(ah),
(6)
where tanh : R →(−1, 1) is the hyperbolic tangent function, and a controls the shape of the
function. The neural network function thus becomes ˆy = g(ewdsq, x)."
N,0.055205047318611984,"We now summarize the latent-weight-based BNN training methods and depict an example of a
single-layer network in Figure 1. First, a real-valued vector h ∈Rd is introduced and its range is
restricted using a differentiable and invertible normalization function ϕ : R →(−1, 1). The forward
pass is then calculated with the normalized weight vector ew. The procedure is described as:"
N,0.056782334384858045,"ˆy = g(ew, x),
ew ≜ϕ(h).
(7)
Second, in the back propagation, the latent weight vector h is updated with its gradient, i.e.,
h(t+1) = h(t) −η∇hℓ. Finally, the normalized weight vector ew are mapped to the discrete space
to approximate w∗via thresholding or stochastic rounding."
N,0.0583596214511041,Under review as a conference paper at ICLR 2022
N,0.05993690851735016,"input
x
σ(·)
nonlinear activation"
N,0.061514195583596214,"ew⊤x
ˆy"
N,0.06309148264984227,"normalization
ϕ(·)"
N,0.06466876971608833,"normalized weight
ew"
N,0.06624605678233439,"latent weight
h ϕ o hi ewi"
N,0.06782334384858044,"Figure 1: Example of a single-layer quantized
neural network with a latent weight vector h ∈
Rd. h is normalized to generate ew ∈(−1, 1)d,
and the output is ˆy = σ(ew⊤x).
A binary
weight wq can be obtained by thresholding or
rounding ew to the discrete space Dd
2."
N,0.0694006309148265,"y
sends quantized
weight w(k,τ)
m
x
local updates
that yields ew(k,τ)
m
Dm"
N,0.07097791798107256,"mth
worker"
N,0.07255520504731862,"{
receives the
soft vote results"
N,0.07413249211356467,"z
server calculates the
voting statistics −1 +1"
N,0.07570977917981073,"Figure 2: One round of FedVote is composed of
four steps.
Each worker ﬁrst updates the local
model and then sends the quantized weight w(k,τ)
m
to the server. Later, the server calculates the vot-
ing statistics and sends back the soft voting results
p(k+1) to each worker."
PROPOSED FEDVOTE ALGORITHM,0.07728706624605679,"4
PROPOSED FEDVOTE ALGORITHM"
PROPOSED FEDVOTE ALGORITHM,0.07886435331230283,"In this section, we present our proposed method with an emphasis on uplink communication efﬁ-
ciency and enhanced Byzantine resilience. We follow the widely adopted analysis framework in
wireless communication to investigate only the worker uplink overhead, assuming that the downlink
bandwidth is much larger and the server will have enough transmission power (Tran et al., 2019). To
reduce the message size per round, we train a quantized neural network under the federated learning
framework. The goal is to ﬁnd a quantized weight vector w∗that minimizes the global objective
function f formulated in (2), i.e.,
w∗= argmin
w∈Ddn
f(w).
(8)"
PROPOSED FEDVOTE ALGORITHM,0.0804416403785489,"For the simplicity of presentation, we mainly focus on the BNN case with D2 = {−1, 1}. We
illustrate the procedure in Figure 2 and provide the pseudo code in Appendix B. Below, we explain
each step in more detail."
LOCAL MODEL TRAINING AND TRANSMISSION,0.08201892744479496,"4.1
LOCAL MODEL TRAINING AND TRANSMISSION"
LOCAL MODEL TRAINING AND TRANSMISSION,0.083596214511041,"We optimize a neural network with a learnable latent weight vector h. In the kth communication
round, we assume all workers are identically initialized by the server, namely, ∀m ∈{1, . . . , M},
h(k,0)
m
= h(k). To reduce the total number of communication rounds, we ﬁrst let each worker
conduct local updates to learn the binary weights. For each local iteration step, the local latent
weight vector h(k,t+1) is updated by the gradient descent:"
LOCAL MODEL TRAINING AND TRANSMISSION,0.08517350157728706,"h(k,t+1)
m
= h(k,t)
m
−η ∇hfm

ϕ(h(k,t)
m
); ξ(k,t)
m

,
t ∈{0, . . . , τ −1},
(9)"
LOCAL MODEL TRAINING AND TRANSMISSION,0.08675078864353312,"where ξ(k,t)
m
is a mini-batch randomly drawn from Dm at the tth iteration of round k. After updating
for τ steps, we obtain h(k,τ)
m
and the corresponding normalized weight vector ew(k,τ)
m
∈(−1, 1)d
deﬁned as follows:
ew(k,τ)
m
≜ϕ(h(k,τ)
m
).
(10)
To reduce the message size, we use the stochastic rounding to draw a randomly quantized version
w(k,τ)
m
using ew(k,τ)
m
, namely,"
LOCAL MODEL TRAINING AND TRANSMISSION,0.08832807570977919,"w(k,τ)
m,i
="
LOCAL MODEL TRAINING AND TRANSMISSION,0.08990536277602523,"(
+1, with probability π(k,τ)
m,i
= 1"
H,0.0914826498422713,"2
h
ew(k,τ)
m,i
+ 1
i
,"
H,0.09305993690851735,"−1, with probability 1 −π(k,τ)
m,i .
(11)"
H,0.0946372239747634,"It can be shown that the stochastic rounding is an unbiased procedure, i.e., E[w(k,τ)
m
ew(k,τ)
m
] =
ew(k,τ)
m
. After quantization, the local worker will send the binary weights w(k,τ)
m
to the server for the
global model aggregation."
H,0.09621451104100946,Under review as a conference paper at ICLR 2022
GLOBAL MODEL AGGREGATION AND BROADCAST,0.09779179810725552,"4.2
GLOBAL MODEL AGGREGATION AND BROADCAST"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.09936908517350158,"Once the server gathers the binary weights from all workers, it will perform the aggregation via
plurality vote, i.e., w(k+1) = sign
PM
m=1 w(k,τ)
m

. A tie in vote will be broken randomly. In
the following lemma, we show that the probability of error reduces exponentially as the number of
workers increases. The proof can be found in Appendix D.1.
Lemma 1 (One-Shot FedVote) Let w∗∈Dd
2 be the optimal solution deﬁned in (8). For the mth
worker, εm,i ≜P(w(k,τ)
m,i
̸= w∗
i ) denotes the error probability of the voting result of the ith coordi-"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.10094637223974763,"nate. Suppose the error events {w(k,τ)
m,i
̸= w∗
i }M
m=1 are mutually independent, and the mean error
probability si =
1
M
PM
m=1 εm,i is smaller than 1"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.10252365930599369,"2. For the voted weight w(k+1), we have"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.10410094637223975,"P

w(k+1)
i
̸= w∗
i

⩽

2si exp(1 −2si)
 M"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.1056782334384858,"2 .
(12)"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.10725552050473186,"In practice, the number of available workers may be limited in each round, and the local data distri-
bution is often heterogenous or even time-variant. Therefore, it is almost always desirable to execute
FedVote in a multiple-round fashion. In this case, we ﬁrst use the soft voting to build an empirical
distribution of global weight w, i.e.,"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.10883280757097792,"bP(w(k+1)
i
= 1) = 1 M M
X"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.11041009463722397,"m=1
1

w(k,τ)
m,i
= 1

,
(13)"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.11198738170347003,"where 1 (·) ∈{0, 1} is the indicator function. Let p(k+1)
i
≜bP(w(k+1)
i
= 1) and p(k+1) =
[p(k+1)
1
, . . . , p(k+1)
d
]⊤. The global latent parameters can be constructed by following (10):"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.11356466876971609,"h(k+1) = ϕ−1(2 p(k+1) −1),
(14)"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.11514195583596215,"where ϕ−1 : (−1, 1) →R is the inverse of the normalization function ϕ. We further apply clip-
ping to restrict the range of the probability, namely, clip(p(k+1)
i
) = max(pmin, min(pmax, p(k+1)
i
)),
where pmin, pmax ∈(0, 1) are predeﬁned thresholds. To keep the notation consistent, we denote
ew(k+1) ≜ϕ(h(k+1)) as the global normalized weight. After broadcasting the soft voting results
p(k+1), all workers are synchronized with the same latent weight h(k+1) and normalized weight
ew(k+1). The learning procedure will repeat until a termination condition is satisﬁed. We relate
FedVote to FedAvg in the following lemma. The detailed proof can be found in Appendix D.2.
Lemma 2 (Relationship with FedAvg) For the normalized weights, FedVote recovers FedAvg in"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.1167192429022082,"expectation: E
ew(k+1)
=
1
M M
P"
GLOBAL MODEL AGGREGATION AND BROADCAST,0.11829652996845426,"m=1
ew(k,τ)
m
, where ew(k+1) = ϕ(h(k+1)) and ew(k,τ)
m
= ϕ(h(k,τ)
m
)."
REPUTATION-BASED BYZANTINE-FEDVOTE,0.11987381703470032,"4.3
REPUTATION-BASED BYZANTINE-FEDVOTE"
REPUTATION-BASED BYZANTINE-FEDVOTE,0.12145110410094637,"Lemma 2 shows that FedVote is related to FedAvg in expectation. As we have reviewed in Section
2, FedAvg cannot tolerate a single Byzantine attacker. It indicates that FedVote will exhibit similar
poor performance in the presence of multiple adversaries (see Appendix C.2). We improve the
design of FedVote based on a reputation voting mechanism, which in essence is a variant of the
weighted soft voting method."
REPUTATION-BASED BYZANTINE-FEDVOTE,0.12302839116719243,"Reputation-based voting was presented in failure-robust large scale grids (Bendahmane et al., 2014).
In our design, we modify (13) to bP(w(k+1)
i
= 1) = PM
m=1 λ(k)
m 1

w(k,τ)
m,i
= 1

, where λ(k)
m is
proportional to a credibility score. In Byzantine-resilient FedVote (Byzantine-FedVote), we assume
that at least 50% of the workers behave normally and treat the plurality vote result as the correct
decision. The credibility score of the mth worker is calculated by counting the number of correct
votes it makes: CR(k+1)
m
=
1
d
Pd
i=1 1

w(k,τ)
m,i
= w(k+1)
i

. Through multiple rounds, we track
the credibility of a local worker by taking an exponential moving average over the communication
rounds, namely, ν(k+1)
m
= β ν(k)
m + (1 −β) CR(k+1)
m
, where β ∈(0, 1) is a predeﬁned coefﬁcient.
The weight λ(k)
m is designed as λ(k)
m = ν(k)
m / PM
m=1 ν(k)
m ."
REPUTATION-BASED BYZANTINE-FEDVOTE,0.12460567823343849,Under review as a conference paper at ICLR 2022
REPUTATION-BASED BYZANTINE-FEDVOTE,0.12618296529968454,"Even though the presentation in this section focuses on the binary weights, the scheme can be nat-
urally extended to quantized neural networks of more discrete levels. We will brieﬂy discuss the
implementation for ternary weights in Section 6."
ANALYSIS OF ALGORITHM,0.1277602523659306,"5
ANALYSIS OF ALGORITHM"
ANALYSIS OF ALGORITHM,0.12933753943217666,"In this section, we present the theoretical analysis of FedVote when local data are independent
and identically distributed (i.i.d.). The empirical results in the non-i.i.d. setting will be discussed
in Section 6, and the corresponding analyses are left for future work. We use the gradient norm
expectation as an indicator of convergence, which is commonly adopted in nonconvex optimization
literature (Reisizadeh et al., 2020; Haddadpour et al., 2021). To simplify the notation, we ﬁrst
denote the stochastic local gradient by ˜g(k,t)
m
≜∇hfm(ϕ(h(k,t)
m
); ξ(k,t)
m
). The local true gradient and
global true gradient will be denoted by g(k,t)
m
≜Eξ
˜g(k,t)
m

, g(k) ≜∇hf(ϕ(h(k))), respectively. In
addition, let ζ(k)
m ≜ew(k,τ)
m
−w(k,τ)
m
denote the error introduced by stochastic rounding. According
to the unbiased property of stochastic rounding, we have Eπ[ζ(k)
m ] = 0. With the aforementioned
notations, we state ﬁve assumptions for the convergence analysis."
ASSUMPTIONS,0.1309148264984227,"5.1
ASSUMPTIONS"
ASSUMPTIONS,0.13249211356466878,"Assumption 1 (Lower bound) ∀h ∈Rd, ew ∈(−1, 1)d, the objective function is lower bounded
by a constant f ∗, i.e., f(ew) ⩾f ∗= minh∈Rd f(ϕ(h)).
Assumption 2 (L-smoothness)
∀ew1, ew2 ∈(−1, 1)d, m ∈{1, . . . , M}, there exists some non-
negative L such that ∥∇fm(ew1) −∇fm(ew2)∥2 ⩽L ∥ew1 −ew2∥2."
ASSUMPTIONS,0.13406940063091483,"Assumptions 1 to 2 are common for necessary analyses (Wang & Joshi, 2018). We limit the range
of the normalized weight ew while in a typical setting there is no restriction to the model weight.
Assumption 3 The normalization function ϕ : R →(−1, 1) is strictly increasing. In particular,
we assume its ﬁrst derivative is bounded for all h(k,t)
m,i , i.e.,
d
dhϕ(h(k,t)
m,i ) ∈[c1, c2], where c1, c2 are
positive parameters independent of k, t, m, and i."
ASSUMPTIONS,0.13564668769716087,"Assumption 3 is not difﬁcult to satisfy in practice. For example, let ϕ(h) = tanh(ah), we have
ϕ′(h) = a

1 −tanh2(ah)

, with c2 = a. Note that ϕ quickly saturates with a large h in the local
updating. On the other hand, the empirical Bernoulli parameter pi will be clipped for stability,
which indicates that h(k,t)
m,i
will be upper bounded by certain hB. In this sense, we have c1 =
a

1 −tanh2(ahB)

. The next two assumptions bound the variance of the stochastic gradient and
quantization noise."
ASSUMPTIONS,0.13722397476340695,"Assumption 4 The stochastic gradient has bounded variance, i.e., E
g(k,t)
m
−˜g(k,t)
m
2
2 ⩽σ2
ε, where
σ2
ε is a ﬁxed variance independent of k, t and m."
ASSUMPTIONS,0.138801261829653,"Assumption 5 The quantization error ζ(k)
m has bounded variance, i.e., E
ζ(k)
m
2
2 ⩽σ2
k, where σ2
k
is a ﬁxed variance independent of m."
ASSUMPTIONS,0.14037854889589904,"Note that quantization error is affected by the quantizer type and the corresponding input. For
example, if the normalization function ϕ approximates the sign function very well, the stochastic
quantization error will be close to zero. Formally, the upper bound σ2
ζ can be viewed as a function
of input dimension d, which we formulate in the following lemma. The proof is in Appendix D.3.
Lemma 3 Suppose we have an input a ∈(−1, 1)d for the quantizer Qsr deﬁned in (11), then the"
ASSUMPTIONS,0.14195583596214512,"quantization error satisﬁes E
hQsr(a) −a
2
2
a
i
= d −
a
2
2."
ASSUMPTIONS,0.14353312302839116,"For existing algorithms quantizing the model update δ(k)
m
≜θ(k) −θ(k,τ)
m
, the quantizer has the
property E
hQ(x) −x
2
2
x
i
⩽q
x
2
2. With a ﬁxed quantization step, q increases when the input
dimension d increases (Basu et al., 2020). We state the result for a widely-used quantizer, QSGD
(Alistarh et al., 2017), which has been adopted in FedPAQ, in the following lemma.
Lemma 4 Suppose we have an input x ∈Rd for the QSGD quantizer Q. In the coarse quantization
scenario, the quantization error satisﬁes E
hQ(x) −x
2
2
x
i
= O

d
1
2
 x
2
2."
ASSUMPTIONS,0.14511041009463724,Under review as a conference paper at ICLR 2022
CONVERGENCE ANALYSIS,0.14668769716088328,"5.2
CONVERGENCE ANALYSIS"
CONVERGENCE ANALYSIS,0.14826498422712933,We state the convergence results in the following theorem. The proof can be found in Appendix D.5.
CONVERGENCE ANALYSIS,0.1498422712933754,"Theorem 1 For FedVote under Assumptions 1 to 5, let the learning rate η = O

( c1"
CONVERGENCE ANALYSIS,0.15141955835962145,"c2 )2
1
Lτ
√ K "
CONVERGENCE ANALYSIS,0.1529968454258675,", then
after K rounds of communication, we have"
K,0.15457413249211358,"1
K K−1
X"
K,0.15615141955835962,"k=0
c2
1E
∇f(ew(k))
2
2 ⩽2

f(ew(0)) −f(ew∗)
"
K,0.15772870662460567,"ητK
+ c2
2Lη
 1"
K,0.15930599369085174,"M + c2
1Lη(τ −1) 2"
K,0.1608832807570978,"
σ2
ε"
K,0.16246056782334384,"+
L
ητKM K−1
X"
K,0.1640378548895899,"k=0
σ2
k + 2(c2
2 −c2
1)
τMK K−1
X k=0 M
X"
K,0.16561514195583596,"m=1
R(k)
m .
(15)"
K,0.167192429022082,"where R(k)
m ≜−
τ−1
P t=0 P"
K,0.16876971608832808,"i/∈I(k,t)
m
E
h
(∇f(ew(k)))i(∇f(ew(k,t)
m
))i
i
and I(k,t)
m
≜
n
i | g(k)
i
g(k,t)
m,i ⩾0
o
."
K,0.17034700315457413,"Remark 1 When there is no normalization function and quantization, i.e., ϕ(x) = x with c1 =
c2 = 1, σ2
k = 0, Theorem 1 recovers the result obtained in Wang & Joshi (2018)."
K,0.1719242902208202,"0.10
0.05
0.00
0.05
0.10
0"
K,0.17350157728706625,"0.2
0.4
0.6
0.8
1.0
1.2
1.4 Count 1e5 (a)"
K,0.1750788643533123,"-1.0
-0.5
0.0
0.5
1.0
0.0 0.5 1.0 1.5 2.0 2.5 Count 1e5 (b)"
K,0.17665615141955837,"Figure 3: Histograms of (a) model updates δ(k)
m,i
and (b) binary weight probabilities π(k,τ)
m,i . We
trained a LeNet on MNIST for a single commu-
nication round."
K,0.17823343848580442,"To discuss the impact of quantization error, con-
sider the distribution of different inputs. For the
model update δ(k)
m , we expect the central limit
theorem to render its distribution shape, where
each entry δ(k)
m,i follows the Gaussian distribu-"
K,0.17981072555205047,"tion. For the Bernoulli probability π(k,τ)
m
, we ex-
pect the Beta distribution as the conjugate prior
to render its distribution shape, where each entry
π(k,τ)
m,i
follows the symmetric Beta distribution.
See Figure 3 for the empirical results."
K,0.18138801261829654,"Remark 2 Following the analysis framework in Theorem 1, the order-wise convergence rate is
1
K
PK−1
k=0 E
∇f
 
w(k)2
2 = O(
1
√"
K,0.1829652996845426,"K )+E(d), where E(d) is the error introduced by the quantiza-"
K,0.18454258675078863,"tion. For FedVote with the normalized weight ew(k,τ)
m
as the input, when π(k,τ)
m,i ’s follow the symmetric
Beta distribution, it can be shown that E∥ζ(k)
m ∥2
2 = O (d) based on Lemma 3. For algorithms such
as FedPAQ with the model update δ(k)
m as the input, when δ(k)
m,i’s follow the Gaussian distribution, it"
K,0.1861198738170347,"can be shown that E
Q(δ(k)
m )−δ(k)
m
2
2 = O
 
d3/2
based on Lemma 4. When the weight dimension
d is sufﬁciently large, FedVote converges faster."
K,0.18769716088328076,"Remark 3 The value of the positive scalar error term R(k)
m in (15) depends on the gradient dissim-
ilarity. If the angle between the local gradient ∇fm(ew(k,t)
m
) and the global gradient ∇f(ew(k,t)) is
not large, R(k)
m can be treated as a bounded variable."
K,0.1892744479495268,"Remark 4 The choice of nonlinear function ϕ : Rd →(−1, 1)d will affect the convergence. If ϕ
behaves more like the sign(·) function, e.g., when a increases in tanh(ax), the quantization error
will be reduced. In other words, we expect a smaller σ2
k according to Lemma 3, which leads to a
tighter bound in (15). Meanwhile, a larger c2 will negatively inﬂuence the convergence."
EXPERIMENTAL RESULTS,0.19085173501577288,"6
EXPERIMENTAL RESULTS"
EXPERIMENTAL RESULTS,0.19242902208201892,"Data and Models.
We choose image classiﬁcation datasets Fashion-MNIST (Xiao et al., 2017)
and CIFAR-10 (Krizhevsky, 2009). Both of them have a total of C = 10 classes. We consider two
data partition strategies: (i) i.i.d. setting where the whole dataset is randomly shufﬂed and assigned
to each worker without overlap; (ii) non-i.i.d. setting where we follow Hsu et al. (2019) and use the
Dirichlet distribution to simulate the heterogeneity. In particular, for the mth worker we draw a ran-
dom vector qm ∼Dir(α), where qm = [qm,1, · · · , qm,C]⊤belongs to the standard (C −1)-simplex.
We then assign data samples from different classes to the mth worker following the distribution of"
EXPERIMENTAL RESULTS,0.19400630914826497,Under review as a conference paper at ICLR 2022
EXPERIMENTAL RESULTS,0.19558359621451105,"0
20
40
60
80
100
Communication Round 0.5 0.6 0.7 0.8"
EXPERIMENTAL RESULTS,0.1971608832807571,Test Accuracy
EXPERIMENTAL RESULTS,0.19873817034700317,"FedAvg
FedVote
FedPAQ
signSGD (a)"
EXPERIMENTAL RESULTS,0.20031545741324921,"0
20
40
60
80
100
Communication Round 0.5 0.6 0.7 0.8"
EXPERIMENTAL RESULTS,0.20189274447949526,Test Accuracy
EXPERIMENTAL RESULTS,0.20347003154574134,"FedAvg
FedVote
FedPAQ
signSGD (b)"
EXPERIMENTAL RESULTS,0.20504731861198738,"0
1
2
3
4
Communication Cost (GB) 0.4 0.5 0.6 0.7 0.8"
EXPERIMENTAL RESULTS,0.20662460567823343,Test Accuracy
EXPERIMENTAL RESULTS,0.2082018927444795,"FedVote
FedPAQ
signSGD
FedAvg (c)"
EXPERIMENTAL RESULTS,0.20977917981072555,"Figure 4: Learning curves of different methods on CIFAR-10 with (a) the i.i.d. setting and (b) the
Dirichlet non-i.i.d. setting. Compared with the gradient quantization methods such as signSGD
(Bernstein et al., 2018) and the model update quantization methods such as FedPAQ (Reisizadeh
et al., 2020), FedVote achieves higher accuracy given the same number of communication rounds.
(c) Test accuracy versus accumulative uplink communication cost on the i.i.d. CIFAR dataset. Fed-
Vote achieves the best accuracy given the transmitted data size."
EXPERIMENTAL RESULTS,0.2113564668769716,Table 1: Test Accuracy in the Byzantine Setting
EXPERIMENTAL RESULTS,0.21293375394321767,"Dataset
Distri-
bution
sign-
SGD
Co-
Med
Pro-
posed"
EXPERIMENTAL RESULTS,0.21451104100946372,"Fashion-
MNIST
i.i.d.
61.5%
77.7%
91.4%
non-i.i.d
61.0%
73.4%
89.4%"
EXPERIMENTAL RESULTS,0.21608832807570977,"CIFAR-
10
i.i.d.
13.5%
29.3%
76.6%
non-i.i.d
11.0%
28.7%
72.0%"
EXPERIMENTAL RESULTS,0.21766561514195584,Table 2: Effect of the Normalization Function
EXPERIMENTAL RESULTS,0.2192429022082019,"Fashion-
MNIST
a
0.5
1.5
2.5
10"
EXPERIMENTAL RESULTS,0.22082018927444794,"i.i.d.
ﬂoat
90.7%
90.6%
90.0%
88.2%
binary 88.7%
90.4%
89.9%
88.2%"
EXPERIMENTAL RESULTS,0.222397476340694,"non-
i.i.d.
ﬂoat
87.3%
86.9%
85.7%
85.0%
binary 83.3%
85.5%
85.2%
84.6%"
EXPERIMENTAL RESULTS,0.22397476340694006,"qm. We set α = 0.5 unless noted otherwise. We use a LeNet-5 architecture for Fashion-MNIST
and a VGG-7 architecture for CIFAR-10. Results are obtained over three repetitions."
EXPERIMENTAL RESULTS,0.22555205047318613,"Implementation Details.
We provide implementation details in the proposed FedVote design.
First, following prior works (Shayer et al., 2018; Gong et al., 2019), we keep the weights of the
BNN ﬁnal layer as ﬂoating-point values for the sake of the model performance. The weights of
the ﬁnal layer are randomly initialized with a shared seed and will be ﬁxed during the training
process. Second, we notice that for quantized neural networks, the batch normalization (BN) (Ioffe
& Szegedy, 2015) after the convolutional layer is necessary to scale the activation. We use the
static BN without learnable parameters and local statistics (Diao et al., 2021) to ensure the voting
aggregation of binary weights. For the normalization function, we choose ϕ(x) = tanh(3x/2)
unless noted otherwise. More details of the experimental setup can be found in Appendix C.1."
EXPERIMENTAL RESULTS,0.22712933753943218,"Communication Efﬁciency and Convergence Rate.
In this experiment, we consider M = 31
workers with full participation and compare FedVote to different methods within N = 100 com-
munication rounds. The results of partial participation can be found in Appendix C.3. The com-
munication cost is calculated as the accumulative uplink message size from all workers. Figure 4
reveals that FedVote outperforms the gradient-quantization-based methods such as signSGD (Bern-
stein et al., 2018) that quantizes gradients to 1 bit signs, and FedPAQ (Reisizadeh et al., 2020) that
quantizes the updates to 2 bits integers. Compared with FedPAQ, signSGD, and FedAvg, FedVote
improves the test accuracy by 5–10%, 15–20%, and 25–30%, respectively, given the ﬁxed commu-
nication costs of 1.5–4.7 GB."
EXPERIMENTAL RESULTS,0.22870662460567823,"Byzantine Resilience.
This experiment validates the effectiveness of Byzantine-FedVote. We
consider omniscient attackers who can access the datasets of normal workers and send the opposite
of the aggregated results to the server. The number of attackers is 15, and the remaining 16 clients are
normal workers. We compare the proposed method with coordinate-wise median based (CoMed)
gradient descent (Yin et al., 2018) and signSGD (Bernstein et al., 2018), and report the testing
accuracy after 100 communication rounds. We do not compare with FedAvg and FedPAQ, as they
are fragile to Byzantine failure. The results are shown in Table 1. It can be observed that Byzantine-
FedVote exhibits much better resilience to Byzantine attacks with close to half adversaries."
EXPERIMENTAL RESULTS,0.2302839116719243,Under review as a conference paper at ICLR 2022
EXPERIMENTAL RESULTS,0.23186119873817035,Table 3: Test Accuracy of TNN and BNN
EXPERIMENTAL RESULTS,0.2334384858044164,"Dataset
Distri-
bution
BNN
TNN"
EXPERIMENTAL RESULTS,0.23501577287066247,"Fashion-
MNIST
i.i.d.
91.1%
91.9%
non-i.i.d
88.3%
89.4%"
EXPERIMENTAL RESULTS,0.23659305993690852,"CIFAR-
10
i.i.d.
80.5%
82.5%
non-i.i.d
74.6%
77.6%"
EXPERIMENTAL RESULTS,0.23817034700315456,Table 4: Forward Pass Efﬁciency
EXPERIMENTAL RESULTS,0.23974763406940064,"Neural
Net
Weight
Type
Adds
Muls
Energy
(mJ)"
EXPERIMENTAL RESULTS,0.24132492113564669,"LeNet-5 ﬂoat
1.7×109
1.8×109
8.1
binary
1.7×109
1.0×105
1.5"
EXPERIMENTAL RESULTS,0.24290220820189273,"VGG-7
ﬂoat
4.8×1010 5.4×1010 242.9
binary
4.8×1010 2.1×105
43.3"
EXPERIMENTAL RESULTS,0.2444794952681388,"Normalization Function.
From Remark 4, we know that the normalization function can inﬂuence
the model convergence. We empirically examine the impact in this experiment. For normalization
function ϕ(x) = tanh(ax), we choose a from {0.5, 1.5, 2.5, 10}. We test the model accuracy after
20 communication rounds on Fashion-MNIST. The results are shown in Table 2. As a increases,
the linear region of the normalization function shrinks, and the algorithm converges slower due
to a larger c2. On the other hand, the gap between the model with normalized weight ew and the
one with binary weight w also decreases due to smaller quantization errors. A good choice of the
normalization function should take this trade-off into consideration."
EXPERIMENTAL RESULTS,0.24605678233438485,"Ternary Neural Network Extension.
In the previous sections, we focus on the BNNs. We ex-
tend FedVote to ternary neural networks (TNNs) and empirically verify its performance. Training
and transmitting the categorical distribution parameters of the ternary weight may bring additional
communication and computation cost to edge devices, we therefore simplify the procedure as fol-
lows. For each ternary weight w(k,t)
m,i , we still keep a latent parameter h(k,t)
m,i to optimize. After τ"
EXPERIMENTAL RESULTS,0.2476340694006309,"local steps, we use the stochastic rounding to the normalized weight ew(k,τ)
m
= ϕ(h(k,τ)
m
) and obtain
quantized weight w(k,τ)
m
. At the aggregation stage on the server, instead of calculating the vote dis-
tribution, we directly compute the global normalized weight as ew(k+1) =
1
M
PM
m=1 w(k,τ)
m
. More
details can be found in Appendix C.4. The training results are shown in Table 3. As TNNs can fur-
ther reduce the quantization error, their performance is better than the BNNs at the cost of additional
1 bit/dimension communication overhead."
EXPERIMENTAL RESULTS,0.24921135646687698,"Deployment Efﬁciency.
We highlight the advantages of BNNs during deployment on edge de-
vices. In FedVote, we intend to deploy lightweight quantized neural networks on the workers after
the training procedure. BNNs require 32 × smaller memory size, which can save storage and en-
ergy consumption for memory access (Hubara et al., 2016). As we do not quantize the activations,
the advantage of BNNs inference mainly lies in the replacement of multiplications by summations.
Consider the matrix multiplication in a neural network with an input x ∈Rd1 and output y ∈Rd2:
y = W ⊤x. For a ﬂoating-point weight matrix W ∈Rd1×d2, the number of multiplications is d1d2,
whereas for a binary matrix Wb ∈Dd1×d2
2
all multiplication operations can be replaced by additions.
We investigate the number of real multiplications and additions in the forward pass of different mod-
els and present the results in Table 4. We use the CIFAR-10 dataset and set the batch size to 100. As
to the energy consumption calculation, we use 3.7 pJ and 0.9 pJ as in Hubara et al. (2016) for each
ﬂoating-point multiplication and addition, respectively."
CONCLUSION,0.250788643533123,"7
CONCLUSION"
CONCLUSION,0.25236593059936907,"In this work, we have proposed FedVote to jointly optimize communication overhead, learning re-
liability, and deployment efﬁciency. In FedVote, the server aggregates neural networks with bi-
nary/ternary weights via voting. We have veriﬁed that FedVote can achieve good model accuracy
even in coarse quantization settings. Compared with gradient quantization, model quantization is a
more effective design that achieves better trade-offs between communication efﬁciency and model
accuracy. With the voting-based aggregation mechanism, FedVote enjoys the ﬂexibility to incorpo-
rate various voting protocols to increase the resilience against Byzantine attacks. We have demon-
strated that Byzantine-FedVote exhibits much better Byzantine resilience in the presence of close to
half attackers compared to the existing algorithms."
CONCLUSION,0.2539432176656151,Under review as a conference paper at ICLR 2022
REFERENCES,0.2555205047318612,REFERENCES
REFERENCES,0.25709779179810727,"Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic.
QSGD:
Communication-efﬁcient SGD via gradient quantization and encoding. In Advances in Neural
Information Processing Systems, pp. 1709–1720, 2017."
REFERENCES,0.2586750788643533,"Debraj Basu, Deepesh Data, Can Karakus, and Suhas N Diggavi. Qsparse-local-sgd: Distributed
sgd with quantization, sparsiﬁcation, and local computations. IEEE Journal on Selected Areas in
Information Theory, 1(1):217–226, 2020."
REFERENCES,0.26025236593059936,"Ahmed Bendahmane, Mohamed Essaaidi, Ahmed El Moussaoui, and Ali Younes. The effectiveness
of reputation-based voting for collusion tolerance in large-scale grids. IEEE Transactions on
Dependable and Secure Computing, 12(6):665–674, 2014."
REFERENCES,0.2618296529968454,"Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, and Animashree Anandkumar.
signSGD: Compressed optimisation for non-convex problems. In International Conference on
Machine Learning, 2018."
REFERENCES,0.2634069400630915,"Peva Blanchard, Rachid Guerraoui, Julien Stainer, et al. Machine learning with adversaries: Byzan-
tine tolerant gradient descent. In Advances in Neural Information Processing Systems, 2017."
REFERENCES,0.26498422712933756,"Xiangyi Chen, Tiancong Chen, Haoran Sun, Steven Z. Wu, and Mingyi Hong. Distributed training
with heterogeneous data: Bridging median- and mean-based algorithms. In Neural Information
Processing Systems, 2020."
REFERENCES,0.2665615141955836,"Enmao Diao, Jie Ding, and Vahid Tarokh. Heteroﬂ: Computation and communication efﬁcient
federated learning for heterogeneous clients. In International Conference on Learning Represen-
tations, 2021."
REFERENCES,0.26813880126182965,"Ruihao Gong, Xianglong Liu, Shenghu Jiang, Tianxiang Li, Peng Hu, Jiazhen Lin, Fengwei Yu, and
Junjie Yan. Differentiable soft quantization: Bridging full-precision and low-bit neural networks.
In International Conference on Computer Vision, 2019."
REFERENCES,0.2697160883280757,Rafael C. Gonzalez and Richard E. Woods. Digital Image Processing 3rd Edition. 2014.
REFERENCES,0.27129337539432175,"Farzin Haddadpour, Mohammad Mahdi Kamani, Aryan Mokhtari, and Mehrdad Mahdavi. Feder-
ated learning with compression: Uniﬁed analysis and sharp guarantees. In International Confer-
ence on Artiﬁcial Intelligence and Statistics, 2021."
REFERENCES,0.27287066246056785,"Lu Hou, Ruiliang Zhang, and James T Kwok. Analysis of quantized models. In International
Conference on Learning Representations, 2019."
REFERENCES,0.2744479495268139,"Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the effects of non-identical data
distribution for federated visual classiﬁcation. arXiv preprint arXiv:1909.06335, 2019."
REFERENCES,0.27602523659305994,"Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. Binarized
neural networks. In Advances in Neural Information Processing Systems, 2016."
REFERENCES,0.277602523659306,"Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015."
REFERENCES,0.27917981072555204,"Richeng Jin, Yufan Huang, Xiaofan He, Huaiyu Dai, and Tianfu Wu. Stochastic-sign sgd for feder-
ated learning with theoretical guarantees. arXiv preprint arXiv:2002.10940, 2020."
REFERENCES,0.2807570977917981,"Peter Kairouz, H Brendan McMahan, Brendan Avent, Aur´elien Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances
and open problems in federated learning. Foundations and Trends in Machine Learning, 14(1),
2021."
REFERENCES,0.2823343848580442,"Alex Krizhevsky. Learning multiple layers of features from tiny images. Master thesis, Dept. of
Comput. Sci., Univ. of Toronto, Toronto, Canada, 2009."
REFERENCES,0.28391167192429023,"Shuai Li, Ce Zhu, Yanbo Gao, Yimin Zhou, Fr´ed´eric Dufaux, and Ming-Ting Sun. Lagrangian multi-
plier adaptation for rate-distortion optimization with inter-frame dependency. IEEE Transactions
on Circuits and Systems for Video Technology, 26(1):117–129, 2015."
REFERENCES,0.2854889589905363,Under review as a conference paper at ICLR 2022
REFERENCES,0.2870662460567823,"Tao Lin, Lingjing Kong, Sebastian U Stich, and Martin Jaggi. Ensemble distillation for robust model
fusion in federated learning. Advances in Neural Information Processing Systems, 2020."
REFERENCES,0.2886435331230284,"H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efﬁcient learning of deep networks from decentralized data. In International
Conference on Artiﬁcial Intelligence and Statistics, pp. 1273–1282, 2017."
REFERENCES,0.2902208201892745,"Luis Mu˜noz-Gonz´alez, Kenneth T Co, and Emil C Lupu. Byzantine-robust federated machine learn-
ing through adaptive model averaging. arXiv preprint arXiv:1909.05125, 2019."
REFERENCES,0.2917981072555205,"Haotong Qin, Ruihao Gong, Xianglong Liu, Xiao Bai, Jingkuan Song, and Nicu Sebe. Binary neural
networks: A survey. Pattern Recognition, pp. 107281, 2020a."
REFERENCES,0.29337539432176657,"Qiaofeng Qin, Konstantinos Poularakis, Kin K Leung, and Leandros Tassiulas. Line-speed and scal-
able intrusion detection at the network edge via federated learning. In International Federation
for Information Processing Networking Conference, 2020b."
REFERENCES,0.2949526813880126,"Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jadbabaie, and Ramtin Pedarsani.
FedPAQ: A communication-efﬁcient federated learning method with periodic averaging and quan-
tization. In International Conference on Artiﬁcial Intelligence and Statistics, 2020."
REFERENCES,0.29652996845425866,"Mher Safaryan and Peter Richtarik. Stochastic sign descent methods: New algorithms and better
theory. In International Conference on Machine Learning, 2021."
REFERENCES,0.2981072555205047,"Felix Sattler, Klaus-Robert M¨uller, Thomas Wiegand, and Wojciech Samek. On the byzantine ro-
bustness of clustered federated learning. In International Conference on Acoustics, Speech and
Signal Processing, 2020."
REFERENCES,0.2996845425867508,"Oran Shayer, Dan Levi, and Ethan Fetaya. Learning discrete weights using the local reparameteri-
zation trick. In International Conference on Learning Representations, 2018."
REFERENCES,0.30126182965299686,"Nguyen H Tran, Wei Bao, Albert Zomaya, Minh NH Nguyen, and Choong Seon Hong. Feder-
ated learning over wireless networks: Optimization model design and analysis. In International
Conference on Computer Communications, 2019."
REFERENCES,0.3028391167192429,"Jianyu Wang and Gauri Joshi. Cooperative SGD: A uniﬁed framework for the design and analysis
of communication-efﬁcient SGD algorithms. arXiv preprint arXiv:1808.07576, 2018."
REFERENCES,0.30441640378548895,"Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmark-
ing machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017."
REFERENCES,0.305993690851735,"Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett. Byzantine-robust distributed
learning: Towards optimal statistical rates. In International Conference on Machine Learning,
2018."
REFERENCES,0.30757097791798105,"Zhi-Hua Zhou. Ensemble methods: foundations and algorithms. Chapman and Hall/CRC, 2019."
REFERENCES,0.30914826498422715,Under review as a conference paper at ICLR 2022
REFERENCES,0.3107255520504732,"A
VOTING METHODS"
REFERENCES,0.31230283911671924,"We review the deﬁnitions of several voting methods (Zhou, 2019). Suppose we have a set of M
individual voters and C candidate output labels {ψ1, . . . , ψC}. For the mth voter, it will output
result vm = [vm,1, . . . , vm,C]⊤. Here, the ith entry vm,i ∈{0, 1}, which takes the value one if the
voter chooses the candidate ψi and zero otherwise."
REFERENCES,0.3138801261829653,"Majority vote requires the winner to receive more than half of the votes; if none of the candidates
receives more than half of the votes, a rejection option will be given. The majority vote result can
be written as"
REFERENCES,0.31545741324921134,"Ψmajority = 

 
"
REFERENCES,0.31703470031545744,"ψi,
if M
X"
REFERENCES,0.3186119873817035,"m=1
vm,i > 1 2 C
X j=1 M
X"
REFERENCES,0.32018927444794953,"m=1
vm,j,"
REFERENCES,0.3217665615141956,"rejection, otherwise. (16)"
REFERENCES,0.32334384858044163,"Plurality vote takes the class label that receives the largest number of votes as the ﬁnal winner, i.e.,"
REFERENCES,0.3249211356466877,"Ψplurality = ψargmax
i"
REFERENCES,0.3264984227129338,"PM
m=1 vm,i.
(17)"
REFERENCES,0.3280757097791798,"In the binary case with C = 2, plurality vote resembles majority vote except that it does not have a
rejection option. If more than two candidates receive the same number of votes, we randomly select
one of them as the ﬁnal results. Weighted vote assigns different weights for voters and the result can
be written as
Ψweighted = ψargmax
i"
REFERENCES,0.32965299684542587,"PM
m=1 λmvm,i,
(18)"
REFERENCES,0.3312302839116719,"where λm is the weight assigned to the mth voter. In contrast to the aforementioned vote methods,
soft vote produces the probability output. The probability that the ith candidate wins is calculated as"
REFERENCES,0.33280757097791797,"bP(Ψsoft = ψi) = 1 M M
X"
REFERENCES,0.334384858044164,"m=1
vm,i.
(19)"
REFERENCES,0.3359621451104101,"B
FEDVOTE ALGORITHM"
REFERENCES,0.33753943217665616,"We summarize the proposed FedVote method and its Byzantine-resilient variant in Algorithm 1.
When there are no attackers involved, we use Option I. When we require the resilience against
Byzantine failure, we choose Option II."
REFERENCES,0.3391167192429022,"C
SETUP AND ADDITIONAL EXPERIMENTS"
REFERENCES,0.34069400630914826,"C.1
HYPERPARAMETERS"
REFERENCES,0.3422712933753943,"For the clipping thresholds, we set pmin = 0.001 and pmax = 1−pmin. The thresholds are introduced
for numerical stability and have little impact on performance. We use β = 0.5 in Byzantine-FedVote.
The choice of the smoothing factor β has little impact on the ﬁnal test accuracy, as the credibility
score decays exponentially for adversaries over multiple communication rounds. We use the Adam
optimizer and search using the learning rate η over the set {10−4, 3×10−4, 10−3, 3×10−3, 10−2, 3×
10−2, 10−1, 3×10−1}. We set the number of local iterations τ to 40 and the local batch size to 100."
REFERENCES,0.3438485804416404,"C.2
COMPARISON OF VANILLA FEDVOTE AND BYZANTINE-FEDVOTE"
REFERENCES,0.34542586750788645,"Lemma 2 shows that FedVote is related to FedAvg in expectation. Adversaries sending the opposite
results will negatively affect the estimation of the weight distribution and impede the convergence
in multiple rounds. We compare the test accuracy of Byzantine-FedVote, Vanilla FedVote, and
signSGD on the non-i.i.d. CIFAR-10 dataset (α = 0.5) with various numbers of omniscient attack-
ers. Figure 6 reveals that the test accuracy of Vanilla FedVote drops severely when the number of
adversaries increases, which is consistent with our analysis. In contrast, the drop of accuracy in
Byzantine-FedVote is negligible, conﬁrming its resilience to omniscient attackers."
REFERENCES,0.3470031545741325,Under review as a conference paper at ICLR 2022
REFERENCES,0.34858044164037855,Algorithm 1: Binary-Weight FedVote with/without Byzantine Tolerance
REFERENCES,0.3501577287066246,1 initialize p(0) and broadcast
REFERENCES,0.35173501577287064,"2 for k = 0, 1, . . . , N −1 do"
REFERENCES,0.35331230283911674,"3
on mth worker:"
REFERENCES,0.3548895899053628,"4
receive p(k) from the server"
REFERENCES,0.35646687697160884,"5
initialize latent weight h(k,0)
m
= ϕ−1(2p(k) −1)"
REFERENCES,0.3580441640378549,"6
for t = 0 : τ −1 do"
REFERENCES,0.35962145110410093,"7
˜g(k,t)
m
= ∇hfm(ϕ(h(k,t)
m
); ξ(t,r)
m
)"
REFERENCES,0.361198738170347,"8
h(k,t+1)
m
= h(k,t)
m
−η(k,t) ˜g(k,t)
m"
REFERENCES,0.3627760252365931,"9
ew(k,τ)
m
= ϕ(h(k,τ))"
REFERENCES,0.3643533123028391,"10
w(k,τ)
m
= sto rounding(ew(k,τ)
m
)
▷Eq.
(11)"
REFERENCES,0.3659305993690852,"11
send w(k,τ)
m
to server"
REFERENCES,0.3675078864353312,"12
on server:"
REFERENCES,0.36908517350157727,"13
{w(k+1), p(k+1)} = vote({w(k,τ)
m
}M
m=1)"
REFERENCES,0.37066246056782337,"14
broadcast p(k+1) to workers"
REFERENCES,0.3722397476340694,"15 function vote({w(k,τ)
m
}M
m=1)"
REFERENCES,0.37381703470031546,"16
for i = 1 : d do"
REFERENCES,0.3753943217665615,"17
w(k+1)
i
= sign
 M
P"
REFERENCES,0.37697160883280756,"m=1
w(k,τ)
m,i  18"
REFERENCES,0.3785488958990536,"p(k+1)
i
=
1
M M
P"
REFERENCES,0.3801261829652997,"m=1
1

bw(k,τ)
m,i
= 1

▷Option I"
REFERENCES,0.38170347003154576,"19
p(k+1)
i
=
M
P"
REFERENCES,0.3832807570977918,"m=1
λ(k)
m 1

w(k,τ)
m,i
= 1

▷Option II"
REFERENCES,0.38485804416403785,"20
return {w(k+1), p(k+1)} to the server"
REFERENCES,0.3864353312302839,"0
20
40
60
80
100
Communication Round 0.1 0.2 0.3 0.4 0.5 0.6 0.7"
REFERENCES,0.38801261829652994,Test Accuracy
REFERENCES,0.38958990536277605,"FedAvg
FedVote
FedPAQ
signSGD"
REFERENCES,0.3911671924290221,"Figure 5: Test accuracy versus communication
round of different methods on the non-i.i.d. CI-
FAR dataset (α = 0.5). We use 100 workers
and sample 20 of them in each round."
REFERENCES,0.39274447949526814,"0
1
2
3
Number of Byzantine Workers 0.45 0.50 0.55 0.60 0.65 0.70 0.75"
REFERENCES,0.3943217665615142,Test Accuracy
REFERENCES,0.39589905362776023,"Byzantine-FedVote
Vanilla FedVote
signSGD"
REFERENCES,0.39747634069400634,"Figure 6: Test accuracy versus the number of
Byzantine workers. As the number of adver-
saries increases, the test accuracy of FedVote
drops rapidly."
REFERENCES,0.3990536277602524,"C.3
CONVERGENCE OF FEDVOTE WITH PARTIAL PARTICIPATION"
REFERENCES,0.40063091482649843,"We increase the number of workers to 100 and sample 20 of them in each communication round.
We compare FedVote with FedAvg McMahan et al. (2017), FedPAQ (Reisizadeh et al., 2020), and
signSGD (Bernstein et al., 2018) in Figure 5 on the non-i.i.d. CIFAR-10 dataset (α = 0.5) without
changing other experimental setups. The observation is consistent with the results in Figure 4.
FedVote outperforms gradient quantization methods such as FedPAQ and signSGD."
REFERENCES,0.4022082018927445,Under review as a conference paper at ICLR 2022
REFERENCES,0.4037854889589905,"C.4
EXTENSION TO TERNARY NEURAL NETWORKS"
REFERENCES,0.40536277602523657,"The stochastic rounding used in the ternary neural networks, wi = Qsr( ew), is an extension of (11): wi ="
REFERENCES,0.4069400630914827,"( +1,
with probability π1 = ˜wi 1( ewi > 0),
−1,
with probability π2 = −˜wi 1( ewi < 0),
0,
with probability 1 −(π1 + π2).
(20)"
REFERENCES,0.4085173501577287,"One can modify the normalization function to optimize neural networks with multiple quantization
levels. For example, consider quaternary weight wi ∈{−2, −1, 1, 2}, the normalization function
ϕ(x) can be modiﬁed to ϕ(x) = 2 tanh(ax)."
REFERENCES,0.41009463722397477,"C.5
BATCH NORMALIZATION IN FEDVOTE"
REFERENCES,0.4116719242902208,"Below we review the commonly-adopted BN function for convenience of presentation. For a one-
dimensional input x(j) from the current batch B = {x(1), · · · , x(nb)}, the output of BN layer is
formulated as"
REFERENCES,0.41324921135646686,"y ≜BNγ,b(x(j)) = γ x(j) −µ
√"
REFERENCES,0.4148264984227129,"σ2 + ϵ
+ b,
(21)"
REFERENCES,0.416403785488959,"where γ, b are learnable afﬁne transformation parameters, and µ, σ2 are the mean and variance
calculated over the batch samples. Note that the normal BN layer will introduce the real-valued pa-
rameters and track the statistics of the input, all of which may cause problems when being binarized
in FedVote. Therefore, we choose to set the parameter-free static BN, i.e.,"
REFERENCES,0.41798107255520506,"y′ ≜BN(x(j)) =
x −EB[x(j)]
p"
REFERENCES,0.4195583596214511,"VarB[x(j)] + ϵ
.
(22)"
REFERENCES,0.42113564668769715,"D
MISSING PROOFS"
REFERENCES,0.4227129337539432,"D.1
PROOF OF LEMMA 1"
REFERENCES,0.4242902208201893,"Lemma 1 (One-Shot FedVote) Let w∗∈Dd
2 be the optimal solution deﬁned in (8). For the mth
worker, εm,i ≜P(w(k,τ)
m,i
̸= w∗
i ) denotes the error probability of the voting result of the ith coordi-"
REFERENCES,0.42586750788643535,"nate. Suppose the error events {w(k,τ)
m,i
̸= w∗
i }M
m=1 are mutually independent, and the mean error
probability si =
1
M
PM
m=1 εm,i is smaller than 1/2. For the voted weight w(k+1), we have"
REFERENCES,0.4274447949526814,"P

w(k+1)
i
̸= w∗
i

⩽

2si exp(1 −2si)
 M"
REFERENCES,0.42902208201892744,"2 .
(23)"
REFERENCES,0.4305993690851735,"Proof. Let Xm,i ≜1

w(k,τ)
m,i
̸= w∗
i

, following Bernoulli distribution with parameter εm,i. Let"
REFERENCES,0.43217665615141954,"Yi = PM
m=1 Xm,i, we have"
REFERENCES,0.43375394321766564,"P

w(k+1)
i
̸= w∗
i

= P

Yi ⩾M 2"
REFERENCES,0.4353312302839117,"
.
(24)"
REFERENCES,0.43690851735015773,Under review as a conference paper at ICLR 2022
REFERENCES,0.4384858044164038,"With independent vote results from workers, Yi follows Poisson binomial distribution with mean
µYi = PM
m=1 εm,i. ∀a > 0, the Chernoff bound can be derived as"
REFERENCES,0.4400630914826498,"P

Yi ⩾M 2"
REFERENCES,0.4416403785488959,"
(25a)"
REFERENCES,0.443217665615142,"= P(eaYi ⩾e
aM"
REFERENCES,0.444794952681388,"2 )
(25b)"
REFERENCES,0.44637223974763407,"x
⩽exp

−aM 2"
REFERENCES,0.4479495268138801,"
E

eaYi
(25c)"
REFERENCES,0.44952681388012616,"= exp

−aM 2 
M
Y"
REFERENCES,0.45110410094637227,"m=1
(1 −εm,i + eaεm,i)
(25d) = exp  −aM 2
+ M
X"
REFERENCES,0.4526813880126183,"m=1
ln (1 + εm,i(ea −1)) ! (25e)"
REFERENCES,0.45425867507886436,"y
⩽exp  −aM 2
+ M
X"
REFERENCES,0.4558359621451104,"m=1
εm,i(ea −1) !"
REFERENCES,0.45741324921135645,".
(25f)"
REFERENCES,0.4589905362776025,"where x is based on Markov’s inequality. y holds due to ln(1 + x) ⩽x for all x ∈(−1, ∞)."
REFERENCES,0.4605678233438486,By assumption we have µYi < M
REFERENCES,0.46214511041009465,"2 . Let a = ln
M
2µYi , we have"
REFERENCES,0.4637223974763407,"P

Yi ⩾M 2"
REFERENCES,0.46529968454258674,"
⩽exp
 
−µYi + M 2
"
REFERENCES,0.4668769716088328,"
M
2µYi  M"
REFERENCES,0.46845425867507884,"2
(26a)"
REFERENCES,0.47003154574132494,"⩽
2µYi"
REFERENCES,0.471608832807571,"M
exp

1 −2µYi M  M"
REFERENCES,0.47318611987381703,"2
.
(26b)"
REFERENCES,0.4747634069400631,"Let si =
µYi"
REFERENCES,0.47634069400630913,"M =
1
M
PM
m=1 εm,i and substitute it into (26b), the proof is complete."
REFERENCES,0.47791798107255523,"D.2
PROOF OF LEMMA 2"
REFERENCES,0.4794952681388013,"Lemma 2 (Relationship with FedAvg) For the normalized weights, FedVote recovers FedAvg in"
REFERENCES,0.4810725552050473,"expectation: E
ew(k+1)
=
1
M M
P"
REFERENCES,0.48264984227129337,"m=1
ew(k,τ)
m
, where ew(k+1) = ϕ(h(k+1)) and ew(k,τ)
m
= ϕ(h(k,τ)
m
)."
REFERENCES,0.4842271293375394,"Proof. From the inverse normalization in (14), we have ew(k+1) = 2p(k+1)−1. Recall the deﬁnition
of the empirical Bernoulli parameter p(k+1) given by (13), we have the elementwise expectation"
REFERENCES,0.48580441640378547,"Eπ
h
ew(k+1)
i
i
= 1 M M
X m=1"
REFERENCES,0.48738170347003157,"
2bP(w(k,τ)
m,i
= 1) −1

(27a) x= 1 M M
X"
REFERENCES,0.4889589905362776,"m=1
ϕ(h(k,τ)
m,i ),
(27b)"
REFERENCES,0.49053627760252366,"where x follows from stochastic rounding deﬁned in (11). Based on the deﬁnition of range normal-
ization in (10), for local normalized weight we have w(k,τ)
m,i
= ϕ(h(k,τ)
m,i ). Substituting the result into
(27b) we have"
REFERENCES,0.4921135646687697,"Eπ
h
ew(k+1)i
= 1 M M
X"
REFERENCES,0.49369085173501576,"m=1
ew(k,τ)
m
,
(28)"
REFERENCES,0.4952681388012618,which completes the proof.
REFERENCES,0.4968454258675079,"D.3
PROOF OF LEMMA 3"
REFERENCES,0.49842271293375395,"Lemma 3 Suppose we have an input a ∈(−1, 1)d for the quantizer Qsr deﬁned in (11), then the"
REFERENCES,0.5,"quantization error satisﬁes E
hQsr(a) −a
2
2
a
i
= d −
a
2
2."
REFERENCES,0.501577287066246,Under review as a conference paper at ICLR 2022
REFERENCES,0.5031545741324921,"Proof. Let ˆa ≜Qsr(a), we have"
REFERENCES,0.5047318611987381,"E
hQsr(a) −a
2
2
a
i
= E "" d
X"
REFERENCES,0.5063091482649842,"i=1
(ˆai −ai)2a # (29a) = d
X i=1"
REFERENCES,0.5078864353312302," 
E

ˆa2
i
a

−a2
i

(29b) = d
X r=1"
REFERENCES,0.5094637223974764," 
1 −a2
i

(29c)"
REFERENCES,0.5110410094637224,"= d −∥a∥2
2.
(29d)"
REFERENCES,0.5126182965299685,The proof is complete.
REFERENCES,0.5141955835962145,"D.4
PROOF OF LEMMA 4"
REFERENCES,0.5157728706624606,"Lemma 4 Suppose we have an input x ∈Rd for the QSGD quantizer Q. In the coarse quantization
scenario, the quantization error satisﬁes E
hQ(x) −x
2
2
x
i
= O

d
1
2
 x
2
2."
REFERENCES,0.5173501577287066,"Proof. Consider a QSGD quantizer (Alistarh et al., 2017) with s = 1. For detailed results of other
quantizers, we refer readers to Basu et al. (2020)."
REFERENCES,0.5189274447949527,"In particular, we have
Qqsgd (xi) = ∥x∥2 · sgn (xi) · ξi(x, s),
(30) where"
REFERENCES,0.5205047318611987,"ξi(x, s)|s=1 ="
REFERENCES,0.5220820189274448,"(
0
with prob. 1 −
|xi|
∥x∥2 ,"
REFERENCES,0.5236593059936908,"1
with prob.
|xi|
∥x∥2 .
(31)"
REFERENCES,0.5252365930599369,The variance of quantization error is
REFERENCES,0.526813880126183,"E
hQ(x) −x
2
2|x
i
= E "" d
X"
REFERENCES,0.5283911671924291,"i=1
(ˆxi −xi)2 x # (32a) = d
X i=1"
REFERENCES,0.5299684542586751," 
E

ˆx2
i
x

−x2
i

(32b)"
REFERENCES,0.5315457413249212,"= ∥x∥2
2"
REFERENCES,0.5331230283911672,"Pd
i=1 |xi|
∥x∥2
−∥x∥2
2
(32c)"
REFERENCES,0.5347003154574133,"= ∥x∥2∥x∥1 −∥x∥2
2
(32d) ⩽(
√"
REFERENCES,0.5362776025236593,"d −1)∥x∥2
2,
(32e)"
REFERENCES,0.5378548895899053,which completes the proof.
REFERENCES,0.5394321766561514,"D.5
PROOF OF THEOREM 1"
REFERENCES,0.5410094637223974,"We ﬁrst introduce some notations for simplicity. Let ∆(k) denote the difference between two suc-
cessive global latent weights, i.e.,"
REFERENCES,0.5425867507886435,"∆(k) ≜ew(k) −ew(k+1).
(33)"
REFERENCES,0.5441640378548895,"We use ε(k,t)
m
to denote the stochastic gradient noise, i.e.,"
REFERENCES,0.5457413249211357,"ε(k,t) ≜˜g(k,t)
m
−g(k,t)
m
.
(34)"
REFERENCES,0.5473186119873817,"Finally, we let ∇f(ew) denote the gradient with respect to ew. The following ﬁve lemmas are pre-
sented to facilitate the proof."
REFERENCES,0.5488958990536278,Under review as a conference paper at ICLR 2022
REFERENCES,0.5504731861198738,"Lemma 5 The global normalized weight ew(k) can be reconstructed as the average of local binary
weight, i.e.,"
REFERENCES,0.5520504731861199,"ew(k+1) = 1 M M
X"
REFERENCES,0.5536277602523659,"m=1
w(k,τ)
m
.
(35)"
REFERENCES,0.555205047318612,Proof. See Appendix D.6.
REFERENCES,0.556782334384858,"Lemma 6 (Lipschitz continuity) Under Assumption 3, ∀x1, x2 ∈R, we have"
REFERENCES,0.5583596214511041,"|ϕ(x1) −ϕ(x2)| ⩽c2|x1 −x2|.
(36)"
REFERENCES,0.5599369085173501,"Proof. Without loss of generality, suppose x1 < x2. Based on the mean value theorem, there exists
some c ∈(x1, x2) such that"
REFERENCES,0.5615141955835962,ϕ′(c) = ϕ(x2) −ϕ(x1)
REFERENCES,0.5630914826498423,"x2 −x1
.
(37)"
REFERENCES,0.5646687697160884,"For the monotonically increasing function ϕ, we have"
REFERENCES,0.5662460567823344,"ϕ (x2) −ϕ (x1) = ϕ′(c) (x2 −x1)
(38a)"
REFERENCES,0.5678233438485805,"x
⩽c2 (x2 −x1) ,
(38b)"
REFERENCES,0.5694006309148265,"where x holds due to Assumption 3. The similar result can be obtained by assuming x2 < x1,
which completes the proof."
REFERENCES,0.5709779179810726,"Lemma 7 (Bounded weight divergence) Under Assumption 4, we have"
REFERENCES,0.5725552050473186,"E
ew(k,τ)
m
−ew(k)2
2 ⩽(c2η)2τ τ−1
X"
REFERENCES,0.5741324921135647,"t=0
E
g(k,t)
m
2
2 + σ2
ε !"
REFERENCES,0.5757097791798107,".
(39)"
REFERENCES,0.5772870662460567,Proof. See Appendix D.7.
REFERENCES,0.5788643533123028,"Lemma 8 Under Assumptions 2 to 5, we have"
REFERENCES,0.580441640378549,"E
D
∇f(ew(k)), ∆(t)E
⩾c2
1ητ"
E,0.582018927444795,"2
E
∇f(ew(k))
2
2
(40)"
E,0.583596214511041,"+ c2
1η
4M
 
2 −(c2L)2η2τ(τ −1)

M
X m=1 τ−1
X"
E,0.5851735015772871,"t=0
E
g(k,t)
m
2
2"
E,0.5867507886435331,−(c1c2L)2η3τ(τ −1)
E,0.5883280757097792,"4
σ2
ε −η(c2
2 −c2
1)
M M
X"
E,0.5899053627760252,"m=1
R(k)
m ,
(41)"
E,0.5914826498422713,"where R(k)
m ≜−
τ−1
P t=0 P"
E,0.5930599369085173,"i/∈I(k,t)
m
E
h
(∇f(ew(k)))i(∇f(ew(k,t)
m
))i
i
and I(k,t)
m
≜
n
i | g(k)
i
g(k,t)
m,i ⩾0
o
."
E,0.5946372239747634,Proof. See Appendix D.8.
E,0.5962145110410094,"Lemma 9 (Bounded global weight difference) Under Assumptions 2 to 5, we have"
E,0.5977917981072555,"E
∆(k)2
2 ⩽(c2η)2τ M M
X m=1 τ−1
X"
E,0.5993690851735016,"t=0
E
g(k,t)
m
2
2 + (c2η)2τ"
E,0.6009463722397477,"M
σ2
ε + 1"
E,0.6025236593059937,"M σ2
k.
(42)"
E,0.6041009463722398,Proof. See Appendix D.9.
E,0.6056782334384858,Under review as a conference paper at ICLR 2022
E,0.6072555205047319,"Theorem 1 For FedVote under Assumptions 1 to 5, if the learning let the learning rate η =
O

( c1"
E,0.6088328075709779,"c2 )2
1
Lτ
√ K"
E,0.610410094637224,"
, then after K rounds of communication, we have"
K,0.61198738170347,"1
K K−1
X"
K,0.613564668769716,"k=0
c2
1E
∇f(ew(k))
2
2 ⩽2

f(ew(0)) −f(ew∗)
"
K,0.6151419558359621,"ητK
+ c2
2Lη
 1"
K,0.6167192429022083,"M + c2
1Lη(τ −1) 2"
K,0.6182965299684543,"
σ2
ε"
K,0.6198738170347003,"+
L
ητKM K−1
X"
K,0.6214511041009464,"k=0
σ2
k + 2(c2
2 −c2
1)
τMK K−1
X k=0 M
X"
K,0.6230283911671924,"m=1
R(k)
m .
(43)"
K,0.6246056782334385,"where R(k)
m ≜−
τ−1
P t=0 P"
K,0.6261829652996845,"i/∈I(k,t)
m
E
h
(∇f(ew(k)))i(∇f(ew(k,t)
m
))i
i
and I(k,t)
m
≜
n
i | g(k)
i
g(k,t)
m,i ⩾0
o
."
K,0.6277602523659306,"Proof. Consider the difference vector ∆(k) deﬁned in (33), we expand it as"
K,0.6293375394321766,"∆(k) = ew(k) −ew(k+1)
(44a)"
K,0.6309148264984227,"x= ew(k) −1 M M
X"
K,0.6324921135646687,"m=1
w(k,τ)
m
(44b)"
K,0.6340694006309149,"y= ew(k) −1 M M
X"
K,0.6356466876971609,"m=1
ew(k,τ)
m
+ 1 M M
X"
K,0.637223974763407,"m=1
ζ(r)
m ,
(44c)"
K,0.638801261829653,"where x follows from (35), and y holds by substituting the deﬁnition of quantization error."
K,0.6403785488958991,"From Assumption 2, we have"
K,0.6419558359621451,"f(ew(k+1)) −f(ew(k)) ⩽−
D
∇f(ew(k)), ∆(k)E
+ L 2"
K,0.6435331230283912,"∆(k)2
2.
(45a)"
K,0.6451104100946372,Let (Lη)2τ(τ−1)
K,0.6466876971608833,"2
+ Lητ"
K,0.6482649842271293,"c2
1 ⩽
1
c2
2 , take the expectation on both sides, and use Lemmas 8–9:"
K,0.6498422712933754,"E
h
f(ew(k+1)) −f(ew(k))
i
⩽−c2
1ητ"
E,0.6514195583596214,"2
E
∇f(ew(k))
2
2"
E,0.6529968454258676,−(c1c2)2η
M,0.6545741324921136,4M  2
M,0.6561514195583596,"c2
2
−L2η2τ(τ −1) −2Lητ c2
1 
M
X m=1 τ−1
X"
M,0.6577287066246057,"t=0
E
g(k,t)
m
2
2"
M,0.6593059936908517,+ (c2η)2Lτ 4  2
M,0.6608832807570978,"M + c2
1Lη(τ −1)

σ2
ε + η(c2
2 −c2
1)
M M
X"
M,0.6624605678233438,"m=1
R(k)
m + L"
M,0.6640378548895899,"2M σ2
k
(46a)"
M,0.6656151419558359,"x
⩽−c2
1ητ"
E,0.667192429022082,"2
E
∇f(ew(k))
2
2 + (c2η)2Lτ 4  2"
E,0.668769716088328,"M + c2
1Lη(τ −1)

σ2
ε"
E,0.6703470031545742,"+ η(c2
2 −c2
1)
M M
X"
E,0.6719242902208202,"m=1
R(k)
m + L"
E,0.6735015772870663,"2M σ2
k,
(46b)"
E,0.6750788643533123,where x follows from the restrictions on learning rate. We rewrite the restriction as
E,0.6766561514195584,"η ⩽
−Lτ"
E,0.6782334384858044,"c2
1 +
q L2τ 2"
E,0.6798107255520505,"c4
1
+ 2L2τ(τ−1)"
E,0.6813880126182965,"c2
2
L2τ(τ −1)
(47a)"
E,0.6829652996845426,"x
⩽
−1 +
q"
E,0.6845425867507886,"1 + 2c4
1
c2
2
L(τ −1)c2
1
(47b)"
E,0.6861198738170347,"y
⩽
c2
1
L(τ −1)c2
2
,
(47c)"
E,0.6876971608832808,"where in x we use τ(τ −1) ⩽τ 2, and y holds due to the Bernoulli inequality (1 + x)
1
2 ⩽ 1 + 1"
E,0.6892744479495269,"2x, ∀x ∈[−1, ∞). Based on (47c), we set the learning rate η = O

( c1"
E,0.6908517350157729,"c2 )2
1
Lτ
√ K"
E,0.692429022082019,"
. Summing"
E,0.694006309148265,Under review as a conference paper at ICLR 2022
E,0.695583596214511,up over K communication rounds yields
K,0.6971608832807571,"1
K K−1
X"
K,0.6987381703470031,"k=0
c2
1E
∇f(ew(k))
2
2 ⩽2

f(ew(0)) −f(ew∗)
"
K,0.7003154574132492,"ητK
+ c2
2Lη
 1"
K,0.7018927444794952,"M + c2
1Lη(τ −1) 2"
K,0.7034700315457413,"
σ2
ε"
K,0.7050473186119873,"+
L
ητKM K−1
X"
K,0.7066246056782335,"k=0
σ2
k + 2(c2
2 −c2
1)
τMK K−1
X k=0 M
X"
K,0.7082018927444795,"m=1
R(k)
m .
(48a)"
K,0.7097791798107256,"D.6
PROOF OF LEMMA 5"
K,0.7113564668769716,"Proof. From the reconstruction rule (14), we have"
K,0.7129337539432177,"ew(k+1) = 2p(k+1) −1.
(49)"
K,0.7145110410094637,The ith entry of p(k) is deﬁned in (13) as:
K,0.7160883280757098,"p(k+1)
i
= 1 M M
X"
K,0.7176656151419558,"m=1
1

w(k,τ)
m,i
= 1

.
(50)"
K,0.7192429022082019,Substituting (50) into (49) yields
K,0.7208201892744479,"ew(k+1)
i
= 1 M M
X m=1"
K,0.722397476340694,"h
21

w(k,τ)
m,i
= 1

−1
i
.
(51)"
K,0.7239747634069401,Note that
K,0.7255520504731862,"21

w(k,τ)
m,i
= 1

−1 ="
K,0.7271293375394322,"(
+1, w(k,τ)
m
= +1,"
K,0.7287066246056783,"−1, w(k,τ)
m
= −1,
(52)"
K,0.7302839116719243,we have
K,0.7318611987381703,"ew(k+1)
i
= 1 M M
X"
K,0.7334384858044164,"m=1
w(k)
i
,
(53)"
K,0.7350157728706624,which completes the proof.
K,0.7365930599369085,"D.7
PROOF OF LEMMA 7"
K,0.7381703470031545,"Proof. With the local initialization and update method described in Algorithm 1, we have"
K,0.7397476340694006,"E
ew(k,τ)
m
−ew(k)2
2 = E
ϕ(h(k,τ)
m
) −ϕ(h(k,0)
m
)
2
2
(54a)"
K,0.7413249211356467,"x
⩽c2
2E
h(k,τ)
m
−h(k,0)
m
2
2
(54b)"
K,0.7429022082018928,"= c2
2E  τ−1
X"
K,0.7444794952681388,"t=0
−η ˜g(k,t)
m  2"
K,0.7460567823343849,"2
(54c)"
K,0.7476340694006309,"= (c2η)2E  τ−1
X t=0"
K,0.749211356466877,"
g(k,t)
m
+ ε(k,t)
m
 2"
K,0.750788643533123,"2
(54d)"
K,0.7523659305993691,"= (c2η)2 E  τ−1
X"
K,0.7539432176656151,"t=0
g(k,t)
m  2 2
+ E  τ−1
X"
K,0.7555205047318612,"t=0
ε(k,t)
m  2 2 ! (54e)"
K,0.7570977917981072,"⩽(c2η)2τ τ−1
X"
K,0.7586750788643533,"t=0
E
g(k,t)
m
2
2 + σ2
ε !"
K,0.7602523659305994,",
(54f)"
K,0.7618296529968455,where x comes from the Lipschitz condition in Lemma 6.
K,0.7634069400630915,Under review as a conference paper at ICLR 2022
K,0.7649842271293376,"D.8
PROOF OF LEMMA 8"
K,0.7665615141955836,Proof. We have
K,0.7681388012618297,"E
D
∇f(ew(k)), ∆(k)E"
K,0.7697160883280757,"= E
D
∇f(ew(k)), ew(k) −1 M M
X"
K,0.7712933753943217,"m=1
ew(k,τ)
m
+ 1 M M
X"
K,0.7728706624605678,"m=1
ζ(k)
m
E
(55a)"
K,0.7744479495268138,"x= E
D
∇f(ew(k)), ew(k) −1 M M
X"
K,0.7760252365930599,"m=1
ew(k,τ)
m
E
(55b)"
K,0.777602523659306,"= E
D
∇f(ew(k)), 1 M M
X"
K,0.7791798107255521,"m=1
ϕ(h(k)) −ϕ(h(k,τ)
m
)
E
,
(55c)"
K,0.7807570977917981,"where x follows from Assumption 5. Based on the mean value theorem, for h(k)
i
, h(t,τ)
m,i ∈R, there"
K,0.7823343848580442,"exists some c(k)
m,i ∈H(r)
m,i such that"
K,0.7839116719242902,"ϕ′(c(k)
m,i) =
ϕ(h(k)
i
) −ϕ(h(k,τ)
m,i )"
K,0.7854889589905363,"h(k)
i
−h(k,τ)
m,i
,
(56)"
K,0.7870662460567823,"where H(r)
m,i is an open interval with endpoints h(k)
i
and h(k,τ)
m,i :"
K,0.7886435331230284,"H(r)
m,i ="
K,0.7902208201892744,"(
(h(k)
i
, h(k,τ)
m,i ),
if h(k)
i
< h(k,τ)
m,i ,"
K,0.7917981072555205,"(h(k,τ)
m,i , h(k)
i
),
otherwise.
(57)"
K,0.7933753943217665,"Let C(k)
m = diag

ϕ′(c(k)
m,1), . . . , ϕ′(c(k)
m,d)

, we have"
K,0.7949526813880127,"ϕ(h(k)) −ϕ(h(k,τ)
m
) = C(k)
m (h(k) −h(k,τ)
m
) = η C(k)
m τ−1
X t=0"
K,0.7965299684542587,"
g(k,t)
m
+ ε(k,t)
m

,
(58)"
K,0.7981072555205048,Substituting (58) into (55c) yields
K,0.7996845425867508,"E
D
∇f(ew(k)), ∆(k)E
= η M M
X m=1 τ−1
X"
K,0.8012618296529969,"t=0
E
D
∇f(ew(k)), C(k)
m g(k,t)
m
E
.
(59)"
K,0.8028391167192429,"According to the chain rule, g(k,t)
m
can be written as"
K,0.804416403785489,"g(k,t)
m
= ∇hfm(ϕ(h(k,t)
m
)) = D(k,t)
m
∇ewfm(ew(k,t)
m
),
(60)"
K,0.805993690851735,"where D(k,t)
m
= diag

dϕ
dh(k,t)
m,1 , . . . ,
dϕ
dh(k,t)
m,d"
K,0.807570977917981,"
. To simplify the notations, let B(k,t)
m
= C(k)
m D(k,t)
m
."
K,0.8091482649842271,"Note that B(k,t)
m
is still a diagonal matrix, where the ith diagonal element b(k,t)
m,i is"
K,0.8107255520504731,"b(k,t)
m,i ≜(B(k,t)
m
)i,i =
dϕ"
K,0.8123028391167192,"dc(k,τ)
m,i dϕ"
K,0.8138801261829653,"dh(k,t)
m,i
.
(61)"
K,0.8154574132492114,Substituting (60) into (59) we have
K,0.8170347003154574,"E
D
∇f(ew(k)), ∆(k)E
= η M M
X m=1 τ−1
X"
K,0.8186119873817035,"t=0
E
D
∇f(ew(k)), B(k,t)
m
∇fm(ew(k,t)
m
)
E
.
(62)"
K,0.8201892744479495,We ﬁrst focus on the following inner product:
K,0.8217665615141956,"D
∇f(ew(k)), B(k,t)
m
∇fm(ew(k,t)
m
)
E
= d
X"
K,0.8233438485804416,"i=1
(∇f(ew(k)))i × b(k,t)
m,i (∇fm(ew(k,t)
m
))i,
(63)"
K,0.8249211356466877,Under review as a conference paper at ICLR 2022
K,0.8264984227129337,"where (∇f)i denotes the ith entry of the gradient vector. Consider an index set I(k,t)
m
deﬁned as"
K,0.8280757097791798,"I(k,t)
m
≜
n
i ∈{1, . . . , d} | (∇f(ew(k)))i(∇fm(ew(k,t)
m
))i ⩾0
o
.
(64)"
K,0.8296529968454258,"Since the sign of (∇f(ew(k)))i(∇fm(ew(k,t)
m
))i is equal to g(k)
i
g(k,t)
m,i , the index set I(k,t)
m
can also be
written as"
K,0.831230283911672,"I(k,t)
m
≜
n
i ∈{1, . . . , d} | g(k)
i
g(k,t)
m,i ⩾0
o
.
(65)"
K,0.832807570977918,The result in (63) can be bounded as
K,0.8343848580441641,"E
D
∇f(ew(k)), B(k,t)
m
∇fm(ew(k,t)
m
)
E
(66a)"
K,0.8359621451104101,"x
⩾c2
1
X"
K,0.8375394321766562,"i∈I(k,t)
m"
K,0.8391167192429022,"E
h
(∇f(ew(k)))i(∇fm(ew(k,t)
m
))i
i
+ c2
2
X"
K,0.8406940063091483,"i/∈I(k,t)
m"
K,0.8422712933753943,"E
h
(∇f(ew(k)))i(∇fm(ew(k,t)
m
))i
i (66b)"
K,0.8438485804416404,"= c2
1E
D
∇f(ew(k)), ∇fm(ew(k,t)
m
)
E
+ (c2
2 −c2
1)
X"
K,0.8454258675078864,"i/∈I(k,t)
m"
K,0.8470031545741324,"E
h
(∇f(ew(k)))i(∇fm(ew(k,t)
m
))i
i
, (66c)"
K,0.8485804416403786,"where x follows from Assumption 3. To simplify the notation, let R(k)
m denote the accumulative
gradient divergence, namely,"
K,0.8501577287066246,"R(k)
m ≜− τ−1
X t=0 X"
K,0.8517350157728707,"i/∈I(k,t)
m"
K,0.8533123028391167,"E
h
(∇f(ew(k)))i(∇f(ew(k,t)
m
))i
i
.
(67)"
K,0.8548895899053628,The expected inner product in (62) can be bounded as
K,0.8564668769716088,"E
D
∇f(ew(k)), ∆(k)E"
K,0.8580441640378549,"⩾c2
1η
M M
X m=1 τ−1
X"
K,0.8596214511041009,"t=0
E
D
∇f(ew(k)), ∇fm(ew(k,t)
m
)
E
−η(c2
2 −c2
1)
M M
X"
K,0.861198738170347,"m=1
R(k)
m
(68a)"
K,0.862776025236593,"x= c2
1η
2M M
X m=1 τ−1
X t=0"
K,0.8643533123028391,"
E
∇f(ew(k))
2
2 + E
∇f(ew(k,t)
m
)
2
2"
K,0.8659305993690851,"−E
∇f(ew(k,t)
m
) −∇f(ew(k))
2
2"
K,0.8675078864353313,"
−η(c2
2 −c2
1)
M M
X"
K,0.8690851735015773,"m=1
R(k)
m
(68b)"
K,0.8706624605678234,"y
⩾c2
1ητ 2"
K,0.8722397476340694,"∇f(ew(k))
2
2 + c2
1η
2M M
X m=1 τ−1
X t=0"
K,0.8738170347003155,"
E
∇f(ew(k,t)
m
)
2
2"
K,0.8753943217665615,"−L2E
ew(k,t)
m
−ew(k)2
2"
K,0.8769716088328076,"
−η(c2
2 −c2
1)
M M
X"
K,0.8785488958990536,"m=1
R(k)
m ,
(68c)"
K,0.8801261829652997,"where x follows from 2

a, b

=
a
2
2 +
b
2
2 −
a −b
2
2, and y holds due to Assumption 2.
From Lemma 7, we can show that"
K,0.8817034700315457,"E
ew(k,t)
m
−ew(k)2
2 ⩽(c2η)2t t−1
X n=0"
K,0.8832807570977917,"g(k,n)
m
2
2 + σ2
ε !"
K,0.8848580441640379,",
(69)"
K,0.886435331230284,Under review as a conference paper at ICLR 2022
K,0.88801261829653,"where t = 1, . . . , τ −1. Substituting (69) in (68c) yields"
K,0.889589905362776,"E
D
∇f(ew(k)), ∆(k)E"
K,0.8911671924290221,"⩾c2
1ητ"
E,0.8927444794952681,"2
E
∇f(ew(k))
2
2 + c2
1η
2M M
X m=1 τ−1
X"
E,0.8943217665615142,"t=0
E
∇f(ew(k,t)
m
)
2
2"
E,0.8958990536277602,−(c1c2L)2η3
M,0.8974763406940063,"4M M
X m=1 τ−1
X"
M,0.8990536277602523,"n=0
(τ(τ −1) −n(n + 1)) E
g(k,n)
m
2
2"
M,0.9006309148264984,−(c1c2L)2η3τ(τ −1)
M,0.9022082018927445,"4
σ2
ε −η(c2
2 −c2
1)
M M
X"
M,0.9037854889589906,"m=1
R(k)
m
(70a)"
M,0.9053627760252366,"x
⩾c2
1ητ"
E,0.9069400630914827,"2
E
∇f(ew(k))
2
2 + c2
1η
2M M
X m=1 τ−1
X"
E,0.9085173501577287,"t=0
E
∇f(ew(k,t)
m
)
2
2"
E,0.9100946372239748,"−
η
4M (c1c2L)2η2τ(τ −1) M
X m=1 τ−1
X"
E,0.9116719242902208,"t=0
E
g(k,t)
m
2
2"
E,0.9132492113564669,−(c1c2L)2η3τ(τ −1)
E,0.9148264984227129,"4
σ2
ε −η(c2
2 −c2
1)
M M
X"
E,0.916403785488959,"m=1
R(k)
m
(70b)"
E,0.917981072555205,"y
⩾c2
1ητ"
E,0.919558359621451,"2
E
∇f(ew(k))
2
2 + c2
1η
4M
 
2 −(c2L)2η2τ(τ −1)

M
X m=1 τ−1
X"
E,0.9211356466876972,"t=0
E
g(k,t)
m
2
2"
E,0.9227129337539433,−(c1c2L)2η3τ(τ −1)
E,0.9242902208201893,"4
σ2
ε −η(c2
2 −c2
1)
M M
X"
E,0.9258675078864353,"m=1
R(k)
m
(70c)"
E,0.9274447949526814,"where x follows from τ(τ −1) −n(n + 1) ⩽τ(τ −1), and y holds due to the chain rule in (60)
and Assumption 3."
E,0.9290220820189274,"D.9
PROOF OF LEMMA 9"
E,0.9305993690851735,Proof. We have
E,0.9321766561514195,"E
∆(k)2
2 = E"
E,0.9337539432176656,"ew(k) −1 M M
X"
E,0.9353312302839116,"m=1
ew(k,τ)
m
+ 1 M M
X"
E,0.9369085173501577,"m=1
ζ(k)
m  2"
E,0.9384858044164038,"2
(71a) = E"
M,0.9400630914826499,"1
M M
X"
M,0.9416403785488959,"m=1
ϕ(h(k)) −ϕ(h(k,τ)
m
) + 1 M M
X"
M,0.943217665615142,"m=1
ζ(k)
m  2"
M,0.944794952681388,"2
(71b) = E"
M,0.9463722397476341,"1
M M
X"
M,0.9479495268138801,"m=1
ϕ(h(k)) −ϕ(h(k,τ)
m
)  2 2
+ E"
M,0.9495268138801262,"1
M M
X"
M,0.9511041009463722,"m=1
ζ(k)
m  2 2 + 2E *
1
M M
X"
M,0.9526813880126183,"m=1
ϕ(h(k)) −ϕ(h(k,τ)
m
), 1 M M
X"
M,0.9542586750788643,"m=1
ζ(t)
m + (71c) x= E"
M,0.9558359621451105,"1
M M
X"
M,0.9574132492113565,"m=1
ϕ(h(k)) −ϕ(h(k,τ)
m
)  2 2
+ E"
M,0.9589905362776026,"1
M M
X"
M,0.9605678233438486,"m=1
ζ(k)
m  2"
M,0.9621451104100947,"2
,
(71d)"
M,0.9637223974763407,Under review as a conference paper at ICLR 2022
M,0.9652996845425867,where x comes from Assumption 5. For the ﬁrst term in (71d) we have E
M,0.9668769716088328,"1
M M
X"
M,0.9684542586750788,"m=1
(ϕ(h(k)) −ϕ(h(k,τ)
m
)  2 2 ⩽1 M M
X"
M,0.9700315457413249,"m=1
E
ϕ(h(k)) −ϕ(h(k,τ)
m
)

2"
M,0.9716088328075709,"2
(72a)"
M,0.973186119873817,"x
⩽c2
2
M M
X m=1"
M,0.9747634069400631,"h(k) −h(k,τ)
m
2
2
(72b)"
M,0.9763406940063092,"y= (c2η)2 M M
X m=1 −η τ−1
X"
M,0.9779179810725552,"t=0
˜g(k,t)
m  2"
M,0.9794952681388013,"2
(72c)"
M,0.9810725552050473,"= (c2η)2 M M
X m=1  τ−1
X"
M,0.9826498422712934,"t=0
(g(k,t)
m
+ ε(k,t)
m
)  2"
M,0.9842271293375394,"2
(72d)"
M,0.9858044164037855,"= (c2η)2τ M M
X m=1 τ−1
X"
M,0.9873817034700315,"t=0
E
g(k,t)
m

2"
M,0.9889589905362776,2 + (c2η)2τ
M,0.9905362776025236,"M
σ2
ε,
(72e)"
M,0.9921135646687698,where x is due to Lemma 6 and y comes from (9). For the second term in (71d) we have E
M,0.9936908517350158,"1
M M
X"
M,0.9952681388012619,"m=1
ζ(k)
m  2 2
⩽1"
M,0.9968454258675079,"M σ2
k.
(73)"
M,0.998422712933754,Combing the results of (72e) and (73) completes the proof.
