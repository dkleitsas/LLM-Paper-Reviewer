Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.005681818181818182,"This paper explores decentralized nonsmooth convex optimization with affine con-
straints. We extend existing research by incorporating a nonsmooth stochastic or-
acle, solved by the well know gradient sliding method. Our result show sliding
algorithm achieves sub-optimal solution for these optimization problems under
certain conditions, addressing limitations of prior methods. This work enhances
the theoretical understanding of distributed optimization and offers practical solu-
tions for applications in sensor networks and machine learning."
INTRODUCTION,0.011363636363636364,"1
INTRODUCTION"
INTRODUCTION,0.017045454545454544,"The study of solving the convex optimization problems in a distributed setting has a long history in
the optimization community (Tsitsiklis, 1984; Bertsekas & Tsitsiklis, 2015). Building on the seminal
work (Tsitsiklis, 1984), in recent years, there has been a flurry of research around the problem of
solving convex optimization problem in the framework of multiagent systems (Nedic & Ozdaglar,
2009; Yuan & Ho, 2014). In particular, the global objective function of the problem is a sum of
functions that are distributed over a network, which consists of multiple interacting nodes. Such
problem arises in a variety of real applications ranging from sensor networks to machine learning
(Duchi et al., 2011; Johansson et al., 2008)."
INTRODUCTION,0.022727272727272728,"Decentralized convex optimization without affine constraints has been extensively studied. It is
well-established that the performance of optimization algorithms applied to strongly-convex smooth
objectives is bounded below by a multiple of the graph condition number and the objective condition
number, up to a logarithmic factor (Scaman et al., 2017).Moreover constrained distributed optimiza-
tion has attracted significant attention from researchers. An early application of first-order methods
to constrained decentralized optimization is illustrated by the projected subgradient algorithm, as
discussed in (Nedic et al., 2010), which also analyzed time-varying networks. A comprehensive
review of the main problem classes in distributed constrained optimization, along with algorithms"
INTRODUCTION,0.028409090909090908,∗Corresponding author
INTRODUCTION,0.03409090909090909,Published as a conference paper at ICOMP 2024
INTRODUCTION,0.03977272727272727,"suitable for various levels of decentralization, is presented in (Necoara et al., 2011). We will breifly
them below:"
INTRODUCTION,0.045454545454545456,"Necoara & Nedelcu (2014) propose distributed dual gradient algorithms for linearly constrained
separable convex problems, it means each agent in the network has their own variable. Moreover,
they supposed affine constraints are network compatable (constraint matrix can have a non-zero
element on position (i, j) only if there is an edge in communication graph between agents i and j.
In our study, we don’t have such conditions, the variable is shared among agents , which is clearly a
special case of (Necoara & Nedelcu, 2014) , and we have various network structure."
INTRODUCTION,0.05113636363636364,"In Necoara et al. (2011) the authors present several formulations of distributed optimization prob-
lems, covering scenarios with various types of interconnections between constraints and objectives,
including cases where the overall objective (cost) does not equal to the sum of individual cost func-
tions for each agent. However, their algorithms for problems with coupled affine constraints need
to solve a ”master problem” at a centralized node during each iteration, thereby compromising the
decentralization ability."
INTRODUCTION,0.056818181818181816,"Rogozin et al. (2022) solve a decentralized convex optimization with affine constraints, and get linear
convergence rate. We take this as the base of our problem, and extend it to nonsmooth stochastic
oracle."
LIT REVIEW,0.0625,"1.1
NOTATIONS AND DEFINITIONS"
LIT REVIEW,0.06818181818181818,"We use ⟨x, y⟩
def
= Pn
i=1 xiyi to denote standard inner product of x, y ∈Rn where xi corresponds to
the i-th component of x in the standard basis in Rn. The dual norm ∥·∥∗for the norm ∥·∥is defined
in the following way: ∥y∥∗
def
= max {⟨x, y⟩| ∥x∥≤1}. To denote maximal and minimal positive
eigenvalues of positive semidefinite matrix A ∈Rn×n we use λmax(A) and λ+
min(A) respectively"
LIT REVIEW,0.07386363636363637,"and we use χ(A)
def
= λmax(A)/λ+
min(A) to denote condition number of A. Operator E[·] denotes
full mathematical expectation. To define the Kronecker product of two matrices. A ∈Rm×m and
B ∈Rn×n we use A ⊗B ∈Rnm×nm. The identity matrix of the size n × n is denoted in our paper
by In. The diameter of set X is denoted by DX = max{∥x −y∥|
∀x, y ∈X}. We use col(·) to
represent the column vector."
LIT REVIEW,0.07954545454545454,"1.2
PROBLEM FORMULATION"
LIT REVIEW,0.08522727272727272,"min
x∈X⊂Rd
1
m m
X"
LIT REVIEW,0.09090909090909091,"i=1
fi(x)
s.t.
Bx = 0.
(1)"
LIT REVIEW,0.09659090909090909,"Assumption 1 Assume that we have access to the stochastic oracle of fi. For a given point x, it
output f
′
i(x, ξ) such that"
LIT REVIEW,0.10227272727272728,"E[f
′
i(x, ξ)] = f ′
i(x) ∈∂fi(x),"
LIT REVIEW,0.10795454545454546,"E[∥f
′
i(x, ξ) −f ′
i(x)∥2] ≤σ2."
LIT REVIEW,0.11363636363636363,Assumption 2 fi is a convex and nonsmooth function satisfying
LIT REVIEW,0.11931818181818182,"fi(x) ≤fi(y) + ⟨f ′
i(x), x −y⟩+ M∥x −y∥2, ∀x, y ∈X.
(2)"
LIT REVIEW,0.125,"We assume that the problem is distributed over a connected network consisting of m agents. Each
agent locally store fi. Agents are connected through a communication network. Agents are only
allowed to exchange information with their neighborhoods. Further, we rely on the notion of gossip
matrix. W is a gossip matrix of an undirected graph G = (V, E), ∥V∥= m, if it satisfies following
properties:"
LIT REVIEW,0.13068181818181818,Assumption 3 propertoes of W:
LIT REVIEW,0.13636363636363635,1. W is a symmetric positive semi-definite matrix.
LIT REVIEW,0.14204545454545456,"2. (Network compatibility) For all i, j = 1, . . . , m it holds [W]ij = 0 if (i, j) /∈E and i ̸= j."
LIT REVIEW,0.14772727272727273,Published as a conference paper at ICOMP 2024
LIT REVIEW,0.1534090909090909,"3. (Kernel property) For any v = [v1, . . . , vm]⊤∈Rm, Wv = 0 if and only if v1 = . . . = vm."
LIT REVIEW,0.1590909090909091,"An classical example of a matrix that satisfies Assumption 3 is the graph Laplacian matrix W ∈
Rm×m:"
LIT REVIEW,0.16477272727272727,"[W]ij = 
 "
LIT REVIEW,0.17045454545454544,"−1,
if (i, j) ∈E,
deg(i),
if i = j,
0,
otherwise.
(3)"
LIT REVIEW,0.17613636363636365,"where deg(i) is the degree of the i-th node, i.e., the number of neighbors of the i-th agent. Since we"
LIT REVIEW,0.18181818181818182,"consider only connected networks, the matrix W has a unique eigenvector 1m
def
= (1, . . . , 1)⊤∈Rm
corresponding to the eigenvalue 0. It implies that for all vectors a = (a1, . . . , am)⊤∈Rm the
following equivalence holds:"
LIT REVIEW,0.1875,"a1 = . . . = am ⇐⇒Wa = 0.
(4)"
LIT REVIEW,0.19318181818181818,"Now let us think about ai as a number that the i-th node stores. Then, we can express in short
matrix form. To generalize it for the case when aj are vectors from Rd, we should consider the"
LIT REVIEW,0.19886363636363635,"matrix W
def
= W ⊗Id, where ⊗represents the Kronecker product. Indeed, if we consider vectors
x1, . . . , xm ∈Rd and x = (x⊤
1 , . . . , x⊤
m)⊤∈Rmd, then"
LIT REVIEW,0.20454545454545456,"x1 = . . . = xm ⇐⇒Wx = 0.
(5)"
IMPLEMENTATION/METHODS,0.21022727272727273,"2
RESULTS AND ALGORITHM"
IMPLEMENTATION/METHODS,0.2159090909090909,"We use the gradient sliding algorithm from (Lan, 2016), which is designed to solve composite convex
optimization problems of the form:"
IMPLEMENTATION/METHODS,0.2215909090909091,"min
x∈Q{ϕ(x) = g(x) + f(x)},
(6)"
IMPLEMENTATION/METHODS,0.22727272727272727,"where f(x) is a nonsmooth convex function and g(x) is a smooth convex function. Initially, we
demonstrate the transformation of problem (7) to fit the gradient sliding algorithm, ensuring that it
can achieve an ε-suboptimal solution. Subsequently, we reformulate problem (1) to problem (7)."
IMPLEMENTATION/METHODS,0.23295454545454544,"2.1
CONVEX OPTIMIZATION WITH TWO AFFINE CONSTRAINTS"
IMPLEMENTATION/METHODS,0.23863636363636365,First we introduce a minimization problem with two affine constraints :
IMPLEMENTATION/METHODS,0.24431818181818182,"min
x∈Q F(x)
(7)"
IMPLEMENTATION/METHODS,0.25,"s.t.
Bx = 0, Cx = 0,
(8)"
IMPLEMENTATION/METHODS,0.2556818181818182,"where F(x) =
1
m
Pm
i=1 fi(xi) and x = col(x1, . . . , xm), and also introduce B = B ⊗Im, C =
C ⊗Id, B ∈Rp×d, C ∈Rm×m."
IMPLEMENTATION/METHODS,0.26136363636363635,"By choosing a positive scalar γ, we can use the trick in Rogozin et al. (2022) to build A⊤=
[B⊤
γC] and the dual problem of problem (7) is:"
IMPLEMENTATION/METHODS,0.26704545454545453,"min
y
Φ(y), where
(9)"
IMPLEMENTATION/METHODS,0.2727272727272727,"Φ(y) = max
x∈Q ⟨y, Ax⟩−F(x) = ⟨A⊤y, x(A⊤y)⟩−F(x(AT y)),
(10)"
IMPLEMENTATION/METHODS,0.2784090909090909,"where x(y) = arg minx∈Q{⟨y, x⟩−F(x)}. We use y⋆to denote the solution of (9) with the
smallest l2-norm Ry = ∥y⋆∥2. And Ry can be bounded as follows:"
IMPLEMENTATION/METHODS,0.2840909090909091,"R2
y ≤∥∇F(x⋆)∥2"
IMPLEMENTATION/METHODS,0.2897727272727273,"λ+
min(A⊤A).
(11)"
IMPLEMENTATION/METHODS,0.29545454545454547,"Then we can introduce
˜F(x) = F(x) + R2
y
ε ∥Ax∥2,
(12)"
IMPLEMENTATION/METHODS,0.30113636363636365,where ε > 0 is the desired accuracy of the solution in terms of F(x) that we want to achieve.
IMPLEMENTATION/METHODS,0.3068181818181818,Published as a conference paper at ICOMP 2024
IMPLEMENTATION/METHODS,0.3125,"Gorbunov et al. (2019) proved that if we have ˆx such that ˜F(ˆx) −minx∈Q ˜F(x) ≤ε, then we have"
IMPLEMENTATION/METHODS,0.3181818181818182,"F(ˆx) −min
x∈Q F(x) ≤ε,
∥Aˆx∥2 ≤2ε"
IMPLEMENTATION/METHODS,0.32386363636363635,"Ry
.
(13)"
IMPLEMENTATION/METHODS,0.32954545454545453,"Then this result can be generalized to the stochastic case: if we have ˆx such that E[˜F(ˆx)] −
minx∈Q ˜F(x) ≤ε, then we have"
IMPLEMENTATION/METHODS,0.3352272727272727,"E[F(ˆx)] −min
x∈Q F(x) ≤ε,
q"
IMPLEMENTATION/METHODS,0.3409090909090909,"E∥Aˆx∥2
2 ≤2ε"
IMPLEMENTATION/METHODS,0.3465909090909091,"Ry
.
(14)"
IMPLEMENTATION/METHODS,0.3522727272727273,"Next, we consider solving this problem with the gradient sliding algorithm 1:"
IMPLEMENTATION/METHODS,0.35795454545454547,"min
x∈Q
˜F(x) = f(x) + g(x),
(15)"
IMPLEMENTATION/METHODS,0.36363636363636365,"where f(x) = 1 m m
X"
IMPLEMENTATION/METHODS,0.3693181818181818,"i=1
fi(xi),
g(x) = R2
y
ε ∥Ax∥2.
(16)"
IMPLEMENTATION/METHODS,0.375,Algorithm 1 Sliding Algorithm
IMPLEMENTATION/METHODS,0.3806818181818182,"1: Input: Initial point x0 ∈X and iteration limit N.
2: Let βk ∈R+, γk ∈R+, and Tk ∈N, k = 1, 2, . . ., be given and set x0 = x0.
3: for k = 1, 2, . . . , N do
4:
Set xk = (1 −γk)xk−1 + γkxk−1, and let hk(·) ≡lg(xk, ·), where lg(x, y) = g(x) +
⟨∇g(x), y −x⟩.
5:
Set (xk, ˜xk) = PS(hk, xk−1, βk, Tk).
6:
Set xk = (1 −γk)xk−1 + γk˜xk.
7: end for
8: Output: xN."
IMPLEMENTATION/METHODS,0.38636363636363635,"9: procedure (x+, ˜x+) = PS(h, x, β, T)
10:
Let the parameters pt ∈R+ and θt ∈[0, 1], t = 1, . . ., be given. Set u0 = ˜u0 = x.
11:
for t = 1, 2, . . . , T do"
IMPLEMENTATION/METHODS,0.39204545454545453,"12:
Set ut = arg min
u∈X"
IMPLEMENTATION/METHODS,0.3977272727272727,"n
h(u) + lf(ut−1, u) + β"
IMPLEMENTATION/METHODS,0.4034090909090909,"2 ∥u −x∥2
2 + βpt"
IMPLEMENTATION/METHODS,0.4090909090909091,"2 ∥u −ut−1∥2
2
o
."
IMPLEMENTATION/METHODS,0.4147727272727273,"13:
Set ˜ut = (1 −θt)˜ut−1 + θtut.
14:
where lf(x, y) = f(x) + ⟨f ′(x, ξ), y −x⟩.
15:
end for
16:
Set x+ = uT and ˜x+ = ˜uT .
17: end procedure"
IMPLEMENTATION/METHODS,0.42045454545454547,"We reuse the parameters in Lan (2016), then we can have this theorem:"
IMPLEMENTATION/METHODS,0.42613636363636365,Theorem 1 Assume that {pt} and {θt} in the PS procedure of algorithm 1 are set to
IMPLEMENTATION/METHODS,0.4318181818181818,pt = t
IMPLEMENTATION/METHODS,0.4375,"2
and
θt = 2(t + 1)"
IMPLEMENTATION/METHODS,0.4431818181818182,"t(t + 3) ,
∀t ≥1."
IMPLEMENTATION/METHODS,0.44886363636363635,"If N is fixed positive number, and {βk}, {γk}, and {Tk} are set to"
IMPLEMENTATION/METHODS,0.45454545454545453,βk = 2L
IMPLEMENTATION/METHODS,0.4602272727272727,"k ,
γk =
2
k + 1,
and
Tk ="
IMPLEMENTATION/METHODS,0.4659090909090909,"&
( ˆ
M 2 + σ2)Nk2 ˜DL2 ' ."
IMPLEMENTATION/METHODS,0.4715909090909091,"Then it can achieve (14) with probability at least 1 −β, β ∈(0, 1) requiring O   s"
IMPLEMENTATION/METHODS,0.4772727272727273,"λmax(A⊤A)R2yD2
Q
ε2 "
IMPLEMENTATION/METHODS,0.48295454545454547,"calculations of A⊤Ax,
(17)"
IMPLEMENTATION/METHODS,0.48863636363636365,"and
eO
(M 2 + σ2)D2
Q
ε2"
IMPLEMENTATION/METHODS,0.4943181818181818,"
calculations of F′(x, ξ),
(18)"
IMPLEMENTATION/METHODS,0.5,Published as a conference paper at ICOMP 2024
IMPLEMENTATION/METHODS,0.5056818181818182,"when f is a µ-strongly convex function, then use restart technique with algorithm 1, it can achieve
(14) with probability at least 1 −β, β ∈(0, 1) requiring eO   s"
IMPLEMENTATION/METHODS,0.5113636363636364,λmax(A⊤A)R2y µε 
IMPLEMENTATION/METHODS,0.5170454545454546,"calculations of A⊤Ax,
(19)"
IMPLEMENTATION/METHODS,0.5227272727272727,"and
eO
M 2 + σ2 µε"
IMPLEMENTATION/METHODS,0.5284090909090909,"
calculations of F′(x, ξ),
(20)"
IMPLEMENTATION/METHODS,0.5340909090909091,"where F′(x, ξ) = col(f
′
1(x, ξ) . . . f
′
m(x, ξ)), ˜D =
3
4DQ and L is the smoothness constant of g,
∥F′(x, ξ)∥2 ≤ˆ
M."
IMPLEMENTATION/METHODS,0.5397727272727273,"In this section, we first reformulate a convex optimization problem with two affine constraints into a
minimization problem by introducing penalty terms. These penalty terms arise from the combination
of the affine constraints and the variable x. We then apply the gradient sliding algorithm to this
problem, yielding the convergence rate discussed above."
IMPLEMENTATION/METHODS,0.5454545454545454,"2.2
DECENTRALIZED GRADIENT SLIDING"
IMPLEMENTATION/METHODS,0.5511363636363636,We can rewrite problem (1) into this form:
IMPLEMENTATION/METHODS,0.5568181818181818,"min
x1=···=xm
x1,x2,··· ,xm∈X
f(x) = 1 m m
X"
IMPLEMENTATION/METHODS,0.5625,"i=1
fi(xi)
(21)"
IMPLEMENTATION/METHODS,0.5681818181818182,"s.t.
Bx = 0,
(22)"
IMPLEMENTATION/METHODS,0.5738636363636364,"where x = col(x1, . . . , xm). As we mentioned before, each agent i store individual objective func-
tion fi in this network, and when x1 = x2 = . . . = xm, Wx will be equal to 0 in our setting.
Therefore, we introduce Wx in (24) as a penalty term to ensure that each xi converges to the opti-
mal solution, then we can reformulate problem (21) into this form:"
IMPLEMENTATION/METHODS,0.5795454545454546,"min
Wx=0,
Bx=0,
x∈X m⊂Rmd"
IMPLEMENTATION/METHODS,0.5852272727272727,"f(x) = 1 m m
X"
IMPLEMENTATION/METHODS,0.5909090909090909,"i=1
fi(xi)
(23)"
IMPLEMENTATION/METHODS,0.5965909090909091,"Then we can directly apply result in section 2.1,"
IMPLEMENTATION/METHODS,0.6022727272727273,"min
x∈X m ˜F(x) = F(x) + R2
y
ε ∥Ax∥2,
(24)"
IMPLEMENTATION/METHODS,0.6079545454545454,where F(x) = 1
IMPLEMENTATION/METHODS,0.6136363636363636,"m
Pm
i=1 fi(xi), and A⊤= [B⊤
γW]."
IMPLEMENTATION/METHODS,0.6193181818181818,"From assumption 2, we can know that ∥f ′
i(xi)∥2 ≤M, for all xi ∈X, all fi are convex functions,
then set x⊤
0 = (x⊤
0 , . . . , x⊤
0 )⊤and x⊤
∗= (x⊤
∗, . . . , x⊤
∗)⊤is the optimality point for (24), from
Gorbunov et al. (2019) we can get"
IMPLEMENTATION/METHODS,0.625,"D2
X m = mD2
X ,
∥∇f(x)∥2 ≤M
√m,
R2
y
def
= ∥y∗∥2
2 ≤
M 2"
IMPLEMENTATION/METHODS,0.6306818181818182,"mλmin(A⊤A).
(25)"
IMPLEMENTATION/METHODS,0.6363636363636364,"We now need to apply the results obtained in Section 2.1 to the problem (24). To produce a point
ˆx that satisfies (14), where ˆx = ˆx, A⊤:= [B⊤
γW], Q := X m, and Ry := Ry, Algorithm 1
applied to the penalized problem (24) , achieving (14) with probability at least 1 −β, β ∈(0, 1), it
requires communication complexity and computation complexity same as in Theorem 1."
IMPLEMENTATION/METHODS,0.6420454545454546,"By accurately choosing factor γ, we can control the condition number χ(A⊤A). The minimal value"
IMPLEMENTATION/METHODS,0.6477272727272727,"of χ(A⊤A) is attained at γ2 = λ+
min(B⊤B)
(λ+
min(W ))2 and equals χ(A⊤A) = χ(B⊤B) + χ2(W) in (Rogozin"
IMPLEMENTATION/METHODS,0.6534090909090909,"et al., 2022). Then achieving (14) with probability at least 1 −β, β ∈(0, 1), algorithm 1 requires"
IMPLEMENTATION/METHODS,0.6590909090909091,"eO
(M 2 + σ2)D2
X
ε2"
IMPLEMENTATION/METHODS,0.6647727272727273,"
calculations of f ′(x, ξ) per node.
(26)"
IMPLEMENTATION/METHODS,0.6704545454545454,Published as a conference paper at ICOMP 2024 and O r
IMPLEMENTATION/METHODS,0.6761363636363636,"χ2(W)MD2
X
ε2 !"
IMPLEMENTATION/METHODS,0.6818181818181818,"communications,
(27) and O r"
IMPLEMENTATION/METHODS,0.6875,"χ(B⊤B)MD2
X
ε2 !"
IMPLEMENTATION/METHODS,0.6931818181818182,"multiplications by B⊤B per node.
(28)"
IMPLEMENTATION/METHODS,0.6988636363636364,"When fi is a µ-strongly convex function, then it can achieve 14 with probability at least 1 −β,
β ∈(0, 1) requiring"
IMPLEMENTATION/METHODS,0.7045454545454546,"eO
M 2 + σ2 µε"
IMPLEMENTATION/METHODS,0.7102272727272727,"
calculations of f ′(x, ξ) per node,
(29) and eO s"
IMPLEMENTATION/METHODS,0.7159090909090909,χ2(W)M µε !
IMPLEMENTATION/METHODS,0.7215909090909091,"communications,
(30) and eO   s"
IMPLEMENTATION/METHODS,0.7272727272727273,χ(B⊤B)M µε 
IMPLEMENTATION/METHODS,0.7329545454545454,"multiplications by B⊤B per node.
(31)"
IMPLEMENTATION/METHODS,0.7386363636363636,"In this section, we reformulate problem (1) into a convex optimization problem with two affine
constraints. Next, we apply the method from Section 2.1, which allows us to obtain the convergence
rate for problem (1)."
CONCLUSION/DISCUSSION ,0.7443181818181818,"3
CONCLUSION"
CONCLUSION/DISCUSSION ,0.75,"In this paper, we have addressed the problem of decentralized convex optimization with affine con-
straints. We introduce a novel approach that extends the gradient sliding method to incorporate a
nonsmooth stochastic oracle, resulting in a decentralized algorithm that achieves linear convergence
for such optimization problems. This work overcomes the limitations of previous methods by pro-
viding a practical solution that advances the theoretical understanding of distributed optimization.
However, our approach relies on the gradient sliding algorithm, which requires parameter estima-
tion before implementation, slightly weakening its theoretical performance. In our experiments, we
showed that the effect of choice for different parameters R and T, as in Figure 1."
CONCLUSION/DISCUSSION ,0.7556818181818182,"Future work will focus on extending the algorithm to handle biased stochastic oracle and non-convex
objectives, as well as exploring adaptive strategies to dynamically adjust the parameters of the algo-
rithm based on the network topology and the structure of the optimization problem."
RESULTS/EXPERIMENTS,0.7613636363636364,"4
NUMERICAL EXPERIMENTS"
RESULTS/EXPERIMENTS,0.7670454545454546,We conducted numerical experiments on the following optimization problem:
RESULTS/EXPERIMENTS,0.7727272727272727,"min
x f(x) := 1 n n
X"
RESULTS/EXPERIMENTS,0.7784090909090909,"i=1
fi(x)
subject to Bx = 0, where"
RESULTS/EXPERIMENTS,0.7840909090909091,fi(x) = r
RESULTS/EXPERIMENTS,0.7897727272727273,"1
m∥Cix −di∥2,"
RESULTS/EXPERIMENTS,0.7954545454545454,"with Ci ∈Rm×d, di ∈Rm×1, and x ∈Rd."
RESULTS/EXPERIMENTS,0.8011363636363636,"The algorithm was tested on four nodes within a single machine. For simplicity, local variables were
stored in a single long vector. The dimension of each local variable was set to 5, and the number of
samples was 1,000. The algorithm was run with a batch size of 100 over 2,000 iterations. Instead of
estimating the parameters, we experimented with various values of the inner loop T and the penalty
term coefficient R = Ry"
RESULTS/EXPERIMENTS,0.8068181818181818,"ϵ . We found that T = 3 provided good performance, leading us to compare
different values of R. Additionally, four distinct network topologies (complete graph, path graph,
cycle graph, and star graph) were used in this experiment. The script and data that support the
findings of this study are available from the corresponding author upon reasonable request."
RESULTS/EXPERIMENTS,0.8125,Published as a conference paper at ICOMP 2024
RESULTS/EXPERIMENTS,0.8181818181818182,"0
1000
2000
Step 10
2 10
1 100"
RESULTS/EXPERIMENTS,0.8238636363636364,Loss Ratio T = 3
RESULTS/EXPERIMENTS,0.8295454545454546,"0
1000
2000
Step T = 5"
RESULTS/EXPERIMENTS,0.8352272727272727,"0
1000
2000
Step T = 7 R"
RESULTS/EXPERIMENTS,0.8409090909090909,"0.001
0.01
0.1"
RESULTS/EXPERIMENTS,0.8465909090909091,"Figure 1: Loss ratio for different choices of T on a complete graph. The choice of T affects the
convergence rate, but the parameter R has a more significant impact. A smaller R leads to faster
convergence, though it results in less consensus among the local variables xi."
RESULTS/EXPERIMENTS,0.8522727272727273,"0
1000
2000
Step 10
2 10
1 100"
RESULTS/EXPERIMENTS,0.8579545454545454,Loss Ratio
RESULTS/EXPERIMENTS,0.8636363636363636,Shape = path
RESULTS/EXPERIMENTS,0.8693181818181818,"0
1000
2000
Step"
RESULTS/EXPERIMENTS,0.875,Shape = cycle
RESULTS/EXPERIMENTS,0.8806818181818182,"0
1000
2000
Step"
RESULTS/EXPERIMENTS,0.8863636363636364,Shape = star R
RESULTS/EXPERIMENTS,0.8920454545454546,"0.001
0.01
0.1"
RESULTS/EXPERIMENTS,0.8977272727272727,Figure 2: Loss ratio for different choice of network structure.
OTHER,0.9034090909090909,ACKNOWLEDGMENTS
OTHER,0.9090909090909091,The research was supported by Russian Science Foundation (project No. 23-11-00229).
REFERENCES,0.9147727272727273,REFERENCES
REFERENCES,0.9204545454545454,"Dimitri Bertsekas and John Tsitsiklis. Parallel and distributed computation: numerical methods.
Athena Scientific, 2015."
REFERENCES,0.9261363636363636,"John C Duchi, Alekh Agarwal, and Martin J Wainwright. Dual averaging for distributed optimiza-
tion: Convergence analysis and network scaling. IEEE Transactions on Automatic control, 57(3):
592–606, 2011."
REFERENCES,0.9318181818181818,"Eduard Gorbunov, Darina Dvinskikh, and Alexander Gasnikov. Optimal decentralized distributed
algorithms for stochastic convex optimization. arXiv preprint arXiv:1911.07363, 2019."
REFERENCES,0.9375,"Bjorn Johansson, Tam´as Keviczky, Mikael Johansson, and Karl Henrik Johansson. Subgradient
methods and consensus algorithms for solving convex optimization problems. In 2008 47th IEEE
Conference on Decision and Control, pp. 4185–4190. IEEE, 2008."
REFERENCES,0.9431818181818182,"Guanghui Lan. Gradient sliding for composite optimization. Mathematical Programming, 159:
201–235, 2016."
REFERENCES,0.9488636363636364,"Ion Necoara and Valentin Nedelcu. Distributed dual gradient methods and error bound conditions.
arXiv preprint arXiv:1401.4398, 2014."
REFERENCES,0.9545454545454546,"Ion Necoara, Valentin Nedelcu, and Ioan Dumitrache. Parallel and distributed optimization methods
for estimation and control in networks. Journal of Process Control, 21(5):756–766, 2011."
REFERENCES,0.9602272727272727,"Angelia Nedic and Asuman Ozdaglar. Distributed subgradient methods for multi-agent optimiza-
tion. IEEE Transactions on Automatic Control, 54(1):48–61, 2009."
REFERENCES,0.9659090909090909,"Angelia Nedic, Asuman Ozdaglar, and Pablo A Parrilo. Constrained consensus and optimization in
multi-agent networks. IEEE Transactions on Automatic Control, 55(4):922–938, 2010."
REFERENCES,0.9715909090909091,"Alexander Rogozin, Demyan Yarmoshik, Ksenia Kopylova, and Alexander Gasnikov. Decentral-
ized strongly-convex optimization with affine constraints: Primal and dual approaches. In Inter-
national Conference on Optimization and Applications, pp. 93–105. Springer, 2022."
REFERENCES,0.9772727272727273,Published as a conference paper at ICOMP 2024
REFERENCES,0.9829545454545454,"Kevin Scaman, Francis Bach, S´ebastien Bubeck, Yin Tat Lee, and Laurent Massouli´e. Optimal
algorithms for smooth and strongly convex distributed optimization in networks. In international
conference on machine learning, pp. 3027–3036. PMLR, 2017."
REFERENCES,0.9886363636363636,"John N Tsitsiklis. Problems in decentralized decision making and computation. PhD thesis, Mas-
sachusetts Institute of Technology, 1984."
REFERENCES,0.9943181818181818,"Deming Yuan and Daniel WC Ho. Randomized gradient-free method for multiagent optimization
over time-varying networks. IEEE Transactions on Neural Networks and Learning Systems, 26
(6):1342–1347, 2014."
