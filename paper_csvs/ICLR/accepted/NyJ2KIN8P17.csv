Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0021413276231263384,"Aiming to find a program satisfying the user intent given input-output examples,
program synthesis has attracted increasing interest in the area of machine learning.
Despite the promising performance of existing methods, most of their success
comes from the privileged information of well-designed input-output examples.
However, providing such input-output examples is unrealistic because it requires
the users to have the ability to describe the underlying program with a few input-
output examples under the training distribution. In this work, we propose a query-
based framework that trains a query neural network to generate informative input-
output examples automatically and interactively from a large query space. The
quality of the query depends on the amount of the mutual information between
the query and the corresponding program, which can guide the optimization of
the query framework. To estimate the mutual information more accurately, we
introduce the functional space (F-space) which models the relevance between the
input-output examples and the programs in a differentiable way. We evaluate the
effectiveness and generalization of the proposed query-based framework on the
Karel task and the list processing task. Experimental results show that the query-
based framework can generate informative input-output examples which achieve
and even outperform well-designed input-output examples."
INTRODUCTION,0.004282655246252677,"1
INTRODUCTION"
INTRODUCTION,0.006423982869379015,"Program synthesis is the task of automatically finding a program that satisfies the user intent ex-
pressed in the form of some specifications like input-output examples (Gulwani et al., 2017). Re-
cently, there has been an increasing interest in tackling it using neural networks in various domains,
including string manipulation (Gulwani, 2011; Gulwani et al., 2012; Devlin et al., 2017b), list pro-
cessing (Balog et al., 2017; Zohar & Wolf, 2018) and graphic applications (Ellis et al., 2018; 2019)."
INTRODUCTION,0.008565310492505354,"Despite their promising performance, most of their success relies on the well-designed input-output
examples, without which the performance of the program synthesis model drops heavily. For exam-
ple, in Karel (Devlin et al., 2017b; Bunel et al., 2018), the given input-output examples are required
to have a high branch coverage ratio on the test program; In list processing, the given input-output
examples are guided by constraint propagation (Balog et al., 2017) to ensure their effectiveness on
the test program. However, providing such input-output examples is unrealistic because it requires
the users to be experienced in programming to describe the underlying program with several input-
output examples. Worse, the users must be familiar with the distribution of the training dataset to
prevent themselves from providing out-of-distribution examples (Shin et al., 2019). In summary,
how to generate informative input-output examples without expert experience is still an important
problem that remains a challenge."
INTRODUCTION,0.010706638115631691,"In this paper, we propose a query-based framework to automatically and efficiently generate infor-
mative input-output examples from a large space, which means that the underlying program can be
easily distinguished with these examples. This framework consists of two parts: the query network"
INTRODUCTION,0.01284796573875803,"‚àóCorresponding author. Contact: {huangdi20b, zhangrui}@ict.ac.cn."
INTRODUCTION,0.014989293361884369,Published as a conference paper at ICLR 2022
INTRODUCTION,0.017130620985010708,Predicted program
INTRODUCTION,0.019271948608137045,"Generate
Synthesize
Interact
Embed"
INTRODUCTION,0.021413276231263382,"Query network
Synthesis network
User intent (program)
Input
Output"
INTRODUCTION,0.023554603854389723,def run():
INTRODUCTION,0.02569593147751606,"move()
putMarker()
turnRight()
move()"
INTRODUCTION,0.027837259100642397,"Figure 1: The query-based framework. The query network generates informative input-output exam-
ples by interacting with the user, and then the generated examples are sent to the synthesis network
to synthesize the underlying program."
INTRODUCTION,0.029978586723768737,"and the synthesis network, and each part is trained separately. The query network is trained to gen-
erate the input-output examples in an iterative manner, and then the synthesis network is trained to
synthesize the program with the input-output examples generated by the query network. It has three
advantages: (1) There is no demand for well-designed input-output examples in both training and
testing, which leads to a good generalization. (2) The query network works in an efficiently gener-
ative manner, which can essentially reduce the computation cost while facing problems with large
input-output space. (3) The query network serves as a plug-and-play module with high scalability,
for it is separated from the program synthesis process entirely."
INTRODUCTION,0.032119914346895075,"To train the query network, the key idea is to model the query process as a decision tree and find
out that the informativeness of the input-output examples is associated with the amount of mutual
information (i.e.the information gain in the decision tree) between the input-output examples and
the programs, and thus the query network can be optimized by maximizing the mutual informa-
tion. The mutual information can be approximated by the InfoNCE loss (van den Oord et al., 2018),
which depends on the relevance between the samples. However, due to the many-to-many relation-
ship between the input-output examples and the programs, the relevance is difficult to be measured
straightforwardly. To this end, we introduce the functional space (F-space). In F-space, each pro-
gram can be projected into a vector, and each input-output example corresponds to a set of candidate
programs, which can be represented by a normal distribution (Sun & Nielsen, 2019). Whenever a
new example is queried, the new set of candidate programs is produced by the intersection of the
two original sets of programs, and the new distribution is produced by the product of the two origi-
nal distributions. The more the queried examples, the smaller the size of the program set, the lower
the entropy of the distribution. With the InfoNCE loss and F-space, the query network is trained
to generate the input-output examples whose F-space distribution can maximize the probability of
the corresponding program and minimize the probability of the others. Once the query network is
trained, the training of the synthesis network is no different from what other researchers have done
before, except that the input-output examples are generated by the query network."
INTRODUCTION,0.034261241970021415,"We evaluate our method on the Karel task and the list processing task which have large input spaces.
Without utilizing the well-designed input-output examples both in training and testing, we achieve
and even outperform the state-of-the-art performance on the Karel task and list processing task,
which shows the effectiveness and generalization of our query-based framework."
PROBLEM STATEMENT,0.03640256959314775,"2
PROBLEM STATEMENT"
PROBLEM STATEMENT,0.03854389721627409,"Intuitively, consider an oracle that contains some kind of symbolic rules (e.g.programs), our goal
is to discover these symbolic rules inside this oracle. To do this, the traditional program synthesis
assumes that the oracle can provide some informative signals (e.g.input-output examples) automat-
ically, based on which the synthesizer can find the rules. However, this is a strong assumption with
high requirements on the oracle that is impractical in many cases. In this work, we consider a query
problem where the informative signals are gained actively by querying the oracle under a much
weaker assumption that the behavior of the oracle is deterministic (i.e.the same input always results
in the same output)."
PROBLEM STATEMENT,0.04068522483940043,"Following the intuition, a reasonable solution for the query problem would be ‚Äùmaking the programs
distinguishable with as few queries as possible‚Äù. To make this statement concrete and practical, we
introduce the following formulations."
PROBLEM STATEMENT,0.042826552462526764,Published as a conference paper at ICLR 2022
PROBLEM STATEMENT,0.044967880085653104,"First, we define the functional equivalence, which is consistent with the definition of the equivalence
of functions in mathematics.
Definition 2.1 (Functional equivalence). Let I be the input example domain containing all valid
input examples, O be the output example domain containing all possible output examples, and P be
the program domain containing all valid programs under the domain specific language (DSL), each
program p ‚ààP can be seen as a function p : I ‚ÜíO. For two programs pi ‚ààP and pj ‚ààP, pi and
pj are functional equivalent if and only if ‚àÄx ‚ààI, pi(x) = pj(x)."
PROBLEM STATEMENT,0.047109207708779445,"Using the concept of functional equivalence, we can formulate the program synthesis task:
Definition 2.2 (Program synthesis). Suppose there is an underlying program p ‚ààP and K input-
output examples JeK = {(xk, yk)|(xk, yk) ‚ààI √ó O, k = 1 ¬∑ ¬∑ ¬∑ K} generated by it, the program
synthesis task aims to find a program ÀÜp which is functional equivalent to p using JeK."
PROBLEM STATEMENT,0.04925053533190578,"Following the definitions above, we can define the task of the query.
Definition 2.3 (Query). Given a program p ‚ààP and a set of history K input-output examples JeK,
the query process firstly generates a query by the query network fq: xK+1 = fq(JeK) ‚ààI. Then, a
corresponding response is given by the program yK+1 = p(xK+1) ‚ààO. The query and response
are added to the history input-output examples: JeK ‚ÜêJeK ‚à™{(xK+1, yK+1)} and this process
repeats."
PROBLEM STATEMENT,0.05139186295503212,"The query process aims to distinguish the underlying program with as few queries as possible, based
on which we can define the optimal query strategy.
Definition 2.4 (The optimal query strategy). Given a set of programs P and a target program p‚àó,
the optimal query strategy Q aims to distinguish the p‚àóby generating as few input-output examples
JeK as possible."
PROBLEM STATEMENT,0.05353319057815846,"When the query space is large, it is impractical to find the optimal query strategy by direct search.
Thus, we take the query process as the expansion of a decision tree where the leaves are the pro-
grams, the nodes are the queries, and the edges are the responses, and then the generation of queries
can be guided by the information gain, which is also known as the mutual information:
JeK‚àó= arg max
JeK
I(P; JeK),
(1)"
METHODS,0.055674518201284794,"3
METHODS"
METHODS,0.057815845824411134,"The mutual information is hard to calculate due to the large spaces of queries and programs. To this
end, we resort to the InfoNCE loss (van den Oord et al., 2018) which estimates the lower bound of
the mutual information:"
METHODS,0.059957173447537475,"LNCE = ‚àíE[log(
exp(f(JeK, pn))
PN
i=1 exp(f(JeK, pi))
)],
(2)"
METHODS,0.06209850107066381,"and
I(P; JeK) ‚â•log(N) ‚àíLNCE,
(3)
where f(¬∑, ¬∑) denotes a relevance function. Maximizing the mutual information is equivalent to min-
imizing LNCE. Intuitively, InfoNCE maximizes the relevance between the positive pairs and mini-
mizes the relevance between the negative pairs. Specifically, for a batch of data {(JeKn, pn), pn}N,
we construct positive pairs as {(JeKi, pi)} and negative pairs as {(JeKi, pj)|i Ã∏= j}. Traditionally,
the relevance is defined as the dot product of the samples, which may be inaccurate for the many-
to-many relationship between the input-output examples and the programs. Thus next, we will
introduce functional space (F-space) to model the relationship properly."
F-SPACE,0.06423982869379015,"3.1
F-SPACE"
F-SPACE,0.06638115631691649,"Definition 3.1 (F-space and functional distance). F-space is a |I| dimensional space which consists
of all valid programs that can be implemented by program domain P. Each program is represented
by |I| different output examples v = (y1, y2, . . . , y|I|). The distance in F-space can be measured by
the number of different output examples: d(vi, vj) = |diff(vi, vj)|."
F-SPACE,0.06852248394004283,Published as a conference paper at ICLR 2022 ùëí p
F-SPACE,0.07066381156316917,"F-space
F-space
F-space
ùëíùëñ‚äÜùëíùëó
ùëí= ùëíùëñ‚ãÉùëíùëó"
F-SPACE,0.0728051391862955,"Figure 2: The illustration of F-space. Left: The projection of the input-output examples JeK and
program p; Middle: The subset relationship between JeKi and JeKj. Note that this relation is opposite
in F-space; Right: The union operation of JeKi and JeKj. This operation is also opposite in F-space
where an union operation correspond to an intersection operation in F-space."
F-SPACE,0.07494646680942184,"Intuitively, F-space (P, d) measures the functional differences between programs. Each program
can be represented by a vector in F-space, and if different programs are represented by the same
vector v = (y1, y2, . . . , y|I|), it indicates that these two programs get the same results for all inputs,
and they are considered to be functionally equivalent. This is also consistent with Definition 2.1.
In practice, a space with dimension |I| is too large to compute, and thus we utilize the sparsity of
F-space and learn an approximate space with dimension reduction by neural networks."
F-SPACE,0.07708779443254818,"Regarding input-output examples, representing them by vectors is not appropriate. Consider a set of
input-output examples JeK = {(xk, yk)}K, we cannot find a vector that represents it when K < |I|
because there are more than one programs that satisfies these K input-output examples."
F-SPACE,0.07922912205567452,"Formally, we summarize the properties of the representation of input-output examples in F-space as
follows:"
F-SPACE,0.08137044967880086,"‚Ä¢ Each set of input-output examples JeK = {(xk, yk)}K should be represented by a set of
F-space vectors JrK = {vn}N.
‚Ä¢ For two sets of input-output examples JeKi and JeKj, if JeKi ‚äÜJeKj, then their F-space
representations JrKi and JrKj have the relationship JrKi ‚äáJrKj.
‚Ä¢ For two sets of input-output examples JeKi and JeKj, suppose JeK‚Ä≤ = JeKi ‚à©JeKj, then in
F-space, their corresponding representations have the relationship JrK‚Ä≤ = JrKi ‚à™JrKj
‚Ä¢ Similarly, if JeK‚Ä≤ = JeKi ‚à™JeKj, then in F-space, their corresponding representations have
the relationship JrK‚Ä≤ = JrKi ‚à©JrKj"
F-SPACE,0.0835117773019272,"Additionally, this representation should be differentiable and thus can be optimized by neural net-
works. To this end, we model the representation of JeK as a Normal distribution (Ren & Leskovec,
2020; Sun & Nielsen, 2019), where the probability of the distribution indicates the possibility that
it is the underlying program to be synthesized given input-output examples JeK. We illustrate the
projection, the subset relationship, and the union/intersection operation of distributions in Figure 2.
Under this representation, the query process becomes the process of reducing the uncertainty of the
distribution. To train the query network, we define several neural operators for the neural network
training as follows."
F-SPACE,0.08565310492505353,"Program projection.
To project a program p to a vector v in F-space, we traditionally use a
sequence model as our encoder:
v = Encoderp(p).
(4)
Note that the program synthesis model differs largely on different datasets, so we choose to vary
our program encoder according to the specific program synthesis models on different datasets. In
practice, our program encoder is the reverse of the program synthesis decoder."
F-SPACE,0.08779443254817987,"Input-output example projection.
Given a single input-output example JeK = {(x, y)}, we can
project it into a Normal distribution using the same architecture of the corresponding program syn-
thesis model, except that we add an MLP to output the two parameters of the Normal distribution:
¬µ and log(œÉ2).
[¬µ, log(œÉ2)] = MLPe(Encodere(JeK)),
(5)
where MLP means a multi-layer perceptron."
F-SPACE,0.08993576017130621,Published as a conference paper at ICLR 2022 Query
F-SPACE,0.09207708779443255,"ùë•1, ùë¶1 ‚Ä¶‚Ä¶"
F-SPACE,0.09421841541755889,"ùë•ùë°‚àí1, ùë¶ùë°‚àí1 ùë•ùë° Query ùë•ùë°+1 Query ùë•ùë°+2"
F-SPACE,0.09635974304068523,InfoNCE loss
F-SPACE,0.09850107066381156,Program
F-SPACE,0.1006423982869379,"ùë•1, ùë¶1 ‚Ä¶‚Ä¶"
F-SPACE,0.10278372591006424,"ùë•ùë°‚àí1, ùë¶ùë°‚àí1"
F-SPACE,0.10492505353319058,"ùë•ùë°, ùë¶ùë°
ùë•ùë°+1, ùë¶ùë°+1"
F-SPACE,0.10706638115631692,"ùë•1, ùë¶1 ‚Ä¶‚Ä¶"
F-SPACE,0.10920770877944326,"ùë•ùë°‚àí1, ùë¶ùë°‚àí1"
F-SPACE,0.11134903640256959,"ùë•ùë°, ùë¶ùë°"
F-SPACE,0.11349036402569593,"Program
Program
‚Ä¶‚Ä¶ ‚Ä¶‚Ä¶"
F-SPACE,0.11563169164882227,InfoNCE
F-SPACE,0.11777301927194861,"loss
InfoNCE loss"
F-SPACE,0.11991434689507495,Figure 3: The recurrent training process.
F-SPACE,0.12205567451820129,"Input-output examples intersection.
Given K input-output examples JeK = {(xk, yk)}K, each
example {(xk, yk)} is represented by a Normal distribution Prk = N(¬µk, œÉk) using the projector
above. The purpose of the intersection is to aggregate these Normal distributions into a new one,
which represents JeK in F-space. Under the assumption of independence, the probability of the
intersection distribution should be:"
F-SPACE,0.12419700214132762,"PrJeK = K
Y"
F-SPACE,0.12633832976445397,"k=1
Prk.
(6)"
F-SPACE,0.1284796573875803,"Fortunately, the product of independent Normal distributions is still a Normal distribution, which
means that we can represent it as [¬µ‚Ä≤, log(œÉ‚Ä≤2)]. In practice, we utilize the attention mechanism
with another MLP to let the neural network learn the new Normal distribution (Ren & Leskovec,
2020):"
F-SPACE,0.13062098501070663,"[¬µ‚Ä≤, log(œÉ‚Ä≤2)] = K
X"
F-SPACE,0.13276231263383298,"i=1
wi[¬µi, log(œÉ2
i )],
(7)"
F-SPACE,0.1349036402569593,"wi =
exp(MLPattention([¬µi, log(œÉ2
i )]))
PK
j=1 exp(MLPattention(¬µj, log(œÉ2
j )))
.
(8)"
F-SPACE,0.13704496788008566,"This formulation not only keeps the form of distributions closed but also approximates the mode of
the effective support of Normal distributions, which satisfies our requirement on the intersection of
distribution (Sun & Nielsen, 2019).
We give detailed proof on the reasonability of doing this in
Appendix C.1."
F-SPACE,0.139186295503212,"Inverse projection to query.
Finally, we need to generate a new query from the representation
of input-output examples in F-space. Using the projection and the intersection operation mentioned
above, we can project the K input-output examples into the representation [¬µ‚Ä≤, log(œÉ‚Ä≤2)]. To gener-
ate query xnew from this representation, we introduce a decoder which has a similar architecture to
Encodere but reversed:
xnew = Decoder([¬µ‚Ä≤, log(œÉ‚Ä≤2)]).
(9)"
F-SPACE,0.14132762312633834,"With these operators, we can model the relevance between input-output examples and programs as
the probability in the distributions in F-space, and rewrite the loss in Equation 2 as"
F-SPACE,0.14346895074946467,"LNCE = ‚àíE[log(
exp(N(pn; ¬µ‚Ä≤, œÉ‚Ä≤))
PN
i=1 exp(N(pi; ¬µ‚Ä≤, œÉ‚Ä≤)
)],
(10)"
F-SPACE,0.145610278372591,"Next, we will introduce how to train the neural network."
F-SPACE,0.14775160599571735,Published as a conference paper at ICLR 2022
TRAINING,0.14989293361884368,"3.2
TRAINING"
TRAINING,0.15203426124197003,"As mentioned above, the query network is optimized by maximizing the mutual information.
We
observe that taking previous query examples as the condition and only optimizing the query strat-
egy at the current query step is a greedy optimization, which may fail into the local minima more
easily. An example is shown in Appendix C.2. Thus, a recurrent training process is adopted to grep
the global mutual information on every step instead of the mutual information conditioned on the
previous examples. See Figure 3 and Algorithm 1."
TRAINING,0.15417558886509636,"Additionally, like the task of sequence generation, we need an input-output example to act as the
start signal < sos >. However, different datasets differ largely in program synthesis, which makes
the design of a universal start signal difficult. Thus, we design specific start signals for each dataset
separately. For example, in Karel, the signal is designed to be an empty map with the robot at
the center of the map; In list processing, the signal is just three lists full of NULL. More training
details such as the network architectures, the processing of datasets, training tricks, can be seen in
Appendix A."
EXPERIMENTS,0.15631691648822268,"4
EXPERIMENTS"
EXPERIMENTS,0.15845824411134904,"We studied three problems in our experiments. (1) The metric that is reasonable in our query-based
framework. (2) The performance of the query-based framework. (3) The generalization ability on
different tasks of the query-based framework. To do this, first, we demonstrate a comparison among
several program synthesis metrics. Then, we present our results of the query on the Karel dataset
and the list processing dataset to show our methods‚Äô performance and generalization ability."
METRICS,0.16059957173447537,"4.1
METRICS"
METRICS,0.16274089935760172,There are three metrics in neural program synthesis.
METRICS,0.16488222698072805,"‚Ä¢ Semantics: Given 5 input-output examples, if the predicted program satisfies all these
examples, then it is semantically correct.
‚Ä¢ Generalization: Given 5 input-output examples and a held-out input-output example, if
the predicted program satisfies all 6 examples, then it is generally correct.
‚Ä¢ Exact match: If the predicted program is the same as the ground-truth program, then it
matches the ground-truth exactly."
METRICS,0.1670235546038544,"Among them, the exact match is the most strict metric and generalization is the second one. In
practice, the exact match has its drawback in that the predicted program may be different from
the ground-truth program, but they are functionally equivalent. Thus, the performance is measured
by generalization on Karel and semantics on list processing traditionally. However, generalization
is not appropriate here for two reasons: (1) It can only measure the performance of the program
synthesis process instead of the query process. In the query process, the network chooses input-
output examples independently, and judging them by the held-out example is meaningless. (2) Even
for the program synthesis process without query, generalization is not strict enough. The program
that satisfies a small set of input-output examples may fail on a larger set of input-output examples.
Thus, the best choice is to use functional equivalence as our metric. Unfortunately, the judgment
of functional equivalent is a notoriously difficult problem which makes it hard to be applied in
evaluation. To alleviate this problem, we generate 95 held-out input-output examples randomly to
achieve a higher branch coverage than 1 held-out example, and make the generalization on these
examples a proxy of the functional equivalence:"
METRICS,0.16916488222698073,"‚Ä¢ Functional equivalence (proxy): Given 5 input-output examples and 95 held-out input-
output examples, if the predicted program satisfies all 100 examples, then it is functional
equivalent to the ground-truth program."
METRICS,0.17130620985010706,"To illustrate the difference between functional equivalence and generalization further, we measured
the average branch coverage of these two metrics on Karel‚Äôs validation set. Given a set of input-
output examples, branch coverage evaluates the percentage of program branches that are covered by
the examples."
METRICS,0.1734475374732334,Published as a conference paper at ICLR 2022
METRICS,0.17558886509635974,"Table 2: The performance of the program synthesis model trained on input-output examples gener-
ated by different methods on the Karel task."
METRICS,0.1777301927194861,"Metric
Bunel et al. (2018)
Chen et al. (2019)
Random
Well-designed
Query
Random
Well-designed
Query"
METRICS,0.17987152034261242,"Exact match
29.44%
41.16%
41.12%
26.08%
37.36%
38.68%
Functional equivalence
33.08%
48.52%
46.64%
32.28%
47.60%
48.48%"
METRICS,0.18201284796573874,"Semantics
Generalization
FE"
METRICS,0.1841541755888651,"Branch coverage
86.57%
87.99%
97.58%"
METRICS,0.18629550321199143,"Table 1: The branch coverage of semantics, general-
ization and functional equivalence (FE)."
METRICS,0.18843683083511778,"The result is shown in Table 1. Functional
equivalence outperforms generalization by
nearly 10%, which indicates that functional
equivalence can represent the correctness of
the predicted program much better than gen-
eralization."
KAREL TASK,0.1905781584582441,"4.2
KAREL TASK"
KAREL TASK,0.19271948608137046,"Karel is an educational programming lan-
guage used to control a robot living in a 2D grid world (Pattis et al., 1981). The domain-specific
language (DSL) and other details are included in Appendix B.1."
KAREL TASK,0.1948608137044968,"Settings.
Following Section 3, we split the training process into the training of the query network
and the training of the synthesis network. For the query network, we set Encodere the same as the
one of Bunel et al. (2018) except for the output layer, and Encoderp a two-layer LSTM (see details
in Appendix A.2). For the synthesis network, all settings stay unchanged as in the original program
synthesis method. We report the top-1 results with beam size 100 for Bunel et al. (2018) and 64 for
Chen et al. (2019) which is the default setting for validation in the original code. As in Section 4.1,
exact match and functional equivalence are more appropriate than other metrics in the query task,
so we save the checkpoints based on the best exact match instead of the best generalization (for the
computation inefficiency of functional equivalence), which may cause differences in our baseline
reproduction."
KAREL TASK,0.19700214132762311,"We generate the dataset with 5 input-output examples using three different methods: randomly
selected (random), baseline models (well-designed), and our method (query). Then, we train the
synthesis network on these datasets with two state-of-the-art methods: Bunel et al. (2018) and Chen
et al. (2019). Note that there is a slight difference between the program simulators used by them
which will give different responses during the query process, and we choose the one in Bunel et al.
(2018) as ours."
KAREL TASK,0.19914346895074947,"Dataset Performance.
Table 2 presents the performance of the trained synthesis networks, from
which we can conclude that (1) The queried dataset performs well on both two training methods,
indicating that the query process is totally decoupled with the synthesis process and has a high
generality. (2) Our query method gets comparable results with both baseline methods and largely
outperforms the random selection method with more than 10%, which shows its effectiveness."
KAREL TASK,0.2012847965738758,"1
2
3
4
5
Number of queries 5% 10% 15% 20% 25% 30% 35% 40%"
KAREL TASK,0.20342612419700215,Exact match
KAREL TASK,0.20556745182012848,"Query
Random
Well-designed
QBC-crash-aware
QBC-crash-unaware"
KAREL TASK,0.20770877944325483,"1
2
3
4
5
Number of queries 15% 20% 25% 30% 35% 40% 45% 50%"
KAREL TASK,0.20985010706638116,Functional equivalence
KAREL TASK,0.21199143468950749,"Query
Random
Well-designed
QBC-crash-aware
QBC-crash-unaware"
KAREL TASK,0.21413276231263384,Figure 4: The query performance of different methods.
KAREL TASK,0.21627408993576017,"Comparison on query.
We also
compared our method with query by
committee (QBC) Seung et al. (1992)
as another baseline, shown in Figure 4.
In QBC, we sample queries based on
their diversity.
That is, we generate
program candidates by beam search,
and then select the query that can re-
sult in the most diverse outputs on
these program candidates. The diver-
sity is measured by the output equiv-
alence. Algorithm details can be seen"
KAREL TASK,0.21841541755888652,Published as a conference paper at ICLR 2022
KAREL TASK,0.22055674518201285,"0.0
0.2
0.4
0.6
0.8
1.0
0.0 0.2 0.4 0.6 0.8 1.0"
KAREL TASK,0.22269807280513917,"0
10
20
30
Number of epochs 10% 20% 30% 40%"
KAREL TASK,0.22483940042826553,Exact match
KAREL TASK,0.22698072805139186,"Well-designed
Query
Random"
KAREL TASK,0.2291220556745182,"0
10
20
30
Number of epochs 10% 20% 30% 40% 50%"
KAREL TASK,0.23126338329764454,Functional equivalence
KAREL TASK,0.2334047109207709,"Well-designed
Query
Random"
KAREL TASK,0.23554603854389722,Bunel et.al
KAREL TASK,0.23768736616702354,"0
2
4
6
8
10
Number of epochs 0% 10% 20% 30% 40%"
KAREL TASK,0.2398286937901499,Exact match
KAREL TASK,0.24197002141327623,"Well-designed
Query
Random"
KAREL TASK,0.24411134903640258,"0
2
4
6
8
10
Number of epochs 0% 10% 20% 30% 40% 50%"
KAREL TASK,0.2462526766595289,Functional equivalence
KAREL TASK,0.24839400428265523,"Well-designed
Query
Random"
KAREL TASK,0.2505353319057816,Chen et.al
KAREL TASK,0.25267665952890794,Figure 5: The training curve of the program synthesis model on Karel.
KAREL TASK,0.25481798715203424,"Table 3: The performance of the program synthesis model trained on input-output examples gener-
ated by different methods on the list processing task."
KAREL TASK,0.2569593147751606,"Dataset
Metric
Searching for semantics
Searching for exact match
Random
Well-designed
Query
Random
Well-designed
Query"
KAREL TASK,0.25910064239828695,"D1
Exact match
20.07%
32.81%
22.26%
50.65%
81.21%
81.56%
Functional equivalence
52.03%
80.26%
68.20%
50.65%
81.21%
81.56%"
KAREL TASK,0.26124197002141325,"D2
Exact match
9.25%
15.72%
10.44%
22.61%
38.51%
38.63%
Functional equivalence
24.49%
39.88%
32.94%
22.61%
38.51%
38.63%"
KAREL TASK,0.2633832976445396,"in Appendix B.4. There are two strategies based on QBC: Crash-aware, which repeats the algorithm
to sample another one if the query crashes; And crash-unaware, which samples queries regardless
of the crash problem (see Appendix B.1 for a detailed explanation of crashes). QBC-crash-unaware
performs worse than Random because Random is chosen by filtering crashed IOs while QBC-crash-
unaware may contain crashes. QBC-crash-aware performs much better than QBC-crash-unaware
because it queries the underlying program multiple times to make sure that the query will not result
in a crash, which is unfair. Even though, out method still outperforms QBC-crash-aware, which
shows its advantage."
KAREL TASK,0.26552462526766596,"Training process.
To do a further study, we plot the training curve in Figure 5. It is shown that
the Query dataset always has a quick start, which indicates that the query method can extract the
features of the distinguishable programs effectively and makes them easier to be synthesized."
LIST PROCESSING TASK,0.2676659528907923,"4.3
LIST PROCESSING TASK"
LIST PROCESSING TASK,0.2698072805139186,"To show the generalization ability of the query method, we conduct another experiment on the list
processing task. The list processing task takes 1-3 lists or integers as the input example, and then
produces a list or an integer as the output example. More details can be seen in Appendix B.2."
LIST PROCESSING TASK,0.27194860813704497,"Settings.
Following PCCoder (Zohar & Wolf, 2018), we generate two datasets with program
length 4 as dataset D1 and program length up to 12 as dataset D2. We set the Encodere of the
query network similar to PCCoder except for an MLP, and use a single layer LSTM as the Encoderp
(see Appendix A.2). The synthesis network and the parameters of complete anytime beam search
(CAB) (Zhang, 1998) stay the same as PCCoder, except that the maximum time is set to 5 seconds
instead of 5,000 seconds for reality."
LIST PROCESSING TASK,0.2740899357601713,"Similar to the Karel task, we generate the dataset with 5 input-output examples with three different
methods. Furthermore, we use two end conditions of CAB: The searching ends when all input-
output examples are satisfied (searching for semantics), and the searching ends when all statements
are true (searching for exact match)."
LIST PROCESSING TASK,0.2762312633832976,"Performance.
The results are presented in Table 3, from which we can conclude that: (1) Our
query method results higher than well-designed input-output examples in searching for the exact
match and consistently outperforms the random. (2) When the length of programs increases, the
performance decreases largely. This results from the original algorithm of PCCoder that the inter-"
LIST PROCESSING TASK,0.278372591006424,Published as a conference paper at ICLR 2022
LIST PROCESSING TASK,0.28051391862955033,"mediate variables are difficult to be saved when the ground-truth program is long. However, the
query method decreases slower than others, and the gap between the well-designed and the query is
closed largely."
RELATED WORK,0.2826552462526767,"5
RELATED WORK"
RELATED WORK,0.284796573875803,"Programming by examples.
Synthesizing a program that satisfies the user intent using the pro-
vided input-output examples is a challenging problem that has been studied for years (Manna &
Waldinger, 1971; Lieberman, 2001; Solar-Lezama et al., 2006; Gulwani, 2011; Gulwani et al., 2012).
Recently, with the development of Deep Learning, more researchers tend to tackle this problem
with neural networks in a variety of tasks, including string transformation (Devlin et al., 2017b),
list processing (Balog et al., 2017; Zohar & Wolf, 2018), graphic generation (Ellis et al., 2018; Tian
et al., 2019), Karel (Devlin et al., 2017a; Bunel et al., 2018), policy abstraction (Sun et al., 2018;
Verma et al., 2018) and so on. Additionally, techniques like program debugger (Balog et al., 2020;
Gupta et al., 2020), traces (Chen et al., 2019; Shin et al., 2018; Ellis et al., 2019), property sig-
natures (Odena & Sutton, 2020; Odena et al., 2021) are also used to improve the performance of
program synthesis. However, their promising performance relies on the well-designed input-output
examples which is a high requirement for users. If the examples provided are of poor quality, the
performance will be affected severely. Worse, if out-of-distribution examples are provided, the pro-
gram synthesis model cannot finish the task as expected (Shin et al., 2019)."
RELATED WORK,0.28693790149892934,"Interactive program synthesis.
Considering the high requirement of input-output examples, Le
et al. (2017) build an abstract framework in which the program synthesis system can interact with
users to guide the process of synthesis. Following this framework, multiple interactive synthesis
systems are studied. Among them, Mayer et al. (2015), Wang et al. (2017), and Laich et al. (2020)
tend to find counter-examples as queries to the users in a random manner. Although they get rid
of the restrictions on the users, the quantity of the input-output examples is not guaranteed, which
may get the synthesis process into trouble. Padhi et al. (2018) select more than one query each time
and let the users choose which one to answer. This brings an additional burden on the users, and
the users are unaware of which query will improve the program synthesized most. Most recently,
Ji et al. (2020) utilizes the minimax branch to select the question where the worst answer gives the
best reduction of the program domain. Theoretically, the performance of the selection is guaranteed.
However, this method is based on search and hardly be applied to tasks with large input-output
space. Worse, the query process and the synthesis process are bound, which results in its poor
scalability. In contrast, our method can be applied to problems with large spaces, and the query
process is decoupled with the synthesis process, which makes its application more flexible."
RELATED WORK,0.2890792291220557,"Learning to acquire information.
Similar to our work, Pu et al. (2018) and Pu et al. (2017) also
study the query problem from an information-theoretic perspective. They show that maximizing the
mutual information between the input-output examples and the corresponding program greedily is
1 ‚àí1"
RELATED WORK,0.291220556745182,"e as good as the optimal solution that considers all examples globally. However, they assume
that the space of queries can be enumerated, which limits the application of their query algorithm
on complex datasets like Karel. By comparison, our work proposes a more general algorithm that
can generate queries in a nearly infinite space. Other related work including active learning and
black-box testing can be seen in Appendix D."
CONCLUSION,0.29336188436830835,"6
CONCLUSION"
CONCLUSION,0.2955032119914347,"In this work, we propose a query-based framework to finish the program synthesis task more re-
alistically. To optimize this framework, we show the correlation between the query strategy and
the mutual information. Moreover, we model the relevance between the input-output examples and
programs by introducing the F-space, where we represent the input-output examples as the distri-
bution of the programs. Using these techniques, we conduct a series of experiments that shows the
effectiveness, generalization, and scalability of our query-based framework. We believe that our
methods work not only on the program synthesis tasks, but also on any task that aims to simulate an
underlying oracle, including reverse engineering, symbolic regression, scientific discovery, and so
on."
CONCLUSION,0.29764453961456105,Published as a conference paper at ICLR 2022
CONCLUSION,0.29978586723768735,ACKNOWLEDGMENTS
CONCLUSION,0.3019271948608137,"This work is partially supported by the National Key Research and Development Program of China
(under Grant 2020AAA0103802), the NSF of China (under Grants 61925208, 62102399, 62002338,
61906179, 61732020, U19B2019), Strategic Priority Research Program of Chinese Academy of
Science (XDB32050200), Beijing Academy of Artificial Intelligence (BAAI) and Beijing Nova Pro-
gram of Science and Technology (Z191100001119093), CAS Project for Young Scientists in Basic
Research (YSBR-029), Youth Innovation Promotion Association CAS and Xplore Prize."
REFERENCES,0.30406852248394006,REFERENCES
REFERENCES,0.30620985010706636,"D. Angluin. Queries and concept learning. Machine Learning, 2:319‚Äì342, 1988."
REFERENCES,0.3083511777301927,"Matej Balog, Alexander L. Gaunt, Marc Brockschmidt, S. Nowozin, and Daniel Tarlow. Deepcoder:
Learning to write programs. In ICLR (Poster). OpenReview.net, 2017."
REFERENCES,0.31049250535331907,"Matej Balog, Rishabh Singh, Petros Maniatis, and Charles Sutton. Neural program synthesis with a
differentiable fixer. ArXiv, abs/2006.10924, 2020."
REFERENCES,0.31263383297644537,"Rudy Bunel, M. Hausknecht, J. Devlin, Rishabh Singh, and P. Kohli. Leveraging grammar and
reinforcement learning for neural program synthesis. In ICLR (Poster). OpenReview.net, 2018."
REFERENCES,0.3147751605995717,"Xi Chen, Yan Duan, Rein Houthooft, J. Schulman, Ilya Sutskever, and P. Abbeel. Infogan: Inter-
pretable representation learning by information maximizing generative adversarial nets. In NIPS,
2016."
REFERENCES,0.3169164882226981,"Xinyun Chen, Chang Liu, and D. Song. Execution-guided neural program synthesis. In ICLR, 2019."
REFERENCES,0.31905781584582443,"Ido Dagan and S. Argamon. Committee-based sampling for training probabilistic classifiers. In
ICML, 1995."
REFERENCES,0.32119914346895073,"J. Devlin, Rudy Bunel, Rishabh Singh, M. Hausknecht, and P. Kohli.
Neural program meta-
induction. In NIPS, 2017a."
REFERENCES,0.3233404710920771,"J. Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel rahman Mohamed, and
P. Kohli. Robustfill: Neural program learning under noisy i/o. In ICML, 2017b."
REFERENCES,0.32548179871520344,"Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, and J. Tenenbaum. Learning to infer graphics
programs from hand-drawn images. In NeurIPS, 2018."
REFERENCES,0.32762312633832974,"Kevin Ellis, Maxwell Nye, Yewen Pu, Felix Sosa, J. Tenenbaum, and Armando Solar-Lezama.
Write, execute, assess: Program synthesis with a repl. In NeurIPS, 2019."
REFERENCES,0.3297644539614561,"S. Gulwani. Automating string processing in spreadsheets using input-output examples. In POPL
‚Äô11, 2011."
REFERENCES,0.33190578158458245,"Sumit Gulwani, William R. Harris, and Rishabh Singh. Spreadsheet data manipulation using exam-
ples. Commun. ACM, 55:97‚Äì105, 2012."
REFERENCES,0.3340471092077088,"Sumit Gulwani, Oleksandr Polozov, and Rishabh Singh. Program synthesis. Found. Trends Program.
Lang., 4:1‚Äì119, 2017."
REFERENCES,0.3361884368308351,"Kavi Gupta, P. E. Christensen, Xinyun Chen, and D. Song. Synthesize, execute and debug: Learning
to repair for neural program synthesis. In NeurIPS, 2020."
REFERENCES,0.33832976445396146,"Eric Jang, Shixiang Shane Gu, and Ben Poole. Categorical reparameterization with gumbel-softmax.
In ICLR (Poster). OpenReview.net, 2017."
REFERENCES,0.3404710920770878,"Ruyi Ji, Jingjing Liang, Yingfei Xiong, Lu Zhang, and Zhenjiang Hu. Question selection for inter-
active program synthesis. Proceedings of the 41st ACM SIGPLAN Conference on Programming
Language Design and Implementation, 2020."
REFERENCES,0.3426124197002141,"R. King, Ken E. Whelan, F. M. Jones, Philip G. K. Reiser, Christopher H. Bryant, S. Muggleton,
D. Kell, and S. Oliver. Functional genomic hypothesis generation and experimentation by a robot
scientist. Nature, 427:247‚Äì252, 2004."
REFERENCES,0.34475374732334046,Published as a conference paper at ICLR 2022
REFERENCES,0.3468950749464668,"Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014."
REFERENCES,0.3490364025695932,"V. Krishnamurthy. Algorithms for optimal scheduling and management of hidden markov model
sensors. IEEE Trans. Signal Process., 50:1382‚Äì1397, 2002."
REFERENCES,0.3511777301927195,"Larissa Laich, Pavol Bielik, and Martin T. Vechev. Guiding program synthesis by learning to gener-
ate examples. In ICLR, 2020."
REFERENCES,0.3533190578158458,"Vu Le, Daniel Perelman, Oleksandr Polozov, Mohammad Raza, A. Udupa, and S. Gulwani. Inter-
active program synthesis. ArXiv, abs/1703.03539, 2017."
REFERENCES,0.3554603854389722,"D. Lewis and W. Gale. A sequential algorithm for training text classifiers. In SIGIR ‚Äô94, 1994."
REFERENCES,0.3576017130620985,H. Lieberman. Your wish is my command: Programming by example. 2001.
REFERENCES,0.35974304068522484,"Chris J. Maddison, Andriy Mnih, and Yee Whye Teh. The concrete distribution: A continuous
relaxation of discrete random variables. In ICLR (Poster). OpenReview.net, 2017."
REFERENCES,0.3618843683083512,"Z. Manna and R. Waldinger. Toward automatic program synthesis. Commun. ACM, 14:151‚Äì165,
1971."
REFERENCES,0.3640256959314775,"Mika¬®el Mayer, Gustavo Soares, Maxim Grechkin, Vu Le, Mark Marron, Oleksandr Polozov,
Rishabh Singh, B. Zorn, and S. Gulwani. User interaction models for disambiguation in program-
ming by example. Proceedings of the 28th Annual ACM Symposium on User Interface Software
& Technology, 2015."
REFERENCES,0.36616702355460384,"Karl Meinke. Automated black-box testing of functional correctness using function approximation.
In ISSTA, pp. 143‚Äì153. ACM, 2004."
REFERENCES,0.3683083511777302,"Karl Meinke and Fei Niu. A learning-based approach to unit testing of numerical software. In
ICTSS, volume 6435 of Lecture Notes in Computer Science, pp. 221‚Äì235. Springer, 2010."
REFERENCES,0.37044967880085655,"Karl Meinke and Muddassar A. Sindhu. Incremental learning-based testing for reactive systems. In
TAP@TOOLS, volume 6706 of Lecture Notes in Computer Science, pp. 134‚Äì151. Springer, 2011."
REFERENCES,0.37259100642398285,"Augustus Odena and Charles Sutton. Learning to represent programs with property signatures. In
ICLR. OpenReview.net, 2020."
REFERENCES,0.3747323340471092,"Augustus Odena, Kensen Shi, David Bieber, Rishabh Singh, and Charles Sutton. Bustle: Bottom-up
program-synthesis through learning-guided exploration. In ICLR. OpenReview.net, 2021."
REFERENCES,0.37687366167023556,"Saswat Padhi, Prateek Jain, Daniel Perelman, Oleksandr Polozov, S. Gulwani, and T. Millstein.
Flashprofile: a framework for synthesizing data profiles. Proceedings of the ACM on Program-
ming Languages, 2:1 ‚Äì 28, 2018."
REFERENCES,0.37901498929336186,"Richard Pattis, J Roberts, and M Stehlik. Karel the robot. A gentele introduction to the Art of
Programming, 1981."
REFERENCES,0.3811563169164882,"Yewen Pu, Leslie Pack Kaelbling, and Armando Solar-Lezama. Learning to acquire information.
In Gal Elidan, Kristian Kersting, and Alexander T. Ihler (eds.), Proceedings of the Thirty-Third
Conference on Uncertainty in Artificial Intelligence, UAI 2017, Sydney, Australia, August 11-15,
2017. AUAI Press, 2017."
REFERENCES,0.38329764453961457,"Yewen Pu, Zachery Miranda, Armando Solar-Lezama, and L. Kaelbling. Selecting representative
examples for program synthesis. In ICML, 2018."
REFERENCES,0.3854389721627409,"Hongyu Ren and J. Leskovec.
Beta embeddings for multi-hop logical reasoning in knowledge
graphs. In NeurIPS, 2020."
REFERENCES,0.3875802997858672,"H. Sebastian Seung, Manfred Opper, and Haim Sompolinsky. Query by committee. In COLT, pp.
287‚Äì294. ACM, 1992."
REFERENCES,0.3897216274089936,"Richard Shin, Illia Polosukhin, and D. Song. Improving neural program synthesis with inferred
execution traces. In NeurIPS, 2018."
REFERENCES,0.39186295503211993,Published as a conference paper at ICLR 2022
REFERENCES,0.39400428265524623,"Richard Shin, Neel Kant, Kavi Gupta, Christopher M. Bender, Brandon Trabucco, Rishabh Singh,
and D. Song. Synthetic datasets for neural program synthesis. In ICLR (Poster). OpenReview.net,
2019."
REFERENCES,0.3961456102783726,"Changjian Shui, Fan Zhou, Christian Gagn‚Äôe, and B. Wang. Deep active learning: Unified and
principled method for query and training. In AISTATS, 2020."
REFERENCES,0.39828693790149894,"Armando Solar-Lezama, Liviu Tancau, R. Bod¬¥ƒ±k, S. Seshia, and V. Saraswat. Combinatorial sketch-
ing for finite programs. In ASPLOS XII, 2006."
REFERENCES,0.4004282655246253,"Ke Sun and F. Nielsen. Information-geometric set embeddings (igse): From sets to probability
distributions. ArXiv, abs/1911.12463, 2019."
REFERENCES,0.4025695931477516,"Shao-Hua Sun, Hyeonwoo Noh, S. Somasundaram, and Joseph J. Lim. Neural program synthesis
from diverse demonstration videos. In ICML, 2018."
REFERENCES,0.40471092077087795,"Yonglong Tian, Andrew Luo, Xingyuan Sun, Kevin Ellis, W. Freeman, J. Tenenbaum, and Jiajun
Wu. Learning to infer and execute 3d shape programs. In ICLR (Poster). OpenReview.net, 2019."
REFERENCES,0.4068522483940043,"A¬®aron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predic-
tive coding. ArXiv, abs/1807.03748, 2018."
REFERENCES,0.4089935760171306,"Abhinav Verma, V. Murali, Rishabh Singh, P. Kohli, and Swarat Chaudhuri. Programmatically
interpretable reinforcement learning. In ICML, volume 80 of Proceedings of Machine Learning
Research, pp. 5052‚Äì5061. PMLR, 2018."
REFERENCES,0.41113490364025695,"Chenglong Wang, Alvin Cheung, and R. Bod¬¥ƒ±k. Interactive query synthesis from input-output ex-
amples. Proceedings of the 2017 ACM International Conference on Management of Data, 2017."
REFERENCES,0.4132762312633833,"Weixiong Zhang. Complete anytime beam search. In AAAI/IAAI, 1998."
REFERENCES,0.41541755888650966,"Amit Zohar and Lior Wolf. Automatic program synthesis of long programs with a learned garbage
collector. In NeurIPS, 2018."
REFERENCES,0.41755888650963596,Published as a conference paper at ICLR 2022
REFERENCES,0.4197002141327623,"A
TRAINING DETAILS"
REFERENCES,0.42184154175588867,"A.1
TRAINING ALGORITHM"
REFERENCES,0.42398286937901497,Algorithm 1 Training process
REFERENCES,0.4261241970021413,"1: function TRAIN( )
2:
Initialize max iterations N and max query times T
3:
for i ‚àà{1 . . . N} do
4:
p ‚ÜêUnderlying programs
5:
(x0, y0) ‚Üê< sos >
6:
JeK ‚Üê{(x0, y0)}
7:
L ‚Üê0
8:
for t ‚àà{1 . . . T} do
9:
v ‚ÜêEncoderp(p)
‚ñ∑Encode program, Equation (4)
10:
¬µ, log(œÉ2) ‚ÜêIO-ENCODER(JeK)
‚ñ∑Encode input-output examples
11:
xt ‚ÜêDecoder(¬µ, log(œÉ2))
‚ñ∑Query next input
12:
yt ‚Üêp(xt)
‚ñ∑Get next output from the oracle
13:
JeK ‚ÜêJeK ‚à™{(xt, yt)}
14:
¬µ‚Ä≤, log(œÉ‚Ä≤2) ‚ÜêIO-ENCODER(JeK)
15:
L ‚ÜêLoss(v, ¬µ‚Ä≤, log(œÉ‚Ä≤2)) + L
‚ñ∑InfoNCE loss, Equation (2)
16:
end for
17:
Update parameters w.r.t. L
18:
end for
19: end function"
REFERENCES,0.4282655246252677,"1: function IO-ENCODER({xk, yk}K)
2:
for i ‚àà{1 . . . K} do
3:
[¬µi, log(œÉ2
i )] ‚ÜêMLPe(Encodere({xi, yi})
‚ñ∑Encode single example, Equation (5)
4:
end for
5:
for i ‚àà{1 . . . K} do"
REFERENCES,0.430406852248394,"6:
wi ‚Üê
exp(MLPattention([¬µi,log(œÉ2
i )]))
PK
j=1 exp(MLPattention(¬µj,log(œÉ2
j )))
‚ñ∑Calculate attentions, Equation (8)"
REFERENCES,0.43254817987152033,"7:
end for
8:
[¬µ, log(œÉ2)] = PK
i=1 wi[¬µi, log(œÉ2
i )]
‚ñ∑Intersection, Equation (7)
9:
return ¬µ, log(œÉ2)
10: end function"
REFERENCES,0.4346895074946467,"A.2
MODEL DETAILS AND HYPER PARAMETERS"
REFERENCES,0.43683083511777304,"Karel.
The query encoder is the same as the one used by Bunel et al. (2018) composed of a
Convolutional Neural Network (CNN) with the residual link. After the query encoder, there is an
MLP to project the embedding into ¬µ, log(œÉ2). The dimension of ¬µ and œÉ is set to 256, and thus
the hidden size of MLP is 512. The query decoder is similar to the query encoder except that the
number of channels is reversed, and additional batch normalization is added to keep the generation
more stable. The program encoder is a two-layer LSTM with a hidden size of 256."
REFERENCES,0.43897216274089934,"Note that in the well-designed dataset, the size of the grid world can be changed from 2 to 16.
However, for the convenience of training, we set the size of the query world fixed to 16. Moreover,
to guarantee that all queries can be recognized by the program simulator, we split the query into three
parts: boundaries (the map size, set to 16√ó16), agent position (where the agent is and towards), and
map state (the placement of markers and obstacles), and generate them as follows:"
REFERENCES,0.4411134903640257,"‚Ä¢ Boundaries: The boundaries indicate the map size, fixed to 16 √ó 16.
‚Ä¢ Agent position: generate a 4 √ó 16 √ó 16 one-hot vector where 4 indicates four facing
directions and 16 √ó 16 indicates the position.
‚Ä¢ Map state: generate a 12 one-hot vector on the 16 √ó 16 map including obstacle, 1-10
markers, and empty grid."
REFERENCES,0.44325481798715205,Published as a conference paper at ICLR 2022
REFERENCES,0.44539614561027835,Input-examples
REFERENCES,0.4475374732334047,Output-examples Conv Conv
REFERENCES,0.44967880085653106,"ResBlocks
Linear
IO embeddings"
REFERENCES,0.4518201284796574,"Input-output 
examples √ó N"
REFERENCES,0.4539614561027837,"IO embeddings
MLP"
REFERENCES,0.45610278372591007,Linear
REFERENCES,0.4582441113490364,Linear ùúá
REFERENCES,0.4603854389721627,log (ùúé‡¨∂)
REFERENCES,0.4625267665952891,Linear
REFERENCES,0.46466809421841543,"Activation
Conv
ReLU"
REFERENCES,0.4668094218415418,"Conv
ReLU
Conv
ReLU
Next layers
Activation"
REFERENCES,0.4689507494646681,"Conv
BN
LReLU"
REFERENCES,0.47109207708779444,"Conv
BN
LReLU"
REFERENCES,0.4732334047109208,"Conv
BN
LReLU
Next layers"
REFERENCES,0.4753747323340471,Latent code
REFERENCES,0.47751605995717344,"Reshape
Decoder"
REFERENCES,0.4796573875802998,Linear Conv
REFERENCES,0.4817987152034261,"Gumbel
Softmax"
REFERENCES,0.48394004282655245,"Gumbel
Softmax"
REFERENCES,0.4860813704496788,"Concat
Agent position"
REFERENCES,0.48822269807280516,Map state
REFERENCES,0.49036402569593146,"Query
Encoder
Intersect
Encoder
Encoder √ó N"
REFERENCES,0.4925053533190578,"16√ó16 
boundaries"
REFERENCES,0.49464668094218417,"(c) IO Encoder
(d) Distribution encoder (MLPe)"
REFERENCES,0.49678800856531047,"(a) ResBlock
(b) ResBNBlock"
REFERENCES,0.4989293361884368,(g) The query network for Karel
REFERENCES,0.5010706638115632,"Input-output 
examples √ó N"
REFERENCES,0.5032119914346895,"IO
Encoder
MLPe ùúá"
REFERENCES,0.5053533190578159,"log (ùúé‡¨∂)
ùúá, log (ùúé‡¨∂), latent code
ResBN-
Blocks
Representation"
REFERENCES,0.5074946466809421,"(e) Encoder
(f) Decoder"
REFERENCES,0.5096359743040685,Figure 6: The architecture of the query network for Karel (zoom in for a better view).
REFERENCES,0.5117773019271948,"Input-output 
examples √ó N"
REFERENCES,0.5139186295503212,Latent code
REFERENCES,0.5160599571734475,"Linear
Gumbel
Softmax"
REFERENCES,0.5182012847965739,"Gumbel
Softmax"
REFERENCES,0.5203426124197003,"Concat
Int proposition
Query
Encoder
Intersect
Encoder
Encoder √ó N"
REFERENCES,0.5224839400428265,"Embed
Input-output 
examples √ó N"
REFERENCES,0.5246252676659529,"Dense
Blocks"
REFERENCES,0.5267665952890792,"IO embeddings
MLP"
REFERENCES,0.5289079229122056,Linear
REFERENCES,0.5310492505353319,Linear ùúá
REFERENCES,0.5331905781584583,log (ùúé‡¨∂)
REFERENCES,0.5353319057815846,IO embeddings
REFERENCES,0.5374732334047109,"Linear
List proposition"
REFERENCES,0.5396145610278372,"Type 
filter
Padding
Int/List/Null"
REFERENCES,0.5417558886509636,Input types
REFERENCES,0.5438972162740899,"Input-output 
examples √ó N"
REFERENCES,0.5460385438972163,"IO
Encoder
MLPe ùúá"
REFERENCES,0.5481798715203426,log (ùúé‡¨∂)
REFERENCES,0.550321199143469,(d) Encoder
REFERENCES,0.5524625267665952,"Linear
Activation
Next layers
Linear
Linear
‚Ä¶
‚Ä¶
‚Ä¶
‚Ä¶"
REFERENCES,0.5546038543897216,(c) Distribution Encoder (MLPe)
REFERENCES,0.556745182012848,"(b) IO Encoder
(a) DenseBlock"
REFERENCES,0.5588865096359743,(e) The query network for list processing Null
REFERENCES,0.5610278372591007,"Figure 7: The architecture of the query network for list processing (zoom in for a better view). Type
filter chooses query between the list proposition and int proposition depends on the input types."
REFERENCES,0.563169164882227,The architecture details are shown in figure 6.
REFERENCES,0.5653104925053534,"For training, the learning rate of the query network is set to 10‚àí4 with the Adam optimizer Kingma &
Ba (2014) while the learning rate of the synthesis network stays the same with the original methods.
The batch size is 128, and the random seed is set to 100."
REFERENCES,0.5674518201284796,"List processing.
The query encoder is the same as the one in PCCoder. The dimension of ¬µ and
œÉ is set to 256 for dataset D1 and 128 for dataset D2 without much tuning. The query decoder is a
single-layer linear network with dimension 256 for dataset D1 and 128 for dataset D2. The program
encoder is a single layer LSTM with hidden size 256 for dataset D1 and 128 for dataset D2."
REFERENCES,0.569593147751606,"The inputs of list processing consist of three types: INT, LIST, and NULL. Thus, each query is
NULL or an integer or a list consisting of integers in the range of [‚àí256, 255]. Each integer is
represented by a 512 one-hot vector. For the well-designed input-output examples, the length of
a LIST is sampled stochastically with the maximum length of 20. However, to make the query
network simpler, we fix the length of queries to 20. The query network generates all three types"
REFERENCES,0.5717344753747323,Published as a conference paper at ICLR 2022
REFERENCES,0.5738758029978587,"Prog p
:=
def run() : s
Stmt s
:=
while(b) : s | repeat(r) : s | s1; s2 | a
|
if(b) : s | ifelse(b) : s1 else : s2
Cond b
:=
frontIsClear() | leftIsClear() | rightIsClear()
|
markersPresent() | noMarkersPresent() | not b
Action a
:=
move() | turnRight() | turnLeft()
|
pickMarker() | putMarker()
Cste r
:=
0 | 1 | ¬∑ ¬∑ ¬∑ | 19"
REFERENCES,0.576017130620985,Figure 8: The DSL of Karel
REFERENCES,0.5781584582441114,"separately by different networks and chooses among them according to the type of inputs using a
type filter."
REFERENCES,0.5802997858672377,The details of the query network for list processing are shown in figure 7.
REFERENCES,0.582441113490364,"For training, the learning rate of the query network is set to 10‚àí4 with a 0.1 decay every 40 epochs
and the Adam optimizer Kingma & Ba (2014). The learning rate of the synthesis network is 10‚àí3,
which stays the same with the original methods with 0.1 decay every 4 epochs. The batch size of
the query process is 64, the batch size of synthesis is 32 for D1 and 100 for D2. The random seed is
set to 100."
REFERENCES,0.5845824411134903,"A.3
OTHER TRAINING TECHNIQUES"
REFERENCES,0.5867237687366167,"Latent code.
The subsequent queries are easy to fail into the mode collapse, generating simi-
lar queries repetitively. To tackle this problem, we introduce a latent code, like the one in Info-
GAN (Chen et al., 2016), as another input, which indicates the current query step, and ask the
encoder in the next query step to decode it accurately. Specifically, given a latent code c which
indicates the current query step, the query network is supposed to maximize the mutual information
between c and the output query x to alleviate the mode collapse problem. To generate x under the
condition of c, we concatenate c with the encoded representation ¬µ and log(œÉ2), and then send it to
the decoder (Equation (9)), shown in Figure 6(g) and Figure 7(e). To maximize the mutual informa-
tion I(c; x), we design a network aiming to classify c from x, which models the distribution Q(c|x)
(details can be seen in Chen et al. (2016)). This network shares its parameters with the Encodere
(Equation (5)) except for the last layer, and it is optimized with the cross-entropy loss."
REFERENCES,0.588865096359743,"Gumbel-Softmax.
Note that the queries are discrete, which makes the query network cannot be
optimized by back-propagation. Thus, we take advantage of the Gumbel-Softmax distribution (Mad-
dison et al., 2017; Jang et al., 2017) and make the query process differentiable."
REFERENCES,0.5910064239828694,"Curriculum learning.
The query network is trained progressively. At the beginning of the train-
ing, the query network generates one query only. As the training goes on, the limit of the number of
queries increases until it achieves five. Specifically, this limit increases every two epochs. Curricu-
lum learning helps to make the training process more stable."
REFERENCES,0.5931477516059958,"Kullback-Leibler (KL) divergence.
A failed attempt. Similar to the latent code, we tried to add
the reciprocal of the KL divergence between different queries on the same program as another loss
to make the queries more diverse. However, this loss does not have a significant impact on training
most of the time and makes the training process unstable, and thus it is abandoned in our final
version."
REFERENCES,0.5952890792291221,Published as a conference paper at ICLR 2022
REFERENCES,0.5974304068522484,"Hero facing North
Hero facing South"
REFERENCES,0.5995717344753747,Hero facing West
REFERENCES,0.6017130620985011,Hero facing East
REFERENCES,0.6038543897216274,"Obstacle
Grid boundary"
MARKER,0.6059957173447538,"1 marker
2 marker
3 marker
4 marker
5 marker
6 marker
7 marker
8 marker
9 marker
10 marker"
MARKER,0.6081370449678801,Table 4: Representation of a cell in grid world
MARKER,0.6102783725910065,def run():
MARKER,0.6124197002141327,"move()
putMarker()
turnRight()
move()"
MARKER,0.6145610278372591,"Input
Output
Program"
MARKER,0.6167023554603854,Figure 9: An example of Karel.
MARKER,0.6188436830835118,"B
EXPERIMENT DETAILS"
MARKER,0.6209850107066381,"B.1
THE KAREL TASK"
MARKER,0.6231263383297645,"Karel is an educational programming language, which can be used to control a robot to move in a
2D grid world (Pattis et al., 1981). Figure 8 presents the domain language specification (DSL) of
Karel. Figure 9 shows a Karel program example. Each cell of the grid world is represented as a
16-dimensional vector corresponding to the features described in Table 4 (Bunel et al., 2018)."
MARKER,0.6252676659528907,"Handling of crashes.
The executor of Karel will get a ‚ÄùCRASH‚Äù result and then terminates if the
agent:"
MARKER,0.6274089935760171,‚Ä¢ Picks a marker while no marker is presented.
MARKER,0.6295503211991434,"‚Ä¢ Puts a marker down while the number of the markers in the cell exceeds the limit (the limit
is set to 10)."
MARKER,0.6316916488222698,‚Ä¢ Walks up an obstacle or out of boundaries.
MARKER,0.6338329764453962,‚Ä¢ Falls into an infinite loop (the loop with more than 105 API calls).
MARKER,0.6359743040685225,"In the early stage of training, the query network generates the queries randomly, and thus the pro-
grams run into these crashed states easily, making the queries cannot be applied to training. To avoid
these situations, we modify the executor so that when crashes happen, the state stays still without
change and the program keeps executing."
MARKER,0.6381156316916489,Published as a conference paper at ICLR 2022
MARKER,0.6402569593147751,"Basic Function
:=
+1 | ‚àí1 | √ó2 | √∑2 | √ó(‚àí1)
|
‚àó‚àó2 | √ó3 | √∑3 | √ó4 | √∑4
|
> 0 | < 0 | %2 | %2 == 1
First-order Function
:=
HEAD | LAST | TAKE | DROP | ACCESS
|
MINIMUM | MAXIMUN | REVERSE | SORT | SUM
Higher-order Function
:=
MAP | FILTER | COUNT | ZIPWITH | SCANL1"
MARKER,0.6423982869379015,Figure 10: The DSL of list processing
MARKER,0.6445396145610278,"FILTER (<0)
MAP (√ó4)
SORT
REVERSE Input"
MARKER,0.6466809421841542,Output
MARKER,0.6488222698072805,Program
MARKER,0.6509635974304069,"[-17, -3, 4, 11, 0, -5, -9, 13, 6, 6, -8, 11]"
MARKER,0.6531049250535332,"[-12, -20, -32, -36, -68]"
MARKER,0.6552462526766595,Figure 11: An example of list processing.
MARKER,0.6573875802997858,"B.2
THE LIST PROCESSING TASK"
MARKER,0.6595289079229122,"The list processing task takes 1-3 lists or integers as input examples and produces a list or an integer
as the output example. An example is shown in Figure 11. Figure 10 shows the DSL of list process-
ing. Following Zohar & Wolf (2018), we generate two datasets: D1 with program length 4 and D2
with program length up to 12."
MARKER,0.6616702355460385,"Handling of the out of range problem.
Constraint propagation guarantees that the execution of
programs never obtains intermediate values that are out of range [‚àí256, 255]. However, when we
query randomly in the early stage of training, the out-of-range problem can easily occur. To handle
this problem, we truncate the intermediate values to [‚àí256, 255] while querying to ensure that all
queries can yield legal responses."
MARKER,0.6638115631691649,"B.3
THE EVOLUTION OF DISTRIBUTION ENTROPY"
MARKER,0.6659528907922913,"To make a sanity check of the F-space formulation, we study how the entropy of the distribution
changes over the step of the query."
MARKER,0.6680942184154176,"The entropy of a multivariate Normal distribution N(x; ¬µ, Œ£)) is given by"
MARKER,0.6702355460385439,H(x) = 1
MARKER,0.6723768736616702,2ln|Œ£| + D
MARKER,0.6745182012847966,"2 (1 + ln(2œÄ)),
(11)"
MARKER,0.6766595289079229,"where Œ£ denotes the covariance matrix and D denotes the dimension of x. In our case, we have
assumed the independence of each dimension of x which means that Œ£ is a diagonal matrix. Hence"
MARKER,0.6788008565310493,"1
2ln(|Œ£|) = 1"
MARKER,0.6809421841541756,"2ln(
Y"
MARKER,0.683083511777302,"i
œÉ2
i ) = 1 2 X"
MARKER,0.6852248394004282,"i
ln(œÉ2
i ),
(12)"
MARKER,0.6873661670235546,"where œÉ2
i is the diagonal element of Œ£, indicating the variance of each dimension. D is a constant
during querying, so we calculate the mean of log(œÉ2) as an equivalent substitute to show the change
of the entropy. Results are shown in Figure 12. In our experiments, Karel performs best and this is
also revealed by the entropy that Karel decreases much faster than list processing. On the contrary,
the entropy of list processing decreases slowly and has worse performance in our experiment. This
performance may be increased by tuning the query network more carefully."
MARKER,0.6895074946466809,Published as a conference paper at ICLR 2022
MARKER,0.6916488222698073,"1
2
3
4
5
Query step 1 2 3 4 log
i"
E,0.6937901498929336,"1e
3 Karel"
E,0.69593147751606,"1
2
3
4
5
Query step 8.0 8.5 9.0 9.5 log
i"
E,0.6980728051391863,"1e
3"
E,0.7002141327623126,List-D1
E,0.702355460385439,"1
2
3
4
5
Query step 3.3 3.4 3.5 3.6 3.7 log
i"
E,0.7044967880085653,"1e
3"
E,0.7066381156316917,List-D2
E,0.708779443254818,Figure 12: The entropy of the distribution decays when query goes on.
E,0.7109207708779444,Table 5: The statistics on the query times of each crash-aware QBC query step.
E,0.7130620985010707,"1
2
3
4
5"
E,0.715203426124197,"avg
5.72
2.47
2.96
4.27
4.86
max
214
200
224
357
226
min
0
0
0
0
0"
E,0.7173447537473233,"B.4
QUERY BY COMMITTEE"
E,0.7194860813704497,"In this section, we present the details of our baseline algorithm: query by committee (Seung et al.,
1992). Algorithm 2 shows the crash-aware version of the QBC algorithm, which selects the query
that can result in the most diverse outputs. The crash-unaware version can be obtained simply by
removing all CRASH judgments. Note that, compared with the crash-unaware version, the crash-
aware version queries the underlying program more times for CRASH judgment (see Table 5), and
thus results in a much better performance."
E,0.721627408993576,"C
THEOREMS AND PROOFS"
E,0.7237687366167024,"C.1
THE PRODUCT OF TWO NORMAL DISTRIBUTIONS"
E,0.7259100642398287,"In this section, we will show that the product of two normal distributions is a scaled normal distri-
bution."
E,0.728051391862955,Theorem C.1 (The product of two normal distributions). Given two normal distributions that sat-
E,0.7301927194860813,"isfies p(x) =
1
‚àö"
E,0.7323340471092077,2œÄœÉe‚àí(x‚àí¬µ)2
E,0.734475374732334,"2œÉ2 , the product of them is a scaled normal ‚Äùdistribution‚Äù in the form of Œ±
1
‚àö"
E,0.7366167023554604,2œÄœÉ‚Ä≤ e‚àí(x‚àí¬µ‚Ä≤)2
E,0.7387580299785867,"2œÉ‚Ä≤2
, where Œ± is the scale factor."
E,0.7408993576017131,Proof. Suppose we have two normal distributions pa and pb:
E,0.7430406852248393,"pa(x) =
1
‚àö"
E,0.7451820128479657,"2œÄœÉa
e
‚àí(x‚àí¬µa)2"
E,0.7473233404710921,"2œÉ2a
,"
E,0.7494646680942184,"pb(x) =
1
‚àö"
E,0.7516059957173448,"2œÄœÉb
e
‚àí
(x‚àí¬µb)2"
E,0.7537473233404711,"2œÉ2
b
. (13)"
E,0.7558886509635975,The product of pa and pb:
E,0.7580299785867237,"pa(x)pb(x) =
1
‚àö"
E,0.7601713062098501,"2œÄœÉa
e
‚àí(x‚àí¬µa)2"
E,0.7623126338329764,"2œÉ2a
¬∑
1
‚àö"
E,0.7644539614561028,"2œÄœÉb
e
‚àí
(x‚àí¬µb)2 2œÉ2
b"
E,0.7665952890792291,"=
1
2œÄœÉaœÉb
e
‚àí( (x‚àí¬µa)2"
E,0.7687366167023555,"2œÉ2a
+
(x‚àí¬µb)2"
E,0.7708779443254818,"2œÉ2
b
). (14)"
E,0.7730192719486081,Published as a conference paper at ICLR 2022
E,0.7751605995717344,Algorithm 2 Query by committee (QBC): crash-aware
E,0.7773019271948608,"1: function QUERY( )
2:
Initialize trained model M, query pool Q and max query times T
3:
p ‚ÜêUnderlying program (oracle)
4:
repeat
5:
x1 ‚ÜêsamplefromQ
6:
y1 ‚Üêp(x1)
7:
until y1 not CRASH
8:
JeK ‚Üê{(x1, y1)}
9:
for t ‚àà{2 . . . T} do
10:
program candidates JÀÜpK ‚ÜêM(JeK)
‚ñ∑Get top K predictions by beam search
11:
xt ‚ÜêSELECT-QUERY(Q, p, JÀÜpK)
12:
yt ‚Üêp(xt)
13:
JeK ‚ÜêJeK ‚à™{(xt, yt)}
14:
end for
15:
return JeK
16: end function"
E,0.7794432548179872,"1: function SELECT-QUERY(Q, p, JÀÜpK)
2:
repeat
3:
queries ‚Üêsample 100 times from Q
4:
score list ‚Üê[]
‚ñ∑Acquisition scores of queries
5:
for q ‚ààqueries do
6:
sq ‚Üê0
7:
for ÀÜp ‚ààJÀÜpK do
8:
ÀÜy ‚ÜêÀÜp(q)
9:
if ÀÜy is unique then
10:
sq ‚Üêsq + 1
‚ñ∑The more diversity the output, the better the query
11:
end if
12:
end for
13:
score list.append((q, sq))
14:
end for
15:
Sort score list in a descending order with sq
16:
for q ‚ààscore list do
‚ñ∑Select the query with the highest score and without CRASH
17:
y ‚Üêp(q)
18:
if y not CRASH then
19:
return q
20:
end if
21:
end for
22:
until a query is found
‚ñ∑If all 100 queries result in CRASH, repeat this process.
23: end function"
E,0.7815845824411135,Consider the index part
E,0.7837259100642399,(x ‚àí¬µa)2
E,0.7858672376873662,"2œÉ2a
+ (x ‚àí¬µb)2"
E,0.7880085653104925,"2œÉ2
b
= (œÉ2
a + œÉ2
b)x2 ‚àí2(¬µbœÉ2
a + ¬µaœÉ2
b)x + (¬µ2
aœÉ2
b + ¬µ2
bœÉ2
a)
2œÉ2a2œÉ2
b"
E,0.7901498929336188,"=
x2 ‚àí2 ¬µbœÉ2
a+¬µaœÉ2
b
œÉ2
a+œÉ2
b
x + ¬µ2
bœÉ2
a+¬µ2
aœÉ2
b
œÉ2
a+œÉ2
b
2œÉ2
aœÉ2
b
œÉ2a+œÉ2
b"
E,0.7922912205567452,"=
(x ‚àí¬µbœÉ2
a+¬µaœÉ2
b
œÉ2a+œÉ2
b
)2"
E,0.7944325481798715,"2œÉ2aœÉ2
b
œÉ2a+œÉ2
b +"
E,0.7965738758029979,"¬µ2
bœÉ2
a+¬µ2
aœÉ2
b
œÉ2a+œÉ2
b
‚àí( ¬µbœÉ2
a+¬µaœÉ2
b
œÉ2a+œÉ2
b
)2"
E,0.7987152034261242,"2œÉ2aœÉ2
b
œÉ2a+œÉ2
b
= Œ≥ + Œª, (15)"
E,0.8008565310492506,Published as a conference paper at ICLR 2022 where
E,0.8029978586723768,"Œ≥ =
(x ‚àí¬µbœÉ2
a+¬µaœÉ2
b
œÉ2a+œÉ2
b
)2"
E,0.8051391862955032,"2œÉ2aœÉ2
b
œÉ2a+œÉ2
b , Œª ="
E,0.8072805139186295,"¬µ2
bœÉ2
a+¬µ2
aœÉ2
b
œÉ2a+œÉ2
b
‚àí( ¬µbœÉ2
a+¬µaœÉ2
b
œÉ2a+œÉ2
b
)2"
E,0.8094218415417559,"2œÉ2aœÉ2
b
œÉ2a+œÉ2
b . (16)"
E,0.8115631691648822,Simplify Œª: Œª =
E,0.8137044967880086,"¬µ2
bœÉ2
a+¬µ2
aœÉ2
b
œÉ2a+œÉ2
b
‚àí( ¬µbœÉ2
a+¬µaœÉ2
b
œÉ2a+œÉ2
b
)2"
E,0.815845824411135,"2œÉ2aœÉ2
b
œÉ2a+œÉ2
b"
E,0.8179871520342612,"= (¬µ2
bœÉ2
a + ¬µ2
aœÉ2
b)(œÉ2
a + œÉ2
b) ‚àí(¬µbœÉ2
a + ¬µaœÉ2
b)2"
E,0.8201284796573876,"2œÉ2aœÉ2
b(œÉ2a + œÉ2
b)"
E,0.8222698072805139,"= œÉ2
aœÉ2
b(¬µ2
a + ¬µ2
b ‚àí2¬µa¬µb)
2œÉ2aœÉ2
b(œÉ2a + œÉ2
b)"
E,0.8244111349036403,= (¬µa ‚àí¬µb)2
E,0.8265524625267666,"2(œÉ2a + œÉ2
b). (17)"
E,0.828693790149893,"Finally, we get"
E,0.8308351177730193,"pa(x)pb(x) =
1
2œÄœÉaœÉb
e‚àíŒªe‚àíŒ≥"
E,0.8329764453961456,"= Œ± ¬∑
1
‚àö"
E,0.8351177730192719,2œÄœÉ‚Ä≤ e‚àí(x‚àí¬µ‚Ä≤)2
E,0.8372591006423983,"2œÉ‚Ä≤2
,
(18) where"
E,0.8394004282655246,"¬µ‚Ä≤ = ¬µbœÉ2
a + ¬µaœÉ2
b
œÉ2a + œÉ2
b
, œÉ‚Ä≤ = s"
E,0.841541755888651,"œÉ2aœÉ2
b
œÉ2a + œÉ2
b
,"
E,0.8436830835117773,"Œ± =
1
p"
E,0.8458244111349036,"2œÄ(œÉ2a + œÉ2
b)
e
‚àí
(¬µa‚àí¬µb)2"
E,0.8479657387580299,"2(œÉ2a+œÉ2
b ) . (19)"
E,0.8501070663811563,"Next, we will show that approximating the new ¬µ‚Ä≤ and log(œÉ‚Ä≤2) with the weighted sum of the [¬µa, ¬µb]
and [log(œÉ2
a), log(œÉ2
b)] is reasonable."
E,0.8522483940042827,"For ¬µ‚Ä≤, it is obvious that it can be seen as"
E,0.854389721627409,"¬µ‚Ä≤ = ¬µbœÉ2
a + ¬µaœÉ2
b
œÉ2a + œÉ2
b
,"
E,0.8565310492505354,"=
œÉ2
b
œÉ2a + œÉ2
b
¬∑ ¬µa +
œÉ2
a
œÉ2a + œÉ2
b
¬∑ ¬µb,
(20)"
E,0.8586723768736617,"which is a weighted sum. For log(œÉ‚Ä≤2), we can rewrite it as follows"
E,0.860813704496788,"log(œÉ‚Ä≤2) = log( œÉ2
aœÉ2
b
œÉ2a + œÉ2
b
),"
E,0.8629550321199143,"= log(œÉ2
a) + log(œÉ2
b) ‚àílog(œÉ2
a + œÉ2
b)"
E,0.8650963597430407,"= log(œÉ2
a) + log(œÉ2
b) ‚àí(hlog(œÉ2
a) + klog(œÉ2
b) + log(
1"
E,0.867237687366167,"œÉ2k
b œÉ2(h‚àí1)
a
+
1"
E,0.8693790149892934,"œÉ2h
a œÉ2(k‚àí1)
b
))"
E,0.8715203426124197,"= (1 ‚àíh)log(œÉ2
a) + (1 ‚àík)log(œÉ2
b) ‚àílog(
1"
E,0.8736616702355461,"œÉ2k
b œÉ2(h‚àí1)
a
+
1"
E,0.8758029978586723,"œÉ2h
a œÉ2(k‚àí1)
b
), (21)"
E,0.8779443254817987,Published as a conference paper at ICLR 2022
E,0.880085653104925,"program
qA
qB
qC
qD
p0
‚àö
√ó
√ó
√ó
p1
‚àö
√ó
√ó
‚àö"
E,0.8822269807280514,"p2
‚àö
√ó
‚àö
‚àö"
E,0.8843683083511777,"p3
‚àö
‚àö
‚àö
√ó
p4
√ó
‚àö
‚àö
√ó
p5
√ó
‚àö
‚àö
‚àö"
E,0.8865096359743041,"p6
√ó
‚àö
√ó
√ó
p7
√ó
√ó
√ó
‚àö"
E,0.8886509635974305,"Figure 13: An example: 8 candidate programs p0‚àí7 and 4 queries qA‚àíD each with 2 possible
responses {‚àö, √ó}."
E,0.8907922912205567,"where h and k are two coefficients. With suitable h and k learned, the last term can be ignored
(
1
œÉ2k
b œÉ2(h‚àí1)
a
+
1
œÉ2h
a œÉ2(k‚àí1)
b
‚âà1) and thus log(œÉ‚Ä≤2) can be approximate by the weighted sum of"
E,0.892933618843683,"[log(œÉ2
a), log(œÉ2
b)]."
E,0.8950749464668094,"C.2
THE RECURRENT TRAINING PROCESS"
E,0.8972162740899358,"We adopt a recurrent training process to model the mutual information between the input-output
examples and the programs more accurately. Traditionally, the next query is gained by selecting the
query with the maximum mutual information conditioned on the former ones:"
E,0.8993576017130621,"qk = arg max
x
I(P; (x, y)|JeKk‚àí1)
(22)"
E,0.9014989293361885,"However, this greedy strategy fails in some cases. An example is shown in Figure 13. Suppose
that after a series of queries, and finally there are only 8 candidate programs P = {p0, ..., p7}
distributed uniformly and 4 queries Q = {qA, ..., qD} each with 2 possible responses {‚àö, √ó} left,
our goal is to find out the underlying program with as few queries as possible (conditioned on the
former queries which are omitted). According to the definition of the mutual information I(X; Y ) =
P x‚ààX
P"
E,0.9036402569593148,"y‚ààY P(x, y)log
P (x,y)
P (x)P (y), we can calculate the mutual information between the 4 queries
and the programs as follows (we use qA‚àíD = ‚àö/√ó to represent pi(qA‚àíD) = ‚àö/√ó for simplicity):"
E,0.9057815845824411,"I(P; qA) =
X p‚ààP X"
E,0.9079229122055674,"qA‚àà{‚àö,√ó}
P(p, qA)log P(p, qA)"
E,0.9100642398286938,"P(p)P(qA)
= 8 ‚àó1"
E,0.9122055674518201,8 ‚àólog(
E,0.9143468950749465,"1
8
1
8 ‚àó1"
E,0.9164882226980728,"2
) = 1.
(23)"
E,0.9186295503211992,"Samilarly, I(P; qB) = I(P; qC) = I(P; qD) = 1. Thus, Equation 22 suggests that 4 queries share
the same priority. When the query process continues, however, this is not the case. For the second
query (let q = (qA, qB)):"
E,0.9207708779443254,"I(P; q) =
X p‚ààP X"
E,0.9229122055674518,"q‚àà{‚àö,√ó}2
P(p, q)log P(p, q)"
E,0.9250535331905781,"P(p)P(q)
= 6 ‚àó1"
E,0.9271948608137045,8 ‚àólog(
E,0.9293361884368309,"1
8
1
8 ‚àó3"
E,0.9314775160599572,"8
) + 2 ‚àó1"
E,0.9336188436830836,8 ‚àólog(
E,0.9357601713062098,"1
8
1
8 ‚àó1"
E,0.9379014989293362,"8
) = 1.81,"
E,0.9400428265524625,"(24)
where {‚àö, √ó}2 = {‚àö, √ó} √ó {‚àö, √ó}. Similarly,"
E,0.9421841541755889,"I(P; (qA, qC)) = I(P; (qA, qD)) = I(P; (qC, qD)) = 2,
I(P; (qB, qC)) = I(P; (qB, qD)) = 1.81.
(25)"
E,0.9443254817987152,"Equation 24 and Equation 25 show that considering the longer horizon, qB is the worst choice as
the first query because it gets the minimum mutual information whichever the second query is. This
conclusion is also straightforward without calculation: if we choose qA,C,D as the first query, then
we only need to query for two more times; And if we choose qB as the first query, then we need 3.25
queries on average with 4 queries in the worst case."
E,0.9464668094218416,"To this end, we adopt a recurrent training process as shown in Figure 3. In the recurrent training
process, the gradient can be propagated through multiple query steps and thus the current query
selection can be affected by future queries."
E,0.9486081370449678,Published as a conference paper at ICLR 2022
E,0.9507494646680942,"D
ADDITIONAL RELATED WORK"
E,0.9528907922912205,"D.1
ACTIVE LEARNING"
E,0.9550321199143469,"Active learning is a research domain that aims to reduce the cost of labeling by selecting the most
representative samples iteratively from the unlabeled dataset and then asking them to an oracle
for labeling while training. According to Shui et al. (2020), active learning can be divided into
pool-based sampling (Angluin, 1988; King et al., 2004), which judges whether a sample should
be selected for query-based on the evaluation of the entire dataset; steam-based sampling (Dagan
& Argamon, 1995; Krishnamurthy, 2002), which judges each sample independently compared to
pool-based sampling; and membership query synthesis (Lewis & Gale, 1994), which means that the
unlabeled sample can be generated by the learner instead of selecting from the dataset only. Al-
though active learning involves querying an oracle iteratively, which is similar to our framework,
there are still two main differences between them. (1) For the final purpose, active learning aims to
finish the training stage at a low cost, and the inference stage remains the same as other machine
learning tasks without the query process, while our framework aims to find the oracle (i.e.the un-
derlying program) in a symbolic form, and the query process is retained during inference. (2) For
the query process, active learning assumes only one oracle (i.e.the same query always gets the same
label). In contrast, our framework assumes multiple oracles (i.e.the same query will get different
responses if the underlying programs are different)."
E,0.9571734475374732,"D.2
AUTOMATED BLACK-BOX TESTING"
E,0.9593147751605996,"Black-box testing is a method of software testing aiming to examine the functionality of a black-
box (such as a piece of a program) by a large number of test cases without perceiving its inter-
nal structures. The most famous automated test cases generation method is learning-based testing
(LBT) (Meinke, 2004; Meinke & Niu, 2010; Meinke & Sindhu, 2011). LBT is an iterative approach
to generate test cases by interacting with the black-box, which sounds similar to the query problem
mentioned in this paper. However, the settings and the purpose of the black-box testing are totally
different from ours. In detail, the black-box testing assumes the existence of a target requirement
(or target function) and a black-box implementation of this requirement (such as a piece of program
which is unknown). The purpose is to check the black-box implementation to ensure that there
is no bug or difference between the target requirement and the black-box by generating test cases
(i.e.input-output examples). In a contrast, in our settings, the target function does not exist, and all
we have is a black-box (or called oracle / underlying program in our paper). Our goal is to query
this black box and guess which program is hidden inside based on the experience learned from the
training set."
E,0.961456102783726,"E
TWO QUERY EXAMPLES"
E,0.9635974304068522,"In this section, we show two query examples that cover all branches of the program while the well-
designed dataset fails to do this. Each example consists of the underlying program and the corre-
sponding important queries that improve the branch coverage. See Figure 14 and Figure 15."
E,0.9657387580299786,Published as a conference paper at ICLR 2022
E,0.9678800856531049,"I
O
Program"
E,0.9700214132762313,def run():
E,0.9721627408993576,if markersPresent:
E,0.974304068522484,"putMarker
if not rightIsClear:"
E,0.9764453961456103,"putMarker
move
pickMarker
turnRight
repeat R=2:"
E,0.9785867237687366,"turnLeft
putMarker
putMarker
move
putMarker"
E,0.9807280513918629,Figure 14: An query example of Karel. The number in the cell denotes the amount of markers.
E,0.9828693790149893,Published as a conference paper at ICLR 2022
E,0.9850107066381156,"I
O
Program"
E,0.987152034261242,def run():
E,0.9892933618843683,repeat R=2:
E,0.9914346895074947,"putMarker
turnRight
if frontIsClear:"
E,0.9935760171306209,"putMarker
putMarker
turnRight
putMarker
while rightIsClear:"
E,0.9957173447537473,"move
move
pickMarker
turnRight
turnLeft
turnLeft
move
putMarker
turnLeft"
E,0.9978586723768736,Figure 15: Another query example of Karel. The number in the cell denotes the amount of markers.
