Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0012091898428053204,"Finite-difference methods are a class of algorithms designed to solve black-box
optimization problems by approximating a gradient of the target function on a set
of directions. In black-box optimization, the non-smooth setting is particularly
relevant since, in practice, differentiability and smoothness assumptions cannot be
verified. To cope with nonsmoothness, several authors use a smooth approximation
of the target function and show that finite difference methods approximate its
gradient. Recently, it has been proved that imposing a structure in the directions
allows improving performance. However, only the smooth setting was considered.
To close this gap, we introduce and analyze O-ZD, the first structured finite-
difference algorithm for non-smooth black-box optimization. Our method exploits
a smooth approximation of the target function and we prove that it approximates its
gradient on a subset of random orthogonal directions. We analyze the convergence
of O-ZD under different assumptions. For non-smooth convex functions, we obtain
the optimal complexity. In the non-smooth non-convex setting, we characterize
the number of iterations needed to bound the expected norm of the smoothed
gradient. For smooth functions, our analysis recovers existing results for structured
zeroth-order methods for the convex case and extends them to the non-convex
setting. We conclude with numerical simulations where assumptions are satisfied,
observing that our algorithm has very good practical performances."
INTRODUCTION,0.0024183796856106408,"1
Introduction"
INTRODUCTION,0.0036275695284159614,"Black-box optimization problems are a class of problems for which only values of the target function
are available and no first-order information is provided. Typically, these problems arise when the
evaluation of the objective function is based on a simulation and no analytical form of the gradient is
accessible or its explicit calculation is too expensive [14, 45, 36, 35]."
INTRODUCTION,0.0048367593712212815,"To face these problems, different methods that do not require first-order information have been
proposed - see for instance [39, 47, 19, 26, 20, 30, 33] and references therein. These techniques are
called derivative-free methods and a wide class of these is the class of finite-difference algorithms
[31, 39, 17]. These iterative procedures mimic first-order optimization strategies by replacing the
gradient of the objective function with an approximation built through finite differences in random
directions."
INTRODUCTION,0.006045949214026602,"Two types of finite-difference methods can be identified: unstructured and structured ones, depending
on the way in which the random directions are generated. In the former, directions are sampled i.i.d.
from some distribution [39, 17, 10, 46] while in the latter, directions have to satisfy some structural
constraints, e.g. orthogonality [32, 42]. Several authors [32, 42, 5, 12] theoretically and empirically"
INTRODUCTION,0.007255139056831923,"∗MaLGa-DIBRIS,
University
of
Genova,
IT
(marco.rando@edu.unige.it,
lorenzo.rosasco@unige.it).
†MaLGa - DIMA, University of Genova, Italy (molinari@dima.unige.it, silvia.villa@unige.it).
‡Istituto Italiano di Tecnologia, Genova, Italy and CBMM - MIT, Cambridge, MA, USA"
INTRODUCTION,0.008464328899637243,"observed that imposing orthogonality among the directions provides better performance than using
unstructured directions. Intuitively, imposing orthogonality allows us to avoid cases in which the
gradient approximation is built using similar or redundant directions."
INTRODUCTION,0.009673518742442563,"Notably, methods based on structured finite differences have been analyzed only for smooth and
convex (or specific non-convex) target functions. This represents a strong limitation, since smoothness
and convexity are in practice hardly verifiable, due to the nature of black-box optimization problems.
The aim of this paper is the analysis of structured finite difference algorithms dropping smoothness
and convexity assumptions."
INTRODUCTION,0.010882708585247884,"For unstructured finite-difference methods, a common way to face nonsmoothness consists in intro-
ducing a smooth approximation of the target function, also known as ""smoothing"" [6, 16] and using
it as a surrogate of the target. Although the gradient of the smoothing is not computable, different
authors showed that for certain types of smoothing the unstructured finite-difference approximation
provides an unbiased estimation of such a gradient - see, for example, [39, 46, 18, 22, 21, 24]. This
key observation allows to prove that unstructured finite-difference methods approximate a solution in
different nonsmooth settings [17, 39, 46, 18, 22, 34]."
INTRODUCTION,0.012091898428053204,"For structured finite-difference methods, the analysis in the nonsmooth setting is not available. A key
step which is missing is the proof of the fact that the surrogate of the gradient built with structured
directions is an estimation of the gradient of a suitable smoothing."
INTRODUCTION,0.013301088270858524,"In this paper, we close the gap, and introduce O-ZD, a structured finite-difference algorithm in the
non-smooth setting. The algorithm builds an approximation of the gradient of a smoothed target using
a set of ℓ≤d orthogonal directions. We analyze the procedure proving that our finite-difference
surrogate is an unbiased estimation of the gradient of a smoothing. We provide convergence rates
for non-smooth convex functions with optimal dependence on the dimension [17] and rates for
the non-smooth non-convex setting (for which lower bounds are not known [34]). Moreover, for
non-smooth convex functions we provide the first proof of convergence of the iterates for structured
finite differences in this setting. For smooth convex functions, we recover the standard results for
structured zeroth-order methods [32, 42]. We conclude with numerical illustrations. To the best of our
knowledge, this is the first work on nonsmooth finite-difference method with structured directions."
INTRODUCTION,0.014510278113663845,"The paper is organized as follows. In Section 2, we introduce the problem and the algorithm. In
Section 3, we state and discuss the main results. In Section 4 we provide some experiments and in 5
some final remarks."
PROBLEM SETTING & ALGORITHM,0.015719467956469165,"2
Problem Setting & Algorithm"
PROBLEM SETTING & ALGORITHM,0.016928657799274487,"Given a function f : Rd →R and assuming that f has at least a minimizer in Rd, we consider the
problem to find
x∗∈arg min
x∈Rd
f(x).
(1)"
PROBLEM SETTING & ALGORITHM,0.018137847642079808,"In particular, we consider the non-smooth setting where f might be non-differentiable. To solve
problem (1), we propose a zeroth-order algorithm, namely an iterative procedure that uses only
function values. At every iteration k ∈N, a first-order information of f is approximated with
finite-differences using a set of ℓ≤d random orthogonal directions (p(i)
k )ℓ
i=1. Such orthogonal
directions are represented as rotations (and reflections) of the first ℓvectors of the canonical basis
(ei)ℓ
i=1. We set p(i)
k
= Gkei, where Gk belongs to the orthogonal group defined as"
PROBLEM SETTING & ALGORITHM,0.019347037484885126,O(d) := {G ∈Rd×d | det G ̸= 0 ∧G−1 = G⊺}.
PROBLEM SETTING & ALGORITHM,0.020556227327690448,"Methods for generating orthogonal matrices are discussed in Appendix D. Given G ∈O(d), 0 < ℓ≤
d and h > 0, we consider the following central finite-difference surrogate of the gradient information"
PROBLEM SETTING & ALGORITHM,0.02176541717049577,"g(G,h)(x) = d ℓ ℓ
X i=1"
PROBLEM SETTING & ALGORITHM,0.022974607013301087,f(x + hGei) −f(x −hGei)
H,0.02418379685610641,"2h
Gei.
(2)"
H,0.02539298669891173,"Then, we introduce the following algorithm."
H,0.026602176541717048,Algorithm 1 O-ZD: Orthogonal Zeroth-order Descent
H,0.02781136638452237,"Input: x0 ∈Rd, (αk)k∈N ⊂R+, (hk)k∈N ⊂R+, ℓ∈N s.t. 1 ≤ℓ≤d
for k = 1, · · · do"
H,0.02902055622732769,"sample Gk i.i.d. from O(d)
xk+1 = xk −αkg(Gk,hk)(xk)
end for"
H,0.030229746070133012,"Starting from an initial guess x0 ∈Rd, at every iteration k ∈N, the algorithm samples an orthog-
onal matrix Gk i.i.d. from the orthogonal group O(d) and computes a surrogate g(Gk,hk) of the
gradient at the current iterate xk. Then, it computes xk+1 by moving in the opposite direction of
g(Gk,hk)(xk). This approach belongs to the class of structured finite-difference methods, where a
bunch of orthogonal directions is used to approximate a gradient of the target function [32, 42]. Such
algorithms have been proposed and analyzed only for smooth functions. To cope with this limitation,
and extend the analysis to the nonsmooth setting, we exploit a smoothing technique. For a fixed a
probability measure ρ on Rd and a positive parameter h > 0 called smoothing parameter, we define
the following smooth surrogate of f"
H,0.03143893591293833,"fh,ρ(x) :=
Z
f(x + hu) dρ(u).
(3)"
H,0.032648125755743655,"As shown in [6], fh,ρ is differentiable even when f is not. In the literature, different authors have used
this strategy to face non-smooth zeroth-order optimization with random finite-difference methods
[18, 39, 49, 22] fixing specific smoothing distribution, but no one applied and analyze it for structured
methods."
H,0.03385731559854897,"In this work, ρ is the uniform distribution over the ℓ2 unit ball Bd, defining the smooth surrogate"
H,0.03506650544135429,"fh(x) =
1
vol(Bd) Z"
H,0.036275695284159616,"Bd f(x + hu) du,
(4)"
H,0.037484885126964934,"where vol(Bd) denotes the volume of Bd. One of our main contributions is the following Lemma
which shows that the surrogate proposed in (2) is an unbiased estimator of the gradient of the
smoothing in (4).
Lemma 1 (Smoothing Lemma). Given a probability space (Ω, F, P), let G : Ω→O(d) be a random
variable where O(d) is the orthogonal group endowed with the Borel σ-algebra. Assume that the
probability distribution of G is the (normalized) Haar measure. Let h > 0 and let g be the gradient
surrogate defined in eq. (2). Then,"
H,0.03869407496977025,"(∀x ∈Rd)
EG[g(G,h)(x)] = ∇fh(x),
where fh is the smooth approximation of the target function f defined in eq. (4)."
H,0.03990326481257558,"The proof of Lemma 1 is provided in Appendix A.1.
Remark 1. Note that Lemma 1 holds also using gF
(G,h) or gS
(G,h) defined as"
H,0.041112454655380895,"gF
(G,h)(x) := d ℓ ℓ
X i=1"
H,0.04232164449818621,f(x + hGei) −f(x)
H,0.04353083434099154,"h
Gei
and
gS
(G,h)(x) := d ℓ ℓ
X i=1"
H,0.044740024183796856,f(x + hGei)
H,0.045949214026602174,"h
Gei,"
H,0.0471584038694075,"since EG[g(G,h)(x)] = EG[gF
(G,h)(x)] = EG[gS
(G,h)(x)]. Despite these two estimators being com-
putationally cheaper than the proposed one, we use central finite differences since they allow us to
derive a better bound for EG[∥g(G,h)(x)∥2] as observed in [46] for the case ℓ= 1."
H,0.04836759371221282,"Thanks to Lemma 1, we can interpret each step of Algorithm 1 as a Stochastic Gradient Descent
(SGD) on the smoothed function fhk. But the analysis of the proposed algorithm does not follow
from the SGD one for two reasons. First, the smoothing parameter hk changes along the iterations;
second (and more importantly), the set of minimizers of fh and f are different in general. However,
we will take advantage of the fact that fh can be seen as an approximation of f. The relationship
between f and its approximation fh depends on the properties of f - see Proposition 1 in Appendix
A."
H,0.049576783555018135,"Our main contributions are the theoretical and numerical analysis of Algorithm 1 under different
choices of the free parameters αk, hk, namely the stepsize and the smoothing parameter. To the best of
our knowledge, Algorithm 1 is the first structured zeroth-order method for non-smooth optimization."
RELATED WORK,0.05078597339782346,"2.1
Related Work"
RELATED WORK,0.05199516324062878,"In practice, the advantage of the use of structured directions in finite-difference methods has been
observed in several applications [12] and motivated their study. In [5], the authors theoretically
and empirically observed that structured directions provide a better approximation of the gradient
with respect to unstructured (Gaussian and spherical) ones. Next, we review the most related works,
showing the differences with our algorithm."
RELATED WORK,0.053204353083434096,"Unstructured Finite-differences.
Most of existing works focused on the theoretical analysis of
methods using a single direction to approximate the gradient - see e.g. [39, 46, 22, 45, 18, 24,
34, 17, 10]. The main results existing so far analyze the convergence of the function values in
expectation. They provide convergence rates in terms of the number of function evaluations and
explicitly characterize the dependence on the dimension of the ambient space.
Smooth setting: In [39, 17], a finite difference algorithm with a single direction is analyzed. Rates
on the expected function values are shown. In [39] the dependence on the dimension in the rates
is not optimal. In [17], both single and multiple direction cases are analyzed and lower bounds
are derived. However, only the convex setting is considered. In [24], both convex and non-convex
settings are analyzed. They obtain optimal dependence on dimension in the complexity for convex
functions. However, only the single-direction case is considered and only the smooth setting is
analyzed. Comparing the result with our rates, Algorithm 1 achieves the same dependence on the
dimension in the complexity taking ℓas a fraction of d. Note that, by parallelizing the computation of
the function evaluations, we can get a better result.
Non-smooth setting: In [39, 17] the non-smooth setting is also analyzed. However, only the single
direction case has been considered and both algorithms do not achieve the lower bound. More
precisely, for convex functions, a complexity of O(d2ε−2) is achieved by [39] and O(d log(d)ε−2)
by [17] while our algorithm gets the optimal dependence. Moreover, note that in [17] the strategy
adopted (also called ""double smoothing"") requires tuning one more sequence of parameters, which
is a challenging problem in practice, and only the convex setting is considered. In [39], also the
non-convex setting is analyzed by bounding the expected norm of the smoothed gradient. However,
they obtain a complexity of O(d3ε−2h−1) while our algorithm gets a better dependence on the
dimension. In [46], the optimal complexity is obtained for convex functions. However, the author
does not analyze the non-convex setting. Moreover, note that, despite the complexity in terms of
function evaluations being the same, our algorithm gets a better complexity in terms of the number of
iterations since it uses multiple directions (and this is an advantage if we can parallelize the function
evaluations). Furthermore, note that the method proposed in [46] can be seen as the special case
of Algorithm 1 with ℓ= 1. In [34] the single direction case is analyzed only in the non-convex
setting. The dependence on the dimension of the complexity in the number of function evaluations
achieved matches our result in this setting (again, in the number of iterations our method obtains a
better dependence)."
RELATED WORK,0.05441354292623942,"Structured Finite-difference.
In [32, 42], authors analyze structured finite differences in both
deterministic and stochastic settings. However, only the smooth convex setting is considered. In [12]
orthogonal matrices are used to build directions but no analysis is provided. In [25], finite-difference
with coordinate directions is analyzed. At every iteration, d + 1 function evaluations are performed
to compute the estimator and only the smooth setting is considered."
MAIN RESULTS,0.05562273276904474,"3
Main Results"
MAIN RESULTS,0.056831922611850064,"In this section, we analyze Algorithm 1 considering both non-smooth and smooth problems. We
present the rates obtained by our method for convex and non-convex settings and compare them with
those obtained by state-of-the-art methods. Proofs are provided in Appendix B. In the following,
we call complexity in the number of iterations / function evaluations, respectively, the number of
iterations / function evaluations required to achieve an accuracy ε ∈(0, 1)."
NON-SMOOTH CONVEX SETTING,0.05804111245465538,"3.1
Non-smooth Convex Setting"
NON-SMOOTH CONVEX SETTING,0.0592503022974607,"In this section, we provide the main results for non-smooth convex functions. In particular, we will
assume that the target function is convex and satisfy the following hypothesis."
NON-SMOOTH CONVEX SETTING,0.060459492140266025,"Assumption 1 (L0-Lipschitz continuous). The function f is L0-Lipschitz continuous; i.e., for some
L0 > 0,
(∀x, y ∈Rd)
|f(x) −f(y)| ≤L0∥x −y∥."
NON-SMOOTH CONVEX SETTING,0.06166868198307134,"Note that this assumption implies that also fh is L0-Lipschitz continuous - see Proposition 1.
Moreover, to analyze the algorithm, we will consider the following parameter setting.
Assumption 2 (Zeroth-order non-smooth convergence conditions). The step-size sequence αk and
the sequence of smoothing parameters hk satisfy the following conditions:"
NON-SMOOTH CONVEX SETTING,0.06287787182587666,"αk ̸∈ℓ1,
α2
k ∈ℓ1
and
αkhk ∈ℓ1."
NON-SMOOTH CONVEX SETTING,0.06408706166868199,"The assumption above is required to guarantee convergence to a solution. In particular, the first
two conditions are common for subgradient method and stochastic gradient descent, while the third
condition was already used in structured zeroth-order methods [32, 42] and links the decay of the
smoothing parameter with the stepsize’s one. An example of αk, hk that satisfy Assumption 2 is
αk = k−θ and hk = k−ρ with θ ∈(1/2, 1) and ρ s.t. θ + ρ > 1."
NON-SMOOTH CONVEX SETTING,0.06529625151148731,"We state now the main theorem for non-smooth convex functions.
Theorem 1 (Non-smooth convex). Under Assumption 1, assume that f is convex and let (xk)k∈N
be a sequence generated by Algorithm 1. For every k ∈N, denote Ak = Pk
i=0 αi and set ¯xk :=
Pk
i=0 αixi/Ak. Then"
NON-SMOOTH CONVEX SETTING,0.06650544135429262,"E[f(¯xk) −min f] ≤Sk/Ak
with
Sk := ∥x0 −x∗∥2"
NON-SMOOTH CONVEX SETTING,0.06771463119709795,"2
+ cdL2
0
ℓ k
X"
NON-SMOOTH CONVEX SETTING,0.06892382103990327,"i=0
α2
i + L0 k
X"
NON-SMOOTH CONVEX SETTING,0.07013301088270858,"i=0
αihi,"
NON-SMOOTH CONVEX SETTING,0.07134220072551391,"where c > 0 is a constant independent of the dimension and x∗is any solution in arg min f. Moreover,
under Assumption 2, we have
lim
k→+∞f(xk) = min f
a.s,"
NON-SMOOTH CONVEX SETTING,0.07255139056831923,and that there exists a random variable x∗taking values in arg min f s.t. xk →x∗a.s.
NON-SMOOTH CONVEX SETTING,0.07376058041112454,"In the next corollary, we derive explicit rates for specific choices of the parameters.
Corollary 1. Under the assumptions of Theorem 1, let x∗∈arg min f. Then, the following hold:"
NON-SMOOTH CONVEX SETTING,0.07496977025392987,"(i) Let θ ∈(1/2, 1) and ρ ∈R such that θ + ρ > 1. For every k ∈N, let αk = α(k + 1)−θ
and hk = h(k + 1)−ρ with α > 0 and h > 0. Then"
NON-SMOOTH CONVEX SETTING,0.0761789600967352,"E[f(¯xk) −min f] ≤
C
αk1−θ + o

1
k1−θ 
,"
NON-SMOOTH CONVEX SETTING,0.0773881499395405,for some constant C provided in the proof.
NON-SMOOTH CONVEX SETTING,0.07859733978234583,"(ii) For every k ∈N, let αk = α and hk = h with α, h > 0. Then"
NON-SMOOTH CONVEX SETTING,0.07980652962515115,E[f(¯xk) −min f] ≤∥x0 −x∗∥2
NON-SMOOTH CONVEX SETTING,0.08101571946795647,"2αk
+ cdL2
0
ℓ
α + L0h,"
NON-SMOOTH CONVEX SETTING,0.08222490931076179,where c is a constant independent of the dimension.
NON-SMOOTH CONVEX SETTING,0.08343409915356712,"(iii) Fix an accuracy ε ∈(0, 1) and let K ≥8(cL2
0∥x0−x∗∥2)(d/ℓ)ε−2. Set αk =
q"
NON-SMOOTH CONVEX SETTING,0.08464328899637243,"ℓ
d
∥x0−x∗∥
√"
NON-SMOOTH CONVEX SETTING,0.08585247883917775,"2cKL0 ,
and hk = h ≤ε/(2L0) for every k ≤K. Then"
NON-SMOOTH CONVEX SETTING,0.08706166868198308,E[f(¯xK) −min f] ≤ε
NON-SMOOTH CONVEX SETTING,0.08827085852478839,and the complexity in terms of number of iterations is O((d/ℓ)ε−2).
NON-SMOOTH CONVEX SETTING,0.08948004836759371,"Discussion.
The bound in Theorem 1 depends on the initialization and on an additional quantity
that can be interpreted as an approximation error. The latter is composed of two parts. The first one is
generated by the approximation of the gradient of the smoothed function; while the second, involving
hk, is generated by the smoothing. Since the rate depends on 1/ Pk
i=0 αi, we would like to choose the
stepsize as large as possible. However, to get convergence, we need to make the approximation errors"
NON-SMOOTH CONVEX SETTING,0.09068923821039904,"vanish sufficiently fast. To guarantee this, as we can observe from Theorem 1, we need to impose
some conditions on the stepsize αk and on the smoothing parameter hk (i.e. Assumption 2), that will
slow down the decay of the first term. In Corollary 1, we provide two choices of parameters: the first
one satisfies Assumption 2 and ensures convergence; the second one corresponds to constant stepsize
and smoothing parameter. For the first choice, we recover the rate of the subgradient method in terms
of k. In particular, for θ approaching 1/2, the convergence rate is arbitrarily close to O(k−1/2) and
is similar to the one derived in [17, Theorem 2]. The dependence on the dimension depends on the
choice of the constant α. The optimal dependence is obtained with the choice α =
p"
NON-SMOOTH CONVEX SETTING,0.09189842805320435,"ℓ/d. Indeed, in
that case, the complexity in the number of iterations is of the order O((d/ℓ)ε−2), which is better than
the one achieved by [17, Theorem 2] and [39]. Note that also [46, Corollary 1] and [22, Theorem
2.4] obtain a worse complexity in terms of the number of iterations (since they use a single direction),
but the same complexity in the number of function evaluations. Clearly, since multiple directions are
used, a single iteration of O-ZD will be more expensive than one iteration of [46, 22]. However, our
algorithm is more efficient if the ℓfunction evaluations required at each iteration can be parallelized.
On the more theoretical side, we observe that the advantage of multiple orthogonal directions is in
the tighter bounds for the variance of the estimator, namely for E[∥g(Gk,hk)(xk)∥2] - see [46, Lemma
5] and Lemma 4."
NON-SMOOTH NON-CONVEX SETTING,0.09310761789600967,"3.2
Non-smooth Non-convex Setting"
NON-SMOOTH NON-CONVEX SETTING,0.094316807738815,"To analyze the non-convex setting, following [39], we provide a bound on the averaged expected
square norm of the gradient of the smoothed target. In particular, we use the following notation:"
NON-SMOOTH NON-CONVEX SETTING,0.09552599758162031,"η(h)
k
:= k
X"
NON-SMOOTH NON-CONVEX SETTING,0.09673518742442563,"i=0
αi E[∥∇fh(xi)∥2] !"
NON-SMOOTH NON-CONVEX SETTING,0.09794437726723096,"/Ak,
where Ak := k
X"
NON-SMOOTH NON-CONVEX SETTING,0.09915356711003627,"i=0
αi."
NON-SMOOTH NON-CONVEX SETTING,0.1003627569528416,"Next, we state the main theorem for the non-convex non-smooth setting."
NON-SMOOTH NON-CONVEX SETTING,0.10157194679564692,"Theorem 2 (Non-smooth non-convex). Under Assumption 1, let (xk)k∈N be a sequence generated
by Algorithm 1 with, for every k ∈N, hk = h for some h > 0. Then"
NON-SMOOTH NON-CONVEX SETTING,0.10278113663845223,"η(h)
k
≤Sk/Ak
with
Sk := fh(x0) −min f + cL3
0d
√ d
ℓ k
X i=0"
NON-SMOOTH NON-CONVEX SETTING,0.10399032648125756,"α2
i
h ."
NON-SMOOTH NON-CONVEX SETTING,0.10519951632406288,"In the next corollary, we derive the rates for specific choices of the parameters."
NON-SMOOTH NON-CONVEX SETTING,0.10640870616686819,"Corollary 2. Under the assumptions of Theorem 2, the following statements hold."
NON-SMOOTH NON-CONVEX SETTING,0.10761789600967352,"(i) If αk = α(k + 1)−θ with α > 0 and θ ∈(1/2, 1), then"
NON-SMOOTH NON-CONVEX SETTING,0.10882708585247884,"η(h)
k
≤C fh(x0) −min f"
NON-SMOOTH NON-CONVEX SETTING,0.11003627569528417,"αk1−θ
+ o

1
k1−θ 
,"
NON-SMOOTH NON-CONVEX SETTING,0.11124546553808948,where C is a constant independent of the dimension.
NON-SMOOTH NON-CONVEX SETTING,0.1124546553808948,"(ii) If αk = α with α > 0 for every k ∈N, then"
NON-SMOOTH NON-CONVEX SETTING,0.11366384522370013,"η(h)
k
≤fh(x0) −min f"
NON-SMOOTH NON-CONVEX SETTING,0.11487303506650544,"αk
+ cL3
0d
√"
NON-SMOOTH NON-CONVEX SETTING,0.11608222490931076,"d
ℓh
α,"
NON-SMOOTH NON-CONVEX SETTING,0.11729141475211609,where c is a constant independent of the dimension.
NON-SMOOTH NON-CONVEX SETTING,0.1185006045949214,"(iii) Let ε
∈
(0, 1), let K
≥
4(fh(x0) −min f)cL3
0d
√"
NON-SMOOTH NON-CONVEX SETTING,0.11970979443772672,"dε−2/(ℓh) and choose α
=
q"
NON-SMOOTH NON-CONVEX SETTING,0.12091898428053205,(fh(x0)−min f)ℓh
NON-SMOOTH NON-CONVEX SETTING,0.12212817412333736,"KcL3
0d
√"
NON-SMOOTH NON-CONVEX SETTING,0.12333736396614269,"d
. Then we have that η(h)
K
≤ε. Thus, the number of function evalua-"
NON-SMOOTH NON-CONVEX SETTING,0.12454655380894801,"tions required to get a precision ηh
k ≤ε is of the order O(d
√"
NON-SMOOTH NON-CONVEX SETTING,0.12575574365175332,dh−1ε−2).
NON-SMOOTH NON-CONVEX SETTING,0.12696493349455865,"Relying on the results in [34], we show that this is related to a precise notion of approximate
stationarity. To do so, we need to introduce a definition of subdifferential which is suitable to this
setting. As shown in [34] the Clarke subdifferential is not the right notion, and the approximate
Goldstein subdifferential should be used instead."
NON-SMOOTH NON-CONVEX SETTING,0.12817412333736397,"Definition 1 (Goldstein subdifferential and stationary point). Under Assumption 1, let x ∈Rd and
h > 0. The h-Goldstein subdifferential of f at x is ∂hf(x) := conv(∪y∈Bd
h(x)∂f(y)) where ∂f is
the Clarke subdifferential [13] and Bd
h(x) is the ball centered in x with radius h. For ε ∈(0, 1), a
point x ∈Rd is a (h, ε)-Goldstein stationary point for the function f if min{∥g∥| g ∈∂hf(x)} ≤ε.
Corollary 3. Under the same assumptions of Theorem 2, fix K ∈N and let I be a random variable
taking values in {0, . . . , K −1} such that, for all i, P[I = i] = αi/AK−1. Let also Sk be defined as
in Theorem 2. Then
EI

min{∥η∥2 : η ∈∂fh(xI)}

≤SK/AK.
In the setting of Corollary 2 (iii), we have also that EI

min{∥η∥2 : η ∈∂fh(xI)}

≤ε."
NON-SMOOTH NON-CONVEX SETTING,0.1293833131801693,"Discussion.
In Theorem 2, we fix the smoothing of the target, i.e. we consider hk constant, and we
analyze the non-smooth non-convex setting providing a rate on the expected norm of the smoothed
gradient. The resulting bound is composed of two parts. The first part is very natural, and due to
the functional value at the initialization. The second part is the approximation error. Recall that
Assumption 1 holds, and therefore fh ≤f + L0h due to Proposition 1. This suggests taking h
as small as possible in order to reduce the gap between fh and f. However, taking h too small
would make the approximation error very big. In our analysis, we consider the case with h constant.
Moreover, as for the convex case, the speed of the rate depends on Ak and so we would like to take
the stepsize as large as possible. But to control the approximation error, we need to assume α2
k ∈ℓ1.
In Corollary 2, we consider two choices of stepsize. The first choice satisfies the property of α2
k ∈ℓ1,
while the second one analyzes the case of constant step-size. Comparing our rate to the one in [39]
we see that we obtain a better dependence on the dimension in the complexity, both in terms of
iterations and function evaluations. Our results match the one of [34, Theorem 3.2] in terms of rate
and in terms of function evaluations. We get a better dependence on the dimension in the number of
iterations. Note again that, despite the complexity in terms of the number of function evaluations
being the same, the possibility of parallelization for the function evaluations yields a better result for
our method. As for the convex setting, we have a tighter upper-bound on the variance of the estimator
of the smoothed gradient with respect to the dimension - see [34, Lemma D.1]. Goldstein stationarity
has been used to assess the approximate stationarity for first-order methods as well, see [15]. The
latter work shows that a cutting plane algorithm achieves a rate of O(dε−3) for Lipschitz functions."
SMOOTH CONVEX SETTING,0.13059250302297462,"3.3
Smooth Convex setting"
SMOOTH CONVEX SETTING,0.13180169286577992,"We consider now the smooth setting, i.e. we assume that the target function satisfies the following
hypothesis.
Assumption 3 (L1-Smooth). The function f is L1-smooth; i.e. the function f is differentiable and,
for some L1 > 0,
(∀x, y ∈Rd)
∥∇f(x) −∇f(y)∥≤L1∥x −y∥."
SMOOTH CONVEX SETTING,0.13301088270858524,"This is the standard assumption for analyzing first-order methods and has been used in many other
works in the literature for zeroth-order algorithms - see e.g. [39, 17]. As shown in previous works,
if f satisfies Assumption 3 then also fh satisfies it - see Proposition 1. We will consider also the
following assumptions on the stepsize and the smoothing in order to guarantee convergence.
Assumption 4 (Smooth zeroth-order convergence conditions). The stepsize sequence (αk)k∈N and
the smoothing sequence (hk)k∈N satisfy the following conditions:"
SMOOTH CONVEX SETTING,0.13422007255139057,"αk ̸∈ℓ1
and
αkhk ∈ℓ1.
Moreover, αk ≤¯α < ℓ/dL1 for every k ∈N."
SMOOTH CONVEX SETTING,0.1354292623941959,"Note that this is a weaker version of Assumption 2. Next, we state the main theorem for convex
smooth functions.
Theorem 3 (Smooth convex). Under Assumptions 3 and 4, let (xk)k∈N be a sequence generated by"
SMOOTH CONVEX SETTING,0.13663845223700122,"Algorithm 1 and x∗∈arg min f. For every k ∈N, set Ak = Pk
i=0 αi and ¯xk =
kP"
SMOOTH CONVEX SETTING,0.13784764207980654,"i=0
αixi/Ak. Then,"
SMOOTH CONVEX SETTING,0.13905683192261184,"for every k ∈N,"
SMOOTH CONVEX SETTING,0.14026602176541716,E[f(¯xk) −min f] ≤Dk
SMOOTH CONVEX SETTING,0.1414752116082225,"Ak
with
Dk := ℓ∆+ d¯α 2ℓ∆"
SMOOTH CONVEX SETTING,0.14268440145102781,"
Sk + k
X"
SMOOTH CONVEX SETTING,0.14389359129383314,"i=0
ρi
p Si + i
X"
SMOOTH CONVEX SETTING,0.14510278113663846,"j=0
ρj

,"
SMOOTH CONVEX SETTING,0.14631197097944376,"where Sk := ∥x0 −x∗∥2 + Pk
i=0
L2
1d2"
SMOOTH CONVEX SETTING,0.1475211608222491,"2ℓα2
i h2
i , ρk := L1dαkhk, and ∆:=

1
L1 −d"
SMOOTH CONVEX SETTING,0.1487303506650544,"ℓ¯α

."
SMOOTH CONVEX SETTING,0.14993954050785974,"Corollary 4. Under the same Assumptions of Theorem 3, the following hold."
SMOOTH CONVEX SETTING,0.15114873035066506,"(i) If for every k ∈N we set αk = α > 0 and hk = h(k + 1)−θ for h > 0 and θ > 1, then"
SMOOTH CONVEX SETTING,0.1523579201934704,"E[f(¯xk) −min f] ≤C αk ,"
SMOOTH CONVEX SETTING,0.15356711003627568,"where C is a constant provided in the proof. Moreover, if α < ℓ/(2dL1), lim
k→∞f(xk) ="
SMOOTH CONVEX SETTING,0.154776299879081,min f a.s. and there exists a random variable ˆx taking values in arg min f s.t. xk →ˆx a.s.
SMOOTH CONVEX SETTING,0.15598548972188633,"(ii) If for every k ∈N we set αk = α > 0 and 0 < hk ≤h, then"
SMOOTH CONVEX SETTING,0.15719467956469166,E[f(¯xk) −min f] ≤C1
SMOOTH CONVEX SETTING,0.15840386940749698,k + C2αh + C3α2h2√
SMOOTH CONVEX SETTING,0.1596130592503023,"k + C4α2h2k,"
SMOOTH CONVEX SETTING,0.1608222490931076,"where C1, C2, C3 and C4 are non-negative constants."
SMOOTH CONVEX SETTING,0.16203143893591293,"Discussion.
As in the previous cases, the bound in Theorem 3 is composed by two terms: the error
due to the initialization and the one due to the approximation. An important difference with the
results in the non-smooth setting is that every term in the approximation error is decreasing with
respect to the smoothing parameter hk. This allows obtaining convergence also with the constant
step-size scheme, taking hk ∈ℓ1. In Corollary 4 (i), we recover the result of [32, Theorem 5.4] with
a specific choice of parameters α, h (up to constants). The complexity depends on the choice of α.
Note that by Assumption 4, α < ℓ/(L1d) thus the dependence on the dimension in the rate will be
at least d/ℓ. In particular, taking α = ℓ/(2dL1), we obtain the optimal complexity of O(dε−1) in
terms of function evaluations. This result has a better dependence on the dimension than [39]. In
Corollary 4 (ii), the dependence on the dimension in the complexity depends on the choice of α
and h. Moreover, the rate obtained is equal (up to constants) to the rate obtained in [32] in the same
setting, i.e. O(1/k) (in which we hide the dependence on d and ℓ). As for [32], for the first setting
we can prove the almost sure convergence of the iterates."
SMOOTH NON-CONVEX SETTING,0.16324062877871826,"3.4
Smooth Non-Convex setting"
SMOOTH NON-CONVEX SETTING,0.16444981862152358,"To analyze the smooth non-convex setting, we introduce the following notation:"
SMOOTH NON-CONVEX SETTING,0.1656590084643289,"(∀k ∈Rd)
Ak := k
X"
SMOOTH NON-CONVEX SETTING,0.16686819830713423,"i=0
αi,
ηk := k
X"
SMOOTH NON-CONVEX SETTING,0.16807738814993953,"i=0
αi E[∥∇f(xi)∥2] ! /Ak."
SMOOTH NON-CONVEX SETTING,0.16928657799274485,"Note that, in comparison with the quantity defined in Section 3.2, here ηk is related to the exact
objective function f and not to its smoothed version fh. Next, we state the main result for smooth
non-convex functions.
Theorem 4 (Smooth non-convex). Suppose that Assumption 3 holds and assume that, for every
k ∈N, αk ≤¯α < ℓ/(2dL1). Let (xk)k∈N be a sequence generated by Algorithm 1. Then"
SMOOTH NON-CONVEX SETTING,0.17049576783555018,"ηk ≤
1
∆Ak "
SMOOTH NON-CONVEX SETTING,0.1717049576783555,"f(x0) −min f + L2
1d2 8 k
X"
SMOOTH NON-CONVEX SETTING,0.17291414752116083,"i=0
αih2
i + L3
1d2 4ℓ k
X"
SMOOTH NON-CONVEX SETTING,0.17412333736396615,"i=0
α2
i h2
i !"
SMOOTH NON-CONVEX SETTING,0.17533252720677148,",
∆:=
1"
SMOOTH NON-CONVEX SETTING,0.17654171704957677,2 −L1d
SMOOTH NON-CONVEX SETTING,0.1777509068923821,"ℓ
¯α

."
SMOOTH NON-CONVEX SETTING,0.17896009673518742,"Corollary 5. Under the assumptions of Theorem 4, the following hold."
SMOOTH NON-CONVEX SETTING,0.18016928657799275,"(i) If αk = α ≤¯α and hk = hk−θ with h > 0 and θ > 1, then"
SMOOTH NON-CONVEX SETTING,0.18137847642079807,"ηk ≤
f(x0) −min f"
SMOOTH NON-CONVEX SETTING,0.1825876662636034,"∆α
+ C1d2h2"
SMOOTH NON-CONVEX SETTING,0.1837968561064087,"∆
+ C2αh2d2 ∆ℓ 
· 1 k ,"
SMOOTH NON-CONVEX SETTING,0.18500604594921402,where C1 and C2 are constants provided in the proof.
SMOOTH NON-CONVEX SETTING,0.18621523579201935,"(ii) If αk = α ≤¯α and hk = h > 0, then"
SMOOTH NON-CONVEX SETTING,0.18742442563482467,ηk ≤f(x0) −min f
SMOOTH NON-CONVEX SETTING,0.18863361547763,"∆αk
+ C1d2h2"
SMOOTH NON-CONVEX SETTING,0.18984280532043532,"∆
+ C2αh2d2 ∆ℓ
,"
SMOOTH NON-CONVEX SETTING,0.19105199516324062,where C1 and C2 are constants provided in the proof.
SMOOTH NON-CONVEX SETTING,0.19226118500604594,"Discussion.
As for the convex case, every term in the approximation error depends on the smoothing
parameter hk. In Corollary 5 (i), we take constant step-size and hk ∈ℓ1. With this choice of
parameters, we get a rate of O(1/k) which matches with the result obtained by [39]. The dependence
on the dimension depends on the choice of α and h. Note that α < ℓ/(2dL1), thus taking h = O(1/d),
in the rate we get a dependence on the dimension of d/ℓ. Taking for instance α = ℓ/(3dL1) and
h = O(1/d), we get a complexity of O(dε−1) in terms of function evaluations."
NUMERICAL RESULTS,0.19347037484885127,"4
Numerical Results"
NUMERICAL RESULTS,0.1946795646916566,"In this section, we provide some numerical experiments to assess the performances of our algorithm.
We consider two target functions: a convex smooth one and a convex non-smooth one. Details on
target functions and parameters of the algorithms are reported in Appendix C. To report our findings,
we run the experiments 10 times and provide the mean and standard deviation of the results."
NUMERICAL RESULTS,0.19588875453446192,"How to choose the number of directions?
In these experiments, we set a fixed budget of 4000
function evaluations and we consider d = 50. We investigate how the performance of Algorithm 1
changes as the value of ℓincreases. In Figure 1, we observe the mean sequence f(xk) −f(x∗) after
each function evaluation. If ℓ> 1, then the target function values are repeated 2ℓtimes, since we
need to perform 2ℓfunction evaluations to do one iteration. For a sufficiently large budget, increasing
the number of directions ℓleads to better results compared to using a single direction in both smooth
and non-smooth settings."
NUMERICAL RESULTS,0.19709794437726724,"0
500
1000
1500
2000
2500
3000
3500
4000
function evaluations 101 102 103"
NUMERICAL RESULTS,0.19830713422007254,f(xk) −f(x * )
NUMERICAL RESULTS,0.19951632406287786,Smooth Convex function
NUMERICAL RESULTS,0.2007255139056832,"ℓ= 1
ℓ= 5
ℓ= 10
ℓ= 20
ℓ= 50"
NUMERICAL RESULTS,0.20193470374848851,"0
500
1000
1500
2000
2500
3000
3500
4000
function evaluations 103"
NUMERICAL RESULTS,0.20314389359129384,7 × 102
NUMERICAL RESULTS,0.20435308343409916,8 × 102
NUMERICAL RESULTS,0.20556227327690446,9 × 102
NUMERICAL RESULTS,0.2067714631197098,f(xk) −f(x * )
NUMERICAL RESULTS,0.2079806529625151,NonSmooth Convex function
NUMERICAL RESULTS,0.20918984280532044,"Figure 1: From left to right, function values per function evaluation in optimizing smooth and
non-smooth target functions with different numbers of directions."
NUMERICAL RESULTS,0.21039903264812576,"Comparison with finite-difference methods.
Now, we compare Algorithm 1 with other finite-
difference methods. More precisely, we consider finite differences with single (and multiple) Gaussian
(and spherical) directions. The budget of function evaluations is 1000 and the ambient dimension is
d = 10. For multiple direction methods, we fix the number of directions ℓ= d. Further experiments
are provided in Appendix F."
NUMERICAL RESULTS,0.21160822249093109,"0
200
400
600
800
1000
function evaluations 10−2 10−1 100 101"
NUMERICAL RESULTS,0.21281741233373638,f(xk) −f(x * )
NUMERICAL RESULTS,0.2140266021765417,Smooth Convex Target
NUMERICAL RESULTS,0.21523579201934703,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Ours"
NUMERICAL RESULTS,0.21644498186215236,"0
200
400
600
800
1000
function evaluations 100 101"
NUMERICAL RESULTS,0.21765417170495768,f(xk) −f(x * )
NUMERICAL RESULTS,0.218863361547763,NonSmooth Convex Target
NUMERICAL RESULTS,0.22007255139056833,"Figure 2: From left to right, function values per function evaluation in optimizing smooth and
non-smooth convex functions with different finite-difference algorithms."
NUMERICAL RESULTS,0.22128174123337363,"In Figure 2, we plot the sequence f(xk) −f(x∗) with respect to the number of function evaluations.
While in terms of rates and complexity the different algorithms are the same, Algorithm 1 shows
better performances than random directions approaches, and we believe this is due to the use of
structured (i.e. orthogonal) directions. Indeed, orthogonal directions yield a better approximation
of first-order information with respect to other methods. The practical advantages of structured
directions were already observed in [32, 42, 5, 12] and these experiments confirm that the good
practical behavior holds even in the nonsmooth setting."
CONCLUSION,0.22249093107617895,"5
Conclusion"
CONCLUSION,0.22370012091898428,"We introduced and analyzed O-ZD a zeroth-order algorithm for non-smooth zeroth-order optimization.
We analyzed the algorithm and derived rates for non-smooth and smooth functions. This work opens
different research directions. An interesting one would be the introduction of a learning procedure
for the orthogonal directions. Such an approach could have significant practical applications."
CONCLUSION,0.2249093107617896,Acknowledgments and Disclosure of Funding
CONCLUSION,0.22611850060459493,"This project has been supported by the TraDE-OPT project, which received funding from the
European Union’s Horizon 2020 research and innovation program under the Marie Skłodowska-Curie
grant agreement No 861137. L. R. and M. R. acknowledge the financial support of the European
Research Council (grant SLING 819789), the AFOSR projects FA9550-18-1-7009 (European Office
of Aerospace Research and Development), the EU H2020-MSCA-RISE project NoMADS - DLV-
777826, and the Center for Brains, Minds and Machines (CBMM), funded by NSF STC award
CCF-1231216. S. V. and L. R. acknowledge the support of the AFOSR project FA8655-22-1-7034.
The research by S. V. and C. M. has been supported by the MIUR Excellence Department Project
awarded to Dipartimento di Matematica, Università di Genova, CUP D33C23001110001. S. V.
and C. M. are members of the Gruppo Nazionale per l’Analisi Matematica, la Probabilità e le
loro Applicazioni (GNAMPA) of the Istituto Nazionale di Alta Matematica (INdAM). This work
represents only the view of the authors. The European Commission and the other organizations are
not responsible for any use that may be made of the information it contains."
REFERENCES,0.22732769044740025,References
REFERENCES,0.22853688029020555,"[1] Hans Wilhelm Alt. Linear Functional Analysis: An Application-Oriented Introduction. Springer
London, London, 2016."
REFERENCES,0.22974607013301088,"[2] T. W. Anderson, I. Olkin, and L. G. Underhill. Generation of random orthogonal matrices.
SIAM Journal on Scientific and Statistical Computing, 8(4):625–629, 1987."
REFERENCES,0.2309552599758162,"[3] J.B. Baillon and G. Haddad. Quelques propriétés des opérateurs angle-bornés etn-cycliquement
monotones. Israel Journal of Mathematics, 26(2):137–150, Jun 1977."
REFERENCES,0.23216444981862153,"[4] A. Barvinok. Approximating orthogonal matrices by permutation matrices. Pure and applied
mathematics quarterly, 2, 11 2005."
REFERENCES,0.23337363966142685,"[5] A. S. Berahas, L. Cao, K. Choromanski, and K. Scheinberg. A theoretical and empirical compar-
ison of gradient approximations in derivative-free optimization. Foundations of Computational
Mathematics, 22(2):507–560, Apr 2022."
REFERENCES,0.23458282950423218,"[6] D. P. Bertsekas. Stochastic optimization problems with nondifferentiable cost functionals.
Journal of Optimization Theory and Applications, 12(2):218–231, Aug 1973."
REFERENCES,0.23579201934703747,"[7] Å. Björck. Numerics of gram-schmidt orthogonalization. Linear Algebra and its Applications,
197-198:297–316, 1994."
REFERENCES,0.2370012091898428,"[8] C. Boutsidis and A. Gittens. Improved matrix algorithms via the subsampled randomized
hadamard transform. SIAM Journal on Matrix Analysis and Applications, 34(3):1301–1340,
2013."
REFERENCES,0.23821039903264812,"[9] Lars Buitinck, Gilles Louppe, Mathieu Blondel, Fabian Pedregosa, Andreas Mueller, Olivier
Grisel, Vlad Niculae, Peter Prettenhofer, Alexandre Gramfort, Jaques Grobler, Robert Layton,
Jake VanderPlas, Arnaud Joly, Brian Holt, and Gaël Varoquaux. API design for machine learning
software: experiences from the scikit-learn project. In ECML PKDD Workshop: Languages for
Data Mining and Machine Learning, pages 108–122, 2013."
REFERENCES,0.23941958887545345,"[10] R. Chen and S. Wild. Randomized derivative-free optimization of noisy convex functions. arXiv
preprint arXiv:1507.03332, 2015."
REFERENCES,0.24062877871825877,"[11] K. Choromanski, M. Rowland, W. Chen, and A. Weller. Unifying orthogonal monte carlo
methods. In International Conference on Machine Learning, pages 1203–1212. PMLR, 2019."
REFERENCES,0.2418379685610641,"[12] K. Choromanski, M. Rowland, V. Sindhwani, R. Turner, and A. Weller. Structured evolution
with compact architectures for scalable policy optimization. In Jennifer Dy and Andreas Krause,
editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of
Proceedings of Machine Learning Research, pages 970–978. PMLR, 10–15 Jul 2018."
REFERENCES,0.2430471584038694,"[13] F. H. Clarke. Optimization and Nonsmooth Analysis. Society for Industrial and Applied
Mathematics, 1990."
REFERENCES,0.24425634824667472,"[14] A. R. Conn, K. Scheinberg, and L. N. Vicente. Introduction to Derivative-Free Optimization.
Society for Industrial and Applied Mathematics, 2009."
REFERENCES,0.24546553808948005,"[15] D. Davis, D. Drusvyatskiy, Y. T. Lee, S. Padmanabhan, and G. Ye. A gradient sampling
method with complexity guarantees for lipschitz functions in high and low dimensions. In
S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in
Neural Information Processing Systems, volume 35, pages 6692–6703. Curran Associates, Inc.,
2022."
REFERENCES,0.24667472793228537,"[16] J. C. Duchi, P. L. Bartlett, L. Peter, and M. J. Wainwright. Randomized smoothing for stochastic
optimization. SIAM Journal on Optimization, 22(2):674–701, 2012."
REFERENCES,0.2478839177750907,"[17] J. C. Duchi, M. I. Jordan, M. J. Wainwright, and A. Wibisono. Optimal rates for zero-order
convex optimization: The power of two function evaluations. IEEE Transactions on Information
Theory, 61(5):2788–2806, 2015."
REFERENCES,0.24909310761789602,"[18] A. Flaxman, A. Tauman Kalai, and B. McMahan. Online convex optimization in the bandit
setting: Gradient descent without a gradient. In SODA ’05 Proceedings of the sixteenth annual
ACM-SIAM symposium on Discrete algorithms, pages 385–394, January 2005."
REFERENCES,0.2503022974607013,"[19] M. Fornasier, T. Klock, and K. Riedl. Consensus-based optimization methods converge globally
in mean-field law. arXiv 2103.15130, 2021."
REFERENCES,0.25151148730350664,"[20] P. I. Frazier. Bayesian Optimization, chapter 11, pages 255–278. INFORMS, 2018."
REFERENCES,0.25272067714631197,"[21] X. Gao, B. Jiang, and S. Zhang. On the information-adaptive variants of the admm: An iteration
complexity perspective. Journal of Scientific Computing, 76(1):327–363, Jul 2018."
REFERENCES,0.2539298669891173,"[22] A. Gasnikov, A. Novitskii, V. Novitskii, F. Abdukhakimov, D. Kamzolov, A. Beznosikov,
M. Takac, P. Dvurechensky, and B. Gu. The power of first-order smooth optimization for
black-box non-smooth problems. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba
Szepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the 39th International Confer-
ence on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages
7241–7265. PMLR, 17–23 Jul 2022."
REFERENCES,0.2551390568319226,"[23] A. Genz. Methods for generating random orthogonal matrices. In Monte-Carlo and Quasi-
Monte Carlo Methods 1998: Proceedings of a Conference held at the Claremont Graduate
University, Claremont, California, USA, June 22–26, 1998, pages 199–213. Springer, 2000."
REFERENCES,0.25634824667472794,"[24] S. Ghadimi and G. Lan. Stochastic first- and zeroth-order methods for nonconvex stochastic
programming. SIAM Journal on Optimization, 23(4):2341–2368, 2013."
REFERENCES,0.25755743651753327,"[25] G. N. Grapiglia. Worst-case evaluation complexity of a derivative-free quadratic regularization
method. Optimization Letters, Feb 2023."
REFERENCES,0.2587666263603386,"[26] N. Hansen. The CMA Evolution Strategy: A Comparing Review, pages 75–102. Springer Berlin
Heidelberg, Berlin, Heidelberg, 2006."
REFERENCES,0.2599758162031439,"[27] C. R. Harris, K. J. Millman, S. J. van der Walt, R. Gommers, P. Virtanen, D. Cournapeau,
E. Wieser, J. Taylor, S. Berg, N. J. Smith, R. Kern, M. Picus, S. Hoyer, M. H. van Kerkwijk,
M. Brett, A. Haldane, J. Fernández del Río, M. Wiebe, P. Peterson, P. Gérard-Marchant,
K. Sheppard, T. Reddy, W. Weckesser, H. Abbasi, C. Gohlke, and T. E. Oliphant. Array
programming with NumPy. Nature, 585(7825):357–362, September 2020."
REFERENCES,0.26118500604594924,"[28] A. Hedayat and W. D. Wallis. Hadamard matrices and their applications. The Annals of
Statistics, 6(6):1184–1238, 1978."
REFERENCES,0.2623941958887545,"[29] J. D. Hunter. Matplotlib: A 2d graphics environment. Computing in Science & Engineering,
9(3):90–95, 2007."
REFERENCES,0.26360338573155984,"[30] N. K. Jain, U. Nangia, and J. Jain. A review of particle swarm optimization. Journal of The
Institution of Engineers (India): Series B, 99(4):407–411, Aug 2018."
REFERENCES,0.26481257557436516,"[31] J. Kiefer and J. Wolfowitz. Stochastic estimation of the maximum of a regression function.
Annals of Mathematical Statistics, 23:462–466, 1952."
REFERENCES,0.2660217654171705,"[32] D. Kozak, C. Molinari, L. Rosasco, L. Tenorio, and S. Villa. Zeroth order optimization with
orthogonal random directions, 2021."
REFERENCES,0.2672309552599758,"[33] R. M. Lewis, V. Torczon, and M. W. Trosset. Direct search methods: then and now. Journal of
Computational and Applied Mathematics, 124(1):191–207, 2000. Numerical Analysis 2000.
Vol. IV: Optimization and Nonlinear Equations."
REFERENCES,0.26844014510278114,"[34] T. Lin, Z. Zheng, and M. Jordan. Gradient-free methods for deterministic and stochastic
nonsmooth nonconvex optimization. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave,
K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35,
pages 26160–26175. Curran Associates, Inc., 2022."
REFERENCES,0.26964933494558646,"[35] S. Liu, P. Y. Chen, B. Kailkhura, G. Zhang, A. O. Hero III, and P. K. Varshney. A primer
on zeroth-order optimization in signal processing and machine learning: Principals, recent
advances, and applications. IEEE Signal Processing Magazine, 37(5):43–54, 2020."
REFERENCES,0.2708585247883918,"[36] H. Mania, A. Guy, and B. Recht. Simple random search of static linear policies is competitive for
reinforcement learning. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi,
and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31. Curran
Associates, Inc., 2018."
REFERENCES,0.2720677146311971,"[37] P. Mattila. Geometry of Sets and Measures in Euclidean Spaces: Fractals and Rectifiability.
Cambridge Studies in Advanced Mathematics. Cambridge University Press, 1995."
REFERENCES,0.27327690447400244,"[38] F. Mezzadri. How to generate random matrices from the classical compact groups. arXiv
preprint math-ph/0609050, 2006."
REFERENCES,0.27448609431680776,"[39] Y. Nesterov and V. Spokoiny. Random gradient-free minimization of convex functions. Founda-
tions of Computational Mathematics, 17:527–566, 2017."
REFERENCES,0.2756952841596131,"[40] Z. Opial. Weak convergence of the sequence of successive approximations for nonexpansive
mappings. Bulletin of the American Mathematical Society, 73(4):591 – 597, 1967."
REFERENCES,0.27690447400241835,"[41] B. T. Polyak. Introduction to optimization. Optimization Software Inc., Publications Division,
New York, 1:32, 1987."
REFERENCES,0.2781136638452237,"[42] M. Rando, C. Molinari, S. Villa, and L. Rosasco. Stochastic zeroth order descent with structured
directions, 2022."
REFERENCES,0.279322853688029,"[43] H. Robbins and D. Siegmund. A convergence theorem for non negative almost supermartingales
and some applications. In J. S. Rustagi, editor, Optimizing Methods in Statistics, pages 233–257.
Academic Press, 1971."
REFERENCES,0.28053204353083433,"[44] C. Rusu and L. Rosasco. Fast approximation of orthogonal matrices and application to pca.
Signal Processing, 194:108451, 2022."
REFERENCES,0.28174123337363965,"[45] T. Salimans, J. Ho, X. Chen, S. Sidor, and I. Sutskever. Evolution strategies as a scalable
alternative to reinforcement learning, 2017."
REFERENCES,0.282950423216445,"[46] O. Shamir. An optimal algorithm for bandit and zero-order convex optimization with two-point
feedback. The Journal of Machine Learning Research, 18(1):1703–1713, 2017."
REFERENCES,0.2841596130592503,"[47] C. Totzeck. Trends in Consensus-Based Optimization, pages 201–226. Springer International
Publishing, Cham, 2022."
REFERENCES,0.28536880290205563,"[48] T. Trogdon. On spectral and numerical properties of random butterfly matrices. Applied
Mathematics Letters, 95:48–58, 2019."
REFERENCES,0.28657799274486095,"[49] F. Yousefian, A. Nedi´c, and U. V. Shanbhag. On stochastic gradient and subgradient methods
with adaptive steplength sequences. Automatica, 48(1):56–67, 2012."
REFERENCES,0.2877871825876663,"A
Auxiliary Results"
REFERENCES,0.2889963724304716,"In this appendix, we state and collect lemmas and propositions required to prove the main results."
REFERENCES,0.29020556227327693,"Notation.
In the following sections, we denote with Fk the filtration σ(G1, · · · , Gk−1). Moreover,
to simplify the notation, we define gk as the gradient surrogate in eq.(2) at time-step k i.e. gk :=
g(Gk,hk)(xk) and g(·) := g(G,h)(·) for an arbitrary G ∈O(d) and h > 0. We denote the normalized
Haar measure [37] by µ. We define the unit ball Bd and the unit sphere Sd−1 as follow"
REFERENCES,0.2914147521160822,"Bd := {v ∈Rd | ∥v∥≤1}
and
Sd−1 := {v ∈Rd | ∥v∥= 1}."
REFERENCES,0.2926239419588875,"We denote by σ and σN the spherical measure and the normalized spherical measure on Sd−1,
respectively. Moreover, we denote with Id,ℓ∈Rd×ℓthe (truncated) identity matrix."
REFERENCES,0.29383313180169285,"Lemma 2. Let β(Sd−1) be the surface area of Sd−1 and let I ∈Rd×d be the identity matrix. Then,
Z"
REFERENCES,0.2950423216444982,"Sd−1 vv⊺dσ(v) = β(Sd−1) d
I."
REFERENCES,0.2962515114873035,"Proof. This result is proved in [21, Lemma 7.3, point (b)]."
REFERENCES,0.2974607013301088,"Lemma 3. Let ϕ : Rd →R be a L-Lipschitz function . If u is uniformly distributed on Sd−1, then"
REFERENCES,0.29866989117291415,"(E[ϕ(u) −E[ϕ(u)]])2 ≤cL2 d ,"
REFERENCES,0.2998790810157195,for some numerical constant c > 0.
REFERENCES,0.3010882708585248,"Proof. The proof follows the same line as [46, Lemma 9]."
REFERENCES,0.3022974607013301,"A.1
Smoothing Lemma & Properties"
REFERENCES,0.30350665054413545,"In this appendix, we provide the proof of the Smoothing Lemma (i.e. Lemma 1)."
REFERENCES,0.3047158403869408,"Proof of Smoothing Lemma.
By eq. (2),"
REFERENCES,0.3059250302297461,"EG[g(G,h)(x)] = d ℓ ℓ
X i=1 Z O(d)"
REFERENCES,0.30713422007255137,f(x + hGei) −f(x −hGei)
H,0.3083434099153567,"2h
Gei dµ(G)."
H,0.309552599758162,"By [37, Theorem 3.7],"
H,0.31076178960096734,"EG[g(G,h)(x)] =
d
2ℓh ℓ
X i=1 Z"
H,0.31197097944377267,Sd−1(f(x + hv(i)) −f(x −hv(i)))v(i) dσN(v(i)).
H,0.313180169286578,"Since v(i) is uniformly distributed on the sphere, which is symmetric with respect to the origin, we
have"
H,0.3143893591293833,"EG[g(G,h)(x)] = d ℓh ℓ
X i=1 Z"
H,0.31559854897218864,Sd−1 f(x + hv(i))v(i) dσN(v(i)).
H,0.31680773881499397,"As a consequence of Stokes’ Theorem (details in [18, Lemma 1] and [1, Theorem A8.8]), we get"
H,0.3180169286577993,"E[g(G,h)(x)] = 1 ℓ ℓ
X"
H,0.3192261185006046,"i=1
∇fh(x)
with
fh(x) :=
1
vol(Bd) Z"
H,0.32043530834340994,Bd f(x + hu) du.
H,0.3216444981862152,"Rearranging terms, we get the claim.
Proposition 1 (Smoothing properties). Let fh be the smooth approximation of f defined in eq. (4).
Then the following hold:
If f is convex then fh is convex and, for every x ∈Rd,"
H,0.32285368802902054,f(x) ≤fh(x).
H,0.32406287787182586,"If f is L0-Lipschitz continuous - i.e. ∀x, y ∈Rd, |f(x)−f(y)| ≤L0∥x−y∥, then fh is L0-Lipschitz
continuous, differentiable and for every x, y ∈Rd"
H,0.3252720677146312,"∥∇fh(x) −∇fh(y)∥≤L0
√"
H,0.3264812575574365,"d
h
∥x −y∥
and
fh(x) ≤f(x) + L0h."
H,0.32769044740024184,"If f is L1-smooth - i.e. f is differentiable and ∀x, y ∈Rd, ∥∇f(x) −∇f(y)∥≤L1∥x −y∥then fh
is L1-smooth and for every x ∈Rd,"
H,0.32889963724304716,∥∇fh(x) −∇f(x)∥≤hdL1
AND,0.3301088270858525,"2
and
fh(x) ≤f(x) + L1 2 h2."
AND,0.3313180169286578,"Proof. These are standard results proposed and proved in different works - see for example [16,
Lemma 8],[21, Proposition 7.5],[34, Proposition 2.2],[49]."
AND,0.33252720677146314,"Lemma 4 (Approximation Error). Let g(·) be the surrogate defined in eq. (2) for arbitrary h > 0
and G ∈O(d). Then the following hold:"
AND,0.33373639661426846,"(i) If f is L0-Lipschitz (see Assumption 1), then, for every x ∈Rd,"
AND,0.3349455864570738,"EG[∥g(x)∥2] ≤2cdL2
0
ℓ,"
AND,0.33615477629987905,where c is a numerical constant.
AND,0.3373639661426844,"(ii) If f is L1-smooth (see Assumption 3), then, for every x ∈Rd,"
AND,0.3385731559854897,EG[∥g(x)∥2] ≤2d
AND,0.33978234582829503,"ℓ∥∇f(x)∥2 + L2
1d2 2ℓh2."
AND,0.34099153567110035,"Proof. Note that, since directions are orthogonal, we have"
AND,0.3422007255139057,"EG[∥g(x)∥2] =
d2 4ℓ2h2 ℓ
X"
AND,0.343409915356711,"i=1
EG[(f(x + hGei) −f(x −hGei))2∥Gei∥2]."
AND,0.34461910519951633,"By [37, Theorem 3.7],"
AND,0.34582829504232165,"EG[∥g(x)∥2] =
d2 4ℓ2h2 ℓ
X"
AND,0.347037484885127,"i=1
Evi[(f(x + hv(i)) −f(x −hv(i)))2∥v(i)∥2],
(5)"
AND,0.3482466747279323,"where each v(i) is uniformly distributed on Sd−1.
(i): Set γ = Ev(i)[f(x + hv(i))] for every i (this expectation does not depend on i). Then"
AND,0.34945586457073763,"EG[∥g(x)∥2] =
d2 4ℓ2h2 ℓ
X"
AND,0.35066505441354295,"i=1
Ev(i)[(f(x + hv(i)) −f(x −hv(i)) + γ −γ)2∥v(i)∥2] =
d2 4ℓ2h2 ℓ
X"
AND,0.3518742442563482,"i=1
Ev(i)[((f(x + hv(i)) −γ) −(f(x −hv(i)) −γ))2∥v(i)∥2] ≤
d2 2ℓ2h2 ℓ
X"
AND,0.35308343409915355,"i=1
Ev(i)[((f(x + hv(i)) −γ)2 + (f(x −hv(i)) −γ)2)∥v(i)∥2] =
d2 2ℓ2h2 ℓ
X i=1"
AND,0.3542926239419589,"h
Ev(i)[(f(x + hv(i)) −γ)2∥v(i)∥2]"
AND,0.3555018137847642,"+ Ev(i)[(f(x −hv(i)) −γ)2∥v(i)∥2]
i
."
AND,0.3567110036275695,"Since v(i) is uniformly distributed on Sd−1, it satisfies ∥v(i)∥2 = 1 and by symmetry we have"
AND,0.35792019347037485,"EG[∥g(x)∥2] ≤
d2 ℓ2h2 ℓ
X"
AND,0.3591293833131802,"i=1
Ev(i)[(f(x + hv(i)) −γ)2]."
AND,0.3603385731559855,The definition of γ yields
AND,0.3615477629987908,"EG[∥g(x)∥2] ≤
d2 ℓ2h2 ℓ
X"
AND,0.36275695284159615,"i=1
Ev(i)[((f(x + hv(i)) −γ)2] =
d2 ℓ2h2 ℓ
X"
AND,0.3639661426844015,"i=1
Ev(i)[(f(x + hv(i)) −Ev(i)[f(x + hv(i))])2]."
AND,0.3651753325272068,"The claim follows by Lemma 3 and the fact that f(x + hv(i)) is hL0-Lipschitz continuous w.r.t to
v(i).
(ii): Equation (5) yields"
AND,0.36638452237001207,"EG[∥g(x)∥2] =
d2 4ℓ2h2 ℓ
X"
AND,0.3675937122128174,"i=1
Ev(i)[(f(x + hv(i)) −f(x −hv(i)) −f(x) + f(x))2∥v(i)∥2] ≤
d2 2ℓ2h2 ℓ
X i=1"
AND,0.3688029020556227,"h
Ev(i)[(f(x + hv(i)) −f(x))2∥v(i)∥2]"
AND,0.37001209189842804,"+ Ev(i)[(f(x −hv(i)) −f(x))2∥v(i)∥2]
i =
d2 ℓ2h2 ℓ
X"
AND,0.37122128174123337,"i=1
Ev(i)[(f(x + hv(i)) −f(x))2],"
AND,0.3724304715840387,"where the last equation follows by symmetry. Adding and subtracting

∇f(x), hv(i)
we derive"
AND,0.373639661426844,"EG[∥g(x)∥2] ≤
d2 ℓ2h2 ℓ
X"
AND,0.37484885126964934,"i=1
Ev(i)"
AND,0.37605804111245467,"""
f(x + hv(i)) −f(x) −
D
∇f(x), hv(i)E
+
D
∇f(x), hv(i)E 2
# ≤2d2 ℓ2h2 ℓ
X i=1  Ev(i)"
AND,0.37726723095526,"""
f(x + hv(i)) −f(x) −
D
∇f(x), hv(i)E 2
#"
AND,0.3784764207980653,+ Ev(i)
AND,0.37968561064087064,""" D
∇f(x), hv(i)E 2
#! ."
AND,0.3808948004836759,Denote by β(Sd−1) the surface area of Sd−1. The Descent Lemma [41] implies
AND,0.38210399032648124,"EG[∥g(x)∥2] ≤2d2 ℓ2h2 ℓ
X i=1"
AND,0.38331318016928656,"""L2
1
4 h4
+ E"
AND,0.3845223700120919,""" D
∇f(x), hv(i)E 2
##"
AND,0.3857315598548972,"= L2
1d2"
AND,0.38694074969770254,"2ℓh2 + 2d2 ℓ2h2 ℓ
X i=1
E"
AND,0.38814993954050786,""" D
∇f(x), hv(i)E 2
#"
AND,0.3893591293833132,"= L2
1d2"
AND,0.3905683192261185,"2ℓh2 +
2d2"
AND,0.39177750906892383,"ℓ2β(Sd−1) ℓ
X i=1 Z"
AND,0.39298669891172916,Sd−1 ∇f(x)⊺v(i)v(i)⊺∇f(x) dσ(v).
AND,0.3941958887545345,"By Lemma 2, we get the claim. Indeed,"
AND,0.3954050785973398,"EG[∥g(x)∥2] ≤L2
1d2"
AND,0.3966142684401451,"2ℓh2 +
2d2"
AND,0.3978234582829504,"ℓ2β(Sd−1) ℓ
X i=1"
AND,0.39903264812575573,β(Sd−1)
AND,0.40024183796856105,"d
∥∇f(x)∥2 = 2d"
AND,0.4014510278113664,"ℓ∥∇f(x)∥2 + L2
1d2 2ℓh2."
AND,0.4026602176541717,"A.2
Auxiliary results and proofs for the nonsmooth setting, convex, and nonconvex."
AND,0.40386940749697703,"In this subsection, for every k, we will denote by Fk the σ-algebra σ(G0, . . . , Gk−1)."
AND,0.40507859733978235,"Lemma 5. Let f : Rd →R be a lower semi-continuous function and denote with S = arg min f
and f ∗= min f. Then,
( (A)
∀x∗∈S, ∃lim
k ∥xk −x∗∥"
AND,0.4062877871825877,"(B)
lim inf
k
f(xk) = f ∗
=⇒∃x∞∈S
s.t.
xk →x∞."
AND,0.407496977025393,"Proof. Since (B) holds, we have that exists (xkj)j∈N subsequence of (xk)k∈N such that f(xkj) →f ∗.
Since S ̸= ∅and (A) we have that
∃x∗∈S
and
∃lim
k ∥xk −x∗∥."
AND,0.40870616686819833,"Thus, the sequence (xk)k∈N is bounded and, therefore, also (xkj)j∈N is bounded. Taking a convergent
subsequence (xkjn)n∈N of (xkj)j∈N, we have that exists x∞s.t.
xkjn →x∞.
Since f is assumed to be lower semi-continuous, we have that
f(x∞) ≤lim inf
n
f(xkjn) = f ∗= lim
j f(xkj)."
AND,0.40991535671100365,"Thus, we have that x∞∈S which implies, by (A), that
∃lim
k ∥xk −x∞∥
and
lim
n ∥xkjn −x∞∥= 0."
AND,0.4111245465538089,"Hence, since xkjn is a subsequence of xk,"
AND,0.41233373639661425,"lim
k ∥xk −x∞∥= 0,"
AND,0.4135429262394196,"and, therefore, xk →x∞∈S."
AND,0.4147521160822249,"Lemma 6 (Convergence: convex non-smooth). Assume that f is convex and L0 Lipschitz continuous.
Let (xk)k∈N be the sequence generated by Algorithm 1 and let x∗∈arg min f. Then, for every
k ∈N, the following inequality holds:"
AND,0.4159613059250302,"E[∥xk+1 −x∗∥2|Fk] −∥xk −x∗∥2 + 2αk(f(xk) −f(x∗)) ≤2cL2
0d
ℓα2
k + 2L0αkhk,"
AND,0.41717049576783555,"where c is some non-negative constant independent from the dimension. Moreover, if the stepsizes
satisfy Assumption 2, we have
lim
k→+∞f(xk) = f(x∗)
a.s,"
AND,0.4183796856106409,and there exists a random variable ˆx taking values in in arg min f such that xk →ˆx a.s.
AND,0.4195888754534462,"Proof. Let k ∈N. By Algorithm 1,
∥xk+1 −x∗∥2 −∥xk −x∗∥2 = α2
k∥gk∥2 −2αk ⟨gk, xk −x∗⟩.
(6)
Since fhk is convex by Proposition 1 and E[gk|Fk] = ∇fhk(xk) (see Lemma 1), we have
−⟨∇fhk(xk), xk −x∗⟩≤fhk(x∗) −fhk(xk).
Thus, taking the conditional expectation with respect to Fk, by Lemma 4, we get,"
AND,0.4207980652962515,"E[∥xk+1 −x∗∥2|Fk] −∥xk −x∗∥2 ≤2cL2
0d
ℓα2
k
|
{z
}
=:Ck"
AND,0.42200725513905685,−2αk(fhk(xk) −fhk(x∗)).
AND,0.42321644498186217,"Then, by Proposition 1,
E[∥xk+1 −x∗∥2|Fk] −∥xk −x∗∥2 ≤Ck −2αk(f(xk) −f(x∗)) + 2L0αkhk.
Next suppose that Assumption 2 holds. Rearranging the terms,
E[∥xk+1 −x∗∥2|Fk] −∥xk −x∗∥2 + 2αk(f(xk) −f(x∗)) ≤Ck + 2L0αkhk,"
AND,0.4244256348246675,"with Ck ∈ℓ1 and αkhk ∈ℓ1. Therefore, Robbins-Siegmund Theorem [43] implies that (∥xk −
x∗∥)k∈N is a.s. convergent, αk(f(xk) −f(x∗)) ∈ℓ1 a.s. and thus, since αk ̸∈ℓ1,
lim inf
k→∞f(xk) = f(x∗)
a.s.
(7)"
AND,0.42563482466747277,"We derive from [32, Lemma 9.9] and Lemma 5 that there exists a random variable ˆx taking values in
arg min f such that xk →ˆx a.s. Finally, continuity of f yields that lim
k f(xk) = f(x∗) a.s."
AND,0.4268440145102781,"In the next Lemma, to derive bounds on function values, we study the sequence (fhk(xk+1) −
fhk(xk))k∈N. It is the difference between the smoothed function at iteration k evaluated at xk and
at xk+1. It corresponds to the function value decrease between the iterations k + 1 and k if hk is
constant.
Lemma 7 (Function Value decrease: nonconvex non-smooth setting). Under Assumption 1, let
(xk)k∈N be the sequence generated by Algorithm 1. Then,"
AND,0.4280532043530834,"E[fhk(xk+1)|Fk] −fhk(xk) ≤−αk∥∇fhk(xk)∥2 + cL3
0d
√"
AND,0.42926239419588874,"d
ℓ
α2
k
hk
,"
AND,0.43047158403869407,where c is a numerical constant.
AND,0.4316807738814994,"Proof. By Lemma 1, we have that fhk is L0
√"
AND,0.4328899637243047,"d/hk-smooth. Thus, by the Descent Lemma [41],"
AND,0.43409915356711004,"fhk(xk+1) −fhk(xk) ≤−αk ⟨∇fhk(xk), gk⟩+ L0
√"
AND,0.43530834340991537,"d
2hk
α2
k∥gk∥2."
AND,0.4365175332527207,"Taking the conditional expectation with respect to Fk,"
AND,0.437726723095526,"E[fhk(xk+1)|Fk] −fhk(xk) ≤−αk∥∇fhk(xk)∥2 + L0
√"
AND,0.43893591293833134,"d
2hk
α2
k E[∥gk∥2|Fk].
(8)"
AND,0.44014510278113667,The claim follows from Lemma 4.
AND,0.44135429262394194,"A.3
Auxiliary results for smooth setting."
AND,0.44256348246674726,"Lemma 8 (Function value decrease: convex smooth setting). Under Assumption 3 , let (xk)k∈N be
the sequence generated by Algorithm 1. Then the following holds:"
AND,0.4437726723095526,"E[f(xk+1)|Fk] −f(xk) ≤−αk
1"
AND,0.4449818621523579,2 −L1d
AND,0.44619105199516323,"ℓαk

∥∇f(xk)∥2 + L2
1d2αkh2
k
8
+ L3
1d2"
AND,0.44740024183796856,"4ℓα2
kh2
k."
AND,0.4486094316807739,"Proof. By the Descent Lemma [41] and Algorithm 1,"
AND,0.4498186215235792,"f(xk+1) −f(xk) ≤−αk ⟨∇f(xk), gk⟩+ L1"
AND,0.45102781136638453,"2 α2
k∥gk∥2."
AND,0.45223700120918986,"Taking the conditional expectation and by Lemma 4,"
AND,0.4534461910519952,"E[f(xk+1)|Fk] −f(xk) ≤−αk ⟨∇f(xk), ∇fhk(xk)⟩+ L1"
AND,0.4546553808948005,"2 α2
k
h2d"
AND,0.4558645707376058,"ℓ∥∇f(xk)∥2 + L2
1d2"
AND,0.4570737605804111,"2ℓh2
k
i
."
AND,0.45828295042321643,"Adding and subtracting ∇f(xk),"
AND,0.45949214026602175,"E[f(xk+1)|Fk] −f(xk) ≤−αk ⟨∇f(xk), ∇fhk(xk) −∇f(xk)⟩−αk∥∇f(xk)∥2 + L1"
AND,0.4607013301088271,"2 α2
k
h2d"
AND,0.4619105199516324,"ℓ∥∇f(xk)∥2 + L2
1d2"
AND,0.46311970979443773,"2ℓh2
k
i
."
AND,0.46432889963724305,"By Cauchy-Schwarz inequality and Proposition 1,"
AND,0.4655380894800484,"E[f(xk+1)|Fk] −f(xk) ≤αk
L1d"
HK,0.4667472793228537,"2 hk

∥∇f(xk)∥−αk∥∇f(xk)∥2 + L1"
HK,0.46795646916565903,"2 α2
k
h2d"
HK,0.46916565900846435,"ℓ∥∇f(xk)∥2 + L2
1d2"
HK,0.4703748488512696,"2ℓh2
k
i
."
HK,0.47158403869407495,"By Young’s inequality,"
HK,0.4727932285368803,"E[f(xk+1)|Fk] −f(xk) ≤L2
1d2αkh2
k
8
+ αk"
HK,0.4740024183796856,2 ∥∇f(xk)∥2 −αk∥∇f(xk)∥2 + L1
HK,0.4752116082224909,"2 α2
k
h2d"
HK,0.47642079806529625,"ℓ∥∇f(xk)∥2 + L2
1d2"
HK,0.47762998790810157,"2ℓh2
k
i
."
HK,0.4788391777509069,"= −αk
1"
HK,0.4800483675937122,2 −L1d
HK,0.48125755743651755,"ℓαk

∥∇f(xk)∥2 + L2
1d2αkh2
k
8
+ L3
1d2"
HK,0.48246674727932287,"4ℓα2
kh2
k."
HK,0.4836759371221282,This concludes the proof.
HK,0.4848851269649335,"Lemma 9 (Convergence in smooth setting). Let (xk)k∈N be the sequence generated by Algorithm 1
and let x∗∈arg min
x∈Rd
f(x). Then, under Assumption 3, the following inequality holds"
HK,0.4860943168077388,E[∥xk+1 −x∗∥2|Fk] −∥xk −x∗∥2 ≤2d
HK,0.4873035066505441,"ℓα2
k∥∇f(xk)∥2 + L2
1d2"
HK,0.48851269649334944,"2ℓα2
kh2
k"
HK,0.48972188633615477,"+ L1dαkhk∥xk −x∗∥−2αk ⟨∇f(xk), xk −x∗⟩."
HK,0.4909310761789601,"Moreover, if f is convex, Assumption 4 holds and αk ≤¯α < ℓ/(2dL1). Then"
HK,0.4921402660217654,• (αk∥∇f(xk)∥2)k∈N ∈ℓ1 a.s.
HK,0.49334945586457074,• (∥xk −x∗∥)k∈N is a.s. convergent.
HK,0.49455864570737607,• (αk(f(xk) −f(x∗)))k∈N ∈ℓ1 a.s.
HK,0.4957678355501814,"• there exists a random variable ˆx taking values in arg min f such that xk →ˆx a.s. and
lim
k→∞f(xk) = min f."
HK,0.4969770253929867,Proof. We have
HK,0.49818621523579204,"∥xk+1 −x∗∥2 −∥xk −x∗∥2 = α2
k∥gk∥2 −2αk ⟨gk, xk −x∗⟩."
HK,0.49939540507859737,"Taking the conditional expectation,"
HK,0.5006045949214026,"E[∥xk+1 −x∗∥2|Fk] −∥xk −x∗∥2 = α2
k E[∥gk∥2|Fk] −2αk ⟨∇fhk(xk), xk −x∗⟩."
HK,0.501813784764208,"For every k, set uk = ∥xk −x∗∥. By Lemma 4,"
HK,0.5030229746070133,"E[u2
k+1|Fk] −u2
k ≤2d"
HK,0.5042321644498187,"ℓα2
k∥∇f(xk)∥2 + L2
1d2"
HK,0.5054413542926239,"2ℓα2
kh2
k −2αk ⟨∇fhk(xk), xk −x∗⟩."
HK,0.5066505441354293,Note that
HK,0.5078597339782346,"−2αk ⟨∇fhk(xk), xk −x∗⟩= 2αk ⟨∇fhk(xk) −∇f(xk), x∗−xk⟩−2αk ⟨∇f(xk), xk −x∗⟩. Thus,"
HK,0.5090689238210399,"E[u2
k+1|Fk] −u2
k ≤2d"
HK,0.5102781136638452,"ℓα2
k∥∇f(xk)∥2 + L2
1d2"
HK,0.5114873035066505,"2ℓα2
kh2
k"
HK,0.5126964933494559,"+ 2αk ⟨∇fhk(xk) −∇f(xk), x∗−xk⟩−2αk ⟨∇f(xk), xk −x∗⟩."
HK,0.5139056831922612,"By the Cauchy-Schwarz inequality,"
HK,0.5151148730350665,"E[u2
k+1|Fk] −u2
k ≤2d"
HK,0.5163240628778718,"ℓα2
k∥∇f(xk)∥2 + L2
1d2"
HK,0.5175332527206772,"2ℓα2
kh2
k"
HK,0.5187424425634825,"+ 2αk∥∇fhk(xk) −∇f(xk)∥uk −2αk ⟨∇f(xk), xk −x∗⟩."
HK,0.5199516324062878,"The first claim follows from Proposition 1. By Proposition 1 and Young’s inequality with parameter
τk = αkhk, we get"
HK,0.5211608222490931,"E[u2
k+1|Fk] −u2
k ≤2d"
HK,0.5223700120918985,"ℓα2
k∥∇f(xk)∥2 + L2
1d2"
HK,0.5235792019347038,"2ℓα2
kh2
k + L1d"
HK,0.524788391777509,"2τk
α2
kh2
k + L1dτk"
HK,0.5259975816203144,"2
u2
k −2αk ⟨∇f(xk), xk −x∗⟩. = 2d"
HK,0.5272067714631197,"ℓα2
k∥∇f(xk)∥2 + L2
1d2"
HK,0.528415961305925,"2ℓα2
kh2
k + L1d"
HK,0.5296251511487303,2 αkhk + L1d
HK,0.5308343409915357,"2 αkhku2
k"
HK,0.532043530834341,"−2αk ⟨∇f(xk), xk −x∗⟩. (9)"
HK,0.5332527206771464,"Since f is convex, by Baillon-Haddad Theorem [3], we derive that"
HK,0.5344619105199516,"E[u2
k+1|Fk] −u2
k ≤−2
 1 L1
−d"
HK,0.535671100362757,"ℓαk

αk∥∇f(xk)∥2 + L2
1d2"
HK,0.5368802902055623,"2ℓα2
kh2
k + L1d"
HK,0.5380894800483675,2 αkhk + L1d
HK,0.5392986698911729,"2 αkhku2
k."
HK,0.5405078597339782,"By Assumption 4,"
HK,0.5417170495767836,"E[u2
k+1|Fk] −u2
k ≤−2
 1 L1
−d ℓ¯α
"
HK,0.5429262394195888,"|
{z
}
=:∆"
HK,0.5441354292623942,αk∥∇f(xk)∥2 + L1d
HK,0.5453446191051995,"2 αkhk
|
{z
}
=:ρk u2
k + L1d"
HK,0.5465538089480049,"2 αkhk + L2
1d2"
HK,0.5477629987908101,"2ℓα2
kh2
k
|
{z
}
=:Ck ."
HK,0.5489721886336155,"Note that ∆> 0. Thus, rearranging the terms"
HK,0.5501813784764208,"E[u2
k+1|Fk] −(1 + ρk)u2
k + 2∆αk∥∇f(xk)∥2 ≤Ck."
HK,0.5513905683192262,"Since ρk, Ck ∈ℓ1 by Assumption 4, Robbins-Siegmund Theorem [43] ensures that (u2
k)k∈N is
convergent and (αk∥∇f(xk)∥2)k∈N ∈ℓ1 a.s. Since f is convex, it follows from (9) that"
HK,0.5525997581620314,"E[u2
k+1|Fk] −(1 + ρk)u2
k ≤2d"
HK,0.5538089480048367,"ℓα2
k∥∇f(xk)∥2 −2αk(f(xk) −f(x∗)) + Ck."
HK,0.5550181378476421,"Robbins-Siegmund Theorem [43] implies that (αk(f(xk) −f(x∗)))k∈N ∈ℓ1 a.s. Assumption 4
implies that αk ̸∈ℓ1 therefore"
HK,0.5562273276904474,"lim inf
k
f(xk) −f(x∗) = 0 a.s.
(10)"
HK,0.5574365175332527,"By Lemma 8 and Assumption 4, we have that the sequence E[f(xk+1)−f(x∗)|Fk]−(f(xk)−f(x∗))
is upper-bounded by a sequence in ℓ1. Thus, by Robbins-Siegmund Theorem [43], limk(f(xk) −
f(x∗)) exists a.s. Then, it follows from (10) that"
HK,0.558645707376058,"lim
k→∞f(xk) = f(x∗)
a.s."
HK,0.5598548972188634,"Moreover, as we saw before, (∥xk −x∗∥)k∈N is convergent a.s. for every x∗∈arg min f. Then, by
Opial’s Lemma [40], there exists a random variable ˆx taking values in arg min f such that xk →ˆx
a.s."
HK,0.5610640870616687,"Lemma 10 (Gradient bound: convex smooth setting). Suppose that Assumptions 3 and 4 hold, and
assume f to be convex. Let (xk)k∈N be the sequence generated by Algorithm 1. Then, for every
k ∈N and every x∗∈arg min f, k
X"
HK,0.562273276904474,"i=0
αi E[∥∇f(xi)∥2] ≤
1
2∆"
HK,0.5634824667472793,"
Sk + k
X"
HK,0.5646916565900847,"i=0
ρi
p"
HK,0.56590084643289,"E[∥xi −x∗∥2]

, and
p"
HK,0.5671100362756953,"E[∥xk −x∗∥2] ≤
p"
HK,0.5683192261185006,"Sk−1 + k
X"
HK,0.5695284159613059,"i=0
ρi, where"
HK,0.5707376058041113,"∆:=
 1 L1
−d"
HK,0.5719467956469165,"ℓ¯α

,
Sk := ∥x0 −x∗∥+ k
X"
HK,0.5731559854897219,"i=0
Ci"
HK,0.5743651753325272,"Ck := L2
1d2"
HK,0.5755743651753326,"2ℓα2
kh2
k
and
ρk := L1dαkhk."
HK,0.5767835550181378,Proof. By Lemma 9 we derive
HK,0.5779927448609432,E[∥xk+1 −x∗∥2|Fk] −∥xk −x∗∥2 ≤2d
HK,0.5792019347037485,"ℓα2
k∥∇f(xk)∥2 + Ck"
HK,0.5804111245465539,"+ ρk∥xk −x∗∥−2αk ⟨∇f(xk), xk −x∗⟩."
HK,0.5816203143893591,"By Baillon-Haddad Theorem and Assumption 4,"
HK,0.5828295042321644,E[∥xk+1 −x∗∥2|Fk] −∥xk −x∗∥2 ≤−2∆αk∥∇f(xk)∥2 + Ck + ρk∥xk −x∗∥.
HK,0.5840386940749698,"Let uk :=
p"
HK,0.585247883917775,"E[∥xk −x∗∥2]. Taking the full expectation, by Jensen inequality we have"
HK,0.5864570737605804,"u2
k+1 −u2
k ≤−2∆αk E[∥∇f(xk)∥2] + ρkuk + Ck."
HK,0.5876662636033857,"Summing the previous inequality from i = 0, · · · , k, we get"
HK,0.5888754534461911,"u2
k+1 + 2∆ k
X"
HK,0.5900846432889963,"i=0
αi E[∥∇f(xi)∥2] ≤u2
0 + k
X"
HK,0.5912938331318017,"i=0
Ci"
HK,0.592503022974607,"|
{z
}
=:Sk + k
X"
HK,0.5937122128174124,"i=0
ρiui.
(11)"
HK,0.5949214026602176,"Since uk is non-negative, the first claim of the lemma follows. Since ∆> 0, ρk ≥0, Sk is non
decreasing, and Sk ≥u2
0 in (11), then"
HK,0.596130592503023,"u2
k+1 ≤Sk + k
X"
HK,0.5973397823458283,"i=0
ρiui."
HK,0.5985489721886336,"Thus, the (discrete) Bihari’s Lemma [32, Lemma 9.8] yields"
HK,0.599758162031439,"uk+1 ≤1 2 k
X"
HK,0.6009673518742442,"i=0
ρi +
h
Sk +
1 2 k
X"
HK,0.6021765417170496,"i=0
ρi
2i1/2
≤
p Sk + k
X"
HK,0.6033857315598549,"i=0
ρi,"
HK,0.6045949214026602,concluding the proof.
HK,0.6058041112454655,"B
Proofs of Main Results"
HK,0.6070133010882709,"B.1
Proof of Theorem 1"
HK,0.6082224909310762,"By Lemma 6,"
HK,0.6094316807738815,"E[∥xk+1 −x∗∥2|Fk] −∥xk −x∗∥2 + 2αk(f(xk) −f(x∗)) ≤2cL2
0d
ℓα2
k + 2L0αkhk."
HK,0.6106408706166868,"Rearranging the terms, taking the full expectation, and summing the first k iterations k
X"
HK,0.6118500604594922,"i=0
αi E[(f(xi) −f(x∗))] ≤∥x0 −x∗∥2"
HK,0.6130592503022975,"2
+ cdL2
0
ℓ k
X"
HK,0.6142684401451027,"i=0
α2
i + L0 k
X"
HK,0.6154776299879081,"i=0
αihi."
HK,0.6166868198307134,"Let ¯xk :=
kP"
HK,0.6178960096735188,"i=0
αixi/(
kP"
HK,0.619105199516324,"i=0
αi). Dividing by
kP"
HK,0.6203143893591294,"i=0
αi and observing that by convexity we have"
HK,0.6215235792019347,E[f(¯xk) −min f] ≤ kP
HK,0.6227327690447401,"i=0
αi E[(f(xi) −f(x∗))] kP"
HK,0.6239419588875453,"i=0
αi ,"
HK,0.6251511487303507,"we get the first claim. Under Assumption 2, the second claim holds by Lemma 6."
HK,0.626360338573156,"B.2
Proof of Corollary 1"
HK,0.6275695284159613,"By Theorem 1,"
HK,0.6287787182587666,"E[f(¯xk) −min f] ≤
1 kP"
HK,0.6299879081015719,"i=0
αi"
HK,0.6311970979443773,∥x0 −x∗∥2
HK,0.6324062877871826,"2
+ cdL2
0
ℓ k
X"
HK,0.6336154776299879,"i=0
α2
i + L0 k
X"
HK,0.6348246674727932,"i=0
αihi ! ."
HK,0.6360338573155986,"Replacing αk and hk with the sequences in the statement,"
HK,0.6372430471584039,"E[f(¯xk) −f(x∗)] ≤
C1
αk1−θ + C2"
HK,0.6384522370012092,"kρ h + d ℓ
C3 kθ α, with"
HK,0.6396614268440145,C1 := (1 −θ)∥x0 −x∗∥2
HK,0.6408706166868199,"2
,
C2 := L0(1 −θ)"
HK,0.6420798065296252,"(1 −θ −ρ)
and
C3 := cL2
0(1 −θ)
(1 −2θ) ."
HK,0.6432889963724304,"The second point of the corollary can be proved replacing αk = α and hk = h. Now, to prove the
third point, fix ε ∈(0, 1). Since we want E[f(¯xk) −f(x∗)] ≤ε, we impose"
HK,0.6444981862152358,∥x0 −x∗∥2
HK,0.6457073760580411,"2αk
+ cdL2
0
ℓ
α + L0h ≤ε."
HK,0.6469165659008465,"Choosing hk = h ≤
ε
2L0 , to get the previous inequality it is sufficient to impose"
HK,0.6481257557436517,∥x0 −x∗∥2
HK,0.6493349455864571,"2αk
+ cdL2
0
ℓ
α ≤ε 2."
HK,0.6505441354292624,"We fix a priori a number of iterations K and we minimize the left handside with respect to α, obtaining α = r"
HK,0.6517533252720678,"ℓ
d
∥x0 −x∗∥
√"
HK,0.652962515114873,"2cKL0
."
HK,0.6541717049576784,"Thus, for hk = h ≤
ε
2L0 , α as above and"
HK,0.6553808948004837,"K ≥8∥x0 −x∗∥2L2
0cd
ℓε2
,"
HK,0.656590084643289,"we have E[f(¯xk)−f(x∗)] ≤ε. Note that, since the computation of the surrogate requires 2ℓfunction
evaluations, to ensure an error of ε we need to perform a number of function evaluations of the order"
HK,0.6577992744860943,O(dε−2).
HK,0.6590084643288996,This concludes the proof.
HK,0.660217654171705,"B.3
Proof of Theorem 2"
HK,0.6614268440145102,"By Lemma 7,"
HK,0.6626360338573156,"E[fh(xk+1)|Fk] −fh(xk) ≤−αk∥∇fh(xk)∥2 + cL3
0d
√"
HK,0.6638452237001209,"d
ℓ
α2
k
h ."
HK,0.6650544135429263,"Taking the full expectation and rearranging the terms,"
HK,0.6662636033857315,"αk E[∥∇fh(xk)∥2] ≤E[fh(xk) −fh(xk+1)] + cL3
0d
√"
HK,0.6674727932285369,"d
ℓ
α2
k
h ."
HK,0.6686819830713422,"Next sum from i = 0 to i = k. By definition of fh, we have fh(x) ≥min f for every x ∈Rd, thus, k
X"
HK,0.6698911729141476,"i=0
αi E[∥∇fh(xi)∥2] ≤E[fh(x0) −min f] + cL3
0d
√ d
ℓ k
X i=0"
HK,0.6711003627569528,"α2
i
h .
(12)"
HK,0.6723095525997581,The claim follows.
HK,0.6735187424425635,"B.4
Proof of Corollaries 2 and 3"
HK,0.6747279322853688,"By Theorem 2,"
HK,0.6759371221281741,"η(h)
k
≤

(fh(x0) −f(x∗)) + cL3
0d
√ d
ℓ k
X i=0"
HK,0.6771463119709794,"α2
i
h"
HK,0.6783555018137848,"
/
 k
X"
HK,0.6795646916565901,"i=0
αi

."
HK,0.6807738814993954,"Due to the choice of αk = α(k + 1)−θ with θ ∈(1/2, 1) and α > 0, we get"
HK,0.6819830713422007,"η(h)
k
≤
C1
α(k + 1)1−θ + C2d
√"
HK,0.6831922611850061,"dα
ℓh
1
(k + 1)θ , where"
HK,0.6844014510278114,"C1 := ∥x0 −x∗∥2(1 −θ)
and
C2 := cL3
0(1 −θ)
(1 −2θ) ."
HK,0.6856106408706167,"If we choose αk = α, we derive"
HK,0.686819830713422,"η(h)
k
≤fh(x0) −min f"
HK,0.6880290205562273,"αk
+ cL3
0d
√"
HK,0.6892382103990327,"dα
ℓh
.
(13)"
HK,0.6904474002418379,"If we fix a priori a number of iteration K and we minimize the right handside with respect to α, we
get ˆα = s"
HK,0.6916565900846433,(fh(x0) −f(x∗))ℓh
HK,0.6928657799274486,"KcL3
0d
√ d
."
HK,0.694074969770254,"Let ε ∈(0, 1). Choosing α = ˆα, we get η(h)
K ≤ε for"
HK,0.6952841596130592,"K ≥4(fh(x0) −f(x∗))cL3
0d
√"
HK,0.6964933494558646,"d
ℓh
ε−2.
(14)"
HK,0.6977025392986699,"This concludes the proof of Corollary 2. To prove Corollary 3, we fix a maximum number of
iterations K ∈N and consider the random variable I of the statement. Let ∂hf be the h-Goldstein
subdifferential defined in Definition 1. It follows from [34, Theorem 3.1] that ∇fh(xI) ∈∂hf(xI)
almost surely, therefore"
HK,0.6989117291414753,EI min[∥η∥2 : η ∈∂hf(xI)] ≤EI E[∥∇fh(xI)∥2].
HK,0.7001209189842805,"In addition, Theorem 2 yields"
HK,0.7013301088270859,"EI EG[∥∇fh(xI)∥2]
=
 K−1
X"
HK,0.7025392986698912,"j=0
αj EG[∥∇fh(xj)∥2]

/ K−1
X"
HK,0.7037484885126964,"j=0
αj"
HK,0.7049576783555018,"≤
E[fh(x0) −min f] + cL3
0d
√ d
ℓ k
X i=0"
HK,0.7061668681983071,"α2
i
h ."
HK,0.7073760580411125,"Thus,
EI[∥η∥2 : η ∈∂hf(xI)] ≤EI E[∥∇fh(xI)∥2] = η(h)
k .
Hence, for α = ¯α and K chosen s.t. inequality (14) holds, we have"
HK,0.7085852478839177,EI[∥η∥2 : η ∈∂hf(xI)] ≤ε.
HK,0.7097944377267231,This concludes the proof.
HK,0.7110036275695284,"B.5
Proof of Theorem 3"
HK,0.7122128174123338,"By Lemma 9,"
HK,0.713422007255139,E[∥xk+1 −x∗∥2|Fk] −∥xk −x∗∥2 ≤2d
HK,0.7146311970979444,"ℓα2
k∥∇f(xk)∥2 + 2αk ⟨∇f(xk), x∗−xk⟩"
HK,0.7158403869407497,"+ L1dαkhk
|
{z
}
=:ρk"
HK,0.717049576783555,"∥x∗−xk∥+ L2
1d2"
HK,0.7182587666263603,"2ℓα2
kh2
k
|
{z
}
=:Ck ."
HK,0.7194679564691656,"By convexity,"
HK,0.720677146311971,E[∥xk+1 −x∗∥2|Fk] −∥xk −x∗∥2 ≤2d
HK,0.7218863361547763,"ℓα2
k∥∇f(xk)∥2 −2αk(f(xk) −f(x∗))"
HK,0.7230955259975816,+ ρk∥x∗−xk∥+ Ck.
HK,0.7243047158403869,"Rearranging the terms and taking the full expectation,"
HK,0.7255139056831923,2 E[αk(f(xk) −f(x∗))] ≤E[∥xk −x∗∥2 −∥xk+1 −x∗∥2] + 2d
HK,0.7267230955259976,"ℓα2
k E[∥∇f(xk)∥2]"
HK,0.727932285368803,+ ρk E[∥x∗−xk∥] + Ck.
HK,0.7291414752116082,"Since E[∥x∗−xk∥] = E[
p"
HK,0.7303506650544136,"∥x∗−xk∥2], Jensen’s inequality implies that"
HK,0.7315598548972189,2 E[αk(f(xk) −f(x∗))] ≤E[∥xk −x∗∥2 −∥xk+1 −x∗∥2] + 2d
HK,0.7327690447400241,"ℓα2
k E[∥∇f(xk)∥2]"
HK,0.7339782345828295,"+ ρk
p"
HK,0.7351874244256348,E[∥x∗−xk∥2] + Ck.
HK,0.7363966142684402,"Denoting with uk = E[∥xk −x∗∥2] and taking the sum from i = 0 to i = k, 2 k
X"
HK,0.7376058041112454,"i=0
αi E[f(xi) −f(x∗)] ≤u2
0 + k
X"
HK,0.7388149939540508,"i=0
Ci"
HK,0.7400241837968561,"|
{z
}
=:Sk +2d ℓ k
X"
HK,0.7412333736396615,"i=0
α2
i E[∥∇f(xi)∥2] + k
X"
HK,0.7424425634824667,"i=0
ρiui"
HK,0.7436517533252721,"≤Sk + 2d ℓ¯α k
X"
HK,0.7448609431680774,"i=0
αi E[∥∇f(xi)∥2] + k
X"
HK,0.7460701330108828,"i=0
ρiui,"
HK,0.747279322853688,"where the last inequality holds by Assumption 4. Let ∆:= (1/L1 −(d/ℓ)¯α). By Lemma 10, we
have
k
X"
HK,0.7484885126964933,"i=0
αi E[f(xi) −f(x∗)] ≤1 2"
HK,0.7496977025392987,"
Sk + d¯α ∆ℓ"
HK,0.750906892382104,"h
Sk + k
X"
HK,0.7521160822249093,"i=0
ρiui
i
+ k
X"
HK,0.7533252720677146,"i=0
ρiui
"
HK,0.75453446191052,= ℓ∆+ d¯α 2ℓ∆
HK,0.7557436517533253,"
Sk + k
X"
HK,0.7569528415961306,"i=0
ρiui
"
HK,0.7581620314389359,≤ℓ∆+ d¯α 2ℓ∆
HK,0.7593712212817413,"
Sk + k
X"
HK,0.7605804111245466,"i=0
ρi(
p Si + i
X"
HK,0.7617896009673518,"j=0
ρj)

."
HK,0.7629987908101572,"Let ¯xk :=
kP"
HK,0.7642079806529625,"i=0
αixi/(
kP"
HK,0.7654171704957679,"i=0
αi). Dividing both sides by
kP"
HK,0.7666263603385731,"i=0
αi, convexity yields"
HK,0.7678355501813785,E[f(¯xk) −min f] ≤ kP
HK,0.7690447400241838,"i=0
αi E[(f(xi) −f(x∗))] kP"
HK,0.7702539298669892,"i=0
αi ."
HK,0.7714631197097944,"B.6
Proof of Corollary 4"
HK,0.7726723095525998,"In this proof, we use the same notation as the one in the proof of Theorem 3. By the choices of the
parameters, we have k
X"
HK,0.7738814993954051,"i=0
ρi ≤C1dαh
with
C1 := L1θ θ −1,"
HK,0.7750906892382105,"Sk ≤∥x0 −x∗∥2 + C2
d2"
HK,0.7762998790810157,"ℓα2h2
with
C2 :=
L2
1θ
2θ −1."
HK,0.777509068923821,"Thus, using these inequalities in Theorem 3, we get"
HK,0.7787182587666264,Dk ≤ℓ∆+ d¯α 2ℓ∆
HK,0.7799274486094316,"
∥x0 −x∗∥2 + C2
d2α2h2 ℓ
+
p"
HK,0.781136638452237,∥x0 −x∗∥2C3dαh
HK,0.7823458282950423,"+ C4
dαh
√"
HK,0.7835550181378477,"ℓ
+ C5d2α2h2
, with"
HK,0.7847642079806529,"C3 := L2
1θ
θ −1,
C4 := L2
1
√"
HK,0.7859733978234583,"2,
C5 :=
L2
1θ
(θ −1)2 ."
HK,0.7871825876662636,"Dividing by
kP"
HK,0.788391777509069,"i=0
αi, we get"
HK,0.7896009673518742,E[f(¯xk) −min f] ≤C αk .
HK,0.7908101571946796,"Note that by Assumption 4, α < ℓ/(dL1), thus 1/α > (dL1)/ℓ. The algorithm performs 2ℓfunction
evaluations at each iteration. Thus, to guarantee E[f(¯xk) −min f] ≤ε for ε ∈(0, 1), the algorithm
has to perform a number of function evaluations in the order of
O(dε−1).
Assuming, instead, αk ≤¯α < ℓ/(2dL1), by Lemma 9 we get the last claim; i.e, there exists a random
variable ˆx taking values in arg min f s.t. xk →ˆx a.s."
HK,0.7920193470374849,"B.7
Proof of Theorem 4"
HK,0.7932285368802902,Set C1 = (dL1)/2. It follows from Lemma 8 that
HK,0.7944377267230955,"E[f(xk+1)|Fk] −f(xk) ≤−
1"
HK,0.7956469165659008,2 −L1d
HK,0.7968561064087062,"ℓ
¯α

αk∥∇f(xk)∥2 + C2
1αkh2
k
2
+ L3
1d2"
HK,0.7980652962515115,"4ℓα2
kh2
k."
HK,0.7992744860943168,"Taking the full expectation and rearranging the terms, and recalling the definition of ∆,"
HK,0.8004836759371221,"∆αk E[∥∇f(xk)∥2] ≤E[f(xk) −f(xk+1)] + C2
1αkh2
k
2
+ L3
1d2"
HK,0.8016928657799275,"4ℓα2
kh2
k."
HK,0.8029020556227328,"Summing for i = 0, · · · , k and observing that min f ≤f(x) for every x, ∆ k
X"
HK,0.8041112454655381,"i=0
αi E[∥∇f(xi)∥2] ≤f(x0) −min f + k
X i=0"
HK,0.8053204353083434,"C2
1αih2
i
2
+ L3
1d2 4ℓ k
X"
HK,0.8065296251511487,"i=0
α2
i h2
i ."
HK,0.8077388149939541,"Divinding by ∆
kP"
HK,0.8089480048367593,"i=0
αi we get the claim."
HK,0.8101571946795647,"B.8
Proof of Corollary 5"
HK,0.81136638452237,"(i): From the choice of αk and hk, we have k
X"
HK,0.8125755743651754,"i=0
αih2
i ≤2θαh2 2θ −1 k
X"
HK,0.8137847642079806,"i=0
α2
i h2
i ≤2θα2h2"
HK,0.814993954050786,2θ −1 .
HK,0.8162031438935913,It follows from Theorem 4 that
HK,0.8174123337363967,"ηk ≤
1
∆αk "
HK,0.8186215235792019,"f(x0) −min f + C1d2αh2 + C2α2h2d2 ℓ ! ,"
HK,0.8198307134220073,"with C1 =
L2
1θ
4(2θ−1) and C2 =
L3
1θ
2(2θ−1).
(ii): It follows directly from Theorem 4 taking into account that k
X"
HK,0.8210399032648126,"i=0
αih2
i = kαh2, k
X"
HK,0.8222490931076178,"i=0
α2
i h2
i = kα2h2,"
HK,0.8234582829504232,"and setting C1 = L2
1/8 and C2 = L3
1/4."
HK,0.8246674727932285,"C
Experimental Details"
HK,0.8258766626360339,"In this appendix, we report details on the experiments performed. We implemented every script in
Python3 (version 3.9.11) and used numpy (version 1.22.2) [27] and matplotlib (version 3.5.1) [29]
libraries."
HK,0.8270858524788391,"Machine used to perform the experiments.
In the following table, we describe the features of the
machine used to perform the experiments in Section 4."
HK,0.8282950423216445,Table 1: Machine used to perform the experiments
HK,0.8295042321644498,Feature
HK,0.8307134220072552,"OS
Debian GNU/Linux 11
CPU(s)
4 x Intel(R) Core(TM) i7-1165G7 11th Gen @ 2.80GHz
CPU Core(s)
4
RAM
8 GB"
HK,0.8319226118500604,"Target Functions.
We considered two synthetic target functions: a convex smooth function f1 and
a convex non-smooth function f2 defined as follows"
HK,0.8331318016928658,"(Convex Smooth)
f1(x) := 1"
HK,0.8343409915356711,"2∥Ax∥2
with
A ∈Rd×d"
HK,0.8355501813784765,"(Convex Non-smooth)
f2(x) := ∥x −¯v∥1"
HK,0.8367593712212817,"where A is a random Gaussian matrix (i.e. Ai,j ∼N(0, 1)) and ¯v := [0, 1, · · · , d −1]⊺."
HK,0.837968561064087,"Choice of the number of directions.
We report here the details of the first experiment of Section 4.
For these experiments, we consider d = 50 and we use, for the smooth convex case, the following
parameters"
HK,0.8391777509068924,αk = 0.99 ℓ
HK,0.8403869407496977,"dL1
and
hk = 10−5"
HK,0.841596130592503,k + 1.
HK,0.8428053204353083,"The constant L1 is computed as the maximum eigenvalue of the matrix A⊺A. Note that this parameter
choice satisfies Assumption 4. For the non-smooth target, we used αk = r"
HK,0.8440145102781137,"ℓ
dk−1/2−10−5
and
hk = 10−7"
HK,0.845223700120919,k + 1.
HK,0.8464328899637243,"Note that this parameter configuration satisfies Assumption 2. The maximum number of function
evaluations considered is 4000. The direction matrices Gk are generated with the QR method - see
Appendix D."
HK,0.8476420798065296,"Comparison with Finite-difference methods.
In Section 4, we compare finite-difference method
with different choice of directions. In order to make a fair comparison we consider only central finite-
differences. However, note that Algorithm 1 can be modified (in practice) considering computationally
cheaper gradient estimators - see Remark 1. For these experiments, we consider d = 10 and ℓ= d
for methods with multiple directions. The maximum number of function evaluations is 1000 for both
smooth and non-smooth targets and the direction matrices Gk for Algorithm 1 are generated with the
QR method - see Appendix D. To solve the smooth problem we consider the following parameter
choice for every method"
HK,0.848851269649335,αk = c ℓ
HK,0.8500604594921403,"dL1
and
hk =
10−7"
HK,0.8512696493349455,"d2(k + 1),"
HK,0.8524788391777509,"where L1 is computed taking the maximum eigenvalue of A⊺A. For Algorithm 1 and finite-difference
with single and multiple spherical directions c = 0.99 while it is equal to c = 0.11 for finite-difference
with single and multiple Gaussian directions. We made this choice since for finite-difference methods
with Gaussian directions we observed divergence for larger choices of c - see Figure 3."
HK,0.8536880290205562,"0
200
400
600
800
1000
function evaluations 10−1 102 105 108 1011 1014 1017"
HK,0.8548972188633616,f(xk) −f(x * )
HK,0.8561064087061668,Smooth Convex Target
HK,0.8573155985489722,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Our"
HK,0.8585247883917775,"0
200
400
600
800
1000
function evaluations 10−2 10−1 100 101 102 103 104 105"
HK,0.8597339782345829,f(xk) −f(x * )
HK,0.8609431680773881,Smooth Convex Target
HK,0.8621523579201935,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Our"
HK,0.8633615477629988,"Figure 3: From left to right, comparison of finite-difference methods for smooth convex target with
c = 0.99 and c = 0.2 for methods with Gaussian directions."
HK,0.8645707376058042,"For the non-smooth convex target, we considered the following parameter choice"
HK,0.8657799274486094,αk = c ℓ
HK,0.8669891172914147,"dk−1/2−10−5
and
hk =
1
d2(k + 1)."
HK,0.8681983071342201,"For every method, we selected c = 0.65 except for the method with multiple Gaussian directions in
which we selected c = 0.08 since it provided better performances - see Figure 4."
HK,0.8694074969770254,"0
200
400
600
800
1000
function evaluations 100 101"
HK,0.8706166868198307,f(xk) −f(x * )
HK,0.871825876662636,NonSmooth Convex Target
HK,0.8730350665054414,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Our"
HK,0.8742442563482467,"0
200
400
600
800
1000
function evaluations 100 101"
HK,0.875453446191052,f(xk) −f(x * )
HK,0.8766626360338573,NonSmooth Convex Target
HK,0.8778718258766627,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Our"
HK,0.879081015719468,"0
200
400
600
800
1000
function evaluations 100 101"
HK,0.8802902055622733,f(xk) −f(x * )
HK,0.8814993954050786,NonSmooth Convex Target
HK,0.8827085852478839,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Our"
HK,0.8839177750906893,"0
200
400
600
800
1000
function evaluations 100 101"
HK,0.8851269649334945,f(xk) −f(x * )
HK,0.8863361547762999,NonSmooth Convex Target
HK,0.8875453446191052,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Our"
HK,0.8887545344619106,"0
200
400
600
800
1000
function evaluations 100 101"
HK,0.8899637243047158,f(xk) −f(x * )
HK,0.8911729141475212,NonSmooth Convex Target
HK,0.8923821039903265,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Our"
HK,0.8935912938331319,"0
200
400
600
800
1000
function evaluations 100 101"
HK,0.8948004836759371,f(xk) −f(x * )
HK,0.8960096735187424,NonSmooth Convex Target
HK,0.8972188633615478,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Our"
HK,0.898428053204353,"0
200
400
600
800
1000
function evaluations 100 101"
HK,0.8996372430471584,f(xk) −f(x * )
HK,0.9008464328899637,NonSmooth Convex Target
HK,0.9020556227327691,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Our"
HK,0.9032648125755743,"0
200
400
600
800
1000
function evaluations 100 101 102"
HK,0.9044740024183797,f(xk) −f(x * )
HK,0.905683192261185,NonSmooth Convex Target
HK,0.9068923821039904,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Our"
HK,0.9081015719467956,"Figure 4: From left to right and up to down, comparison of finite difference method with different
directions and different values of c for multiple Gaussian directions. The values of c considered are
the following [0.085, 0.089, 0.09, 0.1, 0.2, 0.3, 0.5, 0.65]"
HK,0.909310761789601,"D
Techniques to Generate Orthogonal Direction Matrices"
HK,0.9105199516324063,"In the literature, different algorithms were proposed to generate orthogonal matrices - see for instance
[23, 38, 11, 28, 7, 2, 4, 44, 8] and references therein. Such methods can be used to generate the
direction matrices Gk required for the iteration proposed in Algorithm (1). In this appendix, we
briefly discuss three of them."
HK,0.9117291414752116,"QR factorization.
As observed in [32, 42], a way to generate orthogonal consists in generating
a random Gaussian matrix A ∈Rd×d with Ai,j ∼N(0, 1) and perform the QR factorization i.e.
A = QR. Then, the direction matrix is the truncation of the Q matrix i.e. QId,ℓ."
HK,0.9129383313180169,"Householder Reflection.
To obtain a direction matrix, we can use a Householder reflector. This
can be done by sampling a vector v from the unit sphere Sd−1. The direction matrix G is defined as a
Householder reflector, given by"
HK,0.9141475211608222,"G := I −2vv⊺,"
HK,0.9153567110036276,"with I ∈Rd×d identity matrix. To obtain the desired matrix, we compute the product of G with Id,ℓ,
i.e., we take the first ℓcolumns. The (truncated) identity matrix can be generated and stored offline
(note that since it is very sparse, it can be stored using a sparse format (e.g. the COO format proposed
in scikit-learn library[9]). In this way, we can save resources in high-dimensional settings. In order to
quantify the time-cost of this procedure, we compared the time of generating this kind of matrix with
random matrices with different dimensions. For this experiment, we consider the ℓ= d case i.e. the
most expensive. Matrices are computed in CPU and the details of the machine used are described in
Appendix C. We report the mean and standard deviation of the time using 500 repetitions. In Figure
5, we compare the time-cost of generating orthogonal matrices with this procedure against generating
random matrices while in Table 2 we report the mean and standard deviation of the results."
HK,0.9165659008464329,"2
4
8
16
32
64
128
256
512
1024 2048
d 10−7 10−6 10−5 10−4 10−3 10−2 10−1"
HK,0.9177750906892382,Time (s)
HK,0.9189842805320435,Computational Time to generate matrices
HK,0.9201934703748489,"random Gaussian
random spherical
Householder"
HK,0.9214026602176542,Figure 5: Time comparison in CPU of different methods to generate direction matrices.
HK,0.9226118500604595,"In Figure 5, we can observe that using this strategy we can limit the cost of generating random
orthogonal matrices. In particular, for dimensions larger than 32, our method is faster than random
gaussian and spherical directions."
HK,0.9238210399032648,"Table 2: Comparison of the time-cost (seconds) of generating random and orthogonal matrices with
different dimensions"
HK,0.9250302297460702,"d
Random Gaussian
Random Spherical
Householder"
HK,0.9262394195888755,"2
9.27 × 10−7 ± 7.96 × 10−7
5.49 × 10−6 ± 2.05 × 10−6
9.32 × 10−6 ± 3.34 × 10−6"
HK,0.9274486094316807,"4
1.30 × 10−6 ± 7.21 × 10−7
6.56 × 10−6 ± 2.63 × 10−6
1.12 × 10−5 ± 5.79 × 10−6"
HK,0.9286577992744861,"8
2.18 × 10−6 ± 6.06 × 10−7
8.01 × 10−6 ± 5.32 × 10−6
1.11 × 10−5 ± 5.20 × 10−6"
HK,0.9298669891172914,"8
2.18 × 10−6 ± 6.06 × 10−7
8.01 × 10−6 ± 5.32 × 10−6
1.11 × 10−5 ± 5.20 × 10−6"
HK,0.9310761789600968,"16
5.69 × 10−6 ± 1.61 × 10−6
1.15 × 10−5 ± 4.10 × 10−6
1.18 × 10−5 ± 7.20 × 10−6"
HK,0.932285368802902,"32
1.78 × 10−5 ± 6.42 × 10−6
2.49 × 10−5 ± 1.33 × 10−5
1.16 × 10−5 ± 7.25 × 10−6"
HK,0.9334945586457074,"64
6.58 × 10−5 ± 7.03 × 10−6
7.74 × 10−5 ± 1.95 × 10−5
1.62 × 10−5 ± 3.79 × 10−6"
HK,0.9347037484885127,"128
2.73 × 10−4 ± 2.37 × 10−5
2.98 × 10−4 ± 2.45 × 10−5
3.32 × 10−5 ± 4.02 × 10−6"
HK,0.9359129383313181,"256
1.26 × 10−3 ± 2.79 × 10−5
1.36 × 10−3 ± 2.90 × 10−5
1.20 × 10−4 ± 1.04 × 10−4"
HK,0.9371221281741233,"512
5.50 × 10−3 ± 1.63 × 10−4
5.91 × 10−3 ± 1.22 × 10−4
1.22 × 10−3 ± 3.82 × 10−4"
HK,0.9383313180169287,"1024
2.16 × 10−2 ± 6.92 × 10−4
2.41 × 10−2 ± 7.35 × 10−4
4.83 × 10−3 ± 2.26 × 10−3"
HK,0.939540507859734,"2048
8.92 × 10−2 ± 8.19 × 10−2
1.04 × 10−1 ± 1.03 × 10−1
2.40 × 10−2 ± 3.87 × 10−2"
HK,0.9407496977025392,"Moreover, if more computational resources are available, we can build m > 1 Householder reflectors
G1, · · · , Gm using m random vectors v1, · · · , vm sampled i.i.d from Sd−1 and define the direction
matrix as"
HK,0.9419588875453446,"G1G2 · · · GmId,ℓ."
HK,0.9431680773881499,"It is important to note that when m = d, this procedure is equivalent to using the QR factorization."
HK,0.9443772672309553,"Haar Butterfly matrices.
We can build orthogonal matrices using Butterfly matrices [48]. Let
G(0) := [1], we can build an orthogonal matrix of dimension d = 2n with the following recursion"
HK,0.9455864570737605,"G(n) =

cos(θn)G(n−1)
sin(θn)G(n−1)"
HK,0.9467956469165659,"−sin(θn)G(n−1)
cos(θn)G(n−1) "
HK,0.9480048367593712,"where θn is sampled uniformly in [0, 2π]. Then we compute GId,ℓ(we take the first ℓcolumns).
The construction of Haar butterfly matrices is faster than previous methods because it only requires
simple operations. However, this procedure allows to build only matrices with d = 2n for n ≥0. In
literature, different methods were proposed to cope with this limitation e.g. [23]."
HK,0.9492140266021766,"E
Limitations"
HK,0.9504232164449818,"In this appendix, we discuss the main practical limitations of Algorithm 1. Like all finite-difference
methods with multiple directions, O-ZD requires multiple function evaluations to execute a single
step. In many practical applications, function evaluations can be time-consuming, leading to the use
of a small number of directions ℓ. This may result in poor performance as observed in numerical
experiments. As for the subgradient method, in O-ZD the step size significantly affects performance,
and tuning it can be challenging. To address this limitation, an adaptive stepsize selection method
could be proposed. Furthermore, decreasing the sequence hk too quickly can lead to numerical
instability, as noted in [42]."
HK,0.9516324062877872,"F
Other Experiments"
HK,0.9528415961305925,"We performed other experiments in minimizing convex functions. We considered the targets defined
in Table 3 and, for each experiment, we reported the mean and standard deviation using 20 repetitions."
HK,0.9540507859733979,"0
2500
5000
7500
10000
12500
15000
17500
20000
function evaluations 10−1 100 101 102 103"
HK,0.9552599758162031,f(xk) −f(x * )
HK,0.9564691656590084,Elastic Net
HK,0.9576783555018138,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Ours"
HK,0.9588875453446191,"0
2500
5000
7500
10000
12500
15000
17500
20000
function evaluations 100 101 102"
HK,0.9600967351874244,f(xk) −f(x * )
HK,0.9613059250302297,Total Variation
HK,0.9625151148730351,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Ours"
HK,0.9637243047158404,"0
2500
5000
7500
10000
12500
15000
17500
20000
function evaluations 10−14 10−11 10−8 10−5 10−2 101"
HK,0.9649334945586457,f(xk) −f(x * )
HK,0.966142684401451,Huber Loss
HK,0.9673518742442564,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Ours"
HK,0.9685610640870617,"0
2500
5000
7500
10000
12500
15000
17500
20000
function evaluations 101"
HK,0.969770253929867,5 × 100
HK,0.9709794437726723,6 × 100
HK,0.9721886336154776,7 × 100
HK,0.973397823458283,8 × 100
HK,0.9746070133010882,9 × 100
HK,0.9758162031438936,f(xk) −f(x * )
HK,0.9770253929866989,Infinity Norm
HK,0.9782345828295043,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Ours"
HK,0.9794437726723095,"0
2500
5000
7500
10000
12500
15000
17500
20000
function evaluations 100 101 f(xk)"
HK,0.9806529625151149,Sparse Group Lasso
HK,0.9818621523579202,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Ours"
HK,0.9830713422007256,"0
2500
5000
7500
10000
12500
15000
17500
20000
function evaluations 10−14 10−11 10−8 10−5 10−2 101"
HK,0.9842805320435308,f(xk) −f(x * )
HK,0.9854897218863361,L1 Norm
HK,0.9866989117291415,"Single Gaussian
Single Spherical
Multi Gaussian
Multi Spherical
Ours"
HK,0.9879081015719468,Figure 6: Function values per function evaluation in optimizing functions with different algorithms.
HK,0.9891172914147521,"In Figure 6, we can observe that structured finite-difference performs better than unstructured
methods."
HK,0.9903264812575574,Table 3: Functions used and relative dimension and number of directions considered.
HK,0.9915356711003628,"Name
Definition
d
ℓ"
HK,0.992744860943168,"Sparse Group Lasso
f(x) :=
pP"
HK,0.9939540507859734,"i=1
∥x(βi)∥
50
25"
HK,0.9951632406287787,"Huber Loss
f(x) :=

0.5∥x∥2
2
∥x∥2 ≤δ
δ∥x∥2 −0.5δ2
otherwise
for δ > 0
50
25"
HK,0.9963724304715841,"Elastic Net
f(x) := α∥x∥1 + 0.5β∥x∥2
2
50
25
L1
f(x) := ∥x∥1
50
25
Infinity Norm
f(x) := ∥x∥∞
50
20
Total Variation
f(x) := ∥x∥TV
50
25"
HK,0.9975816203143894,"In Table 3, we define the function used for the experiments. In particular:"
HK,0.9987908101571947,"• Sparse Group Lasso: p is set to 3 and given an x ∈Rd, x(βi) is a vector obtained by taking
3 entries of x.
• Huber Loss: δ is set to 0.5.
• Elastic Net: α, β are set to 0.5."
