Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.002512562814070352,"Black-box optimisation is one of the important areas in optimisation. The original
No Free Lunch (NFL) theorems highlight the limitations of traditional black-box
optimisation and learning algorithms, serving as a theoretical foundation for tradi-
tional optimisation. No Free Lunch Analysis in adversarial (also called maximin)
optimisation is a long-standing problem [45, 46]. This paper first rigorously proves
a (NFL) Theorem for general black-box adversarial optimisation when considering
Pure Strategy Nash Equilibrium (NE) as the solution concept. We emphasise the
solution concept (i.e. define the optimality in adversarial optimisation) as the
key in our NFL theorem. In particular, if Nash Equilibrium is considered as the
solution concept and the cost of the algorithm is measured in terms of the number
of columns and rows queried in the payoff matrix, then the average performance of
all black-box adversarial optimisation algorithms is the same. Moreover, we first
introduce black-box complexity to analyse the black-box adversarial optimisation
algorithm. We employ Yao’s Principle and our new NFL Theorem to provide
general lower bounds for the query complexity of finding a Nash Equilibrium in
adversarial optimisation. Finally, we illustrate the practical ramifications of our
results on simple two-player zero-sum games. More specifically, no black-box opti-
misation algorithm for finding the unique Nash equilibrium in two-player zero-sum
games can exceed logarithmic complexity relative to search space size. Meanwhile,
no black-box algorithm can solve any bimatrix game with unique NE with fewer
than a linear number of queries in the size of the payoff matrix."
INTRODUCTION,0.005025125628140704,"1
Introduction"
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.007537688442211055,"1.1
Black-Box Optimisation and the No Free Lunch Theorem"
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.010050251256281407,"Black-Box Optimisation (BBO) is crucial for optimising complex, unknown, or expensive-to-evaluate
functions in real-world scenarios, such as aerodynamic design and hyperparameter tuning, where only
input-output observations are available. Formally, BBO is the task of optimising objective functions
from some function class F where F consists of f : X →R, where the algorithm is limited to
making queries to f [11, 14, 36]. In this case, the algorithm is only able to sample and query the
function value f(x) of search points x ∈X from a “black-box” or “oracle” without access to any
description of the objective functions f. A similar framework can be extended to game-theoretic
BBO, namely adversarial BBO. Specifically, adversarial BBO is the task that optimising payoff
functions from some payoff function class G where G consists of black-box functions g : X ×Y →R,
with a limited budget of function evaluations. Additionally, two players x ∈X and y ∈Y form"
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.01256281407035176,∗Authors are listed in alphabetical order.
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.01507537688442211,"a maximin optimisation (as presented in Figure 1). The original No Free Lunch Theorems for
traditional optimisation can be summarised as follows:"
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.017587939698492462,"“For all possible metrics, no search algorithm or supervised learning algorithm is
better than another when its performance is averaged over all possible problem
instances [45, 44].” Black Box"
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.020100502512562814,"g(x, y)"
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.022613065326633167,Output x
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.02512562814070352,"y
Input"
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.02763819095477387,"Input
Black Box f(x)"
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.03015075376884422,Output x Input
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.032663316582914576,"Figure 1: Comparison between traditional black-box optimisation and maximin black-box optimi-
sation. Instead of querying at x in traditional optimisation, maximin optimisation queries at (x, y)
include both strategy x and the best response y from the opponent, i.e. maxx∈X miny∈Y g(x, y).
Their interaction is converted to the payoff g(x, y) in the given black-box model."
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.035175879396984924,"Wolpert and Macready [45] and Wolpert [44] have revealed the underlying facts about the usefulness
of traditional black-box optimisation algorithms, including various randomised search heuristics
(such as evolutionary algorithms and simulated annealing) and machine learning algorithms (such
as supervised learning). In particular, it shows that the performance of all black-box optimisation
algorithms [45] and learning algorithms [44], when averaged over all problem instances, is the same
for any maximisation or minimisation tasks. Droste et al. [11] has provided a generalised NFL
theorem with more realistic scenarios by relaxing NFL theorem holds from all problem instances to
problem instances closed under permutation. Another seminal work by Schaffer [37] also showed a
conservation law for the generalised performance of learning algorithms in classification problems."
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.03768844221105527,"Adversarial optimisation tasks, such as maximin optimisation, are more complex and often counter-
intuitive compared to traditional optimisation problems. In adversarial settings, defining solution
concepts, or establishing what is meant by optimality, is essential. Common solution concepts include
‘Maximisation Over All Test Cases’, ‘maximin’, and Nash Equilibrium. A ‘free lunch’ in adversarial
optimisation implies that, for a given solution concept, some algorithms consistently outperform
others when averaged across all possible problem instances. This phenomenon was demonstrated
by Wolpert and Macready [46] for adversarial optimisation with respect to the ‘maximin’ solution
concept (Definition 10). Similarly, Service and Tauritz [39] established a ‘free lunch’ result for the
‘Maximisation Over All Test Cases’ concept (Definition 9)."
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.04020100502512563,"Beyond ‘maximin’ and ‘Maximisation Over All Test Cases’, Nash Equilibrium is another widely
studied solution concept in adversarial learning and maximin optimisation. This concept is central
to various applications, including adversarial learning models such as GANs [15, 20] and spatial
games [19, 26, 32]. While previous studies by Wolpert and Macready [46] and Service and Tauritz
[39] have demonstrated the existence of ‘free lunches’ in adversarial optimisation, the following key
questions remain open:"
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.04271356783919598,(1) Does adversarial optimisation exhibit a ‘free lunch’ for all possible solution concepts?
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.04522613065326633,"(2) If we use Nash Equilibrium as the solution concept, how can we characterise the difficulty of
black-box adversarial optimisation problems for problem-independent, possibly randomised,
search heuristics?"
BLACK-BOX OPTIMISATION AND THE NO FREE LUNCH THEOREM,0.04773869346733668,"In this paper, we answer Question (1) in the negative by showing a No Free Lunch theorem for Nash
Equilibrium solution concept and address Question (2) by introducing black-box complexity tools."
CHALLENGES AND TECHNICAL OVERVIEW OF THE NFL AND BBC RESULTS,0.05025125628140704,"1.2
Challenges and Technical Overview of the NFL and BBC Results"
CHALLENGES AND TECHNICAL OVERVIEW OF THE NFL AND BBC RESULTS,0.052763819095477386,"There are several challenges in showing the NFL and BBC results. First, we highlight the challenges
and our technical details in the derivation process compared to previous NFL work. The classical No
Free Lunch theorem applies proof by induction with respect to the size of the function domain. A
natural idea is to extend the previous proof-by-induction method in our NFL proof. However, one
of the most challenging aspects of deriving NFL for Nash Equilibrium (NE) is that the adversarial"
CHALLENGES AND TECHNICAL OVERVIEW OF THE NFL AND BBC RESULTS,0.05527638190954774,"setting significantly increases the difficulty since the problem depends on the performances of both
the player and the opponents. To address this, we introduce two technical lemmas from game theory
(i.e. Lemma 3 and Lemma 4) and help to construct the isomorphism between two different problem
classes (i.e. Corollary 1 and Lemma 2), which is an essential step in the proof of the original NFL
theorem for traditional optimisation (see Section B for more details). Another significant challenge is
that we start with a very weak assumption: we only allow access to the payoff function and make
no assumptions about its properties, such as convexity, continuity, or differentiability. In fact, no
gradients, continuity, or differentiability make the NFL and black box results easier to prove (i.e.,
the function class lacks a specific structure). On the other hand, it makes it more difficult for the
algorithm. Consequently, we have limited analytical tools to proceed. To analyse the black-box
complexity of adversarial optimisation, we introduce Yao’s minimax principle and apply our new
NFL result. Please consult the proof of Theorem 4.2 for more details."
CONTRIBUTION,0.05778894472361809,"1.3
Contribution"
CONTRIBUTION,0.06030150753768844,"We prove a new impossibility result on black-box adversarial optimisation. In a two-player zero-
sum game setting, there is no free lunch with respect to an approximation of the real cost model
when regarding the unique Nash Equilibrium as the solution concept. In other words, all black-box
adversarial optimisation algorithms have the same expected performance over a uniform distribution
of all possible problem instances with the unique Nash Equilibrium as the solution concept. It is
the first step to resolve this long-standing open research problem about NFL in general black-box
adversarial optimisation since [45, 46]. Our results highlight the significance of the choice of solution
concepts and the limitation of general black-box adversarial optimisation. Additionally, we introduce
the first general black-box model and the notion of black-box complexity for adversarial optimisation.
Under this general black-box model, we provide the general lower bounds for query complexity
of computing Nash Equilibrium in adversarial optimisation. Finally, we illustrate our results on
examples of computing unique Nash Equilibrium in two-player zero-sum games."
PRELIMINARIES,0.06281407035175879,"2
Preliminaries"
NOTATION,0.06532663316582915,"2.1
Notation"
NOTATION,0.0678391959798995,"Given n ∈N, [n] := {1, 2, · · · , n}. Given a finite set X, we denote the permutation group by
S(X) := {σ : X →X | σ is a permutation of X}. For any v ∈Rn, let SUPP(v) := {i ∈[n] |
vi ̸= 0}. We refer to query complexity or runtime as the number of payoff function evaluations
until the given algorithm finds the optimum. We consider the search space X × Y, where X and Y
are finite and denote the cardinality of a set by |X|. For any bitstring z, |z|1 denotes the number of
1-bits in z. X ≃Y denotes the isomorphism between X and Y . X ≃Y if there exists a one-to-one
correspondence map from X to Y ."
NOTATION,0.07035175879396985,"Let f : X →Y be a function from a set X to a set Y . If A is a subset of X, then the restriction
of f to A is the function: f|A : A →Y ; x 7→f(x). Let f : X →Y be any function and A and B
be sets such that X ⊆A and Y ⊆B. An extension of f to A is a function g : A →B such that
f(x) = g(x) for all x ∈X. Alternatively, g is an extension of f to A if f is a restriction of g to X."
NOTATION,0.0728643216080402,"In this paper, we assume that the black-box optimisation algorithms do not make the same query
twice. This can be achieved by memorising the outcome of previous queries."
SOLUTION CONCEPTS,0.07537688442211055,"2.2
Solution Concepts"
SOLUTION CONCEPTS,0.07788944723618091,"Solution concepts for classical function optimisation are not directly applicable to adversarial op-
timisation in general-sum or zero-sum game settings [33, 24, 35]. Each agent or player’s payoff
depends on not only its action but also the response from its opponents, and thus, we need to introduce
different solution concepts to specify what kind of optimum we look for."
SOLUTION CONCEPTS,0.08040201005025126,"Pure Strategy Nash equilibrium is considered as our solution concept in this work. We are interested in
whether the black-box adversarial optimisation can efficiently find any given game’s Nash equilibrium.
We use the formulation in [30] to define Nash equilibrium rigorously. In this paper, we only focus on
Pure Strategy Nash Equilibrium (abbrev. NE)."
SOLUTION CONCEPTS,0.0829145728643216,"Definition 1. (Nash) Consider a two-player game. Given strategy spaces X × Y and payoff
functions g, h : X × Y →O, where O is an ordered set which determines the outcome of
candidate solution X on test Y, (x∗, y∗) is a Nash equilibrium if for all (x, y) ∈X × Y,
g(x∗, y∗) ≥g(x, y∗) and h(x∗, y∗) ≥h(x∗, y). In particular, if the two-player game is zero-sum
(that is, if g(x, y) + h(x, y) = 0 for all (x, y) ∈X × Y), then (x∗, y∗) is a Nash equilibrium if for
all (x, y) ∈X × Y, g(x, y∗) ≤g(x∗, y∗) ≤g(x∗, y). The solution concept is defined by"
SOLUTION CONCEPTS,0.08542713567839195,"S = {(x∗, y∗) ∈X × Y | ∀(x, y) ∈X × Y, g(x, y∗) ≤g(x∗, y∗) ≤g(x∗, y)}."
SOLUTION CONCEPTS,0.08793969849246232,"We also defer other solution concepts for comparison in the appendix. We use the formulation in
[46, 39]."
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.09045226130653267,"3
No Free Lunch Theorem for Computing Nash Equilibrium in Adversarial
Optimisation"
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.09296482412060302,"In this section, we prove a No Free Lunch Theorem for black-box adversarial optimisation. As a
first step toward the No Free Lunch Theorem, we consider two-player zero-sum games with the
unique NE as the same setting in [34], but we relax the restriction from potential games to general
two-player zero-sum games. The original NFL theorem for traditional optimisation assumed all
problems instances [45], and later, sharpened work also proved that this holds for functions ‘closed
under permutation’ [38, 11]. We now explain what ‘closed under permutation’ means and how it can
be extended to games."
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.09547738693467336,"Permutation closure of a set of functions means that let X, Y be two finite sets and f : X →Y
defined by f(xi) = yi. Let σ be a permutation σ : X →X and we can permute the function:
f(σ(x)) := σ ◦f(x). Schumacher et al. [38] and Droste et al. [11] defined ‘closed under permutation
(c.u.p.)’ with respect to a single search space X. A class of functions F = f : X × Y →R is called
c.u.p. if for all f ∈F and all permutations σ ∈S(X), f ◦σ ∈F. For our adversarial setting, we
need to extend this notion to X × Y.
Definition 2. Given two-player zero-sum games, suppose F as a subset of all the payoff functions in
these games g : X × Y →O where O ⊆R. We say F is c.u.p if for any g ∈F and any permutations
on X, Y denoted by σ ∈S(X), τ ∈S(Y), we have (σ ⊗τ) ◦g ∈F (or abbreviated (στ)g) where
(σ ⊗τ) ◦g(x, y) := g (σ(x), τ(y)) for all (x, y) ∈X × Y."
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.09798994974874371,"If a set of two-player zero-sum games is c.u.p., we will also call it structure-free. In this paper, we
restrict to the case that X, Y, O are finite sets following the settings in [45, 46]. The proof of the
No Free Lunch theorem for traditional optimisation by Droste et al. [12] is by induction, where one
assumes that the statement is true for all ""smaller problems"". Here, a smaller problem refers to the
following definition of a sub-game or a sub-problem class. Next, we define a sub-problem class for
two-player zero-sum games.
Definition 3. Given two-player zero-sum games, let O ⊆R and F be any subset of the set of payoff
functions in these games g : X × Y →O such that F is closed under permutation. For any given
(x1, y1) ∈X × Y, any function b1 : Y →O, and any function b2 : X →O, we define a sub-problem
class F ((x1, y1), (b1, b2)) with respect to F as follows: f ∈F ((x1, y1), (b1, b2)) if and only if
there exists a g ∈F such that"
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.10050251256281408,"(1) g(x1, y) = b1(y) for all y ∈Y;"
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.10301507537688442,"(2) g(x, y1) = b2(x) for all x ∈X;"
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.10552763819095477,(3) f is a restriction of g on (X \ {x1}) × (Y \ {y1}).
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.10804020100502512,"Next, before we show that a sub-problem class F ((x1, y1), (b1, b2)) is c.u.p., we need a lemma to
guarantee that after any permutation, the permuted payoff function still contains the same unique
Nash Equilibrium2. We provide a corollary to Lemma 4. We defer all the proofs to the appendix due
to the page limit.
Corollary 1. Let |X| = |Y| and F ⊆{g : X × Y →R} be any set of two-player zero-sum
games with a unique NE. Assume furthermore that F is c.u.p.. Then, for any game g ∈F, let"
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.11055276381909548,2The further explanation for sub-problem classes can be found in Section E.
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.11306532663316583,"(x∗, y∗) ∈X × Y denote the unique Nash Equilibrium of g. For any permutations over X, Y denoted
by σ ∈S(X), τ ∈S(Y), (σ ⊗τ) ◦g ∈F exhibits the same unique Nash Equilibrium (x∗, y∗).
Moreover, if for any x0 ̸= x∗and y0 ̸= y∗, the restriction of g on (X \ {x0}) × (Y \ {y0}), denoted
by g|(X\{x0})×(Y\{y0}), exhibits the same unique Nash Equilibrium (x∗, y∗)."
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.11557788944723618,"This permutation essentially swaps the rows and columns in the payoff matrix. Corollary 1 shows
that the permutation of rows and columns does not change the optimum (Nash Equilibrium in any
given payoff function). Moreover, if we remove the row and column in the given payoff function,
which do not contain the unique Nash Equilibrium, then the unique Nash Equilibrium remains the
same in the restricted sub-problem."
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.11809045226130653,"Next, we prove the sub-problem class is closed under permutation.
Lemma 1. If F is c.u.p., then F ((x1, y1), (b1, b2)) is also c.u.p.."
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.12060301507537688,"Then, we want to know if we choose different (x, y) in the sub-problem class, are they still isomorphic
(i.e., essentially the same problem for any black-box optimisation algorithm)?
Lemma 2. For all (x1, y1), (x2, y2) ∈X × Y and b1 : Y →R, b2 : X →R, we have the
isomorphism3:
F ((x1, y1), (b1, b2)) ≃F ((x2, y2), (b1, b2)) ."
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.12311557788944724,"Given (xt, yt) is the search point by Algorithm H on payoff function g at iteration t ∈N and (x∗, y∗)
is the unique NE in a two-player zero-sum game defined by g : X × Y →R, Theorem 3.1 considers
the following query complexity: assume the cost Ct is the unique queries made by Algorithm H,
TLB(H, g) := inf{Ct > 0 | xt = x∗or yt = y∗}.
Now, we prove our main theorem.
Theorem 3.1. Given F as a subset of all the payoff functions g : X × Y →O with a unique Nash
Equilibrium where O ⊆R and |X| = |Y|. Let H be an arbitrary (randomised or deterministic)
black-box adversarial optimisation algorithm for any g ∈F where F is closed under permutations.
Let r(H, F) be the average (under the uniform distribution on F) of the expected query complexity
of H on g ∈F (i.e. E(TLB(H, g))). Then r(H, F) = r(H′, F) for all algorithms H, H′."
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.12562814070351758,"Proof Sketch. The proof of the main theorem is deferred to the appendix. Briefly, we use a proof
by induction on the size of the search space. During the inductive hypothesis, problem class is
reduced from F to F ((x1, y1), (b1, b2)), decreasing the search space from size N × N to size
(N −1) × (N −1), where |X| := N. Then using Lemma 2 and inductive step, it follows that
r(H, F) = r(H′, F) for any two deterministic algorithms H, H′, and the claim for randomised
algorithms quickly follows from the fact that any randomised algorithm can be viewed as a probability
distribution among all deterministic algorithms."
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.12814070351758794,"Theorem 3.1 reveals an important underlying result: All black-box adversarial algorithms can exhibit
the same average runtime r(H, F) of all possible problem instances (or problem instances c.u.p.)
with a unique Nash Equilibrium in a two-player zero-sum game setting. It is a reasonable result since
Theorem 3.1 tells us that if a class of payoff functions with a unique Nash Equilibrium does not
change by any permutation on the input space, there is no structure provided for any search heuristic
or any optimisation algorithm to use and it cannot help to find the Nash Equilibrium. This is also
the reason why the original No Free Lunch theorem for traditional optimisation holds [45, 44]. As
concluded by Ho and Pepyne [23], “if anything is possible and occurs with the same probability, then
nothing can be expected."
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.1306532663316583,"This result is also surprising since Wolpert and Macready [46] and Service and Tauritz [39] both show
there exists free lunch with respect to the two solution concepts in Definition 9 and Definition 10.
However, our result does contradict the previous result. We consider the performance measure
T(H, g) and a different query model considered by the previous work. In particular, Definition 9 and
Definition 10 only take the player x into account, while the opponent optimum and different query
model and performance measures can make a difference, resulting in either FL or NFL results. In
summary, our new NFL theorem highlights the significance of solution concepts and also reveals that
adversarial optimisation can exhibit “no-free-lunch”, in particular for NE solution concept."
"NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL
OPTIMISATION",0.13316582914572864,"3Here we define isomorphism following [11] rather than defining it as a usual group or ring isomorphism
since we do not require any group or ring structure of F in the proof."
BLACK-BOX COMPLEXITY OF BLACK-BOX ADVERSARIAL OPTIMISATION,0.135678391959799,"4
Black-Box Complexity of Black-Box Adversarial Optimisation"
BLACK-BOX COMPLEXITY OF BLACK-BOX ADVERSARIAL OPTIMISATION,0.13819095477386933,"As shown in the previous NFL theorem, no better universal algorithms exist on structure-free
problems (i.e., only assume the payoff function consists of the unique NE). In order for an algorithm
to guarantee good performance, it is necessary to restrict the algorithm to classes of games that
possess some structure. To compute the Nash equilibrium of certain classes of problems, including
Nash equilibrium in a black-box setting, there are many works on analysing the computational
complexity for black-box algorithms, and researchers aim to minimise the query complexity and
provide more efficient algorithms to compute Nash equilibrium in two-player zero-sum game settings
[27, 26, 3, 21, 22] The following questions remain under-explored: How does the performance
measure of an algorithm (like query complexity) depend on the size of the search space, and is
there any limitation that these algorithms will reach regardless of the problem g? We answer these
questions here using black-box complexity."
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.1407035175879397,"4.1
The Unrestricted Black-Box Model and the Black-Box Complexity"
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.14321608040201006,"This section focuses on adversarial black-box optimisation and study the query complexity of learning
Nash equilibrium in a two-player zero-sum-game setting. We refer to [13, 8, 10] as a more detailed
introduction to the black-box complexity theory on traditional black-box optimisation. To prove a
lower bound that holds for all algorithms, it is necessary first formally to define what constitutes an
algorithm. Next, we construct an unrestricted black-box model of adversarial optimisation."
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.1457286432160804,Algorithm 1 An Unrestricted Black-Box Model with Unique Query History
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.14824120603015076,"Require: Search spaces X, Y.
Require: Payoff functions g : X × Y →R, h : X × Y →R;"
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.1507537688442211,"1: Initialise (x0, y0) based on P∅; Initialise H0 = ∅and C0 = 0.
2: for t = 1, 2, · · · until the termination criterion met do
3:
Choose some probability distribution PI(t), depending only on I(t) where
I(t) := Πt−1
j=1(xj, yj, g(xj, yj), h(xj, yj)) ∈(X × Y × R × R)t−1"
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.15326633165829145,"4:
Produce a random search point (xt, yt) based on PI(t).
5:
Query the payoffs g(xt, yt), h(xt, yt)
6:
if (xt, yt) ̸∈Ht−1 then Ct = Ct−1 + 1; Ht = Ht−1 ∪{(xt, yt)}.
7:
else Ct = Ct−1; Ht = Ht−1."
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.15577889447236182,"Algorithm 1 defines a class of algorithms subject to various probability distributions and samples
the new strategy pair based on previous pairs and their payoffs. The initial search point (x0, y0)
is independent of the problem, so we can choose any probability distribution P∅to initialise the
algorithm. Subsequent strategy pairs are obtained by asking the oracle to apply a given variation
operator to all previously queried search points subject to sample probability distribution PI(t). By
specifying different sample probability distribution PI(t), Algorithm 1 represents various black-box
optimisation algorithms, including several adversarial search (also called competitive coevolutionary)
algorithms [46, 32] and randomised algorithms FINDPSNE (designed to learn the NE in bimatrix
games) [27]. Note that the model only considers the cost of unique queries made by the algorithm (i.e.
we check the search point in the previous query history Ht in line 6). We assume that an algorithm
which makes the same query twice is only charged for the cost of one of the queries."
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.15829145728643215,"Now, we define the query complexity (or runtime) of black-box adversarial optimisation algorithms
by extending the idea of the traditional single-objective black-box optimisation algorithm in [13, 43]
and assuming h = −g (i.e. zero-sum game) in this case."
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.16080402010050251,"Definition 4. Given any unrestricted black-box algorithm with unique query history A and the payoff
function g : X × Y →R, T(A, g) is the query complexity of A with respect to g and (xt, yt) is the
search point generated by A if"
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.16331658291457288,"T(A, g) := inf{dCt ∈N | (xt, yt) ∈arg max
x∈X min
y∈Y g(x, y)}"
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.1658291457286432,"where d ∈{1, 2}. If the game is zero-sum, then d = 1. Otherwise, d = 2"
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.16834170854271358,"Note that T(A, g) ∈R ∪{∞} is the number of payoff evaluations until A queries for the first time
some (x∗, y∗) ∈arg maxx∈X miny∈Y g(x, y). Now, we can define what black-box complexity
means with respect to a given class of adversarial optimisation algorithms and problem classes.
Definition 5. For a class G of payoff functions g : X × Y →R, the A-black-box complexity of
G is defined as T(A, G) := supg∈G T(A, g), the runtime of A under the worst-case scenario on G.
Then, the A-black-box complexity of G is T(A, G) := infA∈A T(A, G) = infA∈A supg∈G T(A, g);
the best or minimum complexity among all A ∈A with respect to G. If A is the whole class of all
black-box algorithms, we denote T(A, G) the unrestricted black-box complexity of G."
THE UNRESTRICTED BLACK-BOX MODEL AND THE BLACK-BOX COMPLEXITY,0.1708542713567839,"We want to point out the difference between these two definitions. Definition 4 considers the query
complexity for a particular algorithm and problem instance, and Definition 5 considers the black-box
complexity for the best possible query complexity of all possible given algorithms under the worst-
case scenario. The traditional black-box complexity theory characterises the difficulty of a certain
class of problems and explores the limitations of the given black-box optimisation algorithms. We
expect our extension to adversarial optimisation can provide similar insights as well."
A GENERAL LOWER BOUND FOR BLACK-BOX ADVERSARIAL OPTIMISATION,0.17336683417085427,"4.2
A General Lower Bound for Black-Box Adversarial Optimisation"
A GENERAL LOWER BOUND FOR BLACK-BOX ADVERSARIAL OPTIMISATION,0.17587939698492464,"We first provide a lower bound of query complexity for a general class of black-box adversarial
optimisation problems.
Theorem 4.1. Let X and Y be any finite sets. Assume that B ⊂R with k := |B| ≥2. Consider any
class of two-player zero-sum games G ⊂{g : X × Y →B} such that for all (x, y) ∈X × Y, there
exists a game gx,y ∈G which has (x, y) as unique, pure Nash Equilibrium. Then, the class G has
black box complexity at least ⌈logk |X × Y|⌉−1."
A GENERAL LOWER BOUND FOR TWO-PLAYER ZERO-SUM BIMATRIX GAMES,0.17839195979899497,"4.3
A General Lower Bound for Two-player Zero-Sum Bimatrix Games"
A GENERAL LOWER BOUND FOR TWO-PLAYER ZERO-SUM BIMATRIX GAMES,0.18090452261306533,"In this subsection, we employ Yao’s Principle and No Free Lunch Theorem to provide a general
lower bound for query complexity of searching Nash Equilibrium in zero-sum bimatrix games, and
this leads to a sharper lower bound compared to the previous result in [27].
Theorem 4.2. Let A be the set of all randomised algorithms defined by Algorithm 1 and T(A, P)4
denote the query complexity of A with respect to the input payoff matrix P for a two-player zero-sum
game. Then, there exists an input matrix P ∈Rn×n with a unique pure Nash equilibrium (x∗, y∗)
such that E(T(A, P)) ≥(n + 1)/2. Thus, the black-box complexity with respect to A of the problem
class consisting of all bimatrix games with a unique Nash Equilibrium is at least (n + 1)/2."
A GENERAL LOWER BOUND FOR TWO-PLAYER ZERO-SUM BIMATRIX GAMES,0.18341708542713567,"Theorem 4.2 provides a sharper lower bound by a multiplicative factor 4 compared with the current
best bound by [27]. This result also demonstrates that in a two-player zero-sum bimatrix game (with
an n × n payoff matrix), there are complex instances where no randomised algorithm can achieve
better than O(n) query complexity unless additional problem structure is provided."
APPLICATIONS ON TWO-PLAYER ZERO-SUM GAMES,0.18592964824120603,"4.4
Applications on Two-Player Zero-Sum Games"
INTRODUCTION TO BINARY VOTING GAMES,0.1884422110552764,"4.4.1
Introduction to Binary Voting Games"
INTRODUCTION TO BINARY VOTING GAMES,0.19095477386934673,"This section provides some example applications of our black-box complexity results. Voting games
are popular games studied in game theory, computational social choice theory [5, 4, 16] and Boolean
games [18]. Voting is considered a fundamental tool for analysing multi-agent systems [16, 1]. We
start with simple binary voting games in which the outcome or payoff is 0 or 1 (or −1 and 1). These
games also play a role in the analysis of Boolean functions [31]."
INTRODUCTION TO BINARY VOTING GAMES,0.1934673366834171,"Convergence to NE in plurality voting has been studied from the perspective of social choice theory
and researchers specify certain conditions to guarantee the voting games to converge to NEs [28].
Some natural question arises: are there any randomised algorithms that can find these NEs in voting
games efficiently? What are the limitations of these black-box optimisation algorithms? Using the
black-box complexity analysis, we can answer the questions about the efficiency/inefficiency of
black-box optimisation algorithms on binary voting games."
INTRODUCTION TO BINARY VOTING GAMES,0.19597989949748743,"4Note that T(A, P) = T(A, g) where g(x, y) := eT
y Pex with ex, ey denote the elementary probability
distribution over probability simplex ∆{0,1}n"
INTRODUCTION TO BINARY VOTING GAMES,0.1984924623115578,"We formulate binary voting games in the context of adversarial optimisation as follows. Consider two
parties represented by vectors x, y ∈{0, 1}n where n ∈N. Each group has n members that either
“in favour"" (encoded by 1) or “against"" (encoded by 0) a particular proposal or decision. One group
seeks a strategy x∗that maximises its minimum gains against any strategy of the other group, while
the other group seeks a strategy y∗such that its choice minimises the maximum gains of the first
group. It essentially forms a two-player zero-sum game.
Definition 6. For X = Y = {0, 1}n, the payoff function DIAGONAL : X × Y →{−1, 1} is"
INTRODUCTION TO BINARY VOTING GAMES,0.20100502512562815,"DIAGONAL(x, y) :=
1
|y|1 ≤|x|1
−1
otherwise."
INTRODUCTION TO BINARY VOTING GAMES,0.20351758793969849,"In Definition 6, we present the votes of both groups by binary bitstrings and the payoff g can be
viewed as a binary voting game where the payoff only depends on which group has the stronger
majority “influence"". If one group has a stronger ‘in favour’ “influence"" in the sense of the number
of the support votes (i.e. the number of 1 in the encoding binary bitstring), then we get a payoff
1 and −1 otherwise. We are interested in computing NE in these two-player zero-sum games, i.e.
solving (x∗, y∗) ∈arg maxx∈X miny∈Y g(x, y). Notice that in DIAGONAL, (xn, yn) = (1n, 1n)
is the unique NE optimum. In this optimum, neither of the two groups is willing to deviate from
affecting their payoff g(xn, yn) anymore. This exactly coincides with the definition of NE."
INTRODUCTION TO BINARY VOTING GAMES,0.20603015075376885,"Next, we consider a different binary voting game, denoted by PLATEAU. To make the binary voting
game more challenging, we introduce some plateaus in games.
Definition 7. For X = Y = {0, 1}n, a constant δ ∈(0, 1), the payoff function PLATEAU : X ×Y →
{−1, 1} is defined as"
INTRODUCTION TO BINARY VOTING GAMES,0.20854271356783918,"PLATEAU(x, y) :=
f(y)
if ||x|1 −n"
INTRODUCTION TO BINARY VOTING GAMES,0.21105527638190955,2 | < δn
INTRODUCTION TO BINARY VOTING GAMES,0.2135678391959799,"2
g(x, y)
otherwise"
INTRODUCTION TO BINARY VOTING GAMES,0.21608040201005024,"where f : Y →{−1, 1} and g : X × Y →{−1, 1} are any functions such that the NE of PLATEAU
is (x∗, y∗) ̸∈{(x, y) | ||x|1 −n"
INTRODUCTION TO BINARY VOTING GAMES,0.2185929648241206,2 | < δn 2 }.
INTRODUCTION TO BINARY VOTING GAMES,0.22110552763819097,"Definition 7 introduces a plateau when comparing the “influence” between two groups and defines a
general class of pseudo-Boolean benchmarks with a plateau. Imagine a committee deciding on a new
policy where there are two groups with equal voting power. If the votes from group X are balanced
or nearly balanced (within the plateau), then the votes from the second group (Y) come into play. It
is like their votes are the tiebreaker. If the second group votes in favour, then the policy passes; if
they vote against it, then it fails. If the votes from group X are outside the plateau, then the payoff is
not restricted to be determined by y ∈Y."
INTRODUCTION TO BINARY VOTING GAMES,0.2236180904522613,"Finally, we define game instances generated by (u, v) where u, v ∈{0, 1}n.
Definition 8 ((u, v)-game instance). For all u, v ∈{0, 1}n, given f : {0, 1}n × {0, 1}n →R, we
define the (u, v)-instance of f, denoted by f(u,v), as f(u,v)(x, y) := f(u ⊕x, v ⊕v)."
INTRODUCTION TO BINARY VOTING GAMES,0.22613065326633167,"We can see that for any u, v ∈{0, 1}n, f(u,v) generates the same payoff landscape as f. In this paper,
f will be either DIAGONAL or PLATEAU. We defer more details to Section G5."
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.228643216080402,"4.4.2
Black-Box Complexity of Learning Nash Equilibrium in Binary Voting Games"
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.23115577889447236,"First, let us illustrate how Theorem 4.1 and Theorem 4.2 work on these simple examples. If we
consider a general class of black-box optimisation algorithms defined by Algorithm 1 on binary
voting games with a unique Nash Equilibrium, then we provide a general lower bound of black-box
complexity as follows.
Theorem 4.3. The black-box complexity with respect to Algorithm 1 of the binary voting games with
problem size n ∈N and a unique Nash Equilibrium is eΩ(n)."
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.23366834170854273,"Theorem 4.3 means that there exist no universal good black-box optimisation algorithms defined by
Algorithm 1 that can solve all binary voting games with unique Nash Equilibrium efficiently, (i.e.
with polynomial query complexity of the problem size). To yield a better performance of black-box"
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.23618090452261306,5We defer the definition of xor ⊕to Section G in the supplementary material.
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.23869346733668342,"optimisation algorithms on binary voting games, we need to specify the problem class we work
on. Next, we consider DIAGONAL and explore the black-box complexity with respect to the class
of black-box optimisation algorithms A defined by Algorithm 1 of DIAGONAL. This reveals that
DIAGONAL is a feasible benchmark problem for black-box adversarial optimisation algorithms.
Theorem 4.4. Given the game class"
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.24120603015075376,"DIAGONALn := {DIAGONAL(u,v) | (u, v) ∈{0, 1}n × {0, 1}n},"
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.24371859296482412,the black-box complexity with respect to Algorithm 1 of DIAGONALn is Θ(n).
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.24623115577889448,"Theorem 4.4 implies that DIAGONALn is a sensible maximin benchmark for testing black-box
optimisation algorithms. It means that if we restrict the problem class to a certain class with a specific
structure, then it is possible to solve them in polynomial query complexity."
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.24874371859296482,"We have seen the black-box complexity results on DIAGONALn. Next, we start to consider more
challenging binary voting games, PLATEAU. We are interested in whether there is any efficient
black-box adversarial optimisation that can solve PLATEAUn in polynomial query complexity (i.e.
O(n)). To answer this question, we need to compute its black-box complexity.
Theorem 4.5. Given the game class,"
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.25125628140703515,"PLATEAUn := {PLATEAU(u,v) | (u, v) ∈{0, 1}n × {0, 1}n},"
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.2537688442211055,"the black-box complexity with respect to the class of algorithms defined by Algorithm 1 of PLATEAUn
is eΩ(n)."
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.2562814070351759,"Theorem 4.5 implies that all black-box adversarial optimisation algorithms defined by unrestricted
model (i.e. Algorithm 1) have exponential runtime on PLATEAUn. They need at least an exponentially
large query complexity with respect to the problem size n. It is evident that PLATEAU is too
challenging that it may not be a proper benchmark for black-box adversarial optimisation algorithms."
SUMMARY,0.25879396984924624,"4.4.3
Summary"
SUMMARY,0.2613065326633166,"Our study introduces the concept of black-box complexity in binary voting games, providing insights
into the challenges faced by general black-box adversarial optimisation algorithms. These examples
illustrate two kinds of problems within the general class of binary voting games with unique NE: the
polynomial-solvable class (i.e., there exists an algorithm that can solve all problem instances of this
class in polynomial runtime) and the non-polynomial-solvable class (i.e., there exists no algorithm
that can solve all problem instances of this class in polynomial runtime)."
SUMMARY,0.2638190954773869,"Theorem 4.3 rigorously show that no universal algorithm can efficiently learn the unique Nash
Equilibrium (NE) in these games due to their structure-free nature, where efficiency means small
query complexity. However, when assuming specific problem structures, such as DIAGONALn, it
is possible to come up with a better algorithm which achieves better polynomial query complexity
as shown in Theorem 4.4. DIAGONALn can be a promising benchmark for evaluating black-box
algorithms. Additional assumptions on the payoff function, like those in PLATEAUn problems, proved
in Theorem 4.5, do not lower the difficulty of the problems. This emphasises the need for a more
careful selection of benchmarks. Black-box complexity emerges as a valuable tool for distinguishing
between potentially easy and hard problem instances, guiding the design of black-box algorithms."
FURTHER RELATED WORK,0.2663316582914573,"5
Further Related Work"
CO-EVOLUTIONARY SEARCH HEURISTICS,0.26884422110552764,"5.1
Co-evolutionary Search Heuristics"
CO-EVOLUTIONARY SEARCH HEURISTICS,0.271356783919598,"Next, we provide some practical examples of adversarial optimisation. There are various adversarial
search heuristics, including competitive co-evolutionary algorithms (CoEAs) [35, 26]. CoEAs are a
class of algorithms applied in game-theoretic and strategic adversarial optimisation scenarios. For
example, CoEAs are used to solve maximin optimisation in a cybersecurity context [32] and to
enhance GANs by using a co-evolutionary approach for image translation [41]. Similarly, the neural
architecture search system Lipizzaner employs co-evolutionary adversarial search to find suitable
neural architectures for GANs [42]."
CO-EVOLUTIONARY SEARCH HEURISTICS,0.27386934673366836,"Although several applications of adversarial (or co-evolutionary) search exist, there is limited theo-
retical literature on this topic. Lehre [26] demonstrated that the running time of the co-evolutionary"
CO-EVOLUTIONARY SEARCH HEURISTICS,0.27638190954773867,"algorithm PDCoEA on instances of the discrete bilinear problem is polynomial. Later, Hevia Fa-
jardo et al. [22] showed a weakness of RLS-PD and the sufficiency of a simple archive to prevent
evolutionary forgetting. On the other hand, regarding the general black-box optimisation framework,
Wolpert and Macready [46] showed there exists a “free lunch” in such adversarial (or co-evolutionary)
optimisation setting – there exist some algorithms have better performance than others averaged
across all possible problem instances in adversarial optimisation with respect to the maximin solution
concept (see Definition 10)."
QUERY COMPLEXITY OF LEARNING IN GAMES,0.27889447236180903,"5.2
Query Complexity of Learning in Games"
QUERY COMPLEXITY OF LEARNING IN GAMES,0.2814070351758794,"The query complexity of various solution concepts in zero-sum and general-sum multi-player games
has been well studied (for an overview, see [2, 27]). It is well-known that converging to an exact
(mixed strategy) Nash Equilibrium in general-sum matrix games is PPAD-complete [7]. Chen and
Deng [6] provide a simplified proof of the computational complexity of Nash Equilibrium in two-
player games. Significant focus has also been placed on how the game dynamics converge to the
Nash equilibrium or approximate it [27, 25, 17, 34]."
QUERY COMPLEXITY OF LEARNING IN GAMES,0.28391959798994976,"Panageas et al. [34] considered the complexity of fictitious play in two-player potential games with
a unique Nash Equilibrium (NE). They proved the existence of a hard instance which requires
query complexity Ω

4n ((n/2 −2)!)4
where n refers to the number of actions. They showed
that fictitious play can take exponential time (in the number of strategies) to reach a unique Nash
Equilibrium, even when the game is restricted to two agents and arbitrary tie-breaking rules, by
constructing a two-player coordination game with a unique Nash Equilibrium. Unlike previous work,
our paper focuses on a more general class of games: the entire class of two-player zero-sum games
with a unique NE rather than just potential games. We show that all black-box adversarial algorithms,
including fictitious play, exhibit the same average performance across all problem instances in terms
of query complexity."
CONCLUSION AND DISCUSSION,0.2864321608040201,"6
Conclusion and Discussion"
CONCLUSION AND DISCUSSION,0.2889447236180904,"Utilising the tools from game theory and Yao’s principle, we rigorously prove the impossibility
results for a universally effective adversarial algorithm applicable across various problem classes
in black-box adversarial optimisation. We emphasise the impact of solution concept selection on
the feasibility of a “free lunch"" in adversarial optimisation. Additionally, we introduce the notion of
black-box complexity in black-box adversarial optimisation and characterise the difficulty of learning
the unique optimum in adversarial optimisation and solving two-player zero-sum games."
CONCLUSION AND DISCUSSION,0.2914572864321608,"The results from this paper build up a foundation for future studies on the strengths and limitations of
adversarial optimisation. More specifically, it highlights the need for more comprehensive benchmarks
and careful selections of solution concepts when using any black-box adversarial optimisation
algorithms. Moreover, no black-box optimisation algorithm for learning the Nash equilibrium in
two-player zero-sum games can exceed the logarithmic complexity relative to search space size.
Meanwhile, no algorithm can solve any bimatrix game with unique NE faster than the linear query
complexity in terms of the size of input payoff matrices."
CONCLUSION AND DISCUSSION,0.29396984924623115,"Although our work makes a first step towards the new NFL and BBC results on black-box adversarial
optimisation, we want to point out some limitations of our current work and list them as our future
work. Firstly, our theoretical results build on discrete exponential large search spaces rather than
countably infinite (e.g. N) or uncountable infinite (e.g. R) sets. To generalise our results to infinite
sets, we might require further assumptions on our search spaces. Secondly, our NFL focuses on
two-player zero-sum games with unique NE."
CONCLUSION AND DISCUSSION,0.2964824120603015,"Future direction of our work includes extending Theorem 3.1 to other solution concepts like mixed
strategy Nash Equilibrium or exploring different possible solution concepts which may exhibit free
lunch or not. Additionally, it is interesting to generalise NFL and BBC analysis to zero-sum games
with multiple NEs and more general search spaces. Finally, it is interesting to analyse other black-box
models, such as unbiased black-box complexity models, to characterise the difficulty of adversarial
problems that different classes of search heuristics can solve."
CONCLUSION AND DISCUSSION,0.2989949748743719,Acknowledgements
CONCLUSION AND DISCUSSION,0.3015075376884422,"We would like to thank Dr Alistair Benford and Dr Mario Alejandro Hevia Fajardo for the fruitful
discussion and comments on an earlier draft of this paper. This work was supported by a Turing AI
Fellowship (EPSRC grant ref EP/V025562/1)."
REFERENCES,0.30402010050251255,References
REFERENCES,0.3065326633165829,"[1] Haris Aziz, Felix Brandt, Edith Elkind, and Piotr Skowron. Computational social choice: The
first ten years and beyond. Computing and Software Science: State of the Art and Perspectives,
pages 48–65, 2019."
REFERENCES,0.30904522613065327,"[2] Yakov Babichenko. Informational Bounds on Equilibria (a survey). ACM SIGecom Exchanges,
17(2):25–45, 2020."
REFERENCES,0.31155778894472363,"[3] Alistair Benford and Per Kristian Lehre. Runtime Analysis of Coevolutionary Algorithms on a
Class of Symmetric Zero-Sum Games. In GECCO’24: Genetic and Evolutionary Computation
Conference. Association for Computing Machinery (ACM), 2024."
REFERENCES,0.314070351758794,"[4] Felix Brandt, Vincent Conitzer, and Ulle Endriss. Computational social choice. Multiagent
systems, 2:213–284, 2012."
REFERENCES,0.3165829145728643,"[5] Felix Brandt, Vincent Conitzer, Ulle Endriss, Jérôme Lang, and Ariel D Procaccia. Handbook
of computational social choice. Cambridge University Press, 2016."
REFERENCES,0.31909547738693467,"[6] Xi Chen and Xiaotie Deng. Settling the complexity of two-player Nash equilibrium. In FOCS,
volume 6, pages 261–272, 2006."
REFERENCES,0.32160804020100503,"[7] Constantinos Daskalakis, Paul W Goldberg, and Christos H Papadimitriou. The complexity of
computing a Nash equilibrium. Communications of the ACM, 52(2):89–97, 2009."
REFERENCES,0.3241206030150754,"[8] Benjamin Doerr, Timo Kötzing, Johannes Lengler, and Carola Winzen. Black-box complexities
of combinatorial problems. Theoretical Computer Science, 471:84–106, 2013."
REFERENCES,0.32663316582914576,"[9] Benjamin Doerr, Carola Doerr, and Franziska Ebel. From black-box complexity to designing
new genetic algorithms. Theoretical Computer Science, 567:87–104, 2015."
REFERENCES,0.32914572864321606,"[10] Carola Doerr. Complexity Theory for Discrete Black-Box Optimization Heuristics. Theory of
Evolutionary Computation: Recent Developments in Discrete Optimization, pages 133–212,
2020."
REFERENCES,0.3316582914572864,"[11] Stefan Droste, Thomas Jansen, and Ingo Wegener. Optimization with randomized search
heuristics—the (A) NFL theorem, realistic scenarios, and difficult functions. Theoretical
Computer Science, 287(1):131–144, 2002."
REFERENCES,0.3341708542713568,"[12] Stefan Droste, Thomas Jansen, and Ingo Wegener. On the analysis of the (1+1) evolutionary
algorithm. Theoretical Computer Science, 276(1-2):51–81, April 2002."
REFERENCES,0.33668341708542715,"[13] Stefan Droste, Thomas Jansen, and Ingo Wegener. Upper and lower bounds for randomized
search heuristics in black-box optimization. Theory of computing systems, 39(4):525–544,
2006."
REFERENCES,0.3391959798994975,"[14] Daniel Golovin, Benjamin Solnik, Subhodeep Moitra, Greg Kochanski, John Karro, and David
Sculley. Google vizier: A service for black-box optimization. In Proceedings of the 23rd ACM
SIGKDD international conference on knowledge discovery and data mining, pages 1487–1495,
2017."
REFERENCES,0.3417085427135678,"[15] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil
Ozair, Aaron Courville, and Yoshua Bengio. Generative Adversarial Nets. Advances in Neural
Information Processing systems, 27, 2014."
REFERENCES,0.3442211055276382,"[16] Umberto Grandi, Davide Grossi, and Paolo Turrini. Equilibrium refinement through negotiation
in binary voting. In Proceedings of the 24th International Conference on Artificial Intelligence,
IJCAI’15, page 540–546. AAAI Press, 2015."
REFERENCES,0.34673366834170855,"[17] Hedi Hadiji, Sarah Sachs, Tim van Erven, and Wouter M Koolen. Towards Characterizing the
First-order Query Complexity of Learning (Approximate) Nash Equilibria in Zero-sum Matrix
Games. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. URL
https://openreview.net/forum?id=IPNg84RF1k."
REFERENCES,0.3492462311557789,"[18] Paul Harrenstein, Wiebe van der Hoek, John-Jules Meyer, and Cees Witteveen. Boolean games.
In Proceedings of the 8th Conference on Theoretical Aspects of Rationality and Knowledge,
TARK ’01, page 287–298, San Francisco, CA, USA, 2001. Morgan Kaufmann Publishers Inc."
REFERENCES,0.35175879396984927,"[19] Erik Hemberg, Jamal Toutouh, Abdullah Al-Dujaili, Tom Schmiedlechner, and Una-May
O’Reilly. Spatial coevolution for generative adversarial network training. ACM Transactions on
Evolutionary Learning and Optimization, 1(2):1–28, 2021."
REFERENCES,0.3542713567839196,"[20] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
GANs Trained by a Two Time-scale Update Rule Converge to a Local Nash Equilibrium.
Advances in Neural Information Processing Systems, 30, 2017."
REFERENCES,0.35678391959798994,"[21] Mario Alejandro Hevia Fajardo and Per Kristian Lehre. How fitness aggregation methods affect
the performance of competitive coeas on bilinear problems. In Proceedings of the Genetic and
Evolutionary Computation Conference, GECCO ’23, page 1593–1601, New York, NY, USA,
2023. Association for Computing Machinery. ISBN 9798400701191."
REFERENCES,0.3592964824120603,"[22] Mario Alejandro Hevia Fajardo, Per Kristian Lehre, and Shishen Lin. Runtime analysis of a
co-evolutionary algorithm: Overcoming negative drift in maximin-optimisation. In Proceedings
of the 17th ACM/SIGEVO Conference on Foundations of Genetic Algorithms, FOGA ’23, page
73–83, New York, NY, USA, 2023. Association for Computing Machinery."
REFERENCES,0.36180904522613067,"[23] Y.C. Ho and D.L. Pepyne. Simple Explanation of the No-Free-Lunch Theorem and Its Im-
plications. Journal of Optimization Theory and Applications, 115(3):549–570, December
2002."
REFERENCES,0.36432160804020103,"[24] Junling Hu, Michael P Wellman, et al. Multiagent reinforcement learning: theoretical framework
and an algorithm. In ICML, volume 98, pages 242–250, 1998."
REFERENCES,0.36683417085427134,"[25] Fivos Kalogiannis and Ioannis Panageas. Zero-sum Polymatrix Markov Games: Equilibrium
Collapse and Efficient Computation of Nash Equilibria. In Thirty-seventh Conference on
Neural Information Processing Systems, 2023. URL https://openreview.net/forum?id=
NGiq8qCQNk."
REFERENCES,0.3693467336683417,"[26] Per Kristian Lehre. Runtime Analysis of Competitive co-Evolutionary Algorithms for Max-
imin Optimisation of a Bilinear Function. In Proceedings of the Genetic and Evolutionary
Computation Conference, GECCO ’22, page 1408–1416, 2022."
REFERENCES,0.37185929648241206,"[27] Arnab Maiti, Ross Boczar, Kevin Jamieson, and Lillian J Ratliff. Query-Efficient Algorithms to
Find the Unique Nash Equilibrium in a Two-Player Zero-Sum Matrix Game. arXiv preprint
arXiv:2310.16236, 2023."
REFERENCES,0.3743718592964824,"[28] Reshef Meir, Maria Polukarov, Jeffrey S. Rosenschein, and Nicholas R. Jennings. Convergence
to equilibria in plurality voting. In Proceedings of the Twenty-Fourth AAAI Conference on
Artificial Intelligence, AAAI’10, page 823–828. AAAI Press, 2010."
REFERENCES,0.3768844221105528,"[29] Rajeev Motwani and Prabhakar Raghavan. Randomized Algorithms. Cambridge university
press, 1995."
REFERENCES,0.3793969849246231,"[30] Noam Nisan, Tim Roughgarden, Eva Tardos, and Vazirani Vijay V. Algorithmic Game Theory.
Cambridge University Press, 2007."
REFERENCES,0.38190954773869346,"[31] Ryan O’Donnell. Some topics in analysis of Boolean functions. In Proceedings of the fortieth
annual ACM symposium on Theory of computing (STOC), pages 569–578, 2008."
REFERENCES,0.3844221105527638,"[32] Una-May O’Reilly, Per Kristian Lehre, Mario Hevia Fajardo, Jamal Toutouh, and Erik Hemberg.
Analysis of a pairwise dominance coevolutionary algorithm and defendit. In Proceedings of the
Genetic and Evolutionary Computation Conference, GECCO ’23, page 1027–1035, New York,
NY, USA, 2023. Association for Computing Machinery."
REFERENCES,0.3869346733668342,"[33] Martin J Osborne and Ariel Rubinstein. A course in game theory. MIT press, 1994."
REFERENCES,0.38944723618090454,"[34] Ioannis Panageas, Nikolas Patris, Stratis Skoulakis, and Volkan Cevher. Exponential Lower
Bounds for Fictitious Play in Potential Games. In Thirty-seventh Conference on Neural Informa-
tion Processing Systems, 2023. URL https://openreview.net/forum?id=tkenkPYkxj."
REFERENCES,0.39195979899497485,"[35] Elena Popovici, Anthony Bucci, R. Paul Wiegand, and Edwin D. De Jong. Coevolutionary
Principles. In Grzegorz Rozenberg, Thomas Bäck, and Joost N. Kok, editors, Handbook of
Natural Computing, pages 987–1033. Springer Berlin Heidelberg, Berlin, Heidelberg, 2012."
REFERENCES,0.3944723618090452,"[36] Elad Sarafian, Mor Sinay, Yoram Louzoun, Noa Agmon, and Sarit Kraus. Explicit gradient
learning for black-box optimization. In ICML, pages 8480–8490, 2020."
REFERENCES,0.3969849246231156,"[37] Cullen Schaffer. A Conservation Law for Generalization Performance. In Proceedings of the
Eleventh International Conference on International Conference on Machine Learning, ICML’94,
page 259–265, San Francisco, CA, USA, 1994."
REFERENCES,0.39949748743718594,"[38] C. Schumacher, M. D. Vose, and L. D. Whitley. The No Free Lunch and Problem Description
Length. In Proceedings of the 3rd Annual Conference on Genetic and Evolutionary Computation,
GECCO’01, page 565–570, San Francisco, CA, USA, 2001. Morgan Kaufmann Publishers Inc."
REFERENCES,0.4020100502512563,"[39] Travis C. Service and Daniel R. Tauritz. A No-Free-Lunch Framework for Coevolution. In
Proceedings of the 10th Annual Conference on Genetic and Evolutionary Computation, GECCO
’08, page 371–378, New York, NY, USA, 2008. Association for Computing Machinery."
REFERENCES,0.4045226130653266,"[40] Lloyd S Shapley, Samuel Karlin, and HF Bohnenblust. Solutions of discrete, two-person games.
Contributions to the Theory of Games, 1950."
REFERENCES,0.40703517587939697,"[41] Han Shu, Yunhe Wang, Xu Jia, Kai Han, Hanting Chen, Chunjing Xu, Qi Tian, and Chang Xu.
Co-evolutionary compression for unpaired image translation. In Proceedings of the IEEE/CVF
International Conference on Computer Vision, pages 3235–3244, 2019."
REFERENCES,0.40954773869346733,"[42] Jamal Toutouh, Erik Hemberg, and Una-May O’Reilly. Spatial evolutionary generative adver-
sarial networks. In Proceedings of the Genetic and Evolutionary Computation Conference,
GECCO ’19, page 472–480, New York, NY, USA, 2019. Association for Computing Machinery."
REFERENCES,0.4120603015075377,"[43] Carola Winzen. Toward a complexity theory for randomized search heuristics : black-box
models. Adviser: Mehlhorn, Kurt. PhD thesis. Germany, Germany: Max-Planck-Institut f¨ur
Informatik, 2011."
REFERENCES,0.41457286432160806,"[44] David H Wolpert. The Supervised Learning No-Free-Lunch Theorems. Soft computing and
industry: Recent applications, pages 25–42, 2002."
REFERENCES,0.41708542713567837,"[45] David H Wolpert and William G Macready. No Free Lunch Theorems for Optimization. IEEE
Transactions on Evolutionary Computation, 1(1):67–82, 1997."
REFERENCES,0.41959798994974873,"[46] David H Wolpert and William G Macready. Coevolutionary Free Lunches. IEEE Transactions
on Evolutionary Computation, 9(6):721–735, December 2005."
REFERENCES,0.4221105527638191,"[47] Andrew Chi-Chin Yao. Probabilistic computations: Toward a unified measure of complexity.
In 18th Annual Symposium on Foundations of Computer Science (sfcs 1977), pages 222–227,
October 1977."
REFERENCES,0.42462311557788945,Appendix / Supplementary material
REFERENCES,0.4271356783919598,Contents
INTRODUCTION,0.4296482412060301,"1
Introduction
1"
INTRODUCTION,0.4321608040201005,"1.1
Black-Box Optimisation and the No Free Lunch Theorem . . . . . . . . . . . . . .
1"
CHALLENGES AND TECHNICAL OVERVIEW OF THE NFL AND BBC RESULTS,0.43467336683417085,"1.2
Challenges and Technical Overview of the NFL and BBC Results
. . . . . . . . .
2"
CHALLENGES AND TECHNICAL OVERVIEW OF THE NFL AND BBC RESULTS,0.4371859296482412,"1.3
Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3"
PRELIMINARIES,0.4396984924623116,"2
Preliminaries
3"
PRELIMINARIES,0.44221105527638194,"2.1
Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3"
PRELIMINARIES,0.44472361809045224,"2.2
Solution Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3"
NO FREE LUNCH THEOREM FOR COMPUTING NASH EQUILIBRIUM IN ADVERSARIAL OPTIMISATION,0.4472361809045226,"3
No Free Lunch Theorem for Computing Nash Equilibrium in Adversarial Optimisation
4"
BLACK-BOX COMPLEXITY OF BLACK-BOX ADVERSARIAL OPTIMISATION,0.44974874371859297,"4
Black-Box Complexity of Black-Box Adversarial Optimisation
6"
BLACK-BOX COMPLEXITY OF BLACK-BOX ADVERSARIAL OPTIMISATION,0.45226130653266333,"4.1
The Unrestricted Black-Box Model and the Black-Box Complexity . . . . . . . . .
6"
A GENERAL LOWER BOUND FOR BLACK-BOX ADVERSARIAL OPTIMISATION,0.4547738693467337,"4.2
A General Lower Bound for Black-Box Adversarial Optimisation
. . . . . . . . .
7"
A GENERAL LOWER BOUND FOR BLACK-BOX ADVERSARIAL OPTIMISATION,0.457286432160804,"4.3
A General Lower Bound for Two-player Zero-Sum Bimatrix Games . . . . . . . .
7"
A GENERAL LOWER BOUND FOR BLACK-BOX ADVERSARIAL OPTIMISATION,0.45979899497487436,"4.4
Applications on Two-Player Zero-Sum Games . . . . . . . . . . . . . . . . . . . .
7"
INTRODUCTION TO BINARY VOTING GAMES,0.4623115577889447,"4.4.1
Introduction to Binary Voting Games
. . . . . . . . . . . . . . . . . . . .
7"
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.4648241206030151,"4.4.2
Black-Box Complexity of Learning Nash Equilibrium in Binary Voting Games
8"
BLACK-BOX COMPLEXITY OF LEARNING NASH EQUILIBRIUM IN BINARY VOTING GAMES,0.46733668341708545,"4.4.3
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9"
FURTHER RELATED WORK,0.46984924623115576,"5
Further Related Work
9"
FURTHER RELATED WORK,0.4723618090452261,"5.1
Co-evolutionary Search Heuristics . . . . . . . . . . . . . . . . . . . . . . . . . .
9"
QUERY COMPLEXITY OF LEARNING IN GAMES,0.4748743718592965,"5.2
Query Complexity of Learning in Games
. . . . . . . . . . . . . . . . . . . . . .
10"
CONCLUSION AND DISCUSSION,0.47738693467336685,"6
Conclusion and Discussion
10"
CONCLUSION AND DISCUSSION,0.4798994974874372,"A Two Other Solution Concepts
15"
CONCLUSION AND DISCUSSION,0.4824120603015075,"B Technical Lemmas for Games with Unique Nash Equilibrium
15"
CONCLUSION AND DISCUSSION,0.4849246231155779,"C Analytic Tools from Probability Theory and Analysis of Randomised Algorithms
16"
CONCLUSION AND DISCUSSION,0.48743718592964824,"C.1
Yao’s Principle
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16"
CONCLUSION AND DISCUSSION,0.4899497487437186,"C.2
Markov’s inequality and Chernoff’s bound . . . . . . . . . . . . . . . . . . . . . .
16"
CONCLUSION AND DISCUSSION,0.49246231155778897,"D Omitted Proofs
16"
CONCLUSION AND DISCUSSION,0.4949748743718593,"E
Further Explanations for Sub-Problem Class
21"
CONCLUSION AND DISCUSSION,0.49748743718592964,"F
Further Explanations for the role of Corollary 1 and Lemma 1 in Theorem 3.1
22"
CONCLUSION AND DISCUSSION,0.5,"G Further Explanations for bitwise exclusive or in Black-Box Complexity Analysis
22"
CONCLUSION AND DISCUSSION,0.5025125628140703,"NeurIPS Paper Checklist
23"
CONCLUSION AND DISCUSSION,0.5050251256281407,"A
Two Other Solution Concepts"
CONCLUSION AND DISCUSSION,0.507537688442211,"Definition 9 (Maximisation Over All Test Cases [39] ). Suppose a set of candidate solutions, X, and
a set of test cases, Y. Given an interaction function or payoff function, g : X × Y →O, where O is
an ordered set which determines the outcome of candidate solution X on test Y, the solution concept
is defined by: S = {x∗∈X | ∀x ∈X, ∀y ∈Y, g(x∗, y) ≥g(x, y)}."
CONCLUSION AND DISCUSSION,0.5100502512562815,"Next, we define the Maximin solutions are those solution configurations which maximise the minimum
outcome over all test cases."
CONCLUSION AND DISCUSSION,0.5125628140703518,"Definition 10 (Maximin [46]). Suppose a set of candidate solutions, X, and a set of test cases, Y.
Given an interaction function or payoff function, g : X × Y →O, where O is an ordered set which
determines the outcome of candidate solution X on test Y, the solution concept is defined by:"
CONCLUSION AND DISCUSSION,0.5150753768844221,"S = {x∗∈X | ∀x ∈X, min
y∈Y g(x∗, y) ≥min
y∈Y g(x, y)}."
CONCLUSION AND DISCUSSION,0.5175879396984925,"Notice that in Definition 9, this solution concept considers the candidate solution x with respect to all
test cases y. Definition 10 considers the candidate solution with respect to the worst-case scenario.
If Y is compact, then these two solution concepts are essentially the same. Compared with Nash
Equilibrium in Definition 1, these two solution concepts only focus on finding the best candidate
solution and the algorithm is not required also to produce an opposing “optimal"" solution y∗."
CONCLUSION AND DISCUSSION,0.5201005025125628,"B
Technical Lemmas for Games with Unique Nash Equilibrium"
CONCLUSION AND DISCUSSION,0.5226130653266332,We adopt the notation in [27].
CONCLUSION AND DISCUSSION,0.5251256281407035,"Definition 11. Given a two-player zero-sum game on a payoff matrix P ∈Rn×n. Let ∆n denote the
n-dimensional probability simplex (i.e. for p ∈∆n, Pn
i=1 pi = 1 and pi ≥0). A pair (p∗, q∗) is a
(mixed strategy) Nash Equilibrium of an input matrix P ∈Rn×n if and only if the following holds
for all (p, q) ∈∆n × ∆n:"
CONCLUSION AND DISCUSSION,0.5276381909547738,"⟨p, Pq∗⟩≤⟨p∗, Pq∗⟩≤⟨p∗, Pq⟩."
CONCLUSION AND DISCUSSION,0.5301507537688442,"In this paper, we are only interested in Pure Strategy Nash Equilibrium."
CONCLUSION AND DISCUSSION,0.5326633165829145,"Definition 12. For any payoff matrix P ∈Rn×n, let V ⋆
P := maxp∈∆n minq∈∆n⟨p, Pq⟩. In
particular, we say an entry (i∗, j∗) ∈[n] × [n] is a unique pure strategy Nash Equilibrium if
(ei∗, ej∗) ∈∆n × ∆n is a unique Nash Equilibrium of P where ei∗, ej∗are the unit probability
vector."
CONCLUSION AND DISCUSSION,0.535175879396985,We refer to the following lemma from [40].
CONCLUSION AND DISCUSSION,0.5376884422110553,"Lemma 3 (Lemma 1 in [27]). Consider a matrix A ∈Rn×n with a unique Nash equilibrium (p⋆, q⋆).
The following conditions hold:"
CONCLUSION AND DISCUSSION,0.5402010050251256,"1. The support sizes of p⋆and q⋆are equal (i.e., |supp(p⋆)| = |supp(q⋆)|)."
CONCLUSION AND DISCUSSION,0.542713567839196,"2. V ⋆
A = ⟨ei, Aq⋆⟩for all i ∈supp(p⋆), and V ⋆
A > ⟨ei, Aq⋆⟩for all i /∈supp(p⋆)."
CONCLUSION AND DISCUSSION,0.5452261306532663,"3. V ⋆
A = ⟨p⋆, Aej⟩for all j ∈supp(q⋆), and V ⋆
A < ⟨p⋆, Aej⟩for all j /∈supp(q⋆)."
CONCLUSION AND DISCUSSION,0.5477386934673367,"Lemma 3 allows us to derive the following result, which is proved in Appendix B.1 in [27]."
CONCLUSION AND DISCUSSION,0.550251256281407,"Lemma 4 (Lemma 2 in [27]). Consider a matrix P ∈Rn×n with a unique Nash equilibrium (p⋆, q⋆).
Consider a submatrix M of P with row index set IX and column index set IY . If SUPP(p⋆) ⊆IX
and SUPP(q⋆) ⊆IY , then (ˆp, ˆq) is the unique Nash equilibrium of M where (ˆp)i = (p⋆)i for all
i ∈IX and (ˆq)j = (q⋆)j for all j ∈IY . Moreover, V ⋆
M = V ⋆
P ."
CONCLUSION AND DISCUSSION,0.5527638190954773,"C
Analytic Tools from Probability Theory and Analysis of Randomised
Algorithms"
CONCLUSION AND DISCUSSION,0.5552763819095478,"C.1
Yao’s Principle"
CONCLUSION AND DISCUSSION,0.5577889447236181,"In this section, we provide the mathematical tool that we use in the rest of the analysis. Yao’s Principle
[47] can be used to give lower bounds of a class of randomised algorithms.
Theorem C.1 (Yao’s Principle [47]). Let Π be a problem with a finite set I of input instances (of a
fixed size) permitting a finite set A of deterministic algorithms. Let p be a probability distribution
over I and q be a probability distribution over A. Then,"
CONCLUSION AND DISCUSSION,0.5603015075376885,"min
A∈A E(T(Ip, A)) ≤max
I∈I E(T(I, Aq))"
CONCLUSION AND DISCUSSION,0.5628140703517588,"where Ip denotes a random input chosen from I according to p, Aq a random algorithm chosen from
A according to q and T(I, A) denote the runtime of algorithm A on input I."
CONCLUSION AND DISCUSSION,0.5653266331658291,"C.2
Markov’s inequality and Chernoff’s bound"
CONCLUSION AND DISCUSSION,0.5678391959798995,"Theorem C.2 (Markov’s inequality). Given a non-negative random variable X and a > 0,
Pr (X ≥a) ≤E(X) a
."
CONCLUSION AND DISCUSSION,0.5703517587939698,"Theorem C.3 (Chernoff’s bound). Given X := Pn
i=1 Xi where Xi ∼Ber(pi) where Ber(pi) is
a Bernoulli random variable with probability pi and all Xi are independent. Let µ := E(X) =
Pn
i=1 pi. Then, for δ ∈(0, 1),"
CONCLUSION AND DISCUSSION,0.5728643216080402,Pr (|X −µ| ≥δµ) ≤2e−µδ2/3.
CONCLUSION AND DISCUSSION,0.5753768844221105,"D
Omitted Proofs"
CONCLUSION AND DISCUSSION,0.5778894472361809,"Corollary 2. Let |X| = |Y| and F ⊆{g : X × Y →R} be any set of two-player zero-sum
games with a unique NE. Assume furthermore that F is c.u.p.. Then, for any game g ∈F, let
(x∗, y∗) ∈X × Y denote the unique Nash Equilibrium of g. For any permutations over X, Y denoted
by σ ∈S(X), τ ∈S(Y), (σ ⊗τ) ◦g ∈F exhibits the same unique Nash Equilibrium (x∗, y∗).
Moreover, if for any x0 ̸= x∗and y0 ̸= y∗, the restriction of g on (X \ {x0}) × (Y \ {y0}), denoted
by g|(X\{x0})×(Y\{y0}), exhibits the same unique Nash Equilibrium (x∗, y∗)."
CONCLUSION AND DISCUSSION,0.5804020100502513,"Proof of Lemma 1. We employ the result in [27] (See Lemma 4). For any permutations on X, Y
denoted by σ ∈S(X), τ ∈S(Y), (σ ⊗τ) ◦g ∈F is defined as for any x ∈X, y ∈Y,"
CONCLUSION AND DISCUSSION,0.5829145728643216,"(σ ⊗τ) ◦g(x, y) = g (σ(x), τ(y)) ."
CONCLUSION AND DISCUSSION,0.585427135678392,"We consider the payoff matrix defined by P = (pi,j) where pi,j = g(xi, yj) with xi ∈X, yj ∈Y.
We denote row index set by IX ⊆N and column index set by IY ⊆N. Notice that |IX | = |X| =
|Y| = |IY|. We denote the row index by i ∈IX and the column index by j ∈IY. P ∈R|IX |×|IY|
is the payoff matrix of two-player zero-sum game g with a unique Nash Equilibrium (x∗, y∗). Let
us denote the row index of x∗in the payoff matrix P by i∗and the column index of y∗by j∗in the
payoff matrix P. So (ei∗, ej∗) ∈∆n × ∆n is the unique Nash Equilibrium in the form of probability
vector."
CONCLUSION AND DISCUSSION,0.5879396984924623,"Now, given any permutation σ, τ, we consider a submatrix P ′ such that P ′ = (pσ(i),τ(j)) with a new
row index set I′
X ⊆N and column index set I′
Y ⊆N. Since σ only shuffles around the row indices in
IX , I′
X ≃IX with the isomorphism σ. Similarly, we have I′
Y ≃IY with the isomorphism τ. Now,
we can see that i∗= SUPP(ei∗) ∈I′
X and j∗= SUPP(ej∗) ∈I′
Y, so (ˆp, ˆq) ∈∆n × ∆n is the unique
Nash Equilibrium of P ′ (in the form of a probability vector) where (ˆp)i = (ei∗)i for all i ∈I′
X and
(ˆq)j = (ej∗)j for all j ∈I′
Y. In other words, (ˆp, ˆq) = (ei∗, ej∗). So by using Lemma 4, we can
conclude that (x∗, y∗) ∈X × Y is the unique Nash Equilibrium of (σ ⊗τ) ◦g."
CONCLUSION AND DISCUSSION,0.5904522613065326,"For the second claim, we construct a submatrix Q such that Q = (qi,j) where qi,j = g(xi, yj) with
xi ∈X \{x0}, yj ∈Y \{y0}. We denote the row index set IX\{x0} and the column index set IY\{y0}.
Since x0 ̸= x∗and y0 ̸= y∗, i∗= SUPP(ei∗) ∈IX\{x0} and j∗= SUPP(ej∗) ∈IY\{y0}, by using"
CONCLUSION AND DISCUSSION,0.592964824120603,"Lemma 4 again, we can conclude that (x∗, y∗) is the unique Nash Equilibrium of g|(X\{x0})×(Y\{y0}).
We complete the proof."
CONCLUSION AND DISCUSSION,0.5954773869346733,"Lemma 1. If F is c.u.p., then F ((x1, y1), (b1, b2)) is also c.u.p.."
CONCLUSION AND DISCUSSION,0.5979899497487438,"Proof of Lemma 1. For any σ′ ∈S(X \{x1}), τ ′ ∈S(Y \{y1}) and any g′ ∈F ((x1, y1), (b1, b2)),
we want to show (σ′τ ′)g′ ∈F ((x1, y1), (b1, b2)). We consider the extensions of each permutation.
We define σ : X →X by its restriction on X \ {x1} as"
CONCLUSION AND DISCUSSION,0.6005025125628141,σ|X\{x1} = σ′ and σ(x1) = x1.
CONCLUSION AND DISCUSSION,0.6030150753768844,We define τ : Y →Y by its restriction on Y \ {y1} is
CONCLUSION AND DISCUSSION,0.6055276381909548,τ|X\{y1} = τ ′ and τ(y1) = y1.
CONCLUSION AND DISCUSSION,0.6080402010050251,"Now, let g be the extension of g′ which satisfies (1), (2) and (3) of Definition 3 (such an extension
g exists since we take g′ ∈F ((x1, y1), (b1, b2)) and it follows from the definition of sub-problem
class). As g ∈F, so are (στ)g ∈F. Thus, we construct (στ)g as an extension of (σ′τ ′)g′ and
(στ)g satisfies (1), (2) and (3) of Definition 3. So (σ′τ ′)g′ ∈F ((x1, y1), (b1, b2))."
CONCLUSION AND DISCUSSION,0.6105527638190955,"Lemma 2. For all (x1, y1), (x2, y2) ∈X × Y and b1 : Y →R, b2 : X →R, we have the
isomorphism6:"
CONCLUSION AND DISCUSSION,0.6130653266331658,"F ((x1, y1), (b1, b2)) ≃F ((x2, y2), (b1, b2)) ."
CONCLUSION AND DISCUSSION,0.6155778894472361,"Proof of Lemma 2. To prove the isomorphism, we need to find a bijection between these two sets.
We consider the following map between sets with , defined by:"
CONCLUSION AND DISCUSSION,0.6180904522613065,"ϕ : F ((x1, y1), (b1, b2)) →F ((x2, y2), (b1, b2)) where ϕ(g′) = h′ such that"
CONCLUSION AND DISCUSSION,0.6206030150753769,"for (x, y) ∈(X \ {x1, x2}) × (Y \ {y1, y2}),"
CONCLUSION AND DISCUSSION,0.6231155778894473,"h′(x, y) = ϕ(g′)(x, y) = g′(x, y)."
CONCLUSION AND DISCUSSION,0.6256281407035176,"For y ∈Y \ {y2}, h′(x1, y) = ϕ(g′)(x2, y) = g′(x2, y).
For x ∈Y \ {x2}, h′(x, y1) = ϕ(g′)(x, y2) = g′(x, y2) Let h be the extension of h′ defined by"
CONCLUSION AND DISCUSSION,0.628140703517588,"h(x2, y) = b1(y), h(x, y2) = b2(x)"
CONCLUSION AND DISCUSSION,0.6306532663316583,"For all (x, y) ∈(X \ {x2}) × (Y \ {y2}),"
CONCLUSION AND DISCUSSION,0.6331658291457286,"h(x, y) = h′(x, y)"
CONCLUSION AND DISCUSSION,0.635678391959799,"Now, we notice that h = (πxπy)g where πx, πy are two transpositions in S(X), S(Y) defined by"
CONCLUSION AND DISCUSSION,0.6381909547738693,"πx(x1) = x2, πx(x2) = x1
πy(y1) = y2, πy(y2) = y1"
CONCLUSION AND DISCUSSION,0.6407035175879398,"and for all x′ ∈X \ {x1, x2} and for all y′ ∈Y \ {y1, y2},"
CONCLUSION AND DISCUSSION,0.6432160804020101,"πx(x′) = x′, πy(y′) = y′"
CONCLUSION AND DISCUSSION,0.6457286432160804,"Since g ∈F, so is h = (πxπy)g ∈F. So h′ has the extension h satisfies (1), (2) in Definition 3.
Also, h′ = ϕ(g′) is uniquely determined by g′ and the argument would also hold when swapping
h′, g′ with the map ϕ−1. So we prove there exists an isomorphism between these two sub-problem
classes."
CONCLUSION AND DISCUSSION,0.6482412060301508,"Theorem 3.1. Given F as a subset of all the payoff functions g : X × Y →O with a unique Nash
Equilibrium where O ⊆R and |X| = |Y|. Let H be an arbitrary (randomised or deterministic)
black-box adversarial optimisation algorithm for any g ∈F where F is closed under permutations.
Let r(H, F) be the average (under the uniform distribution on F) of the expected query complexity
of H on g ∈F (i.e. E(TLB(H, g))). Then r(H, F) = r(H′, F) for all algorithms H, H′."
CONCLUSION AND DISCUSSION,0.6507537688442211,"6Here we define isomorphism following [11] rather than defining it as a usual group or ring isomorphism
since we do not require any group or ring structure of F in the proof."
CONCLUSION AND DISCUSSION,0.6532663316582915,"Proof of Theorem 3.1. Recall that the query complexity of H on g is TLB(H, g) := inf{t > 0 | xt =
x∗or yt = y∗} where (xt, yt) is the search point by Algorithm H on payoff function g and (x∗, y∗)
is the unique Nash Equilibrium in a two-player zero-sum game defined by g : X × Y →O. We
denote the set of all functions from a set X to a set O by H(X, O) and the set of all well-defined
functions from a set Y to a set O by H(Y, O)."
CONCLUSION AND DISCUSSION,0.6557788944723618,"Let F be a class of games with all the payoff functions g : X × Y →O with a unique NE, and
assume that F is closed under permutation. For all (x0, y0) ∈X × Y, define"
CONCLUSION AND DISCUSSION,0.6582914572864321,"B(1)
x0 : = {b1 ∈H(Y, O) | there exists g ∈F s.t. b1(y) = g(x0, y) for all y ∈Y};"
CONCLUSION AND DISCUSSION,0.6608040201005025,"B(2)
y0 : = {b2 ∈H(X, O) | there exists g ∈F s.t. b2(x) = g(x, y0) for all x ∈X}."
CONCLUSION AND DISCUSSION,0.6633165829145728,"Let (u, v) ∈X × Y be the first query point that Algorithm 1 makes, we consider b1 ∈B(1)
u
and
b2 ∈B(2)
v ."
CONCLUSION AND DISCUSSION,0.6658291457286433,"We first prove the claim holds for deterministic heuristics by induction. This is done by induction on
the size of search space N = |X|. Suppose for any two deterministic algorithms A, B on F."
CONCLUSION AND DISCUSSION,0.6683417085427136,"If N = 1, then it means that X × Y only consists of one unique NE and F consists of one payoff
function g. So for any two deterministic algorithms A, B, r(A, F) = r(B, F) = 1."
CONCLUSION AND DISCUSSION,0.6708542713567839,"Next, assume N ≥2 and r(A, G) = r(B, G) where G is any set of payoff functions with unique NE
and search space in payoff functions of size N −1 and G is closed under permutation. Moreover, we
assume F now consists of payoff functions with unique NE and search space in payoff functions of
size N. We expand out the average of r(A, F)."
CONCLUSION AND DISCUSSION,0.6733668341708543,"r(A, F) =
X"
CONCLUSION AND DISCUSSION,0.6758793969849246,"g∈F
Pr(g is selected from F) · T(A, g)"
CONCLUSION AND DISCUSSION,0.678391959798995,"If we are lucky, then the first point (u, v) ∈X × Y we query is the optimum (opt.) and (x∗, y∗) is
the NE of the selected g."
CONCLUSION AND DISCUSSION,0.6809045226130653,"= 1 · Pr ((u, v) is the opt. s.t. u = x∗or v = y∗)
+ Pr ((u, v) is not the opt. s.t. u = x∗or v = y∗)
× (1 + r (A, F (u, v), (b1, b2))))"
CONCLUSION AND DISCUSSION,0.6834170854271356,"Notice that after we query (u, v), we can reduce the whole problem class F to F((u, v), (b1, b2))
with case N −1 where b1, b2 are defined above."
CONCLUSION AND DISCUSSION,0.6859296482412061,"Lemma 1 shows that if F is closed under permutation, then F((u, v), (b1, b2)) is closed under
permutation. Corollary 1 shows that if we restrict g ∈F((u, v), (b1, b2)), then all the restriction of g
on (X \{u})×(Y \{v}), denoted by g|(X\{u})×(Y\{v}), exhibits the same unique Nash Equilibrium
(x∗, y∗) as g. So F((u, v), (b1, b2)) is a set of payoff functions with unique NE (x∗, y∗) and the
search space of size N −1 and closed under permutation for all (u, v) in which (u, v) is not the opt.
s.t. u = x∗or v = y∗."
CONCLUSION AND DISCUSSION,0.6884422110552764,"With the help of Corollary 1 and Lemma 1, we apply the inductive hypothesis to this sub-problem
class F((u, v), (b1, b2)) 7. Also note that we consider the uniform distribution on problem class F
and thus for any (u′, v′) ̸= (u, v), we have"
CONCLUSION AND DISCUSSION,0.6909547738693468,"Pr ((u, v) is the opt. s.t. u = x∗or v = y∗) = Pr ((u′, v′) is the opt. s.t. u = x∗or v = y∗) ."
CONCLUSION AND DISCUSSION,0.6934673366834171,"Using the inductive hypothesis on the case N −1 with Lemma 2 gives since two sub-problem classes
are essentially isomorphic and thus have the same average query complexity from the inductive
hypothesis step."
CONCLUSION AND DISCUSSION,0.6959798994974874,"r (A, F((u, v), (b1, b2))) = r (B, F((u′, v′), (b1, b2))) ."
CONCLUSION AND DISCUSSION,0.6984924623115578,"Thus, we can conclude that r(A, F) = r(B, F) for any deterministic algorithms A, B."
CONCLUSION AND DISCUSSION,0.7010050251256281,"7We defer further explanations of the role of Corollary 1 and Lemma 1 to the supplementary material Section
D."
CONCLUSION AND DISCUSSION,0.7035175879396985,"Now, we generalise the result to randomised algorithms. Let m denote the number of different
deterministic search heuristics. We consider a randomised search strategy to be a probability distri-
bution p = (p1, · · · , pm) and choose the i-th deterministic search strategy with probability pi. It is
well-known (see detail in [29]) that the expected cost of a randomised search heuristic is the weighted
average of the cost of the deterministic search heuristics. Since all deterministic search heuristics
have the same cost, this should also hold for all randomised search strategies."
CONCLUSION AND DISCUSSION,0.7060301507537688,"Theorem 4.1. Let X and Y be any finite sets. Assume that B ⊂R with k := |B| ≥2. Consider any
class of two-player zero-sum games G ⊂{g : X × Y →B} such that for all (x, y) ∈X × Y, there
exists a game gx,y ∈G which has (x, y) as unique, pure Nash Equilibrium. Then, the class G has
black box complexity at least ⌈logk |X × Y|⌉−1."
CONCLUSION AND DISCUSSION,0.7085427135678392,"Proof of Theorem 4.1. The proof which uses Yao’s minimax principle is analogous to the proof of
Theorem 2 in [13]. We need to construct a suitable probability distribution p over the set of games. By
assumption, for each (x, y) ∈X × Y, we can associate one game gx,y which has (x, y) as the unique
pure NE. We let p be the uniform distribution over the set of the games {gx,y | (x, y) ∈X ×Y} ⊆G."
CONCLUSION AND DISCUSSION,0.7110552763819096,"We now consider the runtime of any deterministic black-box algorithm A ∈Adet with respect to
a random game gx∗,y∗which is sampled according to distribution p. The algorithm is a decision
tree, where each node is a pair (x, y) ∈X × Y corresponding to a query made by algorithm A, and
each edge corresponds to one of at most k possible outcomes g(x, y) of this query. The runtime of
algorithm A on the random game gx∗,y∗corresponds to the depth of (x∗, y∗) in this decision tree.
The expected depth is therefore lower bounded by ⌈logk(|X × Y|)⌉−1."
CONCLUSION AND DISCUSSION,0.7135678391959799,"Hence, we have for all deterministic algorithms A ∈Adet,"
CONCLUSION AND DISCUSSION,0.7160804020100503,"E(T(Ip, A)) ≥logk(|X × Y|) −1."
CONCLUSION AND DISCUSSION,0.7185929648241206,This implies that
CONCLUSION AND DISCUSSION,0.7211055276381909,"min
A∈Adet E(T(Ip, A)) ≥logk(|X × Y|) −1."
CONCLUSION AND DISCUSSION,0.7236180904522613,"By Yao’s Principle, for any distribution q over the set of deterministic algorithms Adet,"
CONCLUSION AND DISCUSSION,0.7261306532663316,"max
I∈I E(T(I, Aq)) ≥
min
A∈Adet E(T(Ip, A))"
CONCLUSION AND DISCUSSION,0.7286432160804021,≥logk(|X × Y|) −1.
CONCLUSION AND DISCUSSION,0.7311557788944724,"The proof now follows by noting that any randomised algorithm can be described as sampling a
deterministic algorithm according some distribution q, and applying this algorithm."
CONCLUSION AND DISCUSSION,0.7336683417085427,"Theorem 4.2. Let A be the set of all randomised algorithms defined by Algorithm 1 and T(A, P)8
denote the query complexity of A with respect to the input payoff matrix P for a two-player zero-sum
game. Then, there exists an input matrix P ∈Rn×n with a unique pure Nash equilibrium (x∗, y∗)
such that E(T(A, P)) ≥(n + 1)/2. Thus, the black-box complexity with respect to A of the problem
class consisting of all bimatrix games with a unique Nash Equilibrium is at least (n + 1)/2."
CONCLUSION AND DISCUSSION,0.7361809045226131,"Proof of Theorem 4.2. Given payoff matrix P, recall that for any A ∈A,"
CONCLUSION AND DISCUSSION,0.7386934673366834,"TLB(A, P) : = inf{Ct > 0 | xt = x∗or yt = y∗};
T(A, P) : = inf{Ct > 0 | xt = x∗and yt = y∗};"
CONCLUSION AND DISCUSSION,0.7412060301507538,M : = {P ∈Rn×n with a unique PSNE}.
CONCLUSION AND DISCUSSION,0.7437185929648241,"Clearly, T(A, P) ≥TLB(A, P). We denote M as the set of input instances. Now, we estimate
the lower bound by using Yao’s minimax principle (we denote the query complexity of a specified
algorithm namely ALG searching the PSNE of P by T(ALG, P) and the set of all deterministic
black-box adversarial optimisation algorithms by Adet): for any randomised algorithm A ∈A,"
CONCLUSION AND DISCUSSION,0.7462311557788944,"max
P ∈M E(T(A, P)) ≥
min
ALG∈Adet
E
P ∼Unif(M) (T(ALG, P))"
CONCLUSION AND DISCUSSION,0.7487437185929648,"8Note that T(A, P) = T(A, g) where g(x, y) := eT
y Pex with ex, ey denote the elementary probability
distribution over probability simplex ∆{0,1}n"
CONCLUSION AND DISCUSSION,0.7512562814070352,"Using the definition of T(ALG, P) and TLB(ALG, P) gives
≥
min
ALG∈Adet
E
P ∼Unif(M) (TLB(ALG, P))"
CONCLUSION AND DISCUSSION,0.7537688442211056,"Using Theorem 3.1, we know the expected performance of all algorithms on any all problem instance
in M is the same with respect to the unique Nash Equilibrium solution concept. So, we define a
new algorithm ALG∗such that it is a deterministic algorithm starting from i = j = 1, and it makes
one query in each iteration. It continues to query P1,1, P2,2, · · · Pn,n (i.e. query the entries in the
diagonal of the payoff matrix P). ALG∗continues the processes until it reaches either the column or
the row of the position of the unique Nash Equilibrium. So, we derive
=
E
P ∼Unif(M) (TLB(ALG∗, P))"
CONCLUSION AND DISCUSSION,0.7562814070351759,"Note that we consider the uniform distribution on M. It means that the probability that (x∗, y∗)
lies in the j-th column of payoff matrix P is 1/n for all j ∈[n]. Then, the total expected query
complexity is Pn
j=1 j 1"
CONCLUSION AND DISCUSSION,0.7587939698492462,n = n+1
CONCLUSION AND DISCUSSION,0.7613065326633166,"2 . So, we derive"
CONCLUSION AND DISCUSSION,0.7638190954773869,"≥n + 1 2
."
CONCLUSION AND DISCUSSION,0.7663316582914573,This completes the proof.
CONCLUSION AND DISCUSSION,0.7688442211055276,"Theorem 4.3. The black-box complexity with respect to Algorithm 1 of the binary voting games with
problem size n ∈N and a unique Nash Equilibrium is eΩ(n)."
CONCLUSION AND DISCUSSION,0.7713567839195979,"Proof of Theorem 4.3. Given an arbitrary binary voting game with problem size n defined by a payoff
function g : {0, 1}n × {0, 1}n →R, we consider the corresponding payoff matrix P. For each party,
there are 2n possible strategies encoded by a binary bitstring of length n. So P ∈R2n×2n. Using
Theorem 4.2 with arbitrary algorithms in the class defined by Algorithm 1 and the payoff matrix P
gives us the black-box complexity is at least 2n+1"
CONCLUSION AND DISCUSSION,0.7738693467336684,"2
= eΩ(n)."
CONCLUSION AND DISCUSSION,0.7763819095477387,"Theorem 4.4. Given the game class
DIAGONALn := {DIAGONAL(u,v) | (u, v) ∈{0, 1}n × {0, 1}n},"
CONCLUSION AND DISCUSSION,0.7788944723618091,the black-box complexity with respect to Algorithm 1 of DIAGONALn is Θ(n).
CONCLUSION AND DISCUSSION,0.7814070351758794,"Proof of Theorem 4.4. We consider an algorithm A ∈A, which operates in two phases. In each itera-
tion of Phase 1, the algorithm samples x and y uniformly at random, then flips one bit uniformly at ran-
dom in x to obtain x′. It then compares the values of DIAGONALu,v(x, y) and DIAGONALu,v(x′, y).
Phase 1 ends when DIAGONALu,v(x, y) ̸= DIAGONALu,v(x′, y). Once Phase 1 ends, the algorithm
knows that |u ⊕x|1 = |v ⊕y|1."
CONCLUSION AND DISCUSSION,0.7839195979899497,"In Phase 2, Algorithm A sample a bitstring y′ by flipping a single bit in y. If DIAGONALu,v(x, y′) =
−1, we set y = y′, otherwise we repeatedly sampling a new y′. Once we get payoff −1, we accept
the new search point and then sample x′ by flipping a single bit in x until repeat the process until we
get payoff 1. This procedure continues until the termination criterion is met."
CONCLUSION AND DISCUSSION,0.7864321608040201,"We now consider how long it takes for Phase 1 to finish (i.e. the search point arrives at the diagonal).
Since we are using uniformly at random initialisation, so Z1 := |u ⊕x|1 and Z2 := |v ⊕x|1 are
subject to two independent binomial random variables Bin(n, 1/2). We first estimate Pr(Z1 = Z2).
Notice that let Y := n −Z2 and Y is also subject to Bin(n, 1 −1/2) = Bin(n, 1/2). So the event
{Z1 = Z2} is equivalent to {Z1 = Y } = {Z1 + Z2 = n}. Thus, we can derive the following
estimate by using Stirling’s approximation (i.e. n! ∼
√"
CONCLUSION AND DISCUSSION,0.7889447236180904,2πn( n
CONCLUSION AND DISCUSSION,0.7914572864321608,"e )n),"
CONCLUSION AND DISCUSSION,0.7939698492462312,"Pr(Z1 = Z2) =
2n
n"
CONCLUSION AND DISCUSSION,0.7964824120603015,"
2−2n ∼
1
√πn22n · 2−2n =
1
√πn."
CONCLUSION AND DISCUSSION,0.7989949748743719,So the expected runtime for finishing Phase 1 is O(√n).
CONCLUSION AND DISCUSSION,0.8015075376884422,"Now, we consider how long it takes for Phase 2 to reach the optimum. Notice that for each bit, we
need 1 query of the payoff function to determine whether it is the correct bit to flip. We need to
flip the correct bits for both x and y. Since the maximum Hamming distance to the optimum of
DIAGONAL is bounded by 2n, then the overall runtime is bounded above by 2n = O(n). Adding the
expected runtime for both Phases gives O(n) + O(√n) = O(n). Together with Theorem 4.1, we
can conclude that the black-box complexity of DIAGONALn is Θ(n)."
CONCLUSION AND DISCUSSION,0.8040201005025126,"Theorem 4.5. Given the game class,"
CONCLUSION AND DISCUSSION,0.8065326633165829,"PLATEAUn := {PLATEAU(u,v) | (u, v) ∈{0, 1}n × {0, 1}n},"
CONCLUSION AND DISCUSSION,0.8090452261306532,"the black-box complexity with respect to the class of algorithms defined by Algorithm 1 of PLATEAUn
is eΩ(n)."
CONCLUSION AND DISCUSSION,0.8115577889447236,"Proof of Theorem 4.5. Recall the definition of PLATEAUu,v for arbitrary u, v. We call the set {(x, y) |
||u ⊕x|1 −n"
CONCLUSION AND DISCUSSION,0.8140703517587939,2 | ≤εn
CONCLUSION AND DISCUSSION,0.8165829145728644,"2 } x-independent, and we call any query to this set x-independent. Note that
for any x-independent query has payoff PLATEAUu,v(x, y) = f(v ⊕y), i.e., it is independent of x.
Furthermore, note that the Nash Equilibrium is not x-independent."
CONCLUSION AND DISCUSSION,0.8190954773869347,"We will apply Yao’s Principle with respect to the distribution p over instances where u is sampled
uniformly at random among all bitstrings of length n, and v = 0n. We consider the average case
runtime of deterministic algorithms with respect to distribution p. Such algorithms can be modelled
as binary decision trees: in each node, the algorithm makes a query (x, y), and for each outgoing
edge, the algorithm obtains one of two possible payoff values PLATEAUu,v(x, y) ∈{−1, 1}. We call
the x-independent path in the decision tree the longest path (x1, y1), . . . , (xt, yt) such that (x1, y1)
is the root node and all nodes (xi, yi) for i ∈[t] are x-independent. We let t denote the length of the
x-independent path. Since the outcome of an x-independent query only depends on v ⊕y which is
deterministic, the x-independent path of a decision tree is unique. Furthermore, the length of the
x-independent path is a lower bound on the runtime of the algorithm since the Nash Equilibrium is
not x-independent."
CONCLUSION AND DISCUSSION,0.821608040201005,"We now lower bound the length of the x-independent path. Let (xi, yi) be any fixed query in the
decision tree, and Fi the event that (xi, yi) is x-independent. We sample u by picking each bit
independently and uniformly at random in {0, 1}. This implies that the number of 1 bits for each
bit is subject to a Bernoulli random variable Bin(1/2). We therefore have |u ⊕xi|1 is binomially
distributed Bin(n, 1/2). Applying Chernoff’s bound, we get"
CONCLUSION AND DISCUSSION,0.8241206030150754,"Pr (Fi) = Pr

||u ⊕xi|1 −n"
CONCLUSION AND DISCUSSION,0.8266331658291457,2 | > εn 2
CONCLUSION AND DISCUSSION,0.8291457286432161,"
≤2e−ε2n/6.
(1)"
CONCLUSION AND DISCUSSION,0.8316582914572864,"Let E1 be the complement of all the failure events, i.e., E1 = ∪t
i=1Fi. Therefore, by a union bound,
the x-independent path has length t = 2eε2n/12 with probability"
CONCLUSION AND DISCUSSION,0.8341708542713567,"Pr(E1) = 1 −Pr
 
∪t
i=1Fi

≥1 −t2e−ε2n/6 = 1 −e−Ω(n)."
CONCLUSION AND DISCUSSION,0.8366834170854272,We then have by the law of total probability
CONCLUSION AND DISCUSSION,0.8391959798994975,"min
A∈A E(T(Ip, A)) ≥min
A∈A Pr (E1) E(T(Ip, A) | E1)"
CONCLUSION AND DISCUSSION,0.8417085427135679,≥(1 −e−Ω(n))2eε2n/12
CONCLUSION AND DISCUSSION,0.8442211055276382,= eΩ(n).
CONCLUSION AND DISCUSSION,0.8467336683417085,"The proof now follows by Yao’s minimax Principle. The expected worst-case runtime of any
randomised algorithm is lower bounded by the average case runtime of deterministic algorithms."
CONCLUSION AND DISCUSSION,0.8492462311557789,"max
I∈I E(T(I, Aq)) ≥min
A∈A E(T(Ip, A)) = eΩ(n)."
CONCLUSION AND DISCUSSION,0.8517587939698492,"E
Further Explanations for Sub-Problem Class"
CONCLUSION AND DISCUSSION,0.8542713567839196,We provide an example to illustrate the concept of the sub-problem class (see Definition 3).
CONCLUSION AND DISCUSSION,0.8567839195979899,"Figure 2 is an example of a sub-problem class. When querying (x1, y1), we also check the corre-
sponding row and column to verify whether the unique Nash Equilibrium lies on this blue cross or
not. If the answer is negative, then we restrict to the sub-matrix by removing the blue entries in P. x1"
CONCLUSION AND DISCUSSION,0.8592964824120602,"y*
x*
?"
CONCLUSION AND DISCUSSION,0.8618090452261307,"y1
P ="
CONCLUSION AND DISCUSSION,0.864321608040201,"Figure 2: Example of a sub-problem class. Given a payoff matrix P, the blue entries mean that the
actual values are already assigned to g(x1, ·) and g(·, y1). (x∗, y∗) is the Nash Equilibrium we search
for. The sub-problem class here means that the problem consists of different payoff matrices with
given blue entries."
CONCLUSION AND DISCUSSION,0.8668341708542714,"F
Further Explanations for the role of Corollary 1 and Lemma 1 in
Theorem 3.1"
CONCLUSION AND DISCUSSION,0.8693467336683417,"In the main proof of Theorem 3.1, we rely on proof by induction: assume the theorem holds for a
search space of size N, we want to show it also holds for N +1. Corollary 1 and Lemma 1 are crucial
since they ensure that for every payoff function g ∈F, there is a corresponding function g′ where
the NE (x∗, y∗) is switched to (σ(x∗), τ(y∗)) (i.e. σ, τ are two permutations on X, Y respectively)
and the NE is still unique in the game defined by g′. This means that the inductive hypothesis can be
applied to g′ due to the closure under permutation. In short, Corollary 1 and Lemma 1 establish a
property of the problems or payoff functions under consideration that is preserved under permutations.
This property helps to ensure that the induction step can be applied successfully."
CONCLUSION AND DISCUSSION,0.871859296482412,"G
Further Explanations for bitwise exclusive or in Black-Box Complexity
Analysis"
CONCLUSION AND DISCUSSION,0.8743718592964824,"We define ⊕as bitwise exclusive or. ⊕means that for any two binary bitstrings x = x1 · · · xn
and u = u1 · · · un, x ⊕u := (x1 ⊕u1, · · · , xn ⊕un) where 1 ⊕1 = 0, 1 ⊕0 = 1, 0 ⊕1 =
1, 1 ⊕1 = 0. We introduce bitwise exclusive or here to generate problem instances with the same
structure. For example, DIAGONAL(x, y) is only one possible problem instance in binary voting
games and to find its optimum, we only need to design the algorithm querying (1n, 1n) to reach
its optimum. And its black-box complexity is trivially Θ(1). Using bitwise exclusive or ⊕(i.e.
DIAGONAL(u ⊕x, v ⊕y) where (u, v) ∈U × V is sampled uniformly at random), we can generate a
set of problem instances which have the same structure as DIAGONAL(x, y) and the goal of black-box
algorithms is to find (x, y) such that (u ⊕x, v ⊕y) = (1n, 1n). (Note that if (u, v) = (0n, 0n),
then DIAGONAL(0n ⊕x, 0n ⊕y) is reduced to the vanilla DIAGONAL(x, y).) This bitwise exclusive
generator can avoid the trivial black-box complexity mentioned above and reflect the true difficulty
of the class DIAGONAL. We refer to [13, 9] for more detail about black-box complexity theory."
CONCLUSION AND DISCUSSION,0.8768844221105527,NeurIPS Paper Checklist
CLAIMS,0.8793969849246231,1. Claims
CLAIMS,0.8819095477386935,"Question: Do the main claims made in the abstract and introduction accurately reflect the paper’s
contributions and scope?"
CLAIMS,0.8844221105527639,Answer: [Yes]
CLAIMS,0.8869346733668342,"Justification: Our main claims made in the abstract and introduction accurately reflect the paper’s
contributions and scope. The detailed contribution can be checked in Section 1.2 in the main
paper. We also provide a content list as the roadmap of this paper at the beginning of the appendix."
CLAIMS,0.8894472361809045,Guidelines:
CLAIMS,0.8919597989949749,"• The answer NA means that the abstract and introduction do not include the claims made in
the paper.
• The abstract and/or introduction should clearly state the claims made, including the contribu-
tions made in the paper and important assumptions and limitations. A No or NA answer to
this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how much
the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals are
not attained by the paper."
LIMITATIONS,0.8944723618090452,2. Limitations
LIMITATIONS,0.8969849246231156,Question: Does the paper discuss the limitations of the work performed by the authors?
LIMITATIONS,0.8994974874371859,Answer: [Yes]
LIMITATIONS,0.9020100502512562,"Justification: The limitations of our results have been discussed in the conclusion (line 372-384).
Moreover, the bounds for the black-box complexity of binary voting games derived in this paper
mainly consider the asymptotic order, which is sufficient for benchmark dichotomy. There is
room to improve these bounds with respect to the leading coefficients."
LIMITATIONS,0.9045226130653267,Guidelines:
LIMITATIONS,0.907035175879397,"• The answer NA means that the paper has no limitation, while the answer No means that the
paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ""Limitations"" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings, model
well-specification, asymptotic approximations only holding locally). The authors should
reflect on how these assumptions might be violated in practice and what the implications
would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was only
tested on a few datasets or with a few runs. In general, empirical results often depend on
implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach. For
example, a facial recognition algorithm may perform poorly when image resolution is low
or images are taken in low lighting. Or a speech-to-text system might not be used reliably to
provide closed captions for online lectures because it fails to handle technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms and how
they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to address
problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best judgment
and recognize that individual actions in favor of transparency play an important role in
developing norms that preserve the integrity of the community. Reviewers will be specifically
instructed to not penalize honesty concerning limitations."
THEORY ASSUMPTIONS AND PROOFS,0.9095477386934674,3. Theory Assumptions and Proofs
THEORY ASSUMPTIONS AND PROOFS,0.9120603015075377,"Question: For each theoretical result, does the paper provide the full set of assumptions and a
complete (and correct) proof?"
THEORY ASSUMPTIONS AND PROOFS,0.914572864321608,Answer: [Yes]
THEORY ASSUMPTIONS AND PROOFS,0.9170854271356784,"Justification: All the theorems, formulas, and proofs in the paper are numbered and cross-
referenced, and all assumptions are clearly stated or referenced in the statement of all theorems.
Due to the page limit, we defer all the proofs in the supplementary material (see Section D). We
also provide a short proof sketch for our main result: Theorem 3.1."
THEORY ASSUMPTIONS AND PROOFS,0.9195979899497487,Guidelines:
THEORY ASSUMPTIONS AND PROOFS,0.9221105527638191,"• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if they
appear in the supplemental material, the authors are encouraged to provide a short proof
sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented by
formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced."
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9246231155778895,4. Experimental Result Reproducibility
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9271356783919598,"Question: Does the paper fully disclose all the information needed to reproduce the main
experimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9296482412060302,Answer: [NA]
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9321608040201005,"Justification: Our paper is purely a theory paper, and it does not include experiments."
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9346733668341709,Guidelines:
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9371859296482412,"• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived well by
the reviewers: Making the paper reproducible is important, regardless of whether the code
and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken to
make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways. For
example, if the contribution is a novel architecture, describing the architecture fully might
suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary
to either make it possible for others to replicate the model with the same dataset, or provide
access to the model. In general. releasing code and data is often one good way to accomplish
this, but reproducibility can also be provided via detailed instructions for how to replicate
the results, access to a hosted model (e.g., in the case of a large language model), releasing
of a model checkpoint, or other means that are appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submissions
to provide some reasonable avenue for reproducibility, which may depend on the nature of
the contribution. For example"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.9396984924623115,"(a)If the contribution is primarily a new algorithm, the paper should make it clear how to
reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe the
architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should either
be a way to access this model for reproducing the results or a way to reproduce the model
(e.g., with an open-source dataset or instructions for how to construct the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case authors are
welcome to describe the particular way they provide for reproducibility. In the case of
closed-source models, it may be that access to the model is limited in some way (e.g.,
to registered users), but it should be possible for other researchers to have some path to
reproducing or verifying the results."
OPEN ACCESS TO DATA AND CODE,0.9422110552763819,5. Open access to data and code
OPEN ACCESS TO DATA AND CODE,0.9447236180904522,"Question: Does the paper provide open access to the data and code, with sufficient instructions to
faithfully reproduce the main experimental results, as described in supplemental material?
Answer: [NA]
Justification: The paper does not include experiments requiring code.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9472361809045227,"• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/
guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not including
code, unless this is central to the contribution (e.g., for a new open-source benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how to
access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new proposed
method and baselines. If only a subset of experiments are reproducible, they should state
which ones are omitted from the script and why.
• At submission time, to preserve anonymity, the authors should release anonymized versions
(if applicable).
• Providing as much information as possible in supplemental material (appended to the paper)
is recommended, but including URLs to data and code is permitted.
6. Experimental Setting/Details"
OPEN ACCESS TO DATA AND CODE,0.949748743718593,"Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters,
how they were chosen, type of optimizer, etc.) necessary to understand the results?
Answer: [NA]
Justification: The paper does not include experiments.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9522613065326633,"• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail that
is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material.
7. Experiment Statistical Significance"
OPEN ACCESS TO DATA AND CODE,0.9547738693467337,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [NA]
Justification: The paper does not include experiments.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.957286432160804,"• The answer NA means that the paper does not include experiments.
• The authors should answer ""Yes"" if the results are accompanied by error bars, confidence
intervals, or statistical significance tests, at least for the experiments that support the main
claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall run
with given experimental conditions).
• The method for calculating the error bars should be explained (closed form formula, call to a
library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors)."
OPEN ACCESS TO DATA AND CODE,0.9597989949748744,"• It should be clear whether the error bar is the standard deviation or the standard error of the
mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should preferably
report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality
of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or figures
symmetric error bars that would yield results that are out of range (e.g. negative error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how they
were calculated and reference the corresponding figures or tables in the text.
8. Experiments Compute Resources"
OPEN ACCESS TO DATA AND CODE,0.9623115577889447,"Question: For each experiment, does the paper provide sufficient information on the computer
resources (type of compute workers, memory, time of execution) needed to reproduce the experi-
ments?
Answer: [NA]
Justification: The paper does not include experiments.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.964824120603015,"• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster, or
cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual experi-
mental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute than the
experiments reported in the paper (e.g., preliminary or failed experiments that didn’t make it
into the paper).
9. Code Of Ethics"
OPEN ACCESS TO DATA AND CODE,0.9673366834170855,"Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS
Code of Ethics https://neurips.cc/public/EthicsGuidelines?
Answer: [Yes]
Justification: This work strictly follows the NeurIPS Code of Ethics.
10. Broader Impacts"
OPEN ACCESS TO DATA AND CODE,0.9698492462311558,"Question: Does the paper discuss both potential positive societal impacts and negative societal
impacts of the work performed?
Answer: [Yes]
Justification: This paper studies NFL analysis and BBC analysis of black-box adversarial opti-
misation algorithms. From a theoretical viewpoint, our work rigorously outlines the theoretical
limitations of black-box adversarial optimisation algorithms for finding Nash Equilibrium and
characterises the general difficulty of different class problems to be solved via the given black-box
model. From a practical viewpoint, more careful benchmark selections are suggested for use
in many black-box optimisation applications which solve maximin problems with complicated
constraints, e.g. robust optimisation, neuroevolution, bimatrix games, two-player games etc. This
work is of a theoretical nature, and there is no foreseeable negative ethical or societal implication.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9723618090452262,"• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal impact
or why the paper does not address societal impact.
• Examples of negative societal impacts include potential malicious or unintended uses (e.g.,
disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deploy-
ment of technologies that could make decisions that unfairly impact specific groups), privacy
considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied to
particular applications, let alone deployments. However, if there is a direct path to any
negative applications, the authors should point it out. For example, it is legitimate to point"
OPEN ACCESS TO DATA AND CODE,0.9748743718592965,"out that an improvement in the quality of generative models could be used to generate
deepfakes for disinformation. On the other hand, it is not needed to point out that a generic
algorithm for optimizing neural networks could enable people to train models that generate
Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is being
used as intended and functioning correctly, harms that could arise when the technology is
being used as intended but gives incorrect results, and harms following from (intentional or
unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks, mecha-
nisms for monitoring misuse, mechanisms to monitor how a system learns from feedback
over time, improving the efficiency and accessibility of ML).
11. Safeguards"
OPEN ACCESS TO DATA AND CODE,0.9773869346733668,"Question: Does the paper describe safeguards that have been put in place for responsible release
of data or models that have a high risk for misuse (e.g., pretrained language models, image
generators, or scraped datasets)?
Answer: [NA]
Justification: The paper poses no such risks.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9798994974874372,"• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring that
users adhere to usage guidelines or restrictions to access the model or implementing safety
filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors should
describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do not
require this, but we encourage authors to take this into account and make a best faith effort.
12. Licenses for existing assets"
OPEN ACCESS TO DATA AND CODE,0.9824120603015075,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in the
paper, properly credited and are the license and terms of use explicitly mentioned and properly
respected?
Answer: [NA]
Justification: The paper does not use existing assets.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9849246231155779,"• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of service
of that source should be provided.
• If assets are released, the license, copyright information, and terms of use in the package
should be provided. For popular datasets, paperswithcode.com/datasets has curated
licenses for some datasets. Their licensing guide can help determine the license of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of the
derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to the
asset’s creators.
13. New Assets"
OPEN ACCESS TO DATA AND CODE,0.9874371859296482,"Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]"
OPEN ACCESS TO DATA AND CODE,0.9899497487437185,"Justification: The paper does not release new assets.
14. Crowdsourcing and Research with Human Subjects"
OPEN ACCESS TO DATA AND CODE,0.992462311557789,"Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as well as
details about compensation (if any)?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9949748743718593,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribution
of the paper involves human subjects, then as much detail as possible should be included in
the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or
other labor should be paid at least the minimum wage in the country of the data collector.
15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether such
risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals
(or an equivalent approval/review based on the requirements of your country or institution) were
obtained?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:"
OPEN ACCESS TO DATA AND CODE,0.9974874371859297,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Depending on the country in which research is conducted, IRB approval (or equivalent) may
be required for any human subjects research. If you obtained IRB approval, you should
clearly state this in the paper.
• We recognize that the procedures for this may vary significantly between institutions and
locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines
for their institution.
• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review."
