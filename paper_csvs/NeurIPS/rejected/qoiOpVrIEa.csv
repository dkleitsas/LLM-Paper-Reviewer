Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0019646365422396855,"Evaluating the success of a manifold learning method remains a challenging prob-
1"
ABSTRACT,0.003929273084479371,"lem, especially for methods adapted to a specific application domain. The present
2"
ABSTRACT,0.005893909626719057,"work investigates shared geometric structure across different dimensionality reduc-
3"
ABSTRACT,0.007858546168958742,"tion (DR) algorithms within the scope of neuroimaging applications. We examine
4"
ABSTRACT,0.009823182711198428,"reduced-dimension embeddings produced by a representative assay of dimension
5"
ABSTRACT,0.011787819253438114,"reductions for brain data (“brain representations”) through the lens of persistent
6"
ABSTRACT,0.0137524557956778,"homology, making statistical claims about topological differences using a recent
7"
ABSTRACT,0.015717092337917484,"topological boostrap method. We cluster these methods based on their induced
8"
ABSTRACT,0.01768172888015717,"topologies, finding feature type and number — rather than reduction algorithm —
9"
ABSTRACT,0.019646365422396856,"as the main drivers of observed topological differences.
10"
INTRODUCTION,0.021611001964636542,"1
Introduction
11"
INTRODUCTION,0.023575638506876228,"The present work investigates shared geometric structure across different dimensionality reduction
12"
INTRODUCTION,0.025540275049115914,"algorithms within the scope of neuroimaging applications. For most applications, a “dimensionality
13"
INTRODUCTION,0.0275049115913556,"reduction” is any of a large class of methods that make inferences about structures underlying some
14"
INTRODUCTION,0.029469548133595286,"data, typically to represent this data in both a more efficient and more interpretable way. Many
15"
INTRODUCTION,0.03143418467583497,"dimensionality reduction (DR) problems can be equivalently formulated as “manifold learning”
16"
INTRODUCTION,0.03339882121807466,"problems (i.e., estimating the manifold from which a dataset was sampled), and we will use the terms
17"
INTRODUCTION,0.03536345776031434,"synonymously. Efforts to understand theoretical and empirical relationships between DR methods
18"
INTRODUCTION,0.03732809430255403,"remain active1−10.
19"
INTRODUCTION,0.03929273084479371,"The difficulty of relating dimensionality reductions can be compounded within specific application
20"
INTRODUCTION,0.0412573673870334,"domains because methodologies often branch into variably specialized use cases. Nonetheless,
21"
INTRODUCTION,0.043222003929273084,"specific use cases can also suggest more stringent criteria by which to compare dimension reduction
22"
INTRODUCTION,0.04518664047151277,"outcomes. In functional neuroimaging, specialized dimension reduction algorithms proliferate the
23"
INTRODUCTION,0.047151277013752456,"field, bridging disparate use cases, design philosophies, and biological motivations11,12. These
24"
INTRODUCTION,0.04911591355599214,"DR algorithms share the goal of extracting networks of functional activity from resting-state fMRI
25"
INTRODUCTION,0.05108055009823183,"brain data, and we will refer to them throughout as “brain representations.” We compare brain
26"
INTRODUCTION,0.05304518664047151,"representations in terms of the topologies they induce on a single set of shared data (""subject space"")
27"
INTRODUCTION,0.0550098231827112,"and the statistical robustness of the differences between them. We measure these topological statistics
28"
INTRODUCTION,0.05697445972495088,"through persistent homology13 and the related topological bootstrap14,15.
29"
INTRODUCTION,0.05893909626719057,"Problem Statement: Brain Representations & Subject Space
30"
INTRODUCTION,0.060903732809430254,"Our primary goal is to compare the structural changes in a single neuroimaging dataset under a
31"
INTRODUCTION,0.06286836935166994,"variety of brain representations. Because the structure of subject space in the original (un-reduced)
32"
INTRODUCTION,0.06483300589390963,"data is unknown and impractical to compute, it is not feasible to grade brain representations’ quality
33"
INTRODUCTION,0.06679764243614932,"by structure preservation. Instead, we group brain representations based on the similarity of the
34"
INTRODUCTION,0.068762278978389,"subject-space structures they induce in reduced data.
35"
INTRODUCTION,0.07072691552062868,"We frame brain representation as a manifold learning problem, and we frame comparisons between
36"
INTRODUCTION,0.07269155206286837,"them as comparisons between estimated manifolds. We suppose our data lies on some manifold
37"
INTRODUCTION,0.07465618860510806,"S ,→RD (""subject space""), from which we extract a finite dataset bS of N samples. In this
38"
INTRODUCTION,0.07662082514734773,"work, S consists of resting-state fMRI scans, and bS is the Human Connectome Project (HCP)
39"
INTRODUCTION,0.07858546168958742,"Young Adult dataset; we then have D ∼108 and N ∼103. A brain representation is any
40"
INTRODUCTION,0.08055009823182711,"mapping bφi : bS →Rdi with di ≪D; for any brain representation, we define its corresponding
41"
INTRODUCTION,0.0825147347740668,"induced subject space bSi = bφi(bS). We compare brain representations bφi and bφj by comparing the
42"
INTRODUCTION,0.08447937131630648,"persistent homology of their induced subject spaces bSi and bSj. To link the persistent homology and
43"
INTRODUCTION,0.08644400785854617,"manifold learning investigations, we make a key modeling assumption: there exists a local extension
44"
INTRODUCTION,0.08840864440078586,"φi : S →Rdi of bφi that is a submersion in some neighborhood of bS ⊂S. This assumption requires
45"
INTRODUCTION,0.09037328094302555,"that dimensionality reductions behave consistently on unseen data near training data, and constitutes
46"
INTRODUCTION,0.09233791748526522,"only a mild smoothness assumption on bφi. Under this modeling assumption, we may assert the
47"
INTRODUCTION,0.09430255402750491,"existence of a manifold Si ,→Rdi containing bSi such that the following diagram commutes:
48"
INTRODUCTION,0.0962671905697446,"bS
bSi S
Si bφi φi"
INTRODUCTION,0.09823182711198428,"While the smoothness assumption on bφi is easily met by most DR algorithms, the connection between
49"
INTRODUCTION,0.10019646365422397,"the persistent homology of bSi and the manifold Si depends heavily on properties of the manifold
50"
INTRODUCTION,0.10216110019646366,"sampling bS.
51"
INTRODUCTION,0.10412573673870335,"To compare brain representations φi and φj, we compute dissimilarity metrics for all pairs of
52"
INTRODUCTION,0.10609037328094302,"points in bSi and bSj and examine the resulting Vietoris-Rips complex in each space. This approach
53"
INTRODUCTION,0.10805500982318271,"allows flexibility in the data and dissimilarities under consideration while still allowing claims about
54"
INTRODUCTION,0.1100196463654224,"DR-induced topological differences.
55"
INTRODUCTION,0.11198428290766209,"Related Work: Persistent Homology & Dimensionality Reduction
56"
INTRODUCTION,0.11394891944990176,"Most comparisons in the literature are primarily interested in grading the relative performance
57"
INTRODUCTION,0.11591355599214145,"of different DR algorithms. Though we do not share these goals, many comparative approaches
58"
INTRODUCTION,0.11787819253438114,"articulate frameworks and methods with important relationships to our own. We review a selection of
59"
INTRODUCTION,0.11984282907662082,"comparison methods, organized in roughly increasing order of the similarity between their goals and
60"
INTRODUCTION,0.12180746561886051,"framework to our own.
61"
INTRODUCTION,0.1237721021611002,"Some evaluation methods for dimensionality reduction lead with intuition, formalizing helpful
62"
INTRODUCTION,0.12573673870333987,"heuristics into rigorous ratings. We first reference Lee and Verleysen’s co-ranking matrix4, which
63"
INTRODUCTION,0.12770137524557956,"measures insertions to (“intrusion events”) and deletions from (“extrusion events”) k-neighborhoods
64"
INTRODUCTION,0.12966601178781925,"in the low-dimension vs. high-dimension space. While this measure is non-parametric (with respect to
65"
INTRODUCTION,0.13163064833005894,"the data geometry) and thus extremely flexible, it is sensitive only to local structure in the data. Later,
66"
INTRODUCTION,0.13359528487229863,"Lee and Verleysen showed that the performance of a DR method closely follows its (a) insensitivity
67"
INTRODUCTION,0.13555992141453832,"to norm concentration and (b) plasticity (i.e., the cost function gradient vanishing for distant points)7,
68"
INTRODUCTION,0.137524557956778,"leveraging a more geometric perspective to the analysis of DR performance than was typical of the
69"
INTRODUCTION,0.13948919449901767,"contemporary literature9. Extending this line of thinking, Wang et al1 recently offered a strictly
70"
INTRODUCTION,0.14145383104125736,"empirical investigation of different DR methods in which they consider only the attractive and
71"
INTRODUCTION,0.14341846758349705,"repulsive forces of the loss function over varying distance scales. They show that this framework is
72"
INTRODUCTION,0.14538310412573674,"sufficient to characterize DR performance and extrapolate robust empirical principles of “good DR
73"
INTRODUCTION,0.14734774066797643,"methods” without need of an underlying formalism. While this work offers striking practical insights,
74"
INTRODUCTION,0.14931237721021612,"it does not offer an immediate path to describing degrees of divergence between DR methods.
75"
INTRODUCTION,0.1512770137524558,"We now consider a class of methods we characterize by their tendency to originate in formal,
76"
INTRODUCTION,0.15324165029469547,"geometric considerations of manifold learning. Singer and Wu’s vector diffusion distance8, an
77"
INTRODUCTION,0.15520628683693516,"extension of diffusion embeddings17, uses local principal component analysis to locally estimate a
78"
INTRODUCTION,0.15717092337917485,"connection on the tangent bundle of a data manifold, from which it constructs a lower-dimensional
79"
INTRODUCTION,0.15913555992141454,"embedding. While the primary goal of their work is to define a manifold learning method, rather than
80"
INTRODUCTION,0.16110019646365423,"a technique for comparing such methods, their vector diffusion distance explicitly captures a variety
81"
INTRODUCTION,0.16306483300589392,"of geometric and topological data invariants. These invariants could be used analogously to our use
82"
INTRODUCTION,0.1650294695481336,"of persistent homology to compare dimensionality reductions of the same dataset. Similarly, Tyagi et
83"
INTRODUCTION,0.16699410609037327,"al5 propose a set of tangent space estimation criteria for manifold sampling (as a function of manifold
84"
INTRODUCTION,0.16895874263261296,"curvature and intrinsic dimension) that immediately suggest geometric routes of comparison between
85"
INTRODUCTION,0.17092337917485265,"learned data manifolds. Finally, in more direct alignment with our goals, Sun and Machard propose a
86"
INTRODUCTION,0.17288801571709234,"geometric theory of manifold learning, which comes equipped with an intrinsic metric18,19. Their
87"
INTRODUCTION,0.17485265225933203,"approach is firmly grounded in classical information geometry20,21, comparing learned models via
88"
INTRODUCTION,0.17681728880157171,"the pullback of the Fisher information metric on direct probabilistic encodings of reduced data. While
89"
INTRODUCTION,0.1787819253438114,"this perspective diverges substantially from our own, our constructions are mutually translatable, and
90"
INTRODUCTION,0.1807465618860511,"their approach could provide interesting comparison and/or validation.
91"
INTRODUCTION,0.18271119842829076,"To the best of our knowledge, only two other studies2,3 have examined dimensionality reduction
92"
INTRODUCTION,0.18467583497053044,"through the lens of persistent homology. Both works primarily consider the recovery quality of a
93"
INTRODUCTION,0.18664047151277013,"known manifold and propose quality metrics derived from persistent homology. Paul and Chalup2
94"
INTRODUCTION,0.18860510805500982,"compare DR methods while varying manifold complexity, measuring performance by the similarity
95"
INTRODUCTION,0.1905697445972495,"of pre- and post-DR Betti numbers as a function of sampling density. While their goals differ from
96"
INTRODUCTION,0.1925343811394892,"ours, much of our comparison also hinges on counts of topological features; however, they did not
97"
INTRODUCTION,0.1944990176817289,"have access to the topological bootstrap14,15 we employ in our study. Rieck and Leitte3 compute
98"
INTRODUCTION,0.19646365422396855,"the Wasserstein distance between pre- and post-DR persistence diagrams as a metric of embedding
99"
INTRODUCTION,0.19842829076620824,"quality. While their study is most similar to our own, there are several key differences. First, they
100"
INTRODUCTION,0.20039292730844793,"operationalize persistent homology with a sublevel-set filtration of the local density function, whereas
101"
INTRODUCTION,0.20235756385068762,"we use the Vietoris-Rips filtration on pairwise point dissimilarities. Second, they consider reduction
102"
INTRODUCTION,0.2043222003929273,"of a surface embedded in D = 3 reduced to d = 2, whereas we consider data initially embedded in
103"
INTRODUCTION,0.206286836935167,"D ∼108 and reduced to dimensionalities ranging from d ∼102 to d ∼105. Most importantly, we
104"
INTRODUCTION,0.2082514734774067,"are able to leverage the topological bootstrap14,15 in our work, which was not available at the time of
105"
INTRODUCTION,0.21021611001964635,"their publication.
106"
INTRODUCTION,0.21218074656188604,"Finally, we also contrast our analysis of persistence data with a prevalent paradigm in persistent
107"
INTRODUCTION,0.21414538310412573,"homology applications. Many persistent homology analyses6,22−27 (including those above) oper-
108"
INTRODUCTION,0.21611001964636542,"ationalize the assumption that most topological information lives in a diagram’s most persistent
109"
INTRODUCTION,0.2180746561886051,"components, treating low-persistence generators as noise. Instead, we follow work in distributed
110"
INTRODUCTION,0.2200392927308448,"persistence28,29 and examine the distributional properties of our persistence diagrams to parse their
111"
INTRODUCTION,0.2220039292730845,"topological content.
112"
INTRODUCTION,0.22396856581532418,"Our contributions in the present study are as follows: (1) A flexible framework for the statistical
113"
INTRODUCTION,0.22593320235756384,"comparison of dimensionality reductions, applicable to any data and dissimilarity measure compatible
114"
INTRODUCTION,0.22789783889980353,"with a Vietoris-Rips complex; (2) Robust statistical measurement of topological differences between
115"
INTRODUCTION,0.22986247544204322,"dimension-reduced data; (3) Application to real neuroscience data over a diverse slice of widely used
116"
INTRODUCTION,0.2318271119842829,"neuroimaging DR algorithms (“brain representation” or ""BR"").
117"
METHODS,0.2337917485265226,"2
Methods
118"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2357563850687623,"2.1
Brain Data and Brain Representations
119"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.23772102161100198,"The data for this study consists of pre-processed resting-state functional MRI data from N=1003
120"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.23968565815324164,"Human Connectome Project young adult (HCP-YA)30 subjects. Each subject’s minimally pre-
121"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.24165029469548133,"processed data consists of 91,282 spatial “grayordinates” by 1200 time points, giving an embedding
122"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.24361493123772102,"dimension of D ∼108 in the initial space. We then chose six different brain representations that
123"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2455795677799607,"are both common within the field and showcase the methodological variability of widely adopted
124"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2475442043222004,"techniques. The brain representations we consider can roughly be grouped by their underlying models
125"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.24950884086444008,"of brain function. We characterize the first group of methods as seeking to cluster neural activity
126"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.25147347740667975,"into spatially contiguous cortical “parcels.” In the parcellation family, we have Yeo’s parcellated
127"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.25343811394891946,"networks31, Glasser’s multimodal parcellation32, and Schaefer’s local-global parcellation33. We also
128"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2554027504911591,"sample from a family of low-rank matrix factorization methods that parse non-contiguous networks
129"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.25736738703339884,"of functional activity. Independent component analysis (ICA)34, an extension and application
130"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2593320235756385,"refinement of PCA, underlies perhaps the most widely used brain representation in the field35 and
131"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.26129666011787817,"thus is represented here. In addition, we consider PROFUMO36, which parses “functional modes” of
132"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2632612966601179,"brain activity from hierarchical Bayesian signal models. Finally, we include the “principal gradient”
133"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.26522593320235754,"(or “gradients”)37, a diffusion embedding method that organizes brain function through cortical
134"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.26719056974459726,"geometry.
135"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2691552062868369,"From each brain representation, one or more feature types were computed to reflect the typical use of
136"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.27111984282907664,"brain representations in the neuroimaging literature. The five feature types considered in this work
137"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2730844793713163,"are as follows: (1) “amplitude,” the average power of the time signal in a given spatial component; (2)
138"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.275049115913556,"“network matrix (netmat),” the matrix of pairwise Pearson similarities of time courses for each pair of
139"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2770137524557957,"spatial components; (3) “partial correlation,” the variance-normalized precision matrix; (4) “map,”
140"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.27897838899803534,"the spatial membership weights of a given spatial component in grayordinate space; and (5) “spatial
141"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.28094302554027506,"network matrix”, the matrix of pairwise Pearson similarities of maps for each spatial component.
142"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2829076620825147,"The decomposition rank, feature types, and number of features for each brain representation is
143"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.28487229862475444,"summarized in Table 1. Note that since subject data are encoded in terms of features, it is the feature
144"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2868369351669941,"number and not the brain representation’s decomposition rank that denotes the dimension d of the
145"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2888015717092338,"target embedding space in the mapping bφ : bS →Rd. We compare subject-space embeddings using
146"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2907662082514735,"the pairwise dissimilarities of their points, which we compute as described in the next section.
147"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.29273084479371314,"Representation Name
Decomposition
Rank(s) r
Considered Feature Type(s)
Feature Number(s) d"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.29469548133595286,"PROFUMO
33
maps, spatial network matrices
91282 × 33,
 33
2
"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.2966601178781925,"Dual-regression
spatial ICA"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.29862475442043224,"15, 25, 50,
100, 200, 300"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.3005893909626719,"amplitudes, network matrices,
partial network matrices
r,
 r
2

,
 r
2
"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.3025540275049116,"Glasser parcellation
360
amplitudes, network matrices,
partial network matrices
360,
 360
2

,
 360
2
"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.3045186640471513,"Schaefer parcellation
100, 200, 300, 600
amplitudes, network matrices,
partial network matrices
r,
 r
2

,
 r
2
"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.30648330058939094,"Yeo parcellation
17
amplitudes, network matrices,
partial network matrices
17,
 17
2

,
 17
2
"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.30844793713163066,"Gradient
(diffusion embedding)"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.3104125736738703,"1, 15, 25, 50,
100, 200, 300
maps
91282 × r"
BRAIN DATA AND BRAIN REPRESENTATIONS,0.31237721021611004,"Table 1: The combinations of brain representation, decomposition rank parameters, and feature types
investigated in the present work."
DISSIMILARITY MEASURES,0.3143418467583497,"2.2
Dissimilarity Measures
148"
DISSIMILARITY MEASURES,0.3163064833005894,"For each brain representation method, decomposition rank within a given representation, and con-
149"
DISSIMILARITY MEASURES,0.3182711198428291,"sidered feature type, we compute pairwise distances between all subjects. Each feature type under
150"
DISSIMILARITY MEASURES,0.32023575638506874,"consideration is structured either as a vector (maps, amplitudes) or a symmetric positive semidefinite
151"
DISSIMILARITY MEASURES,0.32220039292730845,"(SPSD) matrix (network matrices). This bifurcation of data types is echoed in our choice of measures
152"
DISSIMILARITY MEASURES,0.3241650294695481,"when computing the dissimilarity between a pair of subjects. In both the vector case and the SPSD
153"
DISSIMILARITY MEASURES,0.32612966601178783,"data case, we ran our analysis using one dissimilarity measure intrinsic to the data type and another
154"
DISSIMILARITY MEASURES,0.3280943025540275,"derived from the Pearson correlation. We use Pearson-based dissimilarities in deference to the
155"
DISSIMILARITY MEASURES,0.3300589390962672,"ubiquitous use of the Pearson correlation in neuroimaging analyses.
156"
DISSIMILARITY MEASURES,0.3320235756385069,"We now define the dissimilarity measures we use on vector data. Suppose si and sj are data vectors
157"
DISSIMILARITY MEASURES,0.33398821218074654,"in Rd, and let ρ(si, sj) denote their Pearson correlation. Let ⟨·, ·⟩denote the usual inner product on
158"
DISSIMILARITY MEASURES,0.33595284872298625,"Rd. We then define
159"
DISSIMILARITY MEASURES,0.3379174852652259,"dv1(si, sj) = 1 −⟨si, sj⟩2
(1)"
DISSIMILARITY MEASURES,0.33988212180746563,"dv2(si, sj) = 1 −ρ2(si, sj),
(2)
assuming the matrix Dij = ⟨si, sj⟩is scaled to have entries in [0, 1]. Note that we can interpret dv2
160"
DISSIMILARITY MEASURES,0.3418467583497053,"as approximately the angular distance between the vectors si and sj after each has been centered. We
161"
DISSIMILARITY MEASURES,0.343811394891945,"refer to dv1 as the ""inner product divergence"" and dv2 as the ""Pearson divergence"".
162"
DISSIMILARITY MEASURES,0.34577603143418467,"In the SPSD matrix case, we consider the geodesic distance between matrices on the Riemannian
163"
DISSIMILARITY MEASURES,0.3477406679764244,"SPD cone38 alongside a (modified) Pearson divergence. The geodesic distance dpd1 on the symmetric
164"
DISSIMILARITY MEASURES,0.34970530451866405,"positive definite cone39 is efficiently implemented via the approximate joint diagonalizer40, and we
165"
DISSIMILARITY MEASURES,0.3516699410609037,"modify the Pearson divergence dv2 for the correlation matrix case by precomposing it with Fisher’s
166"
DISSIMILARITY MEASURES,0.35363457760314343,"z-transformation41 (the inverse hyperbolic tangent function): we write
167"
DISSIMILARITY MEASURES,0.3555992141453831,"dpd2(Mi, Mj) = atanh∗dv2(mi, mj),
(3)"
DISSIMILARITY MEASURES,0.3575638506876228,"where mi is the vector of upper-right triangle entries of the symmetric matrix Mi (diagonal excluded).
168"
DISSIMILARITY MEASURES,0.35952848722986247,"This precomposition is necessary for correlation matrices, as it normalizes the correlation values
169"
DISSIMILARITY MEASURES,0.3614931237721022,"before re-correlating them. In contrast to the vector case, there is no simple comparison to be made
170"
DISSIMILARITY MEASURES,0.36345776031434185,"between these two dissimilarity measures.
171"
DISSIMILARITY MEASURES,0.3654223968565815,"For each combination of brain representation, rank parameter, and feature type shown in Table 1,
172"
DISSIMILARITY MEASURES,0.36738703339882123,"we compute pairwise dissimilarity according to both of whichever two measures are relevant. The
173"
DISSIMILARITY MEASURES,0.3693516699410609,"subject-pairwise matrix of dissimilarities then forms the Gram matrix used to compute the persistent
174"
DISSIMILARITY MEASURES,0.3713163064833006,"homology, as we describe in the next section.
175"
PERSISTENT HOMOLOGY,0.37328094302554027,"2.3
Persistent Homology
176"
PERSISTENT HOMOLOGY,0.37524557956778,"We compute the Vietoris-Rips persistence13 of each Gram matrix (which is obtained as described
177"
PERSISTENT HOMOLOGY,0.37721021611001965,"above), and we now give a very brief background on Vietoris-Rips persistence. For a thorough
178"
PERSISTENT HOMOLOGY,0.3791748526522593,"treatment of persistent homology, see Dey and Wang’s text13; for a thorough treatment of algebraic
179"
PERSISTENT HOMOLOGY,0.381139489194499,"topology preliminaries, see Hatcher’s text42.
180"
BRIEF BACKGROUND,0.3831041257367387,"2.3.1
Brief background
181"
BRIEF BACKGROUND,0.3850687622789784,"The topology of a space can be summarized by its homology groups, algebraic invariants that describe
182"
BRIEF BACKGROUND,0.38703339882121807,"its structure. Persistent homology extends the constructions of homology to finite data, delivering a
183"
BRIEF BACKGROUND,0.3889980353634578,"multiscale and threshold-free estimation of data topology. To compute the persistent homology of a
184"
BRIEF BACKGROUND,0.39096267190569745,"dataset X, it must first be equipped with a simplicial structure: a simplicial complex K(X) is a set
185"
BRIEF BACKGROUND,0.3929273084479371,"of subsets of X with the property that σ′ ∈K whenever σ′ ⊂σ for some σ ∈K, and a filtration
186"
BRIEF BACKGROUND,0.3948919449901768,"is a collection {Kt(X)} such that Ks ⊂Kt when s < t. Homology groups Hk(Kt(X)) can be
187"
BRIEF BACKGROUND,0.3968565815324165,"computed for each simplicial complex, and their persistence PHk(X) is described by the evolution of
188"
BRIEF BACKGROUND,0.3988212180746562,"these groups across the filtration. A simple example of a simplicial complex on X is a graph G(X).
189"
BRIEF BACKGROUND,0.40078585461689586,"If that graph G(X) is weighted, then the family {Gr(X)} of graphs obtained from G by thresholding
190"
BRIEF BACKGROUND,0.4027504911591356,"its edges at weight r is a filtration on X. If G(X) is the graph on X with edge weights given by the
191"
BRIEF BACKGROUND,0.40471512770137524,"distance between vertices, then the filtration we just described is the Vietoris-Rips filtration on X.
192"
BRIEF BACKGROUND,0.4066797642436149,"Given any dissimilarity matrix dX, we can assume it is the Gram matrix of some graph G(X) and
193"
BRIEF BACKGROUND,0.4086444007858546,"compute its Vietoris-Rips persistence PHk(X).
194"
TOPOLOGICAL BOOTSTRAP,0.4106090373280943,"2.3.2
Topological bootstrap
195"
TOPOLOGICAL BOOTSTRAP,0.412573673870334,"Because it is possible (and, in fact, common) for multiple data elements to define the same homology
196"
TOPOLOGICAL BOOTSTRAP,0.41453831041257366,"generator, bootstrap re-sampling43 is less straightforward in persistent homology than in many other
197"
TOPOLOGICAL BOOTSTRAP,0.4165029469548134,"modes of analysis. However, Reani and Bobrowski recently demonstrated a ""topological bootstrap""
198"
TOPOLOGICAL BOOTSTRAP,0.41846758349705304,"method14 that uses image persistence44 to register homology generators found in co-embeddable
199"
TOPOLOGICAL BOOTSTRAP,0.4204322200392927,"spaces. If X, Y can both be embedded into a shared space Z, then the inclusion maps X
ιX
,−→Z
200"
TOPOLOGICAL BOOTSTRAP,0.4223968565815324,"and Y
ιY
,−→Z induce homology maps ι∗
X, ι∗
Y with corresponding filtration maps ι∗
r,X, ι∗
r,Y (assuming
201"
TOPOLOGICAL BOOTSTRAP,0.4243614931237721,"compatible filtrations on each space). A pair of nontrivial elements in PHk(X) and PHk(Y ) is
202"
TOPOLOGICAL BOOTSTRAP,0.4263261296660118,"said to match via Z if ι∗
r,X and ι∗
r,Y map them to the same nontrivial element of PHk(Z) for some
203"
TOPOLOGICAL BOOTSTRAP,0.42829076620825146,"filtration value r. For a matched pair, the affinity score α of the match can be computed from ratios
204"
TOPOLOGICAL BOOTSTRAP,0.4302554027504912,"of lengths of intervals in each filtration for which elements in PHk(X) and PHk(Y ) are matched via
205"
TOPOLOGICAL BOOTSTRAP,0.43222003929273084,"Z. We assign α = 0 when no match is found and have α ∈(0, 1] otherwise.
206"
TOPOLOGICAL BOOTSTRAP,0.43418467583497056,"This procedure simplifies substantially in the bootstrapping case; we then have Z = X and Y =
207"
TOPOLOGICAL BOOTSTRAP,0.4361493123772102,"b
X ⊂X, and we need only check nontrivial elements of PHk(X) for matches in PHk( b
X). In the
208"
TOPOLOGICAL BOOTSTRAP,0.4381139489194499,"bootstrap setting, Reani and Bobrowski measure the recurrence stability of a nontrivial generator
209"
TOPOLOGICAL BOOTSTRAP,0.4400785854616896,"η ∈PHk(X) by its prevalence score
210"
TOPOLOGICAL BOOTSTRAP,0.44204322200392926,"ρ(η) := 1 R R
X"
TOPOLOGICAL BOOTSTRAP,0.444007858546169,"j=1
α(η, bηj),
(4)"
TOPOLOGICAL BOOTSTRAP,0.44597249508840864,"where bηj is the match of η in the jth bootstrap. This is just the average affinity (over all bootstraps)
211"
TOPOLOGICAL BOOTSTRAP,0.44793713163064836,"between η and its matches. In the present study, we compute prevalence scores for each generator in
212"
TOPOLOGICAL BOOTSTRAP,0.449901768172888,"PH1(X) for a given subject dissimilarity matrix X.
213"
TOPOLOGICAL BOOTSTRAP,0.4518664047151277,"Our implementation45 of the topological bootstrap is a mild extension of Garcia-Redondo et al’s
214"
TOPOLOGICAL BOOTSTRAP,0.4538310412573674,"work15, which efficiently integrates cycle registration with Ripser46 and Ripser-image47, refines the
215"
TOPOLOGICAL BOOTSTRAP,0.45579567779960706,"cycle affinity measures proposed by Reani and Bobrowski, and broadens the conditions under which
216"
TOPOLOGICAL BOOTSTRAP,0.4577603143418468,"topological bootstrapping may be applied.
217"
TOPOLOGICAL BOOTSTRAP,0.45972495088408644,"To satisfy the exchangeability criteria necessary for (any) bootstrapping, we also needed to account
218"
TOPOLOGICAL BOOTSTRAP,0.46168958742632615,"for family relationships between subjects in our bootstrap re-samples. Following the approach of
219"
TOPOLOGICAL BOOTSTRAP,0.4636542239685658,"Winkler et al.48, we excluded all bootstrap re-samples that placed individuals with the same mother
220"
TOPOLOGICAL BOOTSTRAP,0.4656188605108055,"on different sides of the inclusion/exclusion divide. We conducted cycle registration using R = 1000
221"
TOPOLOGICAL BOOTSTRAP,0.4675834970530452,"bootstraps per dataset at 90% re-sampling (without replacement), and we consider k = 1-dimensional
222"
TOPOLOGICAL BOOTSTRAP,0.46954813359528486,"cycle registration in this work.
223"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.4715127701375246,"2.3.3
Prevalence-weighted Wasserstein-p distance
224"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.47347740667976423,"The space of persistence diagrams is a metric space49 under the Wasserstein-p distance, which
225"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.47544204322200395,"previous work3 has used to compare persistence diagrams of different low-dimensional embeddings.
226"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.4774066797642436,"To include statistical information about the stability of homology generators in this comparison, we
227"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.4793713163064833,"define the prevalence-weighted Wasserstein-p distance
228"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.481335952848723,"W (ρ)
p
(d1, d2) := "
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.48330058939096265,"inf
γ∈Γ12 X"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.48526522593320237,"x∈d1
∥x · ρ(x) −γ(x) · ρ(γ(x))∥p
∞ ! 1"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.48722986247544203,"p
.
(5)"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.48919449901768175,"Here, d1 and d2 are persistence diagrams, Γ12 is the set of bijections between d1 and d2, and ρ(x) is
229"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.4911591355599214,"the prevalence of the homology generator x given in 4. This is a simple re-weighting of the usual
230"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.4931237721021611,"Wasserstein distance, modified to incorporate the prevalence score as a summary of per-cycle stability
231"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.4950884086444008,"statistics.
232"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.49705304518664045,"2.3.4
The ""matched Betti number"" β(matched)
k
233"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.49901768172888017,"We also define the ""first matched Betti number"" β(matched)
k
as the number of matched cycles (i.e.,
234"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.5009823182711198,"matches with nonzero affinity scores) found in each bootstrapped re-sample. Intuitively, this is a count
235"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.5029469548133595,"of the number of stable generators found in each bootstrap. The Betti numbers of a persistence module
236"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.5049115913555993,"are typically summarized by curves, since each value of a filtration may induce a homology with
237"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.5068762278978389,"a different set of Betti numbers. However, since the topological bootstrap already uses persistence
238"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.5088408644400786,"interval information to find matched cycles and compute their affinity, we may consider β(matched)
k
as
239"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.5108055009823183,"having ""collapsed"" these curves via cycle registration. We consider the distribution of bootstrapped
240"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.5127701375245579,"β(matched)
k
values as a coarse summary of the distributed persistence28,29 of a given dissimilarity matrix
241"
PREVALENCE-WEIGHTED WASSERSTEIN-P DISTANCE,0.5147347740667977,"dX.
242"
STUDY DESIGN,0.5166994106090373,"2.4
Study Design
243"
STUDY DESIGN,0.518664047151277,"In Table 1, we lay out parameter and feature selections considered for each brain representation. For
244"
STUDY DESIGN,0.5206286836935167,"every representation, bootstrapped persistence is computed for all combinations of feature, parameter,
245"
STUDY DESIGN,0.5225933202357563,"and dissimilarity measure considered; this gives a total of 90 subject-pairwise dissimilarity matrices
246"
STUDY DESIGN,0.5245579567779961,"for which we compute R = 1000 topological bootstraps. We compute the prevalence-weighted
247"
STUDY DESIGN,0.5265225933202358,"Wasserstein-2 distance between all pairs of methods and the β(matched)
1
distributions for each method.
248"
STUDY DESIGN,0.5284872298624754,"This method-pairwise distance matrix then undergoes Ward hierarchical clustering50 to determine
249"
STUDY DESIGN,0.5304518664047151,"similarity. Our code is publicly available on github.
250"
HYPOTHESES,0.5324165029469549,"2.4.1
Hypotheses
251"
HYPOTHESES,0.5343811394891945,"Comparing across feature and metric choices, we expect the SPD matrix geodesic distance to exhibit
252"
HYPOTHESES,0.5363457760314342,"less sensitivity to concentration of measure and thus provide greater distinction between brain
253"
HYPOTHESES,0.5383104125736738,"representations. We expect that within-feature groupings for map and amplitude will differ very little
254"
HYPOTHESES,0.5402750491159135,"between the considered vector dissimilarity measures (equations 1 and 2). For all comparisons, we
255"
HYPOTHESES,0.5422396856581533,"expect feature number and type to be more important drivers of differences than decomposition rank.
256"
HYPOTHESES,0.5442043222003929,"Finally, within the PROFUMO analysis, we expect that spatial network matrices will be further from
257"
HYPOTHESES,0.5461689587426326,"null than spatial maps, where we expect the very high dimensions of the spatial maps to suffer from
258"
HYPOTHESES,0.5481335952848723,"concentration of measure.
259"
HYPOTHESES,0.550098231827112,"Comparing across different brain representations, we expect to primarily see clustering according to
260"
HYPOTHESES,0.5520628683693517,"(approximate) feature number and type, with secondary similarity clusters forming within each given
261"
HYPOTHESES,0.5540275049115914,"brain representation. We expect our analysis to align with previous results in the literature linking
262"
HYPOTHESES,0.555992141453831,"shared variance in brain representations51−54, the details of which we expand upon in the results
263"
HYPOTHESES,0.5579567779960707,"below.
264"
RESULTS,0.5599214145383105,"3
Results
265"
PERSISTENT HOMOLOGY AND DIMENSION REDUCTION,0.5618860510805501,"3.1
Persistent homology and dimension reduction
266"
PERSISTENT HOMOLOGY AND DIMENSION REDUCTION,0.5638506876227898,"We first note several unexpected instances of trivial (or nearly trivial) persistence structure. First,
267"
PERSISTENT HOMOLOGY AND DIMENSION REDUCTION,0.5658153241650294,"full correlation matrices generated null H1 persistence at every decomposition rank in every brain
268"
PERSISTENT HOMOLOGY AND DIMENSION REDUCTION,0.5677799607072691,"representation. By contrast, the partial correlation matrices (which is similar by conjugation to
269"
PERSISTENT HOMOLOGY AND DIMENSION REDUCTION,0.5697445972495089,"the inverse of the full correlation matrix) have interesting persistence for nearly all feature types,
270"
PERSISTENT HOMOLOGY AND DIMENSION REDUCTION,0.5717092337917485,"decomposition ranks, and dissimilarity measures. Additionally, the inner product divergence (1)
271"
PERSISTENT HOMOLOGY AND DIMENSION REDUCTION,0.5736738703339882,"generated trivial or almost trivial homology in both maps and amplitudes, across all ranks and
272"
PERSISTENT HOMOLOGY AND DIMENSION REDUCTION,0.5756385068762279,"representations; this is not true of the Pearson divergence, which we incorrectly hypothesized would
273"
PERSISTENT HOMOLOGY AND DIMENSION REDUCTION,0.5776031434184676,"exhibit similar behavior. A complete list of all methods that exhibited trivial H1 persistence is given
274"
PERSISTENT HOMOLOGY AND DIMENSION REDUCTION,0.5795677799607073,"in Table S1.
275"
EFFECT OF EMBEDDING DIMENSION,0.581532416502947,"3.1.1
Effect of embedding dimension
276"
EFFECT OF EMBEDDING DIMENSION,0.5834970530451866,"Our analysis saw that topological complexity (as measured by H1 persistence) generally decreased
277"
EFFECT OF EMBEDDING DIMENSION,0.5854616895874263,"with the number of features considered (Fig S1). Under the geodesic distance, mean prevalence
278"
EFFECT OF EMBEDDING DIMENSION,0.587426326129666,"score increased with feature number; for all other dissimilarity measures, mean prevalence score
279"
EFFECT OF EMBEDDING DIMENSION,0.5893909626719057,"was not correlated with feature number (Fig S2). Taken together, these observations suggest that
280"
EFFECT OF EMBEDDING DIMENSION,0.5913555992141454,"embeddings in higher dimensions elicit a smaller number of nontrivial H1 generators which are also
281"
EFFECT OF EMBEDDING DIMENSION,0.593320235756385,"more robust. This runs counter to the consequences we might expect from concentration of measure
282"
EFFECT OF EMBEDDING DIMENSION,0.5952848722986247,"in high dimensions, which pushes spaces towards the discrete topology (and thus a higher number of
283"
EFFECT OF EMBEDDING DIMENSION,0.5972495088408645,"less stable generators). As expected, we also saw that feature number was a more important driver of
284"
EFFECT OF EMBEDDING DIMENSION,0.5992141453831041,"persistence structure than the underlying rank of the decomposition (Fig S3).
285"
EFFECT OF EMBEDDING DIMENSION,0.6011787819253438,"3.1.2
Persistence vs. prevalence
286"
EFFECT OF EMBEDDING DIMENSION,0.6031434184675835,"We see evidence further corroborating Reani and Bobrowski’s observation that the most prevalent
287"
EFFECT OF EMBEDDING DIMENSION,0.6051080550098232,"cycles are not always the most persistent ones14. Figure 1 shows a sample persistence diagram in
288"
EFFECT OF EMBEDDING DIMENSION,0.6070726915520629,"H1 (colored by generator prevalence score) and a plot of all persistence-prevalence pairs observed
289"
EFFECT OF EMBEDDING DIMENSION,0.6090373280943026,"in this experiment. Both plots demonstrate that cycles with low persistence can still have high
290"
EFFECT OF EMBEDDING DIMENSION,0.6110019646365422,"prevalence, suggesting that the topological ""noise"" may carry meaningful structure in our data. In
291"
EFFECT OF EMBEDDING DIMENSION,0.6129666011787819,"addition, we see a substantially richer difference structure between target embeddings when using the
292"
EFFECT OF EMBEDDING DIMENSION,0.6149312377210217,"prevalence-weighted Wasserstein-2 distance instead of the classical Wasserstein-2 distance (Figure
293"
EFFECT OF EMBEDDING DIMENSION,0.6168958742632613,"S4).
294"
EFFECT OF EMBEDDING DIMENSION,0.618860510805501,"Figure 1: (Left) A sample persistence diagram, with color weights given by prevalence score. (Right)
Persistence versus prevalence across all data collected, colored with a Gaussian kernel density
estimator."
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6208251473477406,"3.2
Persistence differences of brain representations
295"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6227897838899804,"Figure 2: Prevalence-weighted 2-Wasserstien distances between H1 persistence diagrams for all
pairs of methods combinations with nontrivial first homology. Ward hierarchical clustering gives
the dendrogram on the left side of the plot, which organizes labels into groups that maximally share
variance. Lighter colors denote smaller distances, while darker (blue) colors denote larger ones."
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6247544204322201,"The prevalence-weighted Wasserstein distance makes its strongest distinction between amplitudes
296"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6267190569744597,"and network matrix/spatial map feature types, which form the two main diagonal blocks and highest
297"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6286836935166994,"dendrogram branches (Fig 2). As hypothesized, this implies that our method distinguishes more
298"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.630648330058939,"strongly between feature type (and number) than between brain representation type, which forms
299"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6326129666011788,"the next set of blocks and branches. This is still somewhat surprising, however, because brain
300"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6345776031434185,"representations differ substantially in terms of whether they are unilateral or bilateral, binary or
301"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6365422396856582,"weighted, and decomposition rank.
302"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6385068762278978,"We are also surprised to see PROFUMO spatial network matrices in the amplitude block. Both
303"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6404715127701375,"amplitudes55 and spatial network matrices12 have been shown to be highly sensitive to individual
304"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6424361493123772,"differences in behavior, but these feature types are interpreted very differently. Amplitudes may be
305"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6444007858546169,"linked to within-network synchronization56, within-network plasticity57, or within-network interneu-
306"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6463654223968566,"ron function58, whereas spatial network matrices are indicative of between-network shared brain
307"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6483300589390962,"regions that may play a role in cross-network integration12. Both amplitudes and spatial netmats have
308"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.650294695481336,"higher test-retest reliability (i.e., within-subject stability) than the features in the other block36,59.
309"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6522593320235757,"Given this context, the clustered blocks of the prevalence-weighted Wasserstein may constitute a
310"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6542239685658153,"segregation of trait-sensitive (amplitude and spatial network matrix) from state-sensitive (temporal
311"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.656188605108055,"network matrix) features. This observation highlights the need for an evaluation method that can
312"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6581532416502947,"detect which elements of the persistence module are shared across representations, rather than only
313"
PERSISTENCE DIFFERENCES OF BRAIN REPRESENTATIONS,0.6601178781925344,"being able to similar topologies of subject similarity.
314"
COMPUTATIONAL RESOURCES,0.6620825147347741,"3.3
Computational resources
315"
COMPUTATIONAL RESOURCES,0.6640471512770137,"All other computations, including cycle registration, were negligible in cost compared to the com-
316"
COMPUTATIONAL RESOURCES,0.6660117878192534,"putation of persistence modules for all bootstraps — roughly 270, 000 persistence modules were
317"
COMPUTATIONAL RESOURCES,0.6679764243614931,"computed in total. Memory demands remained relatively low (≤50GB per homology computation).
318"
COMPUTATIONAL RESOURCES,0.6699410609037328,"Our implementation was embarrassingly parallel on a queue-managed HPC cluster. We estimate that
319"
COMPUTATIONAL RESOURCES,0.6719056974459725,"this experiment used approximately 80, 000 CPU hours over the course of a month. Computation of
320"
COMPUTATIONAL RESOURCES,0.6738703339882122,"image-persistence was the most costly individual step, with each embedded persistence module taking
321"
COMPUTATIONAL RESOURCES,0.6758349705304518,"1-3 hours to compute (compared to order of 10 minutes or less for other persistence computations).
322"
DISCUSSION,0.6777996070726916,"4
Discussion
323"
CONCLUSIONS,0.6797642436149313,"4.1
Conclusions
324"
CONCLUSIONS,0.6817288801571709,"Our method reveals interesting relationships between dimensionality reductions of resting-state fMRI
325"
CONCLUSIONS,0.6836935166994106,"data. The prevalence-weighted Wasserstein distance distinguishes much more strongly between
326"
CONCLUSIONS,0.6856581532416502,"feature type than dimensionality reduction, potentially segregating trait-sensitive from state-sensitive
327"
CONCLUSIONS,0.68762278978389,"features. Notably, this distinction holds without regard to choice of dissimilarity measure.
328"
CONCLUSIONS,0.6895874263261297,"Without exception, full network matrices gave rise to trivial PH1 modules. Persistence modules
329"
CONCLUSIONS,0.6915520628683693,"generated from the inner product divergence (1) were (approximately) trivial as well, in sharp contrast
330"
CONCLUSIONS,0.693516699410609,"to those generated from the Pearson divergence (2); this suggests that amplitude and spatial map
331"
CONCLUSIONS,0.6954813359528488,"features of brain representations tend to be ""mean-dominated,"" in the sense that per-subject deviations
332"
CONCLUSIONS,0.6974459724950884,"from group-level structures are typically small.
333"
CONCLUSIONS,0.6994106090373281,"In addition, we saw a counterintuitive decrease in persistence ""complexity"" as a function of increasing
334"
CONCLUSIONS,0.7013752455795678,"embedding dimension, which highlights the difficulties of evaluating dimension reduction in high-
335"
CONCLUSIONS,0.7033398821218074,"dimensional target spaces. We also examined the relationship between persistence and prevalence,
336"
CONCLUSIONS,0.7053045186640472,"finding that the two are largely uncorrelated for our data. Coupled with the stronger distinctions real-
337"
CONCLUSIONS,0.7072691552062869,"ized by the prevalence-weighted Wasserstein-2 distance, we believe that persistence and prevalence
338"
CONCLUSIONS,0.7092337917485265,"may be somewhat complementary as measures of cycle importance.
339"
LIMITATIONS,0.7111984282907662,"4.2
Limitations
340"
LIMITATIONS,0.7131630648330058,"Because of the high cost of parameter exploration, dimensionality reduction computation, and
341"
LIMITATIONS,0.7151277013752456,"topological bootstrapping, only a few dimensionality reduction methods were examined in this work.
342"
LIMITATIONS,0.7170923379174853,"An extension of this analysis to a wider array of brain representations may be warranted, especially
343"
LIMITATIONS,0.7190569744597249,"newer methods that derive an explicitly geometric basis for functional activity (e.g., Laplacian
344"
LIMITATIONS,0.7210216110019646,"eigenvalues60).
345"
LIMITATIONS,0.7229862475442044,"Another important limitation of our work is the very high dimension-to-sample-size ratio (N ≪d)
346"
LIMITATIONS,0.724950884086444,"of our data. In this regime, it is difficult to ascertain what features we see because of structure in the
347"
LIMITATIONS,0.7269155206286837,"data and what topological features are products of the curse of dimensionality. This could be partially
348"
LIMITATIONS,0.7288801571709234,"ameliorated by conducting our analysis over adequately constructed null data and comparing the
349"
LIMITATIONS,0.730844793713163,"results, which is beyond the scope of this work.
350"
FUTURE DIRECTIONS,0.7328094302554028,"4.3
Future Directions
351"
FUTURE DIRECTIONS,0.7347740667976425,"In addition to addressing some of the limitations noted above, we offer several directions for follow-
352"
FUTURE DIRECTIONS,0.7367387033398821,"up work on this study. First, we propose a consideration of the per-bootstrap Wasserstein distance
353"
FUTURE DIRECTIONS,0.7387033398821218,"between methods; a distributional picture of differences in the endogenous metric of persistence
354"
FUTURE DIRECTIONS,0.7406679764243614,"modules could yield important insights. Second, it is possible to repurpose the topological bootstrap
355"
FUTURE DIRECTIONS,0.7426326129666012,"to track the addition/deletion of homology components by different brain representation; practically,
356"
FUTURE DIRECTIONS,0.7445972495088409,"this is primarily hindered by the lack of a suitable dissimilarity metric between pairs of points under
357"
FUTURE DIRECTIONS,0.7465618860510805,"different embeddings. Finding and validating such a metric would be a valuable direction of inquiry.
358"
FUTURE DIRECTIONS,0.7485265225933202,"Finally, we wish to suggest an investigation into the theoretical properties of the prevalence-weighted
359"
FUTURE DIRECTIONS,0.75049115913556,"Wasserstein metric.
360"
REFERENCES,0.7524557956777996,"References
361"
REFERENCES,0.7544204322200393,"1. Wang, Y., Huang, H., Rudin, C.& Shaposhnik, Y. Understanding how dimension reduction
362"
REFERENCES,0.756385068762279,"tools work: an empirical approach to deciphering t-SNE, UMAP, TriMap, and PaCMAP for data
363"
REFERENCES,0.7583497053045186,"visualization. J. Mach. Learn. Res. 22, 201:9129-201:9201 (2022).
364"
REFERENCES,0.7603143418467584,"2. Paul, R.& Chalup, S. K. A study on validating non-linear dimensionality reduction using persistent
365"
REFERENCES,0.762278978388998,"homology. Pattern Recognition Letters 100, 160–166 (2017).
366"
REFERENCES,0.7642436149312377,"3. Rieck, B.& Leitte, H. Persistent Homology for the Evaluation of Dimensionality Reduction
367"
REFERENCES,0.7662082514734774,"Schemes. Computer Graphics Forum 34, 431–440 (2015).
368"
REFERENCES,0.768172888015717,"4. Lee, J. A.& Verleysen, M. Quality assessment of dimensionality reduction: Rank-based criteria.
369"
REFERENCES,0.7701375245579568,"Neurocomputing 72, 1431–1443 (2009).
370"
REFERENCES,0.7721021611001965,"5. Tyagi, H., Vural, E.& Frossard, P. Tangent space estimation for smooth embeddings of Riemannian
371"
REFERENCES,0.7740667976424361,"manifolds®. Information and Inference: A Journal of the IMA 2, 69–114 (2013).
372"
REFERENCES,0.7760314341846758,"6. Lotz, M. Persistent homology for low-complexity models. Proceedings of the Royal Society A:
373"
REFERENCES,0.7779960707269156,"Mathematical, Physical and Engineering Sciences 475, 20190081 (2019).
374"
REFERENCES,0.7799607072691552,"7.
Lee, J. A.& Verleysen, M. Two key properties of dimensionality reduction methods.
in
375"
REFERENCES,0.7819253438113949,"2014 IEEE Symposium on Computational Intelligence and Data Mining (CIDM) 163–170 (2014).
376"
REFERENCES,0.7838899803536346,"doi:10.1109/CIDM.2014.7008663.
377"
REFERENCES,0.7858546168958742,"8. Singer, A.& Wu, H.-T. Vector Diffusion Maps and the Connection Laplacian. Commun Pure Appl
378"
REFERENCES,0.787819253438114,"Math 65, 10.1002/cpa.21395 (2012).
379"
REFERENCES,0.7897838899803536,"9. Gracia, A., González, S., Robles, V.& Menasalvas, E. A methodology to compare Dimensionality
380"
REFERENCES,0.7917485265225933,"Reduction algorithms in terms of loss of quality. Information Sciences 270, 1–27 (2014).
381"
REFERENCES,0.793713163064833,"10. Amari, S. Information Geometry and its Applications. vol. Volume 194 (2016).
382"
REFERENCES,0.7956777996070727,"11. Bijsterbosch, J. et al. Challenges and future directions for representations of functional brain
383"
REFERENCES,0.7976424361493124,"organization. Nature neuroscience 1–12 (2020) doi:10.1038/s41593-020-00726-z.
384"
REFERENCES,0.7996070726915521,"12. Bijsterbosch, J. D., Beckmann, C. F., Woolrich, M. W., Smith, S. M.& Harrison, S. J. The
385"
REFERENCES,0.8015717092337917,"relationship between spatial configuration and functional connectivity of brain regions revisited.
386"
REFERENCES,0.8035363457760314,"eLife (2019) doi:10.7554/eLife.44890.001.
387"
REFERENCES,0.8055009823182712,"13. Dey, T. K.& Wang, Y. Computational Topology for Data Analysis. (Cambridge University Press,
388"
REFERENCES,0.8074656188605108,"2022). doi:10.1017/9781009099950.
389"
REFERENCES,0.8094302554027505,"14. Reani, Y.& Bobrowski, O. Cycle Registration in Persistent Homology with Applications in
390"
REFERENCES,0.8113948919449901,"Topological Bootstrap. Preprint at https://doi.org/10.48550/arXiv.2101.00698 (2021).
391"
REFERENCES,0.8133595284872298,"15. García-Redondo, I., Monod, A.& Song, A. Fast Topological Signal Identification and Persistent
392"
REFERENCES,0.8153241650294696,"Cohomological Cycle Matching. Preprint at https://doi.org/10.48550/arXiv.2209.15446 (2022).
393"
REFERENCES,0.8172888015717092,"16. Böhm, J. N., Berens, P.& Kobak, D. Attraction-Repulsion Spectrum in Neighbor Embeddings.
394"
REFERENCES,0.8192534381139489,"arXiv:2007.08902 [cs, stat] (2021).
395"
REFERENCES,0.8212180746561886,"17. Coifman, R. R.& Lafon, S. Diffusion maps. Applied and Computational Harmonic Analysis 21,
396"
REFERENCES,0.8231827111984283,"5–30 (2006).
397"
REFERENCES,0.825147347740668,"18. Sun, K.& Marchand-Maillet, S. An Information Geometry of Statistical Manifold Learning. in
398"
REFERENCES,0.8271119842829077,"Proceedings of the 31st International Conference on Machine Learning 1–9 (PMLR, 2014).
399"
REFERENCES,0.8290766208251473,"19. Sun, K. Local measurements of nonlinear embeddings with information geometry. in Handbook
400"
REFERENCES,0.831041257367387,"of Statistics vol. 46 257–281 (Elsevier, 2022).
401"
REFERENCES,0.8330058939096268,"20. Amari, S.& Nagaoka, H. Methods of Information Geometry. vol. 191 (American Mathematical
402"
REFERENCES,0.8349705304518664,"Society, 2007).
403"
REFERENCES,0.8369351669941061,"21. Amari, S.-I., Barndorff-Nielsen, O. E., Kass, R. E., Lauritzen, S. L.& Rao, C. R. Differential
404"
REFERENCES,0.8388998035363457,"Geometry in Statistical Inference. Lecture Notes-Monograph Series 10, i–240 (1987).
405"
REFERENCES,0.8408644400785854,"22. Banman, A.& Ziegelmeier, L. Mind the Gap: A Study in Global Development Through Persistent
406"
REFERENCES,0.8428290766208252,"Homology. in Research in Computational Topology (eds. Chambers, E. W., Fasy, B. T.& Ziegelmeier,
407"
REFERENCES,0.8447937131630648,"L.) 125–144 (Springer International Publishing, 2018). doi:10.1007/978-3-319-89593-2_8.
408"
REFERENCES,0.8467583497053045,"23. Bhattacharya, S., Ghrist, R.& Kumar, V. Persistent Homology for Path Planning in Uncertain
409"
REFERENCES,0.8487229862475442,"Environments. IEEE Transactions on Robotics 31, 578–590 (2015).
410"
REFERENCES,0.8506876227897839,"24. Petri, G. et al. Homological scaffolds of brain functional networks. Journal of the Royal Society
411"
REFERENCES,0.8526522593320236,"Interface (2014) doi:10.1098/rsif.2014.0873.
412"
REFERENCES,0.8546168958742633,"25. Lord, L.-D. et al. Insights into Brain Architectures from the Homological Scaffolds of Functional
413"
REFERENCES,0.8565815324165029,"Connectivity Networks. Frontiers in Systems Neuroscience 10, 85 (2016).
414"
REFERENCES,0.8585461689587426,"26. Fasy, B. T.& Qin, Y. Comparing Distance Metrics on Vectorized Persistence Summaries. 6
415"
REFERENCES,0.8605108055009824,"(2020).
416"
REFERENCES,0.862475442043222,"27. Berry, E., Chen, Y.-C., Cisewski-Kehe, J.& Fasy, B. T. Functional summaries of persistence
417"
REFERENCES,0.8644400785854617,"diagrams. J Appl. and Comput. Topology 4, 211–262 (2020).
418"
REFERENCES,0.8664047151277013,"28. Solomon, E., Wagner, A.& Bendich, P. From Geometry to Topology: Inverse Theorems for
419"
REFERENCES,0.8683693516699411,"Distributed Persistence. (2021).
420"
REFERENCES,0.8703339882121808,"29. Bubenik, P., Hull, M., Patel, D.& Whittle, B. Persistent homology detects curvature. Inverse
421"
REFERENCES,0.8722986247544204,"Problems 36, 025008 (2020).
422"
REFERENCES,0.8742632612966601,"30. Glasser, M. F. et al. The Human Connectome Project’s neuroimaging approach. Nature
423"
REFERENCES,0.8762278978388998,"Neuroscience 19, 1175–1187 (2016).
424"
REFERENCES,0.8781925343811395,"31. Thomas Yeo, B. T. et al. The organization of the human cerebral cortex estimated by intrinsic
425"
REFERENCES,0.8801571709233792,"functional connectivity. Journal of Neurophysiology 106, 1125–1165 (2011).
426"
REFERENCES,0.8821218074656189,"32. Glasser, M. F. et al. A multi-modal parcellation of human cerebral cortex. Nature 536, 171–178
427"
REFERENCES,0.8840864440078585,"(2016).
428"
REFERENCES,0.8860510805500982,"33. Schaefer, A. et al. Local-Global Parcellation of the Human Cerebral Cortex from Intrinsic
429"
REFERENCES,0.888015717092338,"Functional Connectivity MRI. Cerebral Cortex 28, 3095–3114 (2018).
430"
REFERENCES,0.8899803536345776,"34. Comon, P. Independent Component Analysis, a new concept? Signal Processing 36, 287–314
431"
REFERENCES,0.8919449901768173,"(1994).
432"
REFERENCES,0.8939096267190569,"35. Nickerson, L. D., Smith, S. M., Öngür, D.& Beckmann, C. F. Using Dual Regression to Investigate
433"
REFERENCES,0.8958742632612967,"Network Shape and Amplitude in Functional Connectivity Analyses. Frontiers in Neuroscience 11,
434"
REFERENCES,0.8978388998035364,"115 (2017).
435"
REFERENCES,0.899803536345776,"36. Harrison, S. J. et al. Modelling subject variability in the spatial and temporal characteristics of
436"
REFERENCES,0.9017681728880157,"functional modes. NeuroImage 222, 117226 (2020).
437"
REFERENCES,0.9037328094302554,"37. Margulies, D. S. et al. Situating the default-mode network along a principal gradient of macroscale
438"
REFERENCES,0.9056974459724951,"cortical organization. Proceedings of the National Academy of Sciences 113, 12574–12579 (2016).
439"
REFERENCES,0.9076620825147348,"38. Moakher, M. A Differential Geometric Approach to the Geometric Mean of Symmetric Positive-
440"
REFERENCES,0.9096267190569745,"Definite Matrices. SIAM J. Matrix Anal.& Appl. 26, 735–747 (2005).
441"
REFERENCES,0.9115913555992141,"39. Pennec, X., Fillard, P.& Ayache, N. A Riemannian Framework for Tensor Computing. Interna-
442"
REFERENCES,0.9135559921414538,"tional Journal of Computer Vision 66, 41–66 (2006).
443"
REFERENCES,0.9155206286836935,"40. Congedo, M., Afsari, B., Barachant, A.& Moakher, M. Approximate Joint Diagonalization and
444"
REFERENCES,0.9174852652259332,"Geometric Mean of Symmetric Positive Definite Matrices. PLOS ONE 10, e0121423 (2015).
445"
REFERENCES,0.9194499017681729,"41. Fisher, R. A. Frequency Distribution of the Values of the Correlation Coefficient in Samples from
446"
REFERENCES,0.9214145383104125,"an Indefinitely Large Population. Biometrika 10, 507–521 (1915).
447"
REFERENCES,0.9233791748526523,"42. Hatcher, A. Algebraic Topology. (Cambridge University Press, 2002).
448"
REFERENCES,0.925343811394892,"43. Abu-Mostafa, Y. S., Magdon-Ismail, M.& Lin, H.-T. Learning from Data. (2012).
449"
REFERENCES,0.9273084479371316,"44.
Cohen-Steiner, D., Edelsbrunner, H., Harer, J.& Morozov, D. Persistent Homology for
450"
REFERENCES,0.9292730844793713,"Kernels, Images, and Cokernels. in Proceedings of the Twentieth Annual ACM-SIAM Sympo-
451"
REFERENCES,0.931237721021611,"sium on Discrete Algorithms 1011–1020 (Society for Industrial and Applied Mathematics, 2009).
452"
REFERENCES,0.9332023575638507,"doi:10.1137/1.9781611973068.110.
453"
REFERENCES,0.9351669941060904,"45. tyo8/interval-matching-precomp_metric at 67d87792887574195be1376472a9c11f522acc8f.
454"
REFERENCES,0.93713163064833,"GitHub https://github.com/tyo8/interval-matching-precomp_metric.
455"
REFERENCES,0.9390962671905697,"46. Bauer, U. Ripser: efficient computation of Vietoris–Rips persistence barcodes. J Appl. and
456"
REFERENCES,0.9410609037328095,"Comput. Topology 5, 391–423 (2021).
457"
REFERENCES,0.9430255402750491,"47.
Bauer, U.& Schmahl, M. Efficient Computation of Image Persistence.
Preprint at
458"
REFERENCES,0.9449901768172888,"https://doi.org/10.48550/arXiv.2201.04170 (2022).
459"
REFERENCES,0.9469548133595285,"48. Winkler, A. M., Webster, M. A., Vidaurre, D., Nichols, T. E. & Smith, S. M. Multi-level block
460"
REFERENCES,0.9489194499017681,"permutation. Neuroimage 123, 253–268 (2015).
461"
REFERENCES,0.9508840864440079,"49. Cohen-Steiner, D., Edelsbrunner, H. & Harer, J. Stability of Persistence Diagrams. Discrete
462"
REFERENCES,0.9528487229862476,"Comput Geom 37, 103–120 (2007).
463"
REFERENCES,0.9548133595284872,"50. Ward, J. H. Hierarchical Grouping to Optimize an Objective Function. Journal of the American
464"
REFERENCES,0.9567779960707269,"Statistical Association 58, 236–244 (1963).
465"
REFERENCES,0.9587426326129665,"51. Dadi, K. et al. Benchmarking functional connectome-based predictive models for resting-state
466"
REFERENCES,0.9607072691552063,"fMRI. NeuroImage 192, 115–134 (2019).
467"
REFERENCES,0.962671905697446,"52. Botvinik-Nezer, R. et al. Variability in the analysis of a single neuroimaging dataset by many
468"
REFERENCES,0.9646365422396856,"teams. Nature 582, 84–88 (2020).
469"
REFERENCES,0.9666011787819253,"53. Bijsterbosch, J. D. et al. The relationship between spatial configuration and functional connectivity
470"
REFERENCES,0.9685658153241651,"of brain regions. eLife (2018) doi:10.7554/eLife.32992.001.
471"
REFERENCES,0.9705304518664047,"54. R, K. et al. Comparison Between Gradients and Parcellations for Functional Connectivity
472"
REFERENCES,0.9724950884086444,"Prediction of Behavior. Neuroimage 120044 (2023).
473"
REFERENCES,0.9744597249508841,"55. Miller, K. L. et al. Multimodal population brain imaging in the UK Biobank prospective
474"
REFERENCES,0.9764243614931237,"epidemiological study. Nat Neurosci 19, 1523–1536 (2016).
475"
REFERENCES,0.9783889980353635,"56. Lee, S. et al. Amplitudes of resting-state functional networks - investigation into their correlates
476"
REFERENCES,0.9803536345776032,"and biophysical properties. Neuroimage 265, 119779 (2023).
477"
REFERENCES,0.9823182711198428,"57. Sydnor, V. J. et al. Intrinsic activity development unfolds along a sensorimotor–association
478"
REFERENCES,0.9842829076620825,"cortical axis in youth. Nat Neurosci 26, 638–649 (2023).
479"
REFERENCES,0.9862475442043221,"58. Anderson, K. M. et al. Convergent molecular, cellular, and cortical neuroimaging signatures of
480"
REFERENCES,0.9882121807465619,"major depressive disorder. Proceedings of the National Academy of Sciences 117, 25138–25149
481"
REFERENCES,0.9901768172888016,"(2020).
482"
REFERENCES,0.9921414538310412,"59. Dutt, R. K. et al. Mental health in the UK Biobank: A roadmap to self-report measures and
483"
REFERENCES,0.9941060903732809,"neuroimaging correlates. Human Brain Mapping 43, 816–832 (2022).
484"
REFERENCES,0.9960707269155207,"60. Pang, J. C. et al. Geometric constraints on human brain function. 2022.10.04.510897 Preprint at
485"
REFERENCES,0.9980353634577603,"https://doi.org/10.1101/2022.10.04.510897 (2023).
486"
