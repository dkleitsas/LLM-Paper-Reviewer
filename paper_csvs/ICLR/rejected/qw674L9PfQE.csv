Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0006493506493506494,"Contrastive learning with the InfoNCE objective is exceptionally successful in
various self-supervised learning tasks. Recently, the CLIP model yielded im-
pressive results on zero-shot transfer learning when using InfoNCE for learning
visual representations from natural language supervision. However, InfoNCE as
a lower bound on the mutual information has been shown to perform poorly for
high mutual information. In contrast, the InfoLOOB upper bound (leave one out
bound) works well for high mutual information but suffers from large variance and
instabilities. We introduce “Contrastive Leave One Out Boost” (CLOOB), where
modern Hopﬁeld networks boost learning with the InfoLOOB objective. Modern
Hopﬁeld networks replace the original embeddings by retrieved embeddings in the
InfoLOOB objective. The retrieved embeddings give InfoLOOB two assets. Firstly,
the retrieved embeddings stabilize InfoLOOB, since they are less noisy and more
similar to one another than the original embeddings. Secondly, they are enriched
by correlations, since the covariance structure of embeddings is reinforced through
retrievals. We compare CLOOB to CLIP after learning on the Conceptual Captions
and the YFCC dataset with respect to their zero-shot transfer learning performance
on other datasets. CLOOB consistently outperforms CLIP at zero-shot transfer
learning across all considered architectures and datasets."
INTRODUCTION,0.0012987012987012987,"1
INTRODUCTION"
INTRODUCTION,0.001948051948051948,"With the advent of large corpora of unlabeled data in vision and language, self-supervised learning
via contrastive learning has become highly successful. Some contrastive learning objectives, such as
those of BYOL (Grill et al., 2020) and SimSiam (Chen & He, 2021), do not require negative samples.
However, the most popular objective for contrastive learning is InfoNCE (van den Oord et al., 2018),
in which for an anchor sample, a positive sample is contrasted with negative samples."
INTRODUCTION,0.0025974025974025974,"The idea to use objectives with negative samples is well known in deep learning (Gutmann & Hyväri-
nen, 2010; Chen et al., 2017; Mikolov et al., 2013). For contrastive learning, the most successful
objective is InfoNCE, which has been introduced as Contrastive Predictive Coding (CPC) (van den
Oord et al., 2018). InfoNCE has been applied to transfer learning (Hénaff et al., 2019), to natural
language response suggestion (Henderson et al., 2017), to learning sentence representations from
unlabelled data (Logeswaran & Lee, 2018), and to unsupervised feature learning by maximizing
distinctions between instances (Wu et al., 2018). InfoNCE has been used for learning visual repre-
sentations in Pretext-Invariant Representation Learning (PIRL) (Misra & vanDerMaaten, 2020), in
Momentum Contrast (MoCo) (He et al., 2020), and in SimCLR (Chen et al., 2020). SimCLR became
well known as is was highly effective for transfer learning. Zero-shot transfer learning (Lampert
et al., 2009) is one of the most ambitious goals in vision, since it would improve various real-world
downstream applications. Current models in natural language processing and vision perform very
well on standard benchmarks, but they fail at new data, new applications, deployments in the wild,
and stress tests (D’Amour et al., 2020; Recht et al., 2019; Taori et al., 2020; Lapuschkin et al., 2019;
Geirhos et al., 2020). A model with high zero-shot transfer learning performance will not fail on such
data, therefore will be trusted by practitioners."
INTRODUCTION,0.003246753246753247,"Contrastive Language-Image Pre-training (CLIP) based on the InfoNCE objective yielded very
impressive results at zero-shot transfer learning (Radford et al., 2021). CLIP learns expressive image
embeddings directly from raw text, thereby leverages a much richer source of supervision than just"
INTRODUCTION,0.003896103896103896,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.004545454545454545,"labels. A plethora of CLIP follow-up work has already been published (see Appendix Section A.5).
The CLIP model is considered as an important foundation model (Bommasani et al., 2021). Though
CLIP excels at zero-shot transfer learning, it can be improved."
INTRODUCTION,0.005194805194805195,"CLIP training suffers from an “explaining away” problem (Wellman & Henrion, 1993), which leads
to “shortcut learning” (Geirhos et al., 2020) or the Clever Hans phenomenon (Lapuschkin et al., 2019).
Explaining away impedes the increase of the similarity between a text and a corresponding image,
since learning focuses on only one common aspect and does not exploit the full covariance structure
of the data. If one common aspect is sufﬁcient for high similarity, the InfoNCE objective saturates,
since it has the form a/(a + b) with a giving the similarity of a matched pair and b giving the average
similarity of unmatched pairs. For a large similarity a, the objective saturates and increasing a has a
small effect. Contrary to InfoNCE, the leave-one-out (“InfoLOOB”) bound (Poole et al., 2019) is
of the form a/b which does not saturate. However, so far the InfoLOOB bound was not used as an
objective in contrastive learning. We justify the maximization of the InfoLOOB bound for contrastive
learning in Appendix Section A.1.3. We show that maximizing the InfoLOOB bound leads to a good
approximation of the mutual information, in particular for high mutual information. A problem of
InfoLOOB is that it has high variance for small b."
INTRODUCTION,0.005844155844155844,"Even when InfoLOOB avoids saturation, CLIP insufﬁciently extracts the covariance structure in the
data. The covariance originates from co-occurrences of related words in text or from co-occurrences
of objects, textures, or colors in images. CLIP’s problem of insufﬁciently extracting the covariance
structure of the data is tackled by modern Hopﬁeld networks. Hopﬁeld networks are energy-based,
binary associative memories, which popularized artiﬁcial neural networks in the 1980s (Hopﬁeld,
1982; 1984). Associative memory networks have been designed to store and retrieve samples. Their
storage capacity can be considerably increased by polynomial terms in the energy function (Chen
et al., 1986; Psaltis & Cheol, 1986; Baldi & Venkatesh, 1987; Gardner, 1987; Abbott & Arian, 1987;
Horn & Usher, 1988; Caputo & Niemann, 2002; Krotov & Hopﬁeld, 2016). In contrast to these
binary memory networks, we use continuous associative memory networks with very high storage
capacity. These modern Hopﬁeld networks for deep learning architectures have an energy function
with continuous states and can retrieve samples with only one update (Ramsauer et al., 2021; 2020).
Modern Hopﬁeld Networks have already been successfully applied to immune repertoire classiﬁcation
(Widrich et al., 2020) and chemical reaction prediction (Seidl et al., 2021). Modern Hopﬁeld networks
reinforce the covariance structure in the data and stabilize the InfoLOOB objective by increasing b.
The covariance structure of retrieved embeddings is ampliﬁed through co-occurrences of embedding
features in the memory. Additionally, the retrieved embeddings are less noisy and more similar to
one another which leads to a larger b. We introduce “Contrastive Leave One Out Boost” (CLOOB)
which overcomes CLIP’s problems of (i) “explaining away” with saturation and (ii) insufﬁciently
extracting the covariance structure of the data. CLOOB uses the leave-one-out (“InfoLOOB”) bound
(Poole et al., 2019) as the objective in combination with modern Hopﬁeld networks."
INTRODUCTION,0.006493506493506494,Our contributions are:
INTRODUCTION,0.007142857142857143,"(a) we introduce a new contrastive learning method called CLOOB,
(b) we propose InfoLOOB as an objective for contrastive learning,"
INTRODUCTION,0.007792207792207792,"(c) we propose to use modern Hopﬁeld networks to reinforce covariance structures,
(d) we show theoretical properties of the InfoLOOB objective and loss function."
INTRODUCTION,0.008441558441558441,"2
INFOLOOB VS. INFONCE"
INTRODUCTION,0.00909090909090909,"We discuss and analyse known bounds on the mutual information I(X ; Y ) between random variables
X and Y , which are distributed according to p(x, y):"
INTRODUCTION,0.00974025974025974,"I(X ; Y ) = Ep(x,y)"
INTRODUCTION,0.01038961038961039,"
ln
p(x, y)
p(x) p(y)"
INTRODUCTION,0.01103896103896104,"
= Ep(x,y)"
INTRODUCTION,0.011688311688311689,"
ln p(x | y) p(x)"
INTRODUCTION,0.012337662337662338,"
= Ep(x,y)"
INTRODUCTION,0.012987012987012988,"
ln p(y | x) p(y)"
INTRODUCTION,0.013636363636363636,"
. (1)"
INTRODUCTION,0.014285714285714285,"We consider the multi-sample lower bound “InfoNCE” (van den Oord et al., 2018). A pair of an
anchor sample y and a positive sample x1 is drawn via the joint distribution p(x1, y). The negative
samples ˜X = {x2, . . . , xN} are drawn iid according to the marginal distribution p(x). Using
X = {x1, x2, . . . , xN}, the probabilities of the datasets are p( ˜X) = QN
i=2 p(xi), p(X | y) ="
INTRODUCTION,0.014935064935064935,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.015584415584415584,"p(x1 | y) QN
i=2 p(xi), and p(X) = QN
i=1 p(xi). The InfoNCE with score function f(x, y) is"
INTRODUCTION,0.016233766233766232,"IInfoNCE(X1 ; Y ) = Ep(y) """
INTRODUCTION,0.016883116883116882,"Ep(X|y) "" ln"
INTRODUCTION,0.01753246753246753,"f(x1, y)"
"N
PN",0.01818181818181818,"1
N
PN
i=1 f(xi, y) !## ,
(2)"
"N
PN",0.01883116883116883,"using the factor 1/N as in Poole et al. (2019); Tschannen et al. (2019); Cheng et al. (2020); Chen
et al. (2021). For f(x, y) = p(y | x), we obtain the InfoNCE with probabilities. The InfoNCE is a
lower bound on the mutual information (Poole et al., 2019), which is stated in the next theorem.
Theorem 1 (InfoNCE lower bound). InfoNCE with score function f(x, y) is a lower bound on the
mutual information:"
"N
PN",0.01948051948051948,"I(X1 ; Y ) ≥Ep(y) """
"N
PN",0.02012987012987013,"Ep(X|y) "" ln"
"N
PN",0.02077922077922078,"f(x1, y)"
"N
PN",0.02142857142857143,"1
N
PN
i=1 f(xi, y) !##"
"N
PN",0.02207792207792208,"= IInfoNCE(X1 ; Y ) .
(3)"
"N
PN",0.022727272727272728,"In particular, the bound holds for InfoNCE with probabilities, i.e. for f(x, y) = p(y | x)."
"N
PN",0.023376623376623377,For a proof see Poole et al. (2019) and the proof of Theorem A1 in the Appendix.
"N
PN",0.024025974025974027,"The “Leave one out upper bound” (Poole et al., 2019) on the mutual information was called “L1Out”
in Cheng et al. (2020), while we call it “InfoLOOB” (LOOB for “Leave One Out Bound”). InfoLOOB
is the same as InfoNCE (Eq. (3)), but without the positive sample x1 in the denominator. Contrastive
Log-ratio Upper Bound (CLUB), another upper bound on the mutual information, was only used for
minimizing it (Cheng et al., 2020). Maximizing CLUB failed in experiments, because the embedding
distribution was not uniform as known for similar objectives (Wang & Liu, 2021). Uniform embedding
distributions are required for successful contrastive learning (Wang & Isola, 2020)."
"N
PN",0.024675324675324677,"We use InfoLOOB as an objective, since it approximates high mutual information better than InfoNCE.
Maximizing an upper bound on the mutual information might be counter-intuitive. Therefore, we
justify the maximization of the InfoLOOB bound for contrastive learning in Appendix Section A.1.3.
We show that maximizing the InfoLOOB bound approximates the mutual information, the better
the higher it is. Recently, InfoLOOB was independently introduced for and successfully applied to
image-to-image contrastive learning (Yeh et al., 2021)."
"N
PN",0.025324675324675326,"The InfoLOOB with score function f(x, y) is deﬁned in the following, where we obtain the In-
foLOOB with probabilities for f(x, y) = p(y | x):"
"N
PN",0.025974025974025976,"IInfoLOOB(X1 ; Y ) = Ep(y) """
"N
PN",0.026623376623376622,"E˜p(X|y) "" ln"
"N
PN",0.02727272727272727,"f(x1, y)"
"N
PN",0.02792207792207792,"1
N−1
PN
i=2 f(xi, y) !## .
(4)"
"N
PN",0.02857142857142857,"Before we show that InfoLOOB with a score function is an upper bound on the mutual information,
we need some deﬁnitions. ˜p(x | y) draws the positives for y with lower probability than p(x), that
is, the positives are under-sampled. Z(y) = E˜p(x|y) [f(x, y)] gives the average score f(x, y), if
under-sampling via ˜p(x | y), while Z∗(y) = Ep(x) [f(x, y)] average score f(x, y) if sampling
from p(x). We deﬁne the variational distribution q(x | y) = p(x)f(x,y)"
"N
PN",0.02922077922077922,"Z∗(y)
. Our main assumption is
expressed by the log-ratio of the averages Z(y) and Z∗(y):"
"N
PN",0.02987012987012987,"Ep(y) [KL(p(x | y) ∥q(x | y))] ⩽Ep(y) [ln Z∗(y) −ln Z(y)] ,
(5)"
"N
PN",0.03051948051948052,"which ensures that the positives x are sufﬁciently under-sampled via p(x | y). The Kullback-Leibler
divergence gives the minimal difference between averaging f(x, y) via p(x) and via ˜p(x | y). The
next theorem shows that InfoLOOB is an upper bound on the mutual information."
"N
PN",0.03116883116883117,"Theorem 2 (InfoLOOB upper bound). If ˜X = {x2, . . . , xN} are drawn iid according to ˜p(x | y)
and if the main assumption Eq. (5) holds, then InfoLOOB with score function f(x, y) is an upper
bound on the mutual information:"
"N
PN",0.031818181818181815,"I(X1 ; Y ) ⩽Ep(y) """
"N
PN",0.032467532467532464,"E˜p(X|y) "" ln"
"N
PN",0.033116883116883114,"f(x1, y)"
"N
PN",0.033766233766233764,"1
N−1
PN
i=2 f(xi, y) !##"
"N
PN",0.03441558441558441,"= IInfoLOOB(X1 ; Y ) .
(6)"
"N
PN",0.03506493506493506,"The bound is valid for InfoLOOB with probabilities (without under-sampling), where the negative
samples ˜X = {x2, . . . , xN} are drawn iid according to p(x) and f(x, y) = p(y | x)."
"N
PN",0.03571428571428571,The proof for this theorem is given as proof for Theorem A2 in the Appendix.
"N
PN",0.03636363636363636,Under review as a conference paper at ICLR 2022
"N
PN",0.03701298701298701,"Loss functions and their gradients. The training set {(x1, y1), (x2, y2), . . . , (xN, yN)} consists
of N samples that are drawn iid from p(x, y). InfoNCE uses the matrix X = (x1, . . . , xN), while
InfoLOOB uses ˜
X = (x2, . . . , xN). The matrices differ by the positive sample x1. For the score
function f(x, y), we use f(x, y) = exp(τ −1sim(x, y)) with the similarity sim(x, y) = yT x and
τ as the temperature. We have the InfoNCE and InfoLOOB loss functions:"
"N
PN",0.03766233766233766,"LInfoNCE = −1 N N
X"
"N
PN",0.03831168831168831,"i=1
ln
exp(τ −1 xT
i yi)
PN
j=1 exp(τ −1 xT
i yj)
−1 N N
X"
"N
PN",0.03896103896103896,"i=1
ln
exp(τ −1 xT
i yi)
PN
j=1 exp(τ −1 xT
j yi)
,
(7)"
"N
PN",0.03961038961038961,"LInfoLOOB = −1 N N
X"
"N
PN",0.04025974025974026,"i=1
ln
exp(τ −1 xT
i yi)
PN
j̸=i exp(τ −1 xT
i yj)
−1 N N
X"
"N
PN",0.04090909090909091,"i=1
ln
exp(τ −1 xT
i yi)
PN
j̸=i exp(τ −1 xT
j yi)
.
(8)"
"N
PN",0.04155844155844156,"In the second sum of the losses in Eq. 7 and Eq. 8, we consider only the ﬁrst term. For simplicity, we
abbreviate y = y1 leading to the pair (x1, y) and the negatives ˜
X = (x2, . . . , xN)."
"N
PN",0.04220779220779221,"LInfoNCE(y) = −ln
exp(τ −1 xT
1 y)
PN
j=1 exp(τ −1 xT
j y)
,
LInfoLOOB(y) = −ln
exp(τ −1 xT
1 y)
PN
j=2 exp(τ −1 xT
j y)
."
"N
PN",0.04285714285714286,"These loss terms can be simpliﬁed to LInfoNCE(y) = −τ −1yT x1 + τ −1lse(τ −1, XT y) and
LInfoLOOB(y) = −τ −1yT x1 + τ −1lse(τ −1, ˜
XT y), where lse is the log-sum-exp function
(see Eq. (A103) in the Appendix).
The gradient of the InfoNCE loss with respect to y is
−τ −1x1 + τ −1Xsoftmax(τ −1XT y) and the gradient of the InfoLOOB loss is −τ −1x1 +
τ −1 ˜
Xsoftmax(τ −1 ˜
XT y). Using p = (p1, . . . , pN)T = softmax(τ −1XT y), the gradient of
InfoNCE with respect to y is −τ −1(1 −p1)(x1 −˜
Xsoftmax(τ −1 ˜
XT y)) and its gradient with
respect to x1 is −τ −1(1 −p1)y (see Appendix Subsection A.1.4)."
"N
PN",0.04350649350649351,"By and large, the gradient of InfoNCE is scaled by (1 −p1) compared to the gradient of InfoLOOB,
where p1 is softmax similarity between the anchor y and positive sample x1. Consequently, InfoNCE
saturates and learning stalls when anchor and positive sample become similar to each other."
"N
PN",0.04415584415584416,"3
CLOOB: INFOLOOB WITH MODERN HOPFIELD NETWORKS"
"N
PN",0.044805194805194806,"x1
x2
· · ·
xN"
"N
PN",0.045454545454545456,"Ux1 Ux2
· · · UxN"
"N
PN",0.046103896103896105,"x1
x2
· · ·
xN"
"N
PN",0.046753246753246755,"Vx1 Vx2
· · · VxN"
"N
PN",0.047402597402597405,"y1
y2
· · ·
yN"
"N
PN",0.048051948051948054,"Uy1 Uy2
· · · UyN"
"N
PN",0.048701298701298704,"y1
y2
· · ·
yN"
"N
PN",0.04935064935064935,"Vy1 Vy2
· · · VyN"
"N
PN",0.05,"Hopﬁeld retrieval with U
Hopﬁeld retrieval with V"
"N
PN",0.05064935064935065,"Hopﬁeld retrieval with U
Hopﬁeld retrieval with V ≃
≃
≃ ≃
≃
≃"
"N
PN",0.0512987012987013,"image
encoder"
"N
PN",0.05194805194805195,"text
encoder"
"N
PN",0.052597402597402594,"Our dog is
playing in
the snow. ≃"
"N
PN",0.053246753246753244,legend
"N
PN",0.05389610389610389,similarity to anchor
"N
PN",0.05454545454545454,positive sample
"N
PN",0.05519480519480519,negative sample
"N
PN",0.05584415584415584,"Figure 1: The CLOOB architecture for image-text pairs. The image embedding xi and the text em-
bedding yi retrieve the embeddings Uxi and Uyi, respectively, from a modern Hopﬁeld network that
stores image embeddings U = (u1, . . . , uM) (green boxes at the left). The image-retrieved image
embedding Uxi serves as anchor in order to contrast the positive text-retrieved image embedding
Uyi with the negative text-retrieved image embedding Uyj for j ̸= i. Analog, for the second modern
Hopﬁeld network that stores text embeddings V = (v1, . . . , vK) (green boxes at the right)."
"N
PN",0.05649350649350649,Under review as a conference paper at ICLR 2022
"N
PN",0.05714285714285714,"CLOOB for contrastive learning. Our novel Contrastive Leave One Out Boost (CLOOB) combines
the InfoLOOB objective with modern Hopﬁeld networks. Modern Hopﬁeld networks substitute
the original by retrieved embeddings, thereby reduce the variance of InfoLOOB and reinforce the
covariance structure in the data. Figure 1 sketches the CLOOB architecture for image-text pairs."
"N
PN",0.05779220779220779,"The training set consists of N pairs of embeddings {(x1, y1), . . . , (xN, yN)}, M stored embeddings
U = (u1, . . . , uM), and K stored embeddings V = (v1, . . . , vK). The state or query embeddings
xi and yi retrieve Uxi and Uyi, respectively, from U — analogous notation for retrievals from V .
All samples are normalized: ∥xi∥= ∥yi∥= ∥ui∥= ∥vi∥= 1. The following vectors are retrieved
from modern Hopﬁeld networks (Ramsauer et al., 2021):"
"N
PN",0.05844155844155844,"Uxi = U softmax(β U T xi) ,
Uyi = U softmax(β U T yi) ,
(9)"
"N
PN",0.05909090909090909,"Vxi = V softmax(β V T xi) ,
Vyi = V softmax(β V T yi)
(10)"
"N
PN",0.05974025974025974,"where Uxi denotes an image-retrieved image embedding, Uyi a text-retrieved image embedding,
Vxi an image-retrieved text embedding and Vyi a text-retrieved text embedding. The hyperparameter
β corresponds to the inverse temperature: β = 0 retrieves the average of the stored pattern, while
large β retrieves the stored pattern that is most similar to the state pattern (query)."
"N
PN",0.06038961038961039,"In InfoLOOB, CLOOB substitutes the embedded samples xi and yi by the retrieved embedded
samples. In the ﬁrst term, xi and yi are substituted by Uxi and Uyi, respectively, while in the second
term by Vxi and Vyi. All retrieved samples are normalized, ∥Uxi∥= ∥Uyi∥= ∥Vxi∥= ∥Vyi∥= 1.
We obtain the InfoLOOB loss function that is used by CLOOB:"
"N
PN",0.06103896103896104,"LInfoLOOB = −1 N N
X"
"N
PN",0.06168831168831169,"i=1
ln
exp(τ −1 U T
xiUyi)
PN
j̸=i exp(τ −1 U T
xiUyj)
−1 N N
X"
"N
PN",0.06233766233766234,"i=1
ln
exp(τ −1 V T
xiVyi)
PN
j̸=i exp(τ −1 V T
xjVyi)
. (11)"
"N
PN",0.06298701298701298,"Modern Hopﬁeld Networks reduce high variance of InfoLOOB. CLOOB uses InfoLOOB as
objective, since it estimates the mutual information (MI) better than InfoNCE, in particular, for large
MI. Cheng et al. (2020, Fig. 1 and Fig. 2) show that InfoLOOB is a better estimator for the MI than
InfoNCE (van den Oord et al., 2018), MINE (Belghazi et al., 2018), and NWJ (Nguyen et al., 2010).
We experimentally conﬁrmed that InfoLOOB better estimates the mutual information than InfoNCE."
"N
PN",0.06363636363636363,"0
1000
2000
3000
4000
steps −4 −2 0 2 4 6 8 10 12 14"
"N
PN",0.06428571428571428,Mutual information
"N
PN",0.06493506493506493,"without Hopﬁeld
MI 10"
"N
PN",0.06558441558441558,True MI
"N
PN",0.06623376623376623,"0
1000
2000
3000
4000
steps −4 −2 0 2 4 6 8 10 12 14"
"N
PN",0.06688311688311688,Mutual information
"N
PN",0.06753246753246753,"with Hopﬁeld
MI 10"
"N
PN",0.06818181818181818,True MI
"N
PN",0.06883116883116883,"0
1000
2000
3000
4000
5000
6000
steps −4 −2 0 2 4 6 8 10 12 14"
"N
PN",0.06948051948051948,Mutual information
"N
PN",0.07012987012987013,"without Hopﬁeld
MI 14"
"N
PN",0.07077922077922078,True MI
"N
PN",0.07142857142857142,"0
1000
2000
3000
4000
5000
6000
steps −4 −2 0 2 4 6 8 10 12 14"
"N
PN",0.07207792207792207,Mutual information
"N
PN",0.07272727272727272,"with Hopﬁeld
MI 14"
"N
PN",0.07337662337662337,True MI
"N
PN",0.07402597402597402,"Figure 2: Variance reduction of InfoLOOB by modern Hopﬁeld networks. From left to right: without
Hopﬁeld for MI 10, with Hopﬁeld for MI 10, without Hopﬁeld for MI 14, with Hopﬁeld for MI 14.
Modern Hopﬁeld networks reduce the variance of the InfoLOOB loss."
"N
PN",0.07467532467532467,"However, InfoLOOB has higher variance than lower bounds on MI like InfoNCE, which considerably
hampers learning (Cheng et al., 2020, Fig. 1 and Fig. 2), see also Appendix Section A.2. The
InfoNCE objective has the form a/(a + b) while InfoLOOB has the form a/b with a giving the
anchor-to-positive similarity and b the average anchor-to-negative similarity. For small b, we observe
high variance and instability of InfoLOOB. Modern Hopﬁeld networks (Ramsauer et al., 2021)
are a remedy for the high variance. Modern Hopﬁeld networks substitute the original patterns by
retrieved patterns, which are an average over the stored patterns. We tested the variance of MI
estimators/bounds on toy tasks, with samples drawn from Gaussian distributions following (Belghazi
et al., 2018; Poole et al., 2019; Cheng et al., 2020). With the InfoLOOB objective, we train deep
learning architectures with and without modern Hopﬁeld networks on top, where the current learning
batch is stored in the modern Hopﬁeld networks. We used training data with mutual information of"
"N
PN",0.07532467532467532,Under review as a conference paper at ICLR 2022
"N
PN",0.07597402597402597,"10 and 14, where the parameters were optimized for the best performance on a validation set. We
test the ﬁnal model on different levels of mutual information. Figure 2 shows that modern Hopﬁeld
networks reduce the variance of the model. The average variances are reduced from 0.67 to 0.33 for
MI 10 and from 1.00 to 0.48 for MI 14 (more details in Appendix A.2)."
"N
PN",0.07662337662337662,"Modern Hopﬁeld Networks amplify the covariance structure in the data. The covariance struc-
ture is extracted by the retrieved embeddings U T
xiUyi and V T
xiVyi. The Jacobian J of the soft-
max p = softmax(βa) is J(βa) = β
 
diag(p) −ppT 
. We deﬁne the weighted covariance
Cov(U), where sample ui is drawn with probability pi, as [Cov(U)]kl =

UJ(βa)U T "
"N
PN",0.07727272727272727,"kl =
β(PM
i=1 piuikuil −PM
i=1 piuik
PM
i=1 piuil). The formula of the weighted covariance differs from
the standard empirical covariance, since the factor 1/M is replaced by pi. Thus ui is sampled with
probability pi instead of being sampled uniformly with probability 1/M."
"N
PN",0.07792207792207792,"We apply the mean value theorem to the softmax function with mean Jacobian matrix Jm(βa) =
R 1
0 J(λβa) dλ. The mean Jacobian Jm(βa) is a symmetric, diagonally dominant, positive semi-
deﬁnite matrix with one eigenvalue of zero for eigenvector 1 and spectral norm bounded by ∥Jm∥2 ⩽
0.5β (see Appendix Lemma A1). We can express U T
xiUyi as (see Appendix Theorem A3):"
"N
PN",0.07857142857142857,"U T
xiUyi = (¯u + Cov(U, xi) xi)T (¯u + Cov(U, yi) yi) ,
(12)"
"N
PN",0.07922077922077922,"where the mean is ¯u = 1/MU1 and the weighted covariances are Cov(U, xi) = UJm(βU T xi)U T
and Cov(U, yi) = UJm(βU T yi)U T . The weighted covariance Cov(U, .) is the covariance if the
stored pattern ui is drawn according to an averaged pi given by Jm(.). When maximizing the dot
product U T
xiUyi, the normalized vectors xi and yi are encouraged to agree on drawing the patterns
ui with the same probability pi in order to generate similar weighted covariance matrices Cov(U, .).
If subsets of U have a strong covariance structure, then it can be exploited to produce large weighted
covariances and, in turn, large dot products of U T
xiUyi. Furthermore, for a large dot product U T
xiUyi,
xi and yi have to be similar to each other to extract the same direction from the covariance matrices.
Above considerations for U T
xiUyi analogously apply to V T
xiVyi."
"N
PN",0.07987012987012987,"We did not use a loss function that contains dot products like U T
xiVyi, because these dot products
have higher variance than the ones we have used. The dot product U T
xiVyi has higher variance, since
it uses M + K stored patterns, whereas U T
xiUyi and V T
xiVyi use M and K, respectively."
"N
PN",0.08051948051948052,"Modern Hopﬁeld Networks can reuse training samples as stored patterns. We use the training
samples as the stored patterns in the modern Hopﬁeld network. Hence, we set ui = xi and vi = yi,
that is, U = X and V = Y . Consequently, we store the learning batch in the modern Hopﬁeld
networks as U and V . In particular this means that xi can retrieve itself from U = X but not from
V = Y . Analogously, yi can retrieve itself from V = Y but not from U = X."
"N
PN",0.08116883116883117,"Modern Hopﬁeld networks allow the usage of retrieved embeddings. After learning, both the
model embeddings x and y as well as the retrieved embeddings Ux, Uy, Vx, and Vy may serve for
the downstream tasks, e.g. for zero-shot transfer learning. When using the retrieved embeddings, the
modern Hopﬁeld networks can store random samples, prototypes, templates, or proprietary samples.
Therefore, particular embedding features can be ampliﬁed according to the task at hand."
"N
PN",0.08181818181818182,"Modern Hopﬁeld networks is a new concept for contrastive learning. In bioinformatics the
covariance structure in a sequence is reinforced by ﬁrst retrieving similar sequences from a database
and then aligning them. Conserved regions are characterized by high local covariance in the alignment
(Dickson & Gloor, 2012; Kreth & Fodor, 2014). Modern Hopﬁeld networks detect high covariances
of embedded features, which is conveyed by the retrieved sample that corresponds to an alignment."
EXPERIMENTS,0.08246753246753247,"4
EXPERIMENTS"
EXPERIMENTS,0.08311688311688312,"On two pretraining datasets, we compare our new CLOOB to CLIP (Radford et al., 2021) with respect
to their capability of zero-shot transfer learning. The ﬁrst dataset, Conceptual Captions (CC) (Sharma
et al., 2018), has a very rich textual description of images but only three million image-text pairs. The
second dataset, a subset of YFCC100M (Thomee et al., 2016), has 15 million image-text pairs but
the textual description is less rich than for CC and often vacuous. For both pretraining datasets, the
downstream zero-shot transfer learning performance is tested on seven image classiﬁcation datasets."
EXPERIMENTS,0.08376623376623377,Under review as a conference paper at ICLR 2022
EXPERIMENTS,0.08441558441558442,"Table 1: Zero-shot results for models trained on CC with ResNet-50 vision encoders for two different
checkpoints. Results are given as mean accuracy over 5 runs. Statistically signiﬁcant results are
shown in bold. CLIP and CLOOB were trained for 31 epochs while CLIP* and CLOOB* were
trained for 128 epochs. In the majority of tasks CLOOB signiﬁcantly outperforms CLIP."
EXPERIMENTS,0.08506493506493507,"Dataset
CLIP
RN-50
CLOOB
RN-50"
EXPERIMENTS,0.08571428571428572,"CLIP*
RN-50
CLOOB*
RN-50"
EXPERIMENTS,0.08636363636363636,"Birdsnap
2.26 ± 0.20
3.06 ± 0.30
2.8 ± 0.16
3.24 ± 0.31
Country211
0.67 ± 0.11
0.67 ± 0.05
0.7 ± 0.04
0.73 ± 0.05
Flowers102
12.56 ± 0.38
13.45 ± 1.19
13.32 ± 0.43
14.36 ± 1.17
GTSRB
7.66 ± 1.07
6.38 ± 2.11
8.96 ± 1.70
7.03 ± 1.22
UCF101
20.98 ± 1.55
22.26 ± 0.72
21.63 ± 0.65
23.03 ± 0.85
Stanford Cars
0.91 ± 0.10
1.23 ± 0.10
0.99 ± 0.16
1.41 ± 0.32
ImageNet
20.33 ± 0.28
23.97 ± 0.15
21.3 ± 0.42
25.67 ± 0.22
ImageNet V2
20.24 ± 0.50
23.59 ± 0.15
21.24 ± 0.22
25.49 ± 0.11"
CONCEPTUAL CAPTIONS PRETRAINING,0.08701298701298701,"4.1
CONCEPTUAL CAPTIONS PRETRAINING"
CONCEPTUAL CAPTIONS PRETRAINING,0.08766233766233766,"Pretraining dataset. The Conceptual Captions (CC) (Sharma et al., 2018) dataset consists of 2.9
million images with high-quality captions. Images and their captions have been gathered via an
automated process from the web and therefore represent a wide variety of content. Raw descriptions
of images are collected from the alt-text HTML attribute. Both images and texts are ﬁltered for high
quality image-text pairs."
CONCEPTUAL CAPTIONS PRETRAINING,0.08831168831168831,"Methods compared. We compare our new CLOOB to CLIP (Radford et al., 2021). The CLOOB
implementation is based on OpenCLIP (Ilharco et al., 2021), which achieves results equivalent to
CLIP on the YFCC dataset (see Section 4.2). OpenCLIP also reports results on the CC dataset.
As CLIP does not train models on CC we report results from this reimplementation as baseline.
Analogously to Radford et al. (2021, Section 2.4), we use the modiﬁed ResNet (He et al., 2016) and
BERT (Devlin et al., 2018; 2019) architectures to encode image and text input. We use the ResNet
encoders ResNet-50, ResNet-101, and ResNet-50x4."
CONCEPTUAL CAPTIONS PRETRAINING,0.08896103896103896,"Hyperparameter selection and learning schedule. We use the hyperparameter values of OpenCLIP,
concretely, a learning rate of 1 × 10−3 and a weight decay of 0.1 for the Adam optimizer (Kingma
et al., 2014) with decoupled weight decay regularization (Loshchilov & Hutter, 2019). Deviating
from OpenCLIP, we use a batch size of 512 due to computational restraints, which did not change the
performance. The learning rate scheduler for all experiments is cosine annealing with warmup and
hard restarts (Loshchilov & Hutter, 2017). We report the hyperparameter τ (default 0.07) from CLIP
as τ −1 of 14.3 to be in the same regime as the hyperparameter β for the modern Hopﬁeld networks.
The main hyperparameter search for CLOOB (also for YFCC pretraining in the next section) was
done with ResNet-50 as the vision encoder. Learnable τ −1 in combination with the InfoLOOB loss
results in undesired learning behavior (see Appendix Section A.1.4). Therefore, we set τ −1 to a ﬁxed
value of 30, which was determined via hyperparameter search (see Appendix Section A.3.2). For
modern Hopﬁeld networks,the hyperparameter β was set to 8. Further we scale the loss in Eq. (11)
with τ to remove the factor τ −1 from the gradients (see Appendix Section A.1.4) resulting in the loss
function τLInfoLOOB."
CONCEPTUAL CAPTIONS PRETRAINING,0.08961038961038961,"Evaluation metrics: Zero-shot transfer learning. We evaluate and compare both CLIP and
CLOOB on their zero-shot transfer learning capabilities on the following downstream image classi-
ﬁcation tasks. Birdsnap (Berg et al., 2014) contains images of 500 different North American bird
species. The Country211 (Radford et al., 2021) dataset consists of photos across 211 countries and
is designed to test the geolocalization capability of visual representations. Flowers102 (Nilsback &
Zisserman, 2008) is a dataset containing images of 102 ﬂower species. GTSRB (Stallkamp et al.,
2011) contains images for classiﬁcation of German trafﬁc signs. UCF101 (Soomro et al., 2012) is a
video dataset with short clips for action recognition. For UCF101 we follow the procedure reported
in CLIP and extract the middle frame of every video to assemble the dataset. Stanford Cars (Krause
et al., 2013) contains images of 196 types of cars. ImageNet (Deng et al., 2009) is a large scale image
classiﬁcation dataset with images across 1,000 classes. ImageNetv2 (Recht et al., 2019) consists of"
CONCEPTUAL CAPTIONS PRETRAINING,0.09025974025974026,Under review as a conference paper at ICLR 2022
CONCEPTUAL CAPTIONS PRETRAINING,0.09090909090909091,"Table 2: Performance with InfoLOOB vs. InfoNCE objective and with vs. without Hopﬁeld retrieval.
InfoLOOB increases the performance of CLIP in most of the tasks. Hopﬁeld with InfoLOOB strongly
improves the performance in 7 out of 8 datasets compared to both CLIP models."
CONCEPTUAL CAPTIONS PRETRAINING,0.09155844155844156,"CLIP
Hopﬁeld
Dataset
InfoNCE
InfoLOOB
InfoNCE
InfoLOOB"
CONCEPTUAL CAPTIONS PRETRAINING,0.09220779220779221,"Birdsnap
1.94
2.37
1.67
2.53
Country211
0.62
0.63
0.54
0.76
Flowers102
13.04
13.03
11.53
14.24
GTSRB
7.28
4.39
5.76
5.86
UCF101
21.00
19.14
20.56
22.29
Stanford Cars
0.90
1.33
1.24
1.37
ImageNet
20.31
22.13
19.04
24.21
ImageNetV2
20.63
21.65
18.97
23.80"
CONCEPTUAL CAPTIONS PRETRAINING,0.09285714285714286,"three new test sets with 10,000 images each for the ImageNet benchmark. For further details see
Appendix Section A.3.3."
CONCEPTUAL CAPTIONS PRETRAINING,0.09350649350649351,"Results. We employ the same evaluation strategy and use the prompt templates as published in CLIP
(see Appendix Section A.3.3). We report zero-shot results from two checkpoints in Table 1. CLIP and
CLOOB were trained for a comparable number of epochs used in CLIP (see Appendix Section A.3.2)
while CLIP* and CLOOB* were trained until evaluation performance plateaued (epoch 128). In both
cases CLOOB signiﬁcantly outperforms CLIP on the majority of tasks or matches its performance.
Statistical signiﬁcance of these results was assessed by an unpaired Wilcoxon test on a 5% level."
CONCEPTUAL CAPTIONS PRETRAINING,0.09415584415584416,"Ablation studies. CLOOB has two new major components compared to CLIP: (1) the InfoLOOB
objective instead of the InfoNCE objective and (2) the modern Hopﬁeld networks. To assess which of
the new major components of CLOOB has led to the performance increase over CLIP, we performed
ablation studies on CC. First, we enhanced CLIP by replacing the InfoNCE objective with InfoLOOB.
Table 2 shows that the InfoLOOB objective increases the performance of CLIP in the majority of
the datasets. The reason is that InfoLOOB suffers less than InfoNCE from the “explaining away”
problem. However, InfoLOOB is more effective for higher mutual information, that is, for a richer
covariance structure. Hopﬁeld networks amplify the covariance structure by retrieved embeddings.
For InfoLOOB, however, this ampliﬁcation is disadvantageous as the saturation effect is increased
by higher similarity between anchor and positive. Thus, combining modern Hopﬁeld networks with
InfoNCE leads to a performance drop. Combining Hopﬁeld and InfoLOOB into CLOOB strongly
improves the performance on 7 out of 8 zero-shot transfer learning tasks. An additional ablation
considers the learning rate scheduler. For more details see in Appendix Section A.3.1."
YFCC PRETRAINING,0.09480519480519481,"4.2
YFCC PRETRAINING"
YFCC PRETRAINING,0.09545454545454546,"Pretraining dataset. To be comparable to the CLIP results, we use the same subset of 15 million
samples from the YFCC100M dataset (Thomee et al., 2016) as in Radford et al. (2021), which we
refer to as YFCC. YFCC was created by ﬁltering YFCC100M for images which contain natural
language descriptions and/or titles in English. It was not ﬁltered by quality of the captions, therefore
the textual descriptions are less rich and contain superﬂuous information. The dataset with 400
million samples used to train the CLIP models in Radford et al. (2021) has not been released and, thus,
is not available for comparison. Due to limited computational resources we are unable to compare
CLOOB to CLIP on other datasets of this size."
YFCC PRETRAINING,0.09610389610389611,"Methods compared and evaluation. In addition to the comparison of CLOOB and CLIP based on
the OpenCLIP reimplementation (Ilharco et al., 2021), we include the original CLIP results (Radford
et al., 2021, Table 12)."
YFCC PRETRAINING,0.09675324675324676,"Hyperparameter selection. We use the hyperparameters selected at the Conceptual Captions dataset,
except learning rate, batch size, and β. For modern Hopﬁeld networks, the hyperparameter β is set
to 14.3, which is the default parameter of τ −1 for the InfoNCE objective in Radford et al. (2021).
Furthermore, the learning rate is set to 5 × 10−4 and a batch size of 1024 as in OpenCLIP of Ilharco
et al. (2021). For further details see Appendix Section A.3.2."
YFCC PRETRAINING,0.09740259740259741,Under review as a conference paper at ICLR 2022
YFCC PRETRAINING,0.09805194805194806,"Evaluation metrics. As in the previous experiment, methods are again evaluated at their zero-shot
transfer learning capabilities on downstream tasks."
YFCC PRETRAINING,0.0987012987012987,"Results. Table 3 provides results of the original CLIP and CLOOB trained on YFCC. The results
on zero-shot downstream tasks show that CLOOB outperforms the results of CLIP on all 7 tasks
(ImageNet V2 results have not been reported in Radford et al. (2021)). Similarly, CLOOB outperforms
CLIP on 6 out of 7 tasks for linear probing. Results of the comparison of CLOOB an the CLIP
reimplementation of OpenCLIP are given in Table 4. CLOOB exceeds the CLIP reimplementation in
7 out of 8 tasks for zero-shot classiﬁcation using ResNet-50 encoders. With larger ResNet encoders,
CLOOB outperforms CLIP on all tasks. Furthermore, the experiments with larger vision encoder
networks show that CLOOB performance increases with network size. Visualizations of predictions
of CLOOB zero-shot classiﬁers from all datasets are shown in Appendix Section A.3.4."
YFCC PRETRAINING,0.09935064935064936,"Table 3: Results of CLIP and CLOOB trained on YFCC with ResNet-50 encoder. Except for one
linear probing dataset, CLOOB consistently outperforms CLIP across all tasks."
YFCC PRETRAINING,0.1,"Linear Probing
Zero-Shot"
YFCC PRETRAINING,0.10064935064935066,"Dataset
CLIP
(OpenAI)
CLOOB
(ours)"
YFCC PRETRAINING,0.1012987012987013,"CLIP
(OpenAI)
CLOOB
(ours)"
YFCC PRETRAINING,0.10194805194805195,"Birdsnap
47.4
56.2
19.9
28.9
Country211
23.1
20.6
5.2
7.9
Flowers102
94.4
96.1
48.6
55.1
GTSRB
66.8
78.9
6.9
8.1
UCF101
69.2
72.3
22.9
25.3
Stanford Cars
31.4
37.7
3.8
4.1
ImageNet
62.0
65.7
31.3
35.7"
YFCC PRETRAINING,0.1025974025974026,"ImageNet V2
-
58.7
-
34.6"
YFCC PRETRAINING,0.10324675324675325,"Table 4: Zero-shot results for the CLIP reimplementation and CLOOB using different ResNet
architectures trained on YFCC. CLOOB outperforms CLIP in 7 out of 8 tasks using ResNet-50
encoders. With larger ResNet encoders CLOOB outperforms CLIP on all tasks. The performance of
CLOOB scales with increased encoder size."
YFCC PRETRAINING,0.1038961038961039,"Dataset
CLIP
RN-50
CLOOB
RN-50"
YFCC PRETRAINING,0.10454545454545454,"CLIP
RN-101
CLOOB
RN-101"
YFCC PRETRAINING,0.10519480519480519,"CLIP
RN-50x4
CLOOB
RN-50x4"
YFCC PRETRAINING,0.10584415584415584,"Birdsnap
21.8
28.9
22.6
30.3
20.8
32.0
Country211
6.9
7.9
7.8
8.5
8.1
9.3
Flowers102
48.0
55.1
48.0
55.3
50.1
54.3
GTSRB
7.9
8.1
7.4
11.6
9.4
11.8
UCF101
27.2
25.3
28.6
28.8
31.0
31.9
Stanford Cars
3.7
4.1
3.8
5.5
3.5
6.1
ImageNet
34.6
35.7
35.3
37.1
37.7
39.0
ImageNet V2
33.4
34.6
34.1
35.6
35.9
37.3"
CONCLUSION,0.10649350649350649,"5
CONCLUSION"
CONCLUSION,0.10714285714285714,"For constrastive learning, we have introduced “Contrastive Leave One Out Boost” (CLOOB), for
which modern Hopﬁeld networks boost learning with the InfoLOOB objective. Modern Hopﬁeld
networks both increase the stability of InfoLOOB and reinforce the covariance structure of the data.
We have shown theoretical properties of the InfoLOOB bound and objective. Our results suggest
InfoLOOB as an alternative to InfoNCE in contrastive learning. An ablation study shows that both,
the InfoLOOB objective and modern Hopﬁeld networks, are necessary to yield high performance. At
seven zero-shot transfer learning tasks, the novel CLOOB is compared to CLIP after pretraining on
Conceptual Captions and the YFCC dataset. CLOOB consistently outperforms CLIP at zero-shot
transfer learning across all considered architectures and datasets."
CONCLUSION,0.10779220779220779,Under review as a conference paper at ICLR 2022
REPRODUCIBILITY STATEMENT,0.10844155844155844,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.10909090909090909,"We will publish the source code after the reviewing period. This will ensure that the results are
reproducible in their entirety. The datasets used for training our models as well as for the downstream
tasks are publicly available."
REPRODUCIBILITY STATEMENT,0.10974025974025974,ETHICAL CONSIDERATIONS
REPRODUCIBILITY STATEMENT,0.11038961038961038,"Impact on ML and related scientiﬁc ﬁelds.
Our research has the potential to positively impact a
wide variety of ﬁelds of life due to its general applicability. Most importantly, it has the potential to
reduce the cost for training other AI systems, which could lead to a reduction of compute costs and
carbon dioxide emissions."
REPRODUCIBILITY STATEMENT,0.11103896103896103,"However, any new development in machine learning can be applied for good or for bad. Our system
can be used for medical applications where it could save lives but might also be used for surveillance
and malevolent systems."
REPRODUCIBILITY STATEMENT,0.11168831168831168,"Impact on society.
A potential danger could arise from an application of our approach in which
users rely overly on the outcomes. For example, in a medical setting, physicians might rely on the
technical system and shift the liability towards the machine. This might also happen in the domain of
self-driving cars, when drivers start paying less attention to the trafﬁc because of an AI-based driving
system. Finally, our method may also be deployed in companies to automate various simple tasks,
which might lead to a reduced need for particular jobs in production systems."
REPRODUCIBILITY STATEMENT,0.11233766233766233,"Consequences of failures of the method.
Depending on the application area, a failure of this
method might be of lesser concern, such as a failed execution of a computer program. If our method is
employed within a larger automation system, a failure could result in damages such as a car accident
or errors of a production system. However, this holds for almost all machine learning methods, and
their usage and testing depends on the application area."
REPRODUCIBILITY STATEMENT,0.11298701298701298,"Leveraging of biases in the data and potential discrimination.
Our proposed method relies
on human-annotated data and thereby human decisions, which are usually strongly biased. The
undesirable biases contained in dataset are learned and may propagate to downstream applications.
Therefore, the responsible use of our method depends on a careful selection of the training data and
awareness of the potential biases within those."
REFERENCES,0.11363636363636363,REFERENCES
REFERENCES,0.11428571428571428,"L. F. Abbott and Y. Arian. Storage capacity of generalized networks. Phys. Rev. A, 36:5091–5094,
1987. doi: 10.1103/PhysRevA.36.5091."
REFERENCES,0.11493506493506493,"S. Agarwal, G. Krueger, J. Clark, A. Radford, J. W. Kim, and M. Brundage. Evaluating CLIP: towards
characterization of broader capabilities and downstream implications. ArXiv, 2108.02818, 2021."
REFERENCES,0.11558441558441558,"P. Baldi and S. S. Venkatesh. Number of stable points for spin-glasses and neural networks of higher
orders. Phys. Rev. Lett., 58:913–916, 1987. doi: 10.1103/PhysRevLett.58.913."
REFERENCES,0.11623376623376623,"D. Bau, A. Andonian, A. Cui, Y Park, A. Jahanian, A. Oliva, and A. Torralba. Paint by word. arXiv
preprint arXiv:2103.10951, 2021."
REFERENCES,0.11688311688311688,"M. I. Belghazi, A. Baratin, S. Rajeswar, S. Ozair, Y. Bengio, A. Courville, and R. D. Hjelm. Mutual
information neural estimation. In J. Dy and A. Krause (eds.), Proceedings of the 35th International
Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp.
531–540. PMLR, 2018."
REFERENCES,0.11753246753246753,"T. Berg, J. Liu, S. W. Lee, M. L. Alexander, D. W. Jacobs, and P. N. Belhumeur. Birdsnap: Large-scale
ﬁne-grained visual categorization of birds. In Proc. Conf. Computer Vision and Pattern Recognition
(CVPR), pp. 2019–2026, 2014. doi: 10.1109/CVPR.2014.259."
REFERENCES,0.11818181818181818,"R. Bommasani et al. On the opportunities and risks of foundation models. ArXiv, 2108.07258, 2021."
REFERENCES,0.11883116883116883,Under review as a conference paper at ICLR 2022
REFERENCES,0.11948051948051948,"Q. Cai, Y. Wang, Y. Pan, T. Yao, and T. Mei. Joint contrastive learning with inﬁnite possibilities.
In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (eds.), Advances in Neural
Information Processing Systems, volume 33, pp. 12638–12648. Curran Associates, Inc., 2020."
REFERENCES,0.12012987012987013,"B. Caputo and H. Niemann. Storage capacity of kernel associative memories. In Proceedings of the
International Conference on Artiﬁcial Neural Networks (ICANN), pp. 51–56, Berlin, Heidelberg,
2002. Springer-Verlag."
REFERENCES,0.12077922077922078,"N. Carlini and A. Terzis. Poisoning and backdooring contrastive learning. ArXiv, 2106.09667, 2021."
REFERENCES,0.12142857142857143,"H. H. Chen, Y. C. Lee, G. Z. Sun, H. Y. Lee, T. Maxwell, and C. Lee Giles. High order correlation
model for associative memory. AIP Conference Proceedings, 151(1):86–99, 1986. doi: 10.1063/1.
36224."
REFERENCES,0.12207792207792208,"J. Chen, Z. Gan, X. Li, Q. Guo, L. Chen, S. Gao, T. Chung, Y. Xu, B. Zeng, W. Lu, F. Li, L. Carin, and
C. Tao. Simpler, faster, stronger: Breaking the log-K curse on contrastive learners with FlatNCE.
arXiv, 2107.01152, 2021."
REFERENCES,0.12272727272727273,"T. Chen, Y. Sun, Y. Shi, and L. Hong. On sampling strategies for neural network-based collaborative
ﬁltering. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pp. 767–776, New York, NY, USA, 2017. Association for Computing
Machinery. doi: 10.1145/3097983.3098202."
REFERENCES,0.12337662337662338,"T. Chen, S. Kornblith, M. Norouzi, and G. Hinton. A simple framework for contrastive learning of
visual representations. In H. Daumé and A. Singh (eds.), Proceedings of the 37th International
Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp.
1597–1607. PMLR, 2020."
REFERENCES,0.12402597402597403,"X. Chen and K. He. Exploring simple siamese representation learning. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 15750–15758,
2021."
REFERENCES,0.12467532467532468,"P. Cheng, W. Hao, S. Dai, J. Liu, Z. Gan, and L. Carin. CLUB: A contrastive log-ratio upper bound
of mutual information. In H. Daume and A. Singh (eds.), Proceedings of the 37th International
Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp.
1779–1788. PMLR, 2020."
REFERENCES,0.1253246753246753,"A. D’Amour et al. Underspeciﬁcation presents challenges for credibility in modern machine learning.
ArXiv, 2011.03395, 2020."
REFERENCES,0.12597402597402596,"J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical
image database. In 2009 IEEE conference on computer vision and pattern recognition, pp. 248–255.
Ieee, 2009."
REFERENCES,0.1266233766233766,"B. Devillers, R. Bielawski, B. Choski, and R. VanRullen. Does language help generalization in vision
models? ArXiv, 2104.08313, 2021."
REFERENCES,0.12727272727272726,"J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: pre-training of deep bidirectional
transformers for language understanding. ArXiv, 2018."
REFERENCES,0.1279220779220779,"J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: pre-training of deep bidirectional trans-
formers for language understanding. In Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume
1 (Long and Short Papers), pp. 4171–4186. Association for Computational Linguistics, 2019. doi:
10.18653/v1/N19-1423."
REFERENCES,0.12857142857142856,"R. J. Dickson and G. B. Gloor. Protein sequence alignment analysis by local covariation: coevolution
statistics detect benchmark alignment errors. PLoS One, 7(6):e37645, 2012. doi: 10.1371/journal.
pone.0037645."
REFERENCES,0.1292207792207792,"H. Fang, P. Xiong, L. Xu, and Y. Chen. CLIP2Video: mastering video-text retrieval via image CLIP.
ArXiv, 2106.11097, 2021."
REFERENCES,0.12987012987012986,Under review as a conference paper at ICLR 2022
REFERENCES,0.1305194805194805,"K. Frans, L. B. Soros, and O. Witkowski. CLIPDraw: exploring text-to-drawing synthesis through
language-image encoders. ArXiv, 2106.14843, 2021."
REFERENCES,0.13116883116883116,"F. A. Galatolo, M. G. C. A. Cimino, and G. Vaglini. Generating images from caption and vice versa
via CLIP-guided generative latent space search. ArXiv, 2102.01645, 2021."
REFERENCES,0.1318181818181818,"B. Gao and L. Pavel. On the properties of the softmax function with application in game theory and
reinforcement learning. ArXiv, 2017."
REFERENCES,0.13246753246753246,"T. Gao, X. Yao, and D. Chen. SimCSE: simple contrastive learning of sentence embeddings. ArXiv,
2104.08821, 2021."
REFERENCES,0.1331168831168831,"E. Gardner. Multiconnected neural network models. Journal of Physics A, 20(11):3453–3464, 1987.
doi: 10.1088/0305-4470/20/11/046."
REFERENCES,0.13376623376623376,"R. Geirhos, J.-H. Jacobsen, C. Michaelis, R. S. Zemel, W. Brendel, M. Bethge, and F. A. Wichmann.
Shortcut learning in deep neural networks. ArXiv, 2004.07780, 2020."
REFERENCES,0.1344155844155844,"J.-B. Grill, F. Strub, F. Altché, C. Tallec, P. H. Richemond, E. Buchatskaya, C. Doersch, B. Ávila Pires,
Z. D. Guo, M. Gheshlaghi Azar, B. Piot, K. Kavukcuoglu, R. Munos, and M. Valko. Bootstrap your
own latent - a new approach to self-supervised learning. In H. Larochelle, M. Ranzato, R. Hadsell,
M. F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33,
pp. 21271–21284. Curran Associates, Inc., 2020."
REFERENCES,0.13506493506493505,"M. Gutmann and A. Hyvärinen. Noise-contrastive estimation: A new estimation principle for unnor-
malized statistical models. In Y. W. Teh and M. Titterington (eds.), Proceedings of the Thirteenth
International Conference on Artiﬁcial Intelligence and Statistics, volume 9 of Proceedings of
Machine Learning Research, pp. 297–304. JMLR Workshop and Conference Proceedings, 2010."
REFERENCES,0.1357142857142857,"T. Han, W. Xie, and A. Zisserman. Self-supervised co-training for video representation learning.
In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (eds.), Advances in Neural
Information Processing Systems, volume 33, pp. 5679–5690. Curran Associates, Inc., 2020."
REFERENCES,0.13636363636363635,"K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016."
REFERENCES,0.137012987012987,"K. He, H. Fan, Y. Wu, S. Xie, and R. B. Girshick. Momentum contrast for unsupervised visual
representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), 2020."
REFERENCES,0.13766233766233765,"O. J. Hénaff, A. Srinivas, J. DeFauw, A. Razavi, C. Doersch, S. M. A. Eslami, and A. vanDenOord.
Data-efﬁcient image recognition with contrastive predictive coding. ArXiv, 1905.09272, 2019."
REFERENCES,0.1383116883116883,"M. L. Henderson, R. Al-Rfou, B. Strope, Y.-H. Sung, L. Lukács, R. Guo, S. Kumar, B. Miklos, and
R. Kurzweil. Efﬁcient natural language response suggestion for smart reply. ArXiv, 1705.00652,
2017."
REFERENCES,0.13896103896103895,"J. J. Hopﬁeld. Neural networks and physical systems with emergent collective computational abilities.
Proceedings of the National Academy of Sciences, 79(8):2554–2558, 1982."
REFERENCES,0.1396103896103896,"J. J. Hopﬁeld. Neurons with graded response have collective computational properties like those of
two-state neurons. Proceedings of the National Academy of Sciences, 81(10):3088–3092, 1984.
doi: 10.1073/pnas.81.10.3088."
REFERENCES,0.14025974025974025,"D. Horn and M. Usher. Capacities of multiconnected memory models. J. Phys. France, 49(3):
389–395, 1988. doi: 10.1051/jphys:01988004903038900."
REFERENCES,0.1409090909090909,"G. Ilharco, M. Wortsman, N. Carlini, R. Taori, A. Dave, V. Shankar, H. Namkoong, J. Miller,
H. Hajishirzi, A. Farhadi, and L. Schmidt. OpenCLIP, 2021."
REFERENCES,0.14155844155844155,"D. P. Kingma, S. Mohamed, D .J. Rezende, and M. Welling. Semi-supervised learning with deep gen-
erative models. In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger
(eds.), Advances in Neural Information Processing Systems 27, pp. 3581–3589. Curran Associates,
Inc., 2014."
REFERENCES,0.1422077922077922,Under review as a conference paper at ICLR 2022
REFERENCES,0.14285714285714285,"J. Krause, M. Stark, J. Deng, and L. Fei-Fei. 3D object representations for ﬁne-grained categorization.
In 4th International IEEE Workshop on 3D Representation and Recognition (3dRR-13), 2013."
REFERENCES,0.1435064935064935,"K. E. Kreth and A. A. Fodor. Covariance in protein multiple sequence alignments using groups of
columns. ArXiv, 1401.1141, 2014."
REFERENCES,0.14415584415584415,"D. Krotov and J. J. Hopﬁeld. Dense associative memory for pattern recognition. In D. D. Lee,
M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett (eds.), Advances in Neural Information
Processing Systems, pp. 1172–1180. Curran Associates, Inc., 2016."
REFERENCES,0.1448051948051948,"C. H. Lampert, H. Nickisch, and S. Harmeling. Learning to detect unseen object classes by between-
class attribute transfer. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
pp. 951–958. IEEE, 2009."
REFERENCES,0.14545454545454545,"S. Lapuschkin, S. Wäldchen, A. Binder, G. Montavon, W. Samek, and K.-R. Müller. Unmasking
Clever Hans predictors and assessing what machines really learn. Nature Communications, 10,
2019. doi: 10.1038/s41467-019-08987-4."
REFERENCES,0.1461038961038961,"J. Li, P. Zhou, C. Xiong, R. Socher, and S. C. H. Hoi. Prototypical contrastive learning of unsupervised
representations. In International Conference on Learning Representations (ICLR), 2021. URL
https://openreview.net/forum?id=KmykpuSrjcq. ArXiv 2005.04966."
REFERENCES,0.14675324675324675,"L. Logeswaran and H. Lee. An efﬁcient framework for learning sentence representations. In
Sixth International Conference on Learning Representations (ICLR), 2018. URL https://
openreview.net/forum?id=rJvJXZb0W. ArXiv 1803.02893."
REFERENCES,0.1474025974025974,"I. Loshchilov and F. Hutter.
SGDR: stochastic gradient descent with warm restarts.
In 5th
International Conference on Learning Representations ICLR. OpenReview.net, 2017.
URL
https://openreview.net/forum?id=Skq89Scxx."
REFERENCES,0.14805194805194805,"I. Loshchilov and F. Hutter. Decoupled weight decay regularization. In International Conference
on Learning Representations (ICLR), 2019. URL https://openreview.net/forum?id=
Bkg6RiCqY7."
REFERENCES,0.1487012987012987,"H. Luo, L. Ji, M. Zhong, Y. Chen, W. Lei, N. Duan, and T. Li. CLIP4Clip: an empirical study of
CLIP for end to end video clip retrieval. ArXiv, 2104.08860, 2021."
REFERENCES,0.14935064935064934,"D. McAllester and K. Stratos. Formal limitations on the measurement of mutual information. ArXiv,
1811.04251, 2018."
REFERENCES,0.15,"D. McAllester and K. Stratos. Formal limitations on the measurement of mutual information. In Silvia
Chiappa and Roberto Calandra (eds.), Proceedings of the Twenty Third International Conference
on Artiﬁcial Intelligence and Statistics, volume 108 of Proceedings of Machine Learning Research,
pp. 875–884. PMLR, 26–28 Aug 2020. URL https://proceedings.mlr.press/v108/
mcallester20a.html."
REFERENCES,0.15064935064935064,"T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words
and phrases and their compositionality. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani,
and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems, volume 26, pp.
3111–3119. Curran Associates, Inc., 2013."
REFERENCES,0.1512987012987013,"T. Milbich, K. Roth, S. Sinha, L. Schmidt, M. Ghassemi, and B. Ommer. Characterizing generalization
under out-of-distribution shifts in deep metric learning. ArXiv, 2107.09562, 2021."
REFERENCES,0.15194805194805194,"J. Miller, R. Taori, A. Raghunathan, S. Sagawa, P. W. Koh, V. Shankar, P. Liang, Y. Carmon, and
L. Schmidt. Accuracy on the line: On the strong correlation between out-of-distribution and
in-distribution generalization. ArXiv, 2107.04649, 2021."
REFERENCES,0.1525974025974026,"I. Misra and L. vanDerMaaten. Self-supervised learning of pretext-invariant representations. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
2020."
REFERENCES,0.15324675324675324,"M. Narasimhan, A. Rohrbach, and T. Darrell. CLIP-It! language-guided video summarization. ArXiv,
2107.00650, 2021."
REFERENCES,0.1538961038961039,Under review as a conference paper at ICLR 2022
REFERENCES,0.15454545454545454,"X. Nguyen, M. J. Wainwright, and M. Jordan. Estimating divergence functionals and the likelihood
ratio by penalized convex risk minimization. IEEE Transactions on Information Theory, 56(11):
5847–5861, 2010. doi: 10.1109/tit.2010.2068870."
REFERENCES,0.1551948051948052,"M.-E. Nilsback and A. Zisserman. Automated ﬂower classiﬁcation over a large number of classes.
In Proceedings of the 2008 Sixth Indian Conference on Computer Vision, Graphics and Image
Processing, pp. 722–729. IEEE Computer Society, 2008. doi: 10.1109/ICVGIP.2008.47."
REFERENCES,0.15584415584415584,"F. W. J. Olver, D. W. Lozier, R. F. Boisvert, and C. W. Clark. NIST handbook of mathematical
functions. Cambridge University Press, 1 pap/cdr edition, 2010. ISBN 9780521192255."
REFERENCES,0.1564935064935065,"D. Pakhomov, S. Hira, N. Wagle, K. E. Green, and N. Navab. Segmentation in style: Unsupervised
semantic image segmentation with stylegan and CLIP. ArXiv, 2107.12518, 2021."
REFERENCES,0.15714285714285714,"B. Poole, S. Ozair, A. vanDenOord, A. A. Alemi, and G. Tucker. On variational bounds of mutual
information. In K. Chaudhuri and R. Salakhutdinov (eds.), Proceedings of the 36th International
Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp.
5171–5180. PMLR, 2019."
REFERENCES,0.1577922077922078,"D. Psaltis and H. P. Cheol. Nonlinear discriminant functions and associative memories. AIP
Conference Proceedings, 151(1):370–375, 1986. doi: 10.1063/1.36241."
REFERENCES,0.15844155844155844,"A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin,
J. Clark, G. Krueger, and I. Sutskever. Learning transferable visual models from natural language
supervision. In Proceedings of the 38th International Conference on Machine Learning (ICML),
2021."
REFERENCES,0.1590909090909091,"H. Ramsauer, B. Schäﬂ, J. Lehner, P. Seidl, M. Widrich, L. Gruber, M. Holzleitner, M. Pavlovi´c, G. K.
Sandve, V. Greiff, D. Kreil, M. Kopp, G. Klambauer, J. Brandstetter, and S. Hochreiter. Hopﬁeld
networks is all you need. ArXiv, 2008.02217, 2020."
REFERENCES,0.15974025974025974,"H. Ramsauer, B. Schäﬂ, J. Lehner, P. Seidl, M. Widrich, L. Gruber, M. Holzleitner, M. Pavlovi´c, G. K.
Sandve, V. Greiff, D. Kreil, M. Kopp, G. Klambauer, J. Brandstetter, and S. Hochreiter. Hopﬁeld
networks is all you need. In 9th International Conference on Learning Representations (ICLR),
2021. URL https://openreview.net/forum?id=tL89RnzIiCd."
REFERENCES,0.1603896103896104,"B. Recht, R. Roelofs, L. Schmidt, and V. Shankar. Do ImageNet classiﬁers generalize to ImageNet?
In K. Chaudhuri and R. Salakhutdinov (eds.), Proceedings of the 36th International Conference
on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp. 5389–5400.
PMLR, 2019."
REFERENCES,0.16103896103896104,"P. Seidl, P. Renz, N. Dyubankova, P. Neves, J. Verhoeven, J. K. Wegner, S. Hochreiter, and G. Klam-
bauer. Modern hopﬁeld networks for few- and zero-shot reaction prediction. ArXiv, 2104.03279,
2021."
REFERENCES,0.1616883116883117,"P. Sharma, N. Ding, S. Goodman, and R. Soricut. Conceptual captions: A cleaned, hypernymed,
image alt-text dataset for automatic image captioning. In Proceedings of ACL, 2018."
REFERENCES,0.16233766233766234,"S. Shen, L. H. Li, H. Tan, M. Bansal, A. Rohrbach, K.-W. Chang, Z. Yao, and K. Keutzer. How much
can CLIP beneﬁt vision-and-language tasks? ArXiv, 2107.06383, 2021."
REFERENCES,0.16298701298701299,"K. Soomro, A. R. Zamir, and M. Shah. A dataset of 101 human action classes from videos in the
wild. Center for Research in Computer Vision, 2(11), 2012."
REFERENCES,0.16363636363636364,"J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The German trafﬁc sign recognition benchmark:
A multi-class classiﬁcation competition. The 2011 International Joint Conference on Neural
Networks, pp. 1453–1460, 2011."
REFERENCES,0.16428571428571428,"R. Taori, A. Dave, V. Shankar, N. Carlini, B. Recht, and L. Schmidt. Measuring robustness to
natural distribution shifts in image classiﬁcation. In H. Larochelle, M. Ranzato, R. Hadsell, M. F.
Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp.
18583–18599. Curran Associates, Inc., 2020."
REFERENCES,0.16493506493506493,Under review as a conference paper at ICLR 2022
REFERENCES,0.16558441558441558,"B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and L.-J. Li.
YFCC100M: The new data in multimedia research. Commun. ACM, 59(2):64–73, 2016. doi:
10.1145/2812802."
REFERENCES,0.16623376623376623,"Y.-H. H. Tsai, M. Q. Ma, H. Zhao, K. Zhang, L.-P. Morency, and R. Salakhutdinov. Conditional
contrastive learning: Removing undesirable information in self-supervised representations. ArXiv,
2106.02866, 2021."
REFERENCES,0.16688311688311688,"M. Tschannen, J. Djolonga, P. K. Rubenstein, S. Gelly, and M. Lucic.
On mutual informa-
tion maximization for representation learning.
arXiv, 1907.13625, 2019.
URL https:
//openreview.net/forum?id=rkxoh24FPH. 8th International Conference on Learning
Representations (ICLR)."
REFERENCES,0.16753246753246753,"A. van den Oord, Y. Li, and O. Vinyals. Representation learning with contrastive predictive coding.
ArXiv, 1807.03748, 2018."
REFERENCES,0.16818181818181818,"M. J. Wainwright. Basic tail and concentration bounds, pp. 21–57. Cambridge Series in Statistical and
Probabilistic Mathematics. Cambridge University Press, 2019. doi: 10.1017/9781108627771.002."
REFERENCES,0.16883116883116883,"F. Wang and H. Liu. Understanding the behaviour of contrastive loss. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2495–2504, 2021."
REFERENCES,0.16948051948051948,"T. Wang and P. Isola. Understanding contrastive representation learning through alignment and
uniformity on the hypersphere. In Proceedings of the 37th International Conference on Machine
Learning (ICML), 2020."
REFERENCES,0.17012987012987013,"M. P. Wellman and M. Henrion. Explaining ’explaining away’. IEEE Trans. Pattern Anal. Mach.
Intell., 15(3):287–292, 1993. doi: 10.1109/34.204911."
REFERENCES,0.17077922077922078,"M. Widrich, B. Schäﬂ, M. Pavlovi´c, H. Ramsauer, L. Gruber, M. Holzleitner, J. Brandstetter, G. K.
Sandve, V. Greiff, S. Hochreiter, and G. Klambauer. Modern Hopﬁeld networks and attention for
immune repertoire classiﬁcation. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and
H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 18832–18845.
Curran Associates, Inc., 2020."
REFERENCES,0.17142857142857143,"M. Wortsman, G. Ilharco, M. Li, J. W. Kim, H. Hajishirzi, A. Farhadi, H. Namkoong, and L. Schmidt.
Robust ﬁne-tuning of zero-shot models. ArXiv, 2109.01903, 2021."
REFERENCES,0.17207792207792208,"M. Wu, M. Mosse, C. Zhuang, D. Yamins, and N. Goodman. Conditional negative sampling for
contrastive learning of visual representations. In International Conference on Learning Represen-
tations (ICLR), 2021. URL https://openreview.net/forum?id=v8b3e5jN66j."
REFERENCES,0.17272727272727273,"Z. Wu, Y. Xiong, S. X. Yu, and D. Lin. Unsupervised feature learning via non-parametric instance
discrimination. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 3733–3742, Los Alamitos, CA, USA, 2018. IEEE Computer Society. doi: 10.1109/
CVPR.2018.00393."
REFERENCES,0.17337662337662338,"C.-H. Yeh, C.-Y. Hong, Y.-C. Hsu, T.-L. Liu, Y. Chen, and Y. LeCun. Decoupled contrastive learning.
ArXiv, 2110.06848, 2021."
REFERENCES,0.17402597402597403,"K. Zhou, J. Yang, C. C. Loy, and Z. Liu. Learning to prompt for vision-language models. ArXiv,
2109.01134, 2021."
REFERENCES,0.17467532467532468,Under review as a conference paper at ICLR 2022
REFERENCES,0.17532467532467533,"A
APPENDIX"
REFERENCES,0.17597402597402598,"This appendix consists of four sections (A.1–A.4). Section A.1 provides the theoretical properties
of the InfoLOOB and InfoNCE. It is shown how to derive that InfoNCE is a lower bound on
mutual information. Further it is shown how to derive that InfoLOOB is an upper bound on mutual
information. The proposed loss function LInfoLOOB and its gradients are discussed. In Section A.2
we discuss the estimation of mutual information for a toy example. Section A.3 provides details on
the experiments for Section 4. Section A.4 brieﬂy reviews continuous modern Hopﬁeld networks.
Section A.5 discusses further related work."
REFERENCES,0.17662337662337663,CONTENTS OF THE APPENDIX
REFERENCES,0.17727272727272728,"A Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
A.1 InfoLOOB vs. InfoNCE
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
A.1.1 InfoNCE: Lower Bound on Mutual Information . . . . . . . . . . . . . . . .
17
A.1.2 InfoLOOB: Upper Bound on Mutual Information
. . . . . . . . . . . . . . . .
21
A.1.3 InfoLOOB: Analysis of the Objective . . . . . . . . . . . . . . . . . . . . . .
25
A.1.4 InfoNCE and InfoLOOB: Gradients
. . . . . . . . . . . . . . . . . . . . . .
32
A.1.5 InfoLOOB and InfoNCE: Probability Estimators . . . . . . . . . . . . . . . .
34
A.1.6 InfoLOOB and InfoNCE: Losses . . . . . . . . . . . . . . . . . . . . . . . .
36
A.2 Mutual Information Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
A.3 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
A.3.1 Ablation studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
A.3.2 Hyperparameters
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
A.3.3 Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
A.3.4 Zero-shot evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
A.3.5 Linear probing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
A.4 Review of Modern Hopﬁeld Networks . . . . . . . . . . . . . . . . . . . . . . . . .
43
A.5 Further Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46"
REFERENCES,0.17792207792207793,LIST OF THEOREMS
REFERENCES,0.17857142857142858,"A1
Theorem (InfoNCE lower bound) . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
A2
Theorem (InfoLOOB upper bound) . . . . . . . . . . . . . . . . . . . . . . . . . .
23
A3
Theorem (Weighted Covariances)
. . . . . . . . . . . . . . . . . . . . . . . . . .
38
A4
Theorem (Modern Hopﬁeld Networks: Retrieval with One Update) . . . . . . . . .
45
A5
Theorem (Modern Hopﬁeld Networks: Exponential Storage Capacity) . . . . . . .
45"
REFERENCES,0.17922077922077922,LIST OF DEFINITIONS
REFERENCES,0.17987012987012987,"A1
Deﬁnition (Pattern Stored and Retrieved) . . . . . . . . . . . . . . . . . . . . . . .
45"
REFERENCES,0.18051948051948052,LIST OF FIGURES
REFERENCES,0.18116883116883117,"A1 Estimated mutual information of different objectives . . . . . . . . . . . . . . . . .
40
A2 Visualization of zero-shot classiﬁcation of three examples from each dataset . . . . .
44"
REFERENCES,0.18181818181818182,LIST OF TABLES
REFERENCES,0.18246753246753247,"A1 Inﬂuence of loss functions and Hopﬁeld retrieval . . . . . . . . . . . . . . . . . . .
40
A2 Inﬂuence of learning rate scheduler
. . . . . . . . . . . . . . . . . . . . . . . . . . .
41
A3 Datasets used for zero-shot and linear probing . . . . . . . . . . . . . . . . . . . . . .
41
A4 Linear probing for CLIP (reimplementation) and CLOOB trained on YFCC . . . . .
43"
REFERENCES,0.18311688311688312,Under review as a conference paper at ICLR 2022
REFERENCES,0.18376623376623377,"A.1
INFOLOOB VS. INFONCE"
REFERENCES,0.18441558441558442,"A.1.1
INFONCE: LOWER BOUND ON MUTUAL INFORMATION"
REFERENCES,0.18506493506493507,"We derive a lower bound on the mutual information between random variables X and Y distributed
according to p(x, y). The mutual information I(X ; Y ) between random variables X and Y is"
REFERENCES,0.18571428571428572,"I(X ; Y ) = Ep(x,y)"
REFERENCES,0.18636363636363637,"
ln
p(x, y)
p(x) p(y)"
REFERENCES,0.18701298701298702,"
= Ep(x,y)"
REFERENCES,0.18766233766233767,"
ln p(x | y) p(x)"
REFERENCES,0.18831168831168832,"
= Ep(x,y)"
REFERENCES,0.18896103896103897,"
ln p(y | x) p(y) 
. (A1)"
REFERENCES,0.18961038961038962,"“InfoNCE” has been introduced in van den Oord et al. (2018) and is a multi-sample bound. In
the setting introduced in van den Oord et al. (2018), we have an anchor sample y given. For the
anchor sample y we draw a positive sample x1 according to p(x1 | y). Next, we draw a set
˜X = {x2, . . . , xN} according to p( ˜X), which are n −1 negative samples drawn iid according to
p(x). We have drawn a set X = {x1, x2, . . . , xN} according to p(X | y), which is one positive
sample x1 drawn by p(x1 | y) and N −1 negative samples {x2, . . . , xN} drawn iid according to
p(x)."
REFERENCES,0.19025974025974027,The InfoNCE with probabilities is
REFERENCES,0.19090909090909092,"IInfoNCE(X1 ; Y ) = Ep(y) """
REFERENCES,0.19155844155844157,"Ep(X|y) "" ln"
REFERENCES,0.19220779220779222,p(y | x1)
"N
PN",0.19285714285714287,"1
N
PN
i=1 p(y | xi) !##"
"N
PN",0.19350649350649352,",
(A2)"
"N
PN",0.19415584415584416,where we inserted the factor 1
"N
PN",0.19480519480519481,"N in contrast to the original version in van den Oord et al. (2018), where
we followed Poole et al. (2019); Tschannen et al. (2019); Cheng et al. (2020); Chen et al. (2021)."
"N
PN",0.19545454545454546,"The InfoNCE with score function f(x, y) is"
"N
PN",0.1961038961038961,"IInfoNCE(X1 ; Y ) = Ep(y) """
"N
PN",0.19675324675324676,"Ep(X|y) "" ln"
"N
PN",0.1974025974025974,"f(x1, y)"
"N
PN",0.19805194805194806,"1
N
PN
i=1 f(xi, y) !##"
"N
PN",0.1987012987012987,".
(A3)"
"N
PN",0.19935064935064936,The InfoNCE with probabilities can be rewritten as:
"N
PN",0.2,"IInfoNCE(X1 ; Y ) = Ep(y) """
"N
PN",0.20064935064935066,"Ep(X|y) "" ln"
"N
PN",0.2012987012987013,p(y | x1)
"N
PN",0.20194805194805196,"1
N
PN
i=1 p(y | xi) !## (A4)"
"N
PN",0.2025974025974026,= Ep(y) 
"N
PN",0.20324675324675326,Ep(X|y)  ln  
"N
PN",0.2038961038961039,p(y|x1) p(y)
"N
PN",0.20454545454545456,"1
N
PN
i=1
p(y|xi) p(y)      "
"N
PN",0.2051948051948052,= Ep(y) 
"N
PN",0.20584415584415586,Ep(X|y)  ln  
"N
PN",0.2064935064935065,p(x1|y) p(x1)
"N
PN",0.20714285714285716,"1
N
PN
i=1
p(xi|y) p(xi)      ."
"N
PN",0.2077922077922078,"This is the InfoNCE with f(x, y) = p(y | x)."
"N
PN",0.20844155844155843,"Set of pairs. The InfoNCE can be written in a different setting Poole et al. (2019), which is
used in most implementations. We sample N pairs independently from p(x, y), which gives Z =
{(x1, y1), (x2, y2), . . . , (xN, yN)}. The InfoNCE is then"
"N
PN",0.20909090909090908,"IInfoNCE(X ; Y ) = Ep(X|y) ""
1
N N
X"
"N
PN",0.20974025974025973,"i=1
ln"
"N
PN",0.21038961038961038,"f(xi, yi)"
"N
PN",0.21103896103896103,"1
N
PN
j=1 f(xj, yi) !#"
"N
PN",0.21168831168831168,".
(A5)"
"N
PN",0.21233766233766233,Under review as a conference paper at ICLR 2022
"N
PN",0.21298701298701297,Following van den Oord et al. (2018) we have
"N
PN",0.21363636363636362,IInfoNCE(X1 ; Y ) = Ep(y) 
"N
PN",0.21428571428571427,Ep(X|y)  ln  
"N
PN",0.21493506493506492,p(y|x1) p(y)
"N
PN",0.21558441558441557,"1
N
PN
i=1
p(y|xi) p(y)     "
"N
PN",0.21623376623376622,"
(A6)"
"N
PN",0.21688311688311687,= Ep(y) 
"N
PN",0.21753246753246752,Ep(X|y)  ln  
"N
PN",0.21818181818181817,p(x1|y) p(x1)
"N
PN",0.21883116883116882,"1
N
PN
i=1
p(xi|y) p(xi)      "
"N
PN",0.21948051948051947,"= Ep(y) """
"N
PN",0.22012987012987012,"Ep(X|y) "" ln"
"N
PN",0.22077922077922077,"p(x1 | y) QN
l=2 p(xl)
PN
i=1 p(xi | y) Q"
"N
PN",0.22142857142857142,l̸=i p(xl) !##
"N
PN",0.22207792207792207,+ ln(N)
"N
PN",0.22272727272727272,"= Ep(y)

Ep(X|y) [ln p(i = 1 | X, y)]

+ ln(N) ,"
"N
PN",0.22337662337662337,"where p(i = 1 | X, y) is the probability that sample x1 is the positive sample if we know there exists
exactly one positive sample in X."
"N
PN",0.22402597402597402,"The InfoNCE is a lower bound on the mutual information. The following inequality is from van den
Oord et al. (2018):"
"N
PN",0.22467532467532467,I(X1 ; Y ) = Ep(y)
"N
PN",0.22532467532467532,"
Ep(x1|y)"
"N
PN",0.22597402597402597,"
ln
p(x1 | y) p(x1)"
"N
PN",0.22662337662337662,"
(A7)"
"N
PN",0.22727272727272727,= Ep(y)
"N
PN",0.22792207792207791,"
Ep(x1|y)"
"N
PN",0.22857142857142856,"
−ln

p(x1)
p(x1 | y) "
"N
PN",0.2292207792207792,≥Ep(y)
"N
PN",0.22987012987012986,"
Ep(x1|y)"
"N
PN",0.2305194805194805,"
−ln
 1"
"N
PN",0.23116883116883116,"N
+
p(x1)
p(x1 | y) "
"N
PN",0.2318181818181818,"≈Ep(y) """
"N
PN",0.23246753246753246,"Ep(X|y) "" −ln"
"N
PN",0.2331168831168831,"1
N + 1"
"N
PN",0.23376623376623376,"N
p(x1)
p(x1 | y) N
X i=2"
"N
PN",0.2344155844155844,p(xi | y) p(xi) !##
"N
PN",0.23506493506493506,= Ep(y) 
"N
PN",0.2357142857142857,Ep(X|y)  ln  
"N
PN",0.23636363636363636,p(x1|y) p(x1)
N,0.237012987012987,"1
N
p(x1|y)"
N,0.23766233766233766,"p(x1)
+
1
N
PN
i=2
p(xi|y) p(xi)      "
N,0.2383116883116883,"= IInfoNCE(X1 ; Y ) ,"
N,0.23896103896103896,"where the ""≥"" is obtained by bounding ln(1/N + a) by ln(a), which gives a bound that is not very
tight, since a =
p(x1)
p(x1|y) can become small. However for the ""≈"" van den Oord et al. (2018) have to
assume"
N,0.2396103896103896,"1
N N
X i=2"
N,0.24025974025974026,p(xi | y)
N,0.2409090909090909,"p(xi)
=
1
N N
X i=2"
N,0.24155844155844156,p(y | xi)
N,0.2422077922077922,"p(y)
≥1 ,
(A8)"
N,0.24285714285714285,which is unclear how to ensure.
N,0.2435064935064935,For a proof of this bound see Poole et al. (2019).
N,0.24415584415584415,"We assumed that for the anchor sample y a positive sample x1 has been drawn according to p(x1 | y).
A set ˜X = {x2, . . . , xN} of negative samples is drawn according to p(x). Therefore, we have a
set X = {x1, x2, . . . , xN} that is drawn with one positive sample x1 and N −1 negative samples
˜X = {x2, . . . , xN}. We have"
N,0.2448051948051948,"p( ˜X) = N
Y"
N,0.24545454545454545,"i=2
p(xi) ,
(A9)"
N,0.2461038961038961,"p(X | y) = p(x1 | y) N
Y"
N,0.24675324675324675,"i=2
p(xi) ,
(A10)"
N,0.2474025974025974,"p(X) = N
Y"
N,0.24805194805194805,"i=1
p(xi) .
(A11)"
N,0.2487012987012987,Under review as a conference paper at ICLR 2022
N,0.24935064935064935,"Next, we present a theorem that shows this bound, where we largely follow Poole et al. (2019) in the
proof. In contrast to Poole et al. (2019), we do not use the NWJ bound Nguyen et al. (2010). The
mutual information is"
N,0.25,"I(X1 ; Y ) = Ep(x1,y)"
N,0.2506493506493506,"
ln
p(x1 | y) p(x1)"
N,0.2512987012987013,"
.
(A12)"
N,0.2519480519480519,"Theorem A1 (InfoNCE lower bound). InfoNCE with score function f(x, y) according to Eq. (A3)
is a lower bound on the mutual information."
N,0.2525974025974026,"I(X1 ; Y ) ≥Ep(y)p(X|y) "" ln"
N,0.2532467532467532,"f(x1, y)"
"N
PN",0.2538961038961039,"1
N
PN
i=1 f(xi, y) !#"
"N
PN",0.2545454545454545,"= IInfoNCE(X1 ; Y ) .
(A13)"
"N
PN",0.2551948051948052,InfoNCE with probabilities according to Eq. (A2) is a lower bound on the mutual information.
"N
PN",0.2558441558441558,"I(X1 ; Y ) ≥Ep(y)p(X|y) "" ln"
"N
PN",0.2564935064935065,p(y | x1)
"N
PN",0.2571428571428571,"1
N
PN
i=1 p(y | xi) !#"
"N
PN",0.2577922077922078,"= IInfoNCE(X1 ; Y ) .
(A14)"
"N
PN",0.2584415584415584,The second bound Eq. (A14) is a special case of the ﬁrst bound Eq. (A13).
"N
PN",0.2590909090909091,"Proof. Part (I): Lower bound with score function f(x, y)."
"N
PN",0.2597402597402597,"For each set ˜X = {x2, . . . , xN}, we deﬁne as data-dependent (depending on ˜X) score function
g(x1, y, ˜X) that is based on the score function f(x, y). Therefore we have for each ˜X a different
data-dependent score function g based on f. We will derive a bound on the InfoNCE, which is the
expectation of a lower bond on the mutual information over the score functions. For score function
g(x1, y, ˜X), we deﬁne a variational distribution q(x1 | y, ˜X) over x1:"
"N
PN",0.2603896103896104,"q(x1 | y, ˜X) = p(x1) g(x1, y, ˜X)"
"N
PN",0.261038961038961,"Z(y, ˜X)
,
(A15)"
"N
PN",0.2616883116883117,"Z(y, ˜X) = Ep(x1)
h
g(x1, y, ˜X)
i
,
(A16)"
"N
PN",0.2623376623376623,"which ensures
Z
q(x1 | y, ˜X) dx1 = 1 .
(A17)"
"N
PN",0.262987012987013,We have
"N
PN",0.2636363636363636,"q(x1 | y, ˜X)"
"N
PN",0.2642857142857143,"p(x1)
= g(x1, y, ˜X)"
"N
PN",0.2649350649350649,"Z(y, ˜X)
.
(A18)"
"N
PN",0.2655844155844156,"For the function g, we set"
"N
PN",0.2662337662337662,"g(x1, y, ˜X) =
f(x1, y)"
"N
PN",0.2668831168831169,"1
N
PN
i=1 f(xi, y)
,
(A19)"
"N
PN",0.2675324675324675,For the function f we use
"N
PN",0.2681818181818182,"f(x1, y) = exp(τ −1 sim(x1, y)) ,
(A20)"
"N
PN",0.2688311688311688,"where sim(x, y) is typically the cosine similarity."
"N
PN",0.2694805194805195,We next show that InfoNCE is a lower bound on the mutual information.
"N
PN",0.2701298701298701,Under review as a conference paper at ICLR 2022
"N
PN",0.2707792207792208,"I(X1 ; Y ) = Ep( ˜
X) [I(X1 ; Y )] = Ep( ˜
X)"
"N
PN",0.2714285714285714,"
Ep(x1,y)"
"N
PN",0.2720779220779221,"
ln p(x1 | y) p(x1)"
"N
PN",0.2727272727272727,"
(A21)"
"N
PN",0.2733766233766234,"= Ep( ˜
X) """
"N
PN",0.274025974025974,"Ep(x1,y) "" ln"
"N
PN",0.2746753246753247,"p(x1 | y)
q(x1 | y, ˜X)
q(x1 | y, ˜X) p(x1) !##"
"N
PN",0.2753246753246753,"= Ep( ˜
X) """
"N
PN",0.275974025974026,"Ep(x1,y) """
"N
PN",0.2766233766233766,"ln q(x1 | y, ˜X) p(x1) #"
"N
PN",0.2772727272727273,"+ Ep(y)
h
KL(p(x1 | y) ∥q(x1 | y, ˜X))
i#"
"N
PN",0.2779220779220779,"≥Ep( ˜
X) """
"N
PN",0.2785714285714286,"Ep(x1,y) """
"N
PN",0.2792207792207792,"ln q(x1 | y, ˜X) p(x1) ##"
"N
PN",0.2798701298701299,"= Ep( ˜
X) """
"N
PN",0.2805194805194805,"Ep(x1,y) """
"N
PN",0.2811688311688312,"ln g(x1, y, ˜X)"
"N
PN",0.2818181818181818,"Z(y, ˜X) ##"
"N
PN",0.2824675324675325,"= Ep( ˜
X)
h
Ep(x1,y)
h
ln g(x1, y, ˜X) −ln

Ep(x1)
h
g(x1, y, ˜X)
iii"
"N
PN",0.2831168831168831,"= Ep( ˜
X)
h
Ep(y)
h
Ep(x1|y)
h
ln g(x1, y, ˜X)
i
−ln

Ep(x1)
h
g(x1, y, ˜X)
iii"
"N
PN",0.2837662337662338,"= Ep( ˜
X)
h
Ep(y)
h
Ep(x1|y)
h
ln g(x1, y, ˜X)
iii
−Ep( ˜
X)
h
Ep(y)
h
ln

Ep(x1)
h
g(x1, y, ˜X)
iii"
"N
PN",0.2844155844155844,"≥Ep(y)p(X|y)
h
ln g(x1, y, ˜X)
i
−Ep( ˜
X)
h
Ep(y)
h
Ep(x1)
h
g(x1, y, ˜X)
i
−1
ii"
"N
PN",0.2850649350649351,"= Ep(y)p(X|y) """
"N
PN",0.2857142857142857,"ln
f(x1, y)"
"N
PN",0.2863636363636364,"1
N
PN
i=1 f(xi, y) #"
"N
PN",0.287012987012987,"−Ep(y) "" Ep(X)"
"N
PN",0.2876623376623377,"""
f(x1, y)"
"N
PN",0.2883116883116883,"1
N
PN
i=1 f(xi, y) # −1 #"
"N
PN",0.288961038961039,"= Ep(y)p(X|y) """
"N
PN",0.2896103896103896,"ln
f(x1, y)"
"N
PN",0.2902597402597403,"1
N
PN
i=1 f(xi, y) #"
"N
PN",0.2909090909090909,"−Ep(y) ""
1
N N
X"
"N
PN",0.2915584415584416,"i=1
Ep(X)"
"N
PN",0.2922077922077922,"""
f(xi, y)"
"N
PN",0.29285714285714287,"1
N
PN
i=1 f(xi, y) # −1 #"
"N
PN",0.2935064935064935,"= Ep(y)p(X|y) """
"N
PN",0.29415584415584417,"ln
f(x1, y)"
"N
PN",0.2948051948051948,"1
N
PN
i=1 f(xi, y) #"
"N
PN",0.29545454545454547,"−Ep(y) "" Ep(X)"
"N
PN",0.2961038961038961,"""
1
N
PN
i=1 f(xi, y)"
"N
PN",0.29675324675324677,"1
N
PN
i=1 f(xi, y) # −1 #"
"N
PN",0.2974025974025974,"= Ep(y)p(X|y) """
"N
PN",0.29805194805194807,"ln
f(x1, y)"
"N
PN",0.2987012987012987,"1
N
PN
i=1 f(xi, y) #"
"N
PN",0.29935064935064937,= IInfoNCE(X1 ; Y ) .
"N
PN",0.3,"For the ﬁrst ""≥"" we used that the Kullback-Leibler divergence is non-negative. For the second ""≥""
we used the inequality ln a ⩽a −1 for a > 0."
"N
PN",0.30064935064935067,Part (II): Lower bound with probabilities.
"N
PN",0.3012987012987013,If the score function f is
"N
PN",0.30194805194805197,"f(x, y) = p(y | x) ,
(A22)"
"N
PN",0.3025974025974026,then the bound is
"N
PN",0.30324675324675326,"I(X1 ; Y ) ≥Ep(y)p(X|y) "" ln"
"N
PN",0.3038961038961039,"f(x1, y)"
"N
PN",0.30454545454545456,"1
N
PN
i=1 f(xi, y) !#"
"N
PN",0.3051948051948052,"= Ep(y)p(X|y) "" ln"
"N
PN",0.30584415584415586,p(y | x1)
"N
PN",0.3064935064935065,"1
N
PN
i=1 p(y | xi) !# (A23)"
"N
PN",0.30714285714285716,= Ep(y)p(X|y)  ln  
"N
PN",0.3077922077922078,p(y|x1) p(y)
"N
PN",0.30844155844155846,"1
N
PN
i=1
p(y|xi) p(y)   "
"N
PN",0.3090909090909091,= IInfoNCE(X1 ; Y ) .
"N
PN",0.30974025974025976,This is the bound with probabilities in the theorem.
"N
PN",0.3103896103896104,Under review as a conference paper at ICLR 2022
"N
PN",0.31103896103896106,"A.1.2
INFOLOOB: UPPER BOUND ON MUTUAL INFORMATION"
"N
PN",0.3116883116883117,"We derive an upper bound on the mutual information between random variables X and Y distributed
according to p(x, y). The mutual information I(X ; Y ) between random variables X and Y is"
"N
PN",0.31233766233766236,"I(X ; Y ) = Ep(x,y)"
"N
PN",0.312987012987013,"
ln
p(x, y)
p(x) p(y)"
"N
PN",0.31363636363636366,"
= Ep(x,y)"
"N
PN",0.3142857142857143,"
ln p(x | y) p(x)"
"N
PN",0.31493506493506496,"
= Ep(x,y)"
"N
PN",0.3155844155844156,"
ln p(y | x) p(y) 
. (A24)"
"N
PN",0.31623376623376626,"In Poole et al. (2019) Eq. (13) introduces a variational upper bound on the mutual information,
which has been called ""Leave one out upper bound"" (called ""L1Out"" in Cheng et al. (2020)). For
simplicity, we call this bound ""InfoLOOB"", where LOOB is an acronym for ""Leave One Out Bound"".
In contrast to InfoNCE, InfoLOOB is an upper bound on the mutual information. InfoLOOB is analog
to InfoNCE except that the negative samples do not contain a positive sample. Fig. 1 and Fig. 2 in
Cheng et al. (2020) both show that InfoLOOB is a better estimator for the mutual information than
InfoNCE (van den Oord et al., 2018), MINE (Belghazi et al., 2018), and NWJ (Nguyen et al., 2010)."
"N
PN",0.3168831168831169,"The InfoLOOB with score function f(x, y) is deﬁned as"
"N
PN",0.31753246753246755,"IInfoLOOB(X1 ; Y ) = Ep(y) """
"N
PN",0.3181818181818182,"E˜p(X|y) "" ln"
"N
PN",0.31883116883116885,"f(x1, y)"
"N
PN",0.3194805194805195,"1
N−1
PN
i=2 f(xi, y) !##"
"N
PN",0.32012987012987015,".
(A25)"
"N
PN",0.3207792207792208,The InfoLOOB with probabilities is deﬁned as
"N
PN",0.32142857142857145,"IInfoLOOB(X1 ; Y ) = Ep(y) """
"N
PN",0.3220779220779221,"Ep(X|y) "" ln"
"N
PN",0.32272727272727275,p(y | x1)
"N
PN",0.3233766233766234,"1
N−1
PN
i=2 p(y | xi) !##"
"N
PN",0.32402597402597405,".
(A26)"
"N
PN",0.3246753246753247,"This is the InfoLOOB with f(x, y) = p(y | x)."
"N
PN",0.32532467532467535,The InfoLOOB with probabilities can be written in different forms:
"N
PN",0.32597402597402597,"IInfoLOOB(X1 ; Y ) = Ep(y) """
"N
PN",0.32662337662337665,"Ep(X|y) "" ln"
"N
PN",0.32727272727272727,p(y | x1)
"N
PN",0.32792207792207795,"1
N−1
PN
i=2 p(y | xi) !## (A27)"
"N
PN",0.32857142857142857,= Ep(y) 
"N
PN",0.32922077922077925,Ep(X|y)  ln  
"N
PN",0.32987012987012987,p(y|x1) p(y)
"N
PN",0.33051948051948055,"1
N−1
PN
i=2
p(y|xi) p(y)     "
"N
PN",0.33116883116883117,= Ep(y) 
"N
PN",0.33181818181818185,Ep(X|y)  ln  
"N
PN",0.33246753246753247,p(x1|y) p(x1)
"N
PN",0.33311688311688314,"1
N−1
PN
i=2
p(xi|y) p(xi)      ."
"N
PN",0.33376623376623377,"Set of pairs. The InfoLOOB can we written in a different setting (Poole et al., 2019), which will
be used in our implementations. We sample N pairs independently from p(x, y), which gives
X = {(x1, y1), (x2, y2), . . . , (xN, yN)}. The InfoLOOB is then"
"N
PN",0.3344155844155844,"IInfoLOOB(X ; Y ) = Ep(X|y) ""
1
N N
X"
"N
PN",0.33506493506493507,"i=1
ln"
"N
PN",0.3357142857142857,"f(xi, yi)"
"N
PN",0.33636363636363636,"1
N−1
PN
j=1,j̸=i f(xj, yi) !#"
"N
PN",0.337012987012987,".
(A28)"
"N
PN",0.33766233766233766,"We assume that an anchor sample y is given. For the anchor sample y we draw a positive sample
x1 according to p(x1 | y). Next, we draw a set ˜X = {x2, . . . , xN} of negative samples according
to ˜p(x | y). For a given y, the x that have a large p(x | y) are drawn with a lower probability
˜p(x | y) compared to random drawing via p(x). The negatives are indeed negatives. We have
drawn ﬁrst anchor sample y and then X = {x1, . . . , xN}, where x1 is drawn according to p(x1 | y)
and ˜X = {x2, . . . , xN} are drawn iid according to ˜p(x | y). We have"
"N
PN",0.3383116883116883,"˜p( ˜X | y) = N
Y"
"N
PN",0.33896103896103896,"i=2
˜p(xi | y) ,
(A29)"
"N
PN",0.3396103896103896,"˜p(X | y) = p(x1 | y) N
Y"
"N
PN",0.34025974025974026,"i=2
˜p(xi | y) ,
(A30)"
"N
PN",0.3409090909090909,"˜p( ˜X | y) p(x1) = p(x1) N
Y"
"N
PN",0.34155844155844156,"i=2
˜p(xi | y) .
(A31)"
"N
PN",0.3422077922077922,Under review as a conference paper at ICLR 2022
"N
PN",0.34285714285714286,"We assume for score function f(x, y)"
"N
PN",0.3435064935064935,"∀y∀x : 0 < f(x, y) .
(A32)"
"N
PN",0.34415584415584416,We ensure this by using for score function f
"N
PN",0.3448051948051948,"f(x, y) = exp(τ −1 sim(x, y)) ,
(A33)"
"N
PN",0.34545454545454546,"where sim(x, y) is typically the cosine similarity."
"N
PN",0.3461038961038961,"InfoLOOB with score function f(x, y) is"
"N
PN",0.34675324675324676,"IInfoLOOB(X ; Y ) = Ep(y) """
"N
PN",0.3474025974025974,"Ep(X|y) "" ln"
"N
PN",0.34805194805194806,"f(x1, y)"
"N
PN",0.3487012987012987,"1
N−1
PN
i=2 f(xi, y) !##"
"N
PN",0.34935064935064936,".
(A34)"
"N
PN",0.35,"The reference constant Z(y) gives the average score f(x, y), if the negatives for y are selected with
lower probability via ˜p(x | y) than with random drawing according to p(x)."
"N
PN",0.35064935064935066,"Z(y) = E˜p(x|y) [f(x, y)] .
(A35)"
"N
PN",0.3512987012987013,We deﬁne the variational distribution
"N
PN",0.35194805194805195,"q(x | y) = p(x) f(x, y)"
"N
PN",0.3525974025974026,"Z∗(y)
,
Z∗(y) = Ep(x) [f(x, y)] .
(A36)"
"N
PN",0.35324675324675325,"With the variational distribution q(x | y), we express our main assumption. The main assumption
for the bound is:"
"N
PN",0.3538961038961039,"Ep(y) [KL(p(x | y) ∥q(x | y))] ⩽Ep(y) [ln Z∗(y) −ln Z(y)] .
(A37)"
"N
PN",0.35454545454545455,This assumption can be written as Ep(y)
"N
PN",0.3551948051948052,"
Ep(x|y)"
"N
PN",0.35584415584415585,"
ln
p(y | x) Z(y)"
"N
PN",0.3564935064935065,"p(y) f(x, y)"
"N
PN",0.35714285714285715,"
⩽0 .
(A38)"
"N
PN",0.3577922077922078,"This assumption ensures that the x with large p(x | y)) are selected with lower probability via
˜p(x | y) than with random drawing according to p(x). The negatives are ensured to be real negatives,
that is, p(x | y) is small and so is f(x, y). Consequently, we make sure that we draw x with
sufﬁcient small f(x, y). The Kullback-Leibler gives the minimal required gap between drawing
f(x, y) via p(x) and drawing f(x, y) via ˜p(x | y)."
"N
PN",0.35844155844155845,"EXAMPLE. With h(y) > 0, we consider the setting"
"N
PN",0.35909090909090907,"f(x, y) = p(y | x) h(y)"
"N
PN",0.35974025974025975,"p(y)
,
(A39)"
"N
PN",0.36038961038961037,"˜p(x | y) =
p(x) p(y)
h(y) p(y | x) C(y) ,
C(y) = Ep(x)"
"N
PN",0.36103896103896105,"""p(y | x) h(y) p(y) −1#"
"N
PN",0.36168831168831167,".
(A40)"
"N
PN",0.36233766233766235,The main assumption becomes Ep(y)
"N
PN",0.36298701298701297,"
Ep(x|y)"
"N
PN",0.36363636363636365,"
ln Z(y) h(y)"
"N
PN",0.36428571428571427,"
⩽0 .
(A41)"
"N
PN",0.36493506493506495,The main assumption holds since
"N
PN",0.36558441558441557,Z(y) = E˜p(x|y)
"N
PN",0.36623376623376624,p(y | x) h(y) p(y)
"N
PN",0.36688311688311687,"
=
Z
p(x) p(y)
h(y) p(y | x) C(y)
p(y | x) h(y)"
"N
PN",0.36753246753246754,"p(y)
dx
(A42)"
"N
PN",0.36818181818181817,"=
Z
p(x) C(y)−1 dx = C(y)−1 =  Ep(x)"
"N
PN",0.36883116883116884,"""p(y | x) h(y) p(y)"
"N
PN",0.36948051948051946,−1#!−1 ⩽  Ep(x)
"N
PN",0.37012987012987014,p(y | x) h(y) p(y)
"N
PN",0.37077922077922076,−1!−1
"N
PN",0.37142857142857144,= Ep(x)
"N
PN",0.37207792207792206,p(y | x) h(y) p(y) 
"N
PN",0.37272727272727274,"=
Z p(y, x) h(y)"
"N
PN",0.37337662337662336,"p(y)
dx = h(y) ,"
"N
PN",0.37402597402597404,Under review as a conference paper at ICLR 2022
"N
PN",0.37467532467532466,"where we used for the ⩽Jensen’s inequality with the function f(a) = 1/a, which is convex for
a > 0."
"N
PN",0.37532467532467534,"For score function f(x, y) and distribution ˜p(x | y) for sampling the negative samples, we have
deﬁned:"
"N
PN",0.37597402597402596,"Z(y) = E˜p(x|y) [f(x, y)] ,
(A43)"
"N
PN",0.37662337662337664,"Z∗(y) = Ep(x) [f(x, y)] ,
(A44)"
"N
PN",0.37727272727272726,"q(x | y) = p(x) f(x, y)"
"N
PN",0.37792207792207794,"Z∗(y)
.
(A45)"
"N
PN",0.37857142857142856,"Next theorem gives the upper bound of the InfoLOOB on the mutual information, which is"
"N
PN",0.37922077922077924,"I(X1 ; Y ) = Ep(x1,y)"
"N
PN",0.37987012987012986,"
ln p(x1 | y) p(x1)"
"N
PN",0.38051948051948054,"
.
(A46)"
"N
PN",0.38116883116883116,"Theorem A2 (InfoLOOB upper bound). If ˜X = {x2, . . . , xN} are drawn iid according to ˜p(x | y)
and if the main assumption holds:"
"N
PN",0.38181818181818183,"Ep(y) [KL(p(x | y) ∥q(x | y))] ⩽Ep(y) [ln Z∗(y) −ln Z(y)] .
(A47)"
"N
PN",0.38246753246753246,"Then InfoLOOB with score function f(x, y) as in Eq. (A25) is an upper bound on the mutual
information:"
"N
PN",0.38311688311688313,"I(X1 ; Y ) ⩽Ep(y) """
"N
PN",0.38376623376623376,"E˜p(X|y) "" ln"
"N
PN",0.38441558441558443,"f(x1, y)"
"N
PN",0.38506493506493505,"1
N−1
PN
i=2 f(xi, y) !##"
"N
PN",0.38571428571428573,= IInfoLOOB(X1 ; Y ) . (A48)
"N
PN",0.38636363636363635,"If the negative samples ˜X = {x2, . . . , xN} are drawn iid according to p(x), then InfoLOOB with
probabilities according to Eq. (A26) is an upper bound on the mutual information:"
"N
PN",0.38701298701298703,"I(X1 ; Y ) ⩽Ep(y) """
"N
PN",0.38766233766233765,"Ep(X|y) "" ln"
"N
PN",0.38831168831168833,p(y | x1)
"N
PN",0.38896103896103895,"1
N−1
PN
i=2 p(y | Xi) !##"
"N
PN",0.38961038961038963,= IInfoLOOB(X1 ; Y ) . (A49)
"N
PN",0.39025974025974025,The second bound Eq. (A49) is a special case of the ﬁrst bound Eq. (A48).
"N
PN",0.39090909090909093,"Proof. Part (I): Upper bound with score function f(x, y)."
"N
PN",0.39155844155844155,Under review as a conference paper at ICLR 2022
"N
PN",0.3922077922077922,"I(X1 ; Y ) = Ep(x1,y)"
"N
PN",0.39285714285714285,"
ln p(x1 | y) p(x1)"
"N
PN",0.3935064935064935,"
(A50)"
"N
PN",0.39415584415584415,"= Ep(x1,y)"
"N
PN",0.3948051948051948,"
ln
p(x1 | y)"
"N
PN",0.39545454545454545,"q(x1 | y)
q(x1 | y) p(x1) "
"N
PN",0.3961038961038961,"= Ep(x1,y)"
"N
PN",0.39675324675324675,"
ln q(x1 | y) p(x1)"
"N
PN",0.3974025974025974,"
+ Ep(y) [KL(p(x1 | y) ∥q(x1 | y))]"
"N
PN",0.39805194805194805,"⩽Ep(x1,y)"
"N
PN",0.3987012987012987,"
ln q(x1 | y) p(x1)"
"N
PN",0.39935064935064934,"
+ Ep(y)

ln Ep(x1) [f(x1, y)] −ln Z(y)
"
"N
PN",0.4,"= Ep(x1,y)"
"N
PN",0.40064935064935064,"
ln q(x1 | y)"
"N
PN",0.4012987012987013,"p(x1)
+ ln Ep(x1) [f(x1, y)] Z(y) "
"N
PN",0.40194805194805194,"= Ep(x1,y)"
"N
PN",0.4025974025974026,"
ln

f(x1, y)
Ep(x1) [f(x1, y)]
Ep(x1) [f(x1, y)] Z(y) "
"N
PN",0.40324675324675324,"= Ep(x1,y)"
"N
PN",0.4038961038961039,"
ln f(x1, y) Z(y) "
"N
PN",0.40454545454545454,"= Ep(x1,y)  ln "
"N
PN",0.4051948051948052,"
f(x1, y)"
"N
PN",0.40584415584415584,"E˜p(X|y)
h
1
N−1
PN
i=2 f(xi, y)
i    "
"N
PN",0.4064935064935065,"= Ep(x1,y) [ln f(x1, y)] −Ep(y) "" ln "
"N
PN",0.40714285714285714,E˜p(X|y)
"N
PN",0.4077922077922078,"""
1
N −1 N
X"
"N
PN",0.40844155844155844,"i=2
f(xi, y) #!#"
"N
PN",0.4090909090909091,"⩽Ep(x1,y) [ln f(x1, y)] −Ep(y) """
"N
PN",0.40974025974025974,"E˜p(X|y) "" ln"
"N
PN",0.4103896103896104,"1
N −1 N
X"
"N
PN",0.41103896103896104,"i=2
f(xi, y) !##"
"N
PN",0.4116883116883117,"= Ep(y) """
"N
PN",0.41233766233766234,"E˜p(X|y) "" ln"
"N
PN",0.412987012987013,"f(x1, y)"
"N
PN",0.41363636363636364,"1
N−1
PN
i=2 f(xi, y) !##"
"N
PN",0.4142857142857143,"= IInfoLOOB(X1 ; Y ) ,"
"N
PN",0.41493506493506493,"where the ﬁrst ""⩽"" uses assumption Eq. (A37), while Jensens’s inequality was used for the second
""⩽"" by exchanging the expectation and the ""ln"". We also used"
"N
PN",0.4155844155844156,E˜p(X|y)
"N
PN",0.41623376623376623,"""
1
N −1 N
X"
"N
PN",0.41688311688311686,"i=2
f(xi, y) #"
"N
PN",0.41753246753246753,"=
1
N −1 N
X"
"N
PN",0.41818181818181815,"i=2
E˜p(xi|y) [f(xi, y)] =
1
N −1 N
X"
"N
PN",0.41883116883116883,"i=2
Z(y) = Z(y) . (A51)"
"N
PN",0.41948051948051945,Part (II): Upper bound with probabilities.
"N
PN",0.42012987012987013,If the score function f is
"N
PN",0.42077922077922075,"f(x, y) = p(y | x)
(A52) and"
"N
PN",0.42142857142857143,"˜p(x | y) = p(x) ,
(A53) then"
"N
PN",0.42207792207792205,"˜p(X | y) = p(X | y) ,
(A54)
Z(y) = Ep(x) [p(y | x)] = p(y) ,
(A55)"
"N
PN",0.42272727272727273,"Z∗(y) = Ep(x) [p(y | x)] = p(y) ,
(A56)"
"N
PN",0.42337662337662335,q(x | y) = p(x) p(y | x)
"N
PN",0.42402597402597403,"p(y)
= p(x | y) ,
(A57)"
"N
PN",0.42467532467532465,"KL(p(x | y) ∥q(x | y)) = KL(p(x | y) ∥p(x | y)) = 0 .
(A58)"
"N
PN",0.4253246753246753,Under review as a conference paper at ICLR 2022
"N
PN",0.42597402597402595,"Therefore, the main assumption holds, since"
"N
PN",0.4266233766233766,"0 = Ep(y) [KL(p(x | y) ∥q(x | y))] = Ep(y) [ln Z∗(y) −ln Z(y)] .
(A59)"
"N
PN",0.42727272727272725,The bound becomes
"N
PN",0.4279220779220779,"I(X1 ; Y ) ⩽Ep(y) """
"N
PN",0.42857142857142855,"Ep(X|y) "" ln"
"N
PN",0.4292207792207792,p(y | x1)
"N
PN",0.42987012987012985,"1
N−1
PN
i=2 p(y | xi) !## (A60)"
"N
PN",0.4305194805194805,= Ep(y) 
"N
PN",0.43116883116883115,Ep(X|y)  ln  
"N
PN",0.4318181818181818,p(y|x1) p(y)
"N
PN",0.43246753246753245,"1
N−1
PN
i=2
p(y|xi) p(y)     "
"N
PN",0.4331168831168831,= IInfoLOOB(X1 ; Y ) .
"N
PN",0.43376623376623374,An alternative proof is as follows:
"N
PN",0.4344155844155844,"I(X1 ; Y ) = I(X1 ; Y ) −Ep(y) "" ln"
"N
PN",0.43506493506493504,"1
N −1 N
X i=2"
"N
PN",0.4357142857142857,"p(y)
p(y) !# (A61)"
"N
PN",0.43636363636363634,"= I(X1 ; Y ) −Ep(y) "" ln "
"N
PN",0.437012987012987,Ep(X|y)
"N
PN",0.43766233766233764,"""
1
N −1 N
X i=2"
"N
PN",0.4383116883116883,p(y | xi) p(y) #!#
"N
PN",0.43896103896103894,"⩽I(X1 ; Y ) −Ep(y) """
"N
PN",0.4396103896103896,"Ep(X|y) "" ln"
"N
PN",0.44025974025974024,"1
N −1 N
X i=2"
"N
PN",0.4409090909090909,p(y | xi) p(y) !##
"N
PN",0.44155844155844154,= Ep(y)
"N
PN",0.4422077922077922,"
Ep(x1|y)"
"N
PN",0.44285714285714284,"
ln
p(x1 | y) p(x1)"
"N
PN",0.4435064935064935,"
−Ep(y) """
"N
PN",0.44415584415584414,"Ep(X|y) "" ln"
"N
PN",0.4448051948051948,"1
N −1 N
X i=2"
"N
PN",0.44545454545454544,p(xi | y) p(xi) !##
"N
PN",0.4461038961038961,= Ep(y) 
"N
PN",0.44675324675324674,Ep(X|y)  ln  
"N
PN",0.4474025974025974,p(x1|y) p(x1)
"N
PN",0.44805194805194803,"1
N−1
PN
i=2
p(xi|y) p(xi)      "
"N
PN",0.4487012987012987,= IInfoLOOB(X1 ; Y ) .
"N
PN",0.44935064935064933,"where we applied Jensens’s inequality for the exchanging the expectation and the ""ln"" to obtain the
""⩽"" inequality."
"N
PN",0.45,"Experiments that compare upper and lower bounds as mutual information estimates are provided
in Cheng et al. (2020) and in Poole et al. (2019). In Fig. 2 in Cheng et al. (2020) it is shown that
InfoLOOB is a good estimator of the mutual information."
"N
PN",0.45064935064935063,"A.1.3
INFOLOOB: ANALYSIS OF THE OBJECTIVE"
"N
PN",0.4512987012987013,"This subsection justiﬁes the maximization of the InfoLOOB bound for contrastive learning. Maxi-
mizing the InfoLOOB bound is not intuitive as it was introduced as an upper bound on the mutual
information in the previous subsection. Still maximizing the InfoLOOB bound leads to a good
approximation of the mutual information, in particular for high mutual information."
"N
PN",0.45194805194805193,"InfoLOOB with a neural network as a scoring function is not an upper bound on the mutual in-
formation when not under-sampling. As we use InfoLOOB on training data for which we do not
know the sampling procedure, we cannot assume under-sampling. Therefore, we elaborate more on
the rationale behind the maximization of the InfoLOOB bound. (I) We show that InfoLOOB with
neural networks as scoring function is bounded from above. Therefore, there exists a maximum
and the optimization problem is well deﬁned. (II) We show that InfoLOOB with neural networks as
scoring function differs by two terms the mutual information. The ﬁrst term is the Kullback-Leibler
divergence between the variational q(x | y) and the posterior p(x | y). This divergence is minimal
for q(x | y) = p(x | y), which implies f(y | x) = p(y | x). The second term is governed by the
difference between the mean E[f(x, y)] and the empirical mean 1/(N −1) P"
"N
PN",0.4525974025974026,"i f(x, y). Hoeffding’s
inequality bounds this difference as we demonstrate in this subsection. Therefore, the second term"
"N
PN",0.45324675324675323,Under review as a conference paper at ICLR 2022
"N
PN",0.4538961038961039,"is negligible for large N. In contrast, the KL term is dominant and the relevant term, therefore
maximizing InfoLOOB leads tof(y | x) ≈p(y | x)."
"N
PN",0.45454545454545453,"We assume that an anchor sample y is given. For the anchor sample y, we draw a positive sample x1
according to p(x1 | y). We deﬁne the set ˜X = {x2, . . . , xN} of negative samples, which are drawn
iid according to p(x). We deﬁne the set X = {x1, . . . , xN}."
"N
PN",0.4551948051948052,We have
"N
PN",0.45584415584415583,"p( ˜X) = N
Y"
"N
PN",0.4564935064935065,"i=2
p(xi) ,
(A62)"
"N
PN",0.45714285714285713,"p(X | y) = p(x1 | y) N
Y"
"N
PN",0.4577922077922078,"i=2
p(xi) = p(x1 | y) p( ˜X) ,
(A63)"
"N
PN",0.4584415584415584,"p(X) = N
Y"
"N
PN",0.4590909090909091,"i=1
p(xi) = p(x1) p( ˜X) .
(A64)"
"N
PN",0.4597402597402597,We use the score function
"N
PN",0.4603896103896104,"f(x, y) = exp(τ −1 sim(x, y)) ,
(A65)"
"N
PN",0.461038961038961,"where sim(x, y) is typically the cosine similarity."
"N
PN",0.4616883116883117,"The InfoLOOB with score function f(x, y) is deﬁned as"
"N
PN",0.4623376623376623,"IInfoLOOB(X1 ; Y ) = Ep(y) """
"N
PN",0.462987012987013,"Ep(X|y) "" ln"
"N
PN",0.4636363636363636,"f(x1, y)"
"N
PN",0.4642857142857143,"1
N−1
PN
i=2 f(xi, y) !##"
"N
PN",0.4649350649350649,".
(A66)"
"N
PN",0.4655844155844156,We deﬁne the variational distribution
"N
PN",0.4662337662337662,"q(x | y) = p(x) f(x, y)"
"N
PN",0.4668831168831169,"Z(y)
,
(A67)"
"N
PN",0.4675324675324675,"Z(y) = Ep(x) [f(x, y)] .
(A68)"
"N
PN",0.4681818181818182,Under review as a conference paper at ICLR 2022
"N
PN",0.4688311688311688,"The next inequality shows the relation between I(X1 ; Y ) and IInfoLOOB(X1 ; Y ) for random
variables X1 and Y ."
"N
PN",0.4694805194805195,"I(X1 ; Y ) = Ep(x1,y)"
"N
PN",0.4701298701298701,"
ln p(x1 | y) p(x1)"
"N
PN",0.4707792207792208,"
(A69)"
"N
PN",0.4714285714285714,"= Ep(x1,y)"
"N
PN",0.4720779220779221,"
ln
p(x1 | y)"
"N
PN",0.4727272727272727,"q(x1 | y)
q(x1 | y) p(x1) "
"N
PN",0.4733766233766234,"= Ep(x1,y)"
"N
PN",0.474025974025974,"
ln q(x1 | y) p(x1)"
"N
PN",0.4746753246753247,"
+ Ep(y) [KL(p(x1 | y) ∥q(x1 | y))]"
"N
PN",0.4753246753246753,"= Ep(x1,y)"
"N
PN",0.475974025974026,"
ln f(x1, y) Z(y)"
"N
PN",0.4766233766233766,"
+ Ep(y) [KL(p(x1 | y) ∥q(x1 | y))]"
"N
PN",0.4772727272727273,"= Ep(x1,y)  ln "
"N
PN",0.4779220779220779,"
f(x1, y)"
"N
PN",0.4785714285714286,"Ep(X|y)
h
1
N−1
PN
i=2 f(xi, y)
i   "
"N
PN",0.4792207792207792,+ Ep(y) [KL(p(x1 | y) ∥q(x1 | y))]
"N
PN",0.4798701298701299,"= Ep(x1,y) [ln f(x1, y)] −Ep(y) "" ln "
"N
PN",0.4805194805194805,Ep(X|y)
"N
PN",0.4811688311688312,"""
1
N −1 N
X"
"N
PN",0.4818181818181818,"i=2
f(xi, y) #!#"
"N
PN",0.4824675324675325,+ Ep(y) [KL(p(x1 | y) ∥q(x1 | y))]
"N
PN",0.4831168831168831,"= Ep(x1,y) [ln f(x1, y)] −Ep(y) """
"N
PN",0.4837662337662338,"Ep(X|y) "" ln"
"N
PN",0.4844155844155844,"1
N −1 N
X"
"N
PN",0.4850649350649351,"i=2
f(xi, y) !##"
"N
PN",0.4857142857142857,"+ Ep(y) """
"N
PN",0.4863636363636364,"Ep(X|y) "" ln"
"N
PN",0.487012987012987,"1
N −1 N
X"
"N
PN",0.4876623376623377,"i=2
f(xi, y) !##"
"N
PN",0.4883116883116883,"−Ep(y) "" ln "
"N
PN",0.488961038961039,Ep(X|y)
"N
PN",0.4896103896103896,"""
1
N −1 N
X"
"N
PN",0.4902597402597403,"i=2
f(xi, y) #!#"
"N
PN",0.4909090909090909,+ Ep(y) [KL(p(x1 | y) ∥q(x1 | y))]
"N
PN",0.4915584415584416,"= Ep(y) """
"N
PN",0.4922077922077922,"Ep(X|y) "" ln"
"N
PN",0.4928571428571429,"f(x1, y)"
"N
PN",0.4935064935064935,"1
N−1
PN
i=2 f(xi, y) !##"
"N
PN",0.4941558441558442,"+ Ep(y) """
"N
PN",0.4948051948051948,"Ep(X|y) "" ln"
"N
PN",0.4954545454545455,"1
N −1 N
X"
"N
PN",0.4961038961038961,"i=2
f(xi, y) !##"
"N
PN",0.4967532467532468,"−Ep(y) "" ln "
"N
PN",0.4974025974025974,Ep(X|y)
"N
PN",0.4980519480519481,"""
1
N −1 N
X"
"N
PN",0.4987012987012987,"i=2
f(xi, y) #!#"
"N
PN",0.4993506493506494,+ Ep(y) [KL(p(x1 | y) ∥q(x1 | y))]
"N
PN",0.5,= IInfoLOOB(X1 ; Y )
"N
PN",0.5006493506493507,"+ Ep(y) """
"N
PN",0.5012987012987012,"Ep(X|y) "" ln"
"N
PN",0.5019480519480519,"1
N −1 N
X"
"N
PN",0.5025974025974026,"i=2
f(xi, y) !##"
"N
PN",0.5032467532467533,"−Ep(y) "" ln "
"N
PN",0.5038961038961038,Ep(X|y)
"N
PN",0.5045454545454545,"""
1
N −1 N
X"
"N
PN",0.5051948051948052,"i=2
f(xi, y) #!#"
"N
PN",0.5058441558441559,+ Ep(y) [KL(p(x1 | y) ∥q(x1 | y))]
"N
PN",0.5064935064935064,= IInfoLOOB(X1 ; Y )
"N
PN",0.5071428571428571,"+ Ep(y) """
"N
PN",0.5077922077922078,"Ep(X|y) "" ln"
"N
PN",0.5084415584415585,"1
N −1 N
X"
"N
PN",0.509090909090909,"i=2
f(xi, y) !##"
"N
PN",0.5097402597402597,"−Ep(y)

ln
 
Ep(x1) [f(x1, y)]
"
"N
PN",0.5103896103896104,+ Ep(y) [KL(p(x1 | y) ∥q(x1 | y))]
"N
PN",0.5110389610389611,= IInfoLOOB(X1 ; Y )
"N
PN",0.5116883116883116,"−Ep(y) """
"N
PN",0.5123376623376623,"Ep( ˜
X) "" ln"
"N
PN",0.512987012987013,"Ep(x1) [f(x1, y)]"
"N
PN",0.5136363636363637,"1
N−1
PN
i=2 f(xi, y) !##"
"N
PN",0.5142857142857142,+ Ep(y) [KL(p(x1 | y) ∥q(x1 | y))]
"N
PN",0.5149350649350649,"= IInfoLOOB(X1 ; Y ) −DE + Ep(y) [KL(p(x1 | y) ∥q(x1 | y))] ,"
"N
PN",0.5155844155844156,where we used
"N
PN",0.5162337662337663,"DE = Ep(y) """
"N
PN",0.5168831168831168,"Ep( ˜
X) "" ln"
"N
PN",0.5175324675324675,"Ep(x1) [f(x1, y)]"
"N
PN",0.5181818181818182,"1
N−1
PN
i=2 f(xi, y) !## (A70)"
"N
PN",0.5188311688311689,Under review as a conference paper at ICLR 2022 and
"N
PN",0.5194805194805194,"Z(y) = Ep(x1) [f(x1, y)] = Ep( ˜
X)"
"N
PN",0.5201298701298701,"""
1
N −1 N
X"
"N
PN",0.5207792207792208,"i=2
f(xi, y) # (A71)"
"N
PN",0.5214285714285715,= Ep(X|y)
"N
PN",0.522077922077922,"""
1
N −1 N
X"
"N
PN",0.5227272727272727,"i=2
f(xi, y) # ."
"N
PN",0.5233766233766234,"Since both KL and DE are non-negative (for DE see below), to increase InfoLOOB we have either
to decrease KL or to increase DE."
"N
PN",0.5240259740259741,Bounding DE. Next we bound DE. We deﬁne
"N
PN",0.5246753246753246,"L = zT x −β−1
N
X"
"N
PN",0.5253246753246753,"i=1
zi ln zi .
(A72)"
"N
PN",0.525974025974026,"The log-sum-exponential (lse) is the maximum of L on the N-dimensional simplex D with D = {z |
P"
"N
PN",0.5266233766233767,"i zi = 1, 0 ⩽zi} (Gao & Pavel, 2017):"
"N
PN",0.5272727272727272,"lse(β, x) = max
z∈D zT x −β−1
N
X"
"N
PN",0.5279220779220779,"i=1
zi ln zi .
(A73)"
"N
PN",0.5285714285714286,For some z ∈D we have
"N
PN",0.5292207792207793,"Ea [lse(β, a)] ≥Ea """
"N
PN",0.5298701298701298,"zT a −β−1
N
X"
"N
PN",0.5305194805194805,"i=1
zi ln zi #"
"N
PN",0.5311688311688312,"= zT Ea [a] −β−1
N
X"
"N
PN",0.5318181818181819,"i=1
zi ln zi ,
(A74)"
"N
PN",0.5324675324675324,therefore
"N
PN",0.5331168831168831,"Ea [lse(β, a)] ≥max
z∈D zT Ea [a] −β−1
N
X"
"N
PN",0.5337662337662338,"i=1
zi ln zi = lse(β, Ea [a]) .
(A75)"
"N
PN",0.5344155844155845,"We obtain Ep(y) """
"N
PN",0.535064935064935,"Ep( ˜
X) "" ln "
"N
PN",0.5357142857142857,Ep(x1)
"N
PN",0.5363636363636364,"""
exp(τ −1 sim(x1, y))"
"N
PN",0.537012987012987,"1
N−1
PN
i=2 exp(τ −1 sim(xi, y)) #!## (A76)"
"N
PN",0.5376623376623376,"⩽Ep(y) """
"N
PN",0.5383116883116883,"ln Ep(x1)

exp(τ −1 sim(x1, y))

−ln"
"N
PN",0.538961038961039,"1
N −1 N
X"
"N
PN",0.5396103896103897,"i=2
exp(τ −1 Ep(xi) [sim(xi, y)]) !#"
"N
PN",0.5402597402597402,"= Ep(y)

ln Ep(x1)

exp(τ −1 sim(x1, y))

−τ −1 Ep(x1) [sim(x1, y)]

."
"N
PN",0.5409090909090909,"We obtain via Jensen’s inequality Ep(y) """
"N
PN",0.5415584415584416,"Ep( ˜
X) "" ln "
"N
PN",0.5422077922077922,Ep(x1)
"N
PN",0.5428571428571428,"""
exp(τ −1 sim(x1, y))"
"N
PN",0.5435064935064935,"1
N−1
PN
i=2 exp(τ −1 sim(xi, y)) #!## (A77)"
"N
PN",0.5441558441558442,"≥Ep(y) """
"N
PN",0.5448051948051948,"ln Ep(x1)

exp(τ −1 sim(x1, y))

−ln"
"N
PN",0.5454545454545454,"1
N −1 N
X"
"N
PN",0.5461038961038961,"i=2
Ep(xi)

exp(τ −1 sim(x1, y))

!# = 0 ."
"N
PN",0.5467532467532468,"If we combine both previous inequalities, we obtain"
"N
PN",0.5474025974025974,"0 ⩽DE
⩽Ep(y)

ln Ep(x1)

exp(τ −1 sim(x1, y))

−τ −1 Ep(x1) [sim(x1, y)]

.
(A78)"
"N
PN",0.548051948051948,Under review as a conference paper at ICLR 2022
"N
PN",0.5487012987012987,"In particular, for bounded sim(x1, y), we get"
"N
PN",0.5493506493506494,"0 ⩽DE ⩽τ −1

max
y,x1 sim(x1, y) −min
y,x1 sim(x1, y)

,
(A79)"
"N
PN",0.55,while Hoeffding’s lemma gives
"N
PN",0.5506493506493506,0 ⩽DE ⩽1
"N
PN",0.5512987012987013,"8 τ −2

max
y,x1 sim(x1, y) −min
y,x1 sim(x1, y)
2
.
(A80)"
"N
PN",0.551948051948052,"Thus, for bounded sim(x1, y), DE is bounded, therefore also InfoLOOB. For sub-exponential
distributions with variance σ2, for which Bernstein’s condition with τ > b holds (Eq. (2.16) in
Wainwright (2019)), we get (Proposition 2.3 in Wainwright (2019)):"
"N
PN",0.5525974025974026,"0 ⩽DE ⩽
σ2"
"N
PN",0.5532467532467532,"2 (τ 2 −b τ) .
(A81)"
"N
PN",0.5538961038961039,"Next, we show that DE is small. Hoeffding’s inequality states that if f(x, y) ∈[a, b] then p"
"N
PN",0.5545454545454546,"Ep(x1) [f(x1, y)] −
1
N −1 N
X"
"N
PN",0.5551948051948052,"i=2
f(xi, y) ≥ϵ !"
"N
PN",0.5558441558441558,"⩽2 exp

−2 (N −1) ϵ2"
"N
PN",0.5564935064935065,(b −a)2
"N
PN",0.5571428571428572,"
.
(A82) For"
"N
PN",0.5577922077922078,"Ep(x1) [f(x1, y)] −
1
N −1 N
X"
"N
PN",0.5584415584415584,"i=2
f(xi, y) ⩽ϵ
(A83)"
"N
PN",0.5590909090909091,we have ln
"N
PN",0.5597402597402598,"Ep(x1) [f(x1, y)]"
"N
PN",0.5603896103896104,"1
N−1
PN
i=2 f(xi, y) ! ⩽ln"
"N
PN",0.561038961038961,"1
N−1
PN
i=2 f(xi, y) + ϵ"
"N
PN",0.5616883116883117,"1
N−1
PN
i=2 f(xi, y) ! (A84) ⩽
ϵ"
"N
PN",0.5623376623376624,"1
N−1
PN
i=2 f(xi, y)
⩽
ϵ
Z −ϵ ,"
"N
PN",0.562987012987013,where we used ln a ⩽a −1 for 0 < a. Analog for
"N
PN",0.5636363636363636,"1
N −1 N
X"
"N
PN",0.5642857142857143,"i=2
f(xi, y) −Ep(x1) [f(x1, y)] ⩽ϵ
(A85)"
"N
PN",0.564935064935065,we have ln
"N
PN",0.5655844155844156,"Ep(x1) [f(x1, y)]"
"N
PN",0.5662337662337662,"1
N−1
PN
i=2 f(xi, y) !"
"N
PN",0.5668831168831169,"≥ln

Ep(x1) [f(x1, y)]
Ep(x1) [f(x1, y)] + ϵ"
"N
PN",0.5675324675324676,"
(A86)"
"N
PN",0.5681818181818182,"= −ln
Ep(x1) [f(x1, y)] + ϵ"
"N
PN",0.5688311688311688,"Ep(x1) [f(x1, y)]"
"N
PN",0.5694805194805195,"
≥−
ϵ
Ep(x1) [f(x1, y)] = −ϵ Z ,"
"N
PN",0.5701298701298702,where we used −ln a ≥1 −a for 0 < a.
"N
PN",0.5707792207792208,"In summary, for
Ep(x1) [f(x1, y)] −
1
N −1 N
X"
"N
PN",0.5714285714285714,"i=2
f(xi, y)"
"N
PN",0.5720779220779221,"⩽ϵ
(A87)"
"N
PN",0.5727272727272728,we have −ϵ Z ⩽ln
"N
PN",0.5733766233766234,"Ep(x1) [f(x1, y)]"
"N
PN",0.574025974025974,"1
N−1
PN
i=2 f(xi, y) !"
"N
PN",0.5746753246753247,"⩽
ϵ
Z −ϵ .
(A88)"
"N
PN",0.5753246753246753,Under review as a conference paper at ICLR 2022
"N
PN",0.575974025974026,It follows that −ϵ
"N
PN",0.5766233766233766,"Z ⩽DE ⩽
ϵ
Z −ϵ .
(A89)"
"N
PN",0.5772727272727273,"DE averages the ln-term over y and ˜X, therefore it has an even smaller bound than the bound above
on the ln-term. Consequently, for small b −a and large N, the term DE is small."
"N
PN",0.577922077922078,"KL is decreased by making the variation distribution q(x1 | y) more similar to the posterior p(x1 | y).
The value DE only depends on the marginal distributions p(y) and p(x), since p( ˜X) = QN
i=2 p(xi).
The value DE can be changed by adding an offset to f(x, y). However, scaling f(x, y) by a factor
does not change DE. Consequently, DE is difﬁcult to change."
"N
PN",0.5785714285714286,"Therefore, increasing InfoLOOB is most effective by making q(x1 | y) more similar to the posterior
p(x1 | y)."
"N
PN",0.5792207792207792,"Gradient of InfoLOOB expressed by gradients of KL and DE. Assume that the similarity is
parametrized by w giving sim(x, y; w)."
"N
PN",0.5798701298701299,"KL(p(x1 | y) ∥q(x1 | y)) =
Z
p(x1 | y) ln
p(x1 | y)"
"N
PN",0.5805194805194805,q(x1 | y)
"N
PN",0.5811688311688312,"
dx
(A90)"
"N
PN",0.5818181818181818,"= −τ −1
Z
p(x1 | y) sim(x1, y; w) dx1 + ln Z + C ,"
"N
PN",0.5824675324675325,where C is independent of w.
"N
PN",0.5831168831168831,"Next, we compute the derivative of KL with respect to parameters w. ∂KL"
"N
PN",0.5837662337662337,"∂w
(A91)"
"N
PN",0.5844155844155844,"= −τ −1
Z
p(x1 | y) ∂sim(x1, y; w)"
"N
PN",0.5850649350649351,"∂w
dx1 + 1 Z"
"N
PN",0.5857142857142857,"Z
p(x1) exp(τ −1 sim(x1, y; w))"
"N
PN",0.5863636363636363,"∂sim(x1, y; w)
∂sim(x1, y; w)"
"N
PN",0.587012987012987,"∂w
dx1"
"N
PN",0.5876623376623377,"= −τ −1
Z
p(x1 | y) ∂sim(x1, y; w)"
"N
PN",0.5883116883116883,"∂w
dx1 + τ −1
Z
p(x1) exp(τ −1 sim(x1, y; w))"
"N
PN",0.5889610389610389,"Z
∂sim(x1, y; w)"
"N
PN",0.5896103896103896,"∂w
dx1"
"N
PN",0.5902597402597403,"= −τ −1
Z
p(x1 | y) ∂sim(x1, y; w)"
"N
PN",0.5909090909090909,"∂w
dx1 + τ −1
Z
q(x1 | y) ∂sim(x1, y; w)"
"N
PN",0.5915584415584415,"∂w
dx1"
"N
PN",0.5922077922077922,"= τ −1
Z
(q(x1 | y) −p(x1 | y)) ∂sim(x1, y; w)"
"N
PN",0.5928571428571429,"∂w
dx1 ."
"N
PN",0.5935064935064935,"The derivative is the average difference between the posterior distribution p(x1 | y) and the variational
distribution q(x1 | y) multiplied by the derivative of the similarity function. If both distribution
match, then the derivative vanishes."
"N
PN",0.5941558441558441,Under review as a conference paper at ICLR 2022
"N
PN",0.5948051948051948,"Next, we compute the derivative of DE with respect to parameters w. ∂DE"
"N
PN",0.5954545454545455,"∂w
(A92)"
"N
PN",0.5961038961038961,= Ep(y)
"N
PN",0.5967532467532467,∂ln Z ∂w
"N
PN",0.5974025974025974,"
−Ep(y) """
"N
PN",0.5980519480519481,"Ep( ˜
X)"
"N
PN",0.5987012987012987,"""
1
N−1
PN
i=2 τ −1 exp(τ −1 sim(xi, y; w)) ∂sim(xi,y;w)"
"N
PN",0.5993506493506493,"∂w
1
N−1
PN
j=2 f(xj, y) ##"
"N
PN",0.6,= Ep(y)
"N
PN",0.6006493506493507,"
τ −1
Z
q(x1 | y) ∂sim(x1, y; w)"
"N
PN",0.6012987012987013,"∂w
dx1 "
"N
PN",0.6019480519480519,"−Ep(y) """
"N
PN",0.6025974025974026,"Ep( ˜
X)"
"N
PN",0.6032467532467533,"""
1
N−1
PN
i=2 τ −1 exp(τ −1 sim(xi, y; w)) ∂sim(xi,y;w)"
"N
PN",0.6038961038961039,"∂w
1
N−1
PN
j=2 f(xj, y) ##"
"N
PN",0.6045454545454545,= τ −1 Ep(y)
"N
PN",0.6051948051948052,"Z
q(x1 | y) ∂sim(x1, y; w)"
"N
PN",0.6058441558441559,"∂w
dx1 "
"N
PN",0.6064935064935065,"−τ −1 Ep(y) """
"N
PN",0.6071428571428571,"Ep( ˜
X)"
"N
PN",0.6077922077922078,"""
1
N −1 N
X i=2"
"N
PN",0.6084415584415584,"f(xi, y)"
"N
PN",0.6090909090909091,"1
N−1
PN
j=2 f(xj, y)"
"N
PN",0.6097402597402597,"∂sim(xi, y; w) ∂w ##"
"N
PN",0.6103896103896104,= τ −1 Ep(y)
"N
PN",0.611038961038961,"Z p(x1) f(x1, y)"
"N
PN",0.6116883116883117,"Ep(x) [f(x, y)]
∂sim(x1, y; w)"
"N
PN",0.6123376623376623,"∂w
dx1 "
"N
PN",0.612987012987013,"−τ −1 Ep(y) """
"N
PN",0.6136363636363636,"Ep( ˜
X)"
"N
PN",0.6142857142857143,"""
1
N −1 N
X i=2"
"N
PN",0.6149350649350649,"f(xi, y)"
"N
PN",0.6155844155844156,"1
N−1
PN
j=2 f(xj, y)"
"N
PN",0.6162337662337662,"∂sim(xi, y; w) ∂w ##"
"N
PN",0.6168831168831169,= τ −1 Ep(y)
"N
PN",0.6175324675324675,"
Ep(x1)"
"N
PN",0.6181818181818182,"
f(x1, y)
Ep(x) [f(x, y)]
∂sim(x1, y; w) ∂w "
"N
PN",0.6188311688311688,"−τ −1 Ep(y) """
"N
PN",0.6194805194805195,"Ep( ˜
X)"
"N
PN",0.6201298701298701,"""
1
N −1 N
X i=2"
"N
PN",0.6207792207792208,"f(xi, y)"
"N
PN",0.6214285714285714,"1
N−1
PN
j=2 f(xj, y)"
"N
PN",0.6220779220779221,"∂sim(xi, y; w) ∂w ##"
"N
PN",0.6227272727272727,= τ −1 Ep(y)
"N
PN",0.6233766233766234,"""
1
N −1 N
X"
"N
PN",0.624025974025974,"i=2
Ep(xi)"
"N
PN",0.6246753246753247,"
f(xi, y)
Ep(x) [f(x, y)]
∂sim(xi, y; w) ∂w #"
"N
PN",0.6253246753246753,"−τ −1 Ep(y) """
"N
PN",0.625974025974026,"Ep( ˜
X)"
"N
PN",0.6266233766233766,"""
1
N −1 N
X i=2"
"N
PN",0.6272727272727273,"f(xi, y)"
"N
PN",0.6279220779220779,"1
N−1
PN
j=2 f(xj, y)"
"N
PN",0.6285714285714286,"∂sim(xi, y; w) ∂w ##"
"N
PN",0.6292207792207792,"= τ −1 Ep(y) """
"N
PN",0.6298701298701299,"Ep( ˜
X)"
"N
PN",0.6305194805194805,"""
1
N −1 N
X i=2"
"N
PN",0.6311688311688312,"f(xi, y)
Ep(x) [f(x, y)]
∂sim(xi, y; w) ∂w ##"
"N
PN",0.6318181818181818,"−τ −1 Ep(y) """
"N
PN",0.6324675324675325,"Ep( ˜
X)"
"N
PN",0.6331168831168831,"""
1
N −1 N
X i=2"
"N
PN",0.6337662337662338,"f(xi, y)"
"N
PN",0.6344155844155844,"1
N−1
PN
j=2 f(xj, y)"
"N
PN",0.6350649350649351,"∂sim(xi, y; w) ∂w ##"
"N
PN",0.6357142857142857,"= τ −1 Ep(y) """
"N
PN",0.6363636363636364,"Ep( ˜
X)"
"N
PN",0.637012987012987,"""
1
N −1 N
X i=2"
"N
PN",0.6376623376623377,"1
Ep(x) [f(x, y)] −
1"
"N
PN",0.6383116883116883,"1
N−1
PN
j=2 f(xj, y) !"
"N
PN",0.638961038961039,"f(xi, y) ∂sim(xi, y; w) ∂w ##"
"N
PN",0.6396103896103896,"= τ −1 Ep(y) """
"N
PN",0.6402597402597403,"Ep( ˜
X)"
"N
PN",0.6409090909090909,"""
1
N −1 N
X i=2"
"N
PN",0.6415584415584416,"1
Z −
1"
"N
PN",0.6422077922077922,"1
N−1
PN
j=2 f(xj, y) !"
"N
PN",0.6428571428571429,"f(xi, y) ∂sim(xi, y; w) ∂w ## ."
"N
PN",0.6435064935064935,The derivative is the average of 1
"N
PN",0.6441558441558441,"Z −
1
1
N−1
PN
j=2 f(xj,y) multiplied by the score function and the"
"N
PN",0.6448051948051948,"derivative of the similarity function. The average is over y and ˜X, therefore the whole derivative
becomes even smaller. Consequently, for small b −a and large N, the derivative of DE is small."
"N
PN",0.6454545454545455,"Note that for
Ep(x1) [f(x1, y)] −
1
N −1 N
X"
"N
PN",0.6461038961038961,"i=2
f(xi, y)"
"N
PN",0.6467532467532467,"⩽ϵ
(A93)"
"N
PN",0.6474025974025974,Under review as a conference paper at ICLR 2022
"N
PN",0.6480519480519481,"we have
1
Z −
1"
"N
PN",0.6487012987012987,"1
N−1
PN
j=2 f(xj, y)
⩽1"
"N
PN",0.6493506493506493,"Z −
1
Z + ϵ =
ϵ
Z(Z + ϵ) ,
(A94)"
"N
PN",0.65,"1
Z −
1"
"N
PN",0.6506493506493507,"1
N−1
PN
j=2 f(xj, y)
≥1"
"N
PN",0.6512987012987013,"Z −
1
Z −ϵ = −
ϵ
Z(Z −ϵ) ,
(A95)"
"N
PN",0.6519480519480519,"therefore

1
Z −
1"
"N
PN",0.6525974025974026,"1
N−1
PN
j=2 f(xj, y)"
"N
PN",0.6532467532467533,"⩽
ϵ
Z(Z −ϵ) .
(A96)"
"N
PN",0.6538961038961039,"If the expectation Z is well approximated by the average
1
N−1
PN
j=2 f(xj, y), then both DE and its
gradient are small."
"N
PN",0.6545454545454545,Derivative of InfoLOOB via KL and DE:
"N
PN",0.6551948051948052,∂IInfoLOOB(X1 ; Y )
"N
PN",0.6558441558441559,"∂w
= ∂DE"
"N
PN",0.6564935064935065,"∂w
−∂KL"
"N
PN",0.6571428571428571,"∂w .
(A97)"
"N
PN",0.6577922077922078,"In this gradient, the KL term is dominating, therefore f(x, y) is pushed to approximate the conditional
probability p(y | x). Modern Hopﬁeld networks lead to larger values of p(y | x) as the mutual
information becomes larger, therefore modern Hopﬁeld networks help to push f(x, y) to large values.
Furthermore, modern Hopﬁeld networks increase Z, which is in the denominator of the bound on
DE and its derivative."
"N
PN",0.6584415584415585,"A.1.4
INFONCE AND INFOLOOB: GRADIENTS"
"N
PN",0.6590909090909091,"We consider the InfoNCE and the InfoLOOB loss function.
For computing the loss
function, we sample N pairs independently from p(x, y), which gives the training set
{(x1, y1), (x2, y2), . . . , (xN, yN)}. InfoNCE and InfoLOOB only differ in using the positive
example in the negatives.
More precisely, InfoNCE uses for the matrix of negative samples
X = (x1, . . . , xN), while InfoLOOB uses ˜
X = (x2, . . . , xN)."
"N
PN",0.6597402597402597,InfoNCE.
"N
PN",0.6603896103896104,The InfoNCE loss is
"N
PN",0.6610389610389611,"LInfoNCE = −1 N N
X"
"N
PN",0.6616883116883117,"i=1
ln"
"N
PN",0.6623376623376623,"f(xi, yi)"
"N
PN",0.662987012987013,"1
N
PN
j=1 f(xj, yi) ! =
1
N N
X"
"N
PN",0.6636363636363637,"i=1
LInfoNCE(yi) ,
(A98)"
"N
PN",0.6642857142857143,where we used
"N
PN",0.6649350649350649,LInfoNCE(yi) = −ln
"N
PN",0.6655844155844156,"f(xi, yi)"
"N
PN",0.6662337662337663,"1
N
PN
j=1 f(xj, yi) !"
"N
PN",0.6668831168831169,".
(A99)"
"N
PN",0.6675324675324675,"For the score function f(x, y), we use"
"N
PN",0.6681818181818182,"f(x, y) = exp(τ −1 sim(x, y)) ,
(A100)"
"N
PN",0.6688311688311688,"sim(x, y) = yT x
(A101)"
"N
PN",0.6694805194805195,with τ as the temperature.
"N
PN",0.6701298701298701,The loss function for this score function is
"N
PN",0.6707792207792208,"LInfoNCE(y) = −τ −1 yT x1 + τ −1 lse
 
τ −1, XT y

,
(A102)"
"N
PN",0.6714285714285714,where lse is the log-sum-exp function (lse):
"N
PN",0.672077922077922,"lse(β, a) = β−1 log N
X"
"N
PN",0.6727272727272727,"i=1
exp(βai) !"
"N
PN",0.6733766233766234,",
(A103)"
"N
PN",0.674025974025974,Under review as a conference paper at ICLR 2022
"N
PN",0.6746753246753247,"for β > 0 and vector a = (a1, . . . , aN)."
"N
PN",0.6753246753246753,The gradient with respect to y is
"N
PN",0.675974025974026,∂LInfoNCE(y)
"N
PN",0.6766233766233766,"∂y
= −τ −1 x1 + τ −1 X softmax
 
τ −1XT y

,
(A104)"
"N
PN",0.6772727272727272,"which is the positive example x1 that ﬁts to the anchor example y minus the Hopﬁeld network update
with state pattern y and stored patterns X and then this difference multiplied by τ −1."
"N
PN",0.6779220779220779,"This gradient can be simpliﬁed, since the positive example x1 is also in the negative examples. Using
p = (p1, . . . , pN)T = softmax
 
τ −1XT y

, we obtain"
"N
PN",0.6785714285714286,∂LInfoNCE(y)
"N
PN",0.6792207792207792,"∂y
(A105)"
"N
PN",0.6798701298701298,"= −τ −1 (1 −p1)

x1 −
1
1 −p1
X
 
softmax
 
τ −1XT y

−(p1, 0, . . . , 0)T "
"N
PN",0.6805194805194805,"= −τ −1 (1 −p1)

x1 −
˜
X softmax

τ −1 ˜
XT y

= (1 −p1) ∂LInfoLOOB(y) ∂y
."
"N
PN",0.6811688311688312,"where
1
1 −p1
X
 
softmax
 
τ −1XT y

−(p1, 0, . . . , 0)T 
(A106)"
"N
PN",0.6818181818181818,"=
1
1 −p1
X
 
(p1, p2, . . . , pN)T −(p1, 0, . . . , 0)T "
"N
PN",0.6824675324675324,"=
1
1 −p1
X(0, p2, . . . , pN)T =
1
1 −p1 N
X"
"N
PN",0.6831168831168831,"i=2
pi xi"
"N
PN",0.6837662337662338,"is the softmax average over the negatives xi for 2 ⩽i ⩽N without x1. It can be easily seen that
1
1−p1
PN
i=2 pi = 1−p1"
"N
PN",0.6844155844155844,1−p1 = 1. For the derivative of the InfoLOOB see below.
"N
PN",0.685064935064935,The gradient with respect to x1 is
"N
PN",0.6857142857142857,∂LInfoNCE(y)
"N
PN",0.6863636363636364,"∂x1
= −τ −1 y + τ −1
exp(τ −1 xT
1 y)
PN
i=1 exp(τ −1xT
i y)
y
(A107)"
"N
PN",0.687012987012987,"= −τ −1 (1 −p1) y .
(A108)"
"N
PN",0.6876623376623376,"Consequently, the learning rate is scaled by (1 −p1)."
"N
PN",0.6883116883116883,The sum of gradients with respect to x1 and xi is
"N
PN",0.688961038961039,"∂LInfoNCE(y) ∂x1
+ N
X i=1"
"N
PN",0.6896103896103896,∂LInfoNCE(y)
"N
PN",0.6902597402597402,"∂xi
= −τ −1 y + τ −1 y 1T softmax
 
τ −1XT y

(A109)"
"N
PN",0.6909090909090909,"= −τ −1 y + τ −1 y = 0 ,"
"N
PN",0.6915584415584416,"where 1 is the vector with ones. However, the derivatives with respect to the weights are not zero
since the xi are differently computed."
"N
PN",0.6922077922077922,InfoLOOB.
"N
PN",0.6928571428571428,The InfoLOOB loss is
"N
PN",0.6935064935064935,"LInfoLOOB = −1 N N
X"
"N
PN",0.6941558441558442,"i=1
ln"
"N
PN",0.6948051948051948,"f(xi, yi)"
"N
PN",0.6954545454545454,"1
N−1
PN
j=1,j̸=i f(xj, yi) ! =
1
N N
X"
"N
PN",0.6961038961038961,"i=1
LInfoLOOB(yi) ,
(A110)"
"N
PN",0.6967532467532468,where we used
"N
PN",0.6974025974025974,LInfoLOOB(yi) = −ln
"N
PN",0.698051948051948,"f(xi, yi)"
"N
PN",0.6987012987012987,"1
N−1
PN
j=1,j̸=i f(xj, yi) !"
"N
PN",0.6993506493506494,".
(A111)"
"N
PN",0.7,Under review as a conference paper at ICLR 2022
"N
PN",0.7006493506493506,"For the score function f(x, y), we use"
"N
PN",0.7012987012987013,"f(x, y) = exp(τ −1 sim(x, y)) ,
(A112)"
"N
PN",0.701948051948052,"sim(x, y) = yT x
(A113)"
"N
PN",0.7025974025974026,with τ as the temperature.
"N
PN",0.7032467532467532,The loss function for this score function is
"N
PN",0.7038961038961039,"LInfoLOOB(y) = −τ −1 yT x1 + τ −1 lse

τ −1, ˜
XT y

,
(A114)"
"N
PN",0.7045454545454546,where lse is the log-sum-exponential function.
"N
PN",0.7051948051948052,The gradient with respect to y is
"N
PN",0.7058441558441558,∂LInfoLOOB(y)
"N
PN",0.7064935064935065,"∂y
= −τ −1 x1 + τ −1 ˜
X softmax

τ −1 ˜
XT y

,
(A115)"
"N
PN",0.7071428571428572,"which is the positive example x1 that ﬁts to the anchor example y minus the Hopﬁeld network update
with state pattern y and stored patterns ˜
X and then this difference multiplied by τ −1."
"N
PN",0.7077922077922078,The gradient with respect to x1 is
"N
PN",0.7084415584415584,∂LInfoLOOB(y)
"N
PN",0.7090909090909091,"∂x1
= −τ −1 y .
(A116)"
"N
PN",0.7097402597402598,The sum of gradients with respect to x1 and xi is
"N
PN",0.7103896103896103,∂LInfoLOOB(y)
"N
PN",0.711038961038961,"∂x1
+
X i"
"N
PN",0.7116883116883117,∂LInfoLOOB(y)
"N
PN",0.7123376623376624,"∂xi
= −τ −1 y + τ −1 y 1T softmax

τ −1 ˜
XT y
"
"N
PN",0.712987012987013,(A117)
"N
PN",0.7136363636363636,"= −τ −1 y + τ −1 y = 0 ,"
"N
PN",0.7142857142857143,"where 1 is the vector with ones. However, the derivatives with respect to the weights are not zero
since the xi are differently computed."
"N
PN",0.714935064935065,Gradients with respect to τ −1.
"N
PN",0.7155844155844155,The gradient of the InfoNCE loss Eq. (A98) using the similarity Eq. (A100) with respect to τ −1 is
"N
PN",0.7162337662337662,∂LInfoNCE(y)
"N
PN",0.7168831168831169,"∂τ −1
= −yT x1 + yT X softmax
 
τ −1XT y

(A118)"
"N
PN",0.7175324675324676,"= −yT  
x1 −X softmax
 
τ −1XT y

,
(A119)"
"N
PN",0.7181818181818181,"which is the similarity of the anchor y with the difference of the positive example x1 and the Hopﬁeld
network update with state pattern y and stored patterns X. The gradient of the InfoLOOB loss
Eq. (A110) using the similarity Eq. (A112) with respect to τ −1 is"
"N
PN",0.7188311688311688,∂LInfoLOOB(y)
"N
PN",0.7194805194805195,"∂τ −1
= −yT x1 + yT ˜
X softmax

τ −1 ˜
XT y

(A120)"
"N
PN",0.7201298701298702,"= −yT

x1 −
˜
X softmax

τ −1 ˜
XT y

.
(A121)"
"N
PN",0.7207792207792207,"with the difference that the Hopﬁeld network update is done with stored patterns ˜
X instead of X."
"N
PN",0.7214285714285714,"Without the positive example x1 in the stored patterns ˜
X, the term x1 −˜
X softmax

τ −1 ˜
XT y
"
"N
PN",0.7220779220779221,"in Eq. (A120) will not decrease like the term x1 −X softmax
 
τ −1XT y

in Eq. (A118) but grow
even larger with better separation of the positive and negative examples."
"N
PN",0.7227272727272728,"A.1.5
INFOLOOB AND INFONCE: PROBABILITY ESTIMATORS"
"N
PN",0.7233766233766233,"In McAllester & Stratos (2018; 2020) it was shown that estimators of the mutual information by lower
bounds have problems as they come with serious statistical limitations. Statistically more justiﬁed for"
"N
PN",0.724025974025974,Under review as a conference paper at ICLR 2022
"N
PN",0.7246753246753247,"representing the mutual information is a difference of entropies, which are estimated by minimizing
the cross-entropy loss. Both InfoNCE and InfoLOOB losses can be viewed as cross-entropy losses."
"N
PN",0.7253246753246754,"We
sample
N
pairs
independently
from
p(x, y),
which
gives
Z
=
{(x1, y1), (x2, y2), . . . , (xN, yN)}. We set X = {x1, x2, . . . , xN} and Y = {y1, y2, . . . , yN},
so that, Z = X × Y . The score function f(x, y) is an estimator for p(x, y). Then we obtain
estimators ˆq for the conditional probabilities. ˆq(yi | xi, Y \ {yi}) is an estimator for p(yi | xi) and
ˆq(xi | yi, X \ {xi}) an estimator for p(xi | yi). Each estimator ˆq uses beyond (xi, yi) additional
samples to estimate the normalizing constant. For InfoNCE these estimators are"
"N
PN",0.7259740259740259,"ˆq1(yi | xi, Y \ {yi}) =
f(xi, yi)"
"N
PN",0.7266233766233766,"1
N
PN
j=1 f(xi, yj)
≈
f(xi, yi)
Ep(y) [f(xi, y)],
(A122)"
"N
PN",0.7272727272727273,"ˆq2(xi | yi, X \ {xi}) =
f(xi, yi)"
"N
PN",0.727922077922078,"1
N
PN
j=1 f(xj, yi)
≈
f(xi, yi)
Ep(x) [f(x, yi)] .
(A123)"
"N
PN",0.7285714285714285,The cross-entropy losses for the InfoNCE estimators are
"N
PN",0.7292207792207792,"L1
InfoNCE = −1 N N
X"
"N
PN",0.7298701298701299,"i=1
ln"
"N
PN",0.7305194805194806,"f(xi, yi)"
"N
PN",0.7311688311688311,"1
N
PN
j=1 f(xi, yj) !"
"N
PN",0.7318181818181818,",
(A124)"
"N
PN",0.7324675324675325,"L2
InfoNCE = −1 N N
X"
"N
PN",0.7331168831168832,"i=1
ln"
"N
PN",0.7337662337662337,"f(xi, yi)"
"N
PN",0.7344155844155844,"1
N
PN
j=1 f(xj, yi) !"
"N
PN",0.7350649350649351,".
(A125)"
"N
PN",0.7357142857142858,For InfoLOOB these estimators are
"N
PN",0.7363636363636363,"ˆq1(yi | xi, Y \ {yi}) =
f(xi, yi)"
"N
PN",0.737012987012987,"1
N−1
PN
j=1,j̸=i f(xi, yj)
≈
f(xi, yi)
Ep(y) [f(xi, y)] ,
(A126)"
"N
PN",0.7376623376623377,"ˆq2(xi | yi, X \ {xi}) =
f(xi, yi)"
"N
PN",0.7383116883116884,"1
N−1
PN
j=1,j̸=i f(xj, yi)
≈
f(xi, yi)
Ep(x) [f(x, yi)] .
(A127)"
"N
PN",0.7389610389610389,The cross-entropy losses for the InfoLOOB estimators are
"N
PN",0.7396103896103896,"L1
InfoLOOB = −1 N N
X"
"N
PN",0.7402597402597403,"i=1
ln"
"N
PN",0.740909090909091,"f(xi, yi)"
"N
PN",0.7415584415584415,"1
N−1
PN
j=1,j̸=i f(xi, yj) !"
"N
PN",0.7422077922077922,",
(A128)"
"N
PN",0.7428571428571429,"L2
InfoLOOB = −1 N N
X"
"N
PN",0.7435064935064936,"i=1
ln"
"N
PN",0.7441558441558441,"f(xi, yi)"
"N
PN",0.7448051948051948,"1
N−1
PN
j=1,j̸=i f(xj, yi) !"
"N
PN",0.7454545454545455,".
(A129)"
"N
PN",0.7461038961038962,The InfoLOOB estimator uses for normalization
"N
PN",0.7467532467532467,"Ep(x) [f(x, yi)] ≈
1
N −1 N
X"
"N
PN",0.7474025974025974,"j=1,j̸=i
f(xj, yi) ,
(A130)"
"N
PN",0.7480519480519481,"Ep(y) [f(xi, y)] ≈
1
N −1 N
X"
"N
PN",0.7487012987012988,"j=1,j̸=i
f(xi, yj) ,
(A131)"
"N
PN",0.7493506493506493,"in contrast to InfoNCE, which uses"
"N
PN",0.75,"Ep(x) [f(x, yi)] ≈
1
N N
X"
"N
PN",0.7506493506493507,"j=1
f(xj, yi) ,
(A132)"
"N
PN",0.7512987012987012,"Ep(y) [f(xi, y)] ≈
1
N N
X"
"N
PN",0.7519480519480519,"j=1
f(xi, yj) .
(A133)"
"N
PN",0.7525974025974026,"If InfoNCE estimates the normalizing constant separately, then it would be biased. (xi, yi) is drawn
according to p(xi, yi) instead of p(xi)p(yi). In contrast, if InfoLOOB estimated the normalizing
constant separately, then it would be unbiased."
"N
PN",0.7532467532467533,Under review as a conference paper at ICLR 2022
"N
PN",0.7538961038961038,"A.1.6
INFOLOOB AND INFONCE: LOSSES"
"N
PN",0.7545454545454545,"We have N pairs drawn iid from p(x, y), where we assume that a pair (xi, yi) is already
an embedding of the original drawn pair.
These build up the embedding training set Z =
{(x1, y1), (x2, y2), . . . , (xN, yN)} that allows to construct the matrices X = (x1, x2, . . . , xN)
of N embedding samples xi and Y = (y1, y2, . . . , yN) of N embedding samples yi. We also have
M stored patterns U = (u1, . . . , uM) and K stored patterns V = (v1, . . . , vK)."
"N
PN",0.7551948051948052,"The state vectors xi and yi are the queries for the Hopﬁeld networks, which retrieve some vectors
from U or V . We normalize vectors ∥xi∥= ∥yi∥= ∥ui∥= ∥vi∥= 1. The following vectors are
retrieved from modern Hopﬁeld networks (Ramsauer et al., 2021):"
"N
PN",0.7558441558441559,"Uxi = U softmax(β U T xi) ,
Uyi = U softmax(β U T yi) ,
(A134)"
"N
PN",0.7564935064935064,"Vxi = V softmax(β V T xi) ,
Vyi = V softmax(β V T yi)
(A135)"
"N
PN",0.7571428571428571,"where Uxi denotes an image-retrieved image embedding, Uyi a text-retrieved image embedding,
Vxi an image-retrieved text embedding and Vyi a text-retrieved text embedding. The hyperparameter
β corresponds to the inverse temperature: β = 0 retrieves the average of the stored pattern, while
large β retrieve the stored pattern that is most similar to the state pattern (query)."
"N
PN",0.7577922077922078,We consider the loss functions
"N
PN",0.7584415584415585,"LInfoNCE = −1 N N
X"
"N
PN",0.759090909090909,"i=1
log
exp(τ −1 xT
i yi)
PN
j=1 exp(τ −1 xT
i yj)
−1 N N
X"
"N
PN",0.7597402597402597,"i=1
log
exp(τ −1 xT
i yi)
PN
j=1 exp(τ −1 xT
j yi)
,"
"N
PN",0.7603896103896104,(A136)
"N
PN",0.7610389610389611,"LInfoLOOB = −1 N N
X"
"N
PN",0.7616883116883116,"i=1
log
exp(τ −1 xT
i yi)
PN
j̸=i exp(τ −1 xT
i yj)
−1 N N
X"
"N
PN",0.7623376623376623,"i=1
log
exp(τ −1 xT
i yi)
PN
j̸=i exp(τ −1 xT
j yi)
,"
"N
PN",0.762987012987013,(A137)
"N
PN",0.7636363636363637,"LH−UVUV
InfoLOOB = −1 N N
X"
"N
PN",0.7642857142857142,"i=1
log
exp(τ −1 U T
xiVyi)
PN
j̸=i exp(τ −1 U T
xiVyj)
−1 N N
X"
"N
PN",0.7649350649350649,"i=1
log
exp(τ −1 U T
xiVyi)
PN
j̸=i exp(τ −1 U T
xjVyi)
,"
"N
PN",0.7655844155844156,(A138)
"N
PN",0.7662337662337663,"LH−UUVV
InfoLOOB = −1 N N
X"
"N
PN",0.7668831168831168,"i=1
log
exp(τ −1 U T
xiUyi)
PN
j̸=i exp(τ −1 U T
xiUyj)
−1 N N
X"
"N
PN",0.7675324675324675,"i=1
log
exp(τ −1 V T
xiVyi)
PN
j̸=i exp(τ −1 V T
xjVyi)
,"
"N
PN",0.7681818181818182,(A139)
"N
PN",0.7688311688311689,where for InfoLOOB the sum P
"N
PN",0.7694805194805194,"j̸=i in the denominator contains only negative examples j. We do
not consider the loss function LH−UVUV
InfoLOOB because of the high variance in the dot product U T
xiVyi as
elaborated in the following."
"N
PN",0.7701298701298701,"Let us consider the dot product between the anchor retrieval with the positive pattern retrieval for the
loss functions with Hopﬁeld. In the ﬁrst term of the loss function Eq. (A138), Uxi is the anchor with
Vyi as the positive sample and Vyi with Uxi as the positive sample for the second term, since the
anchor also appears in each term of the denominator. Equivalently the same is valid for Eq. (A139),
but with positive samples Vxi and Uyi respectively. These dot products can be written as"
"N
PN",0.7707792207792208,"U T
xiVyi = softmax(β U T xi)T U T V softmax(β V T yi) ,
(A140)"
"N
PN",0.7714285714285715,"U T
xiUyi = softmax(β U T xi)T U T U softmax(β U T yi) ,
(A141)"
"N
PN",0.772077922077922,"V T
xiVyi = softmax(β V T xi)T V T V softmax(β V T yi) .
(A142)"
"N
PN",0.7727272727272727,"High variance of U T
xiVyi. To compute the dot product U T
xiVyi, M + K stored patterns are required
(M of the uj and K of the vj). In contrast, the dot products U T
xiUyi and V T
xiVyi require only M
or respectively K stored patterns. Therefore, U T
xiVyi has higher variance than both U T
xiUyi and
V T
xiVyi."
"N
PN",0.7733766233766234,"Covariance structure extracted by U T
xiUyi and V T
xiVyi."
"N
PN",0.7740259740259741,Under review as a conference paper at ICLR 2022
"N
PN",0.7746753246753246,The Jacobian J of the softmax p = softmax(βa) is
"N
PN",0.7753246753246753,J(βa) = ∂softmax(βa)
"N
PN",0.775974025974026,"∂a
= β
 
diag(p) −ppT 
,
(A143)"
"N
PN",0.7766233766233767,"which is a symmetric, positive semi-deﬁnite matrix with one eigenvalue of zero for eigenvector 1.
J(βa) is diagonally dominant since |pi(1 −pi)| −P"
"N
PN",0.7772727272727272,j̸=i |pipj| = pi −P
"N
PN",0.7779220779220779,j pipj = pi −pi = 0.
"N
PN",0.7785714285714286,Next we give upper bounds on the norm of J.
"N
PN",0.7792207792207793,"Lemma A1. For a softmax p = softmax(βx) with m = maxi pi(1 −pi), the spectral norm of the
Jacobian J of the softmax is bounded:"
"N
PN",0.7798701298701298,"∥J∥2 ⩽2 m β ,
(A144)
∥J∥1 ⩽2 m β ,
(A145)
∥J∥∞⩽2 m β .
(A146)"
"N
PN",0.7805194805194805,In particular everywhere holds
"N
PN",0.7811688311688312,∥J∥2 ⩽1
"N
PN",0.7818181818181819,"2 β .
(A147)"
"N
PN",0.7824675324675324,"If pmax = maxi pi ≥1 −ϵ ≥0.5, then for the spectral norm of the Jacobian holds"
"N
PN",0.7831168831168831,"∥J∥2 ⩽2 ϵ β −2 ϵ2 β
< 2 ϵ β .
(A148)"
"N
PN",0.7837662337662338,Proof. We consider the maximum absolute column sum norm
"N
PN",0.7844155844155845,"∥A∥1 = max
j X"
"N
PN",0.785064935064935,"i
|aij|
(A149)"
"N
PN",0.7857142857142857,and the maximum absolute row sum norm
"N
PN",0.7863636363636364,"∥A∥∞= max
i X"
"N
PN",0.787012987012987,"j
|aij| .
(A150)"
"N
PN",0.7876623376623376,"We have for A = J = β
 
diag(p) −ppT  X"
"N
PN",0.7883116883116883,"j
|aij| = β "
"N
PN",0.788961038961039,"pi(1 −pi) +
X"
"N
PN",0.7896103896103897,"j,j̸=i
pipj "
"N
PN",0.7902597402597402,"= β pi (1 −2pi +
X"
"N
PN",0.7909090909090909,"j
pj)
(A151)"
"N
PN",0.7915584415584416,"= 2 β pi (1 −pi) ⩽2 m β , X"
"N
PN",0.7922077922077922,"i
|aij| = β "
"N
PN",0.7928571428571428,"pj (1 −pj) +
X"
"N
PN",0.7935064935064935,"i,i̸=j
pjpi "
"N
PN",0.7941558441558442,"= β pj (1 −2pj +
X"
"N
PN",0.7948051948051948,"i
pi)
(A152)"
"N
PN",0.7954545454545454,= 2 β pj (1 −pj) ⩽2 m β .
"N
PN",0.7961038961038961,"Therefore, we have"
"N
PN",0.7967532467532468,"∥J∥1 ⩽2 m β ,
(A153)
∥J∥∞⩽2 m β ,
(A154)"
"N
PN",0.7974025974025974,"∥J∥2 ⩽
q"
"N
PN",0.798051948051948,"∥J∥1∥J∥∞⩽2 m β .
(A155)"
"N
PN",0.7987012987012987,The last inequality is a direct consequence of Hölder’s inequality.
"N
PN",0.7993506493506494,"For 0 ⩽pi ⩽1, we have pi(1 −pi) ⩽0.25. Therefore, m ⩽0.25 for all values of pi."
"N
PN",0.8,"If pmax ≥1 −ϵ ≥0.5 (ϵ ⩽0.5), then 1 −pmax ⩽ϵ and for pi ̸= pmax pi ⩽ϵ. The derivative
∂x(1 −x)/∂x = 1 −2x > 0 for x < 0.5, therefore x(1 −x) increases with x for x < 0.5. Using
x = 1 −pmax and for pi ̸= pmax x = pi, we obtain pi(1 −pi) ⩽ϵ(1 −ϵ) for all i. Consequently,
we have m ⩽ϵ(1 −ϵ)."
"N
PN",0.8006493506493506,Under review as a conference paper at ICLR 2022
"N
PN",0.8012987012987013,"For the softmax p = softmax(βa) with Jacobian ∂J/∂a = J(βa) = β
 
diag(p) −ppT 
and for
arbitrary N-dimensional vectors b and c, we have"
"N
PN",0.801948051948052,"bT J(βa) c = β bT  
diag(p) −p pT 
c = β X"
"N
PN",0.8025974025974026,"i
pi bi ci − X"
"N
PN",0.8032467532467532,"i
pi bi !  X"
"N
PN",0.8038961038961039,"i
pi ci !! ."
"N
PN",0.8045454545454546,(A156)
"N
PN",0.8051948051948052,"Therefore, bT J(βa)c is β times the covariance between b and c if component i is drawn with
probability pi of the multinomial distribution p. In our case the component i is sample i."
"N
PN",0.8058441558441558,"Using the mean ˆu = 1/M PM
i=1 ui, the empirical covariance of data U is"
"N
PN",0.8064935064935065,"Cov(U) = 1/M U U T −ˆu ˆuT ,
(A157)"
"N
PN",0.8071428571428572,"[Cov(U)]kl = M
X"
"N
PN",0.8077922077922078,"i=1
1/M uik uil − M
X"
"N
PN",0.8084415584415584,"i=1
1/M uik"
"N
PN",0.8090909090909091,"!  M
X"
"N
PN",0.8097402597402598,"i=1
1/M uil !"
"N
PN",0.8103896103896104,".
(A158)"
"N
PN",0.811038961038961,The weighted covariance (samples ui are drawn according to pi)
"N
PN",0.8116883116883117,"Cov(U) = U J(β a) U T ,
(A159)"
"N
PN",0.8123376623376624,"[Cov(U)]kl = β M
X"
"N
PN",0.812987012987013,"i=1
pi uik uil − M
X"
"N
PN",0.8136363636363636,"i=1
pi uik"
"N
PN",0.8142857142857143,"!  M
X"
"N
PN",0.814935064935065,"i=1
pi uil !!"
"N
PN",0.8155844155844156,",
(A160)"
"N
PN",0.8162337662337662,"which replaces 1/M from equal sampling by the pi, that is, ui is sampled with probability pi."
"N
PN",0.8168831168831169,"The next theorem states how to express the dot product U T
xiUyi by weighted covariances of the data
U."
"N
PN",0.8175324675324676,Theorem A3 (Weighted Covariances). Using the weighted covariances
"N
PN",0.8181818181818182,"Cov(U, yi) = U Jm(β U T yi) U T ,
Cov(U, xi) = U Jm(β U T xi) U T ,
(A161)"
"N
PN",0.8188311688311688,"Jm(β a) =
Z 1"
"N
PN",0.8194805194805195,"0
J(λ β a) dλ ,
(A162)"
"N
PN",0.8201298701298702,"where the mean Jacobian Jm is symmetric, diagonally dominant, and positive semi-deﬁnite with
spectral norm bounded by ∥Jm∥2 ⩽0.5β."
"N
PN",0.8207792207792208,"The dot product U T
xiUyi can be expressed by the weighted covariances"
"N
PN",0.8214285714285714,"U T
xiUyi = (¯u + Cov(U, xi) xi)T (¯u + Cov(U, yi) yi) ,
(A163)"
"N
PN",0.8220779220779221,where the mean is ¯u = 1/MU1.
"N
PN",0.8227272727272728,"Proof. We apply the mean value theorem to the softmax with the symmetric, diagonally dominant,
positive semi-deﬁnite Jacobian matrix Jm =
R 1
0 J(λa + (1 −λ)a′) dλ:"
"N
PN",0.8233766233766234,"softmax(a) −softmax(a′) = Jm (a −a′) .
(A164)"
"N
PN",0.824025974025974,"We set a′ = 0 and use βa instead of a, which gives:"
"N
PN",0.8246753246753247,"softmax(β a) = 1/M 1 + Jm(β a) a ,
Jm(β a) =
Z 1"
"N
PN",0.8253246753246753,"0
J(λ β a) dλ ,
(A165)"
"N
PN",0.825974025974026,which is exact. We obtain
"N
PN",0.8266233766233766,"softmax(β U T xi) = 1/M 1 + Jm(β U T xi) U T xi ,
(A166)"
"N
PN",0.8272727272727273,"softmax(β U T yi) = 1/M 1 + Jm(β U T yi) U T yi .
(A167)"
"N
PN",0.827922077922078,"The spectral norm of Jm is bounded by ∥Jm∥2 ⩽0.5β, since this bound holds for every J(λβa) in
Jm(β a) =
R 1
0 J(λβa) dλ according to Lemma A1."
"N
PN",0.8285714285714286,Under review as a conference paper at ICLR 2022
"N
PN",0.8292207792207792,The dot product between the anchor retrieval and the positive sample is:
"N
PN",0.8298701298701299,"U T
xiUyi = softmax(β U T xi)T U T U softmax(β U T yi)
(A168)"
"N
PN",0.8305194805194805,"=
 
1/M 1 + Jm(β U T xi) U T xi
T U T U
 
1/M 1 + Jm(β U T yi) U T yi
"
"N
PN",0.8311688311688312,"=
 
1/M U 1 + U Jm(β U T xi) U T xi
T  
1/M U1 + U Jm(β U T yi) U T yi
"
"N
PN",0.8318181818181818,"= (¯u + Cov(U, xi) xi)T (¯u + Cov(U, yi) yi) ,"
"N
PN",0.8324675324675325,where we used the mean ¯u = 1/MU1 and the weighted covariances
"N
PN",0.8331168831168831,"Cov(U, yi) = U Jm(β U T yi) U T ,
Cov(U, xi) = U Jm(β U T xi) U T .
(A169)"
"N
PN",0.8337662337662337,"The Jacobian Jm is symmetric, diagonally dominant, and positive semi-deﬁnite. The weighted
covariance Cov(U, .) is the covariance if the stored pattern ui is drawn according to an averaged
pi given by Jm(.). Analog for weighted covariance Cov(V , .). When maximizing the dot product
U T
xiUyi, the normalized vectors xi and yi are encouraged to agree on drawing the patterns ui with
the same probability pi to generate similar weighted covariance matrices Cov(U, .). If subsets of U
have a strong covariance structure, then it can be exploited to produce large weighted covariances
and, in turn, large dot products of U T
xiUyi. Furthermore, for a large dot product U T
xiUyi, xi and
yi have to be similar to one another to extract the same direction from the covariance matrices. All
considerations are analog for V T
xiVyi."
"N
PN",0.8344155844155844,"A.2
MUTUAL INFORMATION ESTIMATION"
"N
PN",0.8350649350649351,"We follow the toy experiment discussed in Poole et al. (2019), Belghazi et al. (2018) and Cheng
et al. (2020) and experimentally conﬁrm the superior quality of InfoLOOB for mutual information
than InfoNCE. The dataset consists of samples (xi, yi) drawn jointly from a multivariate Gaussian
distribution with correlation ρ where the dimension of the samples x and y is set to d = 20. We
examine the performance of InfoLoob with and without Hopﬁeld and InfoNCE at estimating mutual
information of these samples. Due to the Gaussian distribution, the true value of mutual information
can be calculated as I(x, y) = −d"
"N
PN",0.8357142857142857,"2 log(1 −ρ2). We set the mutual information true value to the
values (2.0, 4.0, 6.0, 8.0, 10.0, 14.0) by varying the value of ρ. At each MI true value, we sample
data batches 1024 times, with batch size equal to 64, for the training of variational MI estimators.
Figure 2 shows that modern Hopﬁeld networks reduce the variance of the model. For models trained
on data with mutual information of 10 we observe an average variance of approx. 0.67 for a model
without Hopﬁeld and an average variance of approx. 0.33 for a model with Hopﬁeld. For models
trained on data with mutual information of 14 we observe an average variance of approx. 1.00 for a
model without Hopﬁeld and an average variance of approx. 0.48 for a model with Hopﬁeld."
"N
PN",0.8363636363636363,"In Figure A1 we show the performance of our method InfoLOOB with and without Hopﬁeld at
estimating mutual information as well as InfoNCE. As expected estimates of InfoNCE have estimates
that saturate at log(batch size). InfoLOOB without Hopﬁeld exhibits good estimates of high mutual
information while InfoLOOB with Hopﬁeld accomplishes both - good estimates of high mutual
information with a decreased variance."
"N
PN",0.837012987012987,"A.3
EXPERIMENTS"
"N
PN",0.8376623376623377,"A.3.1
ABLATION STUDIES"
"N
PN",0.8383116883116883,"As mentioned in the main paper, CLOOB has two new main components compared to CLIP: (1) the
InfoLOOB objective instead of the InfoNCE objective and (2) the modern Hopﬁeld networks. To
assess which of the new main components of CLOOB have led to the performance increase over CLIP,
we performed ablation studies on the CC dataset. The results are reported in Table A1. First, we
enhanced CLIP by replacing the InfoNCE objective with InfoLOOB (see column CLIP InfoLOOB).
Next, we added modern Hopﬁeld networks to the CLIP architecture and used retrieved embeddings
instead of the original embeddings, while keeping the InfoNCE objective (see column Hopﬁeld
InfoNCE). Finally, we add modern Hopﬁeld networks to CLIP and replace the InfoNCE objective"
"N
PN",0.8389610389610389,Under review as a conference paper at ICLR 2022
"N
PN",0.8396103896103896,"0
1000
2000
3000
4000
5000
6000
7000
steps −2 0 2 4 6 8 10 12 14"
"N
PN",0.8402597402597403,Mutual information
"N
PN",0.8409090909090909,infoNCE
"N
PN",0.8415584415584415,"True MI
log(64)"
"N
PN",0.8422077922077922,"0
1000
2000
3000
4000
5000
6000
7000
steps −2 0 2 4 6 8 10 12 14"
"N
PN",0.8428571428571429,Mutual information
"N
PN",0.8435064935064935,infoLOOB without Hopﬁeld
"N
PN",0.8441558441558441,True MI
"N
PN",0.8448051948051948,"0
1000
2000
3000
4000
5000
6000
7000
steps −2 0 2 4 6 8 10 12 14"
"N
PN",0.8454545454545455,Mutual information
"N
PN",0.8461038961038961,infoLOOB with Hopﬁeld
"N
PN",0.8467532467532467,True MI
"N
PN",0.8474025974025974,"Figure A1: The estimated mutual information of the InfoNCE objective saturates at the batch size
induced bound. The InfoLOOB objective trained with the same batch size with samples from the
same correlated Gaussian distributions following (Belghazi et al., 2018; Poole et al., 2019; Cheng
et al., 2020) is not limited by that bound and better estimates higher mutual information but suffers
from higher variance. This is remedied by incorporating the modern Hopﬁeld network."
"N
PN",0.8480519480519481,"Table A1: Inﬂuence of loss functions and Hopﬁeld retrieval. InfoLOOB increases the performance of
CLIP in most of the tasks. The InfoNCE loss is not suited for the Hopﬁeld approach as it saturates
leading to a worse performance. Hopﬁeld with InfoLOOB strongly improves the performance in 7
out of 8 datasets compared to both CLIP models."
"N
PN",0.8487012987012987,"CLIP
Hopﬁeld
Dataset
InfoNCE
InfoLOOB
InfoNCE
InfoLOOB"
"N
PN",0.8493506493506493,"Birdsnap
1.94
2.37
1.67
2.53
Country211
0.62
0.63
0.54
0.76
Flowers102
13.04
13.03
11.53
14.24
GTSRB
7.28
4.39
5.76
5.86
UCF101
21.00
19.14
20.56
22.29
Stanford Cars
0.90
1.33
1.24
1.37
ImageNet
20.31
22.13
19.04
24.21
ImageNetV2
20.63
21.65
18.97
23.80"
"N
PN",0.85,"with InfoLOOB (see column Hopﬁeld InfoLOOB). As shown in Table A1 the InfoLOOB objective
increases the performance of CLIP in the majority of the datasets. We attribute this increase to the fact
that InfoLOOB suffers less than InfoNCE from the “explaining away” problem. However, InfoLOOB
is even more effective for higher mutual information, that is, a richer covariance structure. Hopﬁeld
networks amplify the covariance structure in their retrieved embeddings. Though, this ampliﬁed
covariance structure is disadvantageous for InfoNCE, as the saturation effect is stronger. The stronger
saturation effect is caused by a richer covariance structure through Hopﬁeld networks, which in turn
leads to higher similarity between anchor and positive. Therefore, we see a performance drop when
combining modern Hopﬁeld networks with InfoNCE. Concluding, modern Hopﬁeld networks are a
perfect match for InfoLOOB as they yield higher mutual information. Therefore, CLOOB strongly
improves the performance on 7 out of 8 zero-shot transfer learning tasks compared to CLIP."
"N
PN",0.8506493506493507,"For CLIP with InfoNCE, the hyperparameter τ −1 is a learnable parameter. For the other experiments,
we use a ﬁxed τ −1 of 30. The value for τ −1 was determined via hyperparameter search (see
Section A.3.2)."
"N
PN",0.8512987012987013,"In contrast to CLIP, we use a learning rate scheduler with restarts (Loshchilov & Hutter, 2017) to be
more ﬂexible regarding the number of total training epochs and enable training up to a plateau. To
investigate the inﬂuence of the learning rate scheduler, we performed experiments with and without
restarts. Table A2 shows the zero-shot performance for the different downstream tasks for CLIP and
CLOOB respectively. For both CLIP and CLOOB, the performance at the majority of the tasks either
increases or remains roughly the same with restarts."
"N
PN",0.8519480519480519,Under review as a conference paper at ICLR 2022
"N
PN",0.8525974025974026,"Table A2: Inﬂuence of learning rate scheduler. For most of the tasks the performance either increases
or remains roughly the same with restarts for both CLIP and CLOOB."
"N
PN",0.8532467532467533,"CLIP
CLOOB
Dataset
w/o restarts
w/ restarts
w/o restarts
w/ restarts"
"N
PN",0.8538961038961039,"Birdsnap
2.10
1.94
2.64
2.53
Country211
0.71
0.62
0.63
0.76
Flowers102
11.00
13.04
11.50
14.24
GTSRB
6.16
7.28
5.05
5.86
UCF101
19.05
21.00
21.97
22.29
Stanford Cars
1.29
0.90
1.22
1.37
ImageNet
20.19
20.31
23.29
24.21"
"N
PN",0.8545454545454545,"ImageNet V2
20.53
20.63
22.97
23.80"
"N
PN",0.8551948051948052,"Table A3: Datasets used for zero-shot and linear probing. In the case of several train or test sets per
dataset we report the total number of samples. It should be noted that at the time of this work some
Birdsnap images were not accessible anymore."
"N
PN",0.8558441558441559,"Dataset
Classes
Train size
Test size
Evaluation metric"
"N
PN",0.8564935064935065,"Birdsnap
500
38,411
1,855
accuracy
Country211
211
42,200
21,100
accuracy
Flowers102
102
2,040
6,149
class-weighted accuracy
GTSRB
43
26,640
12,630
accuracy
ImageNet
1,000
1,281,167
50,000
accuracy
ImageNet V2
1,000
1,281,167
30,000
accuracy
Stanford Cars
196
8,144
8,041
accuracy
UCF101
101
28,747
11,213
accuracy"
"N
PN",0.8571428571428571,"A.3.2
HYPERPARAMETERS"
"N
PN",0.8577922077922078,"The hyperparameter search was done on a validation split of CC with about 15,000 samples. For the
hyperparameter τ −1 several values were considered (14.3, 30, 50, 70), where 30 leads to the best
results for both YFCC and CC. Analogously to CLIP, we use the Adam optimizer (Kingma et al.,
2014) with decoupled weight decay regularization (Loshchilov & Hutter, 2019). The weight decay is
only applied to weights that are not gains or biases. As proposed in OpenCLIP (Ilharco et al., 2021)
weight decay was set to 0.1. Different choices of weight decay (0.2 or 0.05), did not lead to a relevant
performance change. We use the same learning rate of 1 × 10−3 for CC and 5 × 10−4 for YFCC as
used in OpenCLIP. For the hyperparameter β we considered values in the range of 5 to 20. A value
of 8 resulted in the best performance for CC and 14.3 for YFCC. The batch size for CC was reduced
to 512 due to computational restraints which did not result in performance losses. The batch size for
YFCC was kept at 1024 as reported by OpenCLIP since a reduction resulted in a signiﬁcant drop in
performance. The learning rate scheduler for all experiments is cosine annealing with warmup and
hard restarts (Loshchilov & Hutter, 2017) with a cycle length of 7 epochs. For models trained on
YFCC the warmup was set to 10000 steps and for models trained on CC to 20000 steps."
"N
PN",0.8584415584415584,"A.3.3
DATASETS"
"N
PN",0.8590909090909091,"For pretraining we consider two datasets, Conceptual Captions (CC) (Sharma et al., 2018) and
YFCC100M (Thomee et al., 2016). The CC dataset consists of 2.9 million images and corresponding
high-quality captions. Images and their corresponding notations for CC have been gathered via an
automated process from the web and therefore represent a wide variety of styles. Raw descriptions
of images are collected from the alt-text HTML attribute. Both images and texts are ﬁltered such
that only image-text pairs above a certain quality threshold are part of this dataset. The dataset we
refer to as YFCC is a subset of the Yahoo Flickr Creative Commons 100 Million (YFCC100M)
dataset. It was created by ﬁltering for images which contain natural language descriptions and/or
titles in English resulting in 15 million image-caption pairs. The textual descriptions contain less"
"N
PN",0.8597402597402597,Under review as a conference paper at ICLR 2022
"N
PN",0.8603896103896104,"useful information than CC because they are not ﬁltered by quality. Occasionally they also contain
metadata like camera settings or web addresses."
"N
PN",0.861038961038961,"We evaluate and compare our method on several downstream classiﬁcation tasks. We evaluate
on the same set of datasets as CLIP reported for a model trained on YFCC. This set contains
Birdsnap (Berg et al., 2014), Country211 (Radford et al., 2021), Flowers102 (Nilsback & Zisserman,
2008), GTSRB (Stallkamp et al., 2011), UCF101 (Soomro et al., 2012), Stanford Cars (Krause et al.,
2013) and ImageNet (Deng et al., 2009). Additionally, we include ImageNet V2 in our analysis
(Recht et al., 2019). Table A3 shows an overview of training and test set sizes, number of classes and
the applied evaluation metric. In the case of several test sets per dataset the metric is calculated for
every set individually and the average performance is reported. The set size in Table A3 corresponds
to the total number of samples across all test and training sets of a dataset respectively."
"N
PN",0.8616883116883117,"Birdsnap contains images of North American bird species, however our dataset is smaller than
reported in CLIP as some samples are no longer available. The Country211 dataset was published
in CLIP and is a small subset of the YFCC100m dataset. It consists of photos that can be assigned
to 211 countries via GPS coordinates. For each country 200 photos are sampled for the training set
and 100 for testing. For the Flowers102 images of 102 ﬂower categories commonly occuring in the
United Kingdom were collected. Several classes are very similar and there is a large variation in scale,
pose and lighting. The German Trafﬁc Sign Recognition Benchmark (GTSRB) was a challenge held
at the IJCNN 2011. The dataset contains images of german trafﬁc signs from more than 40 classes.
Note that two versions of this dataset exist, one used for the challenge and an ofﬁcial dataset released
after the competition. For CLIP the linear probing classiﬁers were trained using the competition
training set but tested on the ofﬁcial test set. Stanford Cars contains images of 196 car models at
the level of make, model and year (e.g. Tesla Model S Sedan 2012). UCF101 (Soomro et al., 2012)
is a video dataset with short clips for action recognition consisting of three training sets and three
test sets. We follow the procedure reported in CLIP and extract the middle frame of every video to
assemble the dataset. The ImageNet Large Scale Visual Recognition Challenge was held from 2012
through 2017 and is one of the most widely used benchmarks for object detection and localization.
Several years later ImageNet V2 assembled three new test sets with images from the same 1,000
classes to test for generalization of models optimized for the original ImageNet benchmark. Every
test set comprises 10,000 samples."
"N
PN",0.8623376623376623,"A.3.4
ZERO-SHOT EVALUATION"
"N
PN",0.862987012987013,"Class names for all downstream tasks were adopted from CLIP, that is, among other changes special
characters like hyphens or apostrophes were removed. Furthermore, some class names of the datasets
were slightly changed (e.g. “kite” to “kite (bird of prey)” in ImageNet). For zero-shot
evaluation, we use the same prompt templates as published in CLIP. Depending on the dataset the
number of prompts can vary from one prompt (e.g. “a photo of a {label}, a type of
bird.” for Birdsnap) up to 80 prompts for ImageNet covering various settings (e.g. “a cropped
photo of a {label}.”, “a origami {label}.”). In case of several prompts an average
embedding over all prompt embeddings is calculated. Figure A2 shows the zero-shot results for all
evaluation tasks with the ResNet-50x4 model reported in Table 4."
"N
PN",0.8636363636363636,"A.3.5
LINEAR PROBING"
"N
PN",0.8642857142857143,"We try to follow the evaluation procedure in Radford et al. (2021) as closely as possible. We note one
difference with respect to the implementation: Instead of scikit-learn’s logistic regression using the
L-BFGS solver, we use cuML’s logistic regression classiﬁer with L-BFGS algorithm to utilize GPUs
for efﬁciency. All hyperparameters are the same as described in Radford et al. (2021), the maximum
number of iterations was set to 1000, and the L2 regularization strength λ was determined by using a
parametric binary search."
"N
PN",0.8649350649350649,"We tried to reproduce the CLIP results with the correspondingly published models, however, failed to
produce the exact numbers. This could be due to several factors:"
"N
PN",0.8655844155844156,"• The train and validation split. Same as in Radford et al. (2021) , we use the provided
validation set to perform the hyperparameter search. When there is none provided, we use a
random half of the training dataset for validation."
"N
PN",0.8662337662337662,Under review as a conference paper at ICLR 2022
"N
PN",0.8668831168831169,"Table A4: Linear probing results for the reimplementation of CLIP and CLOOB using different
ResNet architectures trained on YFCC. The performance of CLOOB scales with increased encoder
size"
"N
PN",0.8675324675324675,"Dataset
CLIP
RN-50
CLOOB
RN-50"
"N
PN",0.8681818181818182,"CLOOB
RN-101
CLOOB
RN-50x4"
"N
PN",0.8688311688311688,"Birdsnap
50.9
56.2
58.1
62.2
Country211
19.5
20.6
21.8
24.2
Flowers102
94.8
96.1
96.1
96.2
GTSRB
82.5
78.9
77.9
80.6
UCF101
75.2
72.3
72.8
75.3
Stanford Cars
36.2
37.7
39.0
44.3
ImageNet
66.9
65.7
67.0
69.7
ImageNet V2
60.2
58.7
60.3
62.2"
"N
PN",0.8694805194805195,"• In case of a tie in the validation score, we use the maximal λ for the strongest regularization.
We note though that we came closer to reproducing the results published in CLIP when
using the mean λ over all ties when these exist."
"N
PN",0.8701298701298701,"• For the Birdsnap dataset, the resources that we have got online at the time of this writing
could be different from the resources that CLIP’s authors obtained at the time."
"N
PN",0.8707792207792208,"Linear probing evaluation of YFCC-pretrained models is shown in Table A4. Comparing our
reimplementation of CLIP and CLOOB with ResNet-50 encoders, we observe mixed results. The
reason for this effect might be attributed to the observed task-dependence of multimodal models
(Devillers et al., 2021). Another potential reason is that the beneﬁt of the restrictions to more reliable
patterns that occur in both modalities does not directly translate to an evaluation of just the encoding
part of one modality. Again, as expected in self-supervised training, increasing the capacity of the
CLOOB models beneﬁts accuracy."
"N
PN",0.8714285714285714,"A.4
REVIEW OF MODERN HOPFIELD NETWORKS"
"N
PN",0.8720779220779221,"We brieﬂy review continuous modern Hopﬁeld networks that are used for deep learning architectures.
They are continuous and differentiable, therefore they a work with gradient descent in deep architec-
tures. They retrieve with one update only, therefore they can be activated like other deep learning
layers. They have exponential storage capacity, therefore they can tackle large problems. Hopﬁeld
networks are energy-based, binary associative memories, which popularized artiﬁcial neural networks
in the 1980s (Hopﬁeld, 1982; 1984). Associative memory networks have been designed to store and
retrieve samples. Their storage capacity can be considerably increased by polynomial terms in the
energy function (Chen et al., 1986; Psaltis & Cheol, 1986; Baldi & Venkatesh, 1987; Gardner, 1987;
Abbott & Arian, 1987; Horn & Usher, 1988; Caputo & Niemann, 2002; Krotov & Hopﬁeld, 2016).
In contrast to these binary memory networks, we use continuous associative memory networks with
very high storage capacity. These modern Hopﬁeld networks for deep learning architectures have an
energy function with continuous states and can retrieve samples with only one update (Ramsauer
et al., 2021; 2020). Modern Hopﬁeld Networks have been successfully applied to immune repertoire
classiﬁcation (Widrich et al., 2020) and chemical reaction prediction (Seidl et al., 2021)."
"N
PN",0.8727272727272727,"We assume a set of patterns {u1, . . . , uN} ⊂Rd that are stacked as columns to the matrix U =
(u1, . . . , uN) and a state pattern (query) ξ ∈Rd that represents the current state. The largest norm
of a stored pattern is M = maxi ∥ui∥. Continuous modern Hopﬁeld networks with state ξ have the
energy"
"N
PN",0.8733766233766234,"E = −β−1 log N
X"
"N
PN",0.874025974025974,"i=1
exp(βuT
i ξ) !"
"N
PN",0.8746753246753247,+ β−1 log N + 1
"N
PN",0.8753246753246753,2 ξT ξ + 1
"N
PN",0.875974025974026,"2 M 2 .
(A170)"
"N
PN",0.8766233766233766,"For energy E and state ξ, the update rule"
"N
PN",0.8772727272727273,"ξnew = f(ξ; U, β) = U p = U softmax(βU T ξ)
(A171)"
"N
PN",0.8779220779220779,Under review as a conference paper at ICLR 2022
"N
PN",0.8785714285714286,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.8792207792207792,cottontail rabbit hare
"N
PN",0.8798701298701299,Angora rabbit
"N
PN",0.8805194805194805,Scottish Terrier
"N
PN",0.8811688311688312,Yorkshire Terrier
"N
PN",0.8818181818181818,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.8824675324675325,mosque
"N
PN",0.8831168831168831,Black and Tan Coonhound
"N
PN",0.8837662337662338,rhinoceros beetle
"N
PN",0.8844155844155844,gossamer-winged butterfly
"N
PN",0.8850649350649351,dragonfly
"N
PN",0.8857142857142857,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.8863636363636364,Osprey
"N
PN",0.887012987012987,Bald Eagle
"N
PN",0.8876623376623377,Semipalmated Plover
"N
PN",0.8883116883116883,Swallow tailed Kite
"N
PN",0.888961038961039,Rough legged Hawk
"N
PN",0.8896103896103896,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.8902597402597403,Croatia
"N
PN",0.8909090909090909,Greece
"N
PN",0.8915584415584416,Montenegro
"N
PN",0.8922077922077922,Turkey
"N
PN",0.8928571428571429,Albania
"N
PN",0.8935064935064935,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.8941558441558441,azalea
"N
PN",0.8948051948051948,geranium
"N
PN",0.8954545454545455,pelargonium
"N
PN",0.8961038961038961,sweet william
"N
PN",0.8967532467532467,garden phlox
"N
PN",0.8974025974025974,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.8980519480519481,"red and white triangle with
traffic light approaching warning"
"N
PN",0.8987012987012987,empty red and white circle stop
"N
PN",0.8993506493506493,"red circle with white
horizonal stripe no entry"
"N
PN",0.9,"red and white triangle
road intersection warning"
"N
PN",0.9006493506493507,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9012987012987013,Chevrolet HHR SS 2010
"N
PN",0.9019480519480519,Dodge Caliber Wagon 2007
"N
PN",0.9025974025974026,Audi RS 4 Convertible 2008
"N
PN",0.9032467532467533,Dodge Journey SUV 2012
"N
PN",0.9038961038961039,Dodge Magnum Wagon 2008
"N
PN",0.9045454545454545,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9051948051948052,Military Parade
"N
PN",0.9058441558441559,Pommel Horse
"N
PN",0.9064935064935065,Horse Riding
"N
PN",0.9071428571428571,Typing
"N
PN",0.9077922077922078,Nunchucks
"N
PN",0.9084415584415585,"Horse Riding
correct rank: 3/101"
"N
PN",0.9090909090909091,"Dodge Caliber Wagon 2012
correct rank: 10/196"
"N
PN",0.9097402597402597,"red circle with white
horizontal stripe no entry
correct rank: 4/43"
"N
PN",0.9103896103896104,"azalea
correct rank: 1/102"
"N
PN",0.9110389610389611,"Croatia
correct rank: 1/211"
"N
PN",0.9116883116883117,"Osprey
correct rank: 1/500"
"N
PN",0.9123376623376623,"mosque
correct rank: 1/1000"
"N
PN",0.912987012987013,"cottontail rabbit
correct rank: 1/1000"
"N
PN",0.9136363636363637,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9142857142857143,longhorn beetle
"N
PN",0.9149350649350649,cricket insect
"N
PN",0.9155844155844156,weevil
"N
PN",0.9162337662337663,tiger beetle
"N
PN",0.9168831168831169,cockroach
"N
PN",0.9175324675324675,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9181818181818182,combine harvester hay corn
"N
PN",0.9188311688311688,thatched roof
"N
PN",0.9194805194805195,farm plow
"N
PN",0.9201298701298701,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9207792207792208,Great Blue Heron
"N
PN",0.9214285714285714,Tricolored Heron
"N
PN",0.922077922077922,Little Blue Heron
"N
PN",0.9227272727272727,Reddish Egret
"N
PN",0.9233766233766234,Northern Harrier
"N
PN",0.924025974025974,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9246753246753247,Greece
"N
PN",0.9253246753246753,Croatia Malta
"N
PN",0.925974025974026,Monaco
"N
PN",0.9266233766233766,Bermuda
"N
PN",0.9272727272727272,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9279220779220779,magnolia
"N
PN",0.9285714285714286,frangipani gaura
"N
PN",0.9292207792207792,cyclamen
"N
PN",0.9298701298701298,sweet pea
"N
PN",0.9305194805194805,"0.0
0.2
0.4
0.6
0.8
1.0 stop"
"N
PN",0.9311688311688312,"red circle with white
horizonal stripe no entry"
"N
PN",0.9318181818181818,"blue circle with white
keep right arrow mandatory"
"N
PN",0.9324675324675324,"red and white triangle car
skidding / slipping warning"
"N
PN",0.9331168831168831,empty red and white circle
"N
PN",0.9337662337662338,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9344155844155844,Ford Expedition EL SUV 2009
"N
PN",0.935064935064935,Chevrolet Express Van 2007
"N
PN",0.9357142857142857,"Chevrolet Silverado 1500
Classic Extended Cab 2007"
"N
PN",0.9363636363636364,Ford Freestar Minivan 2007
"N
PN",0.937012987012987,Honda Odyssey Minivan 2007
"N
PN",0.9376623376623376,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9383116883116883,Body Weight Squats
"N
PN",0.938961038961039,Basketball
"N
PN",0.9396103896103896,Table Tennis Shot
"N
PN",0.9402597402597402,Mopping Floor
"N
PN",0.9409090909090909,Bowling
"N
PN",0.9415584415584416,"Handstand Walking
correct rank: 11/101"
"N
PN",0.9422077922077922,"Chrysler Aspen SUV 2009
correct rank: 19/196"
"N
PN",0.9428571428571428,"red and white circle red
truck and black car no passing
correct rank: 36/43"
"N
PN",0.9435064935064935,"magnolia
correct rank: 1/102"
"N
PN",0.9441558441558442,"Greece
correct rank: 1/211"
"N
PN",0.9448051948051948,"Great Blue Heron
correct rank: 1/500"
"N
PN",0.9454545454545454,"threshing machine
correct rank: 13/1000"
"N
PN",0.9461038961038961,"longhorn beetle
correct rank: 1/1000"
"N
PN",0.9467532467532468,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9474025974025974,car mirror
"N
PN",0.948051948051948,collie
"N
PN",0.9487012987012987,Border Collie
"N
PN",0.9493506493506494,Great Pyrenees dog
"N
PN",0.95,American Staffordshire Terrier
"N
PN",0.9506493506493506,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9512987012987013,red wine
"N
PN",0.951948051948052,lighter
"N
PN",0.9525974025974026,perfume
"N
PN",0.9532467532467532,wine bottle
"N
PN",0.9538961038961039,bell pepper
"N
PN",0.9545454545454546,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9551948051948052,Northern Pintail
"N
PN",0.9558441558441558,Long tailed Duck Brant
"N
PN",0.9564935064935065,Greater Scaup
"N
PN",0.9571428571428572,Gadwall
"N
PN",0.9577922077922078,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9584415584415584,Algeria
"N
PN",0.9590909090909091,Palestine Malta
"N
PN",0.9597402597402598,Croatia
"N
PN",0.9603896103896103,Barbados
"N
PN",0.961038961038961,"0.0
0.2
0.4
0.6
0.8
1.0 rose"
"N
PN",0.9616883116883117,desert-rose
"N
PN",0.9623376623376624,bougainvillea
"N
PN",0.962987012987013,osteospermum
"N
PN",0.9636363636363636,camellia
"N
PN",0.9642857142857143,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.964935064935065,"red and white triangle with
exclamation mark warning"
"N
PN",0.9655844155844155,"red and white triangle car
skidding / slipping warning"
"N
PN",0.9662337662337662,"red and white triangle with
person digging / construction"
"N
PN",0.9668831168831169,"red and white triangle with
deer warning"
"N
PN",0.9675324675324676,"red and white triangle with
snowflake / ice warning"
"N
PN",0.9681818181818181,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9688311688311688,Honda Odyssey Minivan 2007
"N
PN",0.9694805194805195,Volvo XC90 SUV 2007
"N
PN",0.9701298701298702,Ford Expedition EL SUV 2009
"N
PN",0.9707792207792207,Daewoo Nubira Wagon 2002
"N
PN",0.9714285714285714,Ford Freestar Minivan 2007
"N
PN",0.9720779220779221,"0.0
0.2
0.4
0.6
0.8
1.0"
"N
PN",0.9727272727272728,Field Hockey Penalty
"N
PN",0.9733766233766233,Soccer Penalty
"N
PN",0.974025974025974,Tennis Swing
"N
PN",0.9746753246753247,Table Tennis Shot
"N
PN",0.9753246753246754,Basketball
"N
PN",0.9759740259740259,"Field Hockey Penalty
correct rank: 1/101"
"N
PN",0.9766233766233766,"Chevrolet Traverse SUV 2012
correct rank: 33/196"
"N
PN",0.9772727272727273,"red and white triangle with
black curve approaching warning
correct rank: 11/43"
"N
PN",0.977922077922078,"rose
correct rank: 1/102"
"N
PN",0.9785714285714285,"Spain
correct rank: 24/211"
"N
PN",0.9792207792207792,"Brant
correct rank: 3/500"
"N
PN",0.9798701298701299,"lipstick
correct rank: 7/1000"
"N
PN",0.9805194805194806,"collie
correct rank: 2/1000"
"N
PN",0.9811688311688311,"Figure A2: Visualization of zero-shot classiﬁcation of three examples from each dataset. The follow-
ing datasets are used (top to bottom): ImageNet, ImageNet V2, Birdsnap, Country211, Flowers102,
GTSRB, Stanford Cars and UCF101. The ground truth label is displayed above the picture. The bar
plots show the softmax values of the top 5 classes."
"N
PN",0.9818181818181818,"has been proven to converge globally to stationary points of the energy E, which are almost always
local minima (Ramsauer et al., 2021). The update rule Eq. (A171) is also the formula of the well-
known transformer attention mechanism (Ramsauer et al., 2021), therefore Hopﬁeld retrieval and
transformer attention coincide."
"N
PN",0.9824675324675325,Under review as a conference paper at ICLR 2022
"N
PN",0.9831168831168832,"The separation ∆i of a pattern ui is deﬁned as its minimal dot product difference to any of the
other patterns: ∆i = minj,j̸=i
 
uT
i ui −uT
i uj

. A pattern is well-separated from the data if
∆i ≥
2
βN + 1"
"N
PN",0.9837662337662337,"β log
 
2(N −1)NβM 2
. If the patterns ui are well separated, the iterate Eq. (A171)
converges to a ﬁxed point close to a stored pattern. If some patterns are similar to one another and,
therefore, not well separated, the update rule Eq. (A171) converges to a ﬁxed point close to the mean
of the similar patterns. This ﬁxed point is a metastable state of the energy function and averages over
similar patterns."
"N
PN",0.9844155844155844,"The next theorem states that the update rule Eq. (A171) typically converges after one update if the
patterns are well separated. Furthermore, it states that the retrieval error is exponentially small in the
separation ∆i."
"N
PN",0.9850649350649351,"Theorem A4 (Modern Hopﬁeld Networks: Retrieval with One Update). With query ξ, after one
update the distance of the new point f(ξ) to the ﬁxed point u∗
i is exponentially small in the separation
∆i. The precise bounds using the Jacobian J = ∂f(ξ)"
"N
PN",0.9857142857142858,"∂ξ
and its value Jm in the mean value theorem
are:"
"N
PN",0.9863636363636363,"∥f(ξ) −u∗
i ∥⩽∥Jm∥2 ∥ξ −u∗
i ∥,
(A172)"
"N
PN",0.987012987012987,"∥Jm∥2 ⩽2 β N M 2 (N −1) exp(−β (∆i −2 max{∥ξ −ui∥, ∥u∗
i −ui∥} M)) . (A173)"
"N
PN",0.9876623376623377,"For given ϵ and sufﬁcient large ∆i, we have ∥f(ξ) −u∗
i ∥< ϵ, that is, retrieval with one update.
The retrieval error ∥f(ξ) −ui∥of pattern ui is bounded by"
"N
PN",0.9883116883116884,"∥f(ξ) −ui∥⩽2 (N −1) exp(−β (∆i −2 max{∥ξ −ui∥, ∥u∗
i −ui∥} M)) M .
(A174)"
"N
PN",0.9889610389610389,"For a proof see (Ramsauer et al., 2021)."
"N
PN",0.9896103896103896,"The main requirement of modern Hopﬁeld networks to be suited for contrastive learning is that they
can store and retrieve enough embeddings if the batch size is large. We want to store a potentially
large set of embeddings. We ﬁrst deﬁne what we mean by storing and retrieving patterns from a
modern Hopﬁeld network."
"N
PN",0.9902597402597403,"Deﬁnition A1 (Pattern Stored and Retrieved). We assume that around every pattern ui a sphere
Si is given. We say ui is stored if there is a single ﬁxed point u∗
i ∈Si to which all points ξ ∈Si
converge, and Si ∩Sj = ∅for i ̸= j. We say ui is retrieved for a given ϵ if iteration (update rule)
Eq. (A171) gives a point ˜xi that is at least ϵ-close to the single ﬁxed point u∗
i ∈Si. The retrieval
error is ∥˜xi −ui∥."
"N
PN",0.990909090909091,"As with classical Hopﬁeld networks, we consider patterns on the sphere, i.e. patterns with a ﬁxed
norm. For randomly chosen patterns, the number of patterns that can be stored is exponential in the
dimension d of the space of the patterns (ui ∈Rd)."
"N
PN",0.9915584415584415,"Theorem A5 (Modern Hopﬁeld Networks: Exponential Storage Capacity). We assume a failure
probability 0 < p ⩽1 and randomly chosen patterns on the sphere with radius M := K
√"
"N
PN",0.9922077922077922,"d −1.
We deﬁne a :=
2
d−1(1 + ln(2βK2p(d −1))), b := 2K2β"
"N
PN",0.9928571428571429,"5
, and c :=
b
W0(exp(a+ln(b)), where W0 is"
"N
PN",0.9935064935064936,"the upper branch of the Lambert W function (Olver et al., 2010, (4.13)), and ensure c ≥

2
√p

4
d−1 .
Then with probability 1 −p, the number of random patterns that can be stored is"
"N
PN",0.9941558441558441,"N ≥√p c
d−1"
"N
PN",0.9948051948051948,"4
.
(A175)"
"N
PN",0.9954545454545455,"Therefore it is proven for c ≥3.1546 with β = 1, K = 3, d = 20 and p = 0.001 (a + ln(b) > 1.27)
and proven for c ≥1.3718 with β = 1, K = 1, d = 75, and p = 0.001 (a + ln(b) < −0.94)."
"N
PN",0.9961038961038962,"For a proof see (Ramsauer et al., 2021)."
"N
PN",0.9967532467532467,"This theorem justiﬁes to use continuous modern Hopﬁeld networks for using retrieved embeddings
instead of the original embeddings for large batch sizes. Even for hundreds of thousands of embed-
dings, the continuous modern Hopﬁeld network is able to retrieve the embeddings if the dimension of
the embeddings is large enough."
"N
PN",0.9974025974025974,Under review as a conference paper at ICLR 2022
"N
PN",0.9980519480519481,"A.5
FURTHER RELATED WORK"
"N
PN",0.9987012987012988,"Multiple works have proposed improvements to InfoNCE. Joint Contrastive Learning (JCL) studies
the effect of sampling multiple positives for each anchor. (Cai et al., 2020). Sampling negatives
around each positive leads to higher bias but lower variance than InfoNCE (Wu et al., 2021). InfoNCE
has been generalized to C-InfoNCE and WeaC-InfoNCE, which are conditional contrastive learning
approaches to remove undesirable information in self-supervised representations (Tsai et al., 2021).
ProtoNCE is a generalized version of the InfoNCE, which pushes representations to be closer to
their assigned prototypes (Li et al., 2021). ProtoNCE combines contrastive learning with clustering.
SimCSE employs InfoNCE for contrastive learning to learn sentence embeddings (Gao et al., 2021).
InfoNCE has been extended to video representation learning (Han et al., 2020)."
"N
PN",0.9993506493506493,"Many follow up works have been based on the CLIP model. The CLIP model is used in Vision-and-
Language tasks (Shen et al., 2021). The CLIP model guided generative models via an additional
training objective (Bau et al., 2021; Galatolo et al., 2021; Frans et al., 2021) and improved clustering of
latent representations (Pakhomov et al., 2021). It is used in studies of out of distribution performance
(Devillers et al., 2021; Milbich et al., 2021; Miller et al., 2021), of ﬁne-tuning robustness (Wortsman
et al., 2021), of zero-shot prompts (Zhou et al., 2021) and of adversarial attacks to uncurated datasets
(Carlini & Terzis, 2021). It stirred discussions about more holistic evaluation schemes in computer
vision (Agarwal et al., 2021). Multiple methods utilize the CLIP model in a straightforward way to
perform text-to-video retrieval (Fang et al., 2021; Luo et al., 2021; Narasimhan et al., 2021)."
