Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0022123893805309734,"Valuation methods of data and machine learning (ML) models are essential to the
establishment of AI marketplaces. Importantly, certain practical considerations
(e.g., operational constraints, legal restrictions) favor the use of model valuation
over data valuation. Also, existing marketplaces that involve trading of pre-trained
ML models call for an equitable model valuation method to price them. In partic-
ular, we investigate the black-box access setting which allows querying a model
(to observe predictions) without disclosing model-specific information (e.g., ar-
chitecture and parameters). By exploiting a Dirichlet abstraction of a model’s
predictions, we propose a novel and equitable model valuation method called
model Shapley. We also leverage a Lipschitz continuity of model Shapley to design
a learning approach for predicting the model Shapley values (MSVs) of many
vendors’ models (e.g., 150) in a large-scale marketplace. We perform extensive
empirical validation on the effectiveness of model Shapley using various real-world
datasets and heterogeneous model types."
INTRODUCTION,0.004424778761061947,"1
Introduction"
INTRODUCTION,0.00663716814159292,"Data valuation methods have important roles in extensive applications such as dataset pricing in a
data marketplace [1], evaluating the contributions of data from multiple collaborating parties [71],
and identifying valuable data (or filtering out less valuable data) for training higher-quality machine
learning (ML) models [20]. However, the following practical considerations favor the use of model
valuation over data valuation: (A) Data valuation can be operationally infeasible due to the character-
istics of training data, such as being massively distributed over millions of sources [73], enormous in
size (e.g., 400 billion byte-pair-encoded tokens for a language model [7]), and/or transient (e.g., the
data for online learning are not stored persistently [14]). In contrast, a trained model is not distributed
by nature (and hence does not need to be aggregated from distributed sources), often much smaller
in size than the training data (e.g., less than 1%),1 and usually stored persistently for inference.
(B) Data privacy regulations (e.g., GDPR) can be a legal impediment to data valuation in designing
fair payments for ML-based collaborations (e.g., in medicine [16] or cyber-defense [25]) because the
centralization of (possibly) private data, which seems necessary for data valuation [39], is prohibited
by such regulations. In contrast, the ML models trained on private data without centralization [40]
can be available for valuation. (C) Existing marketplaces that involve trading of pre-trained ML
models (e.g., AWS marketplace, Modzy) call for an equitable model valuation to price them. These
practical considerations motivate the use of equitable model valuation over data valuation."
INTRODUCTION,0.008849557522123894,"1The GPT-3 language model contains 175 billion parameters trained on 45 TB of text data [7]. It is of size
1.75 × 1011 × (2 × 2) × 10−9 = 350 GB (at 16 bit float precision) which is less than 1% of training data size."
INTRODUCTION,0.011061946902654867,"For model valuation, practitioners (e.g., model vendors or clinicians who use the trained models)
would likely prefer their models to be examined via only black-box access,2 i.e., by querying the
model with input for the corresponding predictions without observing its internal mechanism [8]. It
does not disclose the proprietary model information (for model vendors) nor the sensitive information
contained in the model (for clinicians), and provides an added advantage of the model valuation
being model-agnostic since no model-specific information is used. However, these make model
valuation challenging by restricting the available model information to only a selected query set (e.g.,
a validation set) with the observed predictions. In contrast, with white-box access, there is more model
information available (e.g., information-theoretic criteria for probabilistic models [71] or norms of the
parameters for deep neural networks [22]) to assess model complexity or certain analytical properties
(e.g., uniqueness of an optimal model in logistic regression)."
INTRODUCTION,0.01327433628318584,"Intuitively, the value of a model depends on its intended task: For example, a model trained to
classify MNIST digits [45] is not very valuable to a clinician trying to classify diagnostic scans.
This dependency is useful in practice for selecting the most ‘valuable’ model for the desired task
(i.e., as a query set). We refer to task and query set interchangeably hereafter. While the predictive
accuracy of a model on the task provides an intuitive value [66], it can be too reductive: Suppose
that two models Mi and Mi′ have identical predictive accuracies on the task but Mi (Mi′) makes
highly (barely) certain predictions, i.e., Mi (Mi′) predicts the true class with over 90% (barely over
50%) probability. Intuitively, the values for Mi and Mi′ should not be the same, which cannot be
achieved with accuracy alone, hence suggesting that additional model information beyond accuracy is
required. (1) What then should be a suitable abstraction of a model w.r.t. a task, for model valuation?"
INTRODUCTION,0.015486725663716814,"Satisfying certain equitability properties in model valuation is imperative in the application of model
pricing to ensuring a fair market. For instance, consistent valuation of identical models is important
as it is unfair to price them differently otherwise. Furthermore, the market economy dictates that
the value of a model depends on other available models (e.g., more available substitutes cause
depreciation), which is important to guarantee a fair market by preventing price fixing (i.e., an
exploitative pricing scheme often made illegal by anti-trust laws). (2) How then should model
valuation be formulated to satisfy these equitability properties?"
INTRODUCTION,0.017699115044247787,"In particular, the Shapley value is shown to satisfy these equitability properties but raises another
practical challenge that computing it exactly incurs O(2N) time where N is the number of models in
a marketplace. So, for a given computational budget, there is a fundamental ceiling to the size of the
marketplace such that including more models causes the marketplace to be unable to determine their
values (within reasonable time). (3) How can the desirable equitability properties of the Shapley
value still be exploited without imposing a significant restriction on the size of the marketplace?"
INTRODUCTION,0.01991150442477876,"This paper presents a novel model-agnostic valuation framework to tackle the above challenges. For
(1), we use an insight that the predictive pattern of a model (w.r.t. a task) is an suitable abstraction
for valuation, especially since the black-box access rules out other model information. Specifically,
we use a Dirichlet distribution to approximate a model’s predictive pattern/distribution w.r.t. a task,
which we call the Dirichlet abstraction of this model to encode both its predictive accuracy and
certainty (Sec. 2). We describe how to adjust the level of abstraction to trade off the amount of
model information (i.e., higher abstraction level) for the availability of a smaller query set. Then,
for (2), we observe that ensuring equitability requires a similarity measure of the models (e.g., to
ensure identical models are valued consistently or to identify substitutes). We exploit the ability of
the Dirichlet abstractions to preserve the similarity between models for proposing model Shapley
as an equitable model valuation (Sec. 3). As an illustration, identical models produce identical
Dirichlet abstractions which result in equal model Shapley values (MSVs). To address (3), based on
the Dirichlet abstraction, we leverage a Lipschitz continuity of model Shapley to justify and propose
a learning approach of training a model appraiser (i.e., a regression learner) on a small subset of
models (and their MSVs) for predicting other models’ MSVs to validate model Shapley’s practical
feasibility in a large-scale marketplace (Sec. 4), as empirically verified on real-world datasets and
up to 150 heterogeneous models. We empirically validate that better predictive accuracy (e.g., F1
score) due to better training data, more suitable model types, and/or higher predictive certainty result
in higher MSVs, and demonstrate a use case for identifying a valuable subset of models from the
marketplace to construct a larger learner (e.g., random forests) (Sec. 5)."
INTRODUCTION,0.022123893805309734,"2This is different from black-box models (e.g., deep neural networks) which are difficult to interpret or
explain even with access to the internal mechanism such as architecture and parameters."
DIRICHLET ABSTRACTION OF A MODEL,0.024336283185840708,"2
Dirichlet Abstraction of a Model"
DIRICHLET ABSTRACTION OF A MODEL,0.02654867256637168,We give some preliminaries on the Dirichlet distribution and Hellinger distance below:3
DIRICHLET ABSTRACTION OF A MODEL,0.028761061946902654,"Definition 1 (Dirichlet distribution [63]). The probability density function of a C-dimensional
Dirichlet random variables Z ∼Dir(α) with parameters α = [α1, . . . , αC] ∈(0, ∞)C is p(z; α) =
QC
k=1 zαk−1
k
. nhQC
k=1 Γ(αk)
i .
Γ
PC
k=1 αk
o
where Γ is the gamma function."
DIRICHLET ABSTRACTION OF A MODEL,0.030973451327433628,"Definition 2 (Hellinger distance [27]). The Hellinger distance between distributions (whose proba-
bility density functions are) p and q is dH(p, q) := [1 −
R p"
DIRICHLET ABSTRACTION OF A MODEL,0.033185840707964605,p(x) q(x) dx]1/2.
DIRICHLET ABSTRACTION AND MLE,0.035398230088495575,"2.1
Dirichlet Abstraction and MLE"
DIRICHLET ABSTRACTION AND MLE,0.03761061946902655,"We will now describe an abstraction of a model via a Dirichlet approximation to the model’s predictive
pattern over some task and a maximum likelihood estimation (MLE) for it. Each (learnt) C-way
classification model Mi : X 7→△(C) is a mapping from the input space X to the (C −1)-
probability simplex △(C) (i.e., space of C-dimensional probability vectors). Denote a random
variable X ∼PX whose support supp(X) = X is the input space, then its distribution PX induces
a predictive distribution PMi(X) over △(C). Concretely, PX is represented by a task/query set
D := {(xj ∈X, yj ∈{1, . . . , C})}j=1,...,D where each xj is a realization of X ∼PX, so that
Mi(xj) is a realization of PMi(X) ."
DIRICHLET ABSTRACTION AND MLE,0.03982300884955752,"Dirichlet abstraction.
Note that the predictive distribution PMi(X) (induced by PX) (i) has
the exactly same support to that of a C-dimensional Dirichlet distribution, so PMi(X) can be
mathematically modeled using a Dirichlet distribution; and (ii) can be statistically modeled using a
Dirichlet distribution because the predictive pattern of a classification model can be (statistically)
characterized well with a Dirichlet distribution [68]. Informally, the “shape” of predictive distribution
of a classification model is similar to that of a Dirichlet distribution. Hence, we let PMi(X) = Qi :=
Dir(αi), whose parameters αi can be learnt using MLE (described later) and refer to αi or Qi as
Mi’s Dirichlet abstraction. In words, we abstract the predictive distribution PMi(X) of the model
Mi induced by PX into a Dirichlet distribution, hence the name Dirichlet abstraction. Note that the
notational dependence on PX (or D) is suppressed when the context is clear."
DIRICHLET ABSTRACTION AND MLE,0.0420353982300885,"The proposed Dirichlet abstraction offers several important advantages (further elaborated in Sec. 3):
(a) By design, this formulation replaces the heterogeneity in models with the homogeneity in their
Dirichlet abstractions, and allows the subsequently proposed model valuation to be applicable to
models of different types: The respective Dirichlet abstractions of a multi-layer perceptron and a
logistic regression can be compared directly. (b) Qi encodes the predictive accuracy and certainty of
Mi through a theoretical connection between the Hellinger distance dH of two Dirichlet abstractions
and the cross entropy of Mi (formalized by Proposition 2). (c) Importantly for model valuation, an
appealing analytic property of the Dirichlet distribution is that dH of two Dirichlet abstractions can
be evaluated in closed-form and incurs O(1) computational complexity."
DIRICHLET ABSTRACTION AND MLE,0.04424778761061947,"MLE.
We adopt the MLE approximation of αi using the predictions of Mi on D since the log-
likelihood function is concave with a unique maximizer and can thus be efficiently optimized [57].
Since Mi(xj) denotes a realized predictive probability vector of Mi(X) ∼Dir(αi), we use the ob-
served sufficient statistics log ¯hi := D−1 PD
j=1 log Mi(xj) (i.e., with an element-wise log operation)
to derive the log-likelihood as follows [36]:"
DIRICHLET ABSTRACTION AND MLE,0.046460176991150445,"F(α, ¯hi) := D
h
G(α) + PC
k=1(αk −1) log ¯hi,k
i
(1)"
DIRICHLET ABSTRACTION AND MLE,0.048672566371681415,where G(α) := log Γ (P
DIRICHLET ABSTRACTION AND MLE,0.05088495575221239,k αk) −P
DIRICHLET ABSTRACTION AND MLE,0.05309734513274336,"k log Γ(αk). From (1), ¯hi arises as an alternative (to αi)
abstraction of Mi w.r.t. D. Hence, we compare αi and ¯hi theoretically (Proposition 3 in App. A) and
empirically (Sec. 4.2)."
DIRICHLET ABSTRACTION AND MLE,0.05530973451327434,"3Additional discussion on the choice (e.g., a comparison with the Chernoff distance) and suitability of
Hellinger distance is provided in App. A."
CLASS-SPECIFIC DIRICHLET ABSTRACTION,0.05752212389380531,"2.2
Class-specific Dirichlet Abstraction"
CLASS-SPECIFIC DIRICHLET ABSTRACTION,0.059734513274336286,"Since the Dirichlet abstraction Qi of Mi w.r.t. some task D does not explicitly account for the
class information in D (i.e., the true classification label yj of each data xj), models with certain
(different) predictive patterns can be indistinguishable. This can be problematic because the Dirichlet
abstractions of an optimal model and another model with zero predictive accuracy but a specific
predictive pattern can identical, making it difficult to distinguish between these two models."
CLASS-SPECIFIC DIRICHLET ABSTRACTION,0.061946902654867256,"Suppose that there are C = 3 classes in a balanced query set D (i.e., equal data size for each
class). For some Mi (with optimal predictive accuracy), artificially construct Mi′ to have the
same Dirichlet abstraction, but zero predictive accuracy in the following way: Since D is balanced,
group the data into triplets {(xj,1, xj,2, xj,3)}j=1,...,D/3 for the input data from 3 classes. Next,
define Mi′(xj,c) := Mi(xj,(c mod 3)+1) for c = 1, 2, 3. Intuitively, for each prediction (i.e., a
3-dimensional probability vector in a 2-simplex) by Mi, Mi′ makes an identical one but on an input
data from a wrong class, i.e., we ‘shift’ Mi’s predictions by one class to construct the predictions
of Mi′. Obviously, the predictive accuracy of Mi′ is zero, but its predictions (in aggregation) are
identical to those of Mi, which means ¯hi = ¯hi′ in (1), hence resulting in Qi = Qi′. In Fig. 1: Plots 1
and 2 are the predictions of Mi and Mi′ respectively, on D, which are (visually) indistinguishable.
Plots 3 and 4 are samples from Qi and Qi′ respectively, which are also (visually) indistinguishable.
The implication is that, in this case (of Mi and such specially constructed Mi′), the highest level of
abstraction (i.e., using the entire query set D to construct Dirichlet abstractions Qi and Qi′) is not
effective to distinguish between i and i′. Hence, we adopt a lower level of abstraction, described next."
CLASS-SPECIFIC DIRICHLET ABSTRACTION,0.06415929203539823,"The remedy is the so-called class-specific Dirichlet abstraction: Partition the query set D = ∪C
k=1Dk
where Dk contains only data from the k-th class. The Dirichlet abstraction αi,Dk of Mi on Dk is
called the class-specific Dirichlet abstraction w.r.t. class k. Based on the example above, we verify
using a small experiment.4 Over the entire D, we obtain αi = αi′ = [0.5040, 0.5339, 0.5306].
Restricting to query set D1 from class 1 only, gives αi,D1 = [21.8601, 2.2005, 2.0215] and αi′,D1 =
[1.5817, 1.7576, 19.4037], which are clearly different. In Fig. 1: Plots 5 and 6 are the predictions of
Mi and Mi′, respectively, on D1 while plots 7 and 8 are samples from Qi,D1 and Qi′,D1. We see
that Mi is clearly different from Mi′, and Qi,D1 is clearly different from Qi′,D1, demonstrating the
effectiveness of a lower level of abstraction via the class-specific Dirichlet abstraction."
CLASS-SPECIFIC DIRICHLET ABSTRACTION,0.06637168141592921,"1
2
3
4
5
6
7
8
Figure 1: The triangles denote the 2-simplex and each dot is a 3-dimensional probability vector.
Plots 1-4 (5-8) use D (D1) as query set. Plots 1&5 (2&6) show predictions of Mi (Mi′). Plots 3&7
(4&8) show randomly drawn samples from Dirichlet abstraction Qi (Qi′). For example, plot 4 shows
random samples from Qi′ w.r.t. D, while plot 5 shows predictions of Mi w.r.t. D1."
CLASS-SPECIFIC DIRICHLET ABSTRACTION,0.06858407079646017,"Trade-off between level of Dirichlet abstraction and size of query set.
Note that we need not
stop at partitioning D at the class level. For instance, a more refined partition can be first according to
the classes and then certain groups of input feature values. Doing so produces Dirichlet abstractions
with a lower level of abstraction (i.e., less abstract and containing more model information), but
also requires a larger query set D to begin with so that each smaller partitioned query set contains
sufficient data (for predictions) to obtain an accurate MLE estimate.5 For an extremely refined
partition of D where each partitioned query set is very small (e.g., size ≤5), the obtained MLE
estimates and the corresponding Dirichlet abstraction can be inaccurate and thus not useful. It is thus
important to find a suitable trade-off between the abstraction level vs. query set size. In particular,
in Sec. 5, we observe that partitioning D according to the classes provides such a suitable trade-off:
E.g., it can distinguish models with almost equal predictive accuracy due to the high class imbalance"
CLASS-SPECIFIC DIRICHLET ABSTRACTION,0.07079646017699115,"4On a balanced query set of size D = 900, Mi(xj) := Gj[1(yj = c) + ϵc]c=1,2,3 with ϵc ∼U(0, 0.2)
and normalizing constant Gj, i.e., Mi always makes the correct classification but with a small additive and
independent uniform noise ϵc.
5The work of [3] shows a sample complexity of |D| being polynomial in C and an additive error."
CLASS-SPECIFIC DIRICHLET ABSTRACTION,0.07300884955752213,"in the data6 but different F1 scores. Since the Dirichlet abstraction and the class-specific version are
both Dirichlet distributions, and share the same theoretical properties (e.g., enabling a closed-form
expression of the Hellinger distance), subsequently, we refer to Dirichlet abstractions generally (i.e.,
omitting the specific dependence on D or Dk), unless otherwise specified."
EQUITABLE VALUATION VIA MODEL SHAPLEY,0.0752212389380531,"3
Equitable Valuation via Model Shapley"
EQUITABLE VALUATION VIA MODEL SHAPLEY,0.07743362831858407,"We discuss and formalize several equitability properties to derive a general formulation called model
Shapley to satisfy them. Then, we will specify the characteristic function and a precision-weighted
fusion to encode a model’s predictive accuracy and certainty into its MSV."
EQUITABILITY PROPERTIES AND MODEL SHAPLEY,0.07964601769911504,"3.1
Equitability Properties and Model Shapley"
EQUITABILITY PROPERTIES AND MODEL SHAPLEY,0.08185840707964602,"Consider N models in a marketplace and denote Mi’s equitable value by ϕi. (P1) If a model Mi
has not been queried at all, then its value is indeterminate and we set ϕi = 0 by default. (P2) If
two models Mi and Mi′ give identical predictions (over the task), then their values are equal, i.e.,
ϕi = ϕi′. (P3) If some buyer is interested in multiple tasks simultaneously and a model (from
some vendor) performs very well on only one of the tasks, then it is unfair for the vendor to set
the value/price solely based on this performance. Instead, an equitable value should be based on
the model’s joint performance on these tasks (e.g., a linear combination according to the buyer’s
interests in these tasks). (P4) The existence of perfect substitutes depreciates the value of a model.
(P1)-(P4) are useful for equitable valuation in ML model marketplaces [51, 66]. To formalize these
properties, some notations are needed: Let ν : 2[N] 7→R denote a characteristic function (specified
later) s.t. ν(C) quantifies the value of a collection C ⊆[N] := {1, . . . , N} of models to capture the
dependence of Mi’s value on other existing models Mi′ (e.g., substitutes). Denote Mi’s value by
ϕi ←Φ(i, ν, {Mi}i∈[N]) which is fully specified (up to linear scaling) by the properties:"
EQUITABILITY PROPERTIES AND MODEL SHAPLEY,0.084070796460177,"P1 Null player: (∀C ⊆[N] \ {i} ν(C ∪{i}) −ν(C) = 0) =⇒ϕi = 0 .
P2 Symmetry: (∀C ⊆[N] \ {i, i′} ν(C ∪{i}) = ν(C ∪{i′})) =⇒ϕi = ϕi′ .
P3 Linearity: ∀γ, γ′ ∈R (νD∪D′ := γ νD + γ′ νD′) =⇒ϕi(D ∪D′) = γ ϕi(D) + γ′ ϕi(D′) .
P4 Diminished marginal utility: Add a perfect substitute (i.e., duplicate/copy) Mic of Mi to the pool
of N models already containing Mi and denote the new pool by [N ′] := [N] ∪{ic}. Denote the
value of Mi w.r.t. [N] by ϕi and w.r.t. [N ′] by ϕ′
i. Then, ϕ′
i ≤ϕi .
Proposition 1. Properties P1, P2, and P3 fully specify Φ(·) up to a linear scaling Z:"
EQUITABILITY PROPERTIES AND MODEL SHAPLEY,0.08628318584070796,ϕi := Z P
EQUITABILITY PROPERTIES AND MODEL SHAPLEY,0.08849557522123894,"C⊆[N]\{i} ωC [ν(C ∪{i}) −ν(C)]
where ωC := |C|! × (N −|C| −1)!/N! .
(2)"
EQUITABILITY PROPERTIES AND MODEL SHAPLEY,0.09070796460176991,"Its proof follows directly from [20, Proposition 2.1]. Since (2) coincides with the Shapley value [69],
we refer to Φ as model Shapley and ϕi as the model Shapley value (MSV). Note that P3 requires
two distinct tasks D and D′ to distinguish between the MSVs of Mi w.r.t. to these two tasks. P4
additionally requires ν to be conditionally redundant7 (Proposition 5 in App. A): The benefit of a
redundant copy Mic (conditioned on model Mi already being added) is not more than the initial
benefit of adding Mi. Intuitively, as adding Mi is already sufficient for the desired task, subsequently
adding Mic does not yield (as much) extra benefit [24]. In contrast, [51] also adopts (2) but assumes
ν already exists while we explicitly design ν to encode predictive accuracy and certainty:"
EQUITABILITY PROPERTIES AND MODEL SHAPLEY,0.09292035398230089,"ν(C) := −d(QC, Q∗)
(3)"
EQUITABILITY PROPERTIES AND MODEL SHAPLEY,0.09513274336283185,"where QC is the precision-weighted fusion of the Dirichlet abstractions in C and d(·, ·) is a distribu-
tional distance measure between two Dirichlet abstractions. Recall from Sec. 2 that the predictive
distribution of Mi is represented in its Dirichlet abstraction (visualized in Fig. 1). In particular,
the more accurate Mi is, the closer (distributionally) Qi is to the Dirichlet abstraction Q∗of an
expert (i.e., optimal classifier). Hence, a (high) similarity between Qi and Q∗can suggest Mi’s
(high) predictive accuracy. Specifically, Q∗is implemented as follows: For an input data-label pair
(xj, yj), take the one-hot encoded vector eyj ∈[0, 1]C of yj, add an independent uniform noise
ϵj ∈[0, 0.01]C (to avoid degeneracy during MLE), normalize it to sum to 1 to yield eyj,ϵj as a"
EQUITABILITY PROPERTIES AND MODEL SHAPLEY,0.09734513274336283,"698.22% of the data are from only 3 out of the 23 classes.
7∀C ⊆[N] \ {i} ν(C ∪{i}) −ν(C) ≥ν(C ∪{i, ic}) −ν(C ∪{i}) given that ic /∈[N]."
EQUITABILITY PROPERTIES AND MODEL SHAPLEY,0.09955752212389381,"‘prediction’ of the expert, and solve (1) using these ‘predictions’ over D. The predictive certainty of
Mi is encoded in the precision |αi|1 of its Dirichlet abstraction, which is then used as a weight to
fuse the individual Dirichlet abstractions Qi in C to obtain QC:
Definition
3
(Precision-weighted
Fusion).
Let
the
random
vector
[β1, . . . , βn]
∼
Dir([|α1|1, . . . , |αn|1]) be independent of Mi(x) for all i ∈C
⊆[N] where n := |C|.
Then, the precision-weighted fusion QC is the distribution of Pn
i=1 βi Mi(x)."
EQUITABILITY PROPERTIES AND MODEL SHAPLEY,0.10176991150442478,"In Definition 3, the weight βi on Mi(x) is large if |αi|1 is large, i.e., Qi has a high precision/Mi
has a high predictive certainty. Definition 3 has an important implication: QC is a fully specified
Dirichlet, i.e., QC = Dir([Pn
i=1 αi,1, . . . , Pn
i=1 αi,C]) (Lemma 3 in App. A) with four advantages:
(A) Qi and QC are both Dirichlets so that a single d (e.g., dH) in (3) can be used for both singleton
and non-singleton C’s. Interestingly, it gives a perspective that each Mi lives as Qi in a metric space
w.r.t. dH (Fig. 11 in App. C). (B) We can theoretically justify learning model Shapley (Theorem 1).
(C) (3) using dH can be evaluated in closed form with O(1) time, which is important since (2)
requires O(2N) evaluations of ν(C) for different C’s. (D) An alternative to specify ν(C) is a linear
combination of the performance of Mi, ∀i ∈C as ν(C). However, it is unclear what the weights in
this linear combination should be. In contrast, Definition 3 ‘automatically’ resolves this issue by
fusing each Qi according to its precision |αi|1 into QC."
EQUITABILITY PROPERTIES AND MODEL SHAPLEY,0.10398230088495575,"Interpreting MSV.
Note that (2) is an average (over all possible C ⊆[N] \ {i}) of how much Mi
(or, more precisely, Qi) improves the distributional similarity between QC and Q∗(i.e., the expert)
after i joins C. Both the predictive accuracy and certainty of Mi can affect (2). To see this, a high
predictive accuracy of Mi implies that Qi is (distributionally) close to Q∗; a high predictive certainty
of Mi ensures its weight βi is large when fused into QC, so the predictive certainty can amplify Mi’s
effect in bringing QC close to Q∗(if Qi is close to Q∗). Hence, a model Mi with a high predictive
accuracy and certainty is likely to have a high MSV ϕi. When considering several models jointly
[66], we can use ϕi to indicate how well (on average) Mi combines with other models (i.e., whether
Mi joining C leads to a performance improvement), as verified in Sec. 5. In contrast to the work
of [66], which supports up to N = 32 simpler binary classifiers, our approach –more scalable and
general– supports up to N = 150 C-way classifiers (Sec. 4.2)."
CONNECTION TO CROSS-ENTROPY AND OTHER MODEL EVALUATION CRITERIA,0.10619469026548672,"3.2
Connection to Cross-entropy and Other Model Evaluation Criteria"
CONNECTION TO CROSS-ENTROPY AND OTHER MODEL EVALUATION CRITERIA,0.1084070796460177,"We first formalize the connection between cross-entropy (CE) and our approach that uses the Hellinger
distance, and then use this connection to extend our approach to other evaluation criteria such as
adversarial robustness [43], distributional robustness [67], and algorithmic fairness in ML [56]."
CONNECTION TO CROSS-ENTROPY AND OTHER MODEL EVALUATION CRITERIA,0.11061946902654868,"As a distributional distance measure, CE can be used specify (3) because the CE loss is used to
evaluate the performance of a model. Then, specifying (3) with CE or the Hellinger distance (as
proposed in Sec. 4) can be connected in how they evaluate the model performance.
Proposition 2. Let νCE(C) := −CE(QC, Q∗),8 ν2
H(C) := −d2
H(QC, Q∗) and H(·) be differential
entropy. Then,"
CONNECTION TO CROSS-ENTROPY AND OTHER MODEL EVALUATION CRITERIA,0.11283185840707964,"νCE(C) ≤ν2
H(C) if H(QC)+d2
H(QC, Q∗) ≥0 , and νCE(C) ≥constQ∗×([1+ν2
H(C)]2−1)+log Γ(C)"
CONNECTION TO CROSS-ENTROPY AND OTHER MODEL EVALUATION CRITERIA,0.11504424778761062,where constq := [log(1/qmin −1)]/(1 −2qmin) with qmin := minz q(z) for a density q .
CONNECTION TO CROSS-ENTROPY AND OTHER MODEL EVALUATION CRITERIA,0.1172566371681416,"Proposition 2 shows that νCE(C) has upper and lower bounds that are monotonic in ν2
H, providing
some justification for using νH (instead of νCE). Note that while Proposition 2 utilizes ν2
H due to a
key Lemma 2 (in App. A), we adopt νH := −dH (Sec. 4) as dH satisfies the triangle inequality (for
Theorem 1). Moreover, Proposition 2 confirms that νH encodes the predictive accuracy and certainty
of a model since νCE encodes the predictive accuracy and certainty (see the example in App. A)."
CONNECTION TO CROSS-ENTROPY AND OTHER MODEL EVALUATION CRITERIA,0.11946902654867257,"Interestingly, this connection to CE enables the extension to adversarial robustness, distributional
robustness and algorithmic fairness, with different practical motivations. For instance, adversarial
robustness (in model valuation) is important to application scenarios where the model can encounter
adversarial attacks in deployment [43]. Formally, the respective objective functions objectiveadv [43],
objectiveDRO [67, Equation 5] and objectiveEO [56, Definition 2] can be achieved from a suitable
definition of ν using dH (precise definitions and full deviations are deferred to App. A), as summarized"
CONNECTION TO CROSS-ENTROPY AND OTHER MODEL EVALUATION CRITERIA,0.12168141592920353,"8Note that CE(p, q) := −
R
p(x) log q(x) dx for two distributions with densities p, q."
CONNECTION TO CROSS-ENTROPY AND OTHER MODEL EVALUATION CRITERIA,0.12389380530973451,"in Table 1. We highlight that this illustrates the potential generality of MSVs using the Hellinger
distance w.r.t. Dirichlet abstractions (i.e., using νH(C) in (2)), and defer the formal treatment of such
theoretical connections to future work. A question one might ask is that: (How) can multiple such
evaluation criteria be combined? The answer is yes, by leveraging (P3) to linearly combine selected
evaluation criteria, as discussed in App. A."
CONNECTION TO CROSS-ENTROPY AND OTHER MODEL EVALUATION CRITERIA,0.1261061946902655,"Table 1: Extension to other evaluation criteria for model valuation. The notation dependence on
the query set is made explicit. Dadv, Dclean denote the query sets containing adversarial and non-
adversarial (clean) training examples. {Dg}g∈G is a collection of query sets where Dg contains
training examples from a particular “group”/data distribution. D+
prot, D+
unprot contain positive training
examples under the protected and unprotected groups, respectively."
CONNECTION TO CROSS-ENTROPY AND OTHER MODEL EVALUATION CRITERIA,0.12831858407079647,"Criteria
Query sets
Choices of ν"
CONNECTION TO CROSS-ENTROPY AND OTHER MODEL EVALUATION CRITERIA,0.13053097345132744,"objectiveadv
Dadv, Dclean
−(dH(Q, Q∗; Dadv) + υ dH(Q, Q∗; Dclean))
objectiveDRO
{Dg}g∈G
−maxg∈G dH(Q, Q∗; Dg)
objectiveEO
D+
prot, D+
unprot
−|dH(Q, Q∗; D+
prot) −dH(Q, Q∗; D+
unprot)|"
LEARNING MODEL SHAPLEY,0.13274336283185842,"4
Learning Model Shapley"
LEARNING MODEL SHAPLEY,0.13495575221238937,"To address challenge (3) in Sec. 1, we propose a learning approach to train a model appraiser (i.e., a
regression learner) from the MSVs of a small subset of models for predicting MSVs of the remaining
models (further elaborated in App. C). If we can learn a good appraiser with only 20% of all models
(empirically verified), then the marketplace size can (theoretically) quintuple. To justify this learning
approach, we derive a Lipschitz continuity of model Shapley, which is also empirically verified using
5 real-world datasets and various model types. Next, we implement this learning approach by training
a Gaussian process regression (as the model appraiser) on a subset (from 5% to 50% in size) of
150 model-MSV pairs and examine its predictive performance on the rest. Our implementation is
available at https://github.com/XinyiYS/ModelShapley."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.13716814159292035,"4.1
Lipschitz Continuity of Model Shapley"
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.13938053097345132,"We derive a Lipschitz continuity of the model Shapley function Φ : [N] 7→R: The difference between
the MSVs of two models Mi, Mi′ (i.e., inputs to Φ) is bounded by the distance dH(Qi, Qi′) between
them, multiplied by a constant factor.
Theorem 1 (Lipschitz Continuity). Let d := dH in (3). Then, ∀i, i′ ∈[N]
(∀C ⊆[N] \
{i, i′} dH(QC∪i, QC∪i′) ≤dH(Qi, Qi′)) =⇒|ϕi −ϕi′| ≤ZdH(Qi, Qi′)."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.1415929203539823,"Its proof is in App. A. Theorem 1 states that the difference in MSVs of two models is bounded by the
Hellinger distance between their Dirichlet abstractions, and the constant Z from (2) is the Lipschitz
constant. This is based on a simple fusion-increases-similarity condition: When Qi and Qi′ are
each fused with a common QC, the resulting similarity is higher (i.e., smaller dH) since QC∪i and
QC∪i′ have QC in common (see Proposition 4 in App. A). Moreover, Table 3 and Fig. 6 (in App. A)
empirically verify Theorem 1. Then, Theorem 1 provides a theoretical justification for the learning
approach because it guarantees that similar inputs (i.e., small dH(Qi, Qi′)) imply similar outputs (i.e.,
small |ϕi −ϕi′|). namely, the model Shapley function is well-behaved w.r.t. its inputs, and hence
learnable. This reasoning is applied to justify learning the data Shapley value [21]."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.14380530973451328,"4.2
Empirical Learning Performance via Gaussian Process Regression (GPR)"
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.14601769911504425,"To exploit the Lipschitz continuity (i.e., Theorem 1), we adopt the Gaussian process regression (GPR)
due to a uniform error bound of GPR on Lipschitz continuous functions [47]. Our implementation
trains a GPR (as the model appraiser) on the MSVs of a subset of N = 150 models and examines its
predictive performance on the remaining ones."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.14823008849557523,"Regression setting.
We train N = 150 independent models on MNIST (CIFAR-10): 50 of
logistic regression (LR), multi-layer perceptron (MLP), and convolutional neural network (CNN)
each (ResNet-18, SqueezeNet, and DenseNet-121 each). For simplicity, we use the test set without"
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.1504424778761062,"partitioning as the query set D. For each Mi, we obtain ¯hi via its predictions on D and solve (1)
to obtain αi as input features for separate regressions. For the regression labels, as calculating ϕi
exactly incurs O(2150) time, we use the (ϵ = 0.1, δ = 0.1)-approximation [53] ˆϕi as the average of
3745 Monte-Carlo samples. This results in two sets {αi, ˆϕi} and {¯hi, ˆϕi} of model-MSV pairs of
size 150 each. We train a GPR on a random subset of 150 model-MSV pairs to learn to predict the
MSV on the remaining pairs. In GPR, we use the squared exponential kernel exp(−d(i, i′)/(2σ2))
(the lengthscale σ is learnt) where d(i, i′) := dH(Qi, Qi′) for {αi, ˆϕi}, and d(i, i′) := |¯hi′ −¯hi|1
for {¯hi, ˆϕi} ."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.15265486725663716,"High regression performance verifies learnability.
We examine the test performance using two
error metrics: mean-squared error (MSE) and maximum error (MaxE) w.r.t. varied training ratios
from 5% to 50%, in Fig. 2. In particular, results for training ratio of 20% are in Table 2. We observe
that even using only 20% of model-MSV pairs for training, the learning is effective (i.e., low test
errors), which shows its feasibility in a large-scale model marketplace. This can be attributed to the
learnability justified by Theorem 1 and the uniform error bound of GPR [47]. In addition, learning on
αi is more effective than learning on ¯hi (as Table 2 and Fig. 2 show higher errors for the latter), since
the average operation to get ¯hi loses some model information."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.15486725663716813,"Table 2: Top (bottom) are results on MNIST (CIFAR-10) for the training ratio of 20%. Average
(std. error) over 10 random train-test splits."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.1570796460176991,"MSE
MaxE"
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.1592920353982301,"αi
1.59e−6(6.9e−8)
3.53e−3(9.7e−5)
¯hi
8.36e−5(3.1e−6)
1.59e−2(2.6e−4)"
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.16150442477876106,"αi
1.79e−5(5.2e−6)
9.05e−3(3.9e−4)
¯hi
3.05e−4(4.5e−5)
3.23e−2(2.4e−3)"
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.16371681415929204,"Figure 2: Average (std. errors) of test performance vs. training ratios for MNIST & CIFAR-10 over
10 random train-test splits for each training ratio. Dashed (solid) lines follow the left (right) axis.
Colors indicate αi (blue) or ¯hi (orange). To elaborate, at a training ratio of 5%, the GPR is trained on
a random subset of 5% of the total 150 model-MSV pairs and its test performance on the remaining
95% of the model-MSV pairs is reported."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.16592920353982302,"5
MSV vs. Common Evaluation Criteria"
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.168141592920354,"This work is motivated by the lack of a standardized model valuation, but there are different evaluation
criteria useful in different scenarios (e.g., accuracy, F1 score, predictive certainty). Interestingly, we
find that MSV can produce consistent model values with these criteria. Additionally, we evaluate
the utility of MSV directly in a use case where a buyer wishes to purchase multiple models with
black-box access to build a larger learner (e.g., random forest or voting classifier) [33, 66] and show
that MSV can be used to effectively identify the most ‘valuable’ models for this purpose."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.17035398230088494,"MSV vs. predictive performance.
Fig. 3 (left) compares the MSVs of different model types
(independently trained on the same data) for MNIST. Here D consists of misclassified data (from the
original test set) of all the models to highlight the difference in their predictive accuracies. Without"
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.17256637168141592,"needing to partition D, we observe that CNNs significantly outperform both MLPs and LRs (in
terms of accuracy) and have the highest MSVs. This is expected, since CNNs are more capable of
performing well in image-based tasks, and hence the MSVs for CNNs are correspondingly higher.
Then, we examine predictive certainty. We use the same CNN model type independently trained
on the same MNIST data (i.e., their accuracies are essentially equal), but artificially increase the
predictive certainty for some: We multiply the highest probability of Mi(xj) by a factor of [1, 5, 10]
and then normalize the resulting vector to sum to 1 without affecting the predicted class/accuracy.
Fig. 3 (right) shows that models with higher predictive certainty have higher MSVs, confirmed by
additional results on CIFAR-10, MedNIST, and DrugRe in App. C. These results confirm our intuition
that a model with high predictive accuracy and certainty is likely to have a high MSV."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.1747787610619469,Figure 3: More suitable model types (left)/higher predictive certainty (right) lead to higher MSVs.
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.17699115044247787,"Next, we train 3 groups of 3 LR models independently with varying sizes of training data from 0.001
to 0.01 and 0.1 of the entire KDD99 dataset containing highly imbalanced data; the top 3 classes out
of 23 constitute 98.22% of total data. Intuitively, the models trained on more data should perform
better and thus be more valuable, but due to the class imbalance, Fig. 4 (left) shows difficulties in
differentiating these models based on their accuracies (or MSVs w.r.t. the entire/unpartitioned query
set). Intuitively, to differentiate them, we need a lower level (i.e., more refined) Dirichlet abstraction,
namely the class-specific Dirichlet abstractions: Partition the entire query set according to the
C = 23 classes with γk := |Dk|. Define dH(Qi, Qi′; {Dk}k=1,...,C) := PC
k=1 γk dH(Qi,Dk, Qi′,Dk)
to leverage P3 to compute ϕi({Dk}k=1,...,C) = PC
k=1 γk ϕi(Dk) (right of Fig. 4). Then we can
see that MSVs are indeed consistent with F1 score (a criterion especially suited for imbalanced
data) without explicitly using F1 score in the computation. In addition, for KDD, due to the high
class imbalance, there are classes with extremely small data size (i.e., ≤5) and our calculation
of dH(Qi, Qi′; {Dk}) naturally suppresses their effect (possibly inaccurate Qi) via γk := |Dk|.
However, in practice, it should be noted that partitioning the query set to obtain a lower level of
Dirichlet abstraction should be considered w.r.t. the size of available query set (Sec. 2). In other
words, to obtain a lower level of Dirichlet abstraction (and thus a more refined representation), it
incurs a higher cost from collecting a larger query set. In our experiments, we find that the size of
each partitioned query set Dk should contain at least 102 samples (e.g., for KDD most classes have at
least or close to 102 samples)."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.17920353982300885,"Figure 4: ϕi(D) (left) and ϕi({Dk}) (right) vs. the sizes of training data (as a proportion to the full
dataset)."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.18141592920353983,"Identifying valuable models to purchase.
For a more end-to-end use case (instead of a single
evaluation criterion), we evaluate the MSVs for up to 50 models and the performance of a larger"
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.1836283185840708,"learner by including a subset of these models based on their MSVs in a highest/lowest-first sequence
in Fig. 5. The larger learner is random forests (voting classifier) and models are decision trees (LeNets
[46]) for Breast Cancer (CIFAR-10). As the test accuracy of highest MSV-first increases more quickly
(orange line), it verifies our previous comment on models that perform well when combined with
other models are likely to have high MSVs. This characteristic offers some practical utility. If a buyer
is looking to purchase models from a marketplace [66], then following the highest MSV sequence, the
buyer only needs to purchase a subset of 15 (left of Fig. 5) or 25 (right of Fig. 5) out all 50 available
models, thus saving cost. More results on CIFAR-100 with ResNet-18 are in App. C."
LIPSCHITZ CONTINUITY OF MODEL SHAPLEY,0.18584070796460178,Figure 5: Test accuracy vs. number of models on Breast Cancer dataset (left) and CIFAR-10 (right).
RELATED WORK,0.18805309734513273,"6
Related Work"
RELATED WORK,0.1902654867256637,"The work of [66] investigates the binary classification setting and is not suitable for empirical
comparison as we consider problems with multiple classes. The works of [10, 11, 13, 51] approach
the design of a model marketplace from an economics perspective by addressing issues like arbitrage
(e.g., via horizontal/vertical pricing). In contrast, we formalize the value of a model via what it
has learned w.r.t. a task. The black-box access setting is appealing in a model marketplace as it
accommodates different model types. Some existing methods [8, 29, 30, 33, 44] focus on how to learn
a fused model from several trained models (possibly with black-box access) instead of how to value
these models. We highlight that we design the fusion (Definition 3) to leverage its analytic properties
in Theorem 1. The approach of learning the Shapley value arises in data valuation problems but has
not been considered in model valuation. Interestingly, we can draw parallels between Theorem 1
and [19, Theorem 2.8]. For brevity, we include a more extensive contrasting comparison with data
valuation in App. B."
DISCUSSION AND FUTURE WORK,0.19247787610619468,"7
Discussion and Future Work"
DISCUSSION AND FUTURE WORK,0.19469026548672566,"We exploit a Dirichlet abstraction of classification models with only black-box access for proposing
a novel equitable model valuation called the model Shapley. We discuss that choosing a suitable
level of the Dirichlet abstraction can improve how accurately MSV reflects a model’s predictive
performance and empirically show that using the partitioned query sets (according to the classes) can
provide a suitable trade-off between the level of abstraction and the size of the available query set.
MSV behaves consistently (in our experiments) with some common model evaluation criteria (i.e.,
predictive accuracy and certainty, F1 score) and can be extended to more sophisticated criteria. This
implies MSV can potentially help unify existing evaluation criteria to provide a simplified model
valuation in practice, without needing to explicitly perform separate evaluations."
DISCUSSION AND FUTURE WORK,0.19690265486725664,"For future work, it is interesting to explore how model valuation can help address the practical
considerations encountered in existing data valuation methods [70, 78, 80] and to apply this tech-
nique to existing collaborative (learning) frameworks which require a valuation of models, both
non-parametric ones [2, 62, 72, 74, 81] and parameterized ones [18, 49, 79]. Moreover, a more
detailed investigation into satisfying the equitability of Shapley value [59] and its trade-off with the
computational cost [82] is of practical interest, such as by applying more sophisticated analyses [47]
or methods [9, 31, 32, 52] for our proposed Gaussian process regression learning approach."
DISCUSSION AND FUTURE WORK,0.19911504424778761,Acknowledgments and Disclosure of Funding
DISCUSSION AND FUTURE WORK,0.2013274336283186,"This research/project is supported by the National Research Foundation Singapore and DSO National
Laboratories under the AI Singapore Programme (AISG Award No: AISG2-RP-2020-018). Xinyi
Xu is supported by the Institute for Infocomm Research of Agency for Science, Technology and
Research (A∗STAR)."
REFERENCES,0.20353982300884957,References
REFERENCES,0.20575221238938052,"[1] A. Agarwal, M. Dahleh, and T. Sarkar. A marketplace for data: An algorithmic solution. In
Proc. ACM-EC, 2019."
REFERENCES,0.2079646017699115,"[2] L. Agussurja, X. Xu, and B. K. H. Low. On the convergence of the shapley value in parametric
Bayesian learning games. In Proc. ICML, pages 180–196, 2022."
REFERENCES,0.21017699115044247,"[3] S. Arora, R. Ge, Y. Halpern, D. Mimno, A. Moitra, D. Sontag, Y. Wu, and M. Zhu. A practical
algorithm for topic modeling with provable guarantees. In Proc. ICML, pages 280–288, 2013."
REFERENCES,0.21238938053097345,"[4] M. Basseville.
Distance measures for signal processing and pattern recognition.
Signal
Processing, 18(4):349–369, 1989."
REFERENCES,0.21460176991150443,"[5] J. A. Blackard and D. J. Dean. Comparative accuracies of artificial neural networks and
discriminant analysis in predicting forest cover types from cartographic variables. Computers
and Electronics in Agriculture, 24(3):131–151, 1999."
REFERENCES,0.2168141592920354,"[6] S. Boyd, S. P. Boyd, and L. Vandenberghe. Convex optimization. Cambridge Univ. Press, 2004."
REFERENCES,0.21902654867256638,"[7] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan,
P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child,
A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray,
B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei.
Language models are few-shot learners. In Proc. NeurIPS, 2020."
REFERENCES,0.22123893805309736,"[8] H. Chang, V. Shejwalkar, R. Shokri, and A. Houmansadr. Cronus: Robust and heterogeneous
collaborative learning with black-box knowledge transfer. In Proceedings of the 1st NeurIPS
Workshop on New Frontiers in Federated Learning (NFFL 2021), 2021."
REFERENCES,0.2234513274336283,"[9] J. Chen, N. Cao, K. H. Low, R. Ouyang, C. K.-Y. Tan, and P. Jaillet. Parallel gaussian process
regression with low-rank covariance matrix approximations. In Proc. UAI, page 152–161, 2013."
REFERENCES,0.22566371681415928,"[10] L. Chen, P. Koutris, and A. Kumar. Model-based pricing: Do not pay for more than what
you learn! In Proc. ACM SIGMOD Workshop on Data Management for End-to-end Machine
Learning, 2017."
REFERENCES,0.22787610619469026,"[11] L. Chen, P. Koutris, and A. Kumar. Towards model-based pricing for machine learning in a data
marketplace. In Proc. ACM SIGMOD, page 1535–1552, 2019."
REFERENCES,0.23008849557522124,"[12] H. Chernoff. A Measure of Asymptotic Efficiency for Tests of a Hypothesis Based on the sum
of Observations. The Annals of Mathematical Statistics, 23(4):493–507, 1952."
REFERENCES,0.2323008849557522,"[13] Z. Cong, X. Luo, J. Pei, F. Zhu, and Y. Zhang. Data pricing in machine learning pipelines.
Knowledge and Information Systems, 64:1417–1455, 2022."
REFERENCES,0.2345132743362832,"[14] A. S. Das, M. Datar, A. Garg, and S. Rajaram. Google news personalization: Scalable online
collaborative filtering. In Proc. WWW, 2007."
REFERENCES,0.23672566371681417,"[15] P. Devijver and J. Kittler. Pattern Recognition: A Statistical Approach. Prentice-Hall, London,
1982."
REFERENCES,0.23893805309734514,"[16] J. M. Drazen, S. Morrissey, D. Malina, M. B. Hamel, and E. W. Campion. The importance —
and the complexities — of data sharing. New England Journal of Medicine, 375(12):1182–1183,
2016."
REFERENCES,0.2411504424778761,"[17] M. Ester, H.-P. Kriegel, J. Sander, and X. Xu. A density-based algorithm for discovering clusters
in large spatial databases with noise. In Proc. KDD, 1996."
REFERENCES,0.24336283185840707,"[18] F. X. Fan, Y. Ma, Z. Dai, W. Jing, C. Tan, and B. K. H. Low. Fault-tolerant federated reinforce-
ment learning with theoretical guarantee. In Proc. NeurIPS, 2021."
REFERENCES,0.24557522123893805,"[19] A. Ghorbani, M. Kim, and J. Zou. A distributional framework for data valuation. In Proc.
ICML, pages 3535–3544, 2020."
REFERENCES,0.24778761061946902,"[20] A. Ghorbani and J. Zou. Data Shapley: Equitable valuation of data for machine learning. In
Proc. ICML, pages 2242–2251, 2019."
REFERENCES,0.25,"[21] A. Ghorbani, J. Zou, and A. Esteva. Data Shapley valuation for efficient batch active learning,
2021."
REFERENCES,0.252212389380531,"[22] I. Goodfellow, Y. Bengio, and A. Courville. Deep Learning. MIT Press, 2016."
REFERENCES,0.25442477876106195,"[23] F. Gr¨aßer, S. Kallumadi, H. Malberg, and S. Zaunseder. Aspect-based sentiment analysis of
drug reviews applying cross-domain and cross-data learning. In Proc. International Conference
on Digital Health, page 121–125, 2018."
REFERENCES,0.25663716814159293,"[24] D. Han, M. Wooldridge, A. Rogers, S. Tople, O. Ohrimenko, and S. Tschiatschek. Replication-
robust payoff-allocation for machine learning data markets. Journal of IEEE Transactions on
Artificial Intelligence, 2022."
REFERENCES,0.2588495575221239,"[25] M. F. Haque and R. Krishnan. Toward automated cyber defense with secure sharing of structured
cyber threat intelligence. Information Systems Frontiers, 23(4):883–896, 2021."
REFERENCES,0.2610619469026549,"[26] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proc.
CVPR, 2016."
REFERENCES,0.26327433628318586,"[27] E. Hellinger.
Neue begr¨undung der theorie quadratischer formen von unendlichvielen
ver¨anderlichen. Journal f¨ur die reine und angewandte Mathematik, page 210–271, 1909."
REFERENCES,0.26548672566371684,"[28] S. Hettich and S. D. Bay. KDD Cup 1999 data data set. https://archive.ics.uci.edu/
ml/datasets/kdd+cup+1999+data, 1999."
REFERENCES,0.2676991150442478,"[29] N. Hoang, T. Lam, B. K. H. Low, and P. Jaillet. Learning task-agnostic embedding of multiple
black-box experts for multi-task model fusion. In Proc. ICML, pages 4282–4292, 2020."
REFERENCES,0.26991150442477874,"[30] Q. M. Hoang, T. N. Hoang, B. K. H. Low, and C. Kingsford. Collective model fusion for
multiple black-box experts. In Proc. ICML, pages 4857–4867, 2019."
REFERENCES,0.2721238938053097,"[31] Q. M. Hoang, T. N. Hoang, and K. H. Low. A generalized stochastic variational Bayesian
hyperparameter learning framework for sparse spectrum Gaussian process regression. In Proc.
AAAI, volume 31, 2017."
REFERENCES,0.2743362831858407,"[32] T. N. Hoang, Q. M. Hoang, and B. K. H. Low. A unifying framework of anytime sparse gaussian
process regression models with stochastic variational inference for big data. In Proc. ICML,
volume 37, pages 569–578, 2015."
REFERENCES,0.27654867256637167,"[33] T. N. Hoang, S. Hong, C. Xiao, B. K. H. Low, and J. Sun. AID: Active distillation machine to
leverage pre-trained black-box models in private data settings. In Proc. WWW, pages 3569–3581,
2021."
REFERENCES,0.27876106194690264,"[34] H. Homei. Randomly weighted averages: A multivariate case, 2016."
REFERENCES,0.2809734513274336,"[35] G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger. Densely connected convolutional
networks. In Proc. CVPR, 2017."
REFERENCES,0.2831858407079646,"[36] J. Huang. Maximum likelihood estimation of dirichlet distribution parameters. CMU Technique
report, 18, 2005."
REFERENCES,0.2853982300884956,"[37] F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally, and K. Keutzer. Squeezenet:
Alexnet-level accuracy with 50x fewer parameters and¡ 0.5 mb model size. arXiv preprint
arXiv:1602.07360, 2016."
REFERENCES,0.28761061946902655,"[38] H. Jeffreys. An invariant form for the prior probability in estimation problems. Proceedings of
the Royal Society of London. Series A, Mathematical and Physical Sciences, 186(1007):453–461,
1946."
REFERENCES,0.28982300884955753,"[39] R. Jia, D. Dao, B. Wang, F. A. Hubis, N. Hynes, N. M. G¨urel, B. Li, C. Zhang, D. Song, and
C. J. Spanos. Towards efficient data valuation based on the shapley value. In Proc. AISTATS,
pages 1167–1176, 2019."
REFERENCES,0.2920353982300885,"[40] G. A. Kaissis, M. R. Makowski, D. R¨uckert, and R. F. Braren. Secure, privacy-preserving and
federated machine learning in medical imaging. Nature Machine Intelligence, 2:305–311, 2020."
REFERENCES,0.2942477876106195,"[41] A. Krizhevsky. Learning multiple layers of features from tiny images. Master’s thesis, Depart-
ment of Computer Science, University of Toronto, 2009."
REFERENCES,0.29646017699115046,"[42] S. Kullback and R. A. Leibler. On information and sufficiency. The Annals of Mathematical
Statistics, 22(1):79 – 86, 1951."
REFERENCES,0.29867256637168144,"[43] A. Kurakin, I. J. Goodfellow, and S. Bengio. Adversarial machine learning at scale. In Proc.
ICLR, 2017."
REFERENCES,0.3008849557522124,"[44] T. C. Lam, N. Hoang, B. K. H. Low, and P. Jaillet. Model fusion for personalized learning. In
Proc. ICML, pages 5948–5958, 2021."
REFERENCES,0.3030973451327434,"[45] Y. LeCun, B. Boser, J. Denker, D. Henderson, R. Howard, W. Hubbard, and L. Jackel. Hand-
written digit recognition with a back-propagation network. In Proc. NeurIPS, 1990."
REFERENCES,0.3053097345132743,"[46] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document
recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998."
REFERENCES,0.3075221238938053,"[47] A. Lederer, J. Umlauft, and S. Hirche. Uniform error bounds for Gaussian process regression
with application to safe control. In Proc. NeurIPS, 2019."
REFERENCES,0.30973451327433627,"[48] J. Lin. On the Dirichlet distribution., 2016. Master’s thesis, Department of Mathematics and
Statistics, Queen’s University."
REFERENCES,0.31194690265486724,"[49] X. Lin, X. Xu, S.-K. Ng, C.-S. Foo, and B. K. H. Low. Fair yet asymptotically equal collaborative
learning. In Proc. ICML, pages 21223–21259, 2023."
REFERENCES,0.3141592920353982,"[50] T. Lissack and K.-S. Fu. Error estimation in pattern recognition via lα-distance between
posterior density functions. IEEE Transactions on Information Theory, 22(1):34–45, 1976."
REFERENCES,0.3163716814159292,"[51] J. Liu, J. Lou, J. Liu, L. Xiong, J. Pei, and J. Sun. Dealer: An end-to-end model marketplace
with differential privacy. Proc. VLDB Endow., 14(6):957–969, 2021."
REFERENCES,0.3185840707964602,"[52] B. K. H. Low, J. Yu, J. Chen, and P. Jaillet. Parallel gaussian process regression for big data:
Low-rank representation meets markov approximation. In Proc. AAAI, page 2821–2827, 2015."
REFERENCES,0.32079646017699115,"[53] S. Maleki, L. Tran-Thanh, G. Hines, T. Rahwan, and A. Rogers. Bounding the estimation error
of sampling-based Shapley value approximation with/without stratifying, 2013."
REFERENCES,0.3230088495575221,"[54] A. Malinin. Uncertainty estimation in deep learning with application to spoken language
assessment. PhD thesis, Department of Engineering, University of Cambridge, 2019."
REFERENCES,0.3252212389380531,"[55] A. Malinin and M. Gales. Predictive uncertainty estimation via prior networks. In Proc.
NeurIPS, 2018."
REFERENCES,0.3274336283185841,"[56] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan. A survey on bias and
fairness in machine learning. ACM Computing Surveys, 54(6), 2021."
REFERENCES,0.32964601769911506,"[57] T. Minka. Estimating a dirichlet distribution, 2000."
REFERENCES,0.33185840707964603,"[58] MONAI Consortium.
MONAI: Medical open network for AI.
https://github.com/
Project-MONAI/MONAI, 2020. Version 0.6.0."
REFERENCES,0.334070796460177,"[59] Q. P. Nguyen, B. K. H. Low, and P. Jaillet. Trade-off between payoff and model rewards in
shapley-fair collaborative machine learning. In Proc. NeurIPS, pages 30542–30553, 2022."
REFERENCES,0.336283185840708,"[60] E. Patrick and F. Fischer. Nonparametric feature selection. IEEE Transactions on Information
Theory, 15(5):577–584, 1969."
REFERENCES,0.33849557522123896,"[61] Y. Polyanskiy. Lecture notes on f-divergences, 2019. Lecture notes, https://people.lids.
mit.edu/yp/homepage/data/LN_fdiv.pdf."
REFERENCES,0.3407079646017699,"[62] R. Qiao, X. Xu, and B. K. H. Low. Collaborative causal inference with fair incentives. In Proc.
ICML, pages 28300–28320, 2023."
REFERENCES,0.34292035398230086,"[63] T. W. Rauber, T. Braun, and K. Berns. Probabilistic distance measures of the Dirichlet and Beta
distributions. Pattern Recognition, 41(2):637–645, 2008."
REFERENCES,0.34513274336283184,"[64] S. Romano, N. X. Vinh, J. Bailey, and K. Verspoor. Adjusting for chance clustering comparison
measures. Journal of Machine Learning Research, 17(1):4635–4666, 2016."
REFERENCES,0.3473451327433628,"[65] G. Ronning. Maximum likelihood estimation of Dirichlet distributions. Journal of Statistical
Computation and Simulation, 32(4):215–221, 1989."
REFERENCES,0.3495575221238938,"[66] B. Rozemberczki and R. Sarkar. The Shapley value of classifiers in ensemble games. In Proc.
CIKM, pages 1558–1567, 2021."
REFERENCES,0.35176991150442477,"[67] S. Sagawa, P. W. Koh, T. B. Hashimoto, and P. Liang. Distributionally robust neural networks.
In Proc. ICLR, 2020."
REFERENCES,0.35398230088495575,"[68] M. Sensoy, L. Kaplan, and M. Kandemir. Evidential deep learning to quantify classification
uncertainty. In Proc. NeurIPS, 2018."
REFERENCES,0.3561946902654867,"[69] L. S. Shapley. A value for n-person games. In H. W. Kuhn and A. W. Tucker, editors,
Contributions to the Theory of Games, volume 2, pages 307–317. Princeton University Press,
1953."
REFERENCES,0.3584070796460177,"[70] R. H. L. Sim, X. Xu, and B. K. H. Low. Data valuation in machine learning: ”ingredients”,
strategies, and open challenges. In Proc. IJCAI-22, pages 5607–5614, 2022. Survey Track."
REFERENCES,0.3606194690265487,"[71] R. H. L. Sim, Y. Zhang, M. C. Chan, and B. K. H. Low. Collaborative machine learning with
incentive-aware model rewards. In Proc. ICML, 2020."
REFERENCES,0.36283185840707965,"[72] R. H. L. Sim, Y. Zhang, T. N. Hoang, X. Xu, B. K. H. Low, and P. Jaillet. Incentives in private
collaborative machine learning. In Proc. NeurIPS, 2023."
REFERENCES,0.36504424778761063,"[73] K. Singhal, H. Sidahmed, Z. Garrett, S. Wu, J. K. Rush, and S. Prakash. Federated reconstruction:
Partially local federated learning. In Proc. NeurIPS, 2021."
REFERENCES,0.3672566371681416,"[74] S. S. Tay, X. Xu, C. S. Foo, and B. K. H. Low. Incentivizing collaboration in machine learning
via synthetic data rewards. In Proc. AAAI, volume 36, pages 9448–9456, 2022."
REFERENCES,0.3694690265486726,"[75] C. Tosh and S. Dasgupta. The relative complexity of maximum likelihood estimation, MAP
estimation, and sampling. In Proc. COLT, pages 2993–3035, 2019."
REFERENCES,0.37168141592920356,"[76] T. Wang, Y. Yang, and R. Jia. Learnability of learning performance and its application to data
valuation, 2021."
REFERENCES,0.37389380530973454,"[77] L. Watson, R. Andreeva, H.-T. Yang, and R. Sarkar. Differentially private Shapley values for
data evaluation, 2022."
REFERENCES,0.37610619469026546,"[78] Z. Wu, Y. Shu, and B. K. H. Low. DAVINZ: Data valuation using deep neural networks at
initialization. In Proc. ICML, pages 24150–24176, 2022."
REFERENCES,0.37831858407079644,"[79] X. Xu, L. Lyu, X. Ma, C. Miao, C. S. Foo, and B. K. H. Low. Gradient driven rewards to
guarantee fairness in collaborative machine learning. In Proc. NeurIPS, 2021."
REFERENCES,0.3805309734513274,"[80] X. Xu, Z. Wu, C.-S. Foo, and B. K. H. Low. Validation free and replication robust volume-based
data valuation. In Proc. NeurIPS, 2021."
REFERENCES,0.3827433628318584,"[81] X. Xu, Z. Wu, A. Verma, C. S. Foo, and B. K. H. Low. Fair: Fair collaborative active learning
with individual rationality for scientific discovery. In Proc. AISTATS, pages 4033–4057, 2023."
REFERENCES,0.38495575221238937,"[82] Z. Zhou, X. Xu, R. H. L. Sim, and C.-S. F. B. K. H. Low. Probably approximate Shapley
fairness with applications in machine learning. In Proc. AAAI, 2023."
REFERENCES,0.38716814159292035,"A
Theoretical Discussion"
REFERENCES,0.3893805309734513,"A.1
Results Related to Maximum Likelihood Estimation (MLE)"
REFERENCES,0.3915929203539823,"Log-likelihood function F (1).
For completeness, we provide the full log-likelihood function [36,
57, 65] using the predictions as follows: To avoid notational overload, let yj := Mi(xj) denote
the predictive probability vector of Mi on xj and its dependence on i is suppressed. Similarly, we
suppress the dependence of α on i since the context is clear. Then,"
REFERENCES,0.3938053097345133,"F(α, {yj}j=1,...,D) = log p({yj}j=1,...,D|α) = log D
Y"
REFERENCES,0.39601769911504425,"j=1
p(yj|α) = log D
Y j=1"
REFERENCES,0.39823008849557523,"Γ(PC
k=1 αk)
QC
k=1 Γ(αk) C
Y"
REFERENCES,0.4004424778761062,"k=1
yαk−1
j,k = D "" log Γ C
X"
REFERENCES,0.4026548672566372,"k=1
αk ! − C
X"
REFERENCES,0.40486725663716816,"k=1
log Γ(αk) + C
X"
REFERENCES,0.40707964601769914,"k=1
(αk −1) log ¯hi,k #"
REFERENCES,0.4092920353982301,"where log ¯hi,k is the k-th component of log ¯hi. Since the final expression of the above log-likelihood
function F only depends on the log-predictions {log yj}j=1,...,D through the observed sufficient
statistics log ¯hi (i.e., with an element-wise log operation), we can directly use ¯hi in (1) instead of
{yj}j=1,...,D."
REFERENCES,0.41150442477876104,"Similar predictions between models imply similar MLE approximations of their Dirichlet
abstractions.
Intuitively, two models produce similar predictions if and only if their Dirichlet
abstractions are similar. The result below precisely formalizes this intuition by exploiting the analytic
tractability of the log-likelihood function F (1) which is concave with a unique maximizer:
Proposition 3. Suppose that the observed sufficient statistics log ¯hi (log ¯hi′) based on the predictions
of Mi (Mi′) on D and the MLE approximation of its Dirichlet abstraction αi (αi′) are given. Then,"
REFERENCES,0.413716814159292,|¯hi −¯hi′|1 = 0 ⇐⇒αi = αi′ .
REFERENCES,0.415929203539823,"Proof. From (1),"
REFERENCES,0.41814159292035397,"F(α, ¯hi) = D × [G(α) + log ¯hi α⊤−log ¯hi 1⊤]"
REFERENCES,0.42035398230088494,"argmax
α
F(α, ¯hi) = argmax
α
G(α) + log ¯hi α⊤"
REFERENCES,0.4225663716814159,"= argmax
α
G(α) + log ¯hi′ α⊤−log ¯hi′ α⊤+ log ¯hi α⊤"
REFERENCES,0.4247787610619469,"= argmax
α
F(α, ¯hi′) + D
 
log ¯hi −log ¯hi′
α⊤.
(4)"
REFERENCES,0.4269911504424779,"Note that the RHS expression of (4) to be maximized remains concave since F(α, ¯hi′) is con-
cave in α [36] and the D
 
log ¯hi −log ¯hi′
α⊤term is linear in α.
If |¯hi −¯hi′|1
= 0,
then the D
 
log ¯hi −log ¯hi′
α⊤term in (4) becomes 0.
So, αi = argmaxα F(α, ¯hi) =
argmaxα F(α, ¯hi′) = αi′ since F is concave with a unique maximizer. Therefore, |¯hi −¯hi′|1 =
0 =⇒αi = αi′."
REFERENCES,0.42920353982300885,"From Lemma 1 below, log ¯hi,k = ψ(αi,k) −ψ(|αi|1) and log ¯hi′,k = ψ(αi′,k) −ψ(|αi′|1) where
αi,k (αi′,k) is the k-th component of αi (αi′) and ψ is the digamma function.9 It follows immediately
that
¯hi,k −¯hi′,k = exp[ψ(αi,k) −ψ(|αi|1)] −exp[ψ(αi′,k) −ψ(|αi′|1)] ,"
REFERENCES,0.4314159292035398,so αi = αi′ =⇒|¯hi −¯hi′|1 = 0.
REFERENCES,0.4336283185840708,"Importantly, both abstractions are able to preserve the similarity between Mi and Mi′, via either
the Hellinger distance dH(αi, αi′) (further discussed in Sec. 4.1) or the ℓ1 distance |¯hi −¯hi′|1"
REFERENCES,0.4358407079646018,"9The digamma function ψ(x) := d/dx(ln Γ(x)) is a monotonically increasing function that converges to
ln x −1/2x for any x > 0."
REFERENCES,0.43805309734513276,"(Proposition 3 above) where a lower ℓ1 or dH distance is equivalent to a higher similarity. We also
empirically compare αi, ¯hi in Sec. 4.2 and find that in general αi is better.
Lemma 1. Suppose that the observed sufficient statistics log ¯hi based on the predictions of Mi on D
and the MLE approximation of its Dirichlet abstraction αi are given. Then,"
REFERENCES,0.44026548672566373,"log ¯hi,k = ψ(αi,k) −ψ(|αi|1) ."
REFERENCES,0.4424778761061947,"Proof. The partial derivative of F(α, ¯hi) w.r.t. αk can be explicitly derived as follows:"
REFERENCES,0.4446902654867257,"∂F(α, ¯hi)"
REFERENCES,0.4469026548672566,"∂αk
= D  ψ C
X"
REFERENCES,0.4491150442477876,"k=1
αk !"
REFERENCES,0.45132743362831856,"−ψ(αk) + log ¯hi,k ! ."
REFERENCES,0.45353982300884954,"For a concave optimization problem (i.e., maximizing the log-likelihood) subject to a non-negative
orthant constraint (i.e., α ⪰0), the work of [6] has shown that the optimality conditions can be
expressed as"
REFERENCES,0.4557522123893805,"∇F(α; ¯hi) ⪰0
and
αk × ∂F(α, ¯hi)"
REFERENCES,0.4579646017699115,"∂αk
= 0
for k = 1, . . . , C ."
REFERENCES,0.46017699115044247,"The last condition is known as the complementarity. Focusing on the complementarity condition
w.r.t. the k-th components of αi and ¯hi gives"
REFERENCES,0.46238938053097345,"αi,k = 0
∨
∂F(α, ¯hi)"
REFERENCES,0.4646017699115044,"∂αk
= 0 ."
REFERENCES,0.4668141592920354,"Since αi,k > 0 (Definition 1),"
REFERENCES,0.4690265486725664,"∂F(α, ¯hi)"
REFERENCES,0.47123893805309736,"∂αk
= D
 
ψ(|αi|1) −ψ(αi,k) + log ¯hi,k

= 0"
REFERENCES,0.47345132743362833,"which is simplified to
ψ(|αi|1) −ψ(αi,k) + log ¯hi,k = 0
and thus,
log ¯hi,k = ψ(αi,k) −ψ(|αi|1) ."
REFERENCES,0.4756637168141593,"A.2
Results Related to Dirichlet Distribution and Distributional Distance"
REFERENCES,0.4778761061946903,"Suitable measures of distance between Dirichlet distributions.
We highlight the challenges in
applying the distance measures beside the Hellinger distance in App. A. Specifically, the Hellinger
distance provides unique and desirable theoretical properties (e.g., satisfying the triangle inequality)
which we exploit (e.g., to derive Theorem 1)"
REFERENCES,0.48008849557522126,"In our context, we seek a distance measure that is well-defined between two Dirichlet distributions,
can be evaluated in closed form, and has analytic properties. The work of [63] has painstakingly
compared several probabilistic distance measures including the Kullback–Leibler (KL) and symmetric
KL divergences [38, 42], Patrick–Fischer distance [60], generalized Matusita distance [4], Lissack–Fu
distance [50], Kolmogorov [15] distance, Chernoff distance [12], and Hellinger distance [27], and
made the following observations: The KL and symmetric KL divergences and the Patrick–Fischer
distance can encounter cases where the distance becomes undefined. The generalized Matusita
distance, Lissack–Fu distance, and Kolmogorov distance all lack an anti-derivative. So, we consider
and compare the remaining two options: Chernoff and Hellinger distances, which are connected as
follows."
REFERENCES,0.4823008849557522,"Chernoff vs. Hellinger distances.
As mentioned earlier, the Chernoff distance dH is the other
theoretically appealing choice for Dirichlet distributions [63], so we discuss its connection with the
Hellinger distance as follows. We start by recalling the definition for Chernoff distance and derive an
analytic connection between them.
Definition 4 (Chernoff distance [12]). The Chernoff distance between two distributions p and q is
dC(p, q; λ) := −ln
R
pλ(x) q1−λ(x) dx where λ ∈(0, 1). Note that dC(p, q; λ = 1/2) is symmetric
in p and q."
REFERENCES,0.48451327433628316,"For two continuous distributions p, q, their Hellinger distance dH(p, q) and their Chernoff distance
(with λ = 1/2) dC(p, q; λ = 1/2) are connected via the Bhattacharyya coefficient BC(p, q) :=
R p"
REFERENCES,0.48672566371681414,"p(x)q(x)dx ∈[0, 1] as follows,"
REFERENCES,0.4889380530973451,"1 −d2
H(p, q) = exp(−dC(p, q; λ = 1/2))"
REFERENCES,0.4911504424778761,"by substituting the equalities
dH(p, q) =
p"
REFERENCES,0.49336283185840707,"1 −BC(p, q) ,"
REFERENCES,0.49557522123893805,"and
dC(p, q; λ = 1/2) = −ln(BC(p, q)) ."
REFERENCES,0.497787610619469,"As a result,
dH(p, q) =
p"
REFERENCES,0.5,"1 −exp(−dC(p, q; λ = 1/2)) ,
(5)"
REFERENCES,0.5022123893805309,"or equivalently,
dC(p, q; λ = 1/2) = −ln(1 −d2
H(p, q)) .
(6)"
REFERENCES,0.504424778761062,"From Equ.(6), dC is monotonic w.r.t. dH, but dC has a logarithmic dependence which results in it not
being a proper metric (i.e., does not satisfy the triangle inequality) unlike dH. We specifically leverage
the triangle inequality to prove Theorem 1, which seems difficult to do for the Chernoff distance."
REFERENCES,0.5066371681415929,"Interestingly, this logarithmic dependence turns out to be a practical advantage where dH can run the
risk of numerical overflow [63]. Our clustering experiment of the models (App. C) runs into the issue
of numerical overflow of the Hellinger distance and we resort to the Chernoff distance. Our empirical
results (App. C) also support this that using dC can obtain better results than using dH."
REFERENCES,0.5088495575221239,"Proof of Proposition 2.
Continuing from our discussion in Sec. 3, νCE(C) ≤ν2
H(C) follows from
Lemma 2 below by requiring a sufficient condition on the differential entropy of QC, as stated in
Proposition 2.10 On the other hand, constructing a lower bound of νCE(C) via ν2
H(C) is less direct,
as can be seen from the upper bound on CE using d2
H in Lemma 2. Deriving such a lower bound
(Proposition 2) involves exploiting a property specific to Dirichlet distributions that the differential
entropy is non-positive and bounded from above."
REFERENCES,0.5110619469026548,"Proof of Proposition 2. By substituting p = QC and q = Q∗into the first inequality of Lemma 2,
2d2
H(QC, Q∗) ≤CE(QC, Q∗) −H(QC).
Using H(QC) + d2
H(QC, Q∗) ≥0, it follows that
d2
H(QC, Q∗) ≤CE(QC, Q∗), so νCE(C) ≤ν2
H(C) by plugging in the definitions of νCE(C) :=
−CE(QC, Q∗) and ν2
H(C) := −d2
H(QC, Q∗)."
REFERENCES,0.5132743362831859,"Next, the differential entropy of a Dirichlet distribution p parameterized by α [48, Table 2.1] is"
REFERENCES,0.5154867256637168,"H(p) = −G(α) + (PC
k=1 αk −C) ψ(PC
k=1 αk) −PC
k=1(αk −1) ψ(αk)"
REFERENCES,0.5176991150442478,"which is maximized at α = 1C [55, 54], and its maximum value is therefore −log Γ(C). Substituting
H(p) ≤−log Γ(C) into the second inequality of Lemma 2 gives"
REFERENCES,0.5199115044247787,"CE(p, q) ≤constq ×
 
1 −[1 −d2
H(p, q)]2
−log Γ(C) ."
REFERENCES,0.5221238938053098,"By substituting p = QC and q = Q∗into the above and plugging in the definitions of νCE(C) :=
−CE(QC, Q∗) and ν2
H(C) := −d2
H(QC, Q∗),"
REFERENCES,0.5243362831858407,"−νCE(C) ≤constQ∗×
 
1 −[1 + ν2
H(C)]2
−log Γ(C) ,"
REFERENCES,0.5265486725663717,which can be rearranged to complete the proof.
REFERENCES,0.5287610619469026,"Lemma 2. For any two continuous distributions p and q,"
REFERENCES,0.5309734513274337,"2d2
H(p, q) ≤CE(p, q) −H(p) ≤constq ×
 
1 −[1 −d2
H(p, q)]2"
REFERENCES,0.5331858407079646,"where H(p) := −
R
p(x) log p(x) dx is the differential entropy of p, dH(p, q) ∈[0, 1] is the Hellinger
distance, and constq := [log(1/qmin −1)]/(1 −2qmin) with qmin := minz q(z)."
REFERENCES,0.5353982300884956,"10Note ν2
H(C) := −d2
H(QC, Q∗)."
REFERENCES,0.5376106194690266,"Proof. Firstly,"
REFERENCES,0.5398230088495575,"CE(p, q) := −
Z
p(x) log q(x) dx"
REFERENCES,0.5420353982300885,"= dKL(p, q) + H(p)
(7)"
REFERENCES,0.5442477876106194,"where dKL(p, q) :=
R
p(x) log(p(x)/q(x)) dx is the Kullback-Leibler distance. Next, we derive a
lower bound of dKL(p, q) in terms of dH(p, q):"
REFERENCES,0.5464601769911505,"dKL(p, q) ≥2d2
H(p, q) .
(8)"
REFERENCES,0.5486725663716814,"To prove (8),"
REFERENCES,0.5508849557522124,"dKL(p, q) =
Z
p(x) log p(x)"
REFERENCES,0.5530973451327433,q(x) dx
REFERENCES,0.5553097345132744,"= 2
Z
p(x) log p"
REFERENCES,0.5575221238938053,"p(x)
p"
REFERENCES,0.5597345132743363,"q(x)
dx"
REFERENCES,0.5619469026548672,"= 2
Z
p(x)  −log p"
REFERENCES,0.5641592920353983,"q(x)
p p(x) ! dx"
REFERENCES,0.5663716814159292,"≥2
Z
p(x)  1 − p"
REFERENCES,0.5685840707964602,"q(x)
p p(x) ! dx"
REFERENCES,0.5707964601769911,"=
Z n
p(x) + p(x) −2
p"
REFERENCES,0.5730088495575221,"p(x)
p"
REFERENCES,0.5752212389380531,"q(x)
o
dx"
REFERENCES,0.577433628318584,"= 1 +
Z n
p(x) −2
p"
REFERENCES,0.5796460176991151,"p(x)
p"
REFERENCES,0.581858407079646,"q(x)
o
dx"
REFERENCES,0.584070796460177,"=
Z
q(x) dx +
Z n
p(x) −2
p"
REFERENCES,0.5862831858407079,"p(x)
p"
REFERENCES,0.588495575221239,"q(x)
o
dx"
REFERENCES,0.5907079646017699,"=
Z n
q(x) + p(x) −2
p"
REFERENCES,0.5929203539823009,"p(x)
p"
REFERENCES,0.5951327433628318,"q(x)
o
dx"
REFERENCES,0.5973451327433629,"=
Z np"
REFERENCES,0.5995575221238938,"p(x) −
p"
REFERENCES,0.6017699115044248,"q(x)
o2
dx"
REFERENCES,0.6039823008849557,"= 2d2
H(p, q)"
REFERENCES,0.6061946902654868,"where the inequality is due to −log z ≥1 −z for all z ≥0 by setting z =
p"
REFERENCES,0.6084070796460177,"q(x)/
p"
REFERENCES,0.6106194690265486,"p(x) ≥0.
Moreover, we have an upper bound of dKL(p, q) from [61, Equation 7.27]:"
REFERENCES,0.6128318584070797,"dKL(p, q) ≤constq ×

1 −[1 −d2
H(p,q)]2
.
(9)"
REFERENCES,0.6150442477876106,"Lastly, substituting dKL(p, q) = CE(p, q) −H(p) from (7) into (8) and (9) completes the proof."
REFERENCES,0.6172566371681416,"An example on how cross-entropy loss encodes the predictive accuracy and certainty.
The CE
loss is used to construct upper and lower bounds for our proposed method (i.e., ν in Eq. (3)). Hence,
our proposed method also encodes the predictive accuracy and certainty, as exemplified below."
REFERENCES,0.6194690265486725,"Recall that the CE loss of a C-dimensional predicted probability vector ˆy w.r.t. the one-hot encoded
true label y: − C
X"
REFERENCES,0.6216814159292036,"k=1
yk × ln(ˆyk) ."
REFERENCES,0.6238938053097345,"W.l.o.g., assume that y1 = 1 (i.e., the correct class is the first class)."
REFERENCES,0.6261061946902655,"1. For two predictions [0.9, 0.1, 0, . . . , 0] vs.[0.1, 0.9, 0, . . . , 0]. The CE losses are 0.105 and
2.30, respectively. Note that the first prediction is correct while the second in incorrect and
that both predictions are ”equally certain”. Hence, a higher predictive accuracy implies a
lower CE."
REFERENCES,0.6283185840707964,"2. For two predictions [0.9, 0.1, 0, . . . , 0] vs.[0.6, 0.4, 0, . . . , 0]. The CE losses are 0.105 and
0.511, respectively. Note that both predictions are correct while the first prediction is ”more
certain”. Hence, a higher predictive certainty implies a lower CE, if the prediction is correct."
REFERENCES,0.6305309734513275,"Extension to other model evaluation criteria.
In addition to predictive accuracy and certainty,
there are other possible desirable criteria for model valuation such as adversarial robustness [43],
distributional robustness [67], and algorithmic fairness (i.e., by removing prediction bias) in ML
[56]. Put differently, it is possible to devise other model valuations based on adversarial robustness,
distributional robustness, or the algorithmic fairness of a model. Interestingly, since these more
sophisticated criteria all utilize the same building blocks (i.e., the predictive accuracy and certainty
of models on carefully selected query sets), our proposed approach can subsume these different
criteria, as described below and summarized in Table 1. To be a little technical, the high-level idea
is that, since these criteria leverage the CE loss ℓCE in very specific ways, and we have derived the
relationship between dH and CE above (Lemma 2), our approach can be extended to incorporate
these criteria through careful choices of ν."
REFERENCES,0.6327433628318584,"For instance, the work of [43] explicitly defines “adversarial” training examples Dadv to be distin-
guished from “clean” training examples Dclean and evaluates a model’s performance (i.e., a linear
combination of the CE losses w.r.t. the adversarial and clean training examples separately) as follows:"
REFERENCES,0.6349557522123894,objectiveadv := ℓCE(M; Dadv) + υ ℓCE(M; Dclean)
REFERENCES,0.6371681415929203,"for some weight υ > 0 where we suppress the constants that linearly depend on the sizes of Dadv
and Dclean for simplicity and ℓCE(M; D) is the common CE loss incurred by the predictions of M on
query set D."
REFERENCES,0.6393805309734514,"The work of [67, Equation 5] gives the group-adjusted distributionally robust optimization (DRO)
estimator where each “group” g ∈G contains training examples from a possibly different data
distribution. Effectively, the optimizer minimizes the maximum CE loss over different groups/query
sets s.t. each query set is a dataset from a possibly different data distribution:"
REFERENCES,0.6415929203539823,"objectiveDRO := max
g∈G ℓCE(M; Dg)"
REFERENCES,0.6438053097345132,"where, for simplicity, a group size-dependent constant and a model capacity-dependent constant are
ignored."
REFERENCES,0.6460176991150443,"The work of [56] presents a number of different definitions of fairness in ML to cater to different
situations. In general, these definitions each describe a particular way for the model to make
classifications w.r.t. specific conditions on (the features of) the data in order to be fair. For simplicity,
we illustrate with equal opportunity (EO) [56, Definition 2] which “means that the probability of a
person in a positive class being assigned to a positive outcome should be equal for both protected and
unprotected (female and male) group members.” To relate this to CE, we can define two query sets:
D+
prot containing positive training examples under the protected group and D+
unprot containing positive
training examples under the unprotected group. To achieve equal opportunity, the average CE losses
on both query sets should be (approximately) equal (i.e., both groups have equal true positive rates)
or, equivalently, the difference in the CE losses should be small:"
REFERENCES,0.6482300884955752,"objectiveEO := |ℓCE(M; D+
prot) −ℓCE(M; D+
unprot)| ."
REFERENCES,0.6504424778761062,"Table 1 gives the specific definitions of query sets with the corresponding (possible) choices of the
characteristic function ν adapted from the above-mentioned minimization objectives by replacing
ℓCE(M; D) with d(Q, Q∗; D) and adding a negation since these are minimization objectives."
REFERENCES,0.6526548672566371,"Firstly, we show the original implementations/formulations using the CE loss ℓCE [43, 67, 56] can
be reformulated using the CE between Dirichlet abstractions. We provide the reformulation of
objectiveDRO,
max
g∈G CE(Q, Q∗; D) ,"
REFERENCES,0.6548672566371682,"by replacing ℓCE with CE on the respective Dirichlet abstraction Q (for M) and an expert Q∗(from
the test set) and omit the explicit derivations of the other two for brevity."
REFERENCES,0.6570796460176991,"Such reformulation is enabled by the connection between CE and ℓCE: The CE loss ℓCE(M; D)
implicitly assumes an expert who provides the correct labels to compute the loss on the query set D."
REFERENCES,0.6592920353982301,"On the other hand, CE(Q, Q∗; D) explicitly uses the expert and measures the cross-entropy between
the two Dirichlet abstractions (i.e., one for the model M and the other for the expert) on the query
set D. Therefore, if a model M makes predictions similar to the expert on a fixed query set D, then
both ℓCE(M; D) and CE(Q, Q∗; D) are small (i.e., optimum is 0). Next, inspired by the relationship
between dH and CE in Proposition 2, the expressions in CE are reformulated using dH in Table 1.
Note that Proposition 2 provides us with the intuition and is not used exactly. Hence, our approach of
decoupling the query set(s) from the model valuation makes it general enough to subsume these more
sophisticated criteria (of a model’s performance) for model valuation. A question one might ask is
that: (How) can multiple such evaluation criteria be combined? The answer is yes, by leveraging (P3)
to linearly combine selected evaluation criteria, as discussed next."
REFERENCES,0.661504424778761,"Combining multiple evaluation criteria.
Specifically, for a user (e.g., potential buyer of the model)
who knows the relative importance of several different criteria (formalized by the specific query sets
such as in Table 1), then the user can specify the weights to achieve a desirable trade-off. This is
because different users might have different preferences and there is no one-size-fits-all solution.
To elaborate, suppose the user only cares about whether the model makes accurate predictions but
not at all about adversarial robustness because the user intends to deploy it in a controlled and safe
environment, then the task constructed for adversarial robustness is not very relevant to this user. In
contrast, if the user does care about the adversarial robustness (which, is often at trade-off against
pure predictive performance), then the user can set the weights between the two tasks according to
their preferences."
REFERENCES,0.6637168141592921,"On the other hand, if the trade-offs of the tasks are unknown, for instance the objectives are very
complex, then uncovering the relationship between tasks (which are potentially trade-offs of each
other) is useful. Specifically, the approach to obtain the connections in Table 1 is useful. For instance,
predictive accuracy and adversarial robustness are trade-offs of each other since the objective of
adversarial robustness ”balances” between the clean and adversarial cross entropy (CE) losses.
Upon identifying this theoretical connection, the user can then specify the weight between the two
accordingly.
Remark 1. Note that our discussion on how to extend and combine multiple model evaluation criteria
aims to provide the technical tools for doing so, instead of identifying how a buyer or a seller should
use them. To elaborate, the buyer can use our method to combine several evaluation criteria based on
known preferences of the relative importance of these criteria. Our discussion does not aim to guide
the buyer in identifying such preferences or consider the potential asymmetry of information in a
marketplace where only the buyer (or the seller) knows such preferences, how the other party should
react. We believe these are further and interesting questions for future exploration."
REFERENCES,0.665929203539823,"Other useful technical results.
Lemma 3 (Precision-weighted fusion preserves Dirichlet). The precision-weighted fusion in Defi-
nition 3 follows a Dirichlet distribution: QC = Dir([Pn
i=1 αi,1, . . . , Pn
i=1 αi,C]) [34, Theorem 2.1].
Lemma 4 (Bhattacharyya coefficient between Dirichlet distributions [63]). Let α and α′ denote
the C-dimensional parameters specifying the two Dirichlet distributions p and q, respectively. Then,
the Bhattacharyya coefficient is"
REFERENCES,0.668141592920354,"BC(p, q) =
QC
k=1 Γ((αk + α′
k)/2)"
REFERENCES,0.6703539823008849,"Γ(PC
k=1(αk + α′
k)/2)
× p"
REFERENCES,0.672566371681416,"Γ(|α|1) Γ(|α′|1)
qQC
k=1 Γ(αk) Γ(α′
k)
."
REFERENCES,0.6747787610619469,"Lemma 5. The Hellinger distance between two Dirichlet distributions p and q parameterized by the
respective α and α′ is"
REFERENCES,0.6769911504424779,"dH(p, q) =
√ 2 × "
REFERENCES,0.6792035398230089,"1 −
QC
k=1 Γ((αk + α′
k)/2)"
REFERENCES,0.6814159292035398,"Γ(PC
k=1(αk + α′
k)/2)
× p"
REFERENCES,0.6836283185840708,"Γ(|α|1) Γ(|α′|1)
qQC
k=1 Γ(αk) Γ(α′
k)   1/2 ,"
REFERENCES,0.6858407079646017,"which follows directly from an equivalent definition of dH(p, q) :=
√ 2 ×
p"
REFERENCES,0.6880530973451328,"1 −BC(p, q) ."
REFERENCES,0.6902654867256637,"A.3
Lipschitz Continuity of Model Shapley"
REFERENCES,0.6924778761061947,"We provide the proof of Theorem 1 here and describe a sufficient condition for fusion (i.e., Defini-
tion 3) to increase similarity."
REFERENCES,0.6946902654867256,"Further elaboration on Lipschitz continuity.
We adopt the following general definition for
Lipschitz continuity: For two metric spaces (X, dX) and (Y, dY), a function f : X 7→Y is Lf-
Lipschitz continuous if there exists a constant Lf > 0 s.t. ∀x1, x2 ∈X"
REFERENCES,0.6969026548672567,"dY(f(x1), f(x2)) ≤LfdX(x1, x2) ."
REFERENCES,0.6991150442477876,"In our formulation, for the model Shapley function Φ, the input space is the set [N] (or more precisely
the set {Qi : i ∈[N]} of Dirichlet abstractions) of the N models and the metric is the Hellinger
distance dH, which is a proper metric for probability distributions (in this case Dirichlet distributions);
the output space is R (i.e., for model Shapley values) and the metric is the absolute difference (i.e.,
|ϕi −ϕi′| for two inputs Qi, Qi′)."
REFERENCES,0.7013274336283186,"In summary, recall that ϕi ←Φ(i, ν, {Mi}i∈[N]) in Sec. 3, the Lipschitz continuity of Φ is w.r.t. its
first argument (i.e., i), when ν is defined as in (3) and the set {Mi}i∈[N] of models is fixed (i.e.,
correspondingly the set {Qi}i∈[N] is also fixed). For brevity, we suppress the notational dependence
on the latter arguments and write as ϕi := Φ(i; ·) : [N] 7→R where as mentioned above, the metric
for the input space is defined as d(i, i′) := dH(Qi, Qi′) for i, i′ ∈[N] and the metric for the outputs
is the absolute difference |ϕi −ϕi′| ."
REFERENCES,0.7035398230088495,"Proof of Theorem 1. We follow an idea that the similarity between the Dirichlet abstractions Qi
and Qi′ will lead to a small difference in their expected marginal contributions ϕi and ϕi′ when fused
with a common QC for any C ⊆[N] \ {i, i′}. Consequently, we can apply Lemma 6 in App. A.4."
REFERENCES,0.7057522123893806,"Firstly, from νH(C) = −dH(QC, Q∗) as in (3),"
REFERENCES,0.7079646017699115,"νH(C ∪{i}) −νH(C ∪{i′}) = −dH(QC∪{i}, Q∗) + dH(QC∪{i′}, Q∗) ."
REFERENCES,0.7101769911504425,"Then, using the property of triangle inequality of dH, it follows that"
REFERENCES,0.7123893805309734,"| −dH(QC∪{i}, Q∗) + dH(QC∪{i′}, Q∗)| ≤dH(QC∪{i}, QC∪{i′}) ≤dH(Qi, Qi′)"
REFERENCES,0.7146017699115044,"where the last inequality is due to the fusion-increases-similarity condition stated in Theorem 1 (and
examined below by Proposition 4). The final result can be obtained applying Lemma 6: Note that
d(i, i′) := dH(Qi, Qi′) < 1 (since the Hellinger distance is upper bounded by 1), so the condition in
Lemma 6 is satisfied with L = 1. In other words, for a different distance (other than the Hellinger
distance), a different value of L may be necessary. The constant Z is directly inherited to be the
Lipschitz constant."
REFERENCES,0.7168141592920354,"Proposition 4 (Fusion increases similarity). Suppose that αi and αi′ parameterize Qi and Qi′,
respectively. Then,
h
∀k ∈[C]
ψ
αi,k + αi′,k 2"
REFERENCES,0.7190265486725663,"
−ψ(αi,k)
≥
ψ
|αi|1 + |αi′|1 2"
REFERENCES,0.7212389380530974,"
−ψ(|αi|1)"
REFERENCES,0.7234513274336283,"∧
ψ
αi,k + αi′,k 2"
REFERENCES,0.7256637168141593,"
−ψ(αi′,k)
≥
ψ
|αi|1 + |αi′|1 2"
REFERENCES,0.7278761061946902,"
−ψ(|αi′|1)
i"
REFERENCES,0.7300884955752213,"=⇒
dH(QC∪{i}, QC∪{i′}) ≤dH(Qi, Qi′)"
REFERENCES,0.7323008849557522,where ψ is the digamma function.
REFERENCES,0.7345132743362832,"Proof of Proposition 4. It can be observed from Lemma 5 that dH(p, q) increases iff BC(p, q)
(Lemma 4) decreases. Then, it is equivalent to show that"
REFERENCES,0.7367256637168141,"BC(QC∪{i}, QC∪{i′}) ≥BC(Qi, Qi′) ."
REFERENCES,0.7389380530973452,"It can also be observed that BC can be viewed as a differentiable function taking in 2C parameters
(i.e., αi and αi′). Consider w.l.o.g. its partial derivative w.r.t. αi,k and w.r.t. αi′,k for k = 1, . . . , C:"
REFERENCES,0.7411504424778761,"∂BC
∂αi,k
= coeff ×

−ψ(αi,k) + ψ
αi,k + αi′,k 2"
REFERENCES,0.7433628318584071,"
−ψ
|αi|1 + |αi′|1 2"
REFERENCES,0.745575221238938,"
+ ψ(|αi|1)
"
REFERENCES,0.7477876106194691,"∂BC
∂αi′,k
= coeff ×

−ψ(αi′,k) + ψ
αi,k + αi′,k 2"
REFERENCES,0.75,"
−ψ
|αi|1 + |αi′|1 2"
REFERENCES,0.7522123893805309,"
+ ψ(|αi′|1)
 where"
REFERENCES,0.754424778761062,coeff = p
REFERENCES,0.7566371681415929,"Γ(|αi|1) Γ(|αi′|1) PC
k=1 Γ((αi,k + αi′,k)/2)"
QQC,0.7588495575221239,"2
qQC
k=1 Γ(αi,k) Γ(αi′,k) Γ(PC
k=1(αi,k + αi′,k)/2)
> 0"
QQC,0.7610619469026548,due to the positivity of Γ over the positive domain.11
QQC,0.7632743362831859,"Now, Lemma 3 implies that the fusion always increases αi,k: Since αi,k denotes the k-th component
of αi and αC∪{i},k denotes the k-th component of αC∪{i}, αC∪{i},k ≥αi,k. So, if ∂BC/∂αi,k ≥0
and ∂BC/∂αi′,k ≥0 for k = 1, . . . , C, then the resulting BC increases (or, equivalently, dH
decreases) after fusion."
QQC,0.7654867256637168,"Since coeff > 0,"
QQC,0.7676991150442478,"−ψ(αi,k) + ψ
αi,k + αi′,k 2"
QQC,0.7699115044247787,"
−ψ
|αi|1 + |αi′|1 2"
QQC,0.7721238938053098,"
+ ψ(|αi|1) ≥0 =⇒
∂BC
∂αi,k
≥0"
QQC,0.7743362831858407,"−ψ(αi′,k) + ψ
αi,k + αi′,k 2"
QQC,0.7765486725663717,"
−ψ
|αi|1 + |αi′|1 2"
QQC,0.7787610619469026,"
+ ψ(|αi′|1) ≥0 =⇒
∂BC
∂αi′,k
≥0"
QQC,0.7809734513274337,"for k = 1, . . . , C. So, the final result follows."
QQC,0.7831858407079646,"Let Dsum := PC
k=1 ψ((αi,k + αi′,k)/2) −(ψ(αi,k) + ψ(αi′,k))/2 and D|·| := C[ψ((|αi|1 +
|αi′|1)/2) −(ψ(|αi|1) + ψ(|αi′|1))/2]. The sufficient condition for Proposition 4 implies that
Dsum ≥D|·|. Intuitively, Dsum is a sum of dimension-/class-wise differences between Qi and Qi′
and it is large if every pair of αi,k and αi′,k are different and relatively small (i.e., low concentration
for dimension/class k). Dsum is likely large if the dimension C is large as there are more pairs of αi,k
and αi′,k whose difference contributes towards Dsum. On the other hand, D|·| is a measure of the
difference in the overall precisions of Qi and Qi′. D|·| is large if |αi|1 and |αi′|1 are different and
have small values. D|·| is likely small if C is large. As C increases, the precisions |αi|1 and |αi′|1
will increase, which will cause ψ((|αi|1 + |αi′|1)/2) and (ψ(|αi|1) + ψ(|αi′|1))/2 to be very close
due to the converging behavior of ψ."
QQC,0.7853982300884956,"The condition Dsum ≥D|·| says that if the class-wise difference between Qi and Qi′ outweighs the
difference in their precisions, then fusion increases similarity. Intuitively, if the ‘shapes’ of Qi and Qi′
are very different, then fusing each with a common distribution QC ‘evens out’ the difference in their
shapes and increases the similarity. In particular, if C is large (i.e., a high-dimensional classification
task), then the condition is more likely to be satisfied."
QQC,0.7876106194690266,"Empirical verification of Theorem 1.
Specifically, we verify whether a small dH(Qi, Qi′) leads
to a small |ϕi −ϕi′| via the Pearson coefficient between dH(Qi, Qi′) and |ϕi −ϕi′| over all i, i′,
and visualizing the corresponding heatmaps (Fig. 6). The setting is as follows. We investigate
5 real-world datasets (and various ML models), including MNIST, CIFAR-10 [41], two medical
datasets: a drug reviews dataset that classifies the type of prescribed medicine based on the text
reviews (DrugRe) [23] and a medical imaging dataset that classifies the medical department from the
diagnostic scans (MedNIST) [58], and a cyber-threat detection dataset that classifies network intrusion
based on input features such as IP addresses and network communication protocol (KDD99) [28].
Recall these are some of the highlighted application domains of model valuation (i.e., medicine and
cyber-defense) in Sec. 1. Query set D is the respective test set of each dataset without partitioning."
QQC,0.7898230088495575,"We adopt a grouping paradigm where the grouped models have the same model type (but undergo
independent training with the same data) to ensure some similarity within each group. So, we can
verify whether the models within the same group have similar MSVs. To see why models of the
same type can produce similar Dirichlet abstractions, we provide a clustering result of Qi (Fig. 11 in
App. C). Specifically, for MNIST, we implement 3 model types: logistic regression (LR), multilayer
perceptron (MLP), and a 2-layer convolutional neural network (CNN). For CIFAR-10, we utilize
3 known model types with pre-trained weights: ResNet-18 [26], SqueezeNet [37], and DenseNet-
121 [35]. For DrugRe, we use a CNN and a bi-directional long-short term memory (BiLSTM)
network. More details on other datasets are in App. C."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.7920353982300885,"11The code for verifying this partial derivative using an automatic differentiation package is included in the
supplementary material."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.7942477876106194,"The high Pearson coefficients in Table 3 provide some verification for Theorem 1. The matched color
intensities in the heatmaps in Fig. 6 confirm that similar models have similar MSVs. Left (right) of
Fig. 6 is w.r.t. general (class-specific) Dirichlet abstractions."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.7964601769911505,"Figure 6: Left two plots are heatmaps for dH(Qi, Qi′) and |ϕi −ϕi′|. Right two plots are heatmaps
for dH(Qi, Qi′; {Dk}) and |ϕi({Dk}) −ϕi′({Dk})|."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.7986725663716814,"Table 3: Pearson coefficient between dH(Qi, Qi′) and |ϕi −ϕi′| using the test set as a single query
set. A high coefficient verifies Theorem 1."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8008849557522124,"MNIST
CIFAR-10
MedNIST
KDD
DrugRe"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8030973451327433,"0.974
0.996
0.974
0.999
0.955"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8053097345132744,"A.4
Model Shapley Value"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8075221238938053,"Closed-form expression of ν and the resulting computational complexity.
Recall that an advan-
tage of the combined choices of Definition 3 and the Hellinger distance dH (described in Sec. 3) is an
available closed form evaluation of dH between two Dirichlet abstractions, which has a constant time
computational cost (i.e., O(1)). This is important as dH is used to define the characteristic function
ν (3) for model Shapley (2). Specifically, note that the definition of model Shapley (2) requires
evaluating the characteristic function ν for an exponential number of times due to the summation
over all possible subsets C ⊆[N] \ {i}. In other words, even with a characteristic function ν that
can be evaluated in constant time (e.g., dH), the computational complexity of MSV is still at least
exponential in N, which is almost intractable for large N; if evaluating the characteristic function
has a higher computational complexity, then the computational complexity of MSV would be even
more intractable."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8097345132743363,"Similarity-bounded difference in SVs.
The following lemma provides a general result for bound-
ing the difference in two Shapley values (not necessarily MSVs) and is used in the proof of Theorem 1.
It may be of independent interest.
Lemma 6 (Similarity-bounded difference in the Shapley values). For all i, i′ ∈[N],
(∀C ⊆[N] \ {i, i′} |ν(C ∪{i}) −ν(C ∪{i′})| ≤Ld(i, i′)) =⇒|ϕi −ϕi′| ≤ZLd(i, i′)
where L ≥0 is a constant and d(i, i′) is some distance measure between i and i′ and Z is the linear
scaling as in (2)."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8119469026548672,"Proof of Lemma 6. The difference |ϕi −ϕ′
i| can be bounded by enumerating the coalitions in a paired
way as follows:"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8141592920353983,"|ϕi −ϕi′| ≤
X"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8163716814159292,"C⊆[N]\{i,i′}
ZωC|ν(C ∪{i}) −ν(C ∪{i′})| +
X"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8185840707964602,"(C,C′),
C⊆[N]\{i};i′∈C,
C′⊆[N]\{i′};i∈C′,
C∪{i}=C′∪{i′}"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8207964601769911,ZωC|ν(C′) −ν(C)|
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8230088495575221,"where ωC := |C|!(N −|C| −1)!/N! and we have multiplied the constant Z into the separate
summations. Note that this enumeration (considering both summations) exhausts (w.l.o.g. from
the viewpoint of i) C ⊆[N] \ {i} in the calculation of ϕi. The first summation enumerates all
C ⊆[N] \ {i, i′}, so the remaining C to consider for i’s marginal contributions as in (2) are the
ones that include i′ but not i (considered in the second summation). The summands in the second
summation are in fact also in the form of |ν(C ∪{i}) −ν(C ∪{i′})| for some C ⊆[N] \ {i, i′}. Note
that in the second summation,
(C ∪{i} = C′ ∪{i′}) ∧i′ ∈C ∧i ∈C′ ,"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8252212389380531,"so C′ \ {i} = C \ {i′}. Consequently, let C := C′ \ {i}. Then,"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.827433628318584,|ν(C′) −ν(C)| = |ν(C ∪{i}) −ν(C ∪{i′})| .
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8296460176991151,"To complete the final step, first consider the simpler case of Z = 1 and the coefficient ωC is
defined in a way such that ϕi satisfies efficiency [69] (i.e., P"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.831858407079646,"C⊆[N]\{i} ωC = 1), the condition
∀C ⊆[N] \ {i, i′} |ν(C ∪{i}) −ν(C ∪{i′})| ≤Ld(i, i′) can be used to bound the overall sum of
the RHS as
|ϕi −ϕi′| ≤Ld(i, i′) .
More generally for Z ̸= 1, it can be directly multiplied to the RHS as follows"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.834070796460177,"|ϕi −ϕi′| ≤ZLd(i, i′)"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8362831858407079,since every term is multiplied by the same constant in the above two summations.
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.838495575221239,"Proposition 5 (Diminishing Model Shapley Value due to Substitutes). According to the definitions
as in (P4), ϕi (ϕ′
i) denotes the model Shapley value of Mi w.r.t. [N] ([N ′] := [N] ∪{ic}) and
Mic = Mi is a perfect substitute/identical duplicate/copy. Then,"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8407079646017699,"(∀C ⊆[N] \ {i} ν(C ∪{i}) −ν(C) ≥ν(C ∪{i, ic}) −ν(C ∪{i})) =⇒ϕ′
i ≤ϕi ."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8429203539823009,"Proof of Proposition 5. The inequality ϕi ≥ϕ′
i is shown by examining the pairwise difference over
their respective summands in the summation of model Shapley."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8451327433628318,"For ϕi, ϕi := P"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8473451327433629,"C⊆[N]\{i} sC where the summand sC := ωCMCi(C). ωC is as in (2) and MCi(C) :=
ν(C ∪{i}) −ν(C) is the marginal contribution of i w.r.t. C."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8495575221238938,"For ϕ′
i, ϕ′
i := P
C⊆[N]\{i}
C′=C∪{ic}
s′
C where the summand"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8517699115044248,"s′
C := |C|!(N + 1 −|C| −1)!"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8539823008849557,"(N + 1)!
MCi(C) + |C′|!(N + 1 −|C′| −1)!"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8561946902654868,"(N + 1)!
MCi(C′) ."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8584070796460177,"ϕ′
i is obtained by observing that adding ic to [N] means additionally enumerating all the C ⊆[N]\{i}
but added with ic, as shown above."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8606194690265486,"As |C′| = |C| + 1,"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8628318584070797,"s′
C =
ωC
N + 1[(N −|C|) MCi(C) + (|C| + 1) MCi(C′)]"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8650442477876106,"≤
ωC
N + 1[(N −|C|) MCi(C) + (|C| + 1) MCi(C)]"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8672566371681416,"=
ωC
N + 1[(N + 1) MCi(C)] = sC"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8694690265486725,"where the inequality is due to the conditionally redundant property of ν.12 Since ϕi and ϕ′
i enumerate
the same summation and individual summands have s′
C ≤sC, it follows that ϕ′
i ≤ϕi."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8716814159292036,"Remedy for duplication from a dishonest seller.
While the marginal utility of each duplicate
model decreases, the combined utility of all the duplicated models may be higher than if there is
only one such model. Hence, a dishonest seller might exploit this by duplicating a model to receive
a higher combined utility. As a hypothetical example to illustrate this: two models Mi, Mj from
vendors i, j respectively, each have values 0.5, then if the model seller i decides to fraudulently
duplicate model Mi to another Mic. Although the value for Mi depreciates, such duplication can
lead to a higher value for vendor i, namely the value of Mi and Mic combined might be higher than
if only Mi is present."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8738938053097345,"We note that our proposed approach can be adapted to address this issue relatively easily, by sub-
stituting our proposed in Eq. (3) into the variant of the Shapley value [24, Theorem 4.5], which
importantly continues to satisfy the properties (P1), (P2) and (P3) [24]. However, we highlight that
(the robustness to) such duplication is beyond the scope of this work."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8761061946902655,"12Our definition of conditional redundancy is a weaker version of [24, Assumption 2] which stipulates the
benefit of a copy Mic (conditioned on model Mi already being added) is exactly 0."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8783185840707964,"B
Additional Literature Review"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8805309734513275,"B.1
Relation to Data Valuation and its Design Approach"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8827433628318584,"Data valuation, originating from the motivating application scenario of AI marketplaces [1, 13, 24],
studies how to determine the intrinsic worth of data, often in the context of ML. Intuitively, as these
marketplaces treat data as commodities for trading, a pricing mechanism (i.e., a valuation function) is
necessary. There have been some works exploring data valuation [10, 20, 39, 80], by leveraging ML
principles and assumptions. For instance, data are more valuable if training on the data produces an
ML model with higher performance (i.e., more accurate). In addition to the application scenario of AI
marketplaces, the value of data can also be/has been used in interpretable ML [20], data sharing [16]
and collaborative ML [76, 79]. However, as motivated in Sec. 1, there are various practical scenarios
where data valuation is difficult. Hence, we explore an alternative by shifting our focus onto the ML
models in these scenarios to consider model valuation."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8849557522123894,"In terms of the design approach, although the existing data valuation works have different technical
perspectives and thus different solutions, they often adopt a common first-principle approach, i.e., data
which can produce more accurate models are more valuable. This approach provides an interpretation
for the valuation function or the values assigned to the data. While it may seem counter-intuitive
to market economics where the price/value can naturally arise from the demand and supply, this
approach is sensible because the lack of effective demand (i.e., the willingness and ability of buyers
to purchase goods/data/ML model at different prices). To elaborate, effective demand requires the
buyers to have some intrinsic valuation function for the data/ML model which helps determine the
quantity the buyers are willing to purchase at some fixed price. In contrast to the more conventional
goods, the market for data/ML model is relatively niche in the sense that even the buyers themselves
do not already have a good intrinsic valuation function for the data/ML model. As a result, the buyers
are unable to specify the effective demand, which makes it difficult for the price/valuation to arise
naturally from the demand and supply in a market. To this end, the (proposed) valuation methods (i.e.,
existing data valuation methods and the model valuation method in this paper) aim to fill in this gap
by explicitly designing such a valuation function where the value is determined through the utility
of the data/ML model in the context of ML (e.g., predictive performance). In this vein, the existing
data valuation methods and our proposed model valuation method share a common perspective of
designing the valuation function reflect the utility of the data/ML model in terms of some performance
in the ML context. An added benefit of this design approach is the interpretability of the value. To see
this, suppose in the marketplace (e.g., AWS marketplace), an auditor questions the basis for certain
pricing of some ML model, our proposed valuation function can provide some insight to that question
and can potentially be used by regulators to oversee the ML model marketplaces."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8871681415929203,"In terms of the practical setting, data valuation can be viewed as (mostly) white-box (i.e., the actual
data are used as the input to the designed valuation function and thus completely observed).13
Intuitively, in order to determine the value of some data, the valuation function must “see” the data.
In this regard, this setting for data valuation leads to a relatively straightforward formal representation
of the data, which is the data. In contrast, model valuation can encounter additional practical
difficulties which make the formal representation of ML much less straightforward. Similar to in data
valuation, we might want to use the model itself as its formal representation (e.g., the parameters of
the parametric models). However, the so-called black-box access which is particularly appealing in
model valuation (Sec. 1), excludes the choice of using the model itself (e.g., the parameters). Then, it
becomes unclear what the formal representation of a model to use under this black-box access setting.
In other words, for model valuation, precisely what is the input to the valuation function?"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8893805309734514,"To briefly summarize the comparison between data and model valuation: In light of the practical
obstacles of applying data valuation, we explore the alternative of model valuation. We adopt a
similar design approach to those adopted by existing data valuation works to explicitly design a
model valuation function that reflects the utility of the ML model/data in terms of a performance in
the ML context. To address the additional challenges due to the black-box access setting (which is
not encountered in data valuation), we propose a novel formal representation of an ML model (for
classification)."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8915929203539823,"13Although there is some preliminary work on using some noisy version of data for valuation [77], so it is not
completely white-box, in general there is some form of access to the data or its statistic for valuation."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8938053097345132,"B.2
Model Evaluation Criteria and Model Valuation"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8960176991150443,"Model evaluation criteria. The value of an ML model depends on its utility/performance in the ML
context. But the performance is a multi-faceted concept because there are different evaluation criteria,
motivated by and suitable in different scenarios. For instance, one of the most commonly used
evaluation criteria is the predictive accuracy (i.e., the proportion of correct predictions of the model).
Another useful criterion is the predictive certainty (i.e., the certainty with which the model makes
the predictions), as illustrated in Sec. 1. Furthermore, there are other sophisticated and practically
important evaluation criteria such as fairness in prediction [56], robustness to adversaries [43] and
robustness to distributional shifts in data [67]. In this regard, one approach is to design a model
valuation bespoke to each of these criteria separately. However, it is more scalable and appealing
to leverage a common theoretical connection among these criteria to design a more general model
valuation that can be specified to different criteria as needed."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.8982300884955752,"Model valuation. The work of [66] investigates the binary classification setting and is not suitable for
empirical comparison as we consider problems with multiple classes. The works of [10, 11, 13, 51]
approach the design of a model marketplace from an economics perspective by addressing issues
like arbitrage (e.g., via horizontal/vertical pricing). In contrast, we formalize the value of a model
via what it has learned w.r.t. a task. In addition, the black-box access setting is appealing in a model
marketplace as it accommodates different model types. Some existing methods [8, 30, 33] focus on
how to learn a fused model from several trained models with black-box access instead of how to
value these models."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9004424778761062,"C
Additional Experiments"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9026548672566371,"C.1
Additional Experiment Settings"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9048672566371682,"Licenses of used datasets and computational resources.
MNIST [45]: Creative Commons
Attribution-Share Alike 3.0. CIFAR-10 [41]: The MIT License (MIT). MedNIST [58]: Apache
License 2.0. DrugRe [23]: Apache License 2.0 KDD99 [28]: Apache License 2.0."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9070796460176991,"We perform our experiments on a server with Intel(R) Xeon(R) Gold 6226R CPU @2.90GHz and
four NVIDIA GeForce RTX 3080’s. As in our experiments, we use the pre-trained weights for the
models (where available) instead of training from scratch. This is because our method is w.r.t. trained
models, instead of focusing on the training procedure. As a result, the usage of GPUs is moderate
(mainly for performing inference on the trained models, typically within 1 −2 hours depending on
the complexity of the models)."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9092920353982301,"Multiple independent training for robustness of results. We train a particular setting multiple (i.e.,
3) independent times and compare the results from different settings to ensure the robustness of results.
For instance, Fig. 7 examines the effect of training data ratio on MSVs. For each particular training
data ratio, we perform 3 independent training using the same model type and set of hyperparameters
so that the plotted results are robust to randomness in the training (via stochastic gradient descent)."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.911504424778761,"C.2
Additional Discussion and Experiment Details for Learning MSV"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9137168141592921,"Learning approach.
Conventionally, the model Shapley value (MSV) of each model Mi is
calculated (for sufficiently small N) or approximated (for larger N, e.g., larger than 30). The
computational complexity of exact calculation scales exponentially in the number of models (i.e.,
O(2N)), and that of approximation scales polynomial in N [53], depending on the approximation
requirement (i.e., a better approximation with smaller error would incur a higher computational cost).
Furthermore, each of these computational complexities has to be multiplied by the number N of
models, since the calculation or approximation is performed for each model individually. Our learning
approach aims to reduce the number of models for which calculation or approximation is performed,
following the steps (i) perform calculation or approximation (e.g., Monte Carlo) for a subset (of size
Z) of all N models individually; (ii) use the obtained Z model-MSV (or model-approximate MSV)
pairs to fit a regression learner (e.g., Gaussian process regression); (iii) use the regression learner to
predict the MSV for the remaining (N −Z) models."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.915929203539823,"We highlight that this approach does not aim to reduce the computational complexity of the MSV of
a model. Instead, this approach aims to reduce the total computational complexity of obtaining the"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.918141592920354,"MSVs of N models, by a factor of N/Z (e.g., if Z = 30 for N = 150 models such as in Table 2, the
total computational complexity is reduced to 1/5th). Importantly, our learning approach is parallel
to the prior and existing efforts that aim to reduce the computational complexity of the MSV of a
model. It means that if a more efficient approximation (than the oft-used Monte Carlo) to the MSV of
a model is proposed (in the future), it can be directly integrated with our learning approach in step (i)
described above, namely replacing Monte Carlo."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9203539823008849,"Why Gaussian process regression.
There are several reasons that we adopt the Gaussian process
regression (GPR) as the specific choice for the learning approach: (i) GPR is a kernel-based method,
which can exploit a suitably defined distance function between inputs. The Hellinger distance
between two Dirichlet abstractions, or the ℓ1 distance between the observed sufficient statistics ¯hi
of two models are both such suitable distance functions between the inputs (i.e., models). Hence,
we adopt GPR to exploit the squared exponential kernel exp(−d(i, i′)/(2σ2)) on the similarity
measure between models (where the lengthscale σ is learned). Specifically, for {αi, ˆϕi}, d(i, i′) :=
dH(Qi, Qi′), while for {¯hi, ˆϕi}, d(i, i′) := |¯hi′ −¯hi|1. (ii) While the exact MSVs satisfy (P1)-(P4),
the predicted MSVs are not guaranteed to satisfy these properties. Fortunately, if the predicted MSVs
have a bounded error to the exact MSVs, then these properties can be approximately satisfied [82]. In
particular, GPR has such an error guarantee [47]. The result [47, Theorem 3.1] requires the function
to be learnt to be Lipschitz continuous (which we derive in Theorem 1), and also the kernel to be
Lipschitz continuous, so we adopt the squared exponential kernel, which is Lipschitz continuous [47].
Moreover, note that the result [47, Theorem 3.1] is w.r.t. a continuous input space (i.e., a subset of
Rd for some d), but the error guarantee depends on the Lipschitz continuity only through the metric
between two inputs (i.e., ℓ2 norm of the input vectors). This is to say, their result can be adapted
to our setting (where the input space is not continuous, but discrete): In our formulation for Φ, the
metric between two inputs is the Hellinger distance (i.e., dH(Qi, Qi′). It is thus an appealing future
direction provide a formal guarantee based on these two theoretical results."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.922566371681416,"C.3
Additional Results for MSV vs. Predictive Accuracy/Certainty"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9247787610619469,"Varying size of training data.
We use the same model type and vary the size of training data. For
MNIST, we use a CNN, CIFAR-10, we use ResNet-18, for MedNIST we use a specific architecture
called MedNet,14 and for DrugRe we use a CNN for text. Fig. 7 shows more training data generally
lead to (better trained models, and thus) higher MSVs. Although in some cases the MSVs are negative,
it can be mitigated (if necessary) by exploiting the linearity property of MSV to linear translate all
MSVs by a positive amount. For instance, if only ranking of the models is needed, then negative
values are acceptable as long as the ordering is correct."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9269911504424779,"Figure 7: From left to right: MNIST, CIFAR-10, MedNIST and DrugRe. For CIFAR-10 and
MedNIST, D is the original test set without partitioning and for MNIST and DrugRe we partition the
original test set according to classes."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9292035398230089,"Varying model type.
We vary the model types and train them independently on the same data.
We train each model independently for 3 copies for robustness of results. For KDD99, the model
types are CNN, MLP and LR. For CIFAR-10, the model types are ResNet-18, SqueezeNet and
DenseNet-121. For MedNIST, the model types are ResNet-18, MedNet, and a tiny CNN. For DrugRe,
the model types are CNN for text and BiLSTM. Note that these are the model types used in the
empirical verification of the generalized symmetry result in Sec. 4.1."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9314159292035398,"Fig. 8 shows the following. For KDD99, MLP performs the worst (very negative MSVs) while LR
performs the best. For CIFAR-10, DenseNet-121 outperforms the rest while SqueezeNet performs"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9336283185840708,"14https://github.com/apolanco3225/Medical-MNIST-Classification/blob/master/MedNIST.
ipynb"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9358407079646017,"the worst. For MedNIST, the bespoke MedNet performs the best while the tiny CNN performs the
worst. For DrugRe, BiLSTM outperforms CNN for text."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9380530973451328,"Figure 8: From left to right: KDD99, CIFAR-10, MedNIST and DrugRe. For KDD99, MedNIST
and DrugRe D is the original test set without partitioning and for CIFAR-10 we specifically use the
misclassified input data from the original test set and perform partitioning according to classes."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9402654867256637,"Varying predictive certainty.
We use the same model type (trained on the same data) and only
vary the predictive certainty. The model type is LR for KDD, DenseNet for CIFAR-10, MedNet for
MedNIST and CNN (for text) for DrugRe."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9424778761061947,"Fig. 9 shows increasing predictive certainty (while maintaining the predictive accuracy) improves
MSVs."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9446902654867256,"Figure 9: From left to right: KDD99, CIFAR-10, MedNIST and DrugRe. For all 4 datasets D is the
original test set without partitioning."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9469026548672567,"C.4
Additional Results for Identifying Valuable Models for a Larger Learner"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9491150442477876,"We perform additional experiments on CovType [5], MNIST and CIFAR-100. For CovType, the
models used are decision trees of depths at most 3 and the larger learner is a random forest. For
MNIST (CIFAR-100) the models used are LeNet-5 [46] (Resnet-18) and the larger learner is a voting
classifier. The total number of models is 50 for CovType and CIFAR-10, and 25 for CIFAR-100."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9513274336283186,"Fig. 10 shows for all three datasets, MSVs effectively identify the valuable subset of models since
following the highest-first sequence increases the test accuracy more quickly. In particular, we
identify overfitting for CovType and MNIST since the max attained accuracy occurs before all the
models are included."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9535398230088495,"Figure 10: From left to right: CovType, MNIST, and CIFAR-100. Test accuracy vs. number of
included models."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9557522123893806,"C.5
Empirical Advantage of the Chernoff Distance over the Hellinger Distance"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9579646017699115,"Additional performance metrics of learning MSV.
While using dH produces high regression
performance of learning MSV (i.e., low test errors), we find that the performance may be somewhat
limiting when we apply other performance metrics such as coefficient of determinant (R2) and"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9601769911504425,"explained variance (exVar). In particular, we find thet dC outperforms dH on these two metrics, shown
in Table 4."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9623893805309734,"Table 4: Average (standard errors) of test performance (over 10 random trials) on 80% of data after
training on 20% of data for MNIST (top two rows) and CIFAR-10 (bottom two rows). Left (right)
two columns correspond to using dH (dC). For both metrics, higher is better (optimal is 1)."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9646017699115044,"R2
ExVar
R2
ExVar"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9668141592920354,"αi
0.29(6.72e−3)
0.201(2.90e−2)
0.93(2e−3)
0.92(3e−3)
¯hi
−4.04(0.462)
−3.66e1(1.33)
0.85(7e−3)
0.44(3e−2)"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9690265486725663,"αi
0.73(2.00e−2)
0.67(3.76e−2)
0.93(2e−2)
0.91(3e−2)
¯hi
−8.69(1.21)
−2.20e1(2.47)
0.80(1e−2)
0.76(2e−2)"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9712389380530974,"Notice in Table 4, the right two columns (dC) outperform the left two columns (dH). We hypothesize
that this can to the logarithmic dependence in dC resulting a more “linear” relationship between Qi
and ϕi. For Dirichlet distributions (i.e., Dirichlet abstractions) over a C-dimensional space (C > 1),
the product of the pdf (appears in both dC and dH) over the space may not be well-behaved, and the
integral of this product makes it more intractable (possibly due to the curse of dimensionality). The
logarithmic operation in dC can help mitigate this, resulting in the better regression performance
using GPR, in terms of exVar and R2."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9734513274336283,"C.6
Additional Benefit of A Lower Level of Dirichlet Abstraction"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9756637168141593,"Recall the example in Sec. 2 that using a lower level of Dirichlet abstraction by partitioning D
according to the classes allows us to correctly differentiate Mi from its ‘shifted’ version Mi′. In-
tuitively, partitioning D according to the classes improves the similarity measure between Mi and
Mi′ (via some distributional distance) and we hypothesize that it can also improve the general-
ized symmetry, which exploits the similarity measure between two models (e.g., via dC(Qi, Qi′)).
We verify this on MNIST and CIFAR-10 by partitioning the respective query sets D (i.e., test
set) according to C = 10 classes s.t. query set Dk is from class k and γk := |Dk|.
We
compute dC(Qi, Qi′; {Dk}k=1,...,C) := PC
k=1 γk dC(Qi,Dk, Qi′,Dk) and apply (P3) to compute
ϕi({Dk}k=1,...,C) = PC
k=1 γk ϕi(Dk), as shown in the right two plots of Fig. 6. Note that we
use the Chernoff distance (instead of the Hellinger distance) due to its numerical stability, and will
elaborate later on this point."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9778761061946902,"The setting for this experiment is as follows, we utilize the MNIST and CIFAR-10 datasets respectively.
For each dataset, we train N = 150 models with 3 different model types (50 of each). Specifically,
for MNIST, we train 50 of LR, MLP and CNN while for CIFAR-10, we train 50 of ResNet-18,
SqueezeNet and DenseNet-121. As in Sec. 4.1, we evaluate the performance via the Pearson corre-
lation coefficient between dC(Qi, Qi′; {Dk}k=1,...,C) and |ϕi({Dk}k=1,...,C) −ϕi′({Dk}k=1,...,C)|
in Table 5."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9800884955752213,"Table 5: Comparison of Pearson coefficients between using single query set D vs. partitioned query
sets {Dk} for MNIST (top two rows) and CIFAR-10 (bottom two rows)."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9823008849557522,"Pearson \N
60
90
120
150"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9845132743362832,"ϕi(D)
0.9493
0.9378
0.9146
0.9011
ϕi({Dk})
0.9440
0.9362
0.9326
0.9274"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9867256637168141,"ϕi(D)
0.9958
0.9955
0.9934
0.9898
ϕi({Dk})
0.9961
0.9949
0.9936
0.9924"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9889380530973452,"Results in Table 5 confirm our hypothesis that a lower level of Dirichlet abstraction can lead to better
observation of the symmetry result. This is because a lower level of Dirichlet abstraction provides
a more refined representation of each model (i.e., w.r.t. individual classes instead of overall). In
particular, we note the performance improvement for a larger N is important so that model Shapley
is learnable to be adopted in a large-scale marketplace."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9911504424778761,"Numerical overflow prevents the Hellinger distance from performing well. Due to the numerical
overflow issue of dH: If the argument to Γ(·) (e.g., the denominator in B(α) in Definition 1)
approaches 171.614479 in double precision floating point numbers, from [63]. Recall Definition 3
fuses models in a coalition C ⊆[N] to obtain QC = Dir(Pn
i=1 αi,1, . . . , Pn
i=1 αi,C) where |C| = n.
The summation Pn
i=1 αi,1 can lead to overflow when n (i.e., |C|) is large, which tends to happen when
N (the total number of models is large) because the calculation of MSV ϕi requires the enumeration
of C ⊆[N] \ {i} to obtain the respective QC. For instance N = 150, then the largest C ⊆[N] \ {i}
contains 149 models and if their respective parameter αi′,k for the class k is on average larger than
171.614479/149 ≈1.15, then it leads to numerical overflow for Γ(·) (and thus Hellinger distance).
Note that the Chernoff distance avoids this by combining the logarithmic operation with the Γ(·):
in implementation ln Γ(·) can be computed directly instead of first computing Γ(·) and then the
logarithmic operation."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9933628318584071,"C.7
Same Model Types Produce Distributionally Close Dirichlet Abstractions"
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.995575221238938,"We perform clustering (using dC as the distance measure instead of dH because it shows a better
visual illustration and the cluserting results) to illustrate the effects of model types on the similarity
between the resulting Dirichlet abstractions using the default test set as the query set without perform
partitioning according to classes. Specifically, for the N = 150 models trained on MNIST (50
CNNs, 50 MLPs and 50 LRs), we apply the density-based spatial clustering of applications with
noise (DBSCAN) [17], because it is suitable for data which contain clusters of similar density (in our
case, 3 clusters each of size 50). Fig. 11 shows good separation of different model types, supported by
additional quantitative indices: homogeneity (1.000), completeness (0.971) and V-measure (0.985).
Homogeneity measures the degree to which a single cluster contains only members of a single
class. Completeness measures the degree to which the all the members of a single class are correctly
classified into the same cluster. V-measure is a harmonic mean of both homogeneity and completeness.
These high values suggest the Dirichlet abstractions contain sufficient model information to clearly
distinguish between these model types. As a result, the clustering performance is quite good via the
adjusted random index (ARI) (0.990 and optimal is 1.0), which measures the correctness of the given
clustering via its match with the ground truth. We consider ARI because it is suitable for large equal-
sized clusters [64], which is this case here: 3 equal-sized clusters of size 50. This result confirms the
effectiveness of our approach to “convert” the heterogeneous models into homogeneous Dirichlet
abstractions which live in the metric space (with metric dH, though we highlight the experiments are
performed w.r.t. dC due to practical concerns). In particular, the numerical stability issue of dH [63]
prevented us from obtaining meaningful clustering results using dH. Moreover, this result motivates
our grouping paradigm used in our experiments to verify the generalized symmetry."
THE CODE FOR VERIFYING THIS PARTIAL DERIVATIVE USING AN AUTOMATIC DIFFERENTIATION PACKAGE IS INCLUDED IN THE,0.9977876106194691,"Figure 11: DBSCAN clustering of N = 150 models trained on MNIST based on the Chernoff
distance dC Definition 4."
