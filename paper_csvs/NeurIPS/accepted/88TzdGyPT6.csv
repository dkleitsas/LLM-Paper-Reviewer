Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0007836990595611285,"The problem of benign overfitting asks whether it is possible for a model to perfectly
fit noisy training data and still generalize well. We study benign overfitting in two-
layer leaky ReLU networks trained with the hinge loss on a binary classification
task. We consider input data that can be decomposed into the sum of a common
signal and a random noise component, that lie on subspaces orthogonal to one
another. We characterize conditions on the signal to noise ratio (SNR) of the model
parameters giving rise to benign versus non-benign (or harmful) overfitting: in
particular, if the SNR is high then benign overfitting occurs, conversely if the
SNR is low then harmful overfitting occurs. We attribute both benign and non-
benign overfitting to an approximate margin maximization property and show that
leaky ReLU networks trained on hinge loss with gradient descent (GD) satisfy
this property. In contrast to prior work we do not require the training data to be
nearly orthogonal. Notably, for input dimension d and training sample size n, while
results in prior work require d = Ω(n2 log n), here we require only d = Ω(n)."
INTRODUCTION,0.001567398119122257,"1
Introduction"
INTRODUCTION,0.0023510971786833857,"Intuition from learning theory suggests that fitting noise during training reduces a model’s perfor-
mance on test data. However, it has been observed in some settings that machine learning models can
interpolate noisy training data with only nominal cost to their generalization performance (Zhang
et al., 2017; Belkin et al., 2018, 2019), a phenomenon referred to as benign overfitting. Establishing
theory that can explain this phenomenon has attracted much interest in recent years and there is now
a rich body of work on this topic particularly in the context of linear models. However, the study of
benign overfitting in the context of non-linear models, in particular shallow ReLU or leaky ReLU
networks, has additional technical challenges and subsequently is less well advanced."
INTRODUCTION,0.003134796238244514,"Much of the effort in regard to theoretically characterizing benign overfitting focuses on showing,
under an appropriate scaling of the dimension of the input domain d, size of the training sample
n, number of corruptions k and number of model parameters p that a model can interpolate noisy
training data while achieving an arbitrarily small generalization error. Such characterizations of benign
overfitting position it as a high dimensional phenomenon1: indeed, the decrease in generalization
error is achieved by escaping to higher dimensions at some rate relative to the other aforementioned
hyperparameters. However, for these mathematical results to be relevant for explaining benign
overfitting as observed in practice, clearly the particular scaling of d with respect to n, k and p needs
to reflect the ratios seen in practice. Although a number of works, which we discuss in Section
1.2, establish benign overfitting results for shallow neural networks, a key and significant limitation
they share is the requirement that the input features of the training data are at least approximately"
INTRODUCTION,0.003918495297805642,1We provide a formal definition of benign overfitting as a high dimensional phenomenon in Appendix E.
INTRODUCTION,0.004702194357366771,"orthogonal to one another. To study benign overfitting, these prior works typically assume the input
features consist of a small, low-rank signal component plus an isotropic noise term. Therefore, for
the near orthogonality property to hold with high probability it is required that the input dimension d
scales as d = Ω(n2 log n) or higher. This assumption highly restricts the applicability of these results
for explaining benign overfitting in practice."
INTRODUCTION,0.0054858934169279,"In this work we assume only d = Ω(n) and establish both harmful and benign overfitting results for
shallow leaky ReLU networks trained via gradient descent (GD) on the hinge loss. In particular, we
consider n data point pairs (xi, yi) ∈Rd × {±1}, where, for some vector v ∈Sd−1 and scalar γ ∈
[0, 1], the input features are drawn from a pair of Gaussian clusters xi ∼N(±√γv, √1 −γ 1"
INTRODUCTION,0.006269592476489028,"d(Id −
vvT )) and yi = sign(⟨E[xi], v⟩). The training data is noisy in that k of the n points in the training
sample have their output label flipped. We assume equal numbers of positive and negative points
among clean and corrupt ones. We provide a full description of our setup and assumptions in Section
2. Our proof techniques are novel and identify a new condition allowing for the analysis of benign
and harmful overfitting which we term approximate margin maximization, wherein the norm of the
network parameters is upper bounded by a constant of the norm of the max-margin linear classifier."
SUMMARY OF CONTRIBUTIONS,0.007053291536050157,"1.1
Summary of contributions"
SUMMARY OF CONTRIBUTIONS,0.007836990595611285,Our key results are summarized as follows.
SUMMARY OF CONTRIBUTIONS,0.008620689655172414,"• In Theorem 3.1, we prove that a leaky ReLU network trained on linearly separable data with
gradient descent and the hinge loss will attain zero training loss in finitely many iterations.
Moreover, the network weight matrix W at convergence will be approximately max-margin
in the sense that ∥W ∥= O

∥w∗∥
α√m

, where α is the leaky parameter of the activation
function, m is the width of the network, and w∗is the max-margin linear classifier. We
apply this result to derive generalization bounds for the network on test data."
SUMMARY OF CONTRIBUTIONS,0.009404388714733543,"• In Theorem 3.2, we establish conditions under which benign overfitting occurs for leaky
ReLU networks. If the input dimension d, number of training points n, number of corrupt
points k, and signal strength γ satisfy d = Ω(n) and γ = Ω( 1"
SUMMARY OF CONTRIBUTIONS,0.01018808777429467,"k), then the network will
exhibit benign overfitting. We emphasize that existing works on benign overfitting require
d = Ω(n2 log n) to ensure nearly orthogonal data."
SUMMARY OF CONTRIBUTIONS,0.0109717868338558,"• In Theorem 3.3, we find a complementary lower bound for the generalization error to show
that, for gradient descent classifiers, the bound in Theorem 3.2 is tight up to a constant in
the exponent that can depend on α."
SUMMARY OF CONTRIBUTIONS,0.011755485893416929,"• In Theorem 3.4, we find conditions under which non-benign overfitting occurs. If d = Ω(n)
and γ = O( 1"
SUMMARY OF CONTRIBUTIONS,0.012539184952978056,"d), then the network will exhibit non-benign overfitting: in particular its
generalization error will be at least 1 8."
RELATED WORK,0.013322884012539185,"1.2
Related work"
RELATED WORK,0.014106583072100314,"There is now a significant body of literature theoretically characterizing benign overfitting in the
context of linear models, including linear regression (Bartlett et al., 2020; Muthukumar et al., 2020;
Wu & Xu, 2020; Zou et al., 2021; Hastie et al., 2022; Koehler et al., 2021; Wang et al., 2021a;
Chatterji & Long, 2022; Shamir, 2022), logistic regression (Chatterji & Long, 2021; Muthukumar
et al., 2021; Wang et al., 2021b), max-margin classification with linear and random feature models
(Montanari et al., 2023b,a; Mei & Montanari, 2022; Cao et al., 2021) and kernel regression (Liang
& Rakhlin, 2020; Liang et al., 2020; Adlam & Pennington, 2020). However, the study of benign
overfitting in non-linear models is more nascent."
RELATED WORK,0.014890282131661442,"Homogeneous networks trained with gradient descent and an exponentially tailed loss are known to
converge in direction to a Karush-Kuhn-Tucker (KKT) point of the associated max-margin problem
(Lyu & Li, 2020; Ji & Telgarsky, 2020)2. This property has been widely used in prior works to
prove benign overfitting results for shallow neural networks. Frei et al. (2022) consider a shallow,
smooth leaky ReLU network trained with an exponentially tailed loss and assume the data is drawn
from a mixture of well-separated sub-Gaussian distributions. A key result of this work is, given"
RELATED WORK,0.01567398119122257,2One also needs to assume initialization from a position with a low initial loss.
RELATED WORK,0.016457680250783698,"sufficient iterations of GD, that the network will interpolate noisy training data while also achieving
minimax optimal generalization error up to constants in the exponents. Xu & Gu (2023) extend
this result to more general activation functions, including ReLU, as well as relax the assumptions
on the noise distribution to being centered with bounded logarithmic Sobolev constant, and finally
also improve the convergence rate. George et al. (2023) also study ReLU as opposed to leaky ReLU
networks but do so in the context of the hinge loss, for which, and unlike exponentially tailed losses,
a characterization of the implicit bias is not known. This work also establishes transitions on the
margin of the clean data driving harmful, benign and no-overfitting training outcomes. Frei et al.
(2023) use the aforementioned implicit bias of GD for linear classifiers and shallow leaky ReLU
networks towards solutions that satisfy the KKT conditions of the margin maximization problem to
establish settings where the satisfaction of said KKT conditions implies benign overfitting. Kornowski
et al. (2023) also use the implicit bias results for exponentially tailed losses to derive similar benign
overfitting results for shallow ReLU networks. Cao et al. (2022); Kou et al. (2023) study benign
overfitting in two-layer convolutional as opposed to feedforward neural networks: indeed, whereas in
most prior works data is modeled as the sum of a signal and noise component, in these two works the
signal and noise components are assumed to lie in disjoint patches. The weight vector of each neuron
is applied to both patches separately and a non-linearity, such as ReLU, is applied to the resulting
pre-activation. In this setting, the authors prove interpolation of the noisy training data and derive
conditions on the clean margin under which the network benignly versus harmfully overfits. A follow
up work (Chen et al., 2023) considers the impact of Sharpness Aware Minimization (SAM) in the
same setting. Finally, and assuming d = Ω(n5), Xu et al. (2024) establish benign overfitting results
for a data distribution which, instead of being linearly separable, is separated according to an XOR
function."
RELATED WORK,0.017241379310344827,"We emphasize that the prior work on benign overfitting in the context of shallow neural networks
requires the input data to be approximately orthogonal. Under standard data models studied this
equates to the requirement that the input dimension d versus the size of the training sample n satisfies
d = Ω(n2 log n) or higher. Here we require only d = Ω(n). The weaker dimensionality requirement
requires substantially different proof techniques. George et al. (2023) study a setting most similar to
the one studied here, however, the techniques are very different. In particular, the results presented in
this other work are derived by carefully tracking neuron activation patterns. While in high dimensions
this is feasible due to the near orthogonality of the noise in low dimensions this is far more challenging
as noise vectors can be highly correlated leading to coupling effects."
RELATED WORK,0.018025078369905956,"Finally, we remark that our proof technique for the convergence of GD to a global minimizer in the
context of a shallow leaky ReLU network (Theorem 3.1) is closely related to the proof techniques
used by Brutzkus et al. (2018). While this work does establish a generalization bound, the bound
assumes that population dataset is linearly separable rather than just the training dataset. Hence, it
cannot be applied when the training dataset has label-flipping noise, which is the setting that we are
interested in for benign overfitting."
PRELIMINARIES,0.018808777429467086,"2
Preliminaries"
PRELIMINARIES,0.019592476489028215,"Let [n] = {1, 2, . . . , n} denote the set of the first n natural numbers. We remark that when using
big-O notation we implicitly assume only positive constants. We use c, C, C1, C2, . . . to denote
absolute constants with respect to the input dimension d, the training sample size n, and the width
of the network m. Note constants may change in value from line to line. Furthermore, when using
big-O notation all variables aside from d, n, k and m are considered constants. However, for clarity
we will frequently make the constants concerning the confidence δ and failure probability ϵ explicit.
Moreover, for two functions f, g : N →N, if we say f = O(g) implies property p, what we mean is
there exists an N ∈N and a constant C such that if f(n) ≤Cg(n) for all n ≥N then property p
holds. Likewise, if we say f = Ω(g) implies property p, what we mean is there exists an N ∈N and
a constant C such that if f(n) ≥Cg(n) for all n ≥N then property p holds. Finally, we use ∥· ∥to
denote the ℓ2 norm of the vector argument or ℓ2 →ℓ2 operator norm of the matrix argument."
DATA MODEL,0.02037617554858934,"2.1
Data model"
DATA MODEL,0.02115987460815047,We study data generated as per the following data model.
DATA MODEL,0.0219435736677116,"Definition 2.1. Suppose d, n, k ∈N, γ ∈(0, 1) and v ∈Sd−1. If (X, ˆy, y, x, y) ∼D(d, n, k, γ, v)
then"
DATA MODEL,0.022727272727272728,"1. X ∈Rn×d is a random matrix whose rows, which we denote xi, satisfy xi = √γyiv +
√1 −γni, where ni ∼N(0d, 1"
DATA MODEL,0.023510971786833857,d(Id −vvT )) are mutually i.i.d..
DATA MODEL,0.024294670846394983,"2. y ∈{±1}n is a random vector with entries yi that are mutually independent of one another
as well as the noise vectors (ni)i∈[n] and are uniformly distributed over {±1}. This vector
holds the true labels of the training set."
DATA MODEL,0.025078369905956112,"3. Let B ⊂[n] be any subset chosen independently of y such that |B| = k. Then ˆy ∈{±1}n is
a random vector whose entries satisfy ˆyi ̸= yi for all i ∈B and ˆyi = yi for all i ∈Bc =: G.
This vector holds the observed labels of the training set."
DATA MODEL,0.02586206896551724,4. y is a random variable representing a test label which is uniformly distributed over {±1}.
DATA MODEL,0.02664576802507837,"5. x ∈Rd is a random vector representing the input feature of a test point and satisfies
x = √γyv + √1 −γn, where n ∼N(0d, 1"
DATA MODEL,0.0274294670846395,"d(Id −vvT )) is mutually independent of the
random vectors (ni)i∈[n]."
DATA MODEL,0.02821316614420063,"We refer to (X, ˆy) as the training data and (x, y) as the test data. Furthermore, for typographical
convenience we define y ⊙ˆy =: β ∈{±1}n."
DATA MODEL,0.028996865203761754,"To provide some interpretation to Definition 2.1, the training data consists of n points of which
k have their observed label flipped relative to the true label. We refer to v and ni as the signal
and noise components of the i-th data point respectively: indeed, with γ > 0 then for i ∈G
yi⟨xi, v⟩= √γ > 0. The test data is drawn from the same distribution and is assumed not to be
corrupted. We say that the training data (X, ˆy) is linearly separable if there exists w ∈Rd such that"
DATA MODEL,0.029780564263322883,"ˆyi⟨w, xi⟩≥1,
for all i ∈[n]."
DATA MODEL,0.030564263322884012,"For finite n, this condition is equivalent to the existence of a w with ˆyi⟨w, xi⟩> 0 for all i ∈[n].
We denote the set of linearly separable datasets as Xlin ⊂Rn×d × {±1}n. For a linearly separable
dataset (X, ˆy), the max-margin linear classifier is the unique solution to the optimization problem"
DATA MODEL,0.03134796238244514,"arg min
w∈Rd ∥w∥such that ˆyi⟨w, xi⟩≥1 for all i ∈[n]."
DATA MODEL,0.03213166144200627,"Observe one may equivalently take a strictly convex objective ∥w∥2 and the constraint set is a
closed convex polyhedron that is non-empty iff the data is linearly separable. The max-margin linear
classifier w∗has a corresponding geometric margin 2/∥w∗∥. When d ≥n and γ > 0, input feature
matrices X from our data model almost surely have linearly independent rows xi and thus (X, ˆy) is
almost surely linearly separable for any observed labels ˆy ∈{±1}n."
ARCHITECTURE AND LEARNING ALGORITHM,0.032915360501567396,"2.2
Architecture and learning algorithm"
ARCHITECTURE AND LEARNING ALGORITHM,0.03369905956112853,"We study shallow leaky ReLU networks with a forward pass function f : R2m×d × Rd →R defined
as"
ARCHITECTURE AND LEARNING ALGORITHM,0.034482758620689655,"f(W , x) ="
"M
X",0.03526645768025078,"2m
X"
"M
X",0.03605015673981191,"j=1
(−1)jσ(⟨wj, x⟩),
(1)"
"M
X",0.03683385579937304,"where W ∈R2m×d are the parameters of the network, σ : R →R is the leaky ReLU function,
defined as σ(x) = max(x, αx), where α ∈(0, 1] is referred to as the leaky parameter. We remark
that we only train the weights of the first layer and keep the output weights of each neuron fixed.
Although σ is not differentiable at 0, in the context of gradient descent we adopt a subgradient and let
˙σ(z) = 1 for z ≥0 and let ˙σ(z) = α otherwise. The hinge loss ℓ: R →R≥0 is defined as"
"M
X",0.03761755485893417,"ℓ(z) = max{0, 1 −z}.
(2)"
"M
X",0.0384012539184953,"Again, ℓis not differentiable at zero; adopting a subgradient we define for any j ∈[2m]"
"M
X",0.03918495297805643,"∇wjℓ(ˆyf(W , x)) =
(−1)j+1ˆyx ˙σ(⟨wj, x⟩)
ˆyf(W , x) < 1,
0
ˆyf(W , x) ≥1."
"M
X",0.039968652037617555,The training loss L : R2m×d × Rn×d × Rn →R is defined as
"M
X",0.04075235109717868,"L(W , X, ˆy) = n
X"
"M
X",0.041536050156739814,"i=1
ℓ(ˆyif(W , xi)).
(3)"
"M
X",0.04231974921630094,"Let W (0) ∈R2m×d denote the model parameters at initialization. For each t ∈N we define W (t)
recursively as
W (t) = W (t−1) −η∇W L(W (t−1), X, ˆy),
where η > 0 is the step size. Let F(t) ⊆[n] denote the set of all i ∈[n] such that ˆyif(W (t), xi) < 1.
Then equivalently each neuron is updated according to the following rule: for j ∈[2m]"
"M
X",0.04310344827586207,"w(t)
j
= GD(W (t−1), η) := w(t−1)
j
+ η(−1)j
X"
"M
X",0.0438871473354232,"i∈F(t−1)
ˆyixi ˙σ(⟨w(t−1)
j
, xi⟩).
(4)"
"M
X",0.04467084639498432,"For ease of reference we now provide the following definition of the learning algorithm described
above.
Definition 2.2. Let AGD : Rn×d ×{±1}n ×R×R2m×d →R2m×d return AGD(X, ˆy, η, W (0)) =:
W , where the j-th row wj of W is defined as follows: let w(0)
j
be the j-th row of W (0) and"
"M
X",0.045454545454545456,"generate the sequence (w(t)
j )t≥0 using the recurrence relation w(t)
j
= GD(W (t−1), η) as defined in
equation 4."
"M
X",0.04623824451410658,"1. If for j ∈[2m], limt→∞w(t)
j
does not exist then we say AGD is undefined."
"M
X",0.047021943573667714,"2. Otherwise we say AGD converges and wj = limt→∞w(t)
j ."
"M
X",0.04780564263322884,"3. If there exists a T ∈N such that for all j ∈[2m] w(t)
j
= w(T )
j
for all t ≥T, then we say
AGD converges in finite time."
"M
X",0.048589341692789965,We often find that all matrices in the set
"M
X",0.0493730407523511,"{AGD(X, ˆy, η, W (0)) : ∀j ∥w(0)
j ∥≤λ}"
"M
X",0.050156739811912224,"agree on all relevant properties. In this case, we abuse notation and say that AGD(X, ˆy, η, λ) = W
where W is a generic element from this set."
"M
X",0.050940438871473356,"Finally, in order to derive our results we make the following assumptions concerning the step size
and initialization of the network.
Assumption 1. The step size η satisfies η ≤1/(mn maxi∈[n] ∥xi∥2) and for all j ∈[2m] the"
"M
X",0.05172413793103448,"network at initialization satisfies ∥w(0)
j ∥≤√α/(m mini∈[n] ∥xi∥)."
"M
X",0.052507836990595615,"Under our data model the input data points have approximately unit norm; therefore these assumptions
reduce to η ≤
C
mn and ∥w(0)
j ∥≤C√α m ."
APPROXIMATE MARGIN MAXIMIZATION,0.05329153605015674,"2.3
Approximate margin maximization"
APPROXIMATE MARGIN MAXIMIZATION,0.054075235109717866,"We now introduce the notion of an approximate margin maximizing algorithm, which plays a key
role in deriving our results. Although the primary setting we consider in this work is the learning
algorithm AGD (see Definition 2.2), we derive benign overfitting guarantees more broadly for any
learning algorithm which fits into this category. Recall Xlin denotes the set of linearly separable
datasets (X, ˆy) ∈Rn×d × {±1}n.
Definition 2.3. Let f : Rp × Rd →R denote a predictor function with p parameters. An algorithm
A : Rn×d × Rn →Rp is approximately margin maximizing with factor M > 0 on f if for all
(X, ˆy) ∈Xlin
ˆyif(A(X, ˆy), xi) ≥1 for all i ∈[n]
(5)
and
∥A(X, ˆy)∥≤M∥w∗∥,
(6)
where w∗is the max-margin linear classifier of (X, ˆy). Moreover, if A is an approximate margin
maximizing algorithm we define"
APPROXIMATE MARGIN MAXIMIZATION,0.054858934169279,"|A| = inf{M > 0 : A is approximately margin maximizing with factor M}.
(7)"
APPROXIMATE MARGIN MAXIMIZATION,0.055642633228840124,"In the above definition we take the standard Euclidean norm on Rp. In particular if Rp = R2m×d is a
space of matrices we take the Frobenius norm."
MAIN RESULTS,0.05642633228840126,"3
Main results"
MAIN RESULTS,0.05721003134796238,"In order to prove benign overfitting it is necessary to show that the learning algorithm outputs a model
that correctly classifies all points in the training sample. The following theorem establishes this for
AGD and bounds the margin maximizing factor |AGD|.
Theorem 3.1. Let f : Rp × Rn →R be a leaky ReLU network with forward pass as defined by
equation 1. Suppose the step size η and initialization condition λ satisfy Assumption 1. Then for any
linearly separable data set (X, ˆy) AGD(X, ˆy, η, λ) converges after T iterations, where"
MAIN RESULTS,0.05799373040752351,T ≤C∥w∗∥2
MAIN RESULTS,0.05877742946708464,ηα2m .
MAIN RESULTS,0.05956112852664577,Furthermore AGD is approximately margin maximizing on f (Definition 2.3) with
MAIN RESULTS,0.0603448275862069,"|AGD| ≤
C
α√m."
MAIN RESULTS,0.061128526645768025,"A proof of Theorem 3.1 can be found in Appendix D.1. Note also by Definition 2.3 that the solution
W = AGD(X, ˆy) for (X, ˆy) ∈Xlin is a global minimizer of the training loss defined in equation 3
with L(W , X, ˆy) = 0. Our approach to proving this result is reminiscent of the proof of convergence
of the perceptron algorithm and therefore is also similar to the techniques used by Brutzkus et al.
(2018)."
MAIN RESULTS,0.06191222570532915,"For training and test data as per Definition 2.1 we provide an upper bound on the generalization error
for approximately margin maximizing algorithms. For convenience we summarize our setting as
follows.
Assumption 2. Setting for proving generalization results."
MAIN RESULTS,0.06269592476489028,• f : R2m×d × Rd →R is a shallow leaky ReLU network as per equation 1.
MAIN RESULTS,0.06347962382445141,"• A : Rn×d×{±1}n →R2m×d is a learning algorithm that returns the weights W ∈R2m×d
of the first layer of f."
MAIN RESULTS,0.06426332288401254,"• We let v ∈Sd−1 and consider training data (X, ˆy) and test data (x, y) distributed accord-
ing to (X, ˆy, y, x, y) ∼D(d, n, k, γ, v) as per Definition 2.1."
MAIN RESULTS,0.06504702194357367,"Under this setting we have the following generalization result for an approximately margin maximiz-
ing algorithm A. Note this result requires γ, and hence the signal to noise ratio of the inputs, to be
sufficiently large.
Theorem 3.2. Under the setting given in Assumption 2, let δ ∈(0, 1) and suppose A is approximately
margin-maximizing (Definition 2.3). If n = Ω
 
log 1"
MAIN RESULTS,0.06583072100313479,"δ

, d = Ω(n), k = O(
n
1+m|A|2 ), and γ = Ω
  1 k
"
MAIN RESULTS,0.06661442006269593,"then there is a fixed positive constant C such that with probability at least 1 −δ over (X, ˆy)"
MAIN RESULTS,0.06739811912225706,"P(yf(W , x) ≤0 | X, ˆy) ≤exp

−C ·
d
k(1 + m|A|2) 
."
MAIN RESULTS,0.06818181818181818,"A proof of Theorem 3.2 is provided in Appendix D.2. To comment informally on the relationship
between k and γ, we require γ = Ω(k−1) in order to guarantee that any network which achieves
zero hinge loss does so by focusing on the signal component v rather than the noise components ni.
We use the projection of the model weights onto the signal subspace as a measure of the strength
of the signal the model has learned and derive our generalization results based on this measure. In
Section 4 we provide a proof sketch of this framework in the simpler, linear model setting. Combining
Theorems 3.1, and 3.2 we arrive at the following benign overfitting result for shallow leaky ReLU
networks trained with GD on hinge loss.
Corollary 3.2.1. Under the setting given in Assumption 2, let δ ∈(0, 1) and suppose A = AGD
where η, λ ∈R>0 satisfy Assumption 1. If n = Ω
 
log 1"
MAIN RESULTS,0.06896551724137931,"δ

, d = Ω(n), k = O(α2n), and γ = Ω
  1 k
"
MAIN RESULTS,0.06974921630094044,then the following hold.
MAIN RESULTS,0.07053291536050156,"1. The algorithm AGD terminates almost surely after a finite number of updates. If W =
AGD(X, ˆy), then L(W , X, ˆy) = 0."
MAIN RESULTS,0.0713166144200627,"2. There is a fixed positive constant C such that, with probability at least 1−δ over the training
data (X, ˆy),"
MAIN RESULTS,0.07210031347962383,"P(yf(W , x) ≤0 | X, ˆy) ≤exp

−C · α2d k 
."
MAIN RESULTS,0.07288401253918496,"We remark that the upper bound is at most exp (−Cd/n) for a different constant C as we assume
k = O(α2n)."
MAIN RESULTS,0.07366771159874608,"If k is large enough, this bound is tight up to constants and factors of α in the exponent. This is given
by the following theorem, proven in Appendix D.2.
Theorem 3.3. Under the setting given in Assumption 2, let δ ∈(0, 1) and suppose A = AGD where
η, λ ∈R>0 satisfy Assumption 1. If n = Ω(k), d = Ω(n), and k = Ω(log 1 δ + 1"
MAIN RESULTS,0.07445141065830721,"α), then there is a
fixed positive constant C such that with probability at least 1 −δ over (X, ˆy)"
MAIN RESULTS,0.07523510971786834,"P(yf(W , x) ≤0 | X, ˆy) ≥exp

−C · d αk 
."
MAIN RESULTS,0.07601880877742946,"In addition to this benign overfitting result we also provide the following non-benign overfitting result
for AGD. Note that conversely this result requires γ, and hence the signal to noise ratio of the inputs,
to be sufficiently small.
Theorem 3.4. Under the setting given in Assumption 2, let δ ∈(0, 1) and suppose A = AGD,
where η, λ ∈R>0 satisfy Assumption 1. If n = Ω(1), d = Ω
 
n + log 1"
MAIN RESULTS,0.0768025078369906,"δ

and γ = O

α3"
MAIN RESULTS,0.07758620689655173,"d

then the
following hold."
MAIN RESULTS,0.07836990595611286,"1. The algorithm AGD terminates almost surely after finitely many updates. With W =
AGD(X, ˆy), L(W , X, ˆy) = 0."
MAIN RESULTS,0.07915360501567398,"2. With probability at least 1 −δ over the training data (X, ˆy)"
MAIN RESULTS,0.07993730407523511,"P(yf(W , x) < 0 | X, ˆy) ≥1 8."
MAIN RESULTS,0.08072100313479624,A proof of Theorem 3.4 is provided in Appendix D.3.
MAIN RESULTS,0.08150470219435736,"4
Approximate margin maximization and generalization: insight from linear
models"
MAIN RESULTS,0.0822884012539185,"In this section we outline proofs for the analogues of Theorems 3.2 and 3.4 in the context of linear
models. The arguments are thematically similar and clearer to present. We provide complete proofs
of benign and non-benign overfitting for linear models in Appendix C."
MAIN RESULTS,0.08307210031347963,"An important lemma is the following, which bounds the largest and n-th largest singular values (σ1
and σn respectively) of the noise matrix N:
Lemma 4.1. Let N ∈Rn×d denote a random matrix whose rows are drawn mutually i.i.d. from
N(0d, 1"
MAIN RESULTS,0.08385579937304075,"d(Id −vvT )). If d = Ω
 
n + log 1"
MAIN RESULTS,0.08463949843260188,"δ

, then there exists constants C1 and C2 such that, with
probability at least 1 −δ,
C1 ≤σn(N) ≤σ1(N) ≤C2."
MAIN RESULTS,0.08542319749216301,"We prove this lemma in Appendix B using results from Vershynin (2018) and Rudelson & Vershynin
(2009). A consequence of this lemma is that with probability at least 1 −δ, the condition number of
N restricted to span N can be bounded above independently of all hyperparameters. For this reason,
we refer to the noise as being well-conditioned."
MAIN RESULTS,0.08620689655172414,"Now let w = A(X, ˆy) be the linear classifier returned by the algorithm. Observe that we can
decompose the weight vector into a signal and noise component"
MAIN RESULTS,0.08699059561128526,"w = avv + z,"
MAIN RESULTS,0.0877742946708464,where z ⊥v and av ∈R. Based on this decomposition the proof proceeds as follows.
MAIN RESULTS,0.08855799373040753,"1. Generalization bounds based on the SNR:
For test data as per the data model given in
Definition 2.1 we want to bound the probability of misclassification: in particular, we want to bound
the probability that
X := y⟨w, x⟩= √γav +
p"
MAIN RESULTS,0.08934169278996865,"1 −γ⟨n, z⟩≤0."
MAIN RESULTS,0.09012539184952978,"As the noise is normally distributed, X ∼N
 √γav, 1−γ"
MAIN RESULTS,0.09090909090909091,"d ∥z∥2
and the desired upper bound
therefore follows from Hoeffding’s inequality,"
MAIN RESULTS,0.09169278996865204,"P(X ≤0) ≤exp

−
γda2
v
2(1 −γ)∥z∥2 
."
MAIN RESULTS,0.09247648902821316,"Using Gaussian anti-concentration, we also obtain a lower bound for the probability of misclassifica-
tion:"
MAIN RESULTS,0.0932601880877743,"P(y⟨w, x⟩≤0) ≥max"
MAIN RESULTS,0.09404388714733543,"(
1
2 − s"
MAIN RESULTS,0.09482758620689655,"dγ
2π(1 −γ)
av
∥z∥, 1"
EXP,0.09561128526645768,"4 exp

−6d"
EXP,0.09639498432601881,"π
γ
1 −γ
a2
v
∥z∥2 ) ."
EXP,0.09717868338557993,"2. Upper bound the norm of the max-margin classifier:
In order to use the approximate max-
margin property we require an upper bound on ∥w∗∥. As by definition ∥w∗∥≤∥˜w∥, it suffices to
construct a vector ˜w that interpolates the data and has small norm. Using that the noise matrix of the
data is well-conditioned with high probability, we achieve this by strategically constructing the signal
and noise components of ˜w. This yields the bound"
EXP,0.09796238244514106,∥w∗∥≤∥˜w∥≤C min
EXP,0.0987460815047022,"r
n
1 −γ , s"
EXP,0.09952978056426333,"1
γ +
k
1 −γ ! ,"
EXP,0.10031347962382445,where the arguments of the min function originate from a small and large γ regime respectively.
EXP,0.10109717868338558,"3. Lower bound the SNR using the approximate margin maximization property:
Based on step
1 the key quantity of interest from a generalization perspective is the ratio av/∥z∥, which describes
the signal to noise ratio (SNR) of the learned classifier. To lower bound this quantity we first lower
bound av. In particular, if av is small, then the only way to attain zero loss on the clean data is
for ∥z∥to be large. However, under appropriate assumptions on d, n, k and γ this can be shown to
contradict the bound ∥z∥≤∥w∥≤|A|∥w∗∥, and thus av must be bounded from below. A lower
bound on av/∥z∥then follows by again using ∥z∥≤∥w∗∥. Hence we obtain a lower bound for the
SNR and establish benign overfitting."
EXP,0.10188087774294671,"4. Upper bound the SNR using the zero loss condition:
For the generalization lower bound, we
compute an upper bound for the ratio av/∥z∥rather than a lower bound. Since the model perfectly
fits the training data with margin one,"
EXP,0.10266457680250783,"1 ≤ˆyi⟨w, xi⟩= √γβiav +
p"
EXP,0.10344827586206896,"1 −γˆyi⟨z, ni⟩"
EXP,0.1042319749216301,"for all i ∈[n]. The above inequality implies that √1 −γˆyi⟨ni, z⟩is at least √γav for all corrupt
points. Since the noise is well-conditioned, this gives a lower bound on ∥z∥in terms of av and
hence an upper bound on the SNR av/∥z∥. By the second generalization lower bound in step 1, the
generalization error is bounded below at a similar exponential rate to the upper bound."
EXP,0.10501567398119123,"5. Upper bound the SNR using the zero loss condition and maximum margin property:
To
prove non-benign overfitting, we again compute an upper bound for the ratio av/∥z∥. We return to
the zero loss condition:"
EXP,0.10579937304075235,"1 ≤ˆyi⟨w, xi⟩= √γβiav +
p"
EXP,0.10658307210031348,"1 −γˆyi⟨z, ni⟩"
EXP,0.10736677115987461,"for all i ∈[n]. If γ is small and |√γav| is large, then ∥w∥will be large, contradicting the approximate
margin maximization. Hence the above inequality implies that √1 −γˆyi⟨ni, z⟩is large for all i ∈[n].
Since the noise is well-conditioned, this can only happen when ∥z∥is large. This gives us a lower
bound on ∥z∥. As before, we can also upper bound av by ∥w∥, giving us an upper bound on the
SNR av/∥z∥. By the first generalization lower bound in step 1, the classifier generalizes poorly and
exhibits non-benign overfitting."
FROM LINEAR MODELS TO LEAKY RELU NETWORKS,0.10815047021943573,"4.1
From linear models to leaky ReLU networks"
FROM LINEAR MODELS TO LEAKY RELU NETWORKS,0.10893416927899686,"The proof of benign and non-benign overfitting in the linear case uses the tension between the two
properties of approximate margin maximization: fitting both the clean and corrupt points with margin
versus the bound on the norm. To extend this idea to a shallow leaky ReLU network as per equation 1,
we consider the same decomposition for each neuron j ∈[2m],"
FROM LINEAR MODELS TO LEAKY RELU NETWORKS,0.109717868338558,"wj = ajv + zj,"
FROM LINEAR MODELS TO LEAKY RELU NETWORKS,0.11050156739811912,"where aj ∈R and zj ⊥v. In the linear case ±av can be interpreted as the activation of the linear
classifier on ±v respectively: in terms of magnitude the signal activation is the same in either case
and thus we measure the alignment of the linear model with the signal using |av|. For leaky ReLU
networks we define their activation on ±v respectively as A1 = f(W , v) and A−1 = −f(W , −v),
and then define the alignment of the network as Amin = min{A1, A−1}. Considering the alignment
of the network with the noise, then if Z ∈R2m×d denotes a matrix whose j-th row is zj, then
we measure the alignment of the network using ∥Z∥F . As a result, analogous to av/∥z∥, the key
ratio from a generalization perspective in the context of a leaky ReLU network is Amin/∥Z∥F . The
proof Theorems 3.2, 3.3, and 3.4 then follow the same outline as Steps 1-3 above but with additional
non-trivial technicalities."
CONCLUSION,0.11128526645768025,"5
Conclusion"
CONCLUSION,0.11206896551724138,"In this work we have proven conditions under which leaky ReLU networks trained on binary
classification tasks exhibit benign and non-benign overfitting. We have substantially relaxed the
necessary assumptions on the input data compared with prior work; instead of requiring nearly
orthogonal data with d = Ω(n2 log n) or higher, we only need d = Ω(n). We achieve this by using
the distribution of singular values of the noise rather than specific correlations between noise vectors.
Our emphasis was on networks trained by gradient descent with the hinge loss, but we establish a
new framework that is general enough to accommodate any algorithm that is approximately margin
maximizing."
CONCLUSION,0.11285266457680251,"There are a few limitations of our results which would be natural questions to address in future
work. While we improve upon existing results in our dependence on the input dimension of the
data, we still require that the training dataset is linearly separable. This leaves open the question
of whether an overparameterized network will perfectly fit the training data and generalize well for
lower dimensional data, or satisfy a similar margin maximization condition. We also focus mainly on
two-layer networks with fixed outer layer weights trained with the hinge loss. It would be interesting
to investigate whether analogous results hold for deeper architectures or different loss functions and
data models."
CONCLUSION,0.11363636363636363,Acknowledgments
CONCLUSION,0.11442006269592477,"This material is based upon work supported by the National Science Foundation under Grant No.
DMS-1928930 and by the Alfred P. Sloan Foundation under grant G-2021-16778, while the authors
EG and DN were in residence at the Simons Laufer Mathematical Sciences Institute (formerly MSRI)
in Berkeley, California, during the Fall 2023 semester. EG and DN were also partially supported
by NSF DMS 2011140. EG was also supported by a NSF Graduate Research Fellowship under
grant DGE 2034835. GM and KK were partly supported by NSF CAREER DMS 2145630 and
DFG SPP 2298 Theoretical Foundations of Deep Learning grant 464109215. GM was also partly
supported by NSF grant CCF 2212520, ERC Starting Grant 757983 (DLT), and BMBF in DAAD
project 57616814 (SECAI)."
REFERENCES,0.1152037617554859,References
REFERENCES,0.11598746081504702,"Ben Adlam and Jeffrey Pennington. The neural tangent kernel in high dimensions: Triple descent and
a multi-scale theory of generalization. In Hal Daumé III and Aarti Singh (eds.), Proceedings of
the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine
Learning Research, pp. 74–84. PMLR, 2020. URL https://proceedings.mlr.press/v119/
adlam20a.html."
REFERENCES,0.11677115987460815,"Peter L. Bartlett, Philip M. Long, Gábor Lugosi, and Alexander Tsigler. Benign overfitting in linear
regression. Proceedings of the National Academy of Sciences, 117(48):30063–30070, 2020. URL
https://www.pnas.org/doi/abs/10.1073/pnas.1907378117."
REFERENCES,0.11755485893416928,"Mikhail Belkin, Siyuan Ma, and Soumik Mandal. To understand deep learning we need to understand
kernel learning. In Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th International
Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp.
541–549. PMLR, 2018. URL https://proceedings.mlr.press/v80/belkin18a.html."
REFERENCES,0.11833855799373041,"Mikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Mandal. Reconciling modern machine-learning
practice and the classical bias–variance trade-off. Proceedings of the National Academy of Sciences,
116(32):15849–15854, 2019. URL https://doi.org/10.1073/pnas.190307011."
REFERENCES,0.11912225705329153,"Alon Brutzkus, Amir Globerson, Eran Malach, and Shai Shalev-Shwartz.
SGD learns over-
parameterized networks that provably generalize on linearly separable data. In International
Conference on Learning Representations, 2018. URL https://openreview.net/forum?id=
rJ33wwxRb."
REFERENCES,0.11990595611285267,"Yuan Cao, Quanquan Gu, and Mikhail Belkin. Risk bounds for over-parameterized maximum margin
classification on sub-gaussian mixtures. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang,
and J. Wortman Vaughan (eds.), Advances in Neural Information Processing Systems, volume 34,
pp. 8407–8418. Curran Associates, Inc., 2021. URL https://proceedings.neurips.cc/
paper_files/paper/2021/file/46e0eae7d5217c79c3ef6b4c212b8c6f-Paper.pdf."
REFERENCES,0.1206896551724138,"Yuan Cao, Zixiang Chen, Misha Belkin, and Quanquan Gu. Benign overfitting in two-layer convolu-
tional neural networks. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh
(eds.), Advances in Neural Information Processing Systems, volume 35, pp. 25237–25250. Cur-
ran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/
2022/file/a12c999be280372b157294e72a4bbc8b-Paper-Conference.pdf."
REFERENCES,0.12147335423197492,"Niladri S. Chatterji and Philip M. Long. Finite-sample analysis of interpolating linear classifiers in
the overparameterized regime. Journal of Machine Learning Research, 22(129):1–30, 2021. URL
http://jmlr.org/papers/v22/20-974.html."
REFERENCES,0.12225705329153605,"Niladri S. Chatterji and Philip M. Long.
Foolish crowds support benign overfitting.
Journal
of Machine Learning Research, 23(125):1–12, 2022. URL http://jmlr.org/papers/v23/
21-1199.html."
REFERENCES,0.12304075235109718,"Zixiang Chen, Junkai Zhang, Yiwen Kou, Xiangning Chen, Cho-Jui Hsieh, and Quanquan Gu. Why
does sharpness-aware minimization generalize better than SGD? In Thirty-seventh Conference
on Neural Information Processing Systems, 2023. URL https://openreview.net/forum?id=
3WAnGWLpSQ."
REFERENCES,0.1238244514106583,"Spencer Frei, Niladri S Chatterji, and Peter Bartlett. Benign overfitting without linearity: Neural
network classifiers trained by gradient descent for noisy linear data. In Po-Ling Loh and Maxim
Raginsky (eds.), Proceedings of Thirty Fifth Conference on Learning Theory, volume 178 of
Proceedings of Machine Learning Research, pp. 2668–2703. PMLR, 2022. URL https://
proceedings.mlr.press/v178/frei22a.html."
REFERENCES,0.12460815047021943,"Spencer Frei, Gal Vardi, Peter L. Bartlett, and Nathan Srebro. Benign overfitting in linear classifiers
and leaky relu networks from KKT conditions for margin maximization. In Gergely Neu and
Lorenzo Rosasco (eds.), The Thirty Sixth Annual Conference on Learning Theory, 12-15 July 2023,
Bangalore, India, volume 195 of Proceedings of Machine Learning Research, pp. 3173–3228.
PMLR, 2023. URL https://proceedings.mlr.press/v195/frei23a.html."
REFERENCES,0.12539184952978055,"Erin George, Michael Murray, William Swartworth, and Deanna Needell.
Training shallow
ReLU networks on noisy data using hinge loss: when do we overfit and is it benign?
In
A. Oh, T. Neumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine (eds.), Advances
in Neural Information Processing Systems, volume 36, pp. 35139–35189. Curran Associates,
Inc., 2023.
URL https://proceedings.neurips.cc/paper_files/paper/2023/file/
6e73c39cc428c7d264d9820319f31e79-Paper-Conference.pdf."
REFERENCES,0.12617554858934169,"Trevor Hastie, Andrea Montanari, Saharon Rosset, and Ryan J. Tibshirani. Surprises in high-
dimensional ridgeless least squares interpolation. The Annals of Statistics, 50(2):949–986, 2022.
URL https://doi.org/10.1214/21-AOS2133."
REFERENCES,0.12695924764890282,"Ziwei Ji and Matus Telgarsky.
Directional convergence and alignment in deep learning.
In
H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances in
Neural Information Processing Systems, volume 33, pp. 17176–17186. Curran Associates,
Inc., 2020.
URL https://proceedings.neurips.cc/paper_files/paper/2020/file/
c76e4b2fa54f8506719a5c0dc14c2eb9-Paper.pdf."
REFERENCES,0.12774294670846395,"Frederic Koehler, Lijia Zhou, Danica J. Sutherland, and Nathan Srebro. Uniform convergence of
interpolators: Gaussian width, norm bounds and benign overfitting. In A. Beygelzimer, Y. Dauphin,
P. Liang, and J. Wortman Vaughan (eds.), Advances in Neural Information Processing Systems,
2021. URL https://openreview.net/forum?id=FyOhThdDBM."
REFERENCES,0.12852664576802508,"Guy Kornowski, Gilad Yehudai, and Ohad Shamir. From tempered to benign overfitting in ReLU
neural networks. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.
URL https://openreview.net/forum?id=LnZuxp3Tx7."
REFERENCES,0.12931034482758622,"Yiwen Kou, Zixiang Chen, Yuanzhou Chen, and Quanquan Gu. Benign overfitting in two-layer ReLU
convolutional neural networks. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara
Engelhardt, Sivan Sabato, and Jonathan Scarlett (eds.), Proceedings of the 40th International
Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pp.
17615–17659. PMLR, 2023. URL https://proceedings.mlr.press/v202/kou23a.html."
REFERENCES,0.13009404388714735,"Tengyuan Liang and Alexander Rakhlin. Just interpolate: Kernel “Ridgeless” regression can gen-
eralize. The Annals of Statistics, 48(3):1329 – 1347, 2020. URL https://doi.org/10.1214/
19-AOS1849."
REFERENCES,0.13087774294670845,"Tengyuan Liang, Alexander Rakhlin, and Xiyu Zhai. On the multiple descent of minimum-norm
interpolants and restricted lower isometry of kernels. In Jacob Abernethy and Shivani Agarwal
(eds.), Proceedings of Thirty Third Conference on Learning Theory, volume 125 of Proceedings of
Machine Learning Research, pp. 2683–2711. PMLR, 2020. URL https://proceedings.mlr.
press/v125/liang20a.html."
REFERENCES,0.13166144200626959,"Kaifeng Lyu and Jian Li. Gradient descent maximizes the margin of homogeneous neural networks.
In International Conference on Learning Representations, 2020. URL https://openreview.
net/forum?id=SJeLIgBKPS."
REFERENCES,0.13244514106583072,"Song Mei and Andrea Montanari. The generalization error of random features regression: Precise
asymptotics and the double descent curve. Communications on Pure and Applied Mathematics,
75(4):667–766, 2022. URL https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.
22008."
REFERENCES,0.13322884012539185,"Andrea Montanari, Feng Ruan, Basil Saeed, and Youngtak Sohn. Universality of max-margin
classifiers. arXiv preprint arXiv:2310.00176, 2023a."
REFERENCES,0.13401253918495298,"Andrea Montanari, Feng Ruan, Youngtak Sohn, and Jun Yan. The generalization error of max-margin
linear classifiers: Benign overfitting and high-dimensional asymptotics in the overparametrized
regime. arXiv preprint arXiv:1911.01544, 2023b."
REFERENCES,0.13479623824451412,"Vidya Muthukumar, Kailas Vodrahalli, Vignesh Subramanian, and Anant Sahai. Harmless interpo-
lation of noisy data in regression. IEEE Journal on Selected Areas in Information Theory, 1(1):
67–83, 2020. URL https://doi.org/10.1109/JSAIT.2020.2984716."
REFERENCES,0.13557993730407525,"Vidya Muthukumar, Adhyyan Narang, Vignesh Subramanian, Mikhail Belkin, Daniel Hsu, and Anant
Sahai. Classification vs regression in overparameterized regimes: Does the loss function matter? J.
Mach. Learn. Res., 22(1), 2021. URL http://jmlr.org/papers/v22/20-603.html."
REFERENCES,0.13636363636363635,"George Pólya. Remarks on computing the probability integral in one and two dimensions. In
Proceedings of the Berkeley Symposium on Mathematical Statistics and Probability, number 1, pp.
63. University of California Press Berkeley, 1949."
REFERENCES,0.1371473354231975,"Mark Rudelson and Roman Vershynin. Smallest singular value of a random rectangular matrix.
Communications on Pure and Applied Mathematics, 62(12):1707–1739, 2009. URL https:
//doi.org/10.1002/cpa.20294."
REFERENCES,0.13793103448275862,"Ohad Shamir. The implicit bias of benign overfitting. In Po-Ling Loh and Maxim Raginsky
(eds.), Proceedings of Thirty Fifth Conference on Learning Theory, volume 178 of Proceedings
of Machine Learning Research, pp. 448–478. PMLR, 2022. URL https://proceedings.mlr.
press/v178/shamir22a.html."
REFERENCES,0.13871473354231975,"Roman Vershynin. High-Dimensional Probability: An Introduction with Applications in Data Science.
Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, 2018.
URL https://doi.org/10.1017/9781108231596."
REFERENCES,0.13949843260188088,"Guillaume Wang, Konstantin Donhauser, and Fanny Yang. Tight bounds for minimum ℓ1-norm
interpolation of noisy data. In International Conference on Artificial Intelligence and Statistics,
2021a. URL https://proceedings.mlr.press/v151/wang22k.html."
REFERENCES,0.14028213166144202,"Ke Wang, Vidya Muthukumar, and Christos Thrampoulidis. Benign overfitting in multiclass classifi-
cation: All roads lead to interpolation. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang,
and J. Wortman Vaughan (eds.), Advances in Neural Information Processing Systems, volume 34,
pp. 24164–24179. Curran Associates, Inc., 2021b. URL https://proceedings.neurips.cc/
paper_files/paper/2021/file/caaa29eab72b231b0af62fbdff89bfce-Paper.pdf."
REFERENCES,0.14106583072100312,"Denny Wu and Ji Xu. On the optimal weighted ℓ2 regularization in overparameterized linear re-
gression. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances
in Neural Information Processing Systems, volume 33, pp. 10112–10123. Curran Associates,
Inc., 2020.
URL https://proceedings.neurips.cc/paper_files/paper/2020/file/
72e6d3238361fe70f22fb0ac624a7072-Paper.pdf."
REFERENCES,0.14184952978056425,"Xingyu Xu and Yuantao Gu. Benign overfitting of non-smooth neural networks beyond lazy training.
In Francisco Ruiz, Jennifer Dy, and Jan-Willem van de Meent (eds.), Proceedings of The 26th
International Conference on Artificial Intelligence and Statistics, volume 206 of Proceedings of
Machine Learning Research, pp. 11094–11117. PMLR, 2023. URL https://proceedings.
mlr.press/v206/xu23k.html."
REFERENCES,0.1426332288401254,"Zhiwei Xu, Yutong Wang, Spencer Frei, Gal Vardi, and Wei Hu. Benign overfitting and grokking
in ReLU networks for XOR cluster data. In The Twelfth International Conference on Learning
Representations, 2024. URL https://openreview.net/forum?id=BxHgpC6FNv."
REFERENCES,0.14341692789968652,"Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understand-
ing deep learning requires rethinking generalization. In International Conference on Learning
Representations, 2017. URL https://openreview.net/forum?id=Sy8gdB9xx."
REFERENCES,0.14420062695924765,"Difan Zou, Jingfeng Wu, Vladimir Braverman, Quanquan Gu, and Sham Kakade. Benign overfitting
of constant-stepsize SGD for linear regression. In Mikhail Belkin and Samory Kpotufe (eds.),
Proceedings of Thirty Fourth Conference on Learning Theory, volume 134 of Proceedings of
Machine Learning Research, pp. 4633–4635. PMLR, 2021. URL https://proceedings.mlr.
press/v134/zou21a.html."
REFERENCES,0.14498432601880878,"Appendix A
Preliminaries on random vectors"
REFERENCES,0.14576802507836992,"Recall that the sub-exponential norm of a random variable X is defined as
∥X∥ψ1 := inf{t > 0: E[exp(|X|/t)] ≤2}
(see Vershynin, 2018, Definition 2.7.5) and that the sub-Gaussian norm is defined as
∥X∥ψ2 := inf{t > 0: E[exp(X2/t2)] ≤2}."
REFERENCES,0.14655172413793102,"A random variable X is sub-Gaussian if and only if X2 is sub-exponential. Furthermore, ∥X2∥ψ1 =
∥X∥2
ψ2."
REFERENCES,0.14733542319749215,"Lemma A.1. Let n ∼N(0d, d−1(Id −vvT )) and suppose that Z ∈Rm×d. Then with probability
at least 1 −ϵ,"
REFERENCES,0.1481191222570533,∥Zn∥≤C∥Z∥F r
REFERENCES,0.14890282131661442,"1
d log 1 ϵ ."
REFERENCES,0.14968652037617555,"Proof. Let P = Id −vvT be the orthogonal projection onto span({v})⊥, so that Zn is identi-
cally distributed to d−1/2ZP n′, where n′ has distribution N(0d, Id). Following Vershynin (2018,
Theorem 6.3.2),∥Zn∥−∥d−1/2ZP ∥F

ψ2 =
∥d−1/2ZP n′∥−∥d−1/2ZP ∥F

ψ2
≤C∥d−1/2ZP ∥"
REFERENCES,0.15047021943573669,≤Cd−1/2∥Z∥∥P ∥
REFERENCES,0.15125391849529782,= Cd−1/2∥Z∥
REFERENCES,0.15203761755485892,"≤Cd−1/2∥Z∥F ,
where we used that P is an orthogonal projection in the fourth line and that the operator norm is by
bounded above by the Frobenius norm in the fifth line. As a result the sub-Gaussian norm of ∥Zn∥
is bounded as
∥Zn∥

ψ2 ≤
∥Zn∥−∥d−1/2ZP ∥F

ψ2 +
∥d−1/2ZP ∥F

ψ2
≤Cd−1/2(∥Z∥F + ∥ZP ∥F )"
REFERENCES,0.15282131661442006,"≤Cd−1/2∥Z∥F ,
where the last line follows from the calculation
∥ZP ∥F = ∥P T ZT ∥F
= ∥P ZT ∥F
≤∥P ∥∥ZT ∥F
= ∥ZT ∥F
= ∥Z∥F .
This implies a tail bound (see Vershynin, 2018, Proposition 2.5.2)"
REFERENCES,0.1536050156739812,"P(∥Zn∥≥t) ≤2 exp

−
dt2"
REFERENCES,0.15438871473354232,"C∥Z∥2
F"
REFERENCES,0.15517241379310345,"
,
for all t ≥0."
REFERENCES,0.15595611285266459,"Setting t = C∥Z∥F
q"
REFERENCES,0.15673981191222572,"1
d log 2"
REFERENCES,0.15752351097178682,"ϵ , the result follows."
REFERENCES,0.15830721003134796,"Lemma A.2. Let n ∼N(0d, d−1(Id −vvT )) and suppose z ∈span({v})⊥. There exists a C > 0
such that with probability at least 1 −δ"
REFERENCES,0.1590909090909091,"|⟨n, z⟩| ≤C∥z∥ r"
REFERENCES,0.15987460815047022,"1
d log 1 δ ."
REFERENCES,0.16065830721003135,"Furthermore, there exists a c > 0 such that with probability at least 1 2"
REFERENCES,0.1614420062695925,"|⟨n, z⟩| ≥c∥z∥
√ d
."
REFERENCES,0.16222570532915362,"Proof. Let X = ⟨n, z⟩. Then X is Gaussian with variance"
REFERENCES,0.16300940438871472,E[X2] = E[zT nnT z]
REFERENCES,0.16379310344827586,= zT E[nnT ]z
REFERENCES,0.164576802507837,= d−1zT (Id −vvT )z
REFERENCES,0.16536050156739812,= d−1zT z
REFERENCES,0.16614420062695925,= d−1∥z∥2.
REFERENCES,0.1669278996865204,"Note the third line above follows from the fact that z ∈span({v})⊥. Therefore by Hoeffding’s
inequality, for all t ≥0"
REFERENCES,0.1677115987460815,"P(|⟨n, z⟩| ≥t) ≤2 exp

−
dt2 C∥z∥2 
."
REFERENCES,0.16849529780564262,Setting t = C∥z∥2q
REFERENCES,0.16927899686520376,"1
d log 2"
REFERENCES,0.1700626959247649,"δ , we obtain"
REFERENCES,0.17084639498432602,"P(|⟨n, z⟩| ≥t) ≤δ,"
REFERENCES,0.17163009404388715,which establishes the first part of the result.
REFERENCES,0.1724137931034483,"Since d1/2∥z∥−1X is a standard Gaussian, there exists a constant c such that"
REFERENCES,0.1731974921630094,P(|d1/2∥z∥−1X| ≥c) ≤1 2.
REFERENCES,0.17398119122257052,"Rearranging, we obtain"
REFERENCES,0.17476489028213166,"P(|⟨n, z⟩| ≥cd−1/2∥z∥) ≤1 2."
REFERENCES,0.1755485893416928,This establishes the second part of the result.
REFERENCES,0.17633228840125392,"Appendix B
Upper bounding the norm of the max-margin classifier of the
data"
REFERENCES,0.17711598746081506,"Here we establish key properties concerning the data model given in Definition 2.1, our main goal
being to establish bounds on the norm of the max-margin classifier. To this end we first identify
certain useful facts about rectangular Gaussian matrices. In what follows we index the singular values
of any given matrix A in decreasing order as σ1(A) ≥σ2(A) ≥· · · . Furthermore, we denote the
i-th-row of a matrix A as ai."
REFERENCES,0.1778996865203762,"Lemma B.1. Let G ∈Rn×d be a Gaussian matrix whose entries are mutually i.i.d. with distribution
N(0, 1). If d = Ω
 
n + log 1"
REFERENCES,0.1786833855799373,"δ

, then with probability at least 1 −δ the following inequalities are
simultaneously true."
REFERENCES,0.17946708463949843,"1. σ1(G) ≤C(
√"
REFERENCES,0.18025078369905956,"d + √n),"
REFERENCES,0.1810344827586207,"2. σn(G) ≥c(
√"
REFERENCES,0.18181818181818182,d −√n).
REFERENCES,0.18260188087774296,Proof. We proceed by upper bounding the probability that each individual inequality does not hold.
REFERENCES,0.1833855799373041,"1. To derive an upper bound on σ1(G) we use the following fact (see Vershynin, 2018, Theorem
4.4.5). For any ϵ > 0,"
REFERENCES,0.1841692789968652,"P(σ1(G) ≥C1(√n +
√"
REFERENCES,0.18495297805642633,d + ϵ)) ≤2 exp(−ϵ2).
REFERENCES,0.18573667711598746,"With ϵ = √n +
√"
REFERENCES,0.1865203761755486,d and d ≥log 4
REFERENCES,0.18730407523510972,δ then
REFERENCES,0.18808777429467086,"P(σ1(G) ≥2C1(√n +
√"
REFERENCES,0.18887147335423196,d)) ≤2 exp(−d) ≤δ 2.
REFERENCES,0.1896551724137931,"2. To derive a lower bound on σn(G) we use the following fact (see Rudelson & Vershynin, 2009,
Theorem 1.1). There exist constants C1, C2 > 0 such that, for any ϵ > 0,"
REFERENCES,0.19043887147335423,"P(σn(G) ≤ϵ(
√ d −
√"
REFERENCES,0.19122257053291536,n −1)) ≤(C1ϵ)d−n+1 + e−C2d.
REFERENCES,0.1920062695924765,"Let ϵ =
1
C1e and let d ≥2n +

2 +
1
C2"
REFERENCES,0.19278996865203762,"
log 4"
REFERENCES,0.19357366771159876,δ . Then
REFERENCES,0.19435736677115986,"P(σn(A) ≤ϵ(
√"
REFERENCES,0.195141065830721,d −√n)) ≤exp(−d/2) + exp(−C2d) ≤δ 4 + δ 4 = δ 2.
REFERENCES,0.19592476489028213,Hence both bounds hold simultaneously with probability at least 1 −δ.
REFERENCES,0.19670846394984326,"The next lemma formulates lower and upper bounds on the smallest and largest singular values of a
noise matrix under our data model."
REFERENCES,0.1974921630094044,"Lemma 4.1. Let N ∈Rn×d denote a random matrix whose rows are drawn mutually i.i.d. from
N(0d, 1"
REFERENCES,0.19827586206896552,"d(Id −vvT )). If d = Ω
 
n + log 1"
REFERENCES,0.19905956112852666,"δ

, then there exists constants C1 and C2 such that, with
probability at least 1 −δ,
C1 ≤σn(N) ≤σ1(N) ≤C2."
REFERENCES,0.19984326018808776,"Proof. Let H = span({v})⊥∼= Rd−1. Let N ′ : H →Rn be a random matrix whose rows are
drawn mutually i.i.d. from N(0d, IH). Since d = Ω
 
n + log 1"
REFERENCES,0.2006269592476489,"δ

, with probability at least 1 −δ, we
have
c(
√"
REFERENCES,0.20141065830721003,"d −√n) ≤σn(N ′) ≤σ1(N ′) ≤C(
√"
REFERENCES,0.20219435736677116,d + √n).
REFERENCES,0.2029780564263323,"We denote the above event by ω. Let J : H →Rd be the inclusion map and let P = Id −vvT . For
any random vector n with distribution N(0d, IH), Jn is a Gaussian random vector with covariance
matrix JJT = P . Therefore, d−1/2N ′JT is a random matrix whose rows are drawn mutually i.i.d.
from N(0d, d−1P ). That is, d−1/2N ′JT is identically distributed to N. For the lower bound on
the n-th largest singular value, if d ≥4n"
REFERENCES,0.20376175548589343,"c2 , then conditional on ω we have"
REFERENCES,0.20454545454545456,σn(d−1/2N ′JT ) = d−1/2σmin(JN ′T )
REFERENCES,0.20532915360501566,≥d−1/2σmin(J)σmin(N ′T )
REFERENCES,0.2061128526645768,= d−1/2σmin(N ′T )
REFERENCES,0.20689655172413793,= d−1/2σn(N ′)
REFERENCES,0.20768025078369906,"≥c −
rn d ≥c 2."
REFERENCES,0.2084639498432602,"Note here we define σmin to be the smallest singular value of a matrix. In the first line we used JN ′T
is a linear map Rn →Rd and d ≥n, and in the third line we used the fact that J is an inclusion map.
For the upper bound on the largest singular value, if d ≥
n
C2 , then conditional on ω we have"
REFERENCES,0.20924764890282133,σ1(d−1/2N ′JT ) = d−1/2σ1(JN ′T )
REFERENCES,0.21003134796238246,≤d−1/2σ1(N ′T )
REFERENCES,0.21081504702194356,= d−1/2σ1(N ′)
REFERENCES,0.2115987460815047,"≤C +
rn"
REFERENCES,0.21238244514106583,"d
≤2C."
REFERENCES,0.21316614420062696,"Note here that again we used the fact that J is an inclusion map in the first line. Therefore, if
d = Ω
 
n + log 1 δ
 P
 c"
REFERENCES,0.2139498432601881,"2 ≤σn(N) ≤σ1(N) ≤2C

≥P(ω)"
REFERENCES,0.21473354231974923,≥1 −δ.
REFERENCES,0.21551724137931033,"The following lemma is useful for constructing vectors in the noise subspace with properties suitable
for bounding the norm of the max-margin solution. We remark that the same approach could be
used in the setting where the noise and signal are not orthogonal by considering the pseudo-inverse
([N, v]T )† instead of N †."
REFERENCES,0.21630094043887146,"Lemma B.2. Let I ⊆[n] be an arbitrary subset such that |I| = ℓ. In the context of the data
model given in Definition 2.1, assume d = Ω
 
n + log 1"
REFERENCES,0.2170846394984326,"δ

. Then there exists z ∈Rd such that with
probability at least 1 −δ the following hold simultaneously."
REFERENCES,0.21786833855799373,"1. ˆyi⟨ni, z⟩= 1 for all i ∈I,"
REFERENCES,0.21865203761755486,"2. ˆyi⟨ni, z⟩= 0 for all i /∈I,"
REFERENCES,0.219435736677116,"3. z ⊥v,"
REFERENCES,0.22021943573667713,4. C1 ≤∥z∥≤C2.
REFERENCES,0.22100313479623823,"Proof. Recall that N ∈Rn×d is a random matrix whose rows are selected i.i.d. from N(0d, d−1(Id−
vvT )). By Lemma 4.1, with probability at least 1 −δ we have"
REFERENCES,0.22178683385579936,c ≤σn(N) ≤σ1(N) ≤C.
REFERENCES,0.2225705329153605,"Conditioning on this event, we will construct a vector z which satisfies the desired properties. Let
w ∈Rn satisfy wi = ˆyi if i ∈I and wi = 0 otherwise. Let z = N †w, where N † = N T (NN T )−1
is the right pseudo-inverse of N. Then Nz = w. In particular, for i ∈I, ˆyi⟨ni, z⟩= ˆyiwi = 1,
and for i /∈I, ˆyi⟨ni, z⟩= ˆyiwi = 0. This establishes properties 1 and 2. Since N †w is in the span
of the set {ni}i∈[n], it is orthogonal to v. This establishes property 3. Finally, we can bound"
REFERENCES,0.22335423197492163,∥z∥= ∥N †w∥
REFERENCES,0.22413793103448276,≤∥N †∥∥w∥
REFERENCES,0.2249216300940439,"=
∥w∥
σn(N) ≤∥w∥ c = √"
REFERENCES,0.22570532915360503,"ℓ
c
and"
REFERENCES,0.22648902821316613,∥z∥= ∥N †w∥
REFERENCES,0.22727272727272727,≥σn(N †)∥w∥
REFERENCES,0.2280564263322884,"=
∥w∥
σ1(N) ≥∥w∥ C = √"
REFERENCES,0.22884012539184953,"ℓ
C
which establishes property 4."
REFERENCES,0.22962382445141066,"With Lemma B.2 in place we are now able to appropriately bound the max-margin norm.
Lemma B.3. In the context of the data model given in Definition 2.1, let w∗denote the max-margin
classifier of the training data (X, ˆy), which exists almost surely. If d = Ω
 
n + log 1"
REFERENCES,0.2304075235109718,"δ

then with
probability at least 1 −δ"
REFERENCES,0.23119122257053293,∥w∗∥≤C s
REFERENCES,0.23197492163009403,"1
γ +
k
1 −γ ,"
REFERENCES,0.23275862068965517,where C > 0 is a constant.
REFERENCES,0.2335423197492163,"Proof. Under the assumptions stated, the conditions of Lemma B.2 hold with probability at least
1 −δ. Conditioning on this let"
REFERENCES,0.23432601880877743,"w =
1
√γ v +
2
√1 −γ z"
REFERENCES,0.23510971786833856,where z is the vector constructed in Lemma B.2 with I = B. For any i ∈[n] we therefore have
REFERENCES,0.2358934169278997,"ˆyi⟨xi, w⟩= βi + 2 ˆyi⟨ni, z⟩."
REFERENCES,0.23667711598746083,"As a result, for i ∈G"
REFERENCES,0.23746081504702193,"ˆyi⟨xi, w⟩= 1 + 2 ˆyi⟨ni, z⟩= 1,"
REFERENCES,0.23824451410658307,while for l ∈B
REFERENCES,0.2390282131661442,"ˆyi⟨xi, w⟩= −1 + 2ˆyi⟨ni, z⟩= 1."
REFERENCES,0.23981191222570533,"As a result ˆyi⟨xi, w⟩= 1 for all i ∈[n]. Furthermore, observe"
REFERENCES,0.24059561128526646,∥w∥2 = 1
REFERENCES,0.2413793103448276,"γ +
4
1 −γ ∥z∥2"
REFERENCES,0.2421630094043887,"≤C
 1"
REFERENCES,0.24294670846394983,"γ +
k
1 −γ "
REFERENCES,0.24373040752351097,for a universal constant C. To conclude observe ∥w∗∥≤∥w∥by definition of being max-margin.
REFERENCES,0.2445141065830721,"Lemma B.3 constructs a classifier with margin one using an appropriate linear combination of the
signal vector v and a vector in the noise subspace which classifies all noise components belonging to
bad points correctly. This bound is useful for the benign overfitting setting in which γ is not too small.
However, for small γ, as is the case in the non-benign overfitting setting, this bound behaves poorly
as the only way the construction can fit all the data points is by making the coefficient in front of the
v component large. For the non-benign overfitting setting we therefore require a different approach
and instead fit all data points based on their noise components alone. In particular, the following
bound behaves better than that given in Lemma B.3 when γ approaches 0.
Lemma B.4. In the context of the data model given in Definition 2.1, let w∗denote the max-margin
classifier of the training data (X, ˆy), which exists almost surely. If d = Ω
 
n + log 1"
REFERENCES,0.24529780564263323,"δ

then with
probability at least 1 −δ"
REFERENCES,0.24608150470219436,"∥w∗∥≤C
r
n
1 −γ ."
REFERENCES,0.2468652037617555,"Proof. Applying Lemma B.2 with I = [n] then with probability 1 −δ there exists z ∈Rd such that
∥z∥= Θ(√n), ˆyi⟨ni, z⟩= 1 for all i ∈[n] and z ⊥v. Conditioning on this event, let"
REFERENCES,0.2476489028213166,"w =
1
√1 −γ z."
REFERENCES,0.24843260188087773,"Then for all i ∈[n],
ˆyi⟨xi, w⟩= ˆyi⟨ni, z⟩= 1.
Furthermore, there exists a constant C > 0 such that"
REFERENCES,0.24921630094043887,"∥w∥≤C
r
n
1 −γ ."
REFERENCES,0.25,To conclude observe ∥w∗∥≤∥w∥by definition of being max-margin.
REFERENCES,0.2507836990595611,"Appendix C
Linear models"
REFERENCES,0.25156739811912227,"C.1
Sufficient conditions for benign and harmful overfitting"
REFERENCES,0.25235109717868337,"We start by providing a lemma which characterizes the generalization properties of linear classifiers.
Lemma C.1. In the context of the data model given in Definition 2.1, consider the linear classifier
w = avv + z, where av ∈R and ⟨z, v⟩= 0. If av ≥0, then the generalization error can be
bounded as follows:"
REFERENCES,0.25313479623824453,"P(y⟨w, x⟩≤0) ≤exp

−d"
REFERENCES,0.25391849529780564,"2
γ
1 −γ
a2
v
∥z∥2 
. and"
REFERENCES,0.2547021943573668,"P(y⟨w, x⟩≤0) ≥max"
REFERENCES,0.2554858934169279,"(
1
2 − s"
REFERENCES,0.256269592476489,"dγ
2π(1 −γ)
av
∥z∥, 1"
EXP,0.25705329153605017,"4 exp

−6d"
EXP,0.25783699059561127,"π
γ
1 −γ
a2
v
∥z∥2 ) ."
EXP,0.25862068965517243,"Proof. Recall from Definition 2.1 that a test pair (x, y) satisfies"
EXP,0.25940438871473354,"x = y(√γv +
p"
EXP,0.2601880877742947,"1 −γn),"
EXP,0.2609717868338558,"where n ∼N(0d, d−1(Id −vvT )) is a random vector. Let X = y⟨w, x⟩, so"
EXP,0.2617554858934169,"X = ⟨avv + z, √γv +
p"
EXP,0.26253918495297807,1 −γn⟩
EXP,0.26332288401253917,"= √γav +
p"
EXP,0.26410658307210033,"1 −γ⟨n, z⟩."
EXP,0.26489028213166144,Then X is a Gaussian random variable with expectation
EXP,0.2656739811912226,"E[X] = √γav +
p"
EXP,0.2664576802507837,"1 −γE[⟨n, z⟩]
= √γav
and variance"
EXP,0.2672413793103448,"Var(X) = (1 −γ)Var(⟨n, z⟩)"
EXP,0.26802507836990597,= (1 −γ)E[zT nnT z]
EXP,0.26880877742946707,= 1 −γ
EXP,0.26959247648902823,"d
zT (Id −vvT )z"
EXP,0.27037617554858934,= 1 −γ
EXP,0.2711598746081505,"d
zT z"
EXP,0.2719435736677116,"= (1 −γ)∥z∥2 d
."
EXP,0.2727272727272727,"By Hoeffding’s inequality, for all t ≥0,"
EXP,0.27351097178683387,"P(X ≤√γav −t) ≤exp

−
t2d
2(1 −γ)∥z∥2 
."
EXP,0.274294670846395,"Setting t = √γav, we obtain"
EXP,0.27507836990595613,"P(X ≤0) ≤exp

−
γda2
v
2(1 −γ)∥z∥2 
,"
EXP,0.27586206896551724,which establishes the upper bound on the generalization error.
EXP,0.27664576802507834,"To prove the lower bound, we integrate a standard Gaussian pdf:"
EXP,0.2774294670846395,P(X ≤0) = P
EXP,0.2782131661442006,"X −√γav
√1 −γ∥z∥/
√ d
≤− s"
EXP,0.27899686520376177,"γd
1 −γ
av
∥z∥ ! = 1"
EXP,0.2797805642633229,"2 −
1
√ 2π Z 0 −
q"
EXP,0.28056426332288403,"γd
1−γ
av
∥z∥
e−t2/2dt ≥1"
EXP,0.28134796238244514,"2 −
1
√ 2π s"
EXP,0.28213166144200624,"γd
1 −γ
av
∥z∥ ! ."
EXP,0.2829153605015674,"Another bound can be obtained using the following inequality (Pólya, 1949, (1.5)): 1
√ 2π Z x"
EXP,0.2836990595611285,"0
e−t2/2dt ≤
p"
EXP,0.28448275862068967,1 −e−2x2/π.
EXP,0.2852664576802508,We proceed
EXP,0.28605015673981193,P(X ≤0) = 1
EXP,0.28683385579937304,"2 −
1
√ 2π Z 0 −
q"
EXP,0.28761755485893414,"γd
1−γ
av
∥z∥
e−t2/2dt = 1"
EXP,0.2884012539184953,"2 −
1
√ 2π Z q"
EXP,0.2891849529780564,"γd
1−γ
av
∥z∥"
EXP,0.28996865203761757,"0
e−t2/2dt ≥1 2 −1 2 s"
EXP,0.2907523510971787,"1 −exp

−
2γda2v
π(1 −γ)∥z∥2  ≥1 2 −1 2"
EXP,0.29153605015673983,"
1 −1"
EXP,0.29231974921630094,"2 exp

−
2γda2
v
π(1 −γ)∥z∥2  ≥1"
EXP,0.29310344827586204,"4 exp

−
2γda2
v
π(1 −γ)∥z∥2 
."
EXP,0.2938871473354232,"The following result establishes benign and non-benign overfitting for linear models and data as
per Definition 2.1, with a phase transition between these outcomes depending on the signal to noise
parameter γ."
EXP,0.2946708463949843,"Theorem C.2. In the context of the data model described in Section 2, let w∗be a max-margin
linear classifier of the training data. Let A : Rn×d × {±1}n →Rd be a learning algorithm which is
approximately margin-maximizing, Definition 2.3. For δ ∈(0, 1], let d = Ω
 
n + log 1"
EXP,0.29545454545454547,"δ

. Then with
probability at least 1 −δ over the randomness of the training data (X, ˆy), the following hold with ϵ
denoting the generalization error of A(X, ˆy)."
EXP,0.2962382445141066,"(A) If γ
=
Ω(|A|2n−1) and k
=
O(|A|−2n), then exp
 
−C1dk−1
≤
ϵ
≤
exp
 
−C2dk−1|A|−2
for fixed positive constants C1 and C2."
EXP,0.29702194357366773,"(B) If γ = O(|A|−2d−1), then ϵ ≥1 2 −
p"
EXP,0.29780564263322884,Cdγ|A|2 for a fixed positive constant C.
EXP,0.29858934169278994,"Proof. For training data (X, ˆy) let w = A(X, ˆy) be the learned linear classifier. First, recall
xi = √γyiv + √1 −γni for all i ∈[n], ∥v∥= 1, and observe that we can decompose the vector w
as w = avv + z, where av ∈R, and z ⊥v. As a result, for each i ∈[n],"
EXP,0.2993730407523511,"ˆyi⟨xi, w⟩= √γavβi +
p"
EXP,0.3001567398119122,"1 −γˆyi⟨ni, z⟩.
(8)"
EXP,0.30094043887147337,"First we establish (A). As d = Ω
 
n + log 1"
EXP,0.3017241379310345,"δ

, Lemmas 4.1 and B.3 show that with probability at"
EXP,0.30250783699059564,least 1 −δ
EXP,0.30329153605015674,"2, ∥N∥2, ∥NG∥2, ∥NB∥≤C and ∥w∗∥≤C
q"
EXP,0.30407523510971785,"1
γ +
k
1−γ . Here NG and NB denote the
matrices formed by taking only the rows of N which satisfy β = 1 and β = −1, respectively. We
denote this event ω and condition on it in all that follows for the proof of (A). As A is approximately
max margin then given equation 8 we have for all i ∈G"
EXP,0.304858934169279,"1 ≤√γav +
p"
EXP,0.3056426332288401,"1 −γˆyi⟨ni, z⟩."
EXP,0.30642633228840127,Suppose that √γav < 1
EXP,0.3072100313479624,"2. Then the above inequality implies √1 −γˆyi⟨ni, z⟩≥1"
EXP,0.30799373040752354,"2 for all i ∈G.
Squaring and then summing this expression over all i ∈G it follows that n −k"
EXP,0.30877742946708464,"4
≤(1 −γ)
X"
EXP,0.30956112852664575,"i∈G
|⟨ni, z⟩|2"
EXP,0.3103448275862069,≤(1 −γ)∥NGz∥2
EXP,0.311128526645768,≤(1 −γ)∥NG∥2∥z∥2.
EXP,0.31191222570532917,"Since A is approximately margin-maximizing, n −k"
EXP,0.3126959247648903,"4
≤(1 −γ)C∥z∥2"
EXP,0.31347962382445144,≤(1 −γ)C∥w∥2
EXP,0.31426332288401254,≤C|A|2(1 −γ)∥w∗∥2
EXP,0.31504702194357365,"≤C|A|2(1 −γ)
 1"
EXP,0.3158307210031348,"γ +
k
1 −γ "
EXP,0.3166144200626959,≤C|A|2
EXP,0.31739811912225707,"γ
+ C|A|2k,"
EXP,0.3181818181818182,which further implies n ≤C|A|2
EXP,0.31896551724137934,"γ
+ C|A|2k for some other constant C. For this inequality to hold,"
EXP,0.31974921630094044,"either C|A|2 γ
≥n"
EXP,0.32053291536050155,2 or C|A|2k ≥n
EXP,0.3213166144200627,"2 . With k ≤
n
4C|A|2 and γ ≥1"
EXP,0.3221003134796238,"k, neither of these can be true and
therefore we conclude that √γav ≥1"
THEN,0.322884012539185,2. Then
THEN,0.3236677115987461,"a2
v
∥z∥2 ≥
1
4γ∥z∥2"
THEN,0.32445141065830724,"≥
1
4γ∥w∥2"
THEN,0.32523510971786834,"≥
1
4γ|A|2∥w∗∥2"
THEN,0.32601880877742945,"≥
C
|A|2γ
1"
THEN,0.3268025078369906,"1
γ +
k
1−γ"
THEN,0.3275862068965517,"≥
C
2|A|2γ
1 −γ k"
THEN,0.3283699059561129,"for a positive constant C. Letting (x, y) denote a test point pair, then by Lemma C.1 it follows that
for a different constant C"
THEN,0.329153605015674,"P(y⟨w, x⟩≤0 | ω) ≤exp

−d"
THEN,0.3299373040752351,"2
γ
1 −γ
a2
v
∥z∥2 "
THEN,0.33072100313479624,"≤exp

−Cd |A|2k 
."
THEN,0.33150470219435735,"Hence the generalization error is at most ϵ when ω occurs, which happens with probability at least
1 −δ. This establishes the upper bound of (A)."
THEN,0.3322884012539185,"For the lower bound of (A), since w is a linear classifier,"
THEN,0.3330721003134796,"⟨ni, z⟩≥
1
√1 −γ (1 + av
√γ) ≥av"
THEN,0.3338557993730408,"r
γ
1 −γ"
THEN,0.3346394984326019,"for all i ∈B, from which we conclude |⟨ni, z⟩| ≥av√γ. This implies"
THEN,0.335423197492163,∥NBz∥≥aV s
THEN,0.33620689655172414,"kγ
1 −γ"
THEN,0.33699059561128525,Along with ∥NBz∥≤∥NB∥∥z∥≤C∥z∥we conclude
THEN,0.3377742946708464,∥z∥≥av C s
THEN,0.3385579937304075,"kγ
1 −γ ."
THEN,0.3393416927899687,With this bound we then bound
THEN,0.3401253918495298,"av
∥z∥≤C ·
r1 −γ kγ ."
THEN,0.3409090909090909,By Lemma C.1 we then can bound
THEN,0.34169278996865204,"P(y⟨w, x⟩≤0 | ω) ≥1"
EXP,0.34247648902821315,"4 exp

−6d"
EXP,0.3432601880877743,"π
γ
1 −γ
a2
v
∥z∥2 "
EXP,0.3440438871473354,"≥exp

−Cd k "
EXP,0.3448275862068966,"for a new constant C, provided av is positive. In the last line we can bound d"
EXP,0.3456112852664577,"k below as d ≥n and
k = O(n). If av is negative then the generalization error is at least 1"
EXP,0.3463949843260188,"2, which is still bounded below
by exp(−Cd/k)."
EXP,0.34717868338557994,We now turn our attention to (B). As d = Ω(n + log 1
EXP,0.34796238244514105,"δ ), from Lemmas 4.1 and B.4 with probability
at least 1 −δ it holds that ∥NG∥2 ≤C and ∥w∗∥≤
C√n
√1−γ . We denote this event ω′ and condition
on it in all that follows for the proof of (B). In particular,
a2
v + ∥z∥2 = ∥w∥2"
EXP,0.3487460815047022,≤|A|2∥w∗∥2
EXP,0.3495297805642633,≤C|A|2n
EXP,0.3503134796238245,"1 −γ .
(9)"
EXP,0.3510971786833856,"For all i ∈[n],"
EXP,0.3518808777429467,"1 ≤√γβiav +
p"
EXP,0.35266457680250785,"1 −γ ˆyi⟨ni, z⟩.
For this inequality to hold, either |√γav| ≥1/2 or √1 −γ ˆyi⟨ni, z⟩≥1/2 for all i ∈[n]. If
|√γav| ≥1/2, then with γ ≤
1
4(C+1)|A|2d we have"
EXP,0.35344827586206895,"a2
v ≥2C|A|2d ≥2C|A|2n.
However, from equation 9 we have"
EXP,0.3542319749216301,2C|A|2n > C|A|2n
EXP,0.3550156739811912,"1 −γ
≥a2
v"
EXP,0.3557993730407524,"which is a contradiction. Therefore, under the regime specified there exists a C > 0 such that with
γ ≤
1
C|A|2d, we have √1 −γ ˆyi⟨ni, z⟩≥1/2 for all i ∈[n]. Rearranging, squaring and summing
over all i ∈[n] yields"
EXP,0.3565830721003135,"n
4(1 −γ) ≤ n
X"
EXP,0.3573667711598746,"i=1
|⟨ni, z⟩|2 ≤∥Nz∥2 ≤C∥z∥2,"
EXP,0.35815047021943575,"where the final inequality follows from conditioning on ω. Then
a2
v
∥z∥2 ≤∥w∥2 ∥z∥2"
EXP,0.35893416927899685,≤|A|2∥w∗∥2 ∥z∥2
EXP,0.359717868338558,"≤
C|A|2
n
1−γ
n
1−γ
≤C|A|2,
where the constant C > 0 may vary between inequalities. Letting (x, y) denote a test point pair, by
Lemma C.1 it follows that"
EXP,0.3605015673981191,"P(y⟨w, x⟩≤0 | ω) ≥1 2 − s"
EXP,0.3612852664576803,"dγ
2π(1 −γ)
av
∥z∥ ≥1 2 − s"
EXP,0.3620689655172414,"Cdγ|A|2 1 −γ ≥1 2 −
p"
EXP,0.3628526645768025,Cdγ|A|2.
EXP,0.36363636363636365,"Hence the generalization error is at least 1 2 −
p"
EXP,0.36442006269592475,"Cdγ|A|2 when ω′ occurs, which happens with
probability at least 1 −δ. This establishes (B)."
EXP,0.3652037617554859,"Appendix D
Leaky ReLU Networks"
EXP,0.365987460815047,In this section we consider a leaky ReLU network f : R2m × Rd →R with forward pass given by
EXP,0.3667711598746082,"f(W , x) ="
"M
X",0.3675548589341693,"2m
X"
"M
X",0.3683385579937304,"j=1
(−1)jσ(⟨wj, xi⟩),"
"M
X",0.36912225705329155,"where σ(z) = max(αz, z) for some α ∈(0, 1). For any such network, we may decompose the
neuron weights wj into a signal component and a noise component,"
"M
X",0.36990595611285265,"wj = ajv + zj,"
"M
X",0.3706896551724138,"where aj ∈R and zj ∈Rd satisfies zj ⊥v. The ratio aj/∥zj∥therefore grows with the alignment
of wj with the signal and shrinks if wj instead aligns more with the noise. Collecting the noise
components of the weight vectors, let Z ∈R(2m)×d be the matrix whose j-th row is zj. In order to
track the alignment of the network as a whole with the signal versus noise subspaces we introduce
the following quantities. Let"
"M
X",0.3714733542319749,"A1 = f(W , v) ="
"M
X",0.3722570532915361,"2m
X"
"M
X",0.3730407523510972,"j=1
(−1)jσ(aj),"
"M
X",0.3738244514106583,"A−1 = f(W , −v) ="
"M
X",0.37460815047021945,"2m
X"
"M
X",0.37539184952978055,"j=1
(−1)j+1σ(−aj)"
"M
X",0.3761755485893417,"be referred to as the positive and negative signal activation of the network respectively. Moreover,
define"
"M
X",0.3769592476489028,"Amin = min(A1, A−1)"
"M
X",0.3777429467084639,"as the worst-case signal activation of the network, and"
"M
X",0.3785266457680251,Alin =
"M
X",0.3793103448275862,"2m
X"
"M
X",0.38009404388714735,"j=1
(−1)jaj"
"M
X",0.38087774294670845,as the linearized network activation. To measure the amount of noise the network learns we define
"M
X",0.3816614420062696,zlin =
"M
X",0.3824451410658307,"2m
X"
"M
X",0.3832288401253918,"j=1
(−1)jzj."
"M
X",0.384012539184953,"D.1
Training dynamics"
"M
X",0.3847962382445141,"Theorem 3.1. Let f : Rp × Rn →R be a leaky ReLU network with forward pass as defined by
equation 1. Suppose the step size η and initialization condition λ satisfy Assumption 1. Then for any
linearly separable data set (X, ˆy) AGD(X, ˆy, η, λ) converges after T iterations, where"
"M
X",0.38557993730407525,T ≤C∥w∗∥2
"M
X",0.38636363636363635,ηα2m .
"M
X",0.3871473354231975,Furthermore AGD is approximately margin maximizing on f (Definition 2.3) with
"M
X",0.3879310344827586,"|AGD| ≤
C
α√m."
"M
X",0.3887147335423197,"Proof. Our approach is to adapt a classical technique used for the proof of convergence of the
Perceptron algorithm for linearly separable data. This is also the approach adopted by Brutzkus
et al. (2018). The key idea of the proof is to bound in terms of the number of updates both the norm
of the learned vector w as well as its alignment with any linear separator of the data. From the
Cauchy-Schwarz inequality these bounds cannot cross, and this in turn bounds the number of updates
that can occur. Analogously, we track the alignment of W (t) with the max-margin classifier along
with the Frobenius norm of the W (t). To this end denote"
"M
X",0.3894984326018809,"G(t) = ∥W (t)
j
∥2
F and"
"M
X",0.390282131661442,F(t) =
"M
X",0.39106583072100315,"2m
X"
"M
X",0.39184952978056425,"j=1
(−1)j⟨w(t)
j , w∗⟩,"
"M
X",0.3926332288401254,"where w∗is a max-margin linear classifier of the dataset.
Recall that F(t) = {i ∈[n] :
ˆyif(W (t), xi) < 1} denotes the number of active data points at training step t. We also define
U(t) = Pt−1
s=0 |F(s)| to be the number of data point updates between iterations 0 and t. First, by
Cauchy-Schwarz"
"M
X",0.3934169278996865,"1 ≤⟨w∗, xi⟩≤∥w∗∥· ∥xi∥"
"M
X",0.3942006269592476,"for all i ∈[n]. Therefore,"
"M
X",0.3949843260188088,"∥w∗∥≥
1
mini∈[n] ∥xi∥."
"M
X",0.3957680250783699,"By Assumption 1, for all j ∈[2m],"
"M
X",0.39655172413793105,"∥w(0)
j ∥≤
√α
m mini∈[n] ∥xi∥≤∥w∗∥"
"M
X",0.39733542319749215,"αm .
(10)"
"M
X",0.3981191222570533,"For all t ≥0, the update rule of GD implies"
"M
X",0.3989028213166144,G(t + 1) =
"M
X",0.3996865203761755,"2m
X"
"M
X",0.4004702194357367,"j=1
∥w(t+1)
j
∥2 ="
"M
X",0.4012539184952978,"2m
X j=1"
"M
X",0.40203761755485895,"w(t)
j
+ η(−1)j X"
"M
X",0.40282131661442006,"i∈F(t)
˙σ(⟨w(t)
j , xi⟩)ˆyixi  2 ="
"M
X",0.4036050156739812,"2m
X"
"M
X",0.4043887147335423,"j=1
∥w(t)
j ∥2 + 2η"
"M
X",0.4051724137931034,"2m
X j=1 X"
"M
X",0.4059561128526646,"i∈F(t)
(−1)j ˙σ(⟨w(t)
j , xi⟩)ˆyi⟨w(t)
j , xi⟩+ η2
2m
X j=1 X"
"M
X",0.4067398119122257,"i,l∈F(t)
˙σ(⟨w(t)
j , xi⟩)⟨ˆyixi, ˆyixℓ⟩ ≤"
"M
X",0.40752351097178685,"2m
X"
"M
X",0.40830721003134796,"j=1
∥w(t)
j ∥2 + 2η"
"M
X",0.4090909090909091,"2m
X j=1 X"
"M
X",0.4098746081504702,"i∈F(t)
(−1)j ˙σ(⟨w(t)
j , xi⟩)ˆyi⟨w(t)
j , xi⟩+ 2mη2|F(t)|2 max
i∈[n] ∥xi∥2."
"M
X",0.4106583072100313,"Observe that for all z ∈R, σ(s) = ˙σ(z)z, so can rewrite the second term of the above expression as 2η"
"M
X",0.4114420062695925,"2m
X j=1 X"
"M
X",0.4122257053291536,"i∈F(t)
(−1)j ˙σ(⟨w(t)
j , xi⟩)ˆyi⟨w(t)
j , xi⟩= 2η"
"M
X",0.41300940438871475,"2m
X j=1 X"
"M
X",0.41379310344827586,"i∈F(t)
(−1)jσ(⟨w(t)
j , xi⟩)ˆyi"
"M
X",0.414576802507837,"= 2η
X"
"M
X",0.4153605015673981,"i∈F(t)
ˆyif(W (t), xi)"
"M
X",0.4161442006269592,"< 2η
X"
"M
X",0.4169278996865204,"i∈F(t)
1"
"M
X",0.4177115987460815,= 2η|F(t)|
"M
X",0.41849529780564265,"where the inequality in the second-to-last line follows as we are summing over F(t), which by
definition consists of the i ∈[n] such that ˆyif(W (t), xi) < 1. As a result we obtain"
"M
X",0.41927899686520376,G(t + 1) ≤
"M
X",0.4200626959247649,"2m
X"
"M
X",0.420846394984326,"j=1
∥w(t)
j ∥2 + 2η|F(t)| + 2mη2|F(t)|2 max
i∈[n] ∥xi∥2"
"M
X",0.4216300940438871,"= G(t) + 2η|F(t)| + 2mη2|F(t)|2 max
i∈[n] ∥xi∥2"
"M
X",0.4224137931034483,"≤G(t) + 4η|F(t)|,"
"M
X",0.4231974921630094,where the last line follows since
"M
X",0.42398119122257055,"η ≤
1
mn maxi∈[n] ∥xi∥2 ≤
1
|F(t)|m maxi∈[n] ∥xi∥2 ."
"M
X",0.42476489028213166,"By equation 10, the initialization satisfies"
"M
X",0.42554858934169276,G(0) =
"M
X",0.4263322884012539,"2m
X"
"M
X",0.427115987460815,"j=1
∥w(0)
j ∥2 ≤"
"M
X",0.4278996865203762,"2m
X j=1 ∥w∗∥2 α2m2"
"M
X",0.4286833855799373,= 2∥w∗∥2
"M
X",0.42946708463949845,"α2m
So by induction, for all t ≥0"
"M
X",0.43025078369905956,G(t) ≤2∥w∗∥2
"M
X",0.43103448275862066,"α2m
+ 3η t−1
X"
"M
X",0.4318181818181818,"s=0
|F(s)| = 2∥w∗∥2"
"M
X",0.43260188087774293,"α2m
+ 3ηU(t).
(11)"
"M
X",0.4333855799373041,Next we find a bound for F(t). For all t ≥0 then by definition of the GD update
"M
X",0.4341692789968652,F(t + 1) =
"M
X",0.43495297805642635,"2m
X"
"M
X",0.43573667711598746,"j=1
(−1)j⟨w(t+1)
j
, w∗⟩ ="
"M
X",0.43652037617554856,"2m
X"
"M
X",0.4373040752351097,"j=1
(−1)j⟨w(t)
j , w∗⟩+ η"
"M
X",0.43808777429467083,"2m
X j=1 X"
"M
X",0.438871473354232,"i∈F(t)
˙σ(⟨w(t)
j , xi⟩)ˆyi⟨w∗, xi⟩."
"M
X",0.4396551724137931,"Since ˆyi⟨w∗, xi⟩≥1 for all i ∈[n], the above expression is bounded below by"
"M
X",0.44043887147335425,"2m
X"
"M
X",0.44122257053291536,"j=1
(−1)j⟨w(t)
j , w∗⟩+ η"
"M
X",0.44200626959247646,"2m
X j=1 X"
"M
X",0.4427899686520376,"i∈F(t)
˙σ(⟨w(t)
j , xi⟩)ˆyi = F(t) + η"
"M
X",0.44357366771159873,"2m
X j=1 X"
"M
X",0.4443573667711599,"i∈F(t)
˙σ(⟨w(t)
j , xi⟩)"
"M
X",0.445141065830721,≥F(t) + η
"M
X",0.44592476489028215,"2m
X j=1 X"
"M
X",0.44670846394984326,"i∈F(t)
α"
"M
X",0.44749216300940436,≥F(t) + 2ηmα|F(t)|.
"M
X",0.4482758620689655,Hence unrolling the update for GD for all t ≥0 it follows that
"M
X",0.44905956112852663,"F(t + 1) ≥F(0) + 2ηmα t−1
X"
"M
X",0.4498432601880878,"s=0
|F(s)|."
"M
X",0.4506269592476489,"At initialization, by equation 10 then"
"M
X",0.45141065830721006,F(0) =
"M
X",0.45219435736677116,"2m
X"
"M
X",0.45297805642633227,"j=1
(−1)j⟨w(0)
j , w∗⟩ ≥−"
"M
X",0.4537617554858934,"2m
X"
"M
X",0.45454545454545453,"j=1
∥w(0)
j ∥· ∥w∗∥ ≥−"
"M
X",0.4553291536050157,"2m
X j=1 ∥w∗∥2 αm"
"M
X",0.4561128526645768,"= −2∥w∗∥2 α
."
"M
X",0.45689655172413796,"Therefore by induction, for all t ≥0 we have"
"M
X",0.45768025078369906,F(t) ≥−2∥w∗∥2
"M
X",0.45846394984326017,"α
+ 2ηmα t−1
X"
"M
X",0.4592476489028213,"s=0
|F(s)|"
"M
X",0.46003134796238243,= −2∥w∗∥2
"M
X",0.4608150470219436,"α
+ 2ηmαU(t)."
"M
X",0.4615987460815047,"Combining our bounds for F(t) and G(t), we obtain"
"M
X",0.46238244514106586,−2∥w∗∥2
"M
X",0.46316614420062696,"α
+ 2ηmαU(t) ≤F(t) ="
"M
X",0.46394984326018807,"2m
X"
"M
X",0.4647335423197492,"j=1
(−1)j⟨w(t)
j , w∗⟩ ≤∥w∗∥"
"M
X",0.46551724137931033,"2m
X"
"M
X",0.4663009404388715,"j=1
∥w(t)
j ∥ ≤∥w∗∥  2m"
"M
X",0.4670846394984326,"2m
X"
"M
X",0.46786833855799376,"j=1
∥w(t)
j ∥2   1/2"
"M
X",0.46865203761755486,= ∥w∗∥(2mG(t))1/2
"M
X",0.46943573667711597,"≤∥w∗∥
4∥w∗∥2"
"M
X",0.4702194357366771,"α2
+ 6mηU(t)
1/2
."
"M
X",0.47100313479623823,This implies that either
"M
X",0.4717868338557994,−2∥w∗∥2
"M
X",0.4725705329153605,"α
+ 2ηmαU(t) ≤0
(12)"
"M
X",0.47335423197492166,"or

−2∥w∗∥2"
"M
X",0.47413793103448276,"α
+ 2ηmαU(t)
2
≤∥w∗∥2
4∥w∗∥2"
"M
X",0.47492163009404387,"α2
+ 6mηU(t)

.
(13)"
"M
X",0.475705329153605,"If (12) holds, then"
"M
X",0.47648902821316613,U(t) ≤∥w∗∥2
"M
X",0.4772727272727273,ηα2m .
"M
X",0.4780564263322884,"If (13) holds, then rearranging yields"
"M
X",0.4788401253918495,4η2m2α2U(t)2 ≤14∥w∗∥2ηmU(t)
"M
X",0.47962382445141066,U(t) ≤7∥w∗∥2
"M
X",0.48040752351097177,2ηα2m .
"M
X",0.48119122257053293,"Therefore, in both cases there exists a constant C such that"
"M
X",0.48197492163009403,U(t) ≤C∥w∗∥2
"M
X",0.4827586206896552,"ηα2m .
(14)"
"M
X",0.4835423197492163,"This holds for all t ∈N and therefore
∞
X"
"M
X",0.4843260188087774,"t=0
|F(t)| ≤C∥w∗∥2"
"M
X",0.48510971786833856,"ηα2m
< ∞."
"M
X",0.48589341692789967,"This implies that there exists s ∈N such that |F(s)| = 0. Let T ∈N be the minimal iteration such
that |F(T )| = 0. Then for all i ∈[n] ˆyif(W (T ), xi) ≥1. So the network achieves zero loss and also
has zero gradient at iteration T. In particular, T ="
"M
X",0.48667711598746083,"T −1
X"
"M
X",0.48746081504702193,"t=0
1 ≤"
"M
X",0.4882445141065831,"T −1
X"
"M
X",0.4890282131661442,"t=0
|F(t)| ≤C∥w∗∥2"
"M
X",0.4898119122257053,ηα2m .
"M
X",0.49059561128526646,To bound |AGD| we combine equations (14) and (11) to obtain
"M
X",0.49137931034482757,G(T) ≤2∥w∗∥2
"M
X",0.49216300940438873,"α2m
+ 3ηU(t)"
"M
X",0.49294670846394983,≤2∥w∗∥2
"M
X",0.493730407523511,"α2m
+ C∥w∗∥2 ηα2m"
"M
X",0.4945141065830721,"≤C∥w∗∥2 α2m
."
"M
X",0.4952978056426332,"As a result for all linearly separable datasets (X, ˆy) ∥W ∥F"
"M
X",0.49608150470219436,"∥w∗∥=
C
α√m"
"M
X",0.49686520376175547,"and therefore
|AGD| ≤
C
α√m
as claimed."
"M
X",0.49764890282131663,"The training dynamics of gradient descent also give us the following result relating the linearization
of the noise component of the network to the noise component of the network itself.
Lemma D.1. Let λ, δ > 0. Suppose that d ≥Ω
 
n + log 1"
"M
X",0.49843260188087773,"δ

. In the context of training data (X, ˆy)
sampled under the data model given in Definition 2.1, let W = AGD(X, ˆy, η, λ). Then with
probability at least 1 −δ over the randomness of (X, ˆy)"
"M
X",0.4992163009404389,"∥Z∥2
F −2λ
√"
"M
X",0.5,2m∥Z∥F −2mλ2 ≤C
"M
X",0.5007836990595611,αm (∥zlin∥+ 2mλ)2 .
"M
X",0.5015673981191222,"Proof. At each iteration of gradient descent,"
"M
X",0.5023510971786834,"w(t+1)
j
= w(t)
j
+ η(−1)j
n
X"
"M
X",0.5031347962382445,"i=1
b(t)
ij ˆyixi, where"
"M
X",0.5039184952978056,"b(t)
ij = 

 
"
"M
X",0.5047021943573667,"0
if ˆyif(W (t), xi) ≥1
1
if ˆyif(W (t), xi) < 1 and ⟨w(t)
j , xi⟩≥0
α
otherwise.
."
"M
X",0.5054858934169278,"Let T be the iteration at which gradient descent terminates. Then for each j ∈[2m],"
"M
X",0.5062695924764891,"wj = w(T )
j
= w(0)
j
+ η(−1)j
T −1
X t=0 n
X"
"M
X",0.5070532915360502,"i=1
b(t)
ij ˆyixi."
"M
X",0.5078369905956113,Then the noise component of wj is given by
"M
X",0.5086206896551724,"zj = wj −⟨wj, v⟩v"
"M
X",0.5094043887147336,"= w(0)
j
−⟨w(0)
j , v⟩v + η(−1)j
T −1
X t=0 n
X"
"M
X",0.5101880877742947,"i=1
b(t)
ij ˆyi(xi −⟨xi, v⟩v)"
"M
X",0.5109717868338558,"= w(0)
j
−⟨w(0)
j , v⟩v + η(−1)j
T −1
X t=0 n
X"
"M
X",0.5117554858934169,"i=1
b(t)
ij ˆyini."
"M
X",0.512539184952978,"Define
ˆzj = zj −w(0)
j
+ ⟨w(0)
j , v⟩v
and let"
"M
X",0.5133228840125392,ˆzlin =
"M
X",0.5141065830721003,"2m
X"
"M
X",0.5148902821316614,"j=1
(−1)j ˆzj,"
"M
X",0.5156739811912225,"Then for all j ∈[2n],"
"M
X",0.5164576802507836,(∥ˆzj∥−∥zj∥)2 ≤∥ˆzj −zj∥2
"M
X",0.5172413793103449,"= ∥w(0)
j
−⟨w(0)
j , v⟩v∥2"
"M
X",0.518025078369906,"≤∥w(0)
j ∥2 ≤λ2."
"M
X",0.5188087774294671,"Furthermore, if ∥zj∥≤∥ˆzj∥then the above implies ∥ˆzj∥≤∥zj∥+ λ while if ∥zj∥≥∥ˆzj∥then
this inequality holds trivially. As a result,
∥ˆzj∥2 −∥zj∥2 = |(∥ˆzj∥+ ∥zj∥) · (∥ˆzj∥−∥zj∥)|"
"M
X",0.5195924764890282,"≤|∥ˆzj∥+ ∥zj∥| · |∥ˆzj∥−∥zj∥)|
≤(2∥zj∥+ λ)(λ)."
"M
X",0.5203761755485894,"If ∥zj∥≥∥ˆzj∥then the above implies ∥ˆzj∥2 ≥∥zj∥2 −λ(2∥zj∥+ λ), if ∥zj∥≤∥ˆzj∥this
inequality is trivially true. As a result,"
"M
X",0.5211598746081505,"2m
X"
"M
X",0.5219435736677116,"j=1
∥ˆzj∥2 ≥"
"M
X",0.5227272727272727,"2m
X"
"M
X",0.5235109717868338,"j=1
(∥zj∥2 −λ(2∥zj∥+ λ)) ="
"M
X",0.524294670846395,"2m
X"
"M
X",0.5250783699059561,"j=1
∥zj∥2 −2λ"
"M
X",0.5258620689655172,"2m
X"
"M
X",0.5266457680250783,"j=1
∥zj∥−2mλ2 ≥"
"M
X",0.5274294670846394,"2m
X"
"M
X",0.5282131661442007,"j=1
∥zj∥2 −2λ
√"
M,0.5289968652037618,2m 
M,0.5297805642633229,"
2m
X"
M,0.530564263322884,"j=1
∥zj∥2   1/2 −2mλ2"
M,0.5313479623824452,"= ∥Z∥2
F −2λ
√"
M,0.5321316614420063,"2m∥Z∥F −2mλ2,
(15)"
M,0.5329153605015674,"where the third line is an application of Cauchy-Schwarz. Moreover,"
M,0.5336990595611285,∥ˆzlin −zlin∥= 
"M
X",0.5344827586206896,"2m
X"
"M
X",0.5352664576802508,"j=1
(−1)j(ˆzj −zj)  ≤"
"M
X",0.5360501567398119,"2m
X"
"M
X",0.536833855799373,"j=1
∥ˆzj −zj∥ ≤"
"M
X",0.5376175548589341,"2m
X j=1
λ ≤2mλ, so"
"M
X",0.5384012539184952,"∥ˆzlin∥≥∥zlin∥−2mλ.
(16)"
"M
X",0.5391849529780565,"Let N ′ ∈Rd×n to be the matrix whose i-th column is ˆyini, equivalently N ′ = Ndiag(ˆy). Then"
"M
X",0.5399686520376176,"ˆzj = η(−1)jN ′cj,"
"M
X",0.5407523510971787,where cj ∈Rn is given by
"M
X",0.5415360501567398,(cj)i =
"M
X",0.542319749216301,"T −1
X"
"M
X",0.5431034482758621,"t=0
b(t)
ij ."
"M
X",0.5438871473354232,"Due to symmetry of the noise distribution then the columns of N ′ are i.i.d. with distribution
N(0d, d−1(Id −vvT )). Therefore by Lemma 4.1 (and the assumptions d = Ω
 
n + log 1"
"M
X",0.5446708463949843,"δ

), with
probability at least 1 −δ over the randomness of the training data there exist positive constants C′, C
such that C′ ≤σmin(N ′) ≤σmax(N ′) ≤C. As a result"
"M
X",0.5454545454545454,"C′η∥cj∥≤∥ˆzj∥≤Cη∥cj∥.
(17)"
"M
X",0.5462382445141066,"We claim that for any j, j′ ∈[2m] and i ∈[n], (cj)i ≥α(cj′)i. Indeed, if ˆyif(W (t), xi) ≥1, then
b(t)
ij = b(t)
ij′ = 0, and if ˆyif(W (t), xi) < 1, then both b(t)
ij and b(t)
ij′ are elements of {α, 1}. This in
particular implies that"
"M
X",0.5470219435736677,"⟨cj, cj′⟩≥α⟨cj, cj⟩."
"M
X",0.5478056426332288,Let us define
"M
X",0.54858934169279,clin =
"M
X",0.549373040752351,"2m
X"
"M
X",0.5501567398119123,"j=1
cj. Then"
"M
X",0.5509404388714734,∥ˆzlin∥2 = 
"M
X",0.5517241379310345,"2m
X"
"M
X",0.5525078369905956,"j=1
(−1)j ˆzj  2 = "
"M
X",0.5532915360501567,"2m
X"
"M
X",0.5540752351097179,"j=1
ηN ′cj  2 ≤Cη2 "
"M
X",0.554858934169279,"2m
X"
"M
X",0.5556426332288401,"j=1
cj  2"
"M
X",0.5564263322884012,"= Cη2∥clin∥2,
(18)"
"M
X",0.5572100313479624,where we used that ∥N ′∥≤C in the third line. We also have
"M
X",0.5579937304075235,∥clin∥2 =
"M
X",0.5587774294670846,"2m
X j=1"
"M
X",0.5595611285266457,"2m
X"
"M
X",0.5603448275862069,"j′=1
⟨cj, cj′⟩ ≥α"
"M
X",0.5611285266457681,"2m
X j=1"
"M
X",0.5619122257053292,"2m
X"
"M
X",0.5626959247648903,"j′=1
⟨cj, cj⟩ = 2αm"
"M
X",0.5634796238244514,"2m
X"
"M
X",0.5642633228840125,"j=1
∥cj∥2.
(19)"
"M
X",0.5650470219435737,"Finally we combine our bounds for c, z, and ˆz:"
"M
X",0.5658307210031348,"∥Z∥2
F −2λ
√"
"M
X",0.5666144200626959,2m∥Z∥F −2mλ2 ≤
"M
X",0.567398119122257,"2m
X"
"M
X",0.5681818181818182,"j=1
∥ˆzj∥2"
"M
X",0.5689655172413793,"≤Cη2
2m
X"
"M
X",0.5697492163009404,"j=1
∥cj∥2 ≤Cη2"
"M
X",0.5705329153605015,αm ∥clin∥2 ≤C
"M
X",0.5713166144200627,αm∥ˆzlin∥2 ≤C
"M
X",0.5721003134796239,αm (∥zlin∥+ 2mλ)2 .
"M
X",0.572884012539185,"Here we applied equations (15) in the first line, (17) in the second line, (19) in the third line, (18) in
the fourth line, and (16) in the fifth line. This establishes both the bounds claimed."
"M
X",0.5736677115987461,"D.2
Benign overfitting"
"M
X",0.5744514106583072,"To establish benign overfitting in leaky ReLU networks, we first determine an upper bound on the
generalization error of the model in terms of the signal-to-noise ratio of the network weights.
Lemma D.2. Let ϵ ∈(0, 1). Suppose that"
"M
X",0.5752351097178683,"Amin
∥Z∥F
≥C2 s"
"M
X",0.5760188087774295,(1 −γ)m log 1
"M
X",0.5768025078369906,"ϵ
γd
."
"M
X",0.5775862068965517,"Then for test data (x, y) as per Definition 2.1,"
"M
X",0.5783699059561128,"P(yf(W , x) ≤0) ≤ϵ."
"M
X",0.579153605015674,"Proof. Recall that a test point (x, y) satisfies"
"M
X",0.5799373040752351,"x = y(√γv +
p"
"M
X",0.5807210031347962,"1 −γn),"
"M
X",0.5815047021943573,"where n ∼N(0d, 1"
"M
X",0.5822884012539185,"d(Id −vvT )). If yf(W , x) ≤0, then"
"M
X",0.5830721003134797,"0 ≥yf(W , x) ="
"M
X",0.5838557993730408,"2m
X"
"M
X",0.5846394984326019,"j=1
(−1)jyσ(⟨wj, x⟩) ="
"M
X",0.585423197492163,"2m
X"
"M
X",0.5862068965517241,"j=1
(−1)jyσ(⟨ajv + zj, y(√γv +
p"
"M
X",0.5869905956112853,1 −γn⟩) =
"M
X",0.5877742946708464,"2m
X"
"M
X",0.5885579937304075,"j=1
(−1)jyσ(y(√γaj +
p"
"M
X",0.5893416927899686,"1 −γ⟨zj, n⟩)) ≥"
"M
X",0.5901253918495298,"2m
X"
"M
X",0.5909090909090909,"j=1
(−1)jyσ(y√γaj) −"
"M
X",0.591692789968652,"2m
X j=1 p"
"M
X",0.5924764890282131,"1 −γ|⟨zj, n⟩|"
"M
X",0.5932601880877743,= √γAy −
"M
X",0.5940438871473355,"2m
X j=1 p"
"M
X",0.5948275862068966,"1 −γ|⟨zj, n⟩|."
"M
X",0.5956112852664577,"When Amin ≥0, this implies that"
"M
X",0.5963949843260188,"γA2
min ≤(1 −γ) "
"M
X",0.5971786833855799,"
2m
X"
"M
X",0.5979623824451411,"j=1
|⟨zj, n⟩|   2"
"M
X",0.5987460815047022,≤2m(1 −γ)
"M
X",0.5995297805642633,"2m
X"
"M
X",0.6003134796238244,"j=1
|⟨zj, n⟩|2"
"M
X",0.6010971786833855,= 2m(1 −γ)∥Zn∥2
"M
X",0.6018808777429467,"≤2m(1 −γ)∥Z∥2
F ∥n∥2,"
"M
X",0.6026645768025078,where the second inequality is an application of Cauchy-Schwarz. So
"M
X",0.603448275862069,"P(yf(W , x) ≤0) ≤P

∥Zn∥2 ≥
γA2
min
2m(1 −γ) 
."
"M
X",0.60423197492163,"By Lemma A.1, the above probability is less than ϵ if
r
γ
2m(1 −γ)Amin ≥C∥Z∥F r"
"M
X",0.6050156739811913,"1
d log 1 ϵ ,"
"M
X",0.6057993730407524,"or equivalently,"
"M
X",0.6065830721003135,"Amin
∥Z∥F
≥C2 s"
"M
X",0.6073667711598746,(1 −γ)m log 1
"M
X",0.6081504702194357,"ϵ
γd
."
"M
X",0.6089341692789969,"We will also need the number of positive labels to be (mildly) balanced with the number of negative
labels.
Lemma D.3. Let δ > 0 and suppose that ℓ= Ω
 
log 1"
"M
X",0.609717868338558,"δ

. Let I ⊆[n] be an arbitrary subset such
that |I| = ℓ. Consider training data (X, y) as per the data model given in Definition 2.1. Then with
probability at least 1 −δ,
ℓ
4 ≤|{i ∈S : yi = 1}| ≤3ℓ 4 ."
"M
X",0.6105015673981191,"Proof. For i ∈I let Yi be a random variable taking the value 1 if yi = 1 and 0 if yi = −1. Then the
Yi are i.i.d. Bernoulli random variables with P(Yi = 1) = 1"
LET,0.6112852664576802,"2. Let Y =
X"
LET,0.6120689655172413,"i∈I
Yi = |{i ∈S : yi = 1}|"
LET,0.6128526645768025,so that E[Y ] = l
LET,0.6136363636363636,"2. By Chernoff’s inequality, for all t ∈(0, 1),"
LET,0.6144200626959248,"P
Y −ℓ 2 ≥t ℓ 2"
LET,0.6152037617554859,"
≤2e−Cℓt2."
LET,0.6159874608150471,Setting t = 1
LET,0.6167711598746082,"2, we see that ℓ"
LET,0.6175548589341693,4 ≤Y ≤3ℓ
WITH PROBABILITY AT LEAST,0.6183385579937304,4 with probability at least
WITH PROBABILITY AT LEAST,0.6191222570532915,"1 −2 exp

−Cℓ 4"
WITH PROBABILITY AT LEAST,0.6199059561128527,"
≥1 −δ"
WITH PROBABILITY AT LEAST,0.6206896551724138,"when ℓ= Ω
 
log 1 δ

."
WITH PROBABILITY AT LEAST,0.6214733542319749,We are now able to prove our main benign overfitting result for leaky ReLU networks.
WITH PROBABILITY AT LEAST,0.622257053291536,"Theorem 3.2. Under the setting given in Assumption 2, let δ ∈(0, 1) and suppose A is approximately
margin-maximizing (Definition 2.3). If n = Ω
 
log 1"
WITH PROBABILITY AT LEAST,0.6230407523510971,"δ

, d = Ω(n), k = O(
n
1+m|A|2 ), and γ = Ω
  1 k
"
WITH PROBABILITY AT LEAST,0.6238244514106583,"then there is a fixed positive constant C such that with probability at least 1 −δ over (X, ˆy)"
WITH PROBABILITY AT LEAST,0.6246081504702194,"P(yf(W , x) ≤0 | X, ˆy) ≤exp

−C ·
d
k(1 + m|A|2) 
."
WITH PROBABILITY AT LEAST,0.6253918495297806,"Proof. Since d = Ω(n) = Ω
 
n + log 1"
WITH PROBABILITY AT LEAST,0.6261755485893417,"δ

, by Lemma B.3, with probability at least 1 −δ"
OVER THE,0.6269592476489029,"3 over the
randomness of the data, the max-margin classifier w∗satisfies"
OVER THE,0.627742946708464,∥w∗∥≤C s
OVER THE,0.6285266457680251,"1
γ +
k
1 −γ ."
OVER THE,0.6293103448275862,"We denote this event by ω1. For s ∈{1, −1}, let Gs denote the set of i ∈G such that ⟨v, xi⟩= s. If
n = Ω
  1"
OVER THE,0.6300940438871473,"δ

and k = O(n), then |G| = Ω
 
log 1"
OVER THE,0.6308777429467085,"δ

. Under these assumptions, by Lemma D.3,"
OVER THE,0.6316614420062696,|Gs| ≥1
OVER THE,0.6324451410658307,4|G| ≥Cn
OVER THE,0.6332288401253918,"for both s ∈{1, −1} with probability at least 1 −δ"
OVER THE,0.6340125391849529,"3. We denote this event by ω2. For s ∈{1, −1},
let NGs ∈R|Gs|×d be the matrix whose rows are indexed by Gs and are given by the vectors ni
for i ∈Gs. As d = Ω(n) = Ω
 
n + log 1"
OVER THE,0.6347962382445141,"δ

and the rows of NGs are drawn mutually i.i.d. from
N(0d, d−1(Id −vT )), the following holds by Lemma 4.1. With probability at least 1 −δ"
OVER THE,0.6355799373040752,"3 over the
randomness of the training data, ∥NGs∥≤C for both s ∈{1, −1}. We denote this event by ω3. Let
ω = ω1 ∩ω2 ∩ω3. By the union bound P(ω) ≥1 −δ. We condition on ω for the remainder of this
proof."
OVER THE,0.6363636363636364,"Since W = A(X, ˆy) and A is approximately margin maximizing,"
OVER THE,0.6371473354231975,∥W ∥F ≤|A| · ∥w∗∥ ≤C|A| s
OVER THE,0.6379310344827587,"1
γ +
k
1 −γ .
(20)"
OVER THE,0.6387147335423198,"Let s ∈{−1, 1} be such that As = Amin. Since the network attains zero loss, for all i ∈Gs,"
OVER THE,0.6394984326018809,"1 ≤ˆyif(W , xi) ="
"M
X",0.640282131661442,"2m
X"
"M
X",0.6410658307210031,"j=1
(−1)j ˆyiσ(⟨wj, xi⟩) ="
"M
X",0.6418495297805643,"2m
X"
"M
X",0.6426332288401254,"j=1
(−1)jyiσ(⟨ajv + zj, √γyiv +
p"
"M
X",0.6434169278996865,1 −γni⟩) =
"M
X",0.6442006269592476,"2m
X"
"M
X",0.6449843260188087,"j=1
(−1)jyiσ(√γajyi +
p"
"M
X",0.64576802507837,"1 −γ⟨zj, ni⟩) ≤"
"M
X",0.646551724137931,"2m
X"
"M
X",0.6473354231974922,"j=1
(−1)jyiσ(√γajyi) +"
"M
X",0.6481191222570533,"2m
X"
"M
X",0.6489028213166145,"j=1
|
p"
"M
X",0.6496865203761756,"1 −γ⟨zj, ni⟩| = √γ"
"M
X",0.6504702194357367,"2m
X"
"M
X",0.6512539184952978,"j=1
(−1)jsσ(saj) +
p 1 −γ"
"M
X",0.6520376175548589,"2m
X"
"M
X",0.6528213166144201,"j=1
|⟨zj, ni⟩|"
"M
X",0.6536050156739812,"= √γAs +
p 1 −γ"
"M
X",0.6543887147335423,"2m
X"
"M
X",0.6551724137931034,"j=1
|⟨zj, ni⟩|"
"M
X",0.6559561128526645,"= √γAmin +
p 1 −γ"
"M
X",0.6567398119122257,"2m
X"
"M
X",0.6575235109717869,"j=1
|⟨zj, ni⟩|."
"M
X",0.658307210031348,"Hence, we have either √γAs ≥1"
"M
X",0.6590909090909091,"2 or √1 −γ P2m
j=1 |⟨zj, ni⟩| ≥1"
"M
X",0.6598746081504702,"2 for all i ∈Gs. We consider these
two cases separately."
"M
X",0.6606583072100314,If √γAmin ≥1
"M
X",0.6614420062695925,"2, then"
"M
X",0.6622257053291536,"Amin
∥Z∥F
≥Amin ∥W ∥F"
"M
X",0.6630094043887147,"≥
1
2√γ∥W ∥F"
"M
X",0.6637931034482759,"≥C
1
√γ|A|
q"
"M
X",0.664576802507837,"1
γ +
k
1−γ = C
1 |A|
q"
"M
X",0.6653605015673981,"1 +
kγ
1−γ ≥C
1"
"M
X",0.6661442006269592,"|A| + |A|
q"
"M
X",0.6669278996865203,"kγ
1−γ
."
"M
X",0.6677115987460815,"Then by Lemma D.2, the network has generalization error less than ϵ when 1"
"M
X",0.6684952978056427,"|A| + |A|
q"
"M
X",0.6692789968652038,"kγ
1−γ
≥C s"
"M
X",0.6700626959247649,"(1 −γ)m log 1 ϵ
γd"
"M
X",0.670846394984326,"or equivalently
s"
"M
X",0.6716300940438872,(1 −γ)m log 1
"M
X",0.6724137931034483,"ϵ
γd
+ s"
"M
X",0.6731974921630094,mk log 1
"M
X",0.6739811912225705,"ϵ
d
≤C |A|."
"M
X",0.6747648902821317,"This is satisfied for ϵ = exp(−C ·
d
k(1+m|A|2)) for some different constant C when γ = Ω( 1"
"M
X",0.6755485893416928,"k), which
is true by assumption. So if √γAmin ≥1"
"M
X",0.6763322884012539,"2, then the network has generalization error less than ϵ
whenever ω occurs, which happens with probability at least 1 −δ."
"M
X",0.677115987460815,"Now suppose that √1 −γ P2m
j=1 |⟨zj, ni⟩| ≥1"
"M
X",0.6778996865203761,"2 for all i ∈Gs. Squaring both sides of the inequality
and applying Cauchy-Schwarz, we obtain"
"M
X",0.6786833855799373,"1
4 ≤(1 −γ) "
"M
X",0.6794670846394985,"
2m
X"
"M
X",0.6802507836990596,"j=1
|⟨zj, ni⟩|   2"
"M
X",0.6810344827586207,≤2m(1 −γ)
"M
X",0.6818181818181818,"2m
X"
"M
X",0.682601880877743,"j=1
|⟨zj, ni⟩|2."
"M
X",0.6833855799373041,"Summing over all i ∈Gs, we obtain |Gs|"
"M
X",0.6841692789968652,"4
≤2m(1 −γ)
X i∈Gs"
"M
X",0.6849529780564263,"2m
X"
"M
X",0.6857366771159875,"j=1
|⟨zj, ni⟩|2"
"M
X",0.6865203761755486,= 2m(1 −γ)
"M
X",0.6873040752351097,"2m
X"
"M
X",0.6880877742946708,"j=1
∥NGszj∥2,"
"M
X",0.6888714733542319,"Applying ω2 and ω3, we obtain the bound"
"M
X",0.6896551724137931,n ≤Cm(1 −γ)
"M
X",0.6904388714733543,"2m
X"
"M
X",0.6912225705329154,"j=1
∥NGszj∥2"
"M
X",0.6920062695924765,≤Cm(1 −γ)
"M
X",0.6927899686520376,"2m
X"
"M
X",0.6935736677115988,"j=1
∥NGs∥2∥zj∥2"
"M
X",0.6943573667711599,≤Cm(1 −γ)
"M
X",0.695141065830721,"2m
X"
"M
X",0.6959247648902821,"j=1
∥zj∥2"
"M
X",0.6967084639498433,"= Cm(1 −γ)∥Z∥2
F
≤Cm(1 −γ)∥W ∥2
F ."
"M
X",0.6974921630094044,"Then applying (20),"
"M
X",0.6982758620689655,"n ≤Cm(1 −γ)∥W ∥2
F"
"M
X",0.6990595611285266,"≤Cm(1 −γ)|A|2
 1"
"M
X",0.6998432601880877,"γ +
k
1 −γ "
"M
X",0.700626959247649,"≤Cm|A|2
 1"
"M
X",0.70141065830721,"γ + k

."
"M
X",0.7021943573667712,This implies that
"M
X",0.7029780564263323,"n ≤Cm|A|2 γ
or"
"M
X",0.7037617554858934,"k ≥
Cn
m|A|2 ."
"M
X",0.7045454545454546,"Neither of these conditions can occur if γ = Ω
  1"
"M
X",0.7053291536050157,"k

and k = O

n
|A|2m

. Thus, in all cases, the"
"M
X",0.7061128526645768,"network has generalization error less than exp(−C ·
d
k(1+m|A|2)) when ω occurs, which happens
with probability at least 1 −δ."
"M
X",0.7068965517241379,"We are also able to show the lower bound for the generalization error stated in the main text.
Theorem 3.3. Under the setting given in Assumption 2, let δ ∈(0, 1) and suppose A = AGD where
η, λ ∈R>0 satisfy Assumption 1. If n = Ω(k), d = Ω(n), and k = Ω(log 1 δ + 1"
"M
X",0.707680250783699,"α), then there is a
fixed positive constant C such that with probability at least 1 −δ over (X, ˆy)"
"M
X",0.7084639498432602,"P(yf(W , x) ≤0 | X, ˆy) ≥exp

−C · d αk 
."
"M
X",0.7092476489028213,"Proof. We proceed along the lines of Theorem 3.2. For s ∈{1, −1}, let Bs denote the set of i ∈B
such that ⟨v, xi⟩= s. Note |B| = Ω
 
log 1"
"M
X",0.7100313479623824,"δ

. Under these assumptions, by Lemma D.3,"
"M
X",0.7108150470219435,|Bs| ≥1
"M
X",0.7115987460815048,4|B| ≥Ck
"M
X",0.7123824451410659,"for both s ∈{1, −1} with probability at least 1 −δ"
"M
X",0.713166144200627,"3. We denote this event by ω1. For s ∈{1, −1},
let NBs ∈R|Bs|×d be the matrix whose rows are indexed by Bs and are given by the vectors ni
for i ∈Bs. As d = Ω(n) = Ω
 
k + log 1"
"M
X",0.7139498432601881,"δ

and the rows of NBs are drawn mutually i.i.d. from
N(0d, d−1(Id −vT )), the following holds by Lemma 4.1. With probability at least 1 −δ"
OVER THE,0.7147335423197492,"3 over the
randomness of the training data, ∥NBs∥≤C for both s ∈{1, −1}. We denote this event by ω2. By
Lemma D.1, there is a constant C such that"
OVER THE,0.7155172413793104,"∥Z∥2
F −2λ
√"
OVER THE,0.7163009404388715,2m∥Z∥F −2mλ2 ≤C
OVER THE,0.7170846394984326,"αm (∥zlin∥+ 2mλ)2 .
(21)"
OVER THE,0.7178683385579937,with probability at least 1 −δ
OVER THE,0.7186520376175548,"3. We denote this event by ω3. Let ω = ω1 ∩ω2 ∩ω3. By the union
bound P(ω) ≥1 −δ. We condition on ω for the remainder of this proof."
OVER THE,0.719435736677116,"Let s ∈{1, −1} be such that As = max{A1, A−1}. Since the network attains zero loss, for all
i ∈Bs,
1 ≤ˆyif(W , xi) ="
"M
X",0.7202194357366771,"2m
X"
"M
X",0.7210031347962382,"j=1
(−1)j ˆyiσ(⟨wj, xi⟩) ="
"M
X",0.7217868338557993,"2m
X"
"M
X",0.7225705329153606,"j=1
(−1)jyiσ(⟨ajv + zj, −√γyiv +
p"
"M
X",0.7233542319749217,1 −γni⟩) =
"M
X",0.7241379310344828,"2m
X"
"M
X",0.7249216300940439,"j=1
(−1)jyiσ(−√γajyi +
p"
"M
X",0.725705329153605,"1 −γ⟨zj, ni⟩) ≤"
"M
X",0.7264890282131662,"2m
X"
"M
X",0.7272727272727273,"j=1
(−1)jyiσ(−√γajyi) +"
"M
X",0.7280564263322884,"2m
X"
"M
X",0.7288401253918495,"j=1
|
p"
"M
X",0.7296238244514106,"1 −γ⟨zj, ni⟩| = √γ"
"M
X",0.7304075235109718,"2m
X"
"M
X",0.7311912225705329,"j=1
(−1)j+1sσ(saj) +
p 1 −γ"
"M
X",0.731974921630094,"2m
X"
"M
X",0.7327586206896551,"j=1
|⟨zj, ni⟩|"
"M
X",0.7335423197492164,"= −√γAs +
p 1 −γ"
"M
X",0.7343260188087775,"2m
X"
"M
X",0.7351097178683386,"j=1
|⟨zj, ni⟩|."
"M
X",0.7358934169278997,"From which we conclude
p 1 −γ"
"M
X",0.7366771159874608,"2m
X"
"M
X",0.737460815047022,"j=1
|⟨zj, ni⟩| ≥1 + √γAs ≥√γAs"
"M
X",0.7382445141065831,"for all such i. Squaring both sides of the inequality and applying Cauchy-Schwarz, we obtain"
"M
X",0.7390282131661442,γAs ≤(1 −γ) 
"M
X",0.7398119122257053,"
2m
X"
"M
X",0.7405956112852664,"j=1
|⟨zj, ni⟩|   2"
"M
X",0.7413793103448276,≤2m(1 −γ)
"M
X",0.7421630094043887,"2m
X"
"M
X",0.7429467084639498,"j=1
|⟨zj, ni⟩|2."
"M
X",0.7437304075235109,"Summing over all i ∈Bs, we obtain"
"M
X",0.7445141065830722,"|Bs|γAs ≤2m(1 −γ)
X i∈Bs"
"M
X",0.7452978056426333,"2m
X"
"M
X",0.7460815047021944,"j=1
|⟨zj, ni⟩|2"
"M
X",0.7468652037617555,= 2m(1 −γ)
"M
X",0.7476489028213166,"2m
X"
"M
X",0.7484326018808778,"j=1
∥NBszj∥2,"
"M
X",0.7492163009404389,"Applying ω2 and ω3, we obtain the bound"
"M
X",0.75,kγAs ≤Cm(1 −γ)
"M
X",0.7507836990595611,"2m
X"
"M
X",0.7515673981191222,"j=1
∥NBszj∥2"
"M
X",0.7523510971786834,≤Cm(1 −γ)
"M
X",0.7531347962382445,"2m
X"
"M
X",0.7539184952978056,"j=1
∥NBs∥2∥zj∥2"
"M
X",0.7547021943573667,≤Cm(1 −γ)
"M
X",0.7554858934169278,"2m
X"
"M
X",0.7562695924764891,"j=1
∥zj∥2"
"M
X",0.7570532915360502,"= Cm(1 −γ)∥Z∥2
F ."
"M
X",0.7578369905956113,For k = Ω( 1
"M
X",0.7586206896551724,"α), this inequality along with Assumption 1 implies that"
"M
X",0.7594043887147336,"C∥Z∥2
F ≤∥Z∥2
F + 2λ
√"
"M
X",0.7601880877742947,2m∥Z∥F + 2mλ2
"M
X",0.7609717868338558,"for a different constant C. With the last two inequalities and equation 21, we obtain the bound, for a
new constant C."
"M
X",0.7617554858934169,kγAs ≤C 1 −γ
"M
X",0.762539184952978,"α
(∥zlin∥+ 2mλ)2 ."
"M
X",0.7633228840125392,We then apply k = Ω( 1
"M
X",0.7641065830721003,"α) and Assumption 1 again to conclude that for some C,"
"M
X",0.7648902821316614,∥zlin∥≥C s kγAsα
"M
X",0.7656739811912225,1 −γ .
"M
X",0.7664576802507836,"Note that
Alin = A1 + A−1"
"M
X",0.7672413793103449,"1 + α
≤2As."
"M
X",0.768025078369906,"We then bound
Alin
∥zlin∥≤C
As
q kγAsα 1−γ"
"M
X",0.7688087774294671,"≤C
r1 −γ kγα"
"M
X",0.7695924764890282,"for some constant C. Now consider a test point (x, y), which satisfies"
"M
X",0.7703761755485894,"x = y(√γv +
p"
"M
X",0.7711598746081505,"1 −γn),"
"M
X",0.7719435736677116,"where n ∼N(0d, 1"
"M
X",0.7727272727272727,"d(Id −vvT )). Since the data distribution is symmetric,"
"M
X",0.7735109717868338,"P(yf(W , x) ≤0) ≥1"
"M
X",0.774294670846395,"2P(yf(W , x) ≤0 or −yf(W , −x) ≤0) ≥1"
"M
X",0.7750783699059561,"2P(yf(W , x) −yf(W , −x) ≤0)."
"M
X",0.7758620689655172,We see that
"M
X",0.7766457680250783,"yf(W , x) −yf(W , −x) = (1 + α)

yAlin
√γ + ⟨zlin, n⟩
p"
"M
X",0.7774294670846394,"1 −γ
"
"M
X",0.7782131661442007,By Lemma C.1 we then can bound
"M
X",0.7789968652037618,"P(y⟨w, x⟩≤0 | ω) ≥1"
EXP,0.7797805642633229,"8 exp

−6d"
EXP,0.780564263322884,"π
γ
1 −γ
A2
lin
∥zlin∥2 "
EXP,0.7813479623824452,"≥exp

−Cd αk "
EXP,0.7821316614420063,"for a new constant C, provided Alin is positive. In the last line we can bound d"
EXP,0.7829153605015674,"k below as d =
Ω(n) = Ω(k). If Alin is negative, then the generalization error is at least 1"
WHICH IS ALSO AT LEAST,0.7836990595611285,"4 which is also at least
exp(−Cd/(αk))."
WHICH IS ALSO AT LEAST,0.7844827586206896,"D.3
Non-benign overfitting"
WHICH IS ALSO AT LEAST,0.7852664576802508,"In this section we show that leaky ReLU networks trained on low-signal data exhibit non-benign
overfitting. As in the case of benign overfitting, we will rely on a generalization bound which depends
on the signal-to-noise ratio of the network.
Lemma D.4. Let W ∈R2m×d be the first layer weight matrix of a shallow leaky ReLU network
given by equation 1. Suppose (x, y) is a random test point sampled under the data model given in
Definition 2.1. If W is such that Alin ≥0 and Alin"
WHICH IS ALSO AT LEAST,0.7860501567398119,"zlin
= O
r1 −γ γd "
WHICH IS ALSO AT LEAST,0.786833855799373,"then
P(yf(W , x) < 0) ≥1 8."
WHICH IS ALSO AT LEAST,0.7876175548589341,"Alternatively, if Alin ≤0 then"
WHICH IS ALSO AT LEAST,0.7884012539184952,"P(yf(W , x) < 0) ≥1 4."
WHICH IS ALSO AT LEAST,0.7891849529780565,"Proof. By Definition 2.1 (−x, −y) is identically distributed to (x, y), therefore"
WHICH IS ALSO AT LEAST,0.7899686520376176,"P(0 > yf(W , x)) = 1"
WHICH IS ALSO AT LEAST,0.7907523510971787,"2 (P(0 > yf(W , x)) + P(0 > −yf(W , −x))) ≥1"
WHICH IS ALSO AT LEAST,0.7915360501567398,"2P(0 > yf(W , x) ∪0 > −yf(W , −x)) ≥1"
WHICH IS ALSO AT LEAST,0.792319749216301,"2P (0 > yf(W , x) −yf(W , −x)) ."
WHICH IS ALSO AT LEAST,0.7931034482758621,Next we compute
WHICH IS ALSO AT LEAST,0.7938871473354232,"yf(W , x) −yf(W , −x) ="
"M
X",0.7946708463949843,"2m
X"
"M
X",0.7954545454545454,"j=1
(−1)jy(σ(⟨wj, x⟩) −σ(⟨wj, −x⟩))"
"M
X",0.7962382445141066,= (1 + α)
"M
X",0.7970219435736677,"2m
X"
"M
X",0.7978056426332288,"j=1
(−1)jy⟨wj, x⟩"
"M
X",0.79858934169279,= (1 + α)
"M
X",0.799373040752351,"2m
X"
"M
X",0.8001567398119123,"j=1
(−1)j⟨ajv + zj, √γv +
p"
"M
X",0.8009404388714734,1 −γn⟩
"M
X",0.8017241379310345,= (1 + α)√γ
"M
X",0.8025078369905956,"2m
X"
"M
X",0.8032915360501567,"j=1
(−1)jaj + (1 + α)
p 1 −γ * n,"
"M
X",0.8040752351097179,"2m
X"
"M
X",0.804858934169279,"j=1
(−1)jzj +"
"M
X",0.8056426332288401,"= (1 + α)√γAlin + (1 + α)
p"
"M
X",0.8064263322884012,"1 −γ⟨n, zlin⟩."
"M
X",0.8072100313479624,The above two calculations imply that
"M
X",0.8079937304075235,"P(0 > yf(W , x)) ≥1"
"M
X",0.8087774294670846,"2P(0 > yf(W , x) −yf(W , −x)) = 1"
"M
X",0.8095611285266457,"2P(0 > (1 + α)√γAlin + (1 + α)
p"
"M
X",0.8103448275862069,"1 −γ⟨n, zlin⟩) = 1"
P,0.8111285266457681,"2P

⟨−n, zlin⟩>
r
γ
1 −γ Alin 
."
P,0.8119122257053292,"Suppose that Alin ≥0. As the noise distribution is symmetric ⟨n, zlin⟩
d= ⟨−n, zlin⟩. Therefore,"
P,0.8126959247648903,"1
4P

|⟨n, zlin⟩| >
r
γ
1 −γ Alin 
= 1"
P,0.8134796238244514,"4P

|⟨n, u⟩| >
r
γ
1 −γ
Alin
∥zlin∥ 
,"
P,0.8142633228840125,"where u =
zlin
∥zlin∥is the unit vector pointing in the direction of zlin. Note by construction u ∈
span({v})⊥. If"
P,0.8150470219435737,"Alin
∥zlin∥= O
r1 −γ γd 
,"
P,0.8158307210031348,"then by Lemma A.2,"
P,0.8166144200626959,"P

|⟨n, u⟩| >
r
γ
1 −γ
Alin
∥zlin∥ 
≥1 2"
P,0.817398119122257,and therefore
P,0.8181818181818182,"P(0 > yf(W , x)) ≥1"
P,0.8189655172413793,"4P

|⟨n, u⟩| >
r
γ
1 −γ
Alin
∥zlin∥ 
≥1 8."
P,0.8197492163009404,"If Alin < 0, then again by the symmetry of the noise"
P,0.8205329153605015,"P(0 > yf(W , x)) ≥1"
P,0.8213166144200627,"2P

⟨−n, zlin⟩>
r
γ
1 −γ Alin  ≥1"
P,0.8221003134796239,"2P (⟨−n, zlin⟩> 0) = 1 4."
P,0.822884012539185,This establishes the result.
P,0.8236677115987461,"Theorem 3.4. Under the setting given in Assumption 2, let δ ∈(0, 1) and suppose A = AGD,
where η, λ ∈R>0 satisfy Assumption 1. If n = Ω(1), d = Ω
 
n + log 1"
P,0.8244514106583072,"δ

and γ = O

α3"
P,0.8252351097178683,"d

then the
following hold."
P,0.8260188087774295,"1. The algorithm AGD terminates almost surely after finitely many updates. With W =
AGD(X, ˆy), L(W , X, ˆy) = 0."
P,0.8268025078369906,"2. With probability at least 1 −δ over the training data (X, ˆy)"
P,0.8275862068965517,"P(yf(W , x) < 0 | X, ˆy) ≥1 8."
P,0.8283699059561128,"Proof. If Alin < 0, then by Lemma D.4,"
P,0.829153605015674,"P(yf(W , x) < 0) ≥1 4."
P,0.8299373040752351,"So it suffices to consider the case Alin ≥0. Since d = Ω
 
n + log 1"
P,0.8307210031347962,"δ

, by Lemma B.4, the max-margin
classifier w∗satisfies"
P,0.8315047021943573,"∥w∗∥≤C
r
n
1 −γ"
P,0.8322884012539185,with probability at least 1 −δ
P,0.8330721003134797,"3 over the randomness of the input dataset. We denote this event by ω1
and condition on it for the rest of this proof. By Theorem 3.1,"
P,0.8338557993730408,∥W ∥≤C∥w∗∥ α√m ≤C α
P,0.8346394984326019,"r
n
m(1 −γ)."
P,0.835423197492163,"By Theorem 3.1, the network perfectly fits the training data, so for all i ∈[n], ˆyif(W , xi) ≥1, and
therefore"
P,0.8362068965517241,"1 ≤|f(W , xi)| = "
"M
X",0.8369905956112853,"2m
X"
"M
X",0.8377742946708464,"j=1
(−1)jσ(⟨wj, xi⟩)  ≤"
"M
X",0.8385579937304075,"2m
X"
"M
X",0.8393416927899686,"j=1
|⟨wj, xi⟩| ="
"M
X",0.8401253918495298,"2m
X"
"M
X",0.8409090909090909,"j=1
|⟨ajv + zj, √γyiv +
p"
"M
X",0.841692789968652,1 −γni⟩| =
"M
X",0.8424764890282131,"2m
X"
"M
X",0.8432601880877743,"j=1
|ajyi
√γ +
p"
"M
X",0.8440438871473355,"1 −γ⟨zj, ni⟩| ≤√γ"
"M
X",0.8448275862068966,"2m
X"
"M
X",0.8456112852664577,"j=1
|aj| +
p 1 −γ"
"M
X",0.8463949843260188,"2m
X"
"M
X",0.8471786833855799,"j=1
|⟨zj, ni⟩|."
"M
X",0.8479623824451411,This implies that either 1
"M
X",0.8487460815047022,"2 ≤√γ P2m
j=1 |aj| or 1"
"M
X",0.8495297805642633,"2 ≤√1 −γ P2m
j=1 |⟨zj, ni⟩| for all i ∈[n]. We
consider both cases separately."
"M
X",0.8503134796238244,Suppose that 1
"M
X",0.8510971786833855,"2 ≤√γ P2m
j=1 |aj|. Then squaring both sides and applying Cauchy-Schwarz, we obtain"
"M
X",0.8518808777429467,"1
4 ≤γ "
"M
X",0.8526645768025078,"
2m
X"
"M
X",0.853448275862069,"j=1
|aj|   2 ≤2mγ"
"M
X",0.85423197492163,"2m
X"
"M
X",0.8550156739811913,"j=1
|aj|2 ≤2mγ"
"M
X",0.8557993730407524,"2m
X"
"M
X",0.8565830721003135,"j=1
∥wj∥2"
"M
X",0.8573667711598746,"= 2mγ∥W ∥2
F"
"M
X",0.8581504702194357,"≤
Cγn
α2(1 −γ)."
"M
X",0.8589341692789969,"This cannot occur if γ = O

α2"
"M
X",0.859717868338558,"n

, and in particular it cannot occur if d = Ω(n) and γ = O

α3 d

."
"M
X",0.8605015673981191,Now suppose that 1
"M
X",0.8612852664576802,"2 ≤√1 −γ P2m
j=1 |⟨zj, ni⟩| for all i ∈[n]. Squaring both sides and applying
Cauchy-Schwarz, we obtain"
"M
X",0.8620689655172413,"1
4 ≤(1 −γ) "
"M
X",0.8628526645768025,"
2m
X"
"M
X",0.8636363636363636,"j=1
∥⟨zj, ni⟩|   2"
"M
X",0.8644200626959248,≤2m(1 −γ)
"M
X",0.8652037617554859,"2m
X"
"M
X",0.8659874608150471,"j=1
∥⟨zj, ni⟩∥2."
"M
X",0.8667711598746082,"Summing over all i ∈[n], we obtain"
"M
X",0.8675548589341693,"n
4 ≤2m(1 −γ) n
X i=1"
"M
X",0.8683385579937304,"2m
X"
"M
X",0.8691222570532915,"j=1
∥⟨zj, ni⟩∥2"
"M
X",0.8699059561128527,= 2m(1 −γ)
"M
X",0.8706896551724138,"2m
X"
"M
X",0.8714733542319749,"j=1
∥Nzj∥2"
"M
X",0.872257053291536,"≤2m(1 −γ)∥N∥2
2m
X"
"M
X",0.8730407523510971,"j=1
∥zj∥2"
"M
X",0.8738244514106583,"= 2m(1 −γ)∥N∥2∥Z∥2
F ."
"M
X",0.8746081504702194,"Recall that d = Ω
 
n + log 1"
"M
X",0.8753918495297806,"δ

, and that the rows of N are i.i.d. with distribution N(0d, d−1(Id −
vvT )). So by Lemma 4.1, with probability at least 1 −δ"
"M
X",0.8761755485893417,"3 over the randomness of the dataset,
∥N∥≤C. We denote this event by ω2 and condition on it for the rest of this proof. So"
"M
X",0.8769592476489029,"∥Z∥2
F ≥
Cn
m(1 −γ).
(22)"
"M
X",0.877742946708464,"Let λ =
√α"
"M
X",0.8785266457680251,"m . By Assumption 1, ∥w(0)
j ∥≤λ for all j ∈[2m]. So by Lemma D.1,"
"M
X",0.8793103448275862,"∥Z∥2
F −2λ
√"
"M
X",0.8800940438871473,2m∥Z∥F −2mλ2 ≤C
"M
X",0.8808777429467085,"αm(∥zlin∥+ 2mλ)2.
(23)"
"M
X",0.8816614420062696,"By (22),"
"M
X",0.8824451410658307,"∥Z∥F ≥
C√n
p"
"M
X",0.8832288401253918,m(1 −γ)
"M
X",0.8840125391849529,"≥C√n
√m
≥Cλ√nm ≥8λ
√ 2m,"
"M
X",0.8847962382445141,"where the last line holds if n = Ω(1). Then by (23),"
"M
X",0.8855799373040752,"1
2∥Z∥2
F = ∥Z∥2
F −1"
"M
X",0.8863636363636364,"4∥Z∥2
F −1"
"M
X",0.8871473354231975,"4∥Z∥2
F"
"M
X",0.8879310344827587,"≤∥Z∥2
F −2λ
√"
"M
X",0.8887147335423198,2m∥Z∥F −2mλ2 ≤C
"M
X",0.8894984326018809,αm(∥zlin∥+ 2mλ)2 = C
"M
X",0.890282131661442,αm(∥zlin∥+ 2√α)2.
"M
X",0.8910658307210031,"Taking the square root of both sides and recalling that α ∈(0, 1) is a constant, we obtain"
"M
X",0.8918495297805643,"∥Z∥F ≤C∥zlin∥
√αm
+
C
√m."
"M
X",0.8926332288401254,"This implies that either ∥Z∥F ≤
2C
√m or ∥Z∥F ≤2C∥zlin∥
√αm . The case ∥Z∥F ≤
2C
√m cannot happen,
since by (22),"
"M
X",0.8934169278996865,"∥Z∥F ≥
C′√n
p"
"M
X",0.8942006269592476,m(1 −γ)
"M
X",0.8949843260188087,"≥C′√n
√m"
"M
X",0.89576802507837,"≥2C
√m"
"M
X",0.896551724137931,"when n = Ω(1). So we have ∥Z∥F ≤2C∥zlin∥
√αm . Again applying (22), we obtain"
"M
X",0.8973354231974922,∥zlin∥≥C√αm∥Z∥F
"M
X",0.8981191222570533,"≥C√αn
√1 −γ . So"
"M
X",0.8989028213166145,"Alin
∥zlin∥≤C Alin
√1 −γ
√αn"
"M
X",0.8996865203761756,"= C√1 −γ
√αn"
"M
X",0.9004702194357367,"2m
X"
"M
X",0.9012539184952978,"j=1
(−1)jaj"
"M
X",0.9020376175548589,"≤C√1 −γ
√αn √"
M,0.9028213166144201,2m 
M,0.9036050156739812,"
2m
X"
M,0.9043887147335423,"j=1
|aj|2   1/2 ≤C
p"
M,0.9051724137931034,"m(1 −γ)
√αn "
M,0.9059561128526645,"
2m
X"
M,0.9067398119122257,"j=1
∥wj∥2   1/2"
M,0.9075235109717869,"= C∥W ∥F
p"
M,0.908307210031348,"m(1 −γ)
√αn"
M,0.9090909090909091,"≤
C
α3/2 ."
M,0.9098746081504702,"Here we used that Alin ≥0 and applied Cauchy-Schwarz in the third line. Then by Lemma D.4, if"
M,0.9106583072100314,"C
α3/2 ≤O
r1 −γ γd 
, then"
M,0.9114420062695925,"P(yf(W , x) < 0) ≥1 8."
M,0.9122257053291536,"This occurs if γ = O

α3"
M,0.9130094043887147,"d

. Hence, in all cases, we have shown that with the appropriate scaling, the"
M,0.9137931034482759,generalization error is at least 1
M,0.914576802507837,"8 when both ω1 and ω2 occur. This happens with probability at least
1 −δ."
M,0.9153605015673981,"Appendix E
Formalizing benign overfitting as a high dimensional
phenomenon"
M,0.9161442006269592,"To formalize benign overfitting as a high dimensional phenomenon we first introduce the notion of a
regime. Informally, a regime is a subset of the hyperparameters Ω∈N4 which describes accepted
combinations of the input data dimension d, the number of points in the training sample n, the number
of corrupt points k and the number of trainable model parameters p."
M,0.9169278996865203,Definition E.1. A regime is a subset Ω⊂N4 which satisfies the following properties.
M,0.9177115987460815,"1. For any tuple (d, n, k, p) ∈Ωthe number of corrupt points is at most the total number of
points, k ≤n."
M,0.9184952978056427,"2. There is no upper bound on the number of points,"
M,0.9192789968652038,"sup
(d,n,k,p)∈Ω
n = ∞."
M,0.9200626959247649,A non-trivial regime is a regime which satisfies the following additional condition.
M,0.920846394984326,"3. Define the set of increasing sequences of Ωas Ω∗
=
{(nl, dl, kl, pl)l∈N
⊂
Ωs.t. liml→∞nl = ∞}. For any (nl, dl, kl, pl)l∈N ∈Ω∗it holds that"
M,0.9216300940438872,"lim inf
l→∞
kl
nl
> 0."
M,0.9224137931034483,"Intuitively, a regime defines how the four hyperparameters (d, n, k, p) can grow in relation to one
another as n goes to infinity. A non-trivial regime is one in which the fraction of corrupt points in the
training sample is non-vanishing. In order to make a formal definition of benign overfitting as high
dimensional phenomenon we introduce the following additional concepts."
M,0.9231974921630094,"• A learning algorithm A = (Ad,n,p)(d,n,p)∈N3 is a triple indexed sequence of measurable
functions Ad,n,p : Rn×d × Rn →Rp."
M,0.9239811912225705,"• An architecture M = (fd,p)d,p∈N2 is a double indexed sequence of measurable functions
fd,p : Rd × Rp →R."
M,0.9247648902821317,"• A data model D = (Dd,n,k)(d,n,k)∈N3 is a triple indexed sequence of Borel probability
measures Dd,n,k defined over Rn×d × {±1} × Rd × {±1}."
M,0.9255485893416928,"With these notions in place we are ready to provide a definition of benign overfitting in high
dimensions."
M,0.9263322884012539,"Definition E.2. Let (ϵ, δ) ∈(0, 1]2, A be a learning algorithm, M an architecture, D a data model
and Ωa regime. If for every increasing sequence (dl, nl, kl, pl)l∈N ∈Ω∗there exists an L ∈N such
that for all l ≥L with probability at least 1 −δ over (X, ˆy), where (X, ˆy, x, y) ∼Ddl,nl,kl, it
holds that"
M,0.927115987460815,"1. yif(Adl,nl,pl(X, ˆy), xi) > 0 ∀i ∈[nl],"
M,0.9278996865203761,"2. P(yf(Adl,nl,pl(X, ˆy), x) ≤0) ≤infW ∈Rnl×dl P(yf(W , x) ≤0) + ϵ,"
M,0.9286833855799373,"then the quadruplet (A, M, D, Ω) (ϵ, δ)-benignly overfits. If (A, M, D, Ω) (ϵ, δ)-benignly overfits
for any (ϵ, δ) ∈(0, 1]2 then we say (A, M, D, Ω) benignly overfits."
M,0.9294670846394985,"Analogously, we define non-benign overfitting as follows."
M,0.9302507836990596,"Definition E.3. Let (ϵ, δ) ∈(0, 1]2, A be a learning algorithm, M an architecture, D a data model
and Ωa regime. If for every increasing sequence (dl, nl, kl, pl)l∈N ∈Ω∗there exists an L ∈N such
that for all l ≥L with probability at least 1 −δ over (X, ˆy), where (X, ˆy, x, y) ∼Ddl,nl,kl, it
holds that"
M,0.9310344827586207,"1. yif(Adl,nl,pl(X, ˆy), xi) > 0 ∀i ∈[nl],"
M,0.9318181818181818,"2. P(yf(Adl,nl,pl(X, ˆy), x) ≤0) ≥infW ∈Rnl×dl P(yf(W , x) ≤0) + ϵ,"
M,0.932601880877743,"then the quadruplet (A, M, D, Ω) (ϵ, δ)-non-benignly overfits. If (A, M, D, Ω) (ϵ, δ)-non-benignly
overfits for any (ϵ, δ) ∈(0, 1]2 then we say (A, M, D, Ω) non-benignly overfits."
M,0.9333855799373041,"One of the key contributions of this paper is proving (ϵ, δ)-benign and non-benign overfitting when
the architecture is a two-layer leaky ReLU network (equation 1), the learning algorithm returns the
inner layer weights of the network by minimizing the hinge loss over the training data using gradient
descent (Definition 2.2), and the regime satisfies the conditions d = Ω(n log 1/ϵ), n = Ω(1/δ),
k = O(n) and p = 2dm for some network width 2m, m ∈N."
M,0.9341692789968652,"Appendix F
Experiments"
M,0.9349529780564263,"To further support our theory, we train shallow neural networks on the data model described in
Definition 2.1 and record the numerical results. Scripts to reproduce these experiments can be found
at https://github.com/kedar2/benign_overfitting. These experiments were run on the
CPU of a MacBook Pro M2 with 8GB of RAM. For our first experiment, we investigate the effect of
the ratio d"
M,0.9357366771159875,"n on the generalization error of the network. Recall that by Theorem 3.2, the generalization"
M,0.9365203761755486,error is bouned above by exp (−Cn) when d
M,0.9373040752351097,"n = Ω(1). In other words, if d"
M,0.9380877742946708,"n is larger than a critical
threshold, then the generalizatione error decays quickly to 0 as n increases. We empirically confirm
this prediction in Figure 1, where we train several networks while varying d"
M,0.9388714733542319,"n and n, and estimate
the generalization error for each configuration by averaging over 20 trials. Within each trial, we
trained the inner layer of the network with gradient descent using the hinge loss until the training loss
reached 0. For d"
M,0.9396551724137931,"n greater than around 7, the generalization error rapidly decays to 0 as n →∞."
M,0.9404388714733543,"Figure 1: Generalization error of a two-layer leaky ReLU network trained to 0 hinge loss varying
n and d. Parameter settings: α = 0.1, γ = 5/n, m = 64, k = 0.1n, number of trials = 5, size of
validation sample = 1000."
M,0.9412225705329154,"Next, we train a two-layer network varying n and γ (Figure 2), holding constant the ratio d"
M,0.9420062695924765,"n. Since γ
controls the signal-to-noise ratio of the data, the generalization error of the learned network decreases
as γ increases. For each value of n, the generalization error falls off steeply as γ reaches a certain
threshold. This threshold decreases as n increases, indicating that the network has higher noise
tolerance as n increases. This is in agreement with our theoretical results where we found that benign
overfitting occurs at the threshold γ = Ω
  1"
M,0.9427899686520376,"k

(which is in this case Ω
  1"
M,0.9435736677115988,"n

). We also see that the
generalization error for large values of γ is similar across different values of n. This effect is also
predicted by Corollary 3.2.1, since we scale both d and k proportionally to n."
M,0.9443573667711599,"Figure 2: Generalization error of a two-layer leaky ReLU network trained to 0 hinge loss varying
γ and n. Parameter settings: α = 0.1, d = 2n, m = 64, k = 0.1n, number of trials = 10, size of
validation sample = 1000."
M,0.945141065830721,NeurIPS Paper Checklist
CLAIMS,0.9459247648902821,1. Claims
CLAIMS,0.9467084639498433,"Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: The results stated in the abstract and introduction are stated formally in
Section 3 and then proven in Appendix D.
Guidelines:"
CLAIMS,0.9474921630094044,"• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2. Limitations"
CLAIMS,0.9482758620689655,"Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We discuss limitations of the work in the conclusion of the paper.
Guidelines:"
CLAIMS,0.9490595611285266,"• The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ""Limitations"" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3. Theory Assumptions and Proofs"
CLAIMS,0.9498432601880877,"Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]"
CLAIMS,0.950626959247649,"Justification: All necessary assumptions are stated in the theorems. All theorems are proven
in full detail in Appendices C and D, with proof sketches appearing in Section 4.
Guidelines:"
CLAIMS,0.95141065830721,"• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4. Experimental Result Reproducibility"
CLAIMS,0.9521943573667712,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We describe our experimental setup in Appendix F.
Guidelines:"
CLAIMS,0.9529780564263323,"• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5. Open access to data and code"
CLAIMS,0.9537617554858934,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?"
CLAIMS,0.9545454545454546,"Answer: [Yes]
Justification: We provide a link to our code to reproduce our experiments.
Guidelines:"
CLAIMS,0.9553291536050157,"• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6. Experimental Setting/Details"
CLAIMS,0.9561128526645768,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We describe our setup in Appendix F.
Guidelines:"
CLAIMS,0.9568965517241379,"• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material.
7. Experiment Statistical Significance"
CLAIMS,0.957680250783699,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [No]
Justification: Our experiments consist of a heatmap and a line chart with multiple plots.
It was not possible to add error bars without crowding the plots. In our description of
our experimental setup we describe the sample size, from which standard errors can be
computed.
Guidelines:"
CLAIMS,0.9584639498432602,"• The answer NA means that the paper does not include experiments.
• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)"
CLAIMS,0.9592476489028213,"• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text."
EXPERIMENTS COMPUTE RESOURCES,0.9600313479623824,8. Experiments Compute Resources
EXPERIMENTS COMPUTE RESOURCES,0.9608150470219435,"Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?"
EXPERIMENTS COMPUTE RESOURCES,0.9615987460815048,Answer: [Yes]
EXPERIMENTS COMPUTE RESOURCES,0.9623824451410659,Justification: We describe the resources used in Appendix F.
EXPERIMENTS COMPUTE RESOURCES,0.963166144200627,Guidelines:
EXPERIMENTS COMPUTE RESOURCES,0.9639498432601881,"• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper)."
CODE OF ETHICS,0.9647335423197492,9. Code Of Ethics
CODE OF ETHICS,0.9655172413793104,"Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?"
CODE OF ETHICS,0.9663009404388715,Answer: [Yes]
CODE OF ETHICS,0.9670846394984326,"Justification: The research conducted in the paper did not use data, assets, or human
participants; only studied existing models; and was conducted in accordance to the Code of
Ethics."
CODE OF ETHICS,0.9678683385579937,Guidelines:
CODE OF ETHICS,0.9686520376175548,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction)."
BROADER IMPACTS,0.969435736677116,10. Broader Impacts
BROADER IMPACTS,0.9702194357366771,"Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?"
BROADER IMPACTS,0.9710031347962382,Answer: [NA]
BROADER IMPACTS,0.9717868338557993,"Justification: This paper is a purely theoretical study explaining behaviors seen in neural
networks in practice. There are no foreseeable societal impacts of this work."
BROADER IMPACTS,0.9725705329153606,Guidelines:
BROADER IMPACTS,0.9733542319749217,"• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact."
BROADER IMPACTS,0.9741379310344828,"• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML)."
SAFEGUARDS,0.9749216300940439,11. Safeguards
SAFEGUARDS,0.975705329153605,"Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?"
SAFEGUARDS,0.9764890282131662,Answer: [NA]
SAFEGUARDS,0.9772727272727273,"Justification: No new model or data is presented in this paper. The paper is a theoretical
study of neural networks."
SAFEGUARDS,0.9780564263322884,Guidelines:
SAFEGUARDS,0.9788401253918495,"• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort."
LICENSES FOR EXISTING ASSETS,0.9796238244514106,12. Licenses for existing assets
LICENSES FOR EXISTING ASSETS,0.9804075235109718,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?"
LICENSES FOR EXISTING ASSETS,0.9811912225705329,Answer: [NA]
LICENSES FOR EXISTING ASSETS,0.981974921630094,Justification: The paper does not use existing assests.
LICENSES FOR EXISTING ASSETS,0.9827586206896551,Guidelines:
LICENSES FOR EXISTING ASSETS,0.9835423197492164,"• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided."
LICENSES FOR EXISTING ASSETS,0.9843260188087775,"• If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators."
NEW ASSETS,0.9851097178683386,13. New Assets
NEW ASSETS,0.9858934169278997,"Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?"
NEW ASSETS,0.9866771159874608,Answer: [NA]
NEW ASSETS,0.987460815047022,Justification: The paper does not use new assets.
NEW ASSETS,0.9882445141065831,Guidelines:
NEW ASSETS,0.9890282131661442,"• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used.
• At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9898119122257053,14. Crowdsourcing and Research with Human Subjects
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9905956112852664,"Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9913793103448276,Answer: [NA]
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9921630094043887,Justification: The paper does not involve crowdsourcing nor research with human subjects.
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9929467084639498,Guidelines:
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9937304075235109,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9945141065830722,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9952978056426333,"Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9960815047021944,Answer: [NA]
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9968652037617555,Justification: The paper does not involve crowdsourcing nor research with human subjects.
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9976489028213166,Guidelines:
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9984326018808778,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper."
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9992163009404389,"• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review."
