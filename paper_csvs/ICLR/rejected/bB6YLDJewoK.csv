Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.004878048780487805,"Survival analysis, also known as time-to-event analysis, is the problem to predict
the distribution of the time of the occurrence of an event. This problem has appli-
cations in various ﬁelds such as healthcare, security, and ﬁnance. While there have
been many neural network models proposed for survival analysis, none of them
are calibrated. This means that the average of the predicted distribution is different
from the actual distribution in the dataset. Therefore, X-CAL has recently been
proposed for the calibration, which is supposed to be used as a regularization term
in the loss function of a neural network. X-CAL is formulated on the basis of the
widely used deﬁnition of calibration for distribution regression. In this work, we
propose new calibration deﬁnitions for distribution regression and survival analy-
sis, and demonstrate a simpler alternative to X-CAL based on the new calibration
deﬁnition for survival analysis."
INTRODUCTION,0.00975609756097561,"1
INTRODUCTION"
INTRODUCTION,0.014634146341463415,"Survival analysis, also known as time-to-event analysis, is the problem to predict the time of the
occurrence of an event. In healthcare applications, the event typically corresponds to a death or the
onset of disease in a patient. The time between a well-deﬁned starting point and the occurrence of
the event is called the survival time or failure time. In survival analysis, we usually estimate the dis-
tribution of the survival times of patients. Survival analysis has important applications in healthcare
as well as various other ﬁelds (e.g., credit scoring (Dirick et al., 2017) and fraud detection (Zheng
et al., 2019)). The recent progress of prediction models for survival analysis has been summarized
in a survey paper (Wang et al., 2019)."
INTRODUCTION,0.01951219512195122,"In survival analysis, datasets are often censored, which means that events of interest might not be
observed for some instances. This may be due to either the limited observation time window or
missing traces caused by other irrelevant events. Typical censored data are right censored data.
These are the data points whose exact times of the events are unknown; we know only that the
events had not happened up to a certain time. In this paper, we focus on the uncensored data and the
right censored data, as shown in Figure 1. Here, the event for data point x1 is observed during the
period of study and hence this data is categorized as uncensored data. The data points x2 and x3 are
categorized as right censored data because we did not observe the events during the period of study.
The time between a well-deﬁned starting point and the last observation time (e.g., the time of the
end of study) is called the censoring time."
INTRODUCTION,0.024390243902439025,"One of the classical methods to solve the survival analysis problem is the Kaplan-Meier estima-
tor (Kaplan & Meier, 1958). This is a non-parametric method to estimate the distribution of the
survival times as a survival function S(t), where the value S(t∗) for a speciﬁc time t∗represents the
survival rate at time t∗(i.e., the ratio of the patients who survived at time t∗). It is easy to estimate
the survival function S(t) if the dataset contains only uncensored data points, but the Kaplan-Meier
estimator is designed to work for datasets that include censored data. Here, we brieﬂy explain the
algorithm of the Kaplan-Meier estimator. Let {ti}k
i=1 be the set of distinct times when at least one
uncensored event was observed in the dataset. Let di be the number of (uncensored) events that
happened exactly at time ti, and let ni be the number of data points that are known to have survived
at time ti. Then, the Kaplan-Meier estimator outputs the survival function"
INTRODUCTION,0.02926829268292683,"S(t) =
Y"
INTRODUCTION,0.03414634146341464,i:ti≤t
INTRODUCTION,0.03902439024390244,"
1 −di ni 
."
INTRODUCTION,0.04390243902439024,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.04878048780487805,"Start of study
End of study Time"
INTRODUCTION,0.05365853658536585,"x3
Right censored
×"
INTRODUCTION,0.05853658536585366,"x2
Right censored"
INTRODUCTION,0.06341463414634146,"x1
Uncensored
×"
INTRODUCTION,0.06829268292682927,"Figure 1: Uncensored data and right cen-
sored data, where the symbols × show event
occurrences."
INTRODUCTION,0.07317073170731707,"0
1000
2000
3000
4000
5000
Time 0.0 0.2 0.4 0.6 0.8 1.0"
INTRODUCTION,0.07804878048780488,Survival rate
INTRODUCTION,0.08292682926829269,Kaplan-Meier
INTRODUCTION,0.08780487804878048,"Figure 2: Survival function S(t) estimated
by the Kaplan-Meier estimator for the ﬂchain
dataset."
INTRODUCTION,0.09268292682926829,"Figure 2 shows an example of the survival function S(t) estimated by the Kaplan-Meier estimator
for the ﬂchain dataset (Dispenzieri et al., 2012). Here, we can see that the survival rate at time
t = 2500 is approximately 80%. Note that the true survival rate S(t) at t = ∞must be zero, but the
Kaplan-Meier estimator outputs the survival function S(t) only for time t ∈[0, tmax], where tmax
is the maximum survival time of the uncensored data points in a dataset. This is because we cannot
estimate the survival rate S(t) for the time t > tmax."
INTRODUCTION,0.0975609756097561,"A drawback of the Kaplan-Meier estimator is that it outputs a survival function S(t) for the entire
population and not for a speciﬁc patient. Therefore, there have been many algorithms to estimate
the survival rate S(t|x) for each patient x so as to enable personalized medicine (Wang et al.,
2019). In particular, many neural network models that predict the survival function S(t|x) have
been proposed (Lee et al., 2018; Ren et al., 2019; Zheng et al., 2019; Tjandra et al., 2021)."
CALIBRATION,0.1024390243902439,"1.1
CALIBRATION"
CALIBRATION,0.1073170731707317,"When we use a prediction model, it should be calibrated. In binary classiﬁcation, this means that
a prediction model that outputs a conﬁdence of a true label for an input is expected to satisfy the
condition that the average of the conﬁdence values over all inputs are equal to the ratio of the data
points with a true label in the dataset. For example, if a dataset contains 40% of the data points
with a true label, then we expect that a calibrated prediction model will output a conﬁdence of 0.4
on average. Even though calibration is important for prediction models, and neural network models
have been widely used for prediction models, (Guo et al., 2017) showed that neural network models
are often miscalibrated."
CALIBRATION,0.11219512195121951,"In regression analysis, quantile-based calibration is widely used as the deﬁnition of calibra-
tion (Kuleshov et al., 2018; Song et al., 2019; Cui et al., 2020; Zhao et al., 2020). In survival
analysis, the deﬁnition of calibration is based on this deﬁnition for regression analysis. Goldstein
et al. (2020) showed a method to train a neural network model to achieve calibration by adding a
new regularizer, X-CAL, to the loss function of the neural network to achieve calibration during the
training. This method is in contrast to the widely-used calibration methods for regression analysis
such as Platt scaling and isotonic regression, which are post-training methods."
CALIBRATION,0.11707317073170732,"Note that a calibrated model is not necessarily useful. For example, in binary classiﬁcation we can
construct a trivial calibrated model that always outputs the ratio of true label data points in a dataset
as a conﬁdence value. Therefore, a useful prediction model also needs to be sharp, which means that
it outputs a conﬁdence value close to one or zero for each input. To obtain a prediction model that is
both calibrated and sharp, one approach is to train a neural network with a loss function consisting
of one loss term aimed at sharp prediction and another aimed at calibration. X-CAL utilizes this
approach in that it is a regularizer for calibration and is used in combination with another loss term
that aims at sharp prediction."
CALIBRATION,0.12195121951219512,Under review as a conference paper at ICLR 2022
OUR CONTRIBUTIONS,0.12682926829268293,"1.2
OUR CONTRIBUTIONS"
OUR CONTRIBUTIONS,0.13170731707317074,"In this paper, we propose a Kaplan-Meier regularizer as a simpler alternative to X-CAL. An advan-
tage of our regularizer is that the obtained prediction model is calibrated for any time t ∈[0, tmax].
Another advantage is that our regularizer does not require any hyperparameter, whereas X-CAL re-
quires hyperparameters. The idea behind our new regularizer is simple: just to reduce the difference
between the average predicted survival function and the Kaplan-Meier survival function (see Fig-
ure 3). Our new regularizer is based on a new deﬁnition of calibration for survival analysis, and we
discuss its advantages in Section 4."
SURVIVAL ANALYSIS,0.13658536585365855,"2
SURVIVAL ANALYSIS"
SURVIVAL ANALYSIS,0.14146341463414633,"We formally describe the problem settings of regression analysis and survival analysis. In regression
analysis, we assume that there is an unknown probability distribution P on the sample space X ×Y,
where X is the domain of features and Y is the interval [−∞, ∞]. We refer to the associated random
variables with capital letters (i.e., X and Y ) and realizations with lower case letters (x, y) ∼P. We
assume that we can obtain independent samples {(xi, yi)}n
i=1 from X × Y according to distribution
P."
SURVIVAL ANALYSIS,0.14634146341463414,"In survival analysis, we assume that there is an unknown probability distribution Q on the sample
space X × T × C, where X is the domain of features and T and C are time intervals [0, ∞]. We
refer to the associated random variables with capital letters (i.e., X, T , and C) and realizations with
lower case letters (x, t, c) ∼Q. The random variable T corresponds to the survival time (i.e., the
time of the occurrence of an event), which might not be observable due to the censoring, and the
random variable C corresponds to the censoring time. We assume that the censoring time is ∞for
an uncensored event. The random variable deﬁned by Z = min{T , C} corresponds to the time
of the last observation (i.e., the survival time or the censoring time). Different from the regression
analysis, we cannot obtain samples {(xi, ti, ci)}n
i=1 from X ×T ×C according to distribution Q due
to the censoring in survival analysis. However, we assume that we can obtain independent samples
D = {(xi, zi, δi)}n
i=1 instead, where δi is a binary value indicating if the i-th data point is censored
or not. Here an uncensored data point (xi, zi, δi) ∈D satisﬁes δi = 1 and zi = ti and a censored
data point (xi, zi, δi) ∈D satisﬁes δi = 0 and zi = ci. Hence δi = 0 means that we know only the
fact that ti ≥ci and the exact survival time ti is unknown."
SURVIVAL ANALYSIS,0.15121951219512195,"The task of survival analysis is to predict the probability of an event of interest occurring at time t
for x ∈X as a probability distribution function f(t|x). This function f(t|x) is often represented
in other equivalent forms. For example, it can be represented as its cumulative distribution function
(CDF)"
SURVIVAL ANALYSIS,0.15609756097560976,"F(t|x) =
Z t"
SURVIVAL ANALYSIS,0.16097560975609757,"0
f(τ|x)dτ"
SURVIVAL ANALYSIS,0.16585365853658537,or as the survival function S(t|x) deﬁned by
SURVIVAL ANALYSIS,0.17073170731707318,S(t|x) = 1 −F(t|x).
SURVIVAL ANALYSIS,0.17560975609756097,"Intuitively, F(t|x) represents the probability of observing the event by time t for x and the survival
function S(t|x) represents the probability of not-observing the event until time t for x."
SURVIVAL ANALYSIS,0.18048780487804877,"Many neural network models have been proposed for survival analysis (e.g., (Lee et al., 2018; Ren
et al., 2019; Zheng et al., 2019; Tjandra et al., 2021)). They output the probability distribution
in the form of fθ(t|x), Fθ(t|x), Sθ(T|x), or something equivalent to these forms, where θ is the
parameters of the neural network."
QUANTILE-BASED CALIBRATION,0.18536585365853658,"3
QUANTILE-BASED CALIBRATION"
QUANTILE-BASED CALIBRATION,0.1902439024390244,"In this section, we review the deﬁnitions of calibration for distribution regression and survival anal-
ysis in the literature. First, we consider the distribution regression whose task is to predict the
distribution of the target variable as a CDF Fθ(y|x) for x ∈X, where θ is the parameters of the
prediction model. In distribution regression, quantile-based calibration (Kuleshov et al., 2018) is
widely used as the deﬁnition of calibration (e.g., (Song et al., 2019; Cui et al., 2020; Zhao et al.,
2020))."
QUANTILE-BASED CALIBRATION,0.1951219512195122,Under review as a conference paper at ICLR 2022
QUANTILE-BASED CALIBRATION,0.2,"Deﬁnition 3.1 (Quantile-based calibration.) A prediction model Fθ(y|x) for distribution regression
is quantile-calibrated if this equation holds for any quantile level τ ∈[0, 1]:
Pr(X,Y )∼P(Fθ(Y |X) ≤τ) = τ.
(1)"
QUANTILE-BASED CALIBRATION,0.2048780487804878,"If we can compute the inverse of Fθ(y|x), we can rewrite Eq. (1) as
Pr(X,Y )∼P(Y ≤F −1
θ
(τ|X)) = τ.
This equation means that, for a random sample (x, y) ∼P, y must be at most the τ-th quantile
of the predicted CDF (i.e., F −1
θ
(τ|x)) exactly with probability τ. We can rewrite Deﬁnition 3.1 in
another equivalent formulation: the following equation holds for any subinterval [τ1, τ2] ⊆[0, 1]:
Pr(X,Y )∼P(Fθ(Y |X) ∈[τ1, τ2]) = τ2 −τ1.
This equation means that the quantile level Fθ(y|x) predicted for a random sample (x, y) ∼P is
contained in a subinterval [τ1, τ2] ⊆[0, 1] exactly with probability τ2 −τ1."
QUANTILE-BASED CALIBRATION,0.2097560975609756,"On the basis of Deﬁnition 3.1, Goldstein et al. (2020) deﬁne calibration for survival analysis."
QUANTILE-BASED CALIBRATION,0.2146341463414634,"Deﬁnition 3.2 (Quantile-based calibration for survival analysis.) A prediction model Fθ(t|x) for
survival analysis is quantile-calibrated if this equation holds for any quantile level τ ∈[0, 1]:
Pr(X,T ,C)∼Q(Fθ(T |X) ≤τ) = τ.
(2)"
QUANTILE-BASED CALIBRATION,0.21951219512195122,"We can rewrite Deﬁnition 3.2 into another equivalent formulation: the following equation holds for
any subinterval I = [τ1, τ2] ⊆[0, 1]:
Pr(X,T ,C)∼Q(Fθ(T |X) ∈I) = |I| = τ2 −τ1.
(3)
A problem when using Deﬁnition 3.2 is that we cannot get samples directly from T due to the
censoring. As such, we cannot verify Eq. (3) for datasets that include censored data. Goldstein et al.
(2020) resolved this problem by showing how to estimate the probability Pr(Fθ(t|x) ∈I) for any
t ∈[c, ∞] from Pr(Fθ(c|x) ∈I) for a randomly sampled censored data point (x, c, 0). Under the
assumption that T and C are independent (i.e., T ⊥C | X), they show"
QUANTILE-BASED CALIBRATION,0.22439024390243903,Pr(Fθ(t|x) ∈I) = (τ2 −v)1[v ∈I]
QUANTILE-BASED CALIBRATION,0.22926829268292684,"1 −v
+ (τ2 −τ1)1[v < τ1]"
QUANTILE-BASED CALIBRATION,0.23414634146341465,"1 −v
,
(4)"
QUANTILE-BASED CALIBRATION,0.23902439024390243,"where v = Fθ(c|x) and 1[·] denotes the step function. By using this estimation, we can compute
the left-hand side of Eq. (3) from dataset D that include censored data points."
QUANTILE-BASED CALIBRATION,0.24390243902439024,"On the basis of Eq. (3) and the approaches described in (Andres et al., 2018; Haider et al., 2020),
Goldstein et al. (2020) proposed a metric called distributional calibration (D-CAL), which is deﬁned
as
ℓD−CAL(θ) =
X I∈I"
QUANTILE-BASED CALIBRATION,0.24878048780487805," 
E(X,T ,C)∼Q1[Fθ(T |X) ∈I] −|I|
2 ,"
QUANTILE-BASED CALIBRATION,0.25365853658536586,"where the collection I is chosen to contain disjoint contiguous subintervals of C ⊆[0, 1] that cover
the whole interval [0, 1]."
QUANTILE-BASED CALIBRATION,0.25853658536585367,"A prediction model Fθ(t|x) with a lower ℓD−CAL(θ) is said to be more calibrated, but we cannot
construct a neural network model that directly minimizes D-CAL because ℓD−CAL(θ) is not a dif-
ferentiable function due to its step function. Therefore, Goldstein et al. (2020) deﬁned the explicit
calibration (X-CAL), an approximation of D-CAL, by replacing the step function with a sigmoid
function so that X-CAL becomes a differentiable function. Moreover, X-CAL is designed to handle
a set of data points B = {(xi, zi, δi)}b
i=1 as a mini-batch, which makes it possible to integrate X-
CAL into the loss function of neural network models because most of those models use a mini-batch
training rather than the full batch training. Formally, X-CAL is deﬁned as"
QUANTILE-BASED CALIBRATION,0.2634146341463415,"RX−CAL(θ) = EB∼Q
X I∈I"
QUANTILE-BASED CALIBRATION,0.2682926829268293," 
E(X,T ,C)∼Bζ(Fθ(T |X); I, γ) −|I|
2 ,"
QUANTILE-BASED CALIBRATION,0.2731707317073171,"where ζ(z; I, γ) is a sigmoid function to approximate the step function in D-CAL. (See (Goldstein
et al., 2020) for the precise deﬁnition of the function ζ.) Here, we abuse notation (X, T , C) ∼B to
indicate that we obtain sample data points from mini-batch B (rather than the probability distribution
Q). Note that Goldstein et al. (2020) proposed using X-CAL in the loss function of a neural network
model as a regularizer, which means that it is intended to be combined with other loss functions. This
is because a prediction model that aims only at calibration is useless (as discussed in Section 1) and
the balance between sharpness and calibration must be considered for obtaining a useful prediction
model."
QUANTILE-BASED CALIBRATION,0.2780487804878049,Under review as a conference paper at ICLR 2022
VALUE-BASED CALIBRATION,0.28292682926829266,"4
VALUE-BASED CALIBRATION"
VALUE-BASED CALIBRATION,0.28780487804878047,"In this section, we propose alternative deﬁnitions of calibration, value-based calibration, for dis-
tribution regression and survival analysis. Then, on the basis of the new calibration deﬁnition for
survival analysis, we propose our new Kaplan-Meier regularizer, and we discuss its advantages over
D-CAL and X-CAL."
VALUE-BASED CALIBRATION,0.2926829268292683,We ﬁrst propose an alternative deﬁnition of calibration for distribution regression.
VALUE-BASED CALIBRATION,0.2975609756097561,"Deﬁnition 4.1 (Value-based calibration.) A prediction model Fθ(y|x) for distribution regression is
value-calibrated if this equation holds for any value y ∈[−∞, ∞]:"
VALUE-BASED CALIBRATION,0.3024390243902439,"E(X,Y )∼PFθ(y|X) = Pr(X,Y )∼P(Y ≤y)."
VALUE-BASED CALIBRATION,0.3073170731707317,"This equation means that the average probability of prediction having a value of at most y must
be equal to the actual ratio of data points having a value of at most y. The difference between
Deﬁnitions 3.1 and 4.1 is on the choice of the axis. Whereas Deﬁnition 3.1 gives a natural condition
for calibration with respect to the τ-axis of a prediction model τ = Fθ(y|x), Deﬁnition 4.1 gives a
natural condition for calibration with respect to the y-axis. In appendix (Section A.1), we show that
a quantile-calibrated model is not necessarily a value-calibrated model and vice versa."
VALUE-BASED CALIBRATION,0.3121951219512195,"On the basis of Deﬁnition 4.1, we deﬁne the value-based calibration for survival analysis."
VALUE-BASED CALIBRATION,0.3170731707317073,"Deﬁnition 4.2 (Value-based calibration for survival analysis.) A prediction model Fθ(t|x) for sur-
vival analysis is value-calibrated if this equation holds for any time t ∈[0, tmax], where tmax is the
maximum time of the uncensored data points in the dataset D:"
VALUE-BASED CALIBRATION,0.32195121951219513,"E(X,T ,C)∼QFθ(t|X) = Pr(X,T ,C)∼Q(T ≤t).
(5)"
VALUE-BASED CALIBRATION,0.32682926829268294,"Note that we ask Eq. (5) to hold for t ∈[0, tmax] rather than t ∈[0, ∞]. This is because the
prediction model Fθ(t|x) for survival analysis is usually trained for t ∈[0, tmax] and the prediction
Fθ(t|x) for t > tmax is less accurate."
VALUE-BASED CALIBRATION,0.33170731707317075,"We can rewrite Deﬁnition 4.2 into another equivalent form: the following equation holds for any
subinterval [t1, t2] ⊆[0, tmax]:"
VALUE-BASED CALIBRATION,0.33658536585365856,"E(X,T ,C)∼Q(Fθ(t2|X) −Fθ(t1|X)) = Pr(X,T ,C)∼Q(t1 ≤T ≤t2)."
VALUE-BASED CALIBRATION,0.34146341463414637,"This condition exactly matches the explanation of calibration in (Goldstein et al., 2020), i.e., a
model’s predicted number of events within any time interval is similar to the observed number. Note
also that we can rewrite Eq. (5) into another equivalent form:"
VALUE-BASED CALIBRATION,0.3463414634146341,"E(X,T ,C)∼QSθ(t|X) = Pr(X,T ,C)∼Q(T > t).
(6)"
VALUE-BASED CALIBRATION,0.35121951219512193,"Here, the left-hand side of Eq. (6) is changed from the CDF Fθ(t|X) in Eq. (5) to the survival
function Sθ(t|X), and the right-hand side of the equation is also changed accordingly."
VALUE-BASED CALIBRATION,0.35609756097560974,"On the basis of Eq. (6), we propose our new metric, Kaplan-Meier loss, which is deﬁned as"
VALUE-BASED CALIBRATION,0.36097560975609755,"ℓKM(θ) =
Z tmax 0"
VALUE-BASED CALIBRATION,0.36585365853658536," 
E(X,T ,C)∼QSθ(t|X) −Pr(X,T ,C)∼Q(T > t)
2 dt.
(7)"
VALUE-BASED CALIBRATION,0.37073170731707317,"In contrast to D-CAL, we can use this loss directly in the loss function of a neural network model be-
cause this loss is differentiable. However, we also propose a new regularizer RKM(θ) by modifying
ℓKM(θ) so that it can be used in a mini-batch training with a set of data points B = {(xi, zi, δi)}b
i=1:"
VALUE-BASED CALIBRATION,0.375609756097561,RKM(θ) = EB∼Q
VALUE-BASED CALIBRATION,0.3804878048780488,Z tmax 0
VALUE-BASED CALIBRATION,0.3853658536585366," 
E(X,T ,C)∼BSθ(t|X) −Pr(X,T ,C)∼B(T > t)
2 dt.
(8)"
VALUE-BASED CALIBRATION,0.3902439024390244,"Again, we abuse notation (X, T , C) ∼B to indicate that we obtain sample data points from mini-
batch B (rather than the probability distribution Q). Although we used ℓ2 loss in Eq. (7)–(8), we can
use any other metric to measure the difference between two distributions. Note that we can compute
the ﬁrst term in the parentheses by"
VALUE-BASED CALIBRATION,0.3951219512195122,"E(X,T ,C)∼BSθ(t|X) =
1
|B| X"
VALUE-BASED CALIBRATION,0.4,"(xi,zi,δi)∈B
(1 −Fθ(t|xi)),"
VALUE-BASED CALIBRATION,0.40487804878048783,Under review as a conference paper at ICLR 2022 S(t)
VALUE-BASED CALIBRATION,0.4097560975609756,Time t ↕ ↕
VALUE-BASED CALIBRATION,0.4146341463414634,Kaplan-Meier survival curve
VALUE-BASED CALIBRATION,0.4195121951219512,"Predicted
survival curve"
VALUE-BASED CALIBRATION,0.424390243902439,"Figure 3: Our Kaplan-Meier regularizer is
designed to reduce the ℓ2 loss between the
Kaplan-Meier survival curve and the average
predicted survival curve."
VALUE-BASED CALIBRATION,0.4292682926829268,←→←→←→→←→←
VALUE-BASED CALIBRATION,0.43414634146341463,target
VALUE-BASED CALIBRATION,0.43902439024390244,"Figure 4: Each box corresponds to a bin in C
and each circle corresponds to a data point.
The arrows show the directions of the moves
of the data points during training."
VALUE-BASED CALIBRATION,0.44390243902439025,"and we can estimate the second term in the parentheses Pr(X,T ,C)∼Q(T > t) by the Kaplan-
Meier estimator. Recall that the Kaplan-Meier estimator is designed to estimate Pr(T > t) even
if the dataset contains censored data. Figure 3 illustrates the proposed loss ℓKM(θ) and regularizer
RKM(θ), in which the ﬁrst term in the parentheses of Eq. (7)–(8) corresponds to the average pre-
dicted survival function (thick curve) and the second term corresponds to the Kaplan-Meier survival
curve (red curve) and each equation computes the ℓ2 loss between these two curves."
VALUE-BASED CALIBRATION,0.44878048780487806,The advantages of our approach can be summarized as follows.
VALUE-BASED CALIBRATION,0.45365853658536587,"1. Our value-based calibration for survival analysis (Deﬁnition 4.2) is intuitive for practi-
tioners in healthcare. Practitioners are often interested in the prediction performance at a
speciﬁc time t∗∈[0, tmax], and Eq. (5) shows a natural condition that should hold at time
t∗. In contrast, Eq. (2) states nothing about speciﬁc time t∗."
VALUE-BASED CALIBRATION,0.4585365853658537,"2. Our value-based calibration for survival analysis (Deﬁnition 4.2) is deﬁned only for the
range t ∈[0, tmax]. Regarding the quantile-based calibration, Deﬁnition 3.1 means that, if
a prediction model Fθ(y|x) for distribution regression is quantile-calibrated, then the distri-
bution of Fθ(Y |X) for (X, Y ) ∼P is equal to the uniform distribution over [0, 1] (Zhao
et al., 2020). However, even if a prediction model Fθ(t|x) for survival analysis is quantile-
calibrated, the distribution of Fθ(T ′|X) is usually not equal to the uniform distribution
when T ′ refers to the random variable for the survival time of uncensored events. This
means that the condition in Deﬁnition 3.2 can be satisﬁed only if we can estimate the dis-
tribution of Fθ(T |X) from the dataset D that include censored data by using some method
such as Eq. (4). In other words, we need to estimate Fθ(t|x) for t > tmax when we use
Deﬁnition 3.2."
VALUE-BASED CALIBRATION,0.4634146341463415,"3. Our Kaplan-Meier loss and regularizer do not require any hyperparameter (other than the
batch size |B|), whereas D-CAL and X-CAL require the hyperparameters γ and C."
VALUE-BASED CALIBRATION,0.4682926829268293,"4. Our Kaplan-Meier regularizer uses a simple ℓ2 loss and it avoids the binning approach used
in X-CAL. In the following, we explain the problem in the binning approach. In X-CAL,
we count the number of data points in each bin and we update the parameters θ of a neural
network during the training so that the numbers of data points in the bins are balanced.
Figure 4 illustrates that, for a bin in which the number of data points exceed the target,
the parameters θ is updated so that the data points in the ﬁrst half of the bin are pushed to
the left and the data points in the second half of the bin are pushed to the right due to the
approximation of the step function as the sigmoid function. However, since the numbers of
data points in the three bins in the left exceed the target and the numbers of the data points
in the two bins in the right are below the target in the case of Figure 4, no data point in the
three bins in the left should be pushed left and the data points in these bins should be used
to ﬁll the two bins in the right. Therefore, we sometimes ﬁnd difﬁculties in minimizing X-
CAL due to the binning approach. Note that Goldstein et al. (2020) showed how to avoid
this phenomenon for the left-most and right-most bins, but we cannot avoid this problem
for the other bins."
VALUE-BASED CALIBRATION,0.47317073170731705,Under review as a conference paper at ICLR 2022
VALUE-BASED CALIBRATION,0.47804878048780486,"0
1000
2000
3000
4000
5000
Time 0.0 0.2 0.4 0.6 0.8 1.0"
VALUE-BASED CALIBRATION,0.48292682926829267,Survival rate
VALUE-BASED CALIBRATION,0.4878048780487805,"DeepHit
DRSA
Survival CRPS
Kaplan-Meier"
VALUE-BASED CALIBRATION,0.4926829268292683,(a) ﬂchain
VALUE-BASED CALIBRATION,0.4975609756097561,"0
250
500
750
1000
1250
1500
1750
2000
Time 0.0 0.2 0.4 0.6 0.8 1.0"
VALUE-BASED CALIBRATION,0.5024390243902439,Survival rate
VALUE-BASED CALIBRATION,0.5073170731707317,"DeepHit
DRSA
Survival CRPS
Kaplan-Meier"
VALUE-BASED CALIBRATION,0.5121951219512195,(b) support
VALUE-BASED CALIBRATION,0.5170731707317073,"0
200
400
600
800
1000
1200
1400
1600
Time 0.0 0.2 0.4 0.6 0.8 1.0"
VALUE-BASED CALIBRATION,0.5219512195121951,Survival rate
VALUE-BASED CALIBRATION,0.526829268292683,"DeepHit
DRSA
Survival CRPS
Kaplan-Meier"
VALUE-BASED CALIBRATION,0.5317073170731708,(c) retinopathy
VALUE-BASED CALIBRATION,0.5365853658536586,"Figure 5: Comparison of average predicted survival functions by using loss functions DeepHit,
DRSA, and Survival CRPS with Kaplan-Meier survival curve."
EXPERIMENTS,0.5414634146341464,"5
EXPERIMENTS"
EXPERIMENTS,0.5463414634146342,"In this section, we compare the performance of our Kaplan-Meier regularizer with X-CAL on real
datasets. We show that, by using our Kaplan-Meier regularizer or X-CAL, we can reduce both
Kaplan-Meier loss and D-CAL. This means that we can use one of these two regularizers both for
quantile-based calibration and value-based calibration and do not need to combine the two regular-
izers for two different deﬁnitions of calibration."
NEURAL NETWORK AND DATASETS,0.551219512195122,"5.1
NEURAL NETWORK AND DATASETS"
NEURAL NETWORK AND DATASETS,0.5560975609756098,"We constructed a single neural network for our experiments and combined it with various loss func-
tions. This neural network was a two-layer perceptron with a single hidden layer containing 128
neurons, and the number of outputs was 32. The activation function after the hidden layer was the
ReLU type, and the activation function at the output node was softmax. We used Python 3.7.4 and
PyTorch 1.4.0 for the implementation. The Adam optimizer (Kingma & Ba, 2015) was utilized
for the training algorithm, with the learning rate set to 0.001, the batch size to 1024, and the other
parameters to their default values. We run training for 100 epochs."
NEURAL NETWORK AND DATASETS,0.5609756097560976,"We used three datasets for survival analysis: two obtained from the packages in R (R Core Team,
2016) and one from a private data source. Of these former two, one is the ﬂchain dataset (Dispenzieri
et al., 2012), which was obtained from the ‘survival’ package and contains 7874 data points (69.9%
of which are censored), and the other is the support dataset (Knaus et al., 1995), which was obtained
from the ‘casebase’ package and contains 9104 data points (31.9% of which are censored). The
dataset from the private data source is of patients with retinopathy disease. This dataset contains
6951 data points (33.3% of which are censored)."
NEURAL NETWORK AND DATASETS,0.5658536585365853,"We split each of the three datasets into the training (80%) and test (20%) sets by using random
partitioning. The neural network model was trained using the training set and the experimental
results shown in this section (including the Kaplan-Meier survival curves) were obtained using the
test set. When we computed the metrics (D-CAL and Kaplan-Meier loss) on a test dataset, we used
full batch (rather than the mini-batch). Regarding the parameters for D-CAL and X-CAL, we used
γ = 10000 and the collection C was the set of 20 equally sized bins disjointed over [0, 1]."
RESULTS,0.5707317073170731,"5.2
RESULTS"
RESULTS,0.5756097560975609,"Average predicted survival functions without calibration.
We compared the average survival
functions predicted by the state-of-the-art neural networks with the Kaplan-Meier survival curve on
each dataset. In our experiments, we used the ﬁxed neural network and the loss functions presented
in DeepHit (Lee et al., 2018), DRSA (Ren et al., 2019), and Survival CRPS (Avati et al., 2019). We
used α = σ = 1.0 for DeepHit and α = 0.25 for DRSA as the hyperparameters. Figure 5 shows
the average survival functions predicted by using these three loss functions and the Kaplan-Meier
survival curve on each dataset. The average of the predicted survival functions should be close to
the Kaplan-Meier survival curve if a prediction model is calibrated. However, none of the predicted
results was close to the Kaplan-Meier survival curve, which means the loss functions do not achieve
value-based calibration."
RESULTS,0.5804878048780487,Under review as a conference paper at ICLR 2022
RESULTS,0.5853658536585366,"0
1000
2000
3000
4000
5000
Time 0.0 0.2 0.4 0.6 0.8 1.0"
RESULTS,0.5902439024390244,Survival rate
RESULTS,0.5951219512195122,"lambda=10
lambda=1000
lambda=100000
Kaplan-Meier"
RESULTS,0.6,(a) ﬂchain
RESULTS,0.6048780487804878,"0
250
500
750
1000
1250
1500
1750
2000
Time 0.0 0.2 0.4 0.6 0.8 1.0"
RESULTS,0.6097560975609756,Survival rate
RESULTS,0.6146341463414634,"lambda=10
lambda=1000
lambda=100000
Kaplan-Meier"
RESULTS,0.6195121951219512,(b) support
RESULTS,0.624390243902439,"0
200
400
600
800
1000
1200
1400
1600
Time 0.0 0.2 0.4 0.6 0.8 1.0"
RESULTS,0.6292682926829268,Survival rate
RESULTS,0.6341463414634146,"lambda=10
lambda=1000
lambda=100000
Kaplan-Meier"
RESULTS,0.6390243902439025,(c) retinopathy
RESULTS,0.6439024390243903,Figure 6: Average predicted survival curves with Kaplan-Meier regularizer with varying λ.
RESULTS,0.6487804878048781,"0
1000
2000
3000
4000
5000
Time 0.0 0.2 0.4 0.6 0.8 1.0"
RESULTS,0.6536585365853659,Survival rate
RESULTS,0.6585365853658537,"lambda=10
lambda=1000
lambda=100000
Kaplan-Meier"
RESULTS,0.6634146341463415,(a) ﬂchain
RESULTS,0.6682926829268293,"0
250
500
750
1000
1250
1500
1750
2000
Time 0.0 0.2 0.4 0.6 0.8 1.0"
RESULTS,0.6731707317073171,Survival rate
RESULTS,0.6780487804878049,"lambda=10
lambda=1000
lambda=100000
Kaplan-Meier"
RESULTS,0.6829268292682927,(b) support
RESULTS,0.6878048780487804,"0
200
400
600
800
1000
1200
1400
1600
Time 0.0 0.2 0.4 0.6 0.8 1.0"
RESULTS,0.6926829268292682,Survival rate
RESULTS,0.697560975609756,"lambda=10
lambda=1000
lambda=100000
Kaplan-Meier"
RESULTS,0.7024390243902439,(c) retinopathy
RESULTS,0.7073170731707317,Figure 7: Average predicted survival curves with X-CAL regularizer with varying λ.
RESULTS,0.7121951219512195,"Calibration with our Kaplan-Meier regularizer and X-CAL.
We compared the performances
of the proposed Kaplan-Meier regularizer and X-CAL by using each of them as a regularization term
in conjunction with Survival CRPS (Avati et al., 2019). More speciﬁcally, we used the following
loss function for the Kaplan-Meier regularizer:"
RESULTS,0.7170731707317073,"ℓ(θ) = ℓS−CRPS(θ) + λRKM(θ),"
RESULTS,0.7219512195121951,"where λ is a parameter, and we used the following loss function for X-CAL:"
RESULTS,0.7268292682926829,"ℓ(θ) = ℓS−CRPS(θ) + λRX−CAL(θ),"
RESULTS,0.7317073170731707,"where λ is the parameter. Figures 6 and 7 show results by using these loss functions with various
λ from {10, 103, 105}. We can see that the average predicted survival curves are not close to the
Kaplan-Meier survival curve with small λ and therefore the predictions were not calibrated. How-
ever, regarding the average predicted survival curves with λ = 105, the predicted curves with our
Kaplan-Meier regularizer were close to the Kaplan-Meier survival curves and they are calibrated
enough. In contrast, the predicted curves with X-CAL were close to the Kaplan-Meier survival
curves, but the curves predicted by using our Kaplan-Meier regularizer were better than those with
X-CAL."
RESULTS,0.7365853658536585,"Table 1 shows the D-CAL and the Kaplan-Meier loss of these predicted results. We can see here that
using the Kaplan-Meier regularizer with large λ leads to not only reducing the Kaplan-Meier loss
but also reducing D-CAL. Similarly, using X-CAL with large λ also leads to not only reducing D-
CAL but also reducing Kaplan-Meier loss. These facts demonstrate that we can use one of these two
regularizers (the Kaplan-Meier regularizer or X-CAL) to reduce the two metrics (Kaplan-Meier loss
and D-CAL) for the real datasets, although we theoretically show that a quantile-calibrated model is
not necessarily a value-calibrated model and vice versa in the appendix (Section A.1)."
RELATED WORK,0.7414634146341463,"6
RELATED WORK"
RELATED WORK,0.7463414634146341,"We use the Kaplan-Meier estimator (Kaplan & Meier, 1958) in our Kaplan-Meier loss to estimate
the survival rate S(t) = Pr(X,T ,C)∼Q(T > t). Our loss function is not restricted to the Kaplan-
Meier estimator and we can use any other nonparametric method to estimate the survival rate S(t).
For example, we can use the Nelson-Aalen estimator (Aalen, 1978; Nelson, 1969; 1972) instead."
RELATED WORK,0.751219512195122,Under review as a conference paper at ICLR 2022
RELATED WORK,0.7560975609756098,"Table 1: D-CAL and Kaplan-Meier loss for the various combinations of dataset, regularizer, and λ"
RELATED WORK,0.7609756097560976,"Kaplan-Meier regularizer (proposed)
λ = 10
λ = 103
λ = 105"
RELATED WORK,0.7658536585365854,"D-CAL
0.1181
0.0587
0.0023
Kaplan-Meier loss
0.1110
0.0705
0.0004
ﬂchain
X-CAL (Goldstein et al., 2020)
λ = 10
λ = 103
λ = 105"
RELATED WORK,0.7707317073170732,"D-CAL
0.1176
0.0588
0.0005
Kaplan-Meier loss
0.1110
0.0730
0.0049"
RELATED WORK,0.775609756097561,"Kaplan-Meier regularizer (proposed)
λ = 10
λ = 103
λ = 105"
RELATED WORK,0.7804878048780488,"D-CAL
0.2948
0.0938
0.0089
Kaplan-Meier loss
0.0914
0.0167
0.0009
support
X-CAL (Goldstein et al., 2020)
λ = 10
λ = 103
λ = 105"
RELATED WORK,0.7853658536585366,"D-CAL
0.0839
0.0186
0.0008
Kaplan-Meier loss
0.0889
0.0426
0.0030"
RELATED WORK,0.7902439024390244,"Kaplan-Meier regularizer (proposed)
λ = 10
λ = 103
λ = 105"
RELATED WORK,0.7951219512195122,"D-CAL
0.0800
0.0505
0.0010
Kaplan-Meier loss
0.1731
0.0074
0.0004
retinopathy
X-CAL (Goldstein et al., 2020)
λ = 10
λ = 103
λ = 105"
RELATED WORK,0.8,"D-CAL
0.0783
0.0218
0.0003
Kaplan-Meier loss
0.1733
0.0524
0.0005"
RELATED WORK,0.8048780487804879,"Regarding another calibration for survival analysis, there was study on 1-Calibration (Haider et al.,
2020). In 1-Calibration, we consider the calibration of a single point of the predicted distribution, but
the entire distribution is not evaluated for calibration. We also note that the distributional divergence
for calibration (DDC) Kamran & Wiens (2021) is similar to D-CAL. The difference between DDC
and D-CAL are that D-CAL uses a binning approach and DDC uses the Kullback Leibler divergence
to measure the distance between the predicted survival function and the uniform distribution."
CONCLUSION,0.8097560975609757,"7
CONCLUSION"
CONCLUSION,0.8146341463414634,"In this work, we presented new deﬁnitions of calibration, value-based calibration, for distribution
regression and survival analysis. On the basis of the new calibration deﬁnition for survival analysis,
we then proposed a new metric called Kaplan-Meier loss for value-based calibration. The results
of experiments showed that it can be used as the regularizer of a loss function in a neural network
model for calibration, and it can be seen as a simpler alternative to X-CAL."
CONCLUSION,0.8195121951219512,Under review as a conference paper at ICLR 2022
REPRODUCIBILITY STATEMENT,0.824390243902439,"8
REPRODUCIBILITY STATEMENT"
REPRODUCIBILITY STATEMENT,0.8292682926829268,"We summarize our efforts for reproducibility. The details of our Kaplan-Meier loss and regularizer
are described in Section 4. In addition, we describe the algorithm of the Kaplan-Meier estimator
in Section 1 to make our paper self-contained, although the Kaplan-Meier estimator is a famous
algorithm in survival analysis. Regarding our experiments, we described all of the details about
our Python environment and the parameters used in Section 5. We used three datasets, and two of
them are publicly available datasets. Although we do not attach our source code, we believe that
readers of our paper can easily reproduce our results, because our algorithm is easy to implement
and inﬂuence of the undescribed factors (e.g., choice of the random seed) can be ignored (e.g., the
conclusion of our paper does not change even if the numbers in Table 1 ﬂuctuate by 20%)."
REFERENCES,0.8341463414634146,REFERENCES
REFERENCES,0.8390243902439024,"Odd Aalen. Nonparametric inference for a family of counting processes. The Annals of Statistics, 6
(4):701–726, 1978."
REFERENCES,0.8439024390243902,"Axel Andres, Aldo Montano-Loza, Russell Greiner, Max Uhlich, Ping Jin, Bret Hoehn, David
Bigam, James Andrew Mark Shapiro, and Norman Mark Kneteman. A novel learning algorithm
to predict individual survival after liver transplantation for primary sclerosing cholangitis. PLoS
One, 13(3):e0193523, 2018."
REFERENCES,0.848780487804878,"Anand Avati, Tony Duan, Sharon Zhou, Kenneth Jung, Nigam H. Shah, and Andrew Y. Ng. Count-
down regression: Sharp and calibrated survival predictions. In Proceedings of UAI 2019, pp.
145–155, 2019."
REFERENCES,0.8536585365853658,"Peng Cui, Wenbo Hu, and Jun Zhu. Calibrated reliable regression using maximum mean discrep-
ancy. In Proceedings of NeurIPS 2020, 2020."
REFERENCES,0.8585365853658536,"Lore Dirick, Gerda Claeskens, and Bart Baesens. Time to default in credit scoring using survival
analysis: a benchmark study. Journal of the Operational Research Society, 68(6):652–665, 2017."
REFERENCES,0.8634146341463415,"Angela Dispenzieri, Jerry A. Katzmann, Robert A. Kyle, Dirk R. Larson, Terry M. Therneau,
Colin L. Colby, Raynell J. Clark, Graham P. Mead, Shaji Kumar, L. Joseph Melton III, and
S. Vincent Rajkumar. Use of nonclonal serum immunoglobulin free light chains to predict overall
survival in the general population. Mayo Clinic Proceedings, 87(6):517–523, 2012."
REFERENCES,0.8682926829268293,"Mark Goldstein, Xintian Han, Aahlad Manas Puli, Adler Perotte, and Rajesh Ranganath. X-CAL:
Explicit calibration for survival analysis. In Proceedings of NeurIPS 2020, 2020."
REFERENCES,0.8731707317073171,"Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern neural
networks. In Proceedings of ICML 2017, pp. 1321–1330, 2017."
REFERENCES,0.8780487804878049,"Humza Haider, Bret Hoehn, Sarah Davis, and Russell Greiner. Effective ways to build and evaluate
individual survival distributions. Journal of Machine Learning Research, 21(85):1–63, 2020."
REFERENCES,0.8829268292682927,"Fahad Kamran and Jenna Wiens. Estimating calibrated individualized survival curves with deep
learning. In AAAI 2021, 2021."
REFERENCES,0.8878048780487805,"Edward L. Kaplan and Paul Meier. Nonparametric estimation from incomplete observations. Journal
of the American Statistical Association, 53(282):457–481, 1958."
REFERENCES,0.8926829268292683,"Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Proceedings
of ICLR 2015, 2015."
REFERENCES,0.8975609756097561,"W. A. Knaus, F. E. Harrell Jr., J. Lynn, L. Goldman, R. S. Phillips, A. F. Connors Jr., N. V. Dawson,
W. J. Fulkerson Jr., R. M. Califf, N. Desbiens, P. Layde, R. K. Oye, P. E. Bellamy, R. B. Hakim,
and D. P. Wagner. The SUPPORT prognostic model. objective estimates of survival for seriously
ill hospitalized adults. study to understand prognoses and preferences for outcomes and risks of
treatments. Annals of Internal Medicine, 122(3):191–203, 1995."
REFERENCES,0.9024390243902439,"Volodymyr Kuleshov, Nathan Fenner, and Stefano Ermon. Accurate uncertainties for deep learning
using calibrated regression. In Proceedings of ICML 2018, pp. 2796–2804, 2018."
REFERENCES,0.9073170731707317,Under review as a conference paper at ICLR 2022
REFERENCES,0.9121951219512195,"Changhee Lee, William R. Zame, Jinsung Yoon, and Mihaela van der Schaar. Deephit: A deep
learning approach to survival analysis with competing risks. In Proceedings of AAAI-18, pp.
2314–2321, 2018."
REFERENCES,0.9170731707317074,"Wayne Nelson. Hazard plotting for incomplete failure data. Journal of Quality Technology, 1:27–52,
1969."
REFERENCES,0.9219512195121952,"Wayne Nelson. Theory and applications of hazard plotting for censored failure data. Technometrics,
14(4):945–966, 1972."
REFERENCES,0.926829268292683,"R Core Team. R: A Language and Environment for Statistical Computing. R Foundation for Statis-
tical Computing, Vienna, Austria, 2016. URL https://www.R-project.org/."
REFERENCES,0.9317073170731708,"Kan Ren, Jiarui Qin, Lei Zheng, Zhengyu Yang, Weinan Zhang, Lin Qiu, and Yong Yu. Deep
recurrent survival analysis. In Proceedings of AAAI-19, pp. 4798–4805, 2019."
REFERENCES,0.9365853658536586,"Hao Song, Tom Diethe, Meelis Kull, and Peter Flach. Distribution calibration for regression. In
Proceedings of ICML 2019, pp. 5897–5906, 2019."
REFERENCES,0.9414634146341463,"Donna E. Tjandra, Yifei He, and Jenna Wiens. A hierarchical approach to multi-event survival
analysis. In Proceedings of AAAI 2021, pp. 591–599, 2021."
REFERENCES,0.9463414634146341,"Ping Wang, Yan Li, and Chandan K. Reddy. Machine learning for survival analysis: A survey. ACM
Computing Surveys, 51(6):1–36, 2019."
REFERENCES,0.9512195121951219,"Shengjia Zhao, Tengyu Ma, and Stefano Ermon. Individual calibration with randomized forecasting.
In Proceedings of ICML 2020, pp. 11387–11397, 2020."
REFERENCES,0.9560975609756097,"Panpan Zheng, Shuhan Yuan, and Xintao Wu. Safe: A neural survival analysis model for fraud early
detection. In Proceedings of AAAI-19, pp. 1278–1285, 2019."
REFERENCES,0.9609756097560975,"A
APPENDIX"
REFERENCES,0.9658536585365853,"A.1
RELATIONSHIP BETWEEN TWO DEFINITIONS OF CALIBRATION"
REFERENCES,0.9707317073170731,"We show that Deﬁnition 3.1 and Deﬁnition 4.1 are not equivalent. To see this, suppose that we have
a probability distribution P on X × Y, where X = Y = [0, 1], such that the corresponding random
variables X and Y are the uniform random variables on [0, 1] that satisfy X = Y ."
REFERENCES,0.975609756097561,"A quantile-calibrated model is not a value-calibrated model.
We consider a prediction model
F(y|x) deﬁned by"
REFERENCES,0.9804878048780488,F(y|x) =
REFERENCES,0.9853658536585366,"( 0
(x = 0),
y
(0 < x < 1),
1
(x = 1).
Since the distribution F(Y |X) is the uniform distribution on [0, 1], this prediction model F(y|x) is
quantile-calibrated by Deﬁnition 3.1. However, since we have
E(X,Y )∼PF(y|X) = 0.5
and
Pr(X,Y )∼P(Y ≤y) = y
for any y ∈(0, 1), the prediction model F(y|x) does not satisfy the condition of calibration in
Deﬁnition 4.1."
REFERENCES,0.9902439024390244,"A value-calibrated model is not a quantile-calibrated model.
We consider a prediction model
F(y|x) deﬁned by"
REFERENCES,0.9951219512195122,"F(y|x) =

0
(x > y),
1
(x ≤y).
Then this prediction model F(y|x) is value-calibrated by Deﬁnition 4.1, because we have
E(X,Y )∼PF(y|X) = y = Pr(X,Y )∼P(Y ≤y)
for any y ∈[0, 1]. However, since F(y|x) = 1 for any sample (x, y) ∼P, the prediction model
F(y|x) does not satisfy the condition of calibration in Deﬁnition 3.1."
