Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0006675567423230974,"Minimax problems are receiving an increasing amount of attention in a wide range
of applications in machine learning (ML), for instance, reinforcement learning, ro-
bust optimization, adversarial learning, and distributed computing, to mention but
a few. Current studies focus on the fundamental understanding of general minimax
problems with an emphasis on convergence behavior. As a comparison, there is
far less work to study the generalization performance. Additionally, existing gen-
eralization bounds are almost all derived in expectation, and the high probability
bounds are all presented in the slow order O(1/√n), where n is the sample size.
In this paper, we provide improved generalization analyses and obtain sharper
high probability generalization bounds for most existing generalization measures
of minimax problems. We then use the improved learning bounds to establish
high probability generalization bounds with fast rates for classical empirical sad-
dle point (ESP) solution and several popular gradient-based optimization algo-
rithms, including gradient descent ascent (GDA), stochastic gradient descent as-
cent (SGDA), proximal point method (PPM), extra-gradient (EG), and optimistic
gradient descent ascent (OGDA). In summary, we provide a systematical analysis
of sharper generalization bounds of minimax problems."
INTRODUCTION,0.0013351134846461949,"1
INTRODUCTION"
INTRODUCTION,0.0020026702269692926,"Minimax learning problems have achieved great success over a broad range of learning tasks in ma-
chine learning, with examples including reinforcement learning (Du et al., 2017; Dai et al., 2018),
robust optimization (Chen et al., 2017; Namkoong & Duchi, 2017), adversarial learning (Goodfel-
low et al., 2014), distributed computing (Razaviyayn et al., 2020; Shamma, 2008; Mateos et al.,
2010), and AUC maximization (Lei & Ying, 2021b), to just name a few. This framework is formu-
lated as a zero-sum game characterized as two groups of decision variables, one for minimization
and one for maximization. The coupling of the two groups of variables makes analysis of minimax
problems more complex than the standard statistical learning theory setting, with only one mini-
mization operator (Liu et al., 2021b; Yin et al., 2020; Li & Liu, 2021; Li et al., 2018; Liu et al.,
2020; Li & Liu, 2021). Researchers have designed various optimization algorithms, for instance,
gradient descent ascent (GDA), stochastic gradient descent ascent (SGDA), proximal point method
(PPM), extra-gradient (EG), and optimistic gradient descent ascent (OGDA), to solve the minimax
optimization problem (Farnia & Ozdaglar, 2021). Current theoretical research in ML literature is
mainly devoted to the convergence rate and optimality of these minimax optimization algorithms in
different setting, such as convex-concave settings (Nemirovski et al., 2008), nonconvex-concave set-
ting (Raﬁque et al., 2018), strongly convex-strongly-concave setting (Balamurugan & Bach, 2016),
and nonconvex-nonconcave setting (Liu et al., 2021a; Yang et al., 2020). In contrast, there is far
less work on the generalization performance analysis, which is an important measure to indicate the
performance of the learned model based on training samples when generalized to the test data."
INTRODUCTION,0.0026702269692923898,"To the best of our knowledge, there is only three work on the generalization bounds of minimax op-
timization algorithms (Zhang et al., 2021a; Farnia & Ozdaglar, 2021; Lei et al., 2021). Among them,"
INTRODUCTION,0.0033377837116154874,∗Corresponding Author.
INTRODUCTION,0.004005340453938585,Published as a conference paper at ICLR 2022
INTRODUCTION,0.004672897196261682,"(Zhang et al., 2021a) studies the generalization bounds for ESP solution to minimax problems, (Far-
nia & Ozdaglar, 2021) analyzes the generalization properties of several gradient-based optimization
algorithms: GDA, SGDA, GDmax and PPM, and (Lei et al., 2021) provides a systematical gen-
eralization analysis of SGDA. However, in the above-mentioned papers, almost all generalization
bounds are derived in expectation. Only two high probability bounds exist, proposed in (Lei et al.,
2021). Unfortunately, they are of the slow order O (1/√n)."
INTRODUCTION,0.0053404539385847796,"It is known that the high probability bound is beneﬁcial to understand the robustness of optimization
algorithms (Bousquet et al., 2020; Klochkov & Zhivotovskiy, 2021) and is much more challenging
to be derived (Bousquet et al., 2020; Lei et al., 2021; Lv et al., 2021). In this paper, our goal is
to provide the sharper high probability generalization bounds for minimax learning problems. We
leverage the lens of algorithmic stability, which is also served as an important tool in (Zhang et al.,
2021a; Farnia & Ozdaglar, 2021; Lei et al., 2021). Our contributions are summarized below."
IN VIEW OF THE COUPLING CONSTRUCTION BETWEEN THE MINIMIZATION VARIABLE AND THE MAXIMIZATION,0.006008010680907877,"1. In view of the coupling construction between the minimization variable and the maximization
variable, minimax learning problems have many generalization measures (Lei et al., 2021; Farnia
& Ozdaglar, 2021; Zhang et al., 2021a). In this paper, we provide improved stability analyses for
almost all existing generalization measures, based on which we establish sharper high probability
generalization bounds. These developed learning bounds can be employed to derive generalization
bounds with fast rates for stable minimax learning algorithms."
THE GENERALIZATION PERFORMANCE OF THE ESP SOLUTION AND GRADIENT-BASED OPTIMIZATION ALGORITHMS,0.006675567423230975,"2. The generalization performance of the ESP solution and gradient-based optimization algorithms
stands a central place in the learning theory of minimax problems (Lei et al., 2021). In this paper, we
develop high probability generalization bounds with fast rates for ESP solution and several popular
gradient-based optimization algorithms: GDA, SGDA, PPM, EG, and OGDA. Overall, we provide
a systematical analysis of sharper generalization bounds for minimax learning problems."
RELATED WORK,0.007343124165554072,"2
RELATED WORK"
RELATED WORK,0.00801068090787717,"Algorithmic stability. Algorithmic stability is a fundamental concept in learning theory (Bousquet
& Elisseeff, 2002), which has a deep connection with learnability (Rakhlin et al., 2005; Shalev-
Shwartz & Ben-David, 2014; Shalev-Shwartz et al., 2010). A training algorithm is stable if small
changes in the training set lead to small differences in the output predictions of the trained model.
Different algorithmic stability measures have been developed, including uniform stability (Bousquet
& Elisseeff, 2002; Feldman & Vondrak, 2018; 2019; Klochkov & Zhivotovskiy, 2021; Hardt et al.,
2016; Lei et al., 2020), uniform argument stability (Liu et al., 2017; Bassily et al., 2020), hypothesis
stability (Bousquet & Elisseeff, 2002; Charles & Papailiopoulos, 2018), hypothesis set stability (Fos-
ter et al., 2019), on average stability (Shalev-Shwartz et al., 2010; Lei & Ying, 2020; Kuzborskij &
Lampert, 2018; Zhang et al., 2021b; Lei & Ying, 2021a), locally elastic stability (Deng et al., 2021),
collective stability (London et al., 2016), and PAC-Bayesian stability (Li et al., 2020). These stabil-
ity measures have been extensively studied in the generalization analysis of the standard statistical
learning theory setting (Chen et al., 2018; Zhang et al., 2021b). Several stability measures have also
been extended to minimax learning problems, for instance, weak stability, argument stability, and
uniform stability (Farnia & Ozdaglar, 2021; Zhang et al., 2021a; Lei et al., 2021). In related work
(Farnia & Ozdaglar, 2021; Zhang et al., 2021a; Lei et al., 2021), they mostly focus on the expecta-
tion form of these stability measures since they are to derive bounds in expectation. In this paper,
we will focus on the last two measures, which are often used when establishing high probability
generalization bounds (Feldman & Vondrak, 2018; 2019; Klochkov & Zhivotovskiy, 2021)."
RELATED WORK,0.008678237650200267,"Convergence analysis. Convergence analysis has been widely studied in different settings, includ-
ing convex-concave learning (Nemirovski, 2005; Nedic & Ozdaglar, 2009; Mokhtari et al., 2020;
Cherukuri et al., 2017; Mokhtari et al., 2019; Balamurugan & Bach, 2016; Hsieh et al., 2019; Yan
et al., 2020; Lin et al., 2020b; Wang & Li, 2020; Yoon & Ryu, 2021), nonconvex-concave learning
(Raﬁque et al., 2018; Kong & Monteiro, 2019; Luo et al., 2020; Grnarova et al., 2017; Thekumpara-
mpil et al., 2019; Lu et al., 2020; Namkoong & Duchi, 2016; Sanjabi et al., 2018; Nouiehed et al.,
2019; Lin et al., 2020a; Sinha et al., 2017; Chen et al., 2021), and nonconvex-nonconcave learning
(Heusel et al., 2017; Balduzzi et al., 2018; Daskalakis & Panageas, 2018; Mertikopoulos et al., 2019;
Loizou et al., 2020; Yang et al., 2020; Liu et al., 2021a; Lin et al., 2018; Diakonikolas et al., 2021;
Wang et al., 2020; Loizou et al., 2021; Fiez & Ratliff, 2021). There are so many studies on conver-
gence. Thus, considering the length limit, the references listed here are not complete. Please refer"
RELATED WORK,0.009345794392523364,Published as a conference paper at ICLR 2022
RELATED WORK,0.010013351134846462,"to the related references concerning the above work. We investigate the generalization performance
of minimax problems instead of the convergence behavior. Note that the convergence analysis also
plays an essential role in this paper, formalized as strong PD empirical risk (please refer to Deﬁ-
nition 1), which is deﬁned on the function value difference and referred to as optimization error or
primal-dual gap in some convergence literature (Lei et al., 2021; Nemirovski, 2005; Mokhtari et al.,
2019; 2020)."
PRELIMINARIES,0.010680907877169559,"3
PRELIMINARIES"
PRELIMINARIES,0.011348464619492658,"Let X and Y be two parameter spaces in Rd. Let P be a probability measure deﬁned on a sample
space Z. We deﬁne f : X ×Y ×Z 7→R and consider the following minimax optimization problem"
PRELIMINARIES,0.012016021361815754,"min
x∈X max
y∈Y F(x, y) := Ez∼P[f(x, y; z)].
(1)"
PRELIMINARIES,0.012683578104138851,"The above minimax objective represents an expectation of a cost function f(x, y; z) for minimiza-
tion variable x, maximization variable y and data variable z. Unfortunately, we typically are not
available to the underlying distribution P. In practice, F is approximated by the corresponding em-
pirical risk. Let S = {z1, ..., zn} be a dataset whose samples are independent drawn according to P,
the empirical risk is deﬁned as"
PRELIMINARIES,0.01335113484646195,"FS(x, y) = 1 n n
X"
PRELIMINARIES,0.014018691588785047,"i=1
f(x, y; zi).
(2)"
PRELIMINARIES,0.014686248331108143,"Let the output of a (randomized) algorithm A on a dataset S be A(S) := (Ax(S), Ay(S)) ∈X ×Y.
Since A(S) is just an empirical approximated solution of the true minimax optimization problem,
we are interested in studying how well A(S) generalizes to the unseen data. As claimed in (Farnia
& Ozdaglar, 2021; Lei et al., 2021), the coupling between the minimization variable and the maxi-
mization variable in (1) makes minimax problems have many different generalization performance
measures. These measures are collected in (Lei et al., 2021). For better readability, we use their
symbols. Let E be the expectation with respect to (w.r.t.) the randomness of algorithm A and the
dataset S. These generalization measures are listed below.
Deﬁnition 1. (Lei et al., 2021) There are four groups of generalization measures."
PRELIMINARIES,0.015353805073431242,"1 (Primal Measures.)
The primal population risk of a model x is deﬁned as R(x)
=
supy∈Y F(x, y),
and the corresponding primal empirical risk is deﬁned as RS(x)
=
supy∈Y FS(x, y). Then, when using empirical risk RS(x) to bound R(x), we call this error of
the model x the primal generalization error. While using optimal infx∈X R(x) to bound R(x), we
call this error of the model x the excess primal population risk."
PRELIMINARIES,0.01602136181575434,"2 (Plain Measure.) When using FS(x, y) to bound F(x, y), we call the this error of a model (x, y)
the plain generalization error."
PRELIMINARIES,0.016688918558077435,"3 (Strong Measures.) The strong primal-dual (PD) population risk of a model (x, y) is deﬁned as"
PRELIMINARIES,0.017356475300400534,"△s(x, y) = sup
y′∈Y
F(x, y′) −inf
x′∈X F(x′, y),"
PRELIMINARIES,0.018024032042723633,and the corresponding strong PD empirical risk is deﬁned as
PRELIMINARIES,0.018691588785046728,"△s
S(x, y) = sup
y′∈Y
FS(x, y′) −inf
x′∈X FS(x′, y)."
PRELIMINARIES,0.019359145527369826,"Then, the strong PD generalization error △s(x, y) −△s
S(x, y) of the model (x, y) is deﬁned as

sup
y′∈Y
F(x, y′) −sup
y′∈Y
FS(x, y′)

+

inf
x′∈X FS(x′, y) −inf
x′∈X F(x′, y)

."
PRELIMINARIES,0.020026702269692925,"4 (Weak Measures.) The weak PD population risk of a (randomized) model (x, y) is deﬁned as"
PRELIMINARIES,0.02069425901201602,"△w(x, y) = sup
y′∈Y
E[F(x, y′)] −inf
x′∈X E[F(x′, y)],"
PRELIMINARIES,0.021361815754339118,and the corresponding weak PD empirical risk is deﬁned as
PRELIMINARIES,0.022029372496662217,"△w
S (x, y) = sup
y′∈Y
E[FS(x, y′)] −inf
x′∈X E[FS(x′, y)]."
PRELIMINARIES,0.022696929238985315,Published as a conference paper at ICLR 2022
PRELIMINARIES,0.02336448598130841,"Then, the weak PD generalization error △w(x, y) −△w
S (x, y) of the model (x, y) is deﬁned as

sup
y′∈Y
E[F(x, y′)] −sup
y′∈Y
E[FS(x, y′)]

+

inf
x′∈X E[FS(x′, y)] −inf
x′∈X E[F(x′, y)]

."
PRELIMINARIES,0.02403204272363151,"Remark 1. We provide some discussions for the four groups of measures. (1. Primal Measures:)
In the context of GANs, the primal population risk R(x) represents a divergence measure between
the learned and true distributions, and in the context of adversarial training it represents the learner’s
risk under adversarial perturbations (Farnia & Ozdaglar, 2021). One would be interested in the re-
lationship between R(x) and its corresponding empirical risk RS(x), and the relationship between
R(x) and its inﬁmum infx′∈X R(x′). (2. Plain Measure:) This generalization measure is a direct
extension of the standard generalization error in the minimization optimization. (3. Strong Mea-
sures:) △s
S(x, y) is referred to as the primal-dual gap in the optimization literature. △s(x, y) is
the primal-dual gap of the population risk. △s(x, y) −△s
S(x, y) studies the difference between
the population primal-dual gap and its empirical counterpart. (4. Weak Measures:) The difference
between the strong and weak measures is that weak measures take the expectation over the ran-
domness of the dataset and the algorithm, for instance, supy′∈Y F(x, y′) −infx′∈X F(x′, y) in the
strong measures and supy′∈Y E[F(x, y′)] −infx′∈X E[F(x′, y)] in the weak measures. Therefore,
the upper bounds of weak measures hold in expectation, while the upper bounds of strong measures
hold uniformly for any dataset."
PRELIMINARIES,0.024699599465954607,"Denote the Lp norm of a random variable Z as ∥Z∥p = (EZ|Z|p)1/p. Let ∥·∥be the Euclidean norm
and ⟨·, ·⟩be the inner product. A differentiable function g : W 7→R is called µ-strongly-convex in
w if the following inequality holds for every w1, w2:"
PRELIMINARIES,0.025367156208277702,"g(w1) −g(w2) ≥⟨∇g(w2), w1 −w2⟩+ µ"
PRELIMINARIES,0.0260347129506008,"2 ∥w1 −w1∥2,"
PRELIMINARIES,0.0267022696929239,"where ∇is the gradient operator. We say g is µ-strongly-concave if −g is µ-strongly-convex.
Deﬁnition 2. Let g : X × Y 7→R. Assume that X and Y are convex feasible sets. Then"
PRELIMINARIES,0.027369826435246995,"1. g is µ-strongly-convex-strongly-concave (µ-SC-SC) if g(·, y) is µ-strongly-convex for any y ∈Y
and g(x, ·) is µ-strongly-concave for any x ∈X."
PRELIMINARIES,0.028037383177570093,2. g is convex-concave (C-C) if g is 0-SC-SC.
PRELIMINARIES,0.02870493991989319,"We then introduce the deﬁnition of algorithmic stability this paper used. Algorithmic stability plays
an important role in studying the generalization behavior of a learning algorithm. Intuitively, an
algorithm A : Zn 7→(X, Y) is said to be stable if the output model (Ax(S), Ay(S)) is insensitive
to perturbations. Let S′ be a neighboring dataset that differs at most one single example to S.
Deﬁnition 3 (Algorithmic Stability). Let A be a learning algorithm and ϵ > 0."
PRELIMINARIES,0.029372496662216287,"1. We say A is ϵ-uniformly-stable if for any training datasets S, S′ ∈Zn we have
sup
z [f(Ax(S), Ay(S); z) −f(Ax(S′), Ay(S′); z)] ≤ϵ."
PRELIMINARIES,0.030040053404539385,"2. We say A is ϵ-argument-stable if for any training datasets S, S′ ∈Zn we have
∥Ax(S) −Ax(S′)∥+ ∥Ay(S) −Ay(S′)∥≤ϵ."
PRELIMINARIES,0.030707610146862484,"From Deﬁnition 3, one can see that the uniform stability measures the sensitivity of the function
values, while the argument stability measures the sensitivity of the arguments."
PRELIMINARIES,0.03137516688918558,"We ﬁnally introduce two standard assumptions in minimax problems. Assumption 1 implies f is
Lipschitz continuous w.r.t. both x and y, while Assumption 2 implies f is smooth w.r.t. (x, y).
Assumption 1 (Lipschitz continuity). Let L > 0. Assume that for any x ∈X, y ∈Y and z ∈Z,
f(x, y; z) satisﬁes
∥∇xf(x, y; z)∥≤L
and
∥∇yf(x, y; z)∥≤L.
Assumption 2 (Smoothness). Let β > 0. Assume that for any x1, x2 ∈X, y1, y2 ∈Y and z ∈Z,
f(x, y; z) satisﬁes"
PRELIMINARIES,0.03204272363150868,"∇xf(x1, y1; z) −∇xf(x2, y2; z)
∇yf(x1, y1; z) −∇yf(x2, y2; z)"
PRELIMINARIES,0.03271028037383177," ≤β"
PRELIMINARIES,0.03337783711615487,"x1 −x2
y1 −y2"
PRELIMINARIES,0.03404539385847797," ."
PRELIMINARIES,0.03471295060080107,"Under Assumption 1, the argument stability implies the uniform stability. Therefore, the argument
stability is the main stability measure that we will focus on."
PRELIMINARIES,0.035380507343124167,Published as a conference paper at ICLR 2022
MAIN RESULTS,0.036048064085447265,"4
MAIN RESULTS"
MAIN RESULTS,0.036715620827770364,"In this section, we provide sharper high probability bounds for the generalization measures of Deﬁ-
nition 1, shown as follows."
MAIN RESULTS,0.037383177570093455,"Theorem 1. Let A be a learning algorithm and ϵ > 0. Suppose |f(x, y; z)| ≤M for some M > 0
and x ∈X, y ∈Y, z ∈Z. Fixed any η > 0. There exists an absolute positive constant C."
MAIN RESULTS,0.038050734312416554,"(a.) If the algorithm A is ϵ-uniformly stable, then for any δ > 0, with probability at least 1 −δ,"
MAIN RESULTS,0.03871829105473965,"F(Ax(S), Ay(S)) ≤(1 + η)FS(Ax(S), Ay(S)) + C 1 + η η M"
MAIN RESULTS,0.03938584779706275,"n log(1/δ) + ϵ log2 n log 1 δ 
."
MAIN RESULTS,0.04005340453938585,"(b.) Assume that for all x, the function y 7→F(x, y) is µ-strongly-concave. If the algorithm A is
ϵ-argument stable and Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ,"
MAIN RESULTS,0.04072096128170895,"R(Ax(S))
≤
(1 + η)RS(Ax(S)) + C 1 + η η M"
MAIN RESULTS,0.04138851802403204,n log 1
MAIN RESULTS,0.04205607476635514,"δ +
β"
MAIN RESULTS,0.042723631508678236,"µ + 1

Lϵ log2 n log 1 δ 
."
MAIN RESULTS,0.043391188251001335,"(c.) Assume that for all x and y, the function F(x, y) is µ-SC-SC. If the algorithm A is ϵ-argument
stable and Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ,"
MAIN RESULTS,0.044058744993324434,"△s (Ax(S), Ay(S)) ≤△s
S(Ax(S), Ay(S)) + ηES △s
S (Ax(S), Ay(S))"
MAIN RESULTS,0.04472630173564753,"+ C(1 + η)
L2(1 + η)"
MAIN RESULTS,0.04539385847797063,"nµη
+ M"
MAIN RESULTS,0.04606141522029372,"n +

1 + β µ"
MAIN RESULTS,0.04672897196261682,"
ϵL log2 n

log
1 δ 
."
MAIN RESULTS,0.04739652870493992,"(d.) Assume that for all x and y, the function F(x, y) is µ-SC-SC. If the algorithm A is ϵ-argument
stable and Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ,"
MAIN RESULTS,0.04806408544726302,"△s (Ax(S), Ay(S)) −△s
S(Ax(S), Ay(S)) ≤ηES △s
S (Ax(S), Ay(S))"
MAIN RESULTS,0.048731642189586116,"+ C(1 + η)
L2(1 + η)"
MAIN RESULTS,0.049399198931909215,"nµη
+ M"
MAIN RESULTS,0.050066755674232306,"n +

1 + β µ"
MAIN RESULTS,0.050734312416555405,"
ϵL log2 n

log
1 δ 
."
MAIN RESULTS,0.0514018691588785,"(e.) Assume that for all x, the function y 7→F(x, y) is µ-strongly-concave. If the algorithm A is
ϵ-argument stable and Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ,"
MAIN RESULTS,0.0520694259012016,"R(Ax(S)) ≤(1 + η) inf
x∈X R(x)"
MAIN RESULTS,0.0527369826435247,+ C 2 + η η M
MAIN RESULTS,0.0534045393858478,n log 1
MAIN RESULTS,0.0540720961281709,"δ +
β"
MAIN RESULTS,0.05473965287049399,"µ + 1

Lϵ log2 n log 1"
MAIN RESULTS,0.05540720961281709,"δ + △s
S(Ax(S), Ay(S))

."
MAIN RESULTS,0.056074766355140186,"According to Deﬁnition 1 and Jensen’s inequality, we know that △w(x, y) ≤E[△s(x, y)] and
△w
S (x, y) ≤E[△s
S(x, y)]. By this connection, we have △w(x, y) −△w
S (x, y) ≤E[△s(x, y)] +
|E[△s
S(x, y)]|. We therefore obtain the following results for △w(x, y) and △w(x, y) −△w
S (x, y)."
MAIN RESULTS,0.056742323097463285,Corollary 1. Suppose the same conditions as Theorem 1 hold.
MAIN RESULTS,0.05740987983978638,"(f.) If the assumptions of Part (c) in Theorem 1 hold, then with probability at least 1 −δ,"
MAIN RESULTS,0.05807743658210948,"△w (Ax(S), Ay(S)) ≤(1 + η)E △s
S (Ax(S), Ay(S))"
MAIN RESULTS,0.05874499332443257,"+ C(1 + η)
L2(1 + η)"
MAIN RESULTS,0.05941255006675567,"nµη
+ M"
MAIN RESULTS,0.06008010680907877,"n +

1 + β µ"
MAIN RESULTS,0.06074766355140187,"
ϵL log2 n

log
1 δ 
."
MAIN RESULTS,0.06141522029372497,"(g.) If the assumptions of Part (d) in Theorem 1 hold, then with probability at least 1 −δ,"
MAIN RESULTS,0.062082777036048066,"△w (Ax(S), Ay(S)) −△w
S (Ax(S), Ay(S)) ≤|E △s
S (Ax(S), Ay(S))|"
MAIN RESULTS,0.06275033377837116,"+ (1 + η)E △s
S (Ax(S), Ay(S)) + C(1 + η)
L2(1 + η)"
MAIN RESULTS,0.06341789052069426,"nµη
+ M"
MAIN RESULTS,0.06408544726301736,"n +

1 + β µ"
MAIN RESULTS,0.06475300400534045,"
ϵL log2 n

log
1 δ 
."
MAIN RESULTS,0.06542056074766354,Published as a conference paper at ICLR 2022
MAIN RESULTS,0.06608811748998665,"Remark 2. In Theorem 1, we have established a quantitative connection between the generalization
measures and the stability measures. The complete proof of Theorem 1 is provided in Appendix A."
MAIN RESULTS,0.06675567423230974,"Part (a) provides the relationship between the uniform stability and the plain generalization er-
ror of (Ax(S), Ay(S)).
If the uniform stability of algorithm A is of fast order O(1/n), then
F(Ax(S), Ay(S)) is bounded by (1 + η)O
 
FS(Ax(S), Ay(S)) + log n log(1/δ)"
MAIN RESULTS,0.06742323097463285,"nη

. Usually for a
well-trained model (Ax(S), Ay(S)) over the training set, the empirical risk FS(Ax(S), Ay(S)) is
small or even zero (Lever et al., 2013; Yang et al., 2019; Cortes et al., 2021). If the empirical risk is
of order O(1/n), then we can choose a proper constant for η and the plain generalization error will
be of fast order O
  log n log(1/δ)"
MAIN RESULTS,0.06809078771695594,"n

. It is O(1/n) when we hide the logarithmic term. In the related
work, (Lei et al., 2021) also establish the plain generalization error bound under the same assump-
tions, but their bound is of slow order O
 
ϵ log n log(1/δ) + Mn−1"
P,0.06875834445927904,2 p
P,0.06942590120160214,"log(1/δ)

. Even if they get
a sharper bound for stability measure ϵ, the inﬂuence of O
 
n−1"
P,0.07009345794392523,2 p
P,0.07076101468624833,"log(1/δ)

can not disappear. By
comparison, we have completely removed the O(1/√n) term. Thus, our plain generalization error
bound enables the fast O(1/n) rate when the empirical risk is small."
P,0.07142857142857142,"Part (b) provides the connection between the argument stability and the primal generalization error.
Similar to the analysis of Part (a), if both the argument stability of algorithm A and RS(Ax(S))
are of order O(1/n), then the primal generalization error implies a fast O
 
1/n

rate. Consider-
ing that we assume the function f is well-behaved, i.e., Lipschitz continuity, smoothness, and the
strong-concavity of its population risk F, and that RS(Ax(S)) is data-dependent, thus it is reason-
able to assume RS(Ax(S)) is small for a well-trained model Ax(S) (Lever et al., 2013; Yang et al.,
2019; Cortes et al., 2021). In (Lei et al., 2021), they also establish a bound for primal general-
ization error under the same assumptions. However, their bound is O
 
Lβµ−1ϵlogn log(1/δ) +
Mn−1"
P,0.07209612817089453,2 p
P,0.07276368491321762,"log(1/δ)

, limited to the O(1/√n) order.
In contrast, we successfully removed the
O(1/√n) term, which makes the fast rate possible. (Farnia & Ozdaglar, 2021) studies the expected
primal generalization error, i.e., bounding ES,A[R(Ax(S))] by ES,A[RS(Ax(S))]. They establish
the connection between the stability measure and the expected error under the same assumptions
as Part (b), which is then used to derive generalization bounds for (S)GDA, (S)GDmax, and PPM
algorithms. By comparison, our bound is derived in high probability."
P,0.07343124165554073,"Part (c) provides the relationship between the argument stability and the strong PD population risk.
If both the argument stability of algorithm A and the strong PD empirical risk are all of the order
O(1/n), the strong PD population risk will be of the fast order O(1/n). Note that in our proof for
the gradient-based optimization algorithms, the strong PD empirical risk mainly has a dependence
on the iterative number T (see Lemma 8 of GDA, Lemma 11 of SGDA, etc.). To obtain sharper
generalization bounds, we require T to be associated with n, such as T = O(n2) for GDA, the
strong PD empirical risk ﬁnally has a dependence on the sample size n. To our best knowledge,
this is the ﬁrst high probability strong PD population risk bound. The expected version of this
risk is studied for the ESP solution in (Zhang et al., 2021a). However, the discussion there does
not establish the connection between stability and generalization. Their analysis is restricted to the
speciﬁc ESP problem. Under the same assumptions, they provide the upper bound of order O (1/n).
Compared with their result, our result is presented in high probability. Additionally, our strong PD
population risk bound is applicable for any stable minimax optimization algorithms."
P,0.07409879839786382,"Part (d) provides the connection between the argument stability and the strong PD generalization
error. Similarly, if both the argument stability of algorithm A and the strong PD empirical risk are
all of O(1/n) order, the strong PD generalization error will be of the fast order O(1/n). Although
Part (c) and Part (d) have a similar upper bound, they are different generalization measures (Lei
et al., 2021). To our best knowledge, this is also the ﬁrst high probability strong PD generalization
error bound. The expected version of this generalization error is studied in (Lei et al., 2021), that
is ES,A [△s(Ax(S), Ay(S)) −△s
S(Ax(S), Ay(S))]. Under the same assumptions, their expected
strong PD generalization error is bounded by (1 + β/µ)L
√"
P,0.07476635514018691,"2ϵ, which can also be used to obtain
O (1/n) order rate when ϵ is of order O(1/n). However, this bound is provided for the expected
error, while our bound is high probabilistic and holds uniformly for any dataset."
P,0.07543391188251002,"Part (e) provides the relationship between the argument stability and the excess primal population
risk. Similar to the analysis of Part (a) and Part (b), if the argument stability of algorithm A, the
strong PD empirical risk, and infx∈X R(x) are all of the order O(1/n), the excess primal population"
P,0.07610146862483311,Published as a conference paper at ICLR 2022
P,0.07676902536715621,"risk will also be of the fast order O(1/n). Meanwhile, in the minimization learning problems,
assuming the optimal population risk F ∗is small or even zero, i.e., F ∗≤O(1/n), can be found
in (Lei & Ying, 2021a; Zhang et al., 2017; Zhang & Zhou, 2019; Srebro et al., 2010; Lei & Ying,
2020). Note that the optimal population risk F ∗= O(1/n) just to show that the improved bound can
be got under low noise conditions. F ∗should be independent of n. Similar to the assumption on F ∗
and considering that we assume the function f is well-behaved, it will also be reasonable to assume
infx∈X R(x) is small. High probability excess primal population risk bound is also studied for
SGDA in (Lei et al., 2021). Their bound, however, is of slow order O
 
(β/µ)n−1"
P,0.0774365821094793,"2 log n log2(1/δ)
"
P,0.07810413885180241,"and is restricted to SGDA. By comparison, our result in Part (e) enables O(1/n) bounds for stable
minimax learning algorithms since we have completely removed the O(1/√n) term."
P,0.0787716955941255,"We discuss a noteworthy difference between (Farnia & Ozdaglar, 2021; Lei et al., 2021) and ours.
In Part (a), Part (b), and Part (e), we study the upper bounds of F(Ax(S), Ay(S)), R(Ax(S)) (w.r.t.
RS(Ax(S))), and R(Ax(S)) (w.r.t. infx∈X R(x)), respectively, while (Lei et al., 2021; Farnia &
Ozdaglar, 2021) study the upper bounds of F(Ax(S), Ay(S)) −FS(Ax(S), Ay(S)), R(Ax(S)) −
RS(Ax(S)), and R(Ax(S)) −infx∈X R(x) (or their expected forms). One of our motivations to
study such forms is that, in practice, we are often directly interested in the true risk, i.e., how the
learned models behave on the testing data, such as F(Ax(S), Ay(S)), instead of the error between
the true risk and empirical risk. Note that in the above comparison between Theorem 1 and the
results in (Lei et al., 2021; Farnia & Ozdaglar, 2021), we all take the right side of the generalization
bound inequalities to compare, which is fair since our bounds can be written as F(Ax(S), Ay(S))−
FS(Ax(S), Ay(S)) ≤ηFS(Ax(S), Ay(S)) + C 1+η η ( M"
P,0.0794392523364486,n log(1/δ) + ϵ log2 n log 1
P,0.0801068090787717,"δ ), etc."
P,0.08077436582109479,"Remark 3. From Remark 2, one can see that compared with (Zhang et al., 2021a; Farnia &
Ozdaglar, 2021; Lei et al., 2021), we have established sharper high probability generalization
bounds. In the applications of Section 5, we will establish O(1/n) order bounds for two terms
in Theorem 1: stability measures and strong PD empirical risk. Hence, the strong PD population
risk and the strong PD generalization error will be of the fast order O(1/n) when applying Theorem
1 to these applications. These bounds are clearly of order O(1/n) and sharper than the results in
(Zhang et al., 2021a; Farnia & Ozdaglar, 2021; Lei et al., 2021). For the plain generalization er-
ror, the primal generalization error, and the excess primal population risk, to obtain O(1/n) order
bounds for these applications, we need to assume the extra corresponding terms F(Ax(S), Ay(S)),
R(Ax(S)), and infx∈X R(x) are of order O(1/n), respectively. The clear motivation is that in
practice, learning algorithms achieve a small or even zero empirical risk, as discussed in Remark 2."
P,0.0814419225634179,"Remark 4. This remark discusses η in Part (a), Part (b), and Part (e). (1:) When establishing sharper
generalization error bound (i.e., Pf −Pnf), the existence of η is common in the standard statistical
learning theory. Speciﬁcally, in the uniform localized convergence theory, the generalization error
bound in (Bartlett et al., 2005) is of the form Pf ≤
η
η−1Pnf + O(ηr∗+ η log(1/δ)"
P,0.08210947930574099,"n
) with η >
1 (see Theorem 3.3 and Theorem 4.1). In the PAC-Bayesian theory, the generalization bounds
in (Catoni, 2007) (see Theorem 1.2.6), (Lever et al., 2013) (see Theorem 6), (Yang et al., 2019)
(see Proposition 3.1 and Theorem 4.3), etc., also have η. For instance, the Catoni’s bound is of
the form PQ ≤
1
1−e−η
 
ηPnQ + O( KL(Q∥P rior)+log(1/δ)"
P,0.08277703604806408,"n
)

with η > 0 (Catoni, 2007). In the
algorithmic stability theory, Theorem 1.2 in (Klochkov & Zhivotovskiy, 2021) is of the form Pf ≤
(1 + η)Pnf + 1+η"
P,0.08344459279038718,η O((ϵ log n + 1
P,0.08411214953271028,n) log( 1
P,0.08477970627503338,"δ )) with η > 0. In the recent Cortes’s deviation margin
bounds (Cortes et al., 2021), they also imply a multiplier η. The above bounds can be transformed
into the form of empirical risk multiplied by 1 + η, similar to our results. It is discussed in (Lever
et al., 2013; Yang et al., 2019; Cortes et al., 2021; Bartlett et al., 2005; Klochkov & Zhivotovskiy,
2021) that this type of generalization error bound can obtain a fast rate when the empirical risk
is small. Note that Part (e) also involves generalization error bounds due to the decomposition,
see (31). The above generalization error analysis thus holds for Part (e). (2:) Furthermore, in
(10), we show that F(Ax(S), Ay(S)) −FS(Ax(S), Ay(S)) ≤O
 
( MF (Ax(S),Ay(S)) log(1/δ)"
P,0.08544726301735647,"n
)
1
2 +
ϵ log( 1"
P,0.08611481975967958,"δ )

, where M means that |f(x, y; z)| ≤M, ∀x, y, z. Using the elementary inequality
√"
P,0.08678237650200267,"ab ≤
ηa + 1"
P,0.08744993324432576,"ηb for any a, b, η > 0 and by some rearrangements, the form of Part (a) appears. This is
the reason why η exists. The corresponding bound in (Lei et al., 2021) is F(Ax(S), Ay(S)) −
FS(Ax(S), Ay(S)) ≤O
 
ϵ log n log( 1"
P,0.08811748998664887,δ ) + Mn−1
P,0.08878504672897196,2 log1/2( 1
P,0.08945260347129506,"δ )

. Focusing on the dominated term,
it is clear that F(Ax(S), Ay(S)) ≪M since F(Ax(S), Ay(S)) is data-dependent, which implies
that our plain generalization error bound is sharper. Similar analysis holds for Part (b) and Part (e)."
P,0.09012016021361816,Published as a conference paper at ICLR 2022
P,0.09078771695594126,"Reference
Algorithm
Assumption
Generalization Measure
Learning Bound"
P,0.09145527369826435,"Zhang
ESP
SC-SC, Lip
Weak PD Risk
O(1/n)
SC-SC, Lip, S
(E.) Strong PD Risk
O(1/n)
R-ESP
C-C, Lip
Weak PD Risk
O(1/√n)"
P,0.09212283044058744,Farnia
P,0.09279038718291055,"SGDA
SC-SC, Lip, S
(E.) Primal generalization
O(1/n)
SGDmax
SC-SC, Lip, S
(E.) Primal generalization
O(1/n)
GDA
SC-SC, Lip, S
(E.) Primal generalization
O(1/n)
GDmax
SC-SC, Lip, S
(E.) Primal generalization
O(1/n)
PPM
SC-SC, Lip, S
(E.) Primal generalization
O(1/n)
PPM
C-C, Lip, S
(E.) Primal generalization
O(1/√n)
SGDA
Lip, S
(E.) Primal generalization
O
 
T"
P,0.09345794392523364,"βc
βc+1 /n
"
P,0.09412550066755675,"SGDmax
NC-SC, Lip, S
(E.) Primal generalization
O
 
T"
P,0.09479305740987984,"(k+1)βc
(k+10Lβ+1 /n
"
P,0.09546061415220294,"Lei
SGDA"
P,0.09612817089452604,"C-C, Lip
Weak PD Risk
O(1/√n)
C-C, Lip, S
Weak PD Risk
O(1/√n)
SC-SC, Lip
Weak PD Risk
O(√log n/n)
SC-SC, Lip, S
Weak PD Risk
O(log n/n)
C-SC, Lip, S
(E.) Excess Primal Risk
O(1/√n)
C-SC, Lip, S
(H.P.) Excess Primal Risk
O(log n/√n)
C-C, Lip
(H.P.) Plain Generalization
O(log n/√n)
WC-WC, Lip
Weak PD Generalization
O
 
T"
P,0.09679572763684913,"2cµ
2cµ+3 /n"
P,0.09746328437917223,"2cµ+1
2cµ+3 "
P,0.09813084112149532,"V-WC-WC, Lip, S
Weak PD Generalization
O
 
1/√n
"
P,0.09879839786381843,"AGDA
NC-SC, PL, Lip, S
(E.) Excess Primal Risk
O
 
n−cβ+1"
P,0.09946595460614152,2cβ+1  Ours ESP
P,0.10013351134846461,"SC-SC, Lip, LN
Plain Generalization
O(log n/n)
SC-SC, Lip, S, LN
Primal Generalization
O(log n/n)
SC-SC, Lip, S
Strong PD Risk
O(log n/n)
SC-SC, Lip, S
Strong PD Generalization
O(log n/n)
SC-SC, Lip, S, LN
Excess Primal Risk
O(log n/n) GDA"
P,0.10080106809078772,"SC-SC, Lip, LN
Plain Generalization
O((log n)3/2/n)
SC-SC, Lip, S, LN
Primal Generalization
O((log n)3/2/n)
SC-SC, Lip, S
Strong PD Risk
O((log n)3/2/n)
SC-SC, Lip, S
Strong PD Generalization
O((log n)3/2/n)
SC-SC, Lip, S, LN
Excess Primal Risk
O((log n)3/2/n) SGDA"
P,0.10146862483311081,"SC-SC, Lip, LN
Plain Generalization
O(log n/n)
SC-SC, Lip, S, LN
Primal Generalization
O(log n/n)
SC-SC, Lip, S
Strong PD Risk
O(log n/n)
SC-SC, Lip, S
Strong PD Generalization
O(log n/n)
SC-SC, Lip, S, LN
Excess Primal Risk
O(log n/n) PPM"
P,0.10213618157543392,"SC-SC, Lip, S, LN
Plain Generalization
O(log n/n)
SC-SC, Lip, S, LN
Primal Generalization
O(log n/n)
SC-SC, Lip, S
Strong PD Risk
O(log n/n)
SC-SC, Lip, S
Strong PD Generalization
O(log n/n)
SC-SC, Lip, S, LN
Excess Primal Risk
O(log n/n) EG"
P,0.102803738317757,"SC-SC, Lip, S, LN
Plain Generalization
O(log n/n)
SC-SC, Lip, S, LN
Primal Generalization
O(log n/n)
SC-SC, Lip, S
Strong PD Risk
O(log n/n)
SC-SC, Lip, S
Strong PD Generalization
O(log n/n)
SC-SC, Lip, S, LN
Excess Primal Risk
O(log n/n) OGDA"
P,0.10347129506008011,"SC-SC, Lip, S, LN
Plain Generalization
O(log n/n)
SC-SC, Lip, S, LN
Primal Generalization
O(log n/n)
SC-SC, Lip, S
Strong PD Risk
O(log n/n)
SC-SC, Lip, S
Strong PD Generalization
O(log n/n)
SC-SC, Lip, S, LN
Excess Primal Risk
O(log n/n)"
P,0.1041388518024032,"Table 1: Summary of Results. Here, “Zhang” means reference (Zhang et al., 2021a), “Farnia” means
reference (Farnia & Ozdaglar, 2021), and “Lei” means reference (Lei et al., 2021). The bounds are
established by choosing an optimal iterate number T. “LN” means the low noise condition, see
Section 5.1. Other auxiliary descriptions of Table 1 are shown in Appendix H."
P,0.1048064085447263,Published as a conference paper at ICLR 2022
P,0.1054739652870494,"In summary, the above analyses from two different perspectives support our claim that Part (a), Part
(b), and Part (e) provide sharper high probability generalization bounds.
Remark 5. Different measures quantify different degrees of the generalization error. Thus, deriv-
ing bounds of different generalization measures requires different assumptions (Lei et al., 2021;
Zhang et al., 2021a; Farnia & Ozdaglar, 2021). Strong measures require stronger assumptions
compared with the weak (Lei et al., 2021). For instance, for the term supy∈Y F(Ax(S), y) in
△s(Ax(S), Ay(S)), one has to consider the fact that for different Ax(S), y is different, which
makes the proof more challenging.
While in △w(Ax(S), Ay(S)) and △w(Ax(S), Ay(S)) −
△w
S (Ax(S), Ay(S)), both the supremum over Ax(S) and Ay(S) are outside the expectation op-
erator, thus one does not need to consider the coupling between Ax(S) and y. The upper bounds
shown in Corollary 1 directly derived from Theorem 1 are sub-optimal since △w(Ax(S), Ay(S))
and △w(Ax(S), Ay(S)) −△w
S (Ax(S), Ay(S)) are pretty weak generalization measures (Lei et al.,
2021). We list Corollary 1 here to suggest that, when Theorem 1 is established, the fast order O(1/n)
is easy to be achieved for △w(Ax(S), Ay(S)) and △w(Ax(S), Ay(S)) −△w
S (Ax(S), Ay(S)). On
the other hand, the two weak generalization measures in (Zhang et al., 2021a) is studied for the
speciﬁc ESP solution, while Corollary 1 is applicable for any stable minimax learning algorithms, it
thus may be useful in some applications."
APPLICATIONS,0.10614152202937249,"5
APPLICATIONS"
APPLICATIONS,0.1068090787716956,"We now apply Theorem 1 to the ESP solution and several gradient-based optimization algorithms:
GDA, SGDA, PPM, EG, and OGDA. Considering the length limit, we postpone the introductions
and theorems of these applications to the Appendix. Here, we list the generalization bounds of these
optimization algorithms in Table 1."
APPLICATIONS,0.10747663551401869,"5.1
DESCRIPTIONS OF TABLE 1"
APPLICATIONS,0.1081441922563418,"Table 1 gives almost all existing generalization bounds in minimax learning. In Table 1, “LN” means
the low noise conditions, i.e., the corresponding F(Ax(S), Ay(S)), R(Ax(S)), or infx∈X R(x) of
these applications is of the order O(1/n). For instance, for the ESP solution (ˆx∗
S, ˆy∗
S), we assume
F(ˆx∗
S, ˆy∗
S), R(ˆx∗
S), and infx∈X R(x) are of the order O(1/n) for the plain generalization error, the
primal generalization error, and the excess primal population risk, respectively. For other learning
algorithms, please refer to the Remarks in the Appendix. In Table 1, we compare our results with
(Zhang et al., 2021a; Farnia & Ozdaglar, 2021; Lei et al., 2021) in the way described in the last
paragraph of Remark 2. (E.) denotes that the bound is derived in expectation, while (H.P.) denotes
high probability. Since our results are all established with high probability, we thus omit (H.P.) for
brevity. The descriptions of other notations are shown in Appendix H."
APPLICATIONS,0.10881174899866489,"In Table 1, (Zhang et al., 2021a) and (Farnia & Ozdaglar, 2021) focus on the expected generalization
measures. We improve the learning bounds of the ESP solution in (Zhang et al., 2021a) to high prob-
ability guarantees. Compared with (Farnia & Ozdaglar, 2021), we have provided high probability
primal generalization error bounds for GDA, SGDA, and PPM. Additionally, we also study other
generalization measures. (Lei et al., 2021) focus on SGDA and mainly provide guarantees for weak
generalization measures, i.e., weak PD risk and weak PD generalization error. In contrast, we have
developed bounds for strong PD risk and strong PD generalization error. Note that the two type of
bounds don’t require the “LN” condition. Moreover, although (Lei et al., 2021) provides two high
probability bounds, however, in slow order. Note that in addition to the classical GDA, SGDA, and
PPM, we also provide sharper high probability bounds for EG and OGDA in that their widespread
use in training GANs (Mokhtari et al., 2019; Daskalakis et al., 2017; Liang & Stokes, 2019)."
CONCLUSION,0.10947930574098798,"6
CONCLUSION"
CONCLUSION,0.11014686248331108,"In this paper, we provide a systematical analysis of sharper generalization bounds for minimax
problems. We ﬁrst establish sharper high probability bounds for almost all existing generalization
measures via algorithmic stability and then apply these bounds to several important applications. We
believe that our research can provide in-depth insights into minimax learning problems. For future
work, it would be important to relax the assumptions in this paper. Also, it would be interesting to
investigate how well other theoretical tools perform on the generalization of minimax problems."
CONCLUSION,0.11081441922563418,Published as a conference paper at ICLR 2022
CONCLUSION,0.11148197596795728,ACKNOWLEDGMENTS
CONCLUSION,0.11214953271028037,"We appreciate all the anonymous reviewers for their invaluable and constructive comments.
This work is supported in part by the National Natural Science Foundation of China (No.
62076234, No.61703396, No.
62106257), Beijing Outstanding Young Scientist Program
NO.BJJWZYJH012019100020098, Intelligent Social Governance Platform, Major Innovation &
Planning Interdisciplinary Platform for the ”Double-First Class” initiative, Renmin University of
China, China Unicom Innovation Ecological Cooperation Plan, Public Computing Cloud of Renmin
University of China, Beijing Natural Science Foundation (No. 4222029)."
REFERENCES,0.11281708945260348,REFERENCES
REFERENCES,0.11348464619492657,"Palaniappan Balamurugan and Francis Bach. Stochastic variance reduction methods for saddle-point
problems. In Advances in Neural Information Processing Systems, 2016."
REFERENCES,0.11415220293724966,"David Balduzzi, S´ebastien Racani`ere, James Martens, Jakob N. Foerster, Karl Tuyls, and Thore
Graepel. The mechanics of n-player differentiable games. In International Conference on Ma-
chine Learning, 2018."
REFERENCES,0.11481975967957277,"Peter L. Bartlett, Olivier Bousquet, and Shahar Mendelson. Local rademacher complexities. Annals
of Statistics, 33(4):1497–1537, 2005."
REFERENCES,0.11548731642189586,"Raef Bassily, Vitaly Feldman, Crist´obal Guzm´an, and Kunal Talwar. Stability of stochastic gradient
descent on nonsmooth convex losses. In Advances in Neural Information Processing Systems,
2020."
REFERENCES,0.11615487316421896,"St´ephane Boucheron, G´abor Lugosi, and Pascal Massart. Concentration inequalities: A nonasymp-
totic theory of independence. Oxford university press, 2013."
REFERENCES,0.11682242990654206,"Olivier Bousquet and Andr´e Elisseeff. Stability and generalization. Journal of Machine Learning
Research, 2(3):499–526, 2002."
REFERENCES,0.11748998664886515,"Olivier Bousquet, Yegor Klochkov, and Nikita Zhivotovskiy. Sharper bounds for uniformly stable
algorithms. In Conference On Learning Theory, 2020."
REFERENCES,0.11815754339118825,"Olivier Catoni. PAC-BAYESIAN SUPERVISED CLASSIFICATION: The Thermodynamics of Statis-
tical Learning. 2007."
REFERENCES,0.11882510013351134,"Zachary Charles and Dimitris Papailiopoulos. Stability and generalization of learning algorithms
that converge to global optima. In International Conference on Machine Learning, 2018."
REFERENCES,0.11949265687583445,"Robert S. Chen, Brendan Lucier, Yaron Singer, and Vasilis Syrgkanis. Robust optimization for
non-convex objectives. In Advances in Neural Information Processing Systems, 2017."
REFERENCES,0.12016021361815754,"Yuansi Chen, Chi Jin, and Bin Yu. Stability and convergence trade-off of iterative optimization
algorithms. arXiv preprint arXiv:1804.01619, 2018."
REFERENCES,0.12082777036048065,"Ziyi Chen, Yi Zhou, Tengyu Xu, and Yingbin Liang. Proximal gradient descent-ascent: Variable
convergence under kłgeometry. In International Conference on Learning Representations, 2021."
REFERENCES,0.12149532710280374,"Ashish Cherukuri, Bahman Gharesifard, and Jorge Cortes. Saddle-point dynamics: conditions for
asymptotic stability of saddle points. Siam Journal on Control and Optimization, 55(1):486–511,
2017."
REFERENCES,0.12216288384512683,"Corinna Cortes, Mehryar Mohri, and Ananda Theertha Suresh. Relative deviation margin bounds.
In International Conference on Machine Learning, pp. 2122–2131, 2021."
REFERENCES,0.12283044058744993,"Bo Dai, Albert Shaw, Lihong Li, Lin Xiao, Niao He, Zhen Liu, Jianshu Chen, and Le Song. Sbeed:
Convergent reinforcement learning with nonlinear function approximation. In International Con-
ference on Machine Learning, 2018."
REFERENCES,0.12349799732977303,"Constantinos Daskalakis and Ioannis Panageas. The limit points of (optimistic) gradient descent in
min-max optimization. In Advances in Neural Information Processing Systems, 2018."
REFERENCES,0.12416555407209613,Published as a conference paper at ICLR 2022
REFERENCES,0.12483311081441922,"Constantinos Daskalakis, Andrew Ilyas, Vasilis Syrgkanis, and Haoyang Zeng. Training gans with
optimism. In International Conference on Learning Representations, 2017."
REFERENCES,0.12550066755674233,"Zhun Deng, Hangfeng He, and Weijie Su. Toward better generalization bounds with locally elastic
stability. In International Conference on Machine Learning, 2021."
REFERENCES,0.1261682242990654,"Jelena Diakonikolas, Constantinos Daskalakis, and Michael I. Jordan. Efﬁcient methods for struc-
tured nonconvex-nonconcave min-max optimization. In International Conference on Artiﬁcial
Intelligence and Statistics, 2021."
REFERENCES,0.1268357810413885,"Simon S. Du, Jianshu Chen, Lihong Li, Lin Xiao, and Dengyong Zhou. Stochastic variance reduc-
tion methods for policy evaluation. In International Conference on Machine Learning, 2017."
REFERENCES,0.12750333778371162,"Farzan Farnia and Asuman Ozdaglar. Train simultaneously, generalize better: Stability of gradient-
based minimax learners. In International Conference on Machine Learning, 2021."
REFERENCES,0.12817089452603472,"Vitaly Feldman and Jan Vondrak. Generalization bounds for uniformly stable algorithms. In Ad-
vances in Neural Information Processing Systems, 2018."
REFERENCES,0.1288384512683578,"Vitaly Feldman and Jan Vondrak. High probability generalization bounds for uniformly stable algo-
rithms with nearly optimal rate. In Conference on Learning Theory, 2019."
REFERENCES,0.1295060080106809,"Tanner Fiez and Lillian J Ratliff. Local convergence analysis of gradient descent ascent with ﬁnite
timescale separation. In International Conference on Learning Representations, 2021."
REFERENCES,0.130173564753004,"Dylan J. Foster, Spencer Greenberg, Satyen Kale, Haipeng Luo, Mehryar Mohri, and Karthik Srid-
haran. Hypothesis set stability and generalization. In Advances in Neural Information Processing
Systems, 2019."
REFERENCES,0.1308411214953271,"Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural Infor-
mation Processing Systems, 2014."
REFERENCES,0.1315086782376502,"Paulina Grnarova, Kﬁr Y. Levy, Aur´elien Lucchi, Thomas Hofmann, and Andreas Krause. An online
learning approach to generative adversarial networks. In International Conference on Learning
Representations, 2017."
REFERENCES,0.1321762349799733,"Moritz Hardt, Benjamin Recht, and Yoram Singer.
Train faster, generalize better: stability of
stochastic gradient descent. In International Conference on Machine Learning, 2016."
REFERENCES,0.1328437917222964,"Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a two time-scale update rule converge to a local nash equilibrium. In Advances
in Neural Information Processing Systems, 2017."
REFERENCES,0.13351134846461948,"Yu-Guan Hsieh, Franck Iutzeler, J´erˆome Malick, and Panayotis Mertikopoulos. On the convergence
of single-call stochastic extra-gradient methods. In Advances in Neural Information Processing
Systems, 2019."
REFERENCES,0.1341789052069426,"Hamed Karimi, Julie Nutini, and Mark Schmidt. Linear convergence of gradient and proximal-
gradient methods under the polyak-łojasiewicz condition. In Joint European Conference on Ma-
chine Learning and Knowledge Discovery in Databases, pp. 795–811, 2016."
REFERENCES,0.1348464619492657,"Yegor Klochkov and Nikita Zhivotovskiy. Stability and deviation optimal risk bounds with conver-
gence rate O(1/n). Advances in Neural Information Processing Systems, 2021."
REFERENCES,0.13551401869158877,"Weiwei Kong and Renato D. C. Monteiro. An accelerated inexact proximal point method for solving
nonconvex-concave min-max problems. arXiv preprint arXiv:1905.13433, 2019."
REFERENCES,0.13618157543391188,"G. M. Korpelevich. The extragradient method for ﬁnding saddle points and other problems. Mate-
con, 12:747–756, 1976."
REFERENCES,0.13684913217623498,"Ilja Kuzborskij and Christoph Lampert. Data-dependent stability of stochastic gradient descent. In
International Conference on Machine Learning, 2018."
REFERENCES,0.1375166889185581,Published as a conference paper at ICLR 2022
REFERENCES,0.13818424566088117,"Yunwen Lei and Yiming Ying. Fine-grained analysis of stability and generalization for stochastic
gradient descent. In International Conference on Machine Learning, 2020."
REFERENCES,0.13885180240320427,"Yunwen Lei and Yiming Ying. Sharper generalization bounds for learning with gradient-dominated
objective functions. In International Conference on Learning Representations, 2021a."
REFERENCES,0.13951935914552738,"Yunwen Lei and Yiming Ying. Stochastic proximal auc maximization. Journal of Machine Learning
Research, 22(61):1–45, 2021b."
REFERENCES,0.14018691588785046,"Yunwen Lei, Antoine Ledent, and Marius Kloft. Sharper generalization bounds for pairwise learn-
ing. In Advances in Neural Information Processing Systems, 2020."
REFERENCES,0.14085447263017356,"Yunwen Lei, Zhenhuan Yang, Tianbao Yang, and Yiming Ying. Stability and generalization of
stochastic gradient methods for minimax problems. In International Conference on Machine
Learning, 2021."
REFERENCES,0.14152202937249667,"Guy Lever, Franc¸ois Laviolette, and John Shawe-Taylor.
Tighter pac-bayes bounds through
distribution-dependent priors. Theoretical Computer Science, 473:4–28, 2013."
REFERENCES,0.14218958611481977,"Jian Li, Yong Liu, Rong Yin, Hua Zhang, Lizhong Ding, and Weiping Wang. Multi-class learning:
From theory to algorithm. In Advances in Neural Information Processing Systems, pp. 1586–
1595, 2018."
REFERENCES,0.14285714285714285,"Jian Li, Xuanyuan Luo, and Mingda Qiao. On generalization error bounds of noisy gradient methods
for non-convex learning. In International Conference on Learning Representations, 2020."
REFERENCES,0.14352469959946595,"Shaojie Li and Yong Liu. Sharper generalization bounds for clustering. In International Conference
on Machine Learning, pp. 6392–6402, 2021."
REFERENCES,0.14419225634178906,"Shaojie Li and Yong Liu.
Towards sharper generalization bounds for structured prediction.
In
Advances in Neural Information Processing Systems, 2021."
REFERENCES,0.14485981308411214,"Tengyuan Liang and James Stokes. Interaction matters: A note on non-asymptotic local convergence
of generative adversarial networks. In International Conference on Artiﬁcial Intelligence and
Statistics, 2019."
REFERENCES,0.14552736982643524,"Qihang Lin, Mingrui Liu, Hassan Raﬁque, and Tianbao Yang. Solving weakly-convex-weakly-
concave saddle-point problems as weakly-monotone variational inequality. 2018."
REFERENCES,0.14619492656875835,"Tianyi Lin, Chi Jin, and Michael Jordan. On gradient descent ascent for nonconvex-concave mini-
max problems. In International Conference on Machine Learning, 2020a."
REFERENCES,0.14686248331108145,"Tianyi Lin, Chi Jin, and Michael I. Jordan. Near-optimal algorithms for minimax optimization. In
Conference on Learning Theory, 2020b."
REFERENCES,0.14753004005340453,"Mingrui Liu, Hassan Raﬁque, Qihang Lin, and Tianbao Yang. First-order convergence theory for
weakly-convex-weakly-concave min-max problems. Journal of Machine Learning Research, 22
(169):1–34, 2021a."
REFERENCES,0.14819759679572764,"Tongliang Liu, G´abor Lugosi, Gergely Neu, and Dacheng Tao. Algorithmic stability and hypothesis
complexity. In International Conference on Machine Learning, 2017."
REFERENCES,0.14886515353805074,"Yong Liu, Shizhong Liao, Shali Jiang, Lizhong Ding, Hailun Lin, and Weiping Wang. Fast cross-
validation for kernel-based algorithms.
IEEE Transactions on Pattern Analysis and Machine
Intelligence, 42(5):1083–1096, 2020."
REFERENCES,0.14953271028037382,"Yong Liu, Jiankun Liu, and Shuqiang Wang. Effective distributed learning with random features:
Improved bounds and algorithms.
In International Conference on Learning Representations,
2021b."
REFERENCES,0.15020026702269693,"Nicolas Loizou, Hugo Berard, Alexia Jolicoeur-Martineau, Pascal Vincent, Simon Lacoste-Julien,
and Ioannis Mitliagkas. Stochastic hamiltonian gradient methods for smooth games. In Interna-
tional Conference on Machine Learning, 2020."
REFERENCES,0.15086782376502003,Published as a conference paper at ICLR 2022
REFERENCES,0.15153538050734314,"Nicolas Loizou, Hugo Berard, Gauthier Gidel, Ioannis Mitliagkas, and Simon Lacoste-Julien.
Stochastic gradient descent-ascent and consensus optimization for smooth games: Convergence
analysis under expected co-coercivity. arXiv preprint arXiv:2107.00052, 2021."
REFERENCES,0.15220293724966621,"Ben London, Bert Huang, and Lise Getoor. Stability and generalization in structured prediction.
Journal of Machine Learning Research, 17(221):7808–7859, 2016."
REFERENCES,0.15287049399198932,"Songtao Lu, Ioannis Tsaknakis, Mingyi Hong, and Yongxin Chen. Hybrid block successive ap-
proximation for one-sided non-convex min-max problems: Algorithms and applications. IEEE
Transactions on Signal Processing, 68:3676–3691, 2020."
REFERENCES,0.15353805073431243,"Luo Luo, Haishan Ye, Zhichao Huang, and Tong Zhang.
Stochastic recursive gradient descent
ascent for stochastic nonconvex-strongly-concave minimax problems.
In Advances in Neural
Information Processing Systems, 2020."
REFERENCES,0.1542056074766355,"Shaogao Lv, Junhui Wang, Jiankun Liu, and Yong Liu. Improved learning rates of a functional lasso-
type svm with sparse multi-kernel representation. In Advances in Neural Information Processing
Systems, 2021."
REFERENCES,0.1548731642189586,"Gonzalo Mateos, Juan Andr´es Bazerque, and Georgios B Giannakis. Distributed sparse linear re-
gression. IEEE Transactions on Signal Processing, 58(10):5262–5276, 2010."
REFERENCES,0.15554072096128171,"Panayotis Mertikopoulos, Bruno Lecouat, Houssam Zenati, Chuan-Sheng Foo, Vijay Chan-
drasekhar, and Georgios Piliouras. Optimistic mirror descent in saddle-point problems: Going
the extra (gradient) mile. In International Conference on Learning Representations, 2019."
REFERENCES,0.15620827770360482,"Aryan Mokhtari, Asuman E. Ozdaglar, and Sarath Pattathil. Proximal point approximations achiev-
ing a convergence rate of O(1/k) for smooth convex-concave saddle point problems: Optimistic
gradient and extra-gradient methods. 2019."
REFERENCES,0.1568758344459279,"Aryan Mokhtari, Asuman E. Ozdaglar, and Sarath Pattathil. A uniﬁed analysis of extra-gradient and
optimistic gradient methods for saddle point problems: Proximal point approach. In International
Conference on Artiﬁcial Intelligence and Statistics, 2020."
REFERENCES,0.157543391188251,"Hongseok Namkoong and John C. Duchi. Stochastic gradient methods for distributionally robust
optimization with f-divergences. In Advances in Neural Information Processing Systems, 2016."
REFERENCES,0.1582109479305741,"Hongseok Namkoong and John C. Duchi. Variance-based regularization with convex objectives. In
Advances in Neural Information Processing Systems, 2017."
REFERENCES,0.1588785046728972,"Angelia Nedic and Asuman E. Ozdaglar. Subgradient methods for saddle-point problems. Journal
of Optimization Theory and Applications, 142(1):205–228, 2009."
REFERENCES,0.1595460614152203,"A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro. Robust stochastic approximation approach to
stochastic programming. Siam Journal on Optimization, 19(4):1574–1609, 2008."
REFERENCES,0.1602136181575434,"Arkadi Nemirovski.
Prox-method with rate of convergence O(1/t) for variational inequalities
with lipschitz continuous monotone operators and smooth convex-concave saddle point problems.
Siam Journal on Optimization, 15(1):229–251, 2005."
REFERENCES,0.16088117489986647,"Maher Nouiehed, Maziar Sanjabi, Tianjian Huang, Jason D. Lee, and Meisam Razaviyayn. Solving
a class of non-convex min-max games using iterative ﬁrst order methods. In Advances in Neural
Information Processing Systems, 2019."
REFERENCES,0.16154873164218958,"L. D. Popov. A modiﬁcation of the arrow-hurwicz method for search of saddle points. Mathematical
Notes, 28(5):845–848, 1980."
REFERENCES,0.16221628838451269,"Hassan Raﬁque, Mingrui Liu, Qihang Lin, and Tianbao Yang. Non-convex min-max optimization:
Provable algorithms and applications in machine learning. arXiv: Optimization and Control,
2018."
REFERENCES,0.1628838451268358,"Alexander Rakhlin, Sayan Mukherjee, and Tomaso Poggio. Stability results in learning theory.
Analysis and Applications, 3(04):397–417, 2005."
REFERENCES,0.16355140186915887,Published as a conference paper at ICLR 2022
REFERENCES,0.16421895861148197,"Meisam Razaviyayn, Tianjian Huang, Songtao Lu, Maher Nouiehed, Maziar Sanjabi, and Mingyi
Hong. Non-convex min-max optimization: Applications, challenges, and recent theoretical ad-
vances. arXiv preprint arXiv:2006.08141, 2020."
REFERENCES,0.16488651535380508,"R. Tyrrell Rockafellar. Monotone operators and the proximal point algorithm. Siam Journal on
Control and Optimization, 14(5):877–898, 1976."
REFERENCES,0.16555407209612816,"Maziar Sanjabi, Jimmy Ba, Meisam Razaviyayn, and Jason D. Lee. On the convergence and ro-
bustness of training gans with regularized optimal transport. In Advances in Neural Information
Processing Systems, 2018."
REFERENCES,0.16622162883845126,"Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From theory to algo-
rithms. Cambridge university press, 2014."
REFERENCES,0.16688918558077437,"Shai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, and Karthik Sridharan. Learnability, stability
and uniform convergence. Journal of Machine Learning Research, 11(90):2635–2670, 2010."
REFERENCES,0.16755674232309747,Jeff Shamma. Cooperative Control of Distributed Multi-Agent Systems. 2008.
REFERENCES,0.16822429906542055,"Aman Sinha, Hongseok Namkoong, and John C. Duchi. Certifying some distributional robustness
with principled adversarial training. In International Conference on Learning Representations,
2017."
REFERENCES,0.16889185580774366,"Nathan Srebro, Karthik Sridharan, and Ambuj Tewari. Optimistic rates for learning with a smooth
loss. arXiv preprint arXiv:1009.3896, 2010."
REFERENCES,0.16955941255006676,"Pierre Tarres and Yuan Yao. Online learning as stochastic approximation of regularization paths:
Optimality and almost-sure convergence. IEEE Transactions on Information Theory, 60(9):5716–
5735, 2014."
REFERENCES,0.17022696929238984,"Kiran Koshy Thekumparampil, Prateek Jain, Praneeth Netrapalli, and Sewoong Oh. Efﬁcient algo-
rithms for smooth minimax optimization. In Advances in Neural Information Processing Systems,
2019."
REFERENCES,0.17089452603471295,"Yuanhao Wang and Jian Li. Improved algorithms for convex-concave minimax optimization. In
Advances in Neural Information Processing Systems, 2020."
REFERENCES,0.17156208277703605,"Yuanhao Wang, Guodong Zhang, and Jimmy Ba. On solving minimax optimization locally: A
follow-the-ridge approach. In International Conference on Learning Representations, 2020."
REFERENCES,0.17222963951935916,"Yan Yan, Yi Xu, Qihang Lin, Wei Liu, and Tianbao Yang. Optimal epoch stochastic gradient de-
scent ascent methods for min-max optimization. In Advances in Neural Information Processing
Systems, 2020."
REFERENCES,0.17289719626168223,"Jun Yang, Shengyang Sun, and Daniel M. Roy. Fast-rate pac-bayes generalization bounds via shifted
rademacher processes. In Advances in Neural Information Processing Systems, volume 32, pp.
10802–10812, 2019."
REFERENCES,0.17356475300400534,"Junchi Yang, Negar Kiyavash, and Niao He. Global convergence and variance reduction for a class
of nonconvex-nonconcave minimax problems. In Advances in Neural Information Processing
Systems, 2020."
REFERENCES,0.17423230974632845,"Rong Yin, Yong Liu, Weiping Wang, and Dan Meng. Sketch kernel ridge regression using circulant
matrix: Algorithm and theory. IEEE Transactions on Neural Networks, 31(9):3512–3524, 2020."
REFERENCES,0.17489986648865152,"TaeHo Yoon and Ernest K. Ryu. Accelerated algorithms for smooth convex-concave minimax prob-
lems with O(1/k2) rate on squared gradient norm. arXiv preprint arXiv:2102.07922, 2021."
REFERENCES,0.17556742323097463,"Junyu Zhang, Mingyi Hong, Mengdi Wang, and Shuzhong Zhang.
Generalization bounds for
stochastic saddle point problems. In International Conference on Artiﬁcial Intelligence and Statis-
tics, 2021a."
REFERENCES,0.17623497997329773,"Lijun Zhang and Zhi-Hua Zhou. Stochastic approximation of smooth and strongly convex functions:
Beyond the O(1/t) convergence rate. In Conference on Learning Theory, pp. 3160–3179, 2019."
REFERENCES,0.17690253671562084,Published as a conference paper at ICLR 2022
REFERENCES,0.17757009345794392,"Lijun Zhang, Tianbao Yang, and Rong Jin. Empirical risk minimization for stochastic convex op-
timization: O(1/n)- and O(1/n2)-type of risk bounds. In Conference on Learning Theory, pp.
1954–1979, 2017."
REFERENCES,0.17823765020026702,"Yikai Zhang, Wenjia Zhang, Sammy Bald, Vamsi Pingali, Chao Chen, and Mayank Goswami. Sta-
bility of sgd: Tightness analysis and improved bounds. arXiv preprint arXiv:2102.05274, 2021b."
REFERENCES,0.17890520694259013,"A
PROOF OF THEOREM 1"
REFERENCES,0.1795727636849132,"We now provide proofs of Theorem 1. For better readability, we restate Theorem 1 below.
Theorem 2. Let A be a learning algorithm and ϵ > 0. Suppose |f(x, y; z)| ≤M for some M > 0
and x ∈X, y ∈Y, z ∈Z. Fixed any η > 0. There exists an absolute positive constant C."
REFERENCES,0.1802403204272363,"(a.) If the algorithm A is ϵ-uniformly stable, then for any δ > 0, with probability at least 1 −δ,"
REFERENCES,0.18090787716955942,"F(Ax(S), Ay(S)) ≤(1 + η)FS(Ax(S), Ay(S)) + C 1 + η η M"
REFERENCES,0.18157543391188252,"n log(1/δ) + ϵ log2 n log 1 δ 
."
REFERENCES,0.1822429906542056,"(b.) Assume that for all x, the function y 7→F(x, y) is µ-strongly-concave. If the algorithm A is
ϵ-argument stable and Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ,"
REFERENCES,0.1829105473965287,"R(Ax(S))
≤
(1 + η)RS(Ax(S)) + C 1 + η η M"
REFERENCES,0.1835781041388518,n log 1
REFERENCES,0.1842456608811749,"δ +
β"
REFERENCES,0.184913217623498,"µ + 1

Lϵ log2 n log 1 δ 
."
REFERENCES,0.1855807743658211,"(c.) Assume that for all x and y, the function F(x, y) is µ-SC-SC. If the algorithm A is ϵ-argument
stable and Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ,"
REFERENCES,0.1862483311081442,"△s (Ax(S), Ay(S)) ≤△s
S(Ax(S), Ay(S)) + ηES △s
S (Ax(S), Ay(S))"
REFERENCES,0.18691588785046728,"+ C(1 + η)
L2(1 + η)"
REFERENCES,0.1875834445927904,"nµη
+ M"
REFERENCES,0.1882510013351135,"n +

1 + β µ"
REFERENCES,0.18891855807743657,"
ϵL log2 n

log
1 δ 
."
REFERENCES,0.18958611481975968,"(d.) Assume that for all x and y, the function F(x, y) is µ-SC-SC. If the algorithm A is ϵ-argument
stable and Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ,"
REFERENCES,0.19025367156208278,"△s (Ax(S), Ay(S)) −△s
S(Ax(S), Ay(S)) ≤ηES △s
S (Ax(S), Ay(S))"
REFERENCES,0.1909212283044059,"+ C(1 + η)
L2(1 + η)"
REFERENCES,0.19158878504672897,"nµη
+ M"
REFERENCES,0.19225634178905207,"n +

1 + β µ"
REFERENCES,0.19292389853137518,"
ϵL log2 n

log
1 δ 
."
REFERENCES,0.19359145527369825,"(e.) Assume that for all x, the function y 7→F(x, y) is µ-strongly-concave. If the algorithm A is
ϵ-argument stable and Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ,"
REFERENCES,0.19425901201602136,"R(Ax(S)) ≤(1 + η) inf
x∈X R(x)"
REFERENCES,0.19492656875834447,+ C 2 + η η M
REFERENCES,0.19559412550066757,n log 1
REFERENCES,0.19626168224299065,"δ +
β"
REFERENCES,0.19692923898531375,"µ + 1

Lϵ log2 n log 1"
REFERENCES,0.19759679572763686,"δ + △s
S(Ax(S), Ay(S))

."
REFERENCES,0.19826435246995994,"Remark 6. To prove sharper high probability bounds than (Lei et al., 2021), the concentration
inequality for a summation of weakly-dependent random variables proposed in (Bousquet et al.,
2020) (Lemma 2 in Appendix A) plays a key role in our analysis. However, the direct use of this
inequality will inevitably lead to a slow order bound since it contains a sampling error of slow order
O(1/√n). We exploit the proof techniques of the recent breakthrough work (Klochkov & Zhiv-
otovskiy, 2021) to make new constructions of gi(S) so that the parameter M in Lemma 2 is 0.
However, the proof techniques of (Klochkov & Zhivotovskiy, 2021) can not be directly extended
to minimax problems. The coupling construction between the minimization variables and the max-
imization variables makes the proofs of minimax problems more difﬁcult than the minimization
problem studied by (Klochkov & Zhivotovskiy, 2021). We must proceed with novel decomposi-
tions for the generalization measures. Note that different decompositions are required for different
generalization measures. A pretty technical decomposition is exploited in the proof of Part (c)."
REFERENCES,0.19893190921228304,Published as a conference paper at ICLR 2022
REFERENCES,0.19959946595460615,"Moreover, the proof of minimax problems needs reﬁned analyses due to the minimax structure. For
instance, in proving the primal generalization error, we need to quantify the fact that for different
Ax(S), the optimal y is different in R(Ax(S)). And the analysis of excess primal population risk in
Part (e) is different from the excess risk analysis in (Klochkov & Zhivotovskiy, 2021). The reason
is that the supremum operator in infx∈X R(x) makes the Bernstein condition used in (Klochkov
& Zhivotovskiy, 2021) not applicable for excess primal population risk. Additionally, (Klochkov
& Zhivotovskiy, 2021) only study ERM and GD, while we study more optimization algorithms:
SGDA, PPM, EG, and OGDA.
Remark 7. According to Deﬁnition 1 and Jensen’s inequality, we know that △w
S (x, y) ≤
E[△s
S(x, y)]. Meanwhile, since we will provide the strong PD empirical risk bounds for several
important optimization algorithms in Section 5, it thus implies that we also establish bounds with
fast rates for △w
S (x, y)."
REFERENCES,0.20026702269692923,"To begin the proof of Theorem 1, we ﬁrst introduce some key lemmas on concentration inequalities.
The ﬁrst lemma translates a moment bound into a high probability bound.
Lemma 1. (Bousquet et al., 2020) Let Z be a random variable with"
REFERENCES,0.20093457943925233,∥Z∥p ≤√pa + pb
REFERENCES,0.20160213618157544,"for some a, b > 0 and for any p ≥2. Then for any δ ∈(0, 1) we have, with probability at least
1 −δ,"
REFERENCES,0.20226969292389854,"|Z| ≤e

a
r"
REFERENCES,0.20293724966622162,"log
e δ"
REFERENCES,0.20360480640854473,"
+ b log
e δ 
,"
REFERENCES,0.20427236315086783,where e is the base of the natural logarithm.
REFERENCES,0.2049399198931909,"The second lemma establishes a concentration inequality for a summation of weakly-dependent
random variables.
Lemma 2. (Bousquet et al., 2020) Let S = {z1, ..., zn} be a set of independent random variables
each taking values in Z and M > 0. Denote [n] as the set {1, ..., n}. Deﬁne S\{zi} be set
{z1, ..., zi−1, zi+1, ..., zn}. Let g1, ..., gn be some functions gi : Zn 7→R such that the following
inequalities hold for any i ∈[n], •"
REFERENCES,0.205607476635514,"ES\{zi}[gi(S)]
 ≤M almost surely (a.s.),"
REFERENCES,0.20627503337783712,"• Ezi[gi(S)] = 0 a.s.,"
REFERENCES,0.20694259012016022,"• for any j ∈[n] with j ̸= i, and z′′
j ∈Z
gi(S) −gi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)
 ≤β."
REFERENCES,0.2076101468624833,"Then, for any p ≥2 n
X"
REFERENCES,0.2082777036048064,"i=1
gi(S)

p ≤12
√"
REFERENCES,0.2089452603471295,2pnβ⌈log2 n⌉+ 4M√pn.
REFERENCES,0.2096128170894526,"The following deﬁnition and lemma give the concentration inequality for non-negative weakly self-
bounded functions.
Deﬁnition 4. (Weakly Self-Bounded Function) Assume that a, b > 0. A function f : Zn 7→[0, +∞)
is said to be (a, b)-weakly self-bounded if there exist functions fi : Zn−1 7→[0, +∞) that satisﬁes
for all Zn ∈Zn, n
X"
REFERENCES,0.2102803738317757,"i=1
(f(Zn) −fi(Zn))2 ≤af(Zn) + b."
REFERENCES,0.2109479305740988,"Lemma 3. (Klochkov & Zhivotovskiy, 2021) Suppose that z1, ..., zn are independent random vari-
ables and the function f : Zn 7→[0, +∞) is (a, b)-weakly self-bounded and the corresponding
function fi satisfy fi(Zn) ≥f(Zn) for i = 1, ..., n and any Zn ∈Zn. Then, for any t > 0,"
REFERENCES,0.2116154873164219,"Pr(Ef(z1, ..., zn) ≥f(z1, ..., zn) + t) ≤exp

−
t2"
REFERENCES,0.21228304405874499,"2aEf(z1, ..., zn) + 2b 
."
REFERENCES,0.2129506008010681,Published as a conference paper at ICLR 2022
REFERENCES,0.2136181575433912,"The following lemma is the classical Bernstein concentration inequality.
Lemma 4. (Boucheron et al., 2013) Let z1, ..., zn be i.i.d. random variables and assume that E[zi] =
µ. Suppose |zi| ≤c for any i. Then for any δ ∈(0, 1), with probability at least 1 −δ, 1 n n
X"
REFERENCES,0.21428571428571427,"i=1
zi −µ
 ≤ r"
REFERENCES,0.21495327102803738,2σ2 log(1/δ)
REFERENCES,0.21562082777036048,"n
+ 2c log(1/δ)"
N,0.2162883845126836,"3n
,"
N,0.21695594125500667,where σ2 is the variance of zi.
N,0.21762349799732977,"A.1
PROOF OF PART (A)"
N,0.21829105473965288,We ﬁrst prove the plain generalization error bound.
N,0.21895861148197596,"Proof. Let S
=
{z1, ..., zn} be a set of independent random variables each taking values
in Z and S′
=
{z′
1, ..., z′
n} be its independent copy.
For any i
∈
[n], deﬁne S(i)
=
{z1, ..., zi−1, z′
i, zi+1, ..., zn} be a dataset by replacing the i-th sample in S with another i.i.d. sam-
ple z′
i. We ﬁrst have the following decomposition"
N,0.21962616822429906,"nF(Ax(S), Ay(S)) −nFS(Ax(S), Ay(S)) = n
X"
N,0.22029372496662217,"i=1
EZ[f(Ax(S), Ay(S); Z) −Ez′
i[f(Ax(S(i)), Ay(S(i)); Z)]] + n
X"
N,0.22096128170894527,"i=1
Ez′
i[EZ[f(Ax(S(i)), Ay(S(i)); Z)] −f(Ax(S(i)), Ay(S(i)); zi)] + n
X"
N,0.22162883845126835,"i=1
Ez′
i[f(Ax(S(i)), Ay(S(i)); zi)] − n
X"
N,0.22229639519359146,"i=1
f(Ax(S), Ay(S); zi)."
N,0.22296395193591456,"According to the deﬁnition of uniform stability (Part 1 of Deﬁnition 3), we have"
N,0.22363150867823764,"nF(Ax(S), Ay(S)) −nFS(Ax(S), Ay(S)) ≤2nϵ + n
X"
N,0.22429906542056074,"i=1
gi(S),"
N,0.22496662216288385,"where
we
have
introduced
gi(S)
=
Ez′
i[EZ[f(Ax(S(i)), Ay(S(i)); Z)]
−
f(Ax(S(i)), Ay(S(i)); zi)]. Thus, by a rearrangement, we have
nF(Ax(S), Ay(S)) −nFS(Ax(S), Ay(S)) − n
X"
N,0.22563417890520696,"i=1
gi(S)
 ≤2nϵ.
(3)"
N,0.22630173564753003,"Then, for any i = 1, ..., n, we deﬁne hi(S) = gi(S) −ES\{zi}[gi(S)]. It is easy to verify that
ES\{zi}[hi(S)] = 0 and Ezi[hi(S)] = Ezi[gi(S)] −EziES\{zi}[gi(S)] = 0 −0 = 0. Also, for any
j ∈[n] with j ̸= i, and z′′
j ∈Z, we have the following inequality
hi(S) −hi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)
 ≤
gi(S) −gi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)"
N,0.22696929238985314,"+
ES\{zi}[gi(S)] −ES\{zi}[gi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)]
 ."
N,0.22763684913217624,"For the ﬁrst term |gi(S) −gi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)|,
it can be bounded by 2ϵ
according
to
the
deﬁnition
of
uniform
stability.
Similar
result
holds
for
the
sec-
ond term
ES\{zi}[gi(S)] −ES\{zi}[gi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)]
 according to the deﬁni-
tion of uniform stability.
By a combination of the above analysis, we get |hi(S) −
hi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)| ≤4ϵ."
N,0.22830440587449932,"We thus have veriﬁed that the three conditions in Lemma 2 are satisﬁed for hi(S). There will hold
the following result for any p ≥2 n
X"
N,0.22897196261682243,"i=1
hi(S)

p ≤48
√"
N,0.22963951935914553,"2ϵpn⌈log2 n⌉.
(4)"
N,0.23030707610146864,Published as a conference paper at ICLR 2022
N,0.23097463284379172,"Furthermore, we can derive that"
N,0.23164218958611482,"nF(Ax(S), Ay(S)) −nFS(Ax(S), Ay(S)) − n
X"
N,0.23230974632843793,"i=1
gi(S) + n
X"
N,0.232977303070761,"i=1
hi(S)"
N,0.2336448598130841,"=nF(Ax(S), Ay(S)) −nFS(Ax(S), Ay(S)) − n
X"
N,0.23431241655540722,"i=1
ES\{zi}[gi(S)]"
N,0.2349799732977303,"=nF(Ax(S), Ay(S)) −nFS(Ax(S), Ay(S)) −nES′F(Ax(S′), Ay(S′))"
N,0.2356475300400534,"+ nES′FS(Ax(S′), Ay(S′))"
N,0.2363150867823765,"Due to the i.i.d.
property between S and S′, we know that ES′F(Ax(S′), Ay(S′))
=
ESF(Ax(S), Ay(S))."
N,0.2369826435246996,"Thus, combined (3) with (4), we have"
N,0.2376502002670227,"∥nF(Ax(S), Ay(S)) −nFS(Ax(S), Ay(S)) −nESF(Ax(S), Ay(S)) + nES′FS(Ax(S′), Ay(S′))∥p"
N,0.2383177570093458,"≤
nF(Ax(S), Ay(S)) −nFS(Ax(S), Ay(S)) − n
X"
N,0.2389853137516689,"i=1
gi(S)

p + n
X"
N,0.23965287049399198,"i=1
gi(S) −nESF(Ax(S), Ay(S)) + nES′FS(Ax(S′), Ay(S′))

p"
N,0.24032042723631508,"=
nF(Ax(S), Ay(S)) −nFS(Ax(S), Ay(S)) − n
X"
N,0.2409879839786382,"i=1
gi(S)

p + n
X"
N,0.2416555407209613,"i=1
hi(S)

p"
N,0.24232309746328437,"≤2nϵ + 48
√"
N,0.24299065420560748,"2ϵpn⌈log2 n⌉ ≤50
√"
N,0.24365821094793058,2ϵpn⌈log2 n⌉.
N,0.24432576769025366,"According to Lemma 1, for any δ ∈(0, 1), with probability at least 1 −δ/3, we have"
N,0.24499332443257676,"F(Ax(S), Ay(S)) −FS(Ax(S), Ay(S))"
N,0.24566088117489987,"≤|ES′FS(Ax(S′), Ay(S′)) −ESF(Ax(S), Ay(S))| + 50
√"
N,0.24632843791722298,"2eϵ⌈log2 n⌉log(3e/δ).
(5)"
N,0.24699599465954605,"We now begin to bound the term ES′FS(Ax(S′), Ay(S′)) −ESF(Ax(S), Ay(S)). There holds
that ESES′FS(Ax(S′), Ay(S′)) = ESF(Ax(S), Ay(S)).
We ﬁrst consider the variance of
ES′f(Ax(S′), Ay(S′); zi). By the Jensen’s inequality, we have"
N,0.24766355140186916,"Ezi[(ES′f(Ax(S′), Ay(S′); zi))2] ≤EziES′[(f(Ax(S′), Ay(S′); zi))2]"
N,0.24833110814419226,"= EZES′[(f(Ax(S′), Ay(S′); Z))2]"
N,0.24899866488651534,"= EZES[(f(Ax(S), Ay(S); Z))2]."
N,0.24966622162883845,"Then, by the Bernstein inequality in Lemma 4, we obtain the following inequality with probability
at least 1 −δ/3,"
N,0.25033377837116155,"|ES′FS(Ax(S′), Ay(S′)) −ESF(Ax(S), Ay(S))|
(6) ≤ r"
N,0.25100133511348466,"2EZES[(f(Ax(S), Ay(S); Z))2] log(3/δ)"
N,0.25166889185580776,"n
+ 2M log(3/δ)"
N,0.2523364485981308,"3n
."
N,0.2530040053404539,"Combined (5) with (6), we ﬁnally obtain that with probability at least 1 −2δ/3,"
N,0.253671562082777,"F(Ax(S), Ay(S)) −FS(Ax(S), Ay(S)) ≤ r"
N,0.25433911882510013,"2EZES[(f(Ax(S), Ay(S); Z))2] log(3/δ)"
N,0.25500667556742324,"n
+ 2M log(3/δ)"
N,0.25567423230974634,"3n
+ 50
√"
N,0.25634178905206945,2eϵ⌈log2 n⌉log(3e/δ). (7)
N,0.2570093457943925,"In the following, we deﬁne q
=
q(z1, ..., zn)
=
EZ[(f(Ax(S), Ay(S); Z))2] and qi
=
qi(z1, ..., zn) = supzi∈Z q(z1, ..., zn).
So there holds qi ≥q for any i = 1, .., n and any"
N,0.2576769025367156,Published as a conference paper at ICLR 2022
N,0.2583444592790387,"{z1, ..., zn} ∈Zn. Also, there holds that
n
X"
N,0.2590120160213618,"i=1
(q −qi)2 = n
X i=1"
N,0.2596795727636849,"
EZ[(f(Ax(S), Ay(S); Z))2] −sup
zi∈Z
EZ[(f(Ax(S), Ay(S); Z))2]
2 ≤ n
X"
N,0.260347129506008,"i=1
ϵ2
EZ
h
f(Ax(S), Ay(S); Z) + sup
zi∈Z
f(Ax(S), Ay(S); Z)
i2"
N,0.26101468624833113,"≤nϵ2 (2EZ[(f(Ax(S), Ay(S); Z))] + ϵ)2"
N,0.2616822429906542,"≤8nϵ2q + 2nϵ4,
(8)
where the ﬁrst inequality follows from the Jensen’s inequality and the deﬁnition of uniform stability,
and where the second inequality also follows from the deﬁnition of uniform stability."
N,0.2623497997329773,"From (8), we know that q is (8nϵ2, 2nϵ4) weakly self-bounded. Thus, by Lemma 3, we obtain that
with probability at least 1 −δ/3,"
N,0.2630173564753004,"ESEZ[(f(Ax(S), Ay(S); Z))2] −EZ[(f(Ax(S), Ay(S); Z))2] ≤
q"
N,0.2636849132176235,"(16nϵ2ESEZ[(f(Ax(S), Ay(S); Z))2] + 4nϵ4) log(3/δ) ="
N,0.2643524699599466,"r
ESEZ[(f(Ax(S), Ay(S); Z))2] + 1"
N,0.2650200267022697,"4ϵ2

16nϵ2 log(3/δ) ≤1 2"
N,0.2656875834445928,"
ESEZ[(f(Ax(S), Ay(S); Z))2] + 1"
N,0.26635514018691586,"4ϵ2
+ 8nϵ2 log(3/δ),"
N,0.26702269692923897,"where the last inequality follows from that
√"
N,0.2676902536715621,ab ≤a+b
N,0.2683578104138852,"2
for all a, b > 0."
N,0.2690253671562083,"Since EZ[(f(Ax(S), Ay(S); Z))2] ≤MF(Ax(S), Ay(S)), we have"
N,0.2696929238985314,"ESEZ[(f(Ax(S), Ay(S); Z))2] −2MF(Ax(S), Ay(S)) ≤1"
N,0.2703604806408545,"4ϵ2 + 16nϵ2 log(3/δ).
(9)"
N,0.27102803738317754,"Substituting (9) into (7), we ﬁnally obtain that with probability at least 1 −δ,
F(Ax(S), Ay(S)) −FS(Ax(S), Ay(S)) ≤ s"
N,0.27169559412550065,"(4MF(Ax(S), Ay(S)) + 1"
N,0.27236315086782376,2ϵ2 + 32nϵ2 log(3/δ)) log(3/δ) n
N,0.27303070761014686,+ 2M log(3/δ)
N,0.27369826435246997,"3n
+ 50
√"
N,0.27436582109479307,"2eϵ⌈log2 n⌉log(3e/δ).
(10)"
N,0.2750333778371162,"According to inequalities
√"
N,0.2757009345794392,ab ≤ηa + 1
N,0.27636849132176233,"ηb and
√"
N,0.27703604806408544,"a + b ≤√a +
√"
N,0.27770360480640854,"b for any a, b, η > 0, we have the
following inequality with probability at least 1 −δ
F(Ax(S), Ay(S)) −FS(Ax(S), Ay(S)) ≤ s ( 1"
N,0.27837116154873165,2ϵ2 + 32nϵ2 log(3/δ)) log(3/δ)
N,0.27903871829105475,"n
+
η
1 + η F(Ax(S), Ay(S)) + 1 + η"
N,0.27970627503337786,"η
4M log(3/δ) n"
N,0.2803738317757009,+ 2M log(3/δ)
N,0.281041388518024,"3n
+ 50
√"
N,0.2817089452603471,"2eϵ⌈log2 n⌉log(3e/δ),"
N,0.2823765020026702,"which implies that
F(Ax(S), Ay(S)) −(1 + η)FS(Ax(S), Ay(S))"
N,0.28304405874499333,"≤(1 + η)

s ( 1"
N,0.28371161548731644,2ϵ2 + 32nϵ2 log(3/δ)) log(3/δ)
N,0.28437917222963954,"n
+ 1 + η"
N,0.2850467289719626,"η
4M log(3/δ) n"
N,0.2857142857142857,+ 2M log(3/δ)
N,0.2863818424566088,"3n
+ 50
√"
N,0.2870493991989319,"2eϵ⌈log2 n⌉log(3e/δ)
"
N,0.287716955941255,≤C 1 + η η M
N,0.2883845126835781,"n log(1/δ) + ϵ log2 n log(1/δ)

,"
N,0.2890520694259012,Published as a conference paper at ICLR 2022
N,0.2897196261682243,where C is an absolute constant. The proof is complete.
N,0.2903871829105474,"A.2
PROOF OF PART (B)"
N,0.2910547396528705,"We then prove the primal generalization error bound. Before presenting the proof, we ﬁrst introduce
a lemma that quantiﬁes the sensitivity of the optimal y and x w.r.t the perturbation of x and y
respectively."
N,0.2917222963951936,"Lemma 5. (Zhang et al., 2021a) Let f : X × Y 7→R. Assume that f is µ-strongly-convex-strongly-
concave. Suppose that for any x, x′ ∈X and y, y′ ∈Y we have"
N,0.2923898531375167,"∥∇yf(x, y) −∇yf(x′, y)∥≤β∥x −x′∥
and
∥∇xf(x, y) −∇xf(x, y′)∥≤β∥y −y′∥."
N,0.2930574098798398,"Deﬁne x∗(y) = arg minx∈X h(x, y) and y∗(x) = arg maxy∈Y h(x, y) for any y and x respec-
tively. Then, for any x, x′ ∈X and y, y′ ∈Y there holds that"
N,0.2937249666221629,∥y∗(x) −y∗(x′)∥≤β
N,0.29439252336448596,"µ∥x −x′∥
and
∥x∗(y) −x∗(y′)∥≤β"
N,0.29506008010680906,µ∥y −y′∥.
N,0.29572763684913217,"The proof of Part (b) shares similar proof techniques with Part (a), but requires a novel decompo-
sition and several important changes. For instance, Lemma 5 should be needed to quantify the fact
that for different Ax(S), the optimal y is different in R(Ax(S))."
N,0.2963951935914553,"Proof. Let S
=
{z1, ..., zn} be a set of independent random variables each taking values
in Z and S′
=
{z′
1, ..., z′
n} be its independent copy.
For any i
∈
[n], deﬁne S(i)
=
{z1, ..., zi−1, z′
i, zi+1, ..., zn} be a dataset by replacing the i-th sample in S with another i.i.d. sam-
ple z′
i. Denote y∗
S = arg maxy∈Y F(Ax(S), y) and ˆy∗
S = arg maxy∈Y FS(Ax(S), y). We have
the following decomposition"
N,0.2970627503337784,"nR(Ax(S)) −nRS(Ax(S))
=nF(Ax(S), y∗
S) −nFS(Ax(S), ˆy∗
S) = n
X"
N,0.2977303070761015,"i=1
EZ[f(Ax(S), y∗
S; Z) −Ez′
i[f(Ax(S(i)), y∗
S(i); Z)]] + n
X"
N,0.2983978638184246,"i=1
Ez′
i[EZ[f(Ax(S(i)), y∗
S(i); Z)] −f(Ax(S(i)), y∗
S(i); zi)] + n
X"
N,0.29906542056074764,"i=1
Ez′
i[f(Ax(S(i)), y∗
S(i); zi)] − n
X"
N,0.29973297730307075,"i=1
f(Ax(S), ˆy∗
S; zi).
(11)"
N,0.30040053404539385,"Firstly, we have"
N,0.30106809078771696,"f(Ax(S), y∗
S; Z) −f(Ax(S(i)), y∗
S(i); Z)"
N,0.30173564753004006,"=f(Ax(S), y∗
S; Z) −f(Ax(S), y∗
S(i); Z) + f(Ax(S), y∗
S(i); Z) −f(Ax(S(i)), y∗
S(i); Z)"
N,0.30240320427236317,"≤L∥y∗
S −y∗
S(i)∥+ L∥Ax(S) −Ax(S(i))∥"
N,0.3030707610146863,"≤

1 + β µ"
N,0.3037383177570093,"
L∥Ax(S) −Ax(S(i))∥"
N,0.30440587449933243,"≤

1 + β µ"
N,0.30507343124165553,"
Lϵ,
(12)"
N,0.30574098798397864,where the second inequality follows from Lemma 5 with the fact that F is smooth and µ-SC-SC.
N,0.30640854472630175,Published as a conference paper at ICLR 2022
N,0.30707610146862485,"Secondly, we have n
X"
N,0.30774365821094796,"i=1
Ez′
i[f(Ax(S(i)), y∗
S(i); zi)] = n
X"
N,0.308411214953271,"i=1
Ez′
i[f(Ax(S(i)), y∗
S(i); zi) −f(Ax(S), y∗
S; zi) + f(Ax(S), y∗
S; zi)] ≤ n
X"
N,0.3090787716955941,"i=1
Ez′
i"
N,0.3097463284379172,"
1 + β µ"
N,0.3104138851802403,"
L∥Ax(S) −Ax(S(i))∥+ n
X"
N,0.31108144192256343,"i=1
f(Ax(S), y∗
S; zi)"
N,0.31174899866488653,"≤

1 + β µ"
N,0.31241655540720964,"
Lnϵ + n
X"
N,0.3130841121495327,"i=1
f(Ax(S), y∗
S; zi),"
N,0.3137516688918558,"where the ﬁrst and the last inequalities follow from (12). Substituting the above two results into
(11), we obtain that"
N,0.3144192256341789,"nF(Ax(S), y∗
S) −nFS(Ax(S), ˆy∗
S)"
N,0.315086782376502,"≤2

1 + β µ"
N,0.3157543391188251,"
Lnϵ + n
X"
N,0.3164218958611482,"i=1
f(Ax(S), y∗
S; zi) + n
X"
N,0.3170894526034713,"i=1
gi(S) − n
X"
N,0.3177570093457944,"i=1
f(Ax(S), ˆy∗
S; zi)"
N,0.3184245660881175,"≤2

1 + β µ"
N,0.3190921228304406,"
Lnϵ + n
X"
N,0.3197596795727637,"i=1
gi(S),"
N,0.3204272363150868,"where
the
last
inequality
follows
from
the
facts
that
Pn
i=1 f(Ax(S), y∗
S; zi)
−
Pn
i=1 f(Ax(S), ˆy∗
S; zi) ≤0 and that we have introduced gi(S) = Ez′
i[EZ[f(Ax(S(i)), y∗
S(i); Z)]−
f(Ax(S(i)), y∗
S(i); zi)]."
N,0.3210947930574099,Now we get
N,0.32176234979973295,"nF(Ax(S), y∗
S) −nFS(Ax(S), ˆy∗
S) − n
X"
N,0.32242990654205606,"i=1
gi(S) ≤2

1 + β µ"
N,0.32309746328437916,"
Lnϵ.
(13)"
N,0.32376502002670227,"For any i = 1, ..., n, we deﬁne hi(S) = gi(S) −ES\{zi}[gi(S)]."
N,0.32443257676902537,"We also get that ES\{zi}[hi(S)] = 0 and Ezi[hi(S)] = Ezi[gi(S)]−EziES\{zi}[gi(S)] = 0−0 = 0.
Moreover, for any j ∈[n] with j ̸= i, and z′′
j ∈Z, we have the following inequality"
N,0.3251001335113485,"|hi(S) −hi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)| ≤|gi(S) −gi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)|"
N,0.3257676902536716,"+ |ES\{zi}[gi(S)] −ES\{zi}[gi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)]|."
N,0.32643524699599463,"Denote S(i)
j
as the set collected by replacing the j-th element of S(i) with z′′
j . For the ﬁrst term
|gi(S) −gi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)|, we have"
N,0.32710280373831774,"gi(S) −gi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)"
N,0.32777036048064084,"=
Ez′
i"
N,0.32843791722296395,"h
EZ[f(Ax(S(i)), y∗
S(i); Z)] −f(Ax(S(i)), y∗
S(i); zi)
i"
N,0.32910547396528705,"−Ez′
i"
N,0.32977303070761016,"h
EZ[f(Ax(S(i)
j ), y∗
S(i)
j ; Z)] −f(Ax(S(i)
j ), y∗
S(i)
j ; zi)
i"
N,0.33044058744993327,"≤
Ez′
i"
N,0.3311081441922563,"h
EZ[f(Ax(S(i)), y∗
S(i); Z)] −f(Ax(S(i)
j ), y∗
S(i)
j ; Z)
i"
N,0.3317757009345794,"+
Ez′
i"
N,0.3324432576769025,"h
f(Ax(S(i)), y∗
S(i); zi) −f(Ax(S(i)
j ), y∗
S(i)
j ; zi)
i.
(14)"
N,0.33311081441922563,Published as a conference paper at ICLR 2022
N,0.33377837116154874,"Furthermore, for any z, we have the following result which can help to bound the above inequality.
f(Ax(S(i)), y∗
S(i); z) −f(Ax(S(i)
j ), y∗
S(i)
j ; z)"
N,0.33444592790387184,"≤
f(Ax(S(i)), y∗
S(i); z) −f(Ax(S(i)), y∗
S(i)
j ; z)
 +
f(Ax(S(i)), y∗
S(i)
j ; z) −f(Ax(S(i)
j ), y∗
S(i)
j ; z)"
N,0.33511348464619495,"≤L
y∗
S(i) −y∗
S(i)
j"
N,0.335781041388518,"+ L
Ax(S(i)) −Ax(S(i)
j ) ≤
β"
N,0.3364485981308411,"µ + 1

L
Ax(S(i)) −Ax(S(i)
j ) ≤
β"
N,0.3371161548731642,"µ + 1

Lϵ,
(15)"
N,0.3377837116154873,"where the third inequality follows from Lemma 5. Thus, we can bound the ﬁrst term by 2

β
µ +1

Lϵ."
N,0.3384512683578104,"By a similar analysis, the second term |ES\{zi}[gi(S)] −ES\{zi}[gi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)]|"
N,0.3391188251001335,"can also be bounded by 2

β
µ + 1

Lϵ."
N,0.33978638184245663,"We now have veriﬁed that the three conditions in Lemma 2 are satisﬁed for hi(S). We obtain that
for any p ≥2, there holds  n
X"
N,0.3404539385847797,"i=1
hi(S)

p ≤48
√"
PN,0.3411214953271028,"2pn
β"
PN,0.3417890520694259,"µ + 1

Lϵ⌈log2 n⌉.
(16)"
PN,0.342456608811749,"Thus, combined (13) with (16), we derive that"
PN,0.3431241655540721,"∥nF(Ax(S), y∗
S) −nFS(Ax(S), ˆy∗
S) −nES′F(Ax(S′), y∗
S′) + nES′FS(Ax(S′), y∗
S′)∥p"
PN,0.3437917222963952,"=
nF(Ax(S), y∗
S) − n
X"
PN,0.3444592790387183,"i=1
gi(S) + n
X"
PN,0.34512683578104136,"i=1
gi(S) − n
X"
PN,0.34579439252336447,"i=1
ES\{zi}[gi(S)]

p"
PN,0.3464619492656876,"≤
nF(Ax(S), y∗
S) −nFS(Ax(S), ˆy∗
S) − n
X"
PN,0.3471295060080107,"i=1
gi(S)

p + n
X"
PN,0.3477970627503338,"i=1
hi(S)

p"
PN,0.3484646194926569,"≤2

1 + β µ"
PN,0.34913217623498,"
Lnϵ + 48
√"
PN,0.34979973297730305,"2pn
β"
PN,0.35046728971962615,"µ + 1

Lϵ⌈log2 n⌉ ≤50
√"
PN,0.35113484646194926,"2

1 + β µ"
PN,0.35180240320427236,"
ϵLpn⌈log2 n⌉.
(17)"
PN,0.35246995994659547,"Then, according to Lemma 1, for any δ ∈(0, 1), with probability at least 1 −δ/3, we have"
PN,0.3531375166889186,"F(Ax(S), y∗
S) −FS(Ax(S), ˆy∗
S)"
PN,0.3538050734312417,"≤|ES′F(Ax(S′), y∗
S′) −ES′FS(Ax(S′), y∗
S′)| + 50
√"
PN,0.35447263017356473,"2ϵeL

1 + β µ"
PN,0.35514018691588783,"
⌈log2 n⌉log(3e/δ).
(18)"
PN,0.35580774365821094,"With a similar analysis to the proof of Part (a), we now begin to bound the variance of
ES′f(Ax(S′), y∗
S′; zi)."
PN,0.35647530040053405,"Ezi[(ES′f(Ax(S′), y∗
S′; zi))2] ≤EziES′[(f(Ax(S′), y∗
S′; zi))2]"
PN,0.35714285714285715,"= EZES′[(f(Ax(S′), y∗
S′; Z))2]"
PN,0.35781041388518026,"= EZES[(f(Ax(S), y∗
S; Z))2]."
PN,0.35847797062750336,"There holds that ESES′FS(Ax(S′), y∗
S′) = ES′F(Ax(S′), y∗
S′). Then, by the Bernstein inequality
in Lemma 4, we obtain that with probability at least 1 −δ/3,"
PN,0.3591455273698264,"|ES′F(Ax(S′), y∗
S′) −ES′FS(Ax(S′), y∗
S′)| ≤ r"
PN,0.3598130841121495,"2EZES[(f(Ax(S), y∗
S; Z))2] log(3/δ)
n
+ 2M log(3/δ)"
N,0.3604806408544726,"3n
.
(19)"
N,0.36114819759679573,Published as a conference paper at ICLR 2022
N,0.36181575433911883,"Combined (18) with (19), we ﬁnally obtain that with probability at least 1 −2δ/3,"
N,0.36248331108144194,"F(Ax(S), y∗
S) −FS(Ax(S), ˆy∗
S) ≤ s"
N,0.36315086782376504,"2EZES[(f(Ax(S), y∗
S; Z))2] log
  3 δ
"
N,0.3638184245660881,"n
+ 2M log
  3 δ
"
N,0.3644859813084112,"3n
+ 50
√"
N,0.3651535380507343,2ϵeLβ + µ
N,0.3658210947930574,"µ
⌈log2 n⌉log
3e δ 
. (20)"
N,0.3664886515353805,"In the following, we deﬁne q = q(z1, ..., zn) = EZ[(f(Ax(S), y∗
S; Z))2] and qi = qi(z1, ..., zn) =
supzi∈Z q(z1, ..., zn). So there holds qi ≥q for any i = 1, .., n and any {z1, ..., zn} ∈Zn. Also,
there holds that n
X"
N,0.3671562082777036,"i=1
(q −qi)2 = n
X i=1"
N,0.3678237650200267,"
EZ[(f(Ax(S), y∗
S; Z))2] −sup
zi∈Z
EZ[(f(Ax(S), y∗
S; Z))2]
2 ≤ n
X i=1"
N,0.3684913217623498,"
EZ
h
sup
zi∈Z
(f(Ax(S), y∗
S; Z))2 −(f(Ax(S), y∗
S; Z))2i2 ≤n
β"
N,0.3691588785046729,"µ + 1
2
L2ϵ2

2EZ[f(Ax(S), y∗
S; Z)] +
β"
N,0.369826435246996,"µ + 1

Lϵ
2"
N,0.3704939919893191,"≤8n
β"
N,0.3711615487316422,"µ + 1
2
L2ϵ2q + 2n
β"
N,0.3718291054739653,"µ + 1
4
L4ϵ4,"
N,0.3724966622162884,where the ﬁrst inequality follows from the Jensen’s inequality and the second inequality follows from
N,0.37316421895861146,"a similar analysis to (12) or (15). Now, we know that q is

8n

β
µ + 1
2
L2ϵ2, 2n

β
µ + 1
4
L4ϵ4
-
weakly self-bounded. Thus, by Lemma 3, we obtain the following inequality with probability at
least 1 −δ/3,"
N,0.37383177570093457,"ESEZ[(f(Ax(S), y∗
S; Z))2] −EZ[(f(Ax(S), y∗
S; Z))2] ≤"
N,0.37449933244325767,"s
16n
β"
N,0.3751668891855808,"µ + 1
2
L2ϵ2ESEZ[(f(Ax(S), y∗
S; Z))2] + 4n
β"
N,0.3758344459279039,"µ + 1
4
L4ϵ4

log(3/δ) ="
N,0.376502002670227,"s
ESEZ[(f(Ax(S), y∗
S; Z))2] + 1 4 β"
N,0.3771695594125501,"µ + 1
2
L2ϵ2

16n
β"
N,0.37783711615487314,"µ + 1
2
L2ϵ2 log(3/δ) ≤1 2"
N,0.37850467289719625,"
ESEZ[(f(Ax(S), y∗
S; Z))2] + 1 4 β"
N,0.37917222963951935,"µ + 1
2
L2ϵ2
+ 8n
β"
N,0.37983978638184246,"µ + 1
2
L2ϵ2 log(3/δ),"
N,0.38050734312416556,"where the last inequality follows from
√"
N,0.38117489986648867,ab ≤a+b
N,0.3818424566088118,"2
for all a, b > 0."
N,0.3825100133511348,"Since EZ[(f(Ax(S), y∗
S; Z))2] ≤MF(Ax(S), y∗
S), we have"
N,0.38317757009345793,"ESEZ[(f(Ax(S), y∗
S; Z))2] −2MF(Ax(S), y∗
S) ≤1 4 β"
N,0.38384512683578104,"µ + 1
2
L2ϵ2 + 16n
β"
N,0.38451268357810414,"µ + 1
2
L2ϵ2 log(3/δ).
(21)"
N,0.38518024032042725,"Plugging (21) into (20), we ﬁnally obtain that with probability at least 1 −δ,"
N,0.38584779706275035,"F(Ax(S), y∗
S) −FS(Ax(S), ˆy∗
S) ≤"
N,0.38651535380507346,"v
u
u
t"
N,0.3871829105473965,"
4MF(Ax(S), y∗
S) + 1"
N,0.3878504672897196,"2

β
µ + 1
2
L2ϵ2 + 32n

β
µ + 1
2
L2ϵ2 log(3/δ)

log(3/δ) n"
N,0.3885180240320427,+ 2M log(3/δ)
N,0.3891855807743658,"3n
+ 50
√"
N,0.38985313751668893,2ϵeLβ + µ
N,0.39052069425901204,"µ
⌈log2 n⌉log(3e/δ).
(22)"
N,0.39118825100133514,Published as a conference paper at ICLR 2022
N,0.3918558077436582,"By the elementary inequalities
√"
N,0.3925233644859813,ab ≤ηa + 1
N,0.3931909212283044,"ηb and
√"
N,0.3938584779706275,"a + b ≤√a +
√"
N,0.3945260347129506,"b for any a, b, η > 0, we
have the following inequality with probability at least 1 −δ"
N,0.3951935914552737,"F(Ax(S), y∗
S) −(1 + η)FS(Ax(S), ˆy∗
S) ≤C 1 + η η M"
N,0.39586114819759677,n log 1
N,0.3965287049399199,"δ +
β"
N,0.397196261682243,"µ + 1

Lϵ log2 n log 1 δ 
,"
N,0.3978638184245661,where C is an absolute constant. The proof is complete.
N,0.3985313751668892,"A.3
PROOF OF PART (C)"
N,0.3991989319092123,"We then prove the strong PD population risk bound. To begin, we introduce the following concen-
tration inequality, which is a moment version of the Bernstein inequality.
Lemma 6. (Boucheron et al., 2013) If z1, ..., zn are i.i.d., zero mean and |zi| ≤M almost surely.
Then, for any p ≥2,  n
X"
N,0.3998664886515354,"i=1
zi

p ≤6"
N,0.40053404539385845,"v
u
u
t 
n
X"
N,0.40120160213618156,"i=1
Ez2
i

p + 4pM."
N,0.40186915887850466,"Proof. Let S
=
{z1, ..., zn} be a set of independent random variables each taking values
in Z and S′
=
{z′
1, ..., z′
n} be its independent copy.
For any i
∈
[n], deﬁne S(i)
=
{z1, ..., zi−1, z′
i, zi+1, ..., zn} be a dataset by replacing the i-th sample in S with another i.i.d.
sample z′
i. Denote y∗
S = arg maxy∈Y F(Ax(S), y), ˆy∗
S = arg maxy∈Y FS(Ax(S), y), x∗
S =
arg minx∈X F(x, Ay(S)) and ˆx∗
S = arg minx∈X FS(x, Ay(S))."
N,0.40253671562082777,"The proof of Part (c) requires a pretty technical error decomposition, i.e.,
△s (Ax(S), Ay(S))"
N,0.4032042723631509,"=F(Ax(S), y∗
S) −inf
x′∈X F(x′, Ay(S))"
N,0.403871829105474,"=F(Ax(S), y∗
S) −FS(Ax(S), ˆy∗
S) + ES′FS(Ax(S′), y∗
S′) −ESF(Ax(S), y∗
S)"
N,0.4045393858477971,"+ ESF(x∗
S, Ay(S)) −ES′FS(x∗
S′, Ay(S′)) + FS(ˆx∗
S, Ay(S)) −inf
x′∈X F(x′, Ay(S))"
N,0.40520694259012013,"−ES′FS(Ax(S′), y∗
S′) + ESF(Ax(S), y∗
S) + ES′FS(x∗
S′, Ay(S′)) −ESF(x∗
S, Ay(S))
+ FS(Ax(S), ˆy∗
S) −FS(ˆx∗
S, Ay(S)).
Let’s ﬁrst consider the term F(Ax(S), y∗
S) −FS(Ax(S), ˆy∗
S) + ES′FS(Ax(S′), y∗
S′) −
ESF(Ax(S), y∗
S). It can be then decomposed into"
N,0.40587449933244324,"F(Ax(S), y∗
S) −FS(Ax(S), ˆy∗
S) + 1 n n
X"
N,0.40654205607476634,"i=1
Ez′
i"
N,0.40720961281708945,"h
EZ[f(Ax(S(i)), y∗
S(i); Z)] −f(Ax(S(i)), y∗
S(i); zi)
i −1 n n
X"
N,0.40787716955941256,"i=1
Ez′
i"
N,0.40854472630173566,"h
EZ[f(Ax(S(i)), y∗
S(i); Z)] −f(Ax(S(i)), y∗
S(i); zi)
i
+ ES′FS(Ax(S′), y∗
S′)"
N,0.40921228304405877,"−ESF(Ax(S), y∗
S),
which can be bounded by the proof techniques in the proof of Part (b). According to (17), we know
that
∥F(Ax(S), y∗
S) −FS(Ax(S), ˆy∗
S) + ES′FS(Ax(S′), y∗
S′) −ESF(Ax(S), y∗
S)∥p ≤50
√"
N,0.4098798397863818,"2

1 + β µ"
N,0.4105473965287049,"
ϵLp⌈log2 n⌉.
(23)"
N,0.411214953271028,"For
the
second
term
ESF(x∗
S, Ay(S))
−
ES′FS(x∗
S′, Ay(S′))
+
FS(ˆx∗
S, Ay(S))
−
infx′∈X F(x′, Ay(S)), we have the following decomposition
nFS(ˆx∗
S, Ay(S)) −n inf
x′∈X F(x′, Ay(S))"
N,0.41188251001335113,"=nFS(ˆx∗
S, Ay(S)) − n
X"
N,0.41255006675567424,"i=1
EZ
h
f(x∗
S, Ay(S), Z) −Ez′
i[f(x∗
S(i), Ay(S(i)); Z)]
i + n
X"
N,0.41321762349799734,"i=1
Ez′
i"
N,0.41388518024032045,"h
f(x∗
S(i), Ay(S(i)); zi) −EZ[f(x∗
S(i), Ay(S(i)); Z)]
i
− n
X"
N,0.4145527369826435,"i=1
Ez′
i"
N,0.4152202937249666,"h
f(x∗
S(i), Ay(S(i)); zi)
i
."
N,0.4158878504672897,Published as a conference paper at ICLR 2022
N,0.4165554072096128,"It is clear that
n
X"
N,0.4172229639519359,"i=1
Ez′
i"
N,0.417890520694259,"h
f(x∗
S(i), Ay(S(i)); zi)
i = n
X"
N,0.41855807743658213,"i=1
Ez′
i"
N,0.4192256341789052,"h
f(x∗
S(i), Ay(S(i)); zi) −f(x∗
S, Ay(S); zi) + f(x∗
S, Ay(S); zi)
i"
N,0.4198931909212283,"≥nFS(ˆx∗
S, Ay(S)) + n
X"
N,0.4205607476635514,"i=1
Ez′
i"
N,0.4212283044058745,"h
f(x∗
S(i), Ay(S(i)); zi) −f(x∗
S, Ay(S); zi)
i
.
(24)"
N,0.4218958611481976,"Denote gi(S) = Ez′
i

f(x∗
S(i), Ay(S(i)); zi) −EZ[f(x∗
S(i), Ay(S(i)); Z)]

. By (24), we now get"
N,0.4225634178905207,"nFS(ˆx∗
S, Ay(S)) −n inf
x′∈X F(x′, Ay(S)) − n
X"
N,0.4232309746328438,"i=1
gi(S) ≤− n
X"
N,0.42389853137516686,"i=1
EZ
h
f(x∗
S, Ay(S); Z) −Ez′
i[f(x∗
S(i), Ay(S(i)); Z)]
i − n
X"
N,0.42456608811748997,"i=1
Ez′
i"
N,0.4252336448598131,"h
f(x∗
S(i), Ay(S(i)); zi) −f(x∗
S, Ay(S); zi)
i
."
N,0.4259012016021362,"Furthermore, according to Lemma 5, we have
f(x∗
S, Ay(S); Z) −f(x∗
S(i), Ay(S(i)); Z)
 ≤

1 + β µ"
N,0.4265687583444593,"
L∥Ay(S) −Ay(S(i))∥."
N,0.4272363150867824,"Similarly,
f(x∗
S(i), Ay(S(i)); zi) −f(x∗
S, Ay(S); zi)
 ≤

1 + β µ"
N,0.4279038718291055,"
L∥Ay(S) −Ay(S(i))∥."
N,0.42857142857142855,"Thus, we obtain
nFS(ˆx∗
S, Ay(S)) −n inf
x′∈X F(x′, Ay(S)) − n
X"
N,0.42923898531375165,"i=1
gi(S) ≤ n
X"
N,0.42990654205607476,"i=1
2

1 + β µ"
N,0.43057409879839786,"
L∥Ay(S(i)) −Ay(S)∥≤2n

1 + β µ"
N,0.43124165554072097,"
Lϵ,
(25)"
N,0.4319092122830441,where the last inequality follows from the deﬁnition of argument stability (Part 2 of Deﬁnition 3).
N,0.4325767690253672,"Furthermore, we deﬁne hi(S) = gi(S) −ES\{zi}[gi(S)]. For hi(S), We have ES\{zi}[hi(S)] = 0
and Ezi[hi(S)] = Ezi[gi(S)] −EziES\{zi}[gi(S)] = 0 −0 = 0. Moreover, for any j ∈[n] with
j ̸= i, and z′′
j ∈Z, we get"
N,0.43324432576769023,"|hi(S) −hi(z1, ..., zj−1, z′′
j , zj+1, ..., zn)| ≤2

1 + β µ 
Lϵ,"
N,0.43391188251001334,"where this inequality follows from a similar analysis to (14) and (15) of the proof of Part (b). We
thus can obtain that for any p ≥2, there holds n
X"
N,0.43457943925233644,"i=1
hi(S)

p ≤48
√"
PN,0.43524699599465955,"2pn
β"
PN,0.43591455273698265,"µ + 1

Lϵ⌈log2 n⌉.
(26)"
PN,0.43658210947930576,"Combined (25) with (26), we ﬁnally get the bound of the second term:
ESF(x∗
S, Ay(S)) −ES′FS(x∗
S′, Ay(S′)) + FS(ˆx∗
S, Ay(S)) −inf
x′∈X F(x′, Ay(S))

p"
PN,0.43724966622162886,"≤
FS(ˆx∗
S, Ay(S)) −inf
x′∈X F(x′, Ay(S)) −1 n n
X"
PN,0.4379172229639519,"i=1
gi(S)

p +
 1 n n
X"
PN,0.438584779706275,"i=1
hi(S)

p ≤50
√"
PN,0.4392523364485981,"2

1 + β µ"
PN,0.43991989319092123,"
ϵLp⌈log2 n⌉.
(27)"
PN,0.44058744993324434,Published as a conference paper at ICLR 2022
PN,0.44125500667556744,"We then consider the third term −ES′FS(Ax(S′), y∗
S′)+ESF(Ax(S), y∗
S)+ES′FS(x∗
S′, Ay(S′))−
ESF(x∗
S, Ay(S)).
It is clear that ES[ES′FS(x∗
S′, Ay(S′))]
=
ESF(x∗
S, Ay(S)) and
ES[ES′FS(Ax(S′), y∗
S′)] = ESF(Ax(S), y∗
S)."
PN,0.44192256341789055,"Moreover, we having the following important property due to the strong convexity and strong con-
cavity of F,
E

(ES′f(x∗
S′, Ay(S′); zi) −ES′f(Ax(S′), y∗
S′; zi))2"
PN,0.4425901201602136,"≤EES′ 
L2(∥x∗
S′ −Ax(S′)∥+ ∥Ay(S′) −y∗
S′∥)2"
PN,0.4432576769025367,"≤2L2EES′[∥x∗
S′ −Ax(S′)∥2 + ∥Ay(S′) −y∗
S′∥2]"
PN,0.4439252336448598,"≤4L2µ−1EES′[F(Ax(S′), y∗
S′) −F(x∗
S′, Ax(S′))]"
PN,0.4445927903871829,"=4L2µ−1ES′[F(Ax(S′), y∗
S′) −F(x∗
S′, Ax(S′))],
(28)
where the ﬁrst inequality follows from Jensen’s inequality and the Lipschitz continuity of f (As-
sumption 1), the second inequality follows from that (a + b)2 ≤2a2 + 2b2 and the third inequality
follows from the property of strong convexity and strong concavity of F and the optimality condi-
tion, derived as follows,
F(Ax(S′), y∗
S′) −F(x∗
S′, Ax(S′))"
PN,0.445260347129506,"=F(Ax(S′), y∗
S′) −F(x∗
S′, y∗
S′) + F(x∗
S′, y∗
S′) −F(x∗
S′, Ax(S′)) ≥µ 2"
PN,0.4459279038718291,"h
∥Ax(S′) −x∗
S′∥2 + ∥y∗
S′ −Ax(S′)∥
i
."
PN,0.44659546061415223,"It is clear that E[(Z −EZ)2] ≤E[Z2]. Therefore, by the variance bound in (28) and apply-
ing the moment Bernstein inequality in Lemma 6 to the sum of independent random variables
−ES′f(Ax(S′), y∗
S′; zi)+ES′f(x∗
S′, Ay(S′); zi)+ESF(Ax(S), y∗
S)−ESF(x∗
S, Ay(S)), we have
the following inequality for all p ≥2,
 1 n n
X"
PN,0.4472630173564753,"i=1
−ES′f(Ax(S′), y∗
S′; zi) + ES′f(x∗
S′, Ay(S′); zi) + ESF(Ax(S), y∗
S) −ESF(x∗
S, Ay(S))

p ≤6 s"
PN,0.4479305740987984,"ES′[F(Ax(S′), y∗
S′) −F(x∗
S′, Ax(S′))]4L2p"
PN,0.4485981308411215,"nµ
+ 16pM n
."
PN,0.4492656875834446,"From Deﬁnition 1, we know that the last term FS(Ax(S), ˆy∗
S) −FS(ˆx∗
S, Ay(S)) is actually the
strong PD empirical risk △s
S(Ax(S), Ay(S))."
PN,0.4499332443257677,"Based on the above analysis, we have derived that for each p ≥2,
F(Ax(S), y∗
S) −inf
x′∈X F(x′, Ay(S)) −△s
S(Ax(S), Ay(S))

p ≤12 s"
PN,0.4506008010680908,"ES′[F(Ax(S′), y∗
S′) −F(x∗
S′, Ax(S′))]pL2"
PN,0.4512683578104139,nµ + 16pM
PN,0.45193591455273696,"n
+ 100
√"
PN,0.45260347129506007,"2

1 + β µ"
PN,0.4532710280373832,"
ϵLp⌈log2 n⌉"
PN,0.4539385847797063,"≤
η
1 + η ES′[F(Ax(S′), y∗
S′) −F(x∗
S′, Ax(S′))] + 1 + η"
PN,0.4546061415220294,"η
12pL2"
PN,0.4552736982643525,"nµ
+ 16pM n"
PN,0.4559412550066756,"+ 100
√"
PN,0.45660881174899864,"2

1 + β µ"
PN,0.45727636849132175,"
ϵLp⌈log2 n⌉,
(29)"
PN,0.45794392523364486,"where the last inequality holds since for any a, b, η > 0,
√"
PN,0.45861148197596796,ab ≤ηa + b η.
PN,0.45927903871829107,"Taking p = 2 and using the Cauchy-Schwarz inequality, we obtain that"
PN,0.45994659546061417,"ES
h
F(Ax(S), y∗
S) −inf
x′∈X F(x′, Ay(S)) −△s
S(Ax(S), Ay(S))
i"
PN,0.4606141522029373,"≤∥F(Ax(S), y∗
S) −inf
x′∈X F(x′, Ay(S)) −△s
S(Ax(S), Ay(S))∥2"
PN,0.4612817089452603,"≤
η
1 + η ES′[F(Ax(S′), y∗
S′) −F(x∗
S′, Ax(S′))] + 1 + η"
PN,0.46194926568758343,"η
24L2"
PN,0.46261682242990654,"nµ
+ 32M n"
PN,0.46328437917222964,"+ 200
√"
PN,0.46395193591455275,"2

1 + β µ"
PN,0.46461949265687585,"
ϵL⌈log2 n⌉."
PN,0.4652870493991989,Published as a conference paper at ICLR 2022
PN,0.465954606141522,"Since ES′[F(Ax(S′), y∗
S′) −F(x∗
S′, Ax(S′))] = ES[F(Ax(S), y∗
S) −F(x∗
S, Ax(S))], we ﬁnally
get"
PN,0.4666221628838451,"ES[F(Ax(S), y∗
S) −inf
x′∈X F(x′, Ay(S))]"
PN,0.4672897196261682,"≤(1 + η)

ES △s
S (Ax(S), Ay(S)) + 24L2(1 + η)"
PN,0.4679572763684913,"nµη
+ 32M"
PN,0.46862483311081443,"n
+ 200
√"
PN,0.46929238985313754,"2

1 + β µ"
PN,0.4699599465954606,"
ϵL⌈log2 n⌉

."
PN,0.4706275033377837,"Plugging this inequality into (29), we thus have that for each p ≥2,
F(Ax(S), y∗
S) −inf
x′∈X F(x′, Ay(S)) −△s
S(Ax(S), Ay(S))

p"
PN,0.4712950600801068,"≤η

ES △s
S (Ax(S), Ay(S)) + 24L2(1 + η)"
PN,0.4719626168224299,"nµη
+ 32M"
PN,0.472630173564753,"n
+ 200
√"
PN,0.4732977303070761,"2

1 + β µ"
PN,0.4739652870493992,"
ϵL⌈log2 n⌉
"
PN,0.47463284379172227,+ 12pL2(1 + η)
PN,0.4753004005340454,"nµη
+ 16pM"
PN,0.4759679572763685,"n
+ 100
√"
PN,0.4766355140186916,"2

1 + β µ"
PN,0.4773030707610147,"
ϵLp⌈log2 n⌉."
PN,0.4779706275033378,"According to Lemma 1, for any δ > 0, with probability at least 1 −δ, there holds that"
PN,0.4786381842456609,"F(Ax(S), y∗
S) −inf
x′∈X F(x′, Ay(S)) ≤△s
S(Ax(S), Ay(S)) + ηES △s
S (Ax(S), Ay(S))"
PN,0.47930574098798395,"+ C(1 + η)
L2(1 + η)"
PN,0.47997329773030706,"nµη
+ M"
PN,0.48064085447263016,"n +

1 + β µ"
PN,0.48130841121495327,"
ϵL log2 n

log
1 δ"
PN,0.4819759679572764,"
,
(30)"
PN,0.4826435246995995,where C > 0 is an absolute constant. The proof is complete.
PN,0.4833110814419226,"A.4
PROOF OF PART (D)"
PN,0.48397863818424564,We now prove the strong PD generalization error bound.
PN,0.48464619492656874,"Proof. From (30) in the proof of Part (c), we know that for any δ > 0, with probability at least 1−δ,
there holds that"
PN,0.48531375166889185,"△s (Ax(S), Ay(S)) −△s
S(Ax(S), Ay(S))"
PN,0.48598130841121495,"=F(Ax(S), y∗
S) −inf
x′∈X F(x′, Ay(S)) −△s
S(Ax(S), Ay(S))"
PN,0.48664886515353806,"≤ηES △s
S (Ax(S), Ay(S)) + C(1 + η)
L2(1 + η)"
PN,0.48731642189586116,"nµη
+ M"
PN,0.48798397863818427,"n +

1 + β µ"
PN,0.4886515353805073,"
ϵL log2 n

log
1 δ 
."
PN,0.4893190921228304,"Therefore, the proof is complete."
PN,0.48998664886515353,"A.5
PROOF OF PART (E)"
PN,0.49065420560747663,We ﬁnally prove the excess primal population risk bound.
PN,0.49132176234979974,"Proof. Denote x∗= arg minx∈X R(x) and y∗
S = arg maxy∈Y F(Ax(S), y). Firstly, we have the
following decomposition"
PN,0.49198931909212285,"R(Ax(S)) −inf
x′∈X R(x′) = R(Ax(S)) −RS(Ax(S)) + RS(Ax(S)) −FS(x∗, Ay(S))"
PN,0.49265687583444595,"+ FS(x∗, Ay(S)) −F(x∗, Ay(S)) + F(x∗, Ay(S)) −R(x∗).
(31)"
PN,0.493324432576769,"Consider the ﬁrst term R(Ax(S)) −RS(Ax(S)). From (22) of the Part (b), we know that with
probability at least 1 −δ,"
PN,0.4939919893190921,R(Ax(S)) −RS(Ax(S)) ≤2M log(3/δ)
N,0.4946595460614152,"3n
+ 50
√"
N,0.4953271028037383,2ϵeLβ + µ
N,0.4959946595460614,"µ
⌈log2 n⌉log(3e/δ) +"
N,0.49666221628838453,"v
u
u
t"
N,0.49732977303070763,"
4MF(Ax(S), y∗
S) + 1"
N,0.4979973297730307,"2

β
µ + 1
2
L2ϵ2 + 32n

β
µ + 1
2
L2ϵ2 log(3/δ)

log(3/δ) n
."
N,0.4986648865153538,Published as a conference paper at ICLR 2022
N,0.4993324432576769,"For the second term RS(Ax(S)) −FS(x∗, Ay(S)), we have RS(Ax(S)) −FS(x∗, Ay(S)) ≤
RS(Ax(S)) −infx′∈Y FS(x′, Ay(S)) = △s
S(Ax(S), Ay(S))."
N,0.5,"Note that under Assumption 1, the argument stability implies the uniform stability. Therefore, for
the third term FS(x∗, Ay(S))−F(x∗, Ay(S)), from (10) of Part (a), we know that with probability
at least 1 −δ"
N,0.5006675567423231,"FS(x∗, Ay(S)) −F(x∗, Ay(S)) ≤2M log(3/δ)"
N,0.5013351134846462,"3n
+ 50
√"
N,0.5020026702269693,2eϵ⌈log2 n⌉log(3e/δ) + s
N,0.5026702269692924,"(4MF(x∗, Ay(S)) + 1"
N,0.5033377837116155,"2ϵ2 + 32nϵ2 log(3/δ)) log(3/δ) n
."
N,0.5040053404539386,"It is clear that F(x∗, Ay(S)) −R(x∗) ≤0."
N,0.5046728971962616,"Since F(x∗, Ay(S)) ≤supy′∈Y F(x∗, y′) = R(x∗) = infx′∈X R(x), based on the above results,
we have the following inequality with probability at least 1 −2δ"
N,0.5053404539385847,"R(Ax(S)) −inf
x′∈X R(x) ≤"
N,0.5060080106809078,"v
u
u
t"
N,0.5066755674232309,"
4MF(Ax(S), y∗
S) + 1"
N,0.507343124165554,"2

β
µ + 1
2
L2ϵ2 + 32n

β
µ + 1
2
L2ϵ2 log(3/δ)

log(3/δ) n"
N,0.5080106809078772,+ 4M log(3/δ)
N,0.5086782376502003,"3n
+ s"
N,0.5093457943925234,(4M infx′∈X R(x) + 1
N,0.5100133511348465,2ϵ2 + 32nϵ2 log(3/δ)) log(3/δ) n
N,0.5106809078771696,"+ 50
√"
N,0.5113484646194927,2ϵeLβ + µ
N,0.5120160213618158,"µ
⌈log2 n⌉log(3e/δ) + △s
S(Ax(S), Ay(S)) + 50
√"
N,0.5126835781041389,2eϵ⌈log2 n⌉log(3e/δ) ≤
N,0.513351134846462,"v
u
u
t"
N,0.514018691588785,"
1
2

β
µ + 1
2
L2ϵ2 + 32n

β
µ + 1
2
L2ϵ2 log(3/δ)

log(3/δ)"
N,0.5146862483311081,"n
+
η
1 + η F(Ax(S), y∗
S)"
N,0.5153538050734312,+ 1 + η
N,0.5160213618157543,"η
4M log(3/δ)"
N,0.5166889185580774,"n
+ 4M log(3/δ)"
N,0.5173564753004005,"3n
+ s ( 1"
N,0.5180240320427236,2ϵ2 + 32nϵ2 log(3/δ)) log(3/δ) n
N,0.5186915887850467,"+
η
1 + η inf
x′∈X R(x) + 1 + η"
N,0.5193591455273698,"η
4M log(3/δ) n"
N,0.5200267022696929,"+ 50
√"
N,0.520694259012016,2ϵeLβ + µ
N,0.5213618157543392,"µ
⌈log2 n⌉log(3e/δ) + △s
S(Ax(S), Ay(S)) + 50
√"
N,0.5220293724966623,"2eϵ⌈log2 n⌉log(3e/δ),"
N,0.5226969292389854,"where the last inequality follows from the elementary inequalities
√"
N,0.5233644859813084,ab ≤ηa + 1
N,0.5240320427236315,"ηb and
√"
N,0.5246995994659546,"a + b ≤
√a +
√"
N,0.5253671562082777,"b for any a, b > 0. Therefore, by a rearrangement, we have the following inequality with
probability at least 1 −δ"
N,0.5260347129506008,"R(Ax(S)) −(1 + 2η) inf
x′∈X R(x)"
N,0.5267022696929239,≤C 1 + η η M
N,0.527369826435247,n log 1
N,0.5280373831775701,"δ +
β"
N,0.5287049399198932,"µ + 1

Lϵ log2 n log 1"
N,0.5293724966622163,"δ + △s
S(Ax(S), Ay(S))

,"
N,0.5300400534045394,that is
N,0.5307076101468625,"R(Ax(S)) −(1 + η) inf
x′∈X R(x)"
N,0.5313751668891856,≤C 2 + η η M
N,0.5320427236315087,n log 1
N,0.5327102803738317,"δ +
β"
N,0.5333778371161548,"µ + 1

Lϵ log2 n log 1"
N,0.5340453938584779,"δ + △s
S(Ax(S), Ay(S))

,"
N,0.534712950600801,where C is an absolute constant. The proof is complete.
N,0.5353805073431241,"Till here, the proof of Theorem 1 is complete."
N,0.5360480640854473,Published as a conference paper at ICLR 2022
N,0.5367156208277704,"B
EMPIRICAL SADDLE POINT"
N,0.5373831775700935,"Empirical saddle point (ESP) problem refers to problem (2), which is also known as sample average
approximation (SAA) (Zhang et al., 2021a). We denote (ˆx∗
S, ˆy∗
S) as the ESP solution to (2), which
is analogy to the ERM in stochastic optimization (Shalev-Shwartz et al., 2010). We ﬁrst provide the
main theorem of the ESP solution, as shown below."
N,0.5380507343124166,"Theorem 3. Assume for all z, the function (x, y) 7→f(x, y; z) is µ-SC-SC. Suppose |f(x, y; z)| ≤
M for some M > 0 and x ∈X, y ∈Y, z ∈Z. Denote Ax(S) = ˆx∗
S and Ay(S) = ˆy∗
S for
(ˆx∗
S, ˆy∗
S). Fixed any η > 0. There exists an absolute positive constant C."
N,0.5387182910547397,"(a) If Assumption 1 holds, then for any δ > 0, with probability at least 1 −δ, we have"
N,0.5393858477970628,"F(ˆx∗
S, ˆy∗
S) ≤(1 + η)FS(ˆx∗
S, ˆy∗
S) + C 1 + η η M"
N,0.5400534045393859,n log(1/δ) + 4L
N,0.540720961281709,"nµ log2 n log(1/δ)

."
N,0.5413885180240321,"(b) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
N,0.5420560747663551,"R(ˆx∗
S) ≤(1 + η)RS(ˆx∗
S) + C 1 + η η M"
N,0.5427236315086782,n log 1
N,0.5433911882510013,"δ +
β"
N,0.5440587449933244,"µ + 1
4L2"
N,0.5447263017356475,"nµ log2 n log 1 δ 
."
N,0.5453938584779706,"(c) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
N,0.5460614152202937,"△s(ˆx∗
S, ˆy∗
S) ≤C(1 + η)
L2(1 + η)"
N,0.5467289719626168,"nµη
+ M"
N,0.5473965287049399,"n +

1 + β µ 4L2"
N,0.548064085447263,"nµ log2 n

log
1 δ 
."
N,0.5487316421895861,"(d) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
N,0.5493991989319092,"△s (ˆx∗
S, ˆy∗
S) −△s
S(ˆx∗
S, ˆy∗
S)"
N,0.5500667556742324,"≤C(1 + η)
L2(1 + η)"
N,0.5507343124165555,"nµη
+ M"
N,0.5514018691588785,"n +

1 + β µ 4L2"
N,0.5520694259012016,"nµ log2 n

log
1 δ 
."
N,0.5527369826435247,"(e) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
N,0.5534045393858478,"R(ˆx∗
S) ≤(1 + η) inf
x∈X R(x) + C 2 + η η M"
N,0.5540720961281709,n log 1
N,0.554739652870494,"δ +
β"
N,0.5554072096128171,"µ + 1
4L2"
N,0.5560747663551402,"nµ log2 n log 1 δ 
."
N,0.5567423230974633,"Proof. To prove Theorem 3, we should derive the strong PD empirical risk bound and the stability
bound of (ˆx∗
S, ˆy∗
S). It is easy to verify that △s
S(ˆx∗
S, ˆy∗
S) = 0 (Zhang et al., 2021a). We then
investigate the stability bound of (ˆx∗
S, ˆy∗
S)."
N,0.5574098798397864,"Let S = {z1, ..., zn} be a set of independent random variables each taking values in Z. For any
i ∈[n], deﬁne S(i) = {z1, ..., zi−1, z′
i, zi+1, ..., zn} be a dataset by replacing the i-th sample in
S with another i.i.d. sample z′
i. We deﬁne FS(i) be the empirical risk on dataset S(i) and deﬁne
(ˆx∗
S(i), ˆy∗
S(i)) be the ESP solution on dataset S(i)."
N,0.5580774365821095,Published as a conference paper at ICLR 2022
N,0.5587449933244326,Then we have
N,0.5594125500667557,"FS(ˆx∗
S(i), ˆy∗
S) −FS(ˆx∗
S, ˆy∗
S(i)) = 1 n n
X j=1"
N,0.5600801068090788," 
f(ˆx∗
S(i), ˆy∗
S; zj) −f(ˆx∗
S, ˆy∗
S(i); zj)
 = 1 n 
n
X"
N,0.5607476635514018,"j=1,j̸=i
(f(ˆx∗
S(i), ˆy∗
S; zj) −f(ˆx∗
S, ˆy∗
S(i); zj)) + f(ˆx∗
S(i), ˆy∗
S; z′
i) −f(ˆx∗
S, ˆy∗
S(i); z′
i)
 + 1"
N,0.5614152202937249,"n
 
f(ˆx∗
S(i), ˆy∗
S; zi) −f(ˆx∗
S, ˆy∗
S(i); zi)

−1"
N,0.562082777036048,"n
 
f(ˆx∗
S(i), ˆy∗
S; z′
i) −f(ˆx∗
S, ˆy∗
S(i); z′
i)
"
N,0.5627503337783711,"=FS(i)(ˆx∗
S(i), ˆy∗
S) −FS(i)(ˆx∗
S, ˆy∗
S(i)) + 1"
N,0.5634178905206942,"n
 
f(ˆx∗
S(i), ˆy∗
S; zi) −f(ˆx∗
S, ˆy∗
S; zi) + f(ˆx∗
S, ˆy∗
S; zi) −f(ˆx∗
S, ˆy∗
S(i); zi)
 −1"
N,0.5640854472630173,"n
 
f(ˆx∗
S(i), ˆy∗
S; z′
i) −f(ˆx∗
S, ˆy∗
S; z′
i) + f(ˆx∗
S, ˆy∗
S; z′
i) −f(ˆx∗
S, ˆy∗
S(i); z′
i)
"
N,0.5647530040053405,"≤FS(i)(ˆx∗
S(i), ˆy∗
S) −FS(i)(ˆx∗
S, ˆy∗
S(i)) + 2L"
N,0.5654205607476636,"n (∥ˆx∗
S(i) −ˆx∗
S∥+ ∥ˆy∗
S −ˆy∗
S(i)∥)"
N,0.5660881174899867,"=FS(i)(ˆx∗
S(i), ˆy∗
S) −FS(i)(ˆx∗
S(i), ˆy∗
S(i)) + FS(i)(ˆx∗
S(i), ˆy∗
S(i)) −FS(i)(ˆx∗
S, ˆy∗
S(i)) + 2L"
N,0.5667556742323098,"n (∥ˆx∗
S(i) −ˆx∗
S∥+ ∥ˆy∗
S −ˆy∗
S(i)∥) ≤−µ"
N,0.5674232309746329,"2 ∥ˆx∗
S(i) −ˆx∗
S∥2 −µ"
N,0.568090787716956,"2 ∥ˆy∗
S −ˆy∗
S(i)∥2 + 2L"
N,0.5687583444592791,"n (∥ˆx∗
S(i) −ˆx∗
S∥+ ∥ˆy∗
S −ˆy∗
S(i)∥),"
N,0.5694259012016022,"where the ﬁrst inequality follows from the Lipschitz continuous assumption, and where the second
inequality follows from the facts that the µ-SC-SC property of FS(i) and (ˆx∗
S(i), ˆy∗
S(i)) is the ESP
solution of FS(i)."
N,0.5700934579439252,"Similarly, according to the µ-SC-SC property of FS, we have"
N,0.5707610146862483,"FS(ˆx∗
S(i), ˆy∗
S) −FS(ˆx∗
S, ˆy∗
S(i))
=FS(ˆx∗
S(i), ˆy∗
S) −FS(ˆx∗
S, ˆy∗
S) + FS(ˆx∗
S, ˆy∗
S) −FS(ˆx∗
S, ˆy∗
S(i)) ≥µ"
N,0.5714285714285714,"2 ∥ˆx∗
S(i) −ˆx∗
S∥2 + µ"
N,0.5720961281708945,"2 ∥ˆy∗
S −ˆy∗
S(i)∥2
(32)"
N,0.5727636849132176,"Based on the above results, we have"
N,0.5734312416555407,"µ∥ˆx∗
S(i) −ˆx∗
S∥2 + µ∥ˆy∗
S −ˆy∗
S(i)∥2 ≤2L"
N,0.5740987983978638,"n (∥ˆx∗
S(i) −ˆx∗
S∥+ ∥ˆy∗
S −ˆy∗
S(i)∥) ≤2L n √"
Q,0.5747663551401869,"2
q"
Q,0.57543391188251,"∥ˆx∗
S(i) −ˆx∗
S∥2 + ∥ˆy∗
S −ˆy∗
S(i)∥2,"
Q,0.5761014686248331,"where the last inequality uses the Caucy-Schwarz inequality. Therefore, we have"
Q,0.5767690253671562,"∥ˆx∗
S(i) −ˆx∗
S∥+ ∥ˆy∗
S −ˆy∗
S(i)∥ ≤
q"
Q,0.5774365821094793,"2(∥ˆx∗
S(i) −ˆx∗
S∥2 + ∥ˆy∗
S −ˆy∗
S(i)∥2) ≤4L"
Q,0.5781041388518025,"nµ.
(33)"
Q,0.5787716955941254,"Now, plugging this stability bound into Theorem 1, we obtain generalization bounds of the ESP
solution. The proof of Theorem 3 is complete."
Q,0.5794392523364486,"Remark 8. When conditions in Theorem 3 hold, we obtain that (a) If Assumption 1 holds and
FS(ˆx∗
S, ˆy∗
S) = O

1
n

, then for any δ > 0, with probability at least 1 −δ, the plain generalization"
Q,0.5801068090787717,"error of (ˆx∗
S, ˆy∗
S) is of the order O

log2 n"
Q,0.5807743658210948,"n
log(1/δ)

. (b) If Assumptions 1 and 2 hold and RS(ˆx∗
S) ="
Q,0.5814419225634179,"O

1
n

, then for any δ > 0, with probability at least 1 −δ, the primal generalization error of"
Q,0.582109479305741,Published as a conference paper at ICLR 2022
Q,0.5827770360480641,"(ˆx∗
S, ˆy∗
S) is of the order O

log2 n"
Q,0.5834445927903872,"n
log(1/δ)

. (c) If Assumptions 1 and 2 hold, then for any δ > 0,
with probability at least 1 −δ, the strong PD population risk and the strong PD generalization
error of (ˆx∗
S, ˆy∗
S) are all of the order O

log2 n"
Q,0.5841121495327103,"n
log(1/δ)

. (d) If Assumptions 1 and 2 hold and"
Q,0.5847797062750334,"infx∈X R(x) = O

1
n

, then for any δ > 0, with probability at least 1 −δ, the excess primal"
Q,0.5854472630173565,"population risk of (ˆx∗
S, ˆy∗
S) is of the order O

log2 n"
Q,0.5861148197596796,"n
log(1/δ)

."
Q,0.5867823765020027,"Remark 9. (Zhang et al., 2021a) also studies the generalization bound of the ESP solution. They
provide O(1/n) order bounds for weak PD population risk and expected strong PD population
risk. Their proofs also show that the expected strong PD population risk is more difﬁcult to an-
alyze than the former. They have to consider the fact that different ˆx∗
S corresponds to different
y, as discussed in Remark 5. Moreover, the expectation operator in expected strong PD popula-
tion risk also relaxes the difﬁculty of proof. Speciﬁcally, deﬁne S(i) be a dataset by replacing the
i-th sample in S with another i.i.d. sample z′
i and y∗(x) = arg maxy∈Y F(x, y), there holds
the following important property E

supy∈Y F(ˆx∗
S, y)

=
1
n
Pn
i=1 E

F(ˆx∗
S(i), y∗(ˆx∗
S(i)))

=
1
n
Pn
i=1 E

f(ˆx∗
S(i), y∗(ˆx∗
S(i)); zi)

because (ˆx∗
S, y∗(ˆx∗
S)) and (ˆx∗
S(i), y∗(ˆx∗
S(i))) are identically dis-
tributed and the independence between zi and S(i). On the contrary, when there is no expectation
operator, we do not have this property and the proof is much more challenging."
Q,0.5874499332443258,"C
GRADIENT DESCENT ASCENT"
Q,0.5881174899866488,"We need some notations to state results on GDA. Speciﬁcally, assume the initial point satisﬁes
x1 = 0 and y1 = 0. Let {ηt} be a sequence of positive step sizes. At the t-th iteration, GDA
updates"
Q,0.5887850467289719,"xt+1 = xt −ηt∇xFS(xt, yt),
yt+1 = yt + ηt∇yFS(xt, yt).
(34)"
Q,0.589452603471295,We denote the average of iterates by
Q,0.5901201602136181,"¯xT =
PT
t=1 xt"
Q,0.5907877169559412,"T
and
¯yT =
PT
t=1 yt"
Q,0.5914552736982643,"T
.
(35)"
Q,0.5921228304405874,"Here, we ﬁrst provide an important lemma to connect the argument stability with the strong PD
empirical risk, which will also be used in the remaining applications."
Q,0.5927903871829105,"Lemma 7. For any i ∈[n], deﬁne S(i) = {z1, ..., zi−1, z′
i, zi+1, ..., zn}. Let (xt, yt) be the output
produced by FS on dataset S in running a minimax learning algorithm. Let (xi
t, yi
t) be the corre-
sponding output produced by FS(i) on dataset S(i), where FS(i) is empirical risk on dataset S(i).
Suppose Assumption 1 holds. Assume for all z, the function (x, y) 7→f(x, y; z) is µ-SC-SC. For
any S(i) and S, we have"
Q,0.5934579439252337,"∥xi
t −xt∥+ ∥yi
t −yt∥≤4L"
Q,0.5941255006675568,"nµ + 4
r 1 µ q"
Q,0.5947930574098799,"△s
S(xt, yt)."
Q,0.595460614152203,"Proof. Deﬁne (ˆx∗
S(i), ˆy∗
S(i)) be the ESP solution on dataset S(i) and (ˆx∗
S, ˆy∗
S) be the ESP solution
on dataset S. To prove the stability bound, we consider"
Q,0.5961281708945261,"∥xi
t −xt∥+ ∥yi
t −yt∥"
Q,0.5967957276368492,"=∥xi
t −ˆx∗
S(i) + ˆx∗
S(i) −ˆx∗
S + ˆx∗
S −xt∥+ ∥yi
t −ˆy∗
S(i) + ˆy∗
S(i) −ˆy∗
S + ˆy∗
S −yt∥"
Q,0.5974632843791722,"≤∥xi
t −ˆx∗
S(i)∥+ ∥ˆx∗
S(i) −ˆx∗
S∥+ ∥ˆx∗
S −xt∥+ ∥yi
t −ˆy∗
S(i)∥+ ∥ˆy∗
S(i) −ˆy∗
S∥+ ∥ˆy∗
S −yt∥ ≤4L"
Q,0.5981308411214953,"nµ + ∥xi
t −ˆx∗
S(i)∥+ ∥ˆx∗
S −xt∥+ ∥yi
t −ˆy∗
S(i)∥+ ∥ˆy∗
S −yt∥ ≤4L"
Q,0.5987983978638184,"nµ +
√"
Q,0.5994659546061415,"2
q"
Q,0.6001335113484646,"∥xi
t −ˆx∗
S(i)∥2 + ∥yi
t −ˆy∗
S(i)∥2 +
√"
Q,0.6008010680907877,"2
q"
Q,0.6014686248331108,"∥ˆy∗
S −yt∥2 + ∥ˆx∗
S −xt∥2 ≤4L"
Q,0.6021361815754339,"nµ +
r 4 µ q"
Q,0.602803738317757,"FS(i)(xi
t, ˆy∗
S(i)) −FS(i)(ˆx∗
S(i), yi
t) +
r 4 µ q"
Q,0.6034712950600801,"FS(xt, ˆy∗
S) −FS(ˆx∗
S, yt),"
Q,0.6041388518024032,Published as a conference paper at ICLR 2022
Q,0.6048064085447263,"where the second inequality uses the result in (33), the third inequality uses the Caucy-Schwarz
inequality, and the last inequality uses the strong convexity and strong concavity of FS(i) and
FS and the optimality condition (please refer to (32)). As will see in the rest paper, we bound
FS(i)(xi
t, ˆy∗
S(i)) −FS(i)(ˆx∗
S(i), ˆy∗
S(i)) and FS(xt, ˆy∗
S) −FS(ˆx∗
S, yt) with the same upper bound
since they are all strong PD empirical risk. Thus, for brevity, we derive the following inequality"
Q,0.6054739652870494,"∥xi
t −xt∥+ ∥yi
t −yt∥ ≤4L"
Q,0.6061415220293725,"nµ + 4
r 1 µ q"
Q,0.6068090787716955,"FS(xt, ˆy∗
S) −FS(ˆx∗
S, yt) ≤4L"
Q,0.6074766355140186,"nµ + 4
r 1 µ q"
Q,0.6081441922563418,"△s
S(xt, yt)."
Q,0.6088117489986649,The proof is complete.
Q,0.609479305740988,"Remark 10. Lemma 7 provides the connection between the stability bound and the strong PD em-
pirical risk. The subscript t here represents not only the output of an iterative optimization algorithm,
but any output of the empirical risk of any minimax learning algorithm.
Remark 11. In studying the stability bound of gradient-based optimization algorithms, a popular
approach is to use the property of smoothness to establish the nonexpansiveness of gradient mapping,
proposed in the seminal work (Hardt et al., 2016). (Farnia & Ozdaglar, 2021; Lei et al., 2021) extend
this approach to the minimax problems and use it to analyze the stability bound of SGDA, GDA,
PPM, etc. However, their stability bounds are often derived in expectation. In (Lei et al., 2021),
the authors also use the Chernoff bounds of Bernoulli variables to establish high probability stability
bounds when they are to derive high probability generalization bounds. Unfortunately, these stability
bounds are often of slow order O(1/√n). To derive sharper stability bounds, we established Lemma
7."
Q,0.6101468624833111,"The following lemma shows the strong PD empirical risk of GDA.
Lemma 8. Suppose Assumption 1 holds and FS(·, ·) be µ-SC-SC with µ > 0. Let {xt, yt} be the
sequence produced by (34) with ηt =
1
µ(t+t0). Assume t0 ≥0. Suppose supx∈X ∥x∥≤RX and
supy∈Y ∥y∥≤RY . Then for (¯xT , ¯yT ) in (35) we have"
Q,0.6108144192256342,"sup
y∈Y
FS(¯xT , y) −inf
x∈X FS(x, ¯yT ) ≤µt0(R2
X + R2
Y )
T
+ L2 log(eT) µT
."
Q,0.6114819759679573,"If t0 = 0, then"
Q,0.6121495327102804,"sup
y∈Y
FS(¯xT , y) −inf
x∈X FS(x, ¯yT ) ≤L2 log(eT) µT
."
Q,0.6128170894526035,"Proof. Firstly, we have"
Q,0.6134846461949266,"∥xt+1 −x∥2 = ∥xt −ηt∇xFS(xt, yt) −x∥2"
Q,0.6141522029372497,"= ∥xt −x∥2 + η2
t ∥∇xFS(xt, yt)∥2 + 2ηt⟨x −xt, ∇xFS(xt, yt)⟩"
Q,0.6148197596795728,"≤∥xt −x∥2 + η2
t L2 + 2ηt⟨x −xt, ∇xFS(xt, yt)⟩,"
Q,0.6154873164218959,"where the ﬁrst inequality holds because of Assumption 1. By the strong convexity of FS(·, yt), we
have"
Q,0.6161548731642189,"2ηt(FS(xt, yt) −FS(x, yt)) ≤(1 −ηtµ)∥xt −x∥2 −∥xt+1 −x∥2 + η2
t L2."
Q,0.616822429906542,"Since ηt =
1
µ(t+t0), we further get"
Q,0.6174899866488651,"2
µ(t + t0)(FS(xt, yt) −FS(x, yt)) ≤

1 −
1
(t + t0)"
Q,0.6181575433911882,"
∥xt −x∥2 −∥xt+1 −x∥2 +

1
µ(t + t0)"
Q,0.6188251001335113,"2
L2."
Q,0.6194926568758344,"Multiplying both sides by t + t0, we have"
Q,0.6201602136181575,"2
µ(FS(xt, yt) −FS(x, yt)) ≤(t + t0 −1)∥xt −x∥2 −(t + t0)∥xt+1 −x∥2 +
L2"
Q,0.6208277703604806,µ2(t + t0).
Q,0.6214953271028038,Published as a conference paper at ICLR 2022
Q,0.6221628838451269,"Since x1 = 0 and PT
t=1 t−1 ≤log(eT), by taking a summation of the above inequality from t = 1
to T, we obtain T
X"
Q,0.62283044058745,"t=1
(FS(xt, yt) −FS(x, yt)) ≤µ"
Q,0.6234979973297731,"2 t0R2
X + L2 log(eT) 2µ
."
Q,0.6241655540720962,"From the concavity of FS(x, ·) we get T
X"
Q,0.6248331108144193,"t=1
(FS(xt, yt) −FS(x, ¯yT )) ≤µ"
Q,0.6255006675567423,"2 t0R2
X + L2 log(eT) 2µ
."
Q,0.6261682242990654,"Since this inequality holds for any x, we get T
X"
Q,0.6268357810413885,"t=1
(FS(xt, yt) −inf
x∈X FS(x, ¯yT )) ≤µ"
Q,0.6275033377837116,"2 t0R2
X + L2 log(eT) 2µ
."
Q,0.6281708945260347,This implies that
T,0.6288384512683578,"1
T T
X"
T,0.6295060080106809,"t=1
(FS(xt, yt) −inf
x∈X FS(x, ¯yT )) ≤µt0R2
X
2T
+ L2 log(eT) 2µT
."
T,0.630173564753004,"In a similar way, we have the following inequality"
T,0.6308411214953271,"sup
y∈Y
FS(¯xT , y) −1 T T
X"
T,0.6315086782376502,"t=1
(FS(xt, yt)) ≤µt0R2
Y
2T
+ L2 log(eT) 2µT
."
T,0.6321762349799733,Combined the above two inequalities together we get
T,0.6328437917222964,"sup
y∈Y
FS(¯xT , y) −inf
x∈X FS(x, ¯yT ) ≤µt0(R2
X + R2
Y )
T
+ L2 log(eT) µT
."
T,0.6335113484646195,"For optimization algorithm GDA, substituting the strong PD empirical risk bound of (¯xT , ¯yT ) into
Lemma 7, we get the following stability bound,"
T,0.6341789052069426,"∥¯xi
T −¯xT ∥+ ∥¯yi
T −¯yT ∥≤4L"
T,0.6348464619492656,"nµ + 4
r 1 µ q"
T,0.6355140186915887,"△s
S(¯xT , ¯yT ) ≤4L"
T,0.6361815754339119,"nµ + 4
r 1 µ s"
T,0.636849132176235,"µt0(R2
X + R2
Y )
T
+ L2 log(eT)"
T,0.6375166889185581,"µT
.
(36)"
T,0.6381842456608812,"Furthermore, for any x ∈X, y ∈Y and z ∈Z,"
T,0.6388518024032043,"f(x, y; z) −f(0, 0; z) ≤L∥x −0∥+ L∥y −0∥≤L(RY + RY ),"
T,0.6395193591455274,which implies that
T,0.6401869158878505,"f(x, y; z) ≤sup
z∈Z
f(0, 0; z) + L(RY + RY ).
(37)"
T,0.6408544726301736,"Till here, plugging (37), the stability bound in (36) and the strong PD empirical risk bound in Lemma
8 into Theorem 1, we obtain generalization bounds of GDA."
T,0.6415220293724967,We now write the main theorem of GDA.
T,0.6421895861148198,"Theorem 4. Assume for all z, the function (x, y) 7→f(x, y; z) is µ-SC-SC. Suppose supx∈X ∥x∥≤
RX and supy∈Y ∥y∥≤RY . Let {xt, yt} be produced by (34) with ηt =
1
µ(t+t0). Assume t0 ≥0.
Denote Ax(S) = ¯xT and Ay(S) = ¯yT for (¯xT , ¯yT ) in (35). Let M = supz∈Z f(0, 0; z)+L(RX +
RY ). Fixed any η > 0. There exists an absolute positive constant C."
T,0.6428571428571429,Published as a conference paper at ICLR 2022
T,0.6435246995994659,"(a) If Assumption 1 holds, then for any δ > 0, with probability at least 1 −δ, we have"
T,0.644192256341789,"F(¯xT , ¯yT ) ≤(1 + η)FS(¯xT , ¯yT )"
T,0.6448598130841121,+ C 1 + η η M
T,0.6455273698264352,"n log(1/δ) +
4L"
T,0.6461949265687583,"nµ + 4
r 1 µ s"
T,0.6468624833110814,"µt0(R2
X + R2
Y )
T
+ L2 log(eT) µT"
T,0.6475300400534045,"
log2 n log(1/δ)

."
T,0.6481975967957276,"(b) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
T,0.6488651535380507,R(¯xT ) ≤(1 + η)RS(¯xT ) + C 1 + η η
T,0.6495327102803738,"×
M log 1"
T,0.650200267022697,"δ
n
+ β + µ"
T,0.6508678237650201,"µ
L
4L"
T,0.6515353805073432,"nµ + 4
r 1 µ s"
T,0.6522029372496663,"µt0(R2
X + R2
Y )
T
+ L2 log(eT) µT"
T,0.6528704939919893,"
log2 n log 1 δ 
."
T,0.6535380507343124,"(c) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
T,0.6542056074766355,"△s (¯xT , ¯yT ) ≤(1 + η)
µt0(R2
X + R2
Y )
T
+ L2 log(eT) µT"
T,0.6548731642189586,"
+ C(1 + η)"
T,0.6555407209612817,"×
L2(1 + η)"
T,0.6562082777036048,"nµη
+M"
T,0.6568758344459279,n +β + µ µ 4L
T,0.657543391188251,"nµ+4
r 1 µ s"
T,0.6582109479305741,"µt0(R2
X + R2
Y )
T
+ L2 log(eT) µT"
T,0.6588785046728972,"
L log2 n

log
1 δ 
."
T,0.6595460614152203,"(d) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
T,0.6602136181575434,"△s (¯xT , ¯yT ) −△s
S(¯xT , ¯yT ) ≤η
µt0(R2
X + R2
Y )
T
+ L2 log(eT) µT"
T,0.6608811748998665,"
+ C(1 + η)"
T,0.6615487316421896,"×
L2(1 + η)"
T,0.6622162883845126,"nµη
+M"
T,0.6628838451268357,n +β + µ µ 4L
T,0.6635514018691588,"nµ+4
r 1 µ s"
T,0.664218958611482,"µt0(R2
X + R2
Y )
T
+ L2 log(eT) µT"
T,0.664886515353805,"
L log2 n

log
1 δ 
."
T,0.6655540720961282,"(e) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
T,0.6662216288384513,"R(¯xT ) ≤(1 + η) inf
x∈X R(x) + C 2 + η η"
T,0.6668891855807744,"µt0(R2
X + R2
Y )
T
+ L2 log(eT) µT "
T,0.6675567423230975,+C 2 + η η M
T,0.6682242990654206,n log 1
T,0.6688918558077437,"δ +
β"
T,0.6695594125500668,"µ +1

L
4L"
T,0.6702269692923899,"nµ +4
r 1 µ s"
T,0.670894526034713,"µt0(R2
X + R2
Y )
T
+ L2 log(eT) µT"
T,0.671562082777036,"
log2 n log 1 δ 
."
T,0.6722296395193591,"Remark 12. When conditions in Theorem 4 hold, we obtain that (a) If Assumption 1 holds and
FS(¯xT , ¯yT ) = O

1
n

, then for any δ > 0, with probability at least 1 −δ, the plain generalization"
T,0.6728971962616822,"error of (¯xT , ¯yT ) of GDA is of the order O

1
n +
q log T"
T,0.6735647530040053,"T

log2 n log(1/δ)

. (b) If Assumptions"
T,0.6742323097463284,"1 and 2 hold and RS(¯xT ) = O

1
n

, then for any δ > 0, with probability at least 1 −δ, the primal"
T,0.6748998664886515,"generalization error of (¯xT , ¯yT ) of GDA is of the order O

1
n +
q log T"
T,0.6755674232309746,"T

log2 n log(1/δ)

. (c)
If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, the strong PD
population risk and the strong PD generalization error of (¯xT , ¯yT ) of GDA are all of the order"
T,0.6762349799732977,"O

1
n +
q log T"
T,0.6769025367156208,"T

log2 n log(1/δ)

. (d) If Assumptions 1 and 2 hold and infx∈X R(x) = O

1
n

,"
T,0.677570093457944,"then for any δ > 0, with probability at least 1 −δ, the excess primal population risk of (¯xT , ¯yT )"
T,0.678237650200267,"of GDA is of the order O

1
n +
q log T"
T,0.6789052069425902,"T

log2 n log(1/δ)

. For the above bounds, we can take"
T,0.6795727636849133,"T = O(n2) gradient evaluations to get bound of the order O

log3/2 n"
T,0.6802403204272364,"n
log(1/δ)

."
T,0.6809078771695594,"D
STOCHASTIC GRADIENT DESCENT ASCENT"
T,0.6815754339118825,"We need some notations to state results on SGDA. Speciﬁcally, assume the initial point satisﬁes
x1 = 0 and y1 = 0. Let {ηt} be a sequence of positive step sizes. At the t-th iteration, SGDA"
T,0.6822429906542056,Published as a conference paper at ICLR 2022
T,0.6829105473965287,"ﬁrst randomly select an index it form the uniform distribution over [n] := {1, ..., n} and then do the
update"
T,0.6835781041388518,"xt+1 = xt −ηt∇xf(xt, yt, zit),
yt+1 = yt + ηt∇yf(xt, yt, zit).
(38)"
T,0.6842456608811749,We denote the average of iterates by
T,0.684913217623498,"¯xT =
PT
t=1 xt"
T,0.6855807743658211,"T
and
¯yT =
PT
t=1 yt"
T,0.6862483311081442,"T
.
(39)"
T,0.6869158878504673,"Let’s ﬁrst introduce two concentration inequalities for martingales, which are required in deriving
the strong PD empirical risk bound of SGDA."
T,0.6875834445927904,"Lemma 9. (Boucheron et al., 2013) Let z1, ..., zn be a sequence of random variables such that
zk may depend the previous variables z1, ..., zk−1 for all k = 1, ..., n. Consider a sequence of
functionals ξk(z1, ..., zk), k = 1, ..., n. Assume |ξk −Ezk[ξk]| ≤bk for each k. Let δ ∈(0, 1). With
probability at least 1 −δ n
X"
T,0.6882510013351135,"k=1
ξk − n
X"
T,0.6889185580774366,"k=1
Ezk[ξk] ≤

2 n
X"
T,0.6895861148197597,"k=1
b2
k log 1 δ  1 2 ."
T,0.6902536715620827,"Lemma 10. (Tarres & Yao, 2014) Let {ξk}k∈N be a martingale difference sequence in Rd. Suppose
that almost surely ∥ξk∥≤D and Pt
k=1 E[∥ξk∥2|ξ1, ..., ξk−1] ≤σ2
t . Then, for any 0 < δ < 1, the
following inequality holds with probability at least 1 −δ"
T,0.6909212283044058,"max
1≤j≤t  j
X"
T,0.6915887850467289,"k=1
ξk
 ≤2
D"
T,0.692256341789052,"3 + σt

log 2 δ ."
T,0.6929238985313751,The following lemma shows the strong PD empirical risk bound of SGDA.
T,0.6935914552736983,"Lemma 11. Suppose Assumption 1 holds and FS(·, ·) be µ-SC-SC with µ > 0. Let {xt, yt} be the
sequence produced by (38) with ηt =
1
µ(t+t0). Assume t0 ≥0. Suppose supx∈X ∥x∥≤RX and
supy∈Y ∥y∥≤RY . Let δ > 0. Then for (¯xT , ¯yT ) in (39), with probability at least 1 −δ we have"
T,0.6942590120160214,"sup
y∈Y
FS(¯xT , y) −inf
x∈X FS(x, ¯yT ) ≤2µt0(R2
X + R2
Y )
T
+ L2 log(eT) µT"
T,0.6949265687583445,+2(RX + RY ) T 2L
T,0.6955941255006676,"3 + 2L
√"
T,0.6962616822429907,"T

log 6"
T,0.6969292389853138,"δ + 2L(RX + RY )(2T log(6/δ))
1
2
T
."
T,0.6975967957276369,"If t0 = 0, then with probability at least 1 −δ we have"
T,0.69826435246996,"sup
y∈Y
FS(¯xT , y) −inf
x∈X FS(x, ¯yT ) ≤L2 log(eT)"
T,0.6989319092122831,"µT
+ 2(RX + RY ) T 2L"
T,0.6995994659546061,"3 + 2L
√"
T,0.7002670226969292,"T

log 6 δ"
T,0.7009345794392523,"+ 2L(RX + RY )(2T log(6/δ))
1
2
T
."
T,0.7016021361815754,"Proof. This proof follows from (Lei et al., 2021). Firstly, we have"
T,0.7022696929238985,"∥xt+1 −x∥2 = ∥xt −ηt∇xf(xt, yt; zit) −x∥2"
T,0.7029372496662216,"= ∥xt −x∥2 + η2
t ∥∇xf(xt, yt; zit)∥2 + 2ηt⟨x −xt, ∇xf(xt, yt; zit)⟩"
T,0.7036048064085447,"≤∥xt −x∥2 + η2
t L2 + 2ηt⟨x −xt, ∇xf(xt, yt; zit) −∇xFS(xt, yt)⟩+ 2ηt⟨x −xt, ∇xFS(xt, yt)⟩,"
T,0.7042723631508678,"where the ﬁrst inequality holds because of Assumption 1. By the strong convexity of FS(·, yt), we
have"
T,0.7049399198931909,"2ηt(FS(xt, yt) −FS(x, yt)) ≤(1 −ηtµ)∥xt −x∥2 −∥xt+1 −x∥2 + η2
t L2"
T,0.705607476635514,"+2ηt⟨x −xt, ∇xf(xt, yt; zit) −∇xFS(xt, yt)⟩."
T,0.7062750333778371,Published as a conference paper at ICLR 2022
T,0.7069425901201603,"Since ηt =
1
µ(t+t0), we further get"
T,0.7076101468624834,"2
µ(t + t0)(FS(xt, yt) −FS(x, yt)) ≤

1 −
1
(t + t0)"
T,0.7082777036048065,"
∥xt −x∥2 −∥xt+1 −x∥2"
T,0.7089452603471295,"+

1
µ(t + t0)"
T,0.7096128170894526,"2
L2 +
2
µ(t + t0)⟨x −xt, ∇xf(xt, yt; zit) −∇xFS(xt, yt)⟩."
T,0.7102803738317757,"Multiplying both sides by t + t0, we have"
T,0.7109479305740988,"2
µ(FS(xt, yt) −FS(x, yt)) ≤(t + t0 −1)∥xt −x∥2 −(t + t0)∥xt+1 −x∥2 +
L2"
T,0.7116154873164219,µ2(t + t0) + 2
T,0.712283044058745,"µ⟨x −xt, ∇xf(xt, yt; zit) −∇xFS(xt, yt)⟩."
T,0.7129506008010681,"Since x1 = 0 and PT
t=1 t−1 ≤log(eT), by taking a summation of the above inequality from t = 1
to T, we obtain T
X"
T,0.7136181575433912,"t=1
(FS(xt, yt) −FS(x, yt)) ≤µ"
T,0.7142857142857143,"2 t0R2
X + L2 log(eT) 2µ + T
X"
T,0.7149532710280374,"t=1
⟨x, ∇xf(xt, yt; zit) −∇xFS(xt, yt)⟩+ T
X"
T,0.7156208277703605,"t=1
⟨xt, ∇xFS(xt, yt) −∇xf(xt, yt; zit)⟩."
T,0.7162883845126836,"From the concavity of FS(x, ·) we get T
X"
T,0.7169559412550067,"t=1
(FS(xt, yt) −FS(x, ¯yT )) ≤µ"
T,0.7176234979973297,"2 t0R2
X + L2 log(eT) 2µ + T
X"
T,0.7182910547396528,"t=1
⟨x, ∇xf(xt, yt; zit) −∇xFS(xt, yt)⟩+ T
X"
T,0.7189586114819759,"t=1
⟨xt, ∇xFS(xt, yt) −∇xf(xt, yt; zit)⟩."
T,0.719626168224299,"Since this inequality holds for any x, we get T
X"
T,0.7202937249666221,"t=1
(FS(xt, yt) −inf
x∈X FS(x, ¯yT )) ≤µ"
T,0.7209612817089452,"2 t0R2
X + L2 log(eT) 2µ + T
X"
T,0.7216288384512684,"t=1
sup
x∈X
⟨x, ∇xf(xt, yt; zit) −∇xFS(xt, yt)⟩+ T
X"
T,0.7222963951935915,"t=1
⟨xt, ∇xFS(xt, yt) −∇xf(xt, yt; zit)⟩."
T,0.7229639519359146,"By Schwarz’s inequality, we have T
X"
T,0.7236315086782377,"t=1
(FS(xt, yt) −inf
x∈X FS(x, ¯yT )) ≤µ"
T,0.7242990654205608,"2 t0R2
X + L2 log(eT) 2µ + RX T
X"
T,0.7249666221628839,"t=1
∇xf(xt, yt; zit) −∇xFS(xt, yt)
 + T
X"
T,0.725634178905207,"t=1
⟨xt, ∇xFS(xt, yt) −∇xf(xt, yt; zit)⟩."
T,0.7263017356475301,"Denote ξt
=
⟨xt, ∇xFS(xt, yt) −∇xf(xt, yt; zit)⟩.
Since Eit[⟨xt, ∇xFS(xt, yt) −
∇xf(xt, yt; zit)⟩] = 0, so {ξt|t = 1, ..., T} is a martingale difference sequence. By Schwarz’s
inequality and Assumption 1, we know that |⟨xt, ∇xFS(xt, yt) −∇xf(xt, yt; zit)⟩| ≤2LRX.
Then, according to Lemma 9, we have the following inequality with probability at least 1 −δ/6 T
X"
T,0.7269692923898531,"t=1
⟨xt, ∇xFS(xt, yt) −∇xf(xt, yt; zit)⟩≤2LRX(2T log(6/δ))
1
2 ."
T,0.7276368491321762,"Deﬁne ξ′
t = ∇xf(xt, yt; zit) −∇xFS(xt, yt). Then we get ∥ξ′
t∥≤2L and T
X"
T,0.7283044058744993,"t=1
E[∥ξ′
t∥2|ξ′
1, ..., ξ′
t−1] ≤4TL2."
T,0.7289719626168224,Published as a conference paper at ICLR 2022
T,0.7296395193591455,"Applying Lemma 10 to the martingale difference sequence {ξ′
t}, we have the following inequality
with probability at least 1 −δ/3  T
X"
T,0.7303070761014686,"t=1
ξ′
t
 ≤2
2L"
T,0.7309746328437917,"3 + 2L
√"
T,0.7316421895861148,"T

log 6 δ ."
T,0.7323097463284379,"That is, with probability at least 1 −δ/3  T
X"
T,0.732977303070761,"t=1
∇xf(xt, yt; zit) −∇xFS(xt, yt)
 ≤2
2L"
T,0.7336448598130841,"3 + 2L
√"
T,0.7343124165554072,"T

log 6 δ ."
T,0.7349799732977303,"Combined with the above results, we ﬁnally have the following inequality with probability at least
1 −δ/2"
T,0.7356475300400535,"1
T T
X"
T,0.7363150867823764,"t=1
(FS(xt, yt) −inf
x∈X FS(x, ¯yT )) ≤µt0R2
X
2T
+ L2 log(eT) 2µT +2RX T 2L"
T,0.7369826435246996,"3 + 2L
√"
T,0.7376502002670227,"T

log 6"
T,0.7383177570093458,"δ + 2LRX(2T log(6/δ))
1
2
T
."
T,0.7389853137516689,"In a similar way, we have the following inequality with probability at least 1 −δ/2"
T,0.739652870493992,"sup
y∈Y
FS(¯xT , y) −1 T T
X"
T,0.7403204272363151,"t=1
(FS(xt, yt)) ≤µt0R2
Y
2T
+ L2 log(eT) 2µT +2RY T 2L"
T,0.7409879839786382,"3 + 2L
√"
T,0.7416555407209613,"T

log 6"
T,0.7423230974632844,"δ + 2LRY (2T log(6/δ))
1
2
T
."
T,0.7429906542056075,Combined the above two inequalities together we get the result with probability at least 1 −δ
T,0.7436582109479306,"sup
y∈Y
FS(¯xT , y) −inf
x∈X FS(x, ¯yT ) ≤µt0(R2
X + R2
Y )
T
+ L2 log(eT) µT"
T,0.7443257676902537,+2(RX + RY ) T 2L
T,0.7449933244325768,"3 + 2L
√"
T,0.7456608811748998,"T

log 6"
T,0.7463284379172229,"δ + 2L(RX + RY )(2T log(6/δ))
1
2
T
."
T,0.746995994659546,"Denote E = µt0(R2
X+R2
Y )
T
+ L2 log(eT )"
T,0.7476635514018691,"µT
+ 2(RX+RY )( 2L"
T,0.7483311081441922,"3 +2L
√"
T,0.7489986648865153,T ) log 6
T,0.7496662216288384,"δ
T
+ 2L(RX+RY )(2T log(6/δ))
1
2
T
.
Now, plugging Lemma 11 to Lemma 7, we know that the argument stability bound of SGDA is"
T,0.7503337783711616,"∥¯xi
T −¯xT ∥+ ∥¯yi
T −¯yT ∥≤4L"
T,0.7510013351134847,"nµ + 4
r 1 µ q"
T,0.7516688918558078,"△s
S(¯xT , ¯yT ) ≤4
r 1 µ √"
T,0.7523364485981309,E + 4L
T,0.753004005340454,"nµ.
(40)"
T,0.7536715620827771,"Furthermore, for any x ∈X, y ∈Y and z ∈Z,"
T,0.7543391188251002,"f(x, y; z) ≤f(0, 0; z) + L∥x −0∥+ L∥y −0∥≤sup
z∈Z
f(0, 0; z) + L(RX + RY ),
(41)"
T,0.7550066755674232,"Note that since SGDA is a randomized algorithm, thus we need the following variant of Theorem 1.
Theorem 5. Let A be a randomized learning algorithm and ϵ > 0. Suppose |f(x, y; z)| ≤M for
some M > 0 and x ∈X, y ∈Y, z ∈Z. Fixed any η > 0. There exists an absolute positive
constant C."
T,0.7556742323097463,"(a.) If A has ϵ-uniform stability with probability at least 1 −δ′ for some δ′ ∈(0, 1) over the
randomness of A, i.e.,"
T,0.7563417890520694,"PrA

sup
z [f(Ax(S), Ay(S); z) −f(Ax(S′), Ay(S′); z)]

≤ϵ,"
T,0.7570093457943925,"And if the randomness of A is independent of the training set S. Then for any δ > 0, with probability
at least 1 −δ′ −δ,"
T,0.7576769025367156,"F(Ax(S), Ay(S)) ≤(1 + η)FS(Ax(S), Ay(S)) + C 1 + η η M"
T,0.7583444592790387,"n log(1/δ) + ϵ log2 n log 1 δ 
."
T,0.7590120160213618,Published as a conference paper at ICLR 2022
T,0.7596795727636849,"(b.) Assume that for all x, the function y 7→F(x, y) is µ-strongly-concave. Suppose Assumptions
1 and 2 hold. If the algorithm A is ϵ-argument stable with probability at least 1 −δ′ for some
δ′ ∈(0, 1) over the randomness of A, i.e.,"
T,0.760347129506008,"PrA

∥Ax(S) −Ax(S′)∥+ ∥Ay(S) −Ay(S′)∥

≤ϵ."
T,0.7610146862483311,"And if the randomness of A is independent of the training set S. Then for any δ > 0, with probability
at least 1 −δ′ −δ,"
T,0.7616822429906542,"R(Ax(S))
≤
(1 + η)RS(Ax(S)) + C 1 + η η M"
T,0.7623497997329773,n log 1
T,0.7630173564753004,"δ +
β"
T,0.7636849132176236,"µ + 1

Lϵ log2 n log 1 δ 
."
T,0.7643524699599465,"(c.) Assume that for all x and y, the function F(x, y) is µ-SC-SC. Suppose Assumptions 1 and 2
hold. If the algorithm A is ϵ-argument stable with probability at least 1 −δ′ for some δ′ ∈(0, 1)
over the randomness of A, i.e.,"
T,0.7650200267022697,"PrA

∥Ax(S) −Ax(S′)∥+ ∥Ay(S) −Ay(S′)∥

≤ϵ."
T,0.7656875834445928,"And if the randomness of A is independent of the training set S. Then for any δ > 0, with probability
at least 1 −δ′ −δ,"
T,0.7663551401869159,"△s (Ax(S), Ay(S)) ≤△s
S(Ax(S), Ay(S)) + ηES △s
S (Ax(S), Ay(S))"
T,0.767022696929239,"+ C(1 + η)
L2(1 + η)"
T,0.7676902536715621,"nµη
+ M"
T,0.7683578104138852,"n +

1 + β µ"
T,0.7690253671562083,"
ϵL log2 n

log
1 δ 
."
T,0.7696929238985314,"(d.) Assume that for all x and y, the function F(x, y) is µ-SC-SC. Suppose Assumptions 1 and 2
hold. If the algorithm A is ϵ-argument stable with probability at least 1 −δ′ for some δ′ ∈(0, 1)
over the randomness of A, i.e.,"
T,0.7703604806408545,"PrA

∥Ax(S) −Ax(S′)∥+ ∥Ay(S) −Ay(S′)∥

≤ϵ."
T,0.7710280373831776,"And if the randomness of A is independent of the training set S. Then for any δ > 0, with probability
at least 1 −δ′ −δ,"
T,0.7716955941255007,"△s (Ax(S), Ay(S)) −△s
S(Ax(S), Ay(S)) ≤ηES △s
S (Ax(S), Ay(S))"
T,0.7723631508678238,"+ C(1 + η)
L2(1 + η)"
T,0.7730307076101469,"nµη
+ M"
T,0.7736982643524699,"n +

1 + β µ"
T,0.774365821094793,"
ϵL log2 n

log
1 δ 
."
T,0.7750333778371161,"(e.) Assume that for all x, the function y 7→F(x, y) is µ-strongly-concave. Suppose Assumptions
1 and 2 hold. If the algorithm A is ϵ-argument stable with probability at least 1 −δ′ for some
δ′ ∈(0, 1) over the randomness of A, i.e.,"
T,0.7757009345794392,"PrA

∥Ax(S) −Ax(S′)∥+ ∥Ay(S) −Ay(S′)∥

≤ϵ."
T,0.7763684913217623,"And if the randomness of A is independent of the training set S. Then for any δ > 0, with probability
at least 1 −δ′ −δ,"
T,0.7770360480640854,"R(Ax(S)) ≤(1 + η) inf
x∈X R(x)"
T,0.7777036048064085,+ C 2 + η η M
T,0.7783711615487316,n log 1
T,0.7790387182910548,"δ +
β"
T,0.7797062750333779,"µ + 1

Lϵ log2 n log 1"
T,0.780373831775701,"δ + △s
S(Ax(S), Ay(S))

."
T,0.7810413885180241,"Therefore, plugging (41), the stability bound in (40) and the strong PD empirical risk bound in
Lemma 11 into Theorem 5, we obtain generalization bounds of SGDA. Now, we write the main
theorem of SGDA as follows.
Theorem 6. Assume for all z, the function (x, y) 7→f(x, y; z) is µ-SC-SC. Suppose supx∈X ∥x∥≤
RX and supy∈Y ∥y∥≤RY . Let {xt, yt} be produced by (38) with ηt = 1/(µ(t + t0)). Assume
t0 ≥0. Denote Ax(S) = ¯xT and Ay(S) = ¯yT for (¯xT , ¯yT ) in (39). Fixed any η > 0. Let"
T,0.7817089452603472,Published as a conference paper at ICLR 2022
T,0.7823765020026703,"M = supz∈Z f(0, 0; z) + L(RX + RY ). Let E = µt0(R2
X+R2
Y )
T
+ L2 log(eT )"
T,0.7830440587449933,"µT
+ 2(RX+RY )"
T,0.7837116154873164,"T

2L 3 +"
L,0.7843791722296395,"2L
√"
L,0.7850467289719626,"T

log 6"
L,0.7857142857142857,"δ + 2L(RX+RY )(2T log(6/δ))
1
2
T
and B = 4L"
L,0.7863818424566088,"nµ+4
q 1
µ
√"
L,0.7870493991989319,"E. There exists an absolute positive
constant C."
L,0.787716955941255,"(a) If Assumption 1 holds, then for any δ > 0, with probability at least 1 −2δ, we have"
L,0.7883845126835781,"F(¯xT , ¯yT ) ≤(1 + η)FS(¯xT , ¯yT ) + C 1 + η η M"
L,0.7890520694259012,"n log(1/δ) + B log2 n log(1/δ)

."
L,0.7897196261682243,"(b) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −2δ, we have"
L,0.7903871829105474,R(¯xT ) ≤(1 + η)RS(¯xT ) + C 1 + η η M
L,0.7910547396528705,n log 1
L,0.7917222963951935,"δ +
β"
L,0.7923898531375166,"µ + 1

LB log2 n log 1 δ 
."
L,0.7930574098798397,"(c) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −2δ, we have"
L,0.7937249666221629,"△s(¯xT , ¯yT ) ≤(1 + η)E + C(1 + η)
L2(1 + η)"
L,0.794392523364486,"nµη
+ M"
L,0.7950600801068091,"n +

1 + β µ"
L,0.7957276368491322,"
BL log2 n

log
1 δ 
."
L,0.7963951935914553,"(d) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −2δ, we have"
L,0.7970627503337784,"△s (¯xT , ¯yT ) −△s
S(¯xT , ¯yT )"
L,0.7977303070761015,"≤ηE + C(1 + η)
L2(1 + η)"
L,0.7983978638184246,"nµη
+ M"
L,0.7990654205607477,"n +

1 + β µ"
L,0.7997329773030708,"
BL log2 n

log
1 δ 
."
L,0.8004005340453939,"(e) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −2δ, we have"
L,0.8010680907877169,"R(¯xT ) ≤(1 + η) inf
x∈X R(x) + C 2 + η η M"
L,0.80173564753004,n log 1
L,0.8024032042723631,"δ +
β"
L,0.8030707610146862,"µ + 1

LB log2 n log 1"
L,0.8037383177570093,"δ + E

."
L,0.8044058744993324,"Remark 13. When conditions in Theorem 6 hold, we obtain that (a) If Assumption 1 holds and
FS(¯xT , ¯yT ) = O

1
n

, then for any δ > 0, with probability at least 1 −δ, the plain gen-"
L,0.8050734312416555,"eralization error of (¯xT , ¯yT ) of SGDA is of the order O

1
n +
q"
L,0.8057409879839786,"log(1/δ) T
1
2"
L,0.8064085447263017,"
log2 n log(1/δ)

."
L,0.8070761014686249,"(b) If Assumptions 1 and 2 hold and RS(¯xT ) = O

1
n

, then for any δ > 0, with prob-"
L,0.807743658210948,"ability at least 1 −δ, the primal generalization error of (¯xT , ¯yT ) of SGDA is of the order"
L,0.8084112149532711,"O

1
n +
q"
L,0.8090787716955942,"log(1/δ) T
1
2"
L,0.8097463284379173,"
log2 n log(1/δ)

. (c) If Assumptions 1 and 2 hold, then for any δ > 0,
with probability at least 1 −δ, the strong PD population risk and strong PD generalization error of
(¯xT , ¯yT ) of SGDA are all of the order O

1
n +
q"
L,0.8104138851802403,"log(1/δ) T
1
2"
L,0.8110814419225634,"
log2 n log(1/δ)

. (d) If Assumptions 1"
L,0.8117489986648865,"and 2 hold and infx∈X R(x) = O

1
n

, then for any δ > 0, with probability at least 1−δ, the excess"
L,0.8124165554072096,"primal population risk of (¯xT , ¯yT ) of SGDA is of the order O

1
n +
q"
L,0.8130841121495327,"log(1/δ) T
1
2"
L,0.8137516688918558,"
log2 n log(1/δ)

."
L,0.8144192256341789,"For the above bounds, we can take T = O(n4) stochastic gradient evaluations to get bound of the"
L,0.815086782376502,"order O

log n"
L,0.8157543391188251,"n
log
3
2 (1/δ)

."
L,0.8164218958611482,"E
PROXIMAL POINT METHOD"
L,0.8170894526034713,"One of the classical algorithms studied for solving the minimax problem is the Proximal Point
method (Rockafellar, 1976). We denote the t-th iterate of PPM as (xt, yt). The averaged iterate is
deﬁned as"
L,0.8177570093457944,"¯xT = 1 T T
X"
L,0.8184245660881175,"t=1
xt
and
¯yT = 1 T T
X"
L,0.8190921228304406,"t=1
yt.
(42)"
L,0.8197596795727636,Published as a conference paper at ICLR 2022
L,0.8204272363150867,"Given stepsize parameter ν, the PPM generates the iterate {xt+1, yt+1} by"
L,0.8210947930574098,"arg min
x∈X
arg max
y∈Y"
L,0.821762349799733,"
FS(x, y) + 1"
L,0.822429906542056,2ν ∥x −xt∥−1
L,0.8230974632843792,"2ν ∥y −yt∥

.
(43)"
L,0.8237650200267023,"{xt+1, yt+1} is the unique solution since the objective function of problem (43) is strongly convex
in x and strongly concave in y. From the discussion in (Mokhtari et al., 2019), the update of PPM
can be written as"
L,0.8244325767690254,"xt+1 = xt −ν∇xFS(xt+1, yt+1),
yt+1 = yt + ν∇yFS(xt+1, yt+1),
(44)"
L,0.8251001335113485,Assume that the initial point satisﬁes x0 = 0 and y0 = 0.
L,0.8257676902536716,"We now begin to prove the strong PD empirical risk. Firstly, two lemmas are introduced."
L,0.8264352469959947,"Lemma 12. (Nemirovski, 2005) Deﬁne vector v = [x, y] ∈R2d and the operator P : R2d 7→R2d
as"
L,0.8271028037383178,"P(v) = [∇xFS(x, y); −∇yFS(x, y)].
(45)"
L,0.8277703604806409,"Consider (¯xT , ¯yT ) in (42). Suppose the ESP solution exists. Assume the function FS(x, y) is
continuously differentiable in x and y. Assume that FS(x, y) is a convex function of x for any y
and is a concave function of y for any x. Then for any v = [x, y] ∈R2d, we have"
L,0.828437917222964,"FS(¯xT , y) −FS(x, ¯yT ) ≤1 T T
X"
L,0.829105473965287,"t=1
P(vt)T (vt −v)."
L,0.8297730307076101,"Lemma 13. (Mokhtari et al., 2019) Consider the sequence of iterates {vt} ∈R2d generated by the
following update"
L,0.8304405874499332,"vt+1 = vt −νP(vt+1),"
L,0.8311081441922563,"where P is a monotone and Lipschitz continuous operator, and ν is a positive constant. Then for
any v ∈R2d and for each t ≥1 we have"
L,0.8317757009345794,P(vt+1)T (vt+1 −v) = 1
L,0.8324432576769025,2ν ∥vt −v∥2 −1
L,0.8331108144192256,2ν ∥vt+1 −v∥2 −1
L,0.8337783711615487,2ν ∥vt+1 −vt∥2.
L,0.8344459279038718,The following lemma is the strong PD empirical risk bound of PPM.
L,0.835113484646195,"Lemma 14. Let {xt, yt} be the iterates generated by PPM in (44). Assume ν is a positive constant.
Suppose the ESP solution exists. Assume that FS(x, y) is a convex function of x for any y and
is a concave function of y for any x. Suppose supx∈X ∥x∥≤RX and supy∈Y ∥y∥≤RY . If
Assumption 2 holds, then for all T ≥1, we have"
L,0.835781041388518,"sup
y∈Y
FS(¯xT , y) −inf
x∈X FS(x, ¯yT ) ≤R2
X + R2
Y
2νT
."
L,0.8364485981308412,Proof. The update of the PPM in (44) can be written as
L,0.8371161548731643,vt+1 = vt −νP(vt+1).
L,0.8377837116154874,"According to Lemma 1 in (Mokhtari et al., 2019), if FS(x, y) is convex-concave and Assumption 2
holds, then P(v) deﬁned in (45) is monotone and Lipschitz continuous. According to Lemma 13,
we have"
L,0.8384512683578104,P(vt+1)T (vt+1 −v) = 1
L,0.8391188251001335,2ν ∥vt −v∥2 −1
L,0.8397863818424566,2ν ∥vt+1 −v∥2 −1
L,0.8404539385847797,2ν ∥vt+1 −vt∥2.
L,0.8411214953271028,"Taking a summation of the above inequality from t = 0 to T −1, we obtain"
L,0.8417890520694259,"T −1
X"
L,0.842456608811749,"t=0
P(vt+1)T (vt+1 −v) ≤1"
L,0.8431241655540721,2ν ∥v0 −v∥2 −1
L,0.8437917222963952,"2ν ∥vT −v∥2.
(46)"
L,0.8444592790387183,Published as a conference paper at ICLR 2022
L,0.8451268357810414,"According to (46), we know that"
L,0.8457943925233645,"T −1
X"
L,0.8464619492656876,"t=0
P(vt+1)T (vt+1 −v) ≤1"
L,0.8471295060080107,2ν ∥v0 −v∥2
L,0.8477970627503337,"= ∥x0 −x∥2 + ∥y0 −y∥2 2ν
."
L,0.8484646194926568,"Combined this result with Lemma 12, we can write"
L,0.8491321762349799,"FS(¯xT , y) −FS(x, ¯yT ) ≤∥x0 −x∥2 + ∥y0 −y∥2 2νT
,"
L,0.849799732977303,which implies that
L,0.8504672897196262,"sup
y∈Y
FS(¯xT , y) −inf
x∈X FS(x, ¯yT ) ≤R2
X + R2
Y
2νT
."
L,0.8511348464619493,The proof is complete.
L,0.8518024032042724,"Combined Lemma 7 and Lemma 14, we know that the argument stability bound of PPM is"
L,0.8524699599465955,"∥¯xi
T −¯xT ∥+ ∥¯yi
T −¯yT ∥≤4L"
L,0.8531375166889186,"nµ + 4
r 1 µ q"
L,0.8538050734312417,"△s
S(¯xT , ¯yT ) ≤4L"
L,0.8544726301735648,"nµ + 4
r 1 µ r"
L,0.8551401869158879,"R2
X + R2
Y
2νT
.
(47)"
L,0.855807743658211,"Furthermore, for any x ∈X, y ∈Y and z ∈Z,"
L,0.8564753004005341,"f(x, y; z) ≤f(0, 0; z) + L∥x −0∥+ L∥y −0∥≤sup
z∈Z
f(0, 0; z) + L(RX + RY ),
(48)"
L,0.8571428571428571,"Therefore, plugging (48), the stability bound in (47) and the strong PD empirical risk bound in
Lemma 14 into Theorem 1, we obtain generalization bounds of PPM, shown as below.
Theorem 7. Assume for all z, the function (x, y) 7→f(x, y; z) is µ-SC-SC. Suppose supx∈X ∥x∥≤
RX and supy∈Y ∥y∥≤RY . Let {xt, yt} be produced by (44). Assume ν is a positive con-
stant. Denote Ax(S) = ¯xT and Ay(S) = ¯yT for (¯xT , ¯yT ) in (42). Fixed any η > 0. Let"
L,0.8578104138851802,"M = supz∈Z f(0, 0; z) + L(RX + RY ). Let E = R2
X+R2
Y
2νT
and B = 4L"
L,0.8584779706275033,"nµ + 4
q 1
µ
√"
L,0.8591455273698264,"E. There exists
an absolute positive constant C."
L,0.8598130841121495,"(a) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
L,0.8604806408544726,"F(¯xT , ¯yT ) ≤(1 + η)FS(¯xT , ¯yT ) + C 1 + η η M"
L,0.8611481975967957,"n log(1/δ) + B log2 n log(1/δ)

."
L,0.8618157543391188,"(b) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
L,0.8624833110814419,R(¯xT ) ≤(1 + η)RS(¯xT ) + C 1 + η η M
L,0.863150867823765,n log 1
L,0.8638184245660881,"δ +
β"
L,0.8644859813084113,"µ + 1

LB log2 n log 1 δ 
."
L,0.8651535380507344,"(c) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
L,0.8658210947930574,"△s(¯xT , ¯yT ) ≤(1 + η)E + C(1 + η)
L2(1 + η)"
L,0.8664886515353805,"nµη
+ M"
L,0.8671562082777036,"n +

1 + β µ"
L,0.8678237650200267,"
BL log2 n

log
1 δ 
."
L,0.8684913217623498,"(d) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
L,0.8691588785046729,"△s (¯xT , ¯yT ) −△s
S(¯xT , ¯yT )"
L,0.869826435246996,"≤ηE + C(1 + η)
L2(1 + η)"
L,0.8704939919893191,"nµη
+ M"
L,0.8711615487316422,"n +

1 + β µ"
L,0.8718291054739653,"
BL log2 n

log
1 δ 
."
L,0.8724966622162884,"(e) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
L,0.8731642189586115,"R(¯xT ) −(1 + η) inf
x∈X R(x) ≤C 2 + η η M"
L,0.8738317757009346,n log 1
L,0.8744993324432577,"δ +
β"
L,0.8751668891855807,"µ + 1

LB log2 n log 1"
L,0.8758344459279038,"δ + E

."
L,0.8765020026702269,Published as a conference paper at ICLR 2022
L,0.87716955941255,"Remark 14. When conditions in Theorem 7 hold, we obtain that (a) If Assumption 1 and 2 hold and
FS(¯xT , ¯yT ) = O

1
n

, then for any δ > 0, with probability at least 1 −δ, the plain generalization"
L,0.8778371161548731,"error of (¯xT , ¯yT ) of PPM is of the order O

1
n +
q"
T,0.8785046728971962,"1
T

log2 n log(1/δ)

. (b) If Assumptions"
T,0.8791722296395194,"1 and 2 hold and RS(¯xT ) = O

1
n

, then for any δ > 0, with probability at least 1 −δ, the"
T,0.8798397863818425,"primal generalization error of (¯xT , ¯yT ) of PPM is of the order O

1
n +
q"
T,0.8805073431241656,"1
T

log2 n log(1/δ)

.
(c) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, the strong
PD population risk and strong PD generalization error of (¯xT , ¯yT ) of PPM are all of the order"
T,0.8811748998664887,"O

1
n +
q"
T,0.8818424566088118,"1
T

log2 n log(1/δ)

. (d) If Assumptions 1 and 2 hold and infx∈X R(x) = O

1
n

,"
T,0.8825100133511349,"then for any δ > 0, with probability at least 1 −δ, the excess primal population risk of (¯xT , ¯yT ) of"
T,0.883177570093458,"PPM is of the order O

1
n+
q"
T,0.8838451268357811,"1
T

log2 n log(1/δ)

. For the above bounds, we can take T = O(n2)"
T,0.8845126835781041,"gradient evaluations to get bound of the order O

log n"
T,0.8851802403204272,"n
log(1/δ)

."
T,0.8858477970627503,"F
EXTRAGRADIENT METHOD"
T,0.8865153538050734,"EG is a classical algorithm for solving minimax problems introduced by (Korpelevich, 1976). We
now introduce some notations. Followed (Mokhtari et al., 2019), we consider the following update
of EG: given stepsize parameter ν, we ﬁrst compute a set of mid-point iterates {xt+ 1"
T,0.8871829105473965,"2 , yt+ 1 2 } xt+ 1"
T,0.8878504672897196,"2 = xt −ν∇xFS(xt, yt), yt+ 1"
T,0.8885180240320427,"2 = yt + ν∇yFS(xt, yt),
(49)"
T,0.8891855807743658,"we then compute the next iterates {xt+1, yt+1}"
T,0.8898531375166889,xt+1 = xt −ν∇xFS(xt+ 1
T,0.890520694259012,"2 , yt+ 1 2 ),"
T,0.8911882510013351,yt+1 = yt + ν∇yFS(xt+ 1
T,0.8918558077436582,"2 , yt+ 1"
T,0.8925233644859814,"2 ).
(50)"
T,0.8931909212283045,Consider the averaged iterate
T,0.8938584779706275,"¯xT = 1 T T
X"
T,0.8945260347129506,"t=1
xt
and
¯yT = 1 T T
X"
T,0.8951935914552737,"t=1
yt.
(51)"
T,0.8958611481975968,Assume that the initial point satisﬁes x0 = x−1/2 and y0 = y−1/2.
T,0.8965287049399199,"We now show the strong PD empirical risk bound for (¯xT , ¯yT ) of EG."
T,0.897196261682243,"Lemma 15. (Mokhtari et al., 2019) Let {xt, yt}, {xt+1/2, yt+1/2} be the iterates generated by the
EG updates in (49) and (50). Assume that the initial point satisﬁes x0 = x−1/2 and y0 = y−1/2.
Suppose the ESP solution (ˆx∗, ˆy∗) exists. Assume that FS(x, y) is a convex function of x for any
y and is a concave function of y for any x. If Assumption 2 holds and the stepsize ν satisﬁes the
condition ν =
c
2β for any c ∈(0, 1), then:"
T,0.8978638184245661,"(a) the iterates {xt, yt}, {xt+1/2, yt+1/2} stay within the compact convex set"
T,0.8985313751668892,"D :=

(x, y)|∥x −ˆx∗∥2 + ∥y −ˆy∗∥2 ≤

2 +
2
1 −4ν2β2"
T,0.8991989319092123,"
(∥x0 −ˆx∗∥2 + ∥y0 −ˆy∗∥2)

. (52)"
T,0.8998664886515354,"(b) for all T ≥1, we have"
T,0.9005340453938585,"sup
y:(¯xT ,y)∈D
FS(¯xT , y) −
inf
x:(x,¯yT )∈D FS(x, ¯yT ) ≤
2β(16 +
33
2(1−c2))(∥x0 −ˆx∗∥2 + ∥y0 −ˆy∗∥2) T
."
T,0.9012016021361816,Published as a conference paper at ICLR 2022
T,0.9018691588785047,"Combined Lemma 7 and Lemma 15, we know that the argument stability bound of EG is"
T,0.9025367156208278,"∥¯xi
T −¯xT ∥+ ∥¯yi
T −¯yT ∥≤4L"
T,0.9032042723631508,"nµ + 4
r 1 µ q"
T,0.9038718291054739,"△s
S(¯xT , ¯yT ) ≤4L"
T,0.904539385847797,"nµ + 4
r 1 µ s"
T,0.9052069425901201,"2β(16 +
33
2(1−c2))(∥x0 −ˆx∗∥2 + ∥y0 −ˆy∗∥2) T
. (53)"
T,0.9058744993324432,"Furthermore, for any x ∈X, y ∈Y and z ∈Z,"
T,0.9065420560747663,"f(x, y; z) ≤f(ˆx∗, ˆy∗; z) + L∥x −ˆx∗∥+ L∥y −ˆy∗∥"
T,0.9072096128170895,"≤sup
z∈Z
f(ˆx∗, ˆy∗; z) +
√"
"L
P",0.9078771695594126,"2L
p"
"L
P",0.9085447263017357,∥x −ˆx∗∥2 + ∥y −ˆy∗∥2
"L
P",0.9092122830440588,"≤sup
z∈Z
f(ˆx∗, ˆy∗; z) + L
r
4 +
4
1 −4ν2β2"
"L
P",0.9098798397863819,"
(∥x0 −ˆx∗∥2 + ∥y0 −ˆy∗∥2),
(54)"
"L
P",0.910547396528705,"where the ﬁrst inequality follows from Assumption 1, the second inequality follows from Caucy-
Schwarz inequality and the last inequality follows from (52). Now, plugging (54), the stability
bound in (53) and the strong PD empirical risk bound in Lemma 15 into Theorem 1, we obtain
generalization bounds of EG. The main theorem is shown below.
Theorem 8. Assume for all z, the function (x, y) 7→f(x, y; z) is µ-SC-SC. Let {xt, yt} and
{xt+1/2, yt+1/2} be the iterates produced by (49)-(50). Assume the stepsize ν satisﬁes the con-
dition ν =
c
2β for any c ∈(0, 1). Denote Ax(S) = ¯xT and Ay(S) = ¯yT for (¯xT , ¯yT ) in
(51). Denote the ESP solution as (ˆx∗, ˆy∗). Consider the compact convex set in (52). Fixed any"
"L
P",0.9112149532710281,"η > 0. Let M = supz∈Z f(ˆx∗, ˆy∗; z) + L
r
4 +
4
1−4ν2β2

(∥x0 −ˆx∗∥2 + ∥y0 −ˆy∗∥2). Let"
"L
P",0.9118825100133512,"B =
2β(16+
33
2(1−c2) )(∥x0−ˆx∗∥2+∥y0−ˆy∗∥2)"
"L
P",0.9125500667556742,"T
and E = 4L"
"L
P",0.9132176234979973,"nµ + 4
q 1
µ
√"
"L
P",0.9138851802403204,"B. There exists an absolute posi-
tive constant C."
"L
P",0.9145527369826435,"(a) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
"L
P",0.9152202937249666,"F(¯xT , ¯yT ) ≤(1 + η)FS(¯xT , ¯yT ) + C 1 + η η M"
"L
P",0.9158878504672897,"n log(1/δ) + B log2 n log(1/δ)

."
"L
P",0.9165554072096128,"(b) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
"L
P",0.9172229639519359,R(¯xT ) ≤(1 + η)RS(¯xT ) + C 1 + η η M
"L
P",0.917890520694259,n log 1
"L
P",0.9185580774365821,"δ +
β"
"L
P",0.9192256341789052,"µ + 1

LB log2 n log 1 δ 
."
"L
P",0.9198931909212283,"(c) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
"L
P",0.9205607476635514,"△s(¯xT , ¯yT ) ≤(1 + η)E + C(1 + η)
L2(1 + η)"
"L
P",0.9212283044058746,"nµη
+ M"
"L
P",0.9218958611481975,"n +

1 + β µ"
"L
P",0.9225634178905207,"
BL log2 n

log
1 δ 
."
"L
P",0.9232309746328438,"(d) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
"L
P",0.9238985313751669,"△s (¯xT , ¯yT ) −△s
S(¯xT , ¯yT )"
"L
P",0.92456608811749,"≤ηE + C(1 + η)
L2(1 + η)"
"L
P",0.9252336448598131,"nµη
+ M"
"L
P",0.9259012016021362,"n +

1 + β µ"
"L
P",0.9265687583444593,"
BL log2 n

log
1 δ 
."
"L
P",0.9272363150867824,"(e) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
"L
P",0.9279038718291055,"R(¯xT ) ≤(1 + η) inf
x∈X R(x) + C 2 + η η M"
"L
P",0.9285714285714286,n log 1
"L
P",0.9292389853137517,"δ +
β"
"L
P",0.9299065420560748,"µ + 1

LB log2 n log 1"
"L
P",0.9305740987983978,"δ + E

."
"L
P",0.9312416555407209,"Remark 15. When conditions in Theorem 8 hold, we obtain that (a) If Assumptions 1 and 2 hold and
FS(¯xT , ¯yT ) = O

1
n

, then for any δ > 0, with probability at least 1 −δ, the plain generalization"
"L
P",0.931909212283044,Published as a conference paper at ICLR 2022
"L
P",0.9325767690253671,"error of (¯xT , ¯yT ) of EG is of the order O

1
n +
q"
T,0.9332443257676902,"1
T

log2 n log(1/δ)

. (b) If Assumptions 1"
T,0.9339118825100133,"and 2 hold and RS(¯xT ) = O

1
n

, then for any δ > 0, with probability at least 1 −δ, the primal"
T,0.9345794392523364,"generalization error of (¯xT , ¯yT ) of EG is of the order O

1
n +
q"
T,0.9352469959946595,"1
T

log2 n log(1/δ)

. (c) If
Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, the strong PD
population risk and the strong PD generalization error of (¯xT , ¯yT ) of EG are all of the order O

1
n+
q"
T,0.9359145527369827,"1
T

log2 n log(1/δ)

. (d) If Assumptions 1 and 2 hold and infx∈X R(x) = O

1
n

, then for"
T,0.9365821094793058,"any δ > 0, with probability at least 1 −δ, the excess primal population risk of (¯xT , ¯yT ) of EG"
T,0.9372496662216289,"is O

1
n +
q"
T,0.937917222963952,"1
T

log2 n log(1/δ)

. For the above bounds, we can take T = O(n2) gradient"
T,0.9385847797062751,"evaluations to get bound of the order O

log n"
T,0.9392523364485982,"n
log(1/δ)

."
T,0.9399198931909212,"G
OPTIMISTIC GRADIENT DESCENT ASCENT"
T,0.9405874499332443,"OGDA is introduced by Popov (1980), as a variant of the EG method. We introduce some notations
to state the result of OGDA. Given a stepsize parameter ν > 0, OGDA do the following update for
each t ≥0"
T,0.9412550066755674,"xt+1 = xt −2ν∇xFS(xt, yt) + ν∇xFS(xt−1, yt−1),
yt+1 = yt + 2ν∇yFS(xt, yt) −ν∇yFS(xt−1, yt−1).
(55)"
T,0.9419225634178905,Assume that the initial point satisﬁes x0 = x−1 and y0 = y−1. Consider the averaged iterate
T,0.9425901201602136,"¯xT = 1 T T
X"
T,0.9432576769025367,"t=1
xt
and
¯yT = 1 T T
X"
T,0.9439252336448598,"t=1
yt.
(56)"
T,0.9445927903871829,"We ﬁrst provide a lemma on the strong PD empirical risk of OGDA.
Lemma 16. (Mokhtari et al., 2019) Let {xt, yt} be the iterates generated by the OGDA updates in
(55). Assume that the initial point satisﬁes x0 = x−1 and y0 = y−1. Suppose the ESP solution
(ˆx∗, ˆy∗) exists. Assume that FS(x, y) is a convex function of x for any y and is a concave function
of y for any x. If Assumption 2 holds and the stepsize ν satisﬁes 0 < ν ≤
1
4β , then:"
T,0.945260347129506,"(a) the iterates {xt, yt} stay within the compact convex set"
T,0.9459279038718291,"D :=

(x, y)|∥x −ˆx∗∥2 + ∥y −ˆy∗∥2 ≤2(∥x0 −ˆx∗∥2 + ∥y0 −ˆy∗∥2)
	
.
(57)"
T,0.9465954606141522,"(b) for all T ≥1, we have"
T,0.9472630173564753,"sup
y:(¯xT ,y)∈D
FS(¯xT , y) −
inf
x:(x,¯yT )∈D FS(x, ¯yT ) ≤(16β +
1
2ν )(∥x0 −ˆx∗∥2 + ∥y0 −ˆy∗∥2) T
."
T,0.9479305740987984,"Combined Lemma 7 and Lemma 16, we know that the argument stability bound of OGDA is"
T,0.9485981308411215,"∥¯xi
T −¯xT ∥+ ∥¯yi
T −¯yT ∥≤4L"
T,0.9492656875834445,"nµ + 4
r 1 µ q"
T,0.9499332443257676,"△s
S(¯xT , ¯yT ) ≤4L"
T,0.9506008010680908,"nµ + 4
r 1 µ s"
T,0.9512683578104139,"(16β +
1
2ν )(∥x0 −ˆx∗∥2 + ∥y0 −ˆy∗∥2)"
T,0.951935914552737,"T
.
(58)"
T,0.9526034712950601,"Moreover, similar to (54), we have"
T,0.9532710280373832,"f(x, y; z) ≤f(ˆx∗, ˆy∗; z) + L∥x −ˆx∗∥+ L∥y −ˆy∗∥"
T,0.9539385847797063,"≤sup
z∈Z
f(ˆx∗, ˆy∗; z) + 2L
p"
T,0.9546061415220294,"∥x0 −ˆx∗∥2 + ∥y0 −ˆy∗∥2.
(59)"
T,0.9552736982643525,"Therefore, plugging (59), the stability bound in (58) and the strong PD empirical risk bound in
Lemma 16 into Theorem 1, we obtain generalization bounds of OGDA."
T,0.9559412550066756,Published as a conference paper at ICLR 2022
T,0.9566088117489987,"Theorem 9. Assume for all z, the function (x, y) 7→f(x, y; z) is µ-SC-SC. Let {xt, yt} be pro-
duced by (55). Assume the stepsize parameter ν satisﬁes 0 < ν ≤
1
4β . Denote Ax(S) = ¯xT and
Ay(S) = ¯yT for (¯xT , ¯yT ) in (56). Denote the ESP solution as (ˆx∗, ˆy∗). Consider the compact con-
vex set in (57). Fixed any η > 0. Let M = supz∈Z f(ˆx∗, ˆy∗; z) + 2L
p"
T,0.9572763684913218,∥x0 −ˆx∗∥2 + ∥y0 −ˆy∗∥2.
T,0.9579439252336449,"Deﬁne B =
(16β+ 1"
T,0.9586114819759679,2ν )(∥x0−ˆx∗∥2+∥y0−ˆy∗∥2)
T,0.959279038718291,"T
and E =
4L
nµ + 4
q 1
µ
√"
T,0.9599465954606141,"B. There exists an absolute
positive constant C."
T,0.9606141522029372,"(a) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
T,0.9612817089452603,"F(¯xT , ¯yT ) ≤(1 + η)FS(¯xT , ¯yT ) + C 1 + η η M"
T,0.9619492656875834,"n log(1/δ) + B log2 n log(1/δ)

."
T,0.9626168224299065,"(b) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
T,0.9632843791722296,R(¯xT ) ≤(1 + η)RS(¯xT ) + C 1 + η η M
T,0.9639519359145527,n log 1
T,0.9646194926568759,"δ +
β"
T,0.965287049399199,"µ + 1

LB log2 n log 1 δ 
."
T,0.9659546061415221,"(c) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
T,0.9666221628838452,"△s(¯xT , ¯yT ) ≤(1 + η)E + C(1 + η)
L2(1 + η)"
T,0.9672897196261683,"nµη
+ M"
T,0.9679572763684913,"n +

1 + β µ"
T,0.9686248331108144,"
BL log2 n

log
1 δ 
."
T,0.9692923898531375,"(d) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
T,0.9699599465954606,"△s (¯xT , ¯yT ) −△s
S(¯xT , ¯yT )"
T,0.9706275033377837,"≤ηE + C(1 + η)
L2(1 + η)"
T,0.9712950600801068,"nµη
+ M"
T,0.9719626168224299,"n +

1 + β µ"
T,0.972630173564753,"
BL log2 n

log
1 δ 
."
T,0.9732977303070761,"(e) If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, we have"
T,0.9739652870493992,"R(¯xT ) ≤(1 + η) inf
x∈X R(x) + C 2 + η η M"
T,0.9746328437917223,n log 1
T,0.9753004005340454,"δ +
β"
T,0.9759679572763685,"µ + 1

LB log2 n log 1"
T,0.9766355140186916,"δ + E

."
T,0.9773030707610146,"Remark 16. When conditions in Theorem 9 hold, we obtain that (a) If Assumptions 1 and 2 hold and
FS(¯xT , ¯yT ) = O

1
n

, then for any δ > 0, with probability at least 1 −δ, the plain generalization"
T,0.9779706275033377,"error of (¯xT , ¯yT ) of OGDA is of the order O

1
n +
q"
T,0.9786381842456608,"1
T

log2 n log(1/δ)

. (b) If Assumptions 1"
T,0.979305740987984,"and 2 hold and RS(¯xT ) = O

1
n

, then for any δ > 0, with probability at least 1 −δ, the primal"
T,0.9799732977303071,"generalization error of (¯xT , ¯yT ) of OGDA is of the order O

1
n +
q"
T,0.9806408544726302,"1
T

log2 n log(1/δ)

. (c)
If Assumptions 1 and 2 hold, then for any δ > 0, with probability at least 1 −δ, the strong PD
population risk and the strong PD generalization error of (¯xT , ¯yT ) of OGDA are all of the order"
T,0.9813084112149533,"O

1
n +
q"
T,0.9819759679572764,"1
T

log2 n log(1/δ)

. (d) If Assumptions 1 and 2 hold and infx∈X R(x) = O

1
n

,
then for any δ > 0, with probability at least 1 −δ, the excess primal population risk of OGDA is of"
T,0.9826435246995995,"the order O

1
n +
q"
T,0.9833110814419226,"1
T

log2 n log(1/δ)

. For the above bounds, we can take T = O(n2) gradient"
T,0.9839786381842457,"evaluations to get bound of the order O

log n"
T,0.9846461949265688,"n
log(1/δ)

."
T,0.9853137516688919,"H
AUXILIARY DESCRIPTIONS OF TABLE 1"
T,0.985981308411215,"In Table 1, Lip means Lipschitz continuity and S means smoothness.
(R)-ESP means the
(regularized)-empirical risk saddle point (Zhang et al., 2021a). C-SC means convex-µ-strongly-
concave, and NC-SC means nonconvex-µ-strongly-concave.
A function f(x, y) is called
nonconvex-strongly-concave if f(x, ·) is strongly-concave for every x. Moreover, a function f(x, y)
is µ-weakly-convex-weakly-concave (WC-WC) if f + µ"
T,0.986648865153538,"2
 
∥x∥2 + ∥y∥2
is convex-concave. V-WC-
WC is a variant of WC-WC, please refer to (Lei et al., 2021). PL means the two-sided PL condition,
which relaxes the convex-concavity requirement of the objective function (Yang et al., 2020) and is
usually used to guarantee the linear convergence rate (Karimi et al., 2016; Yang et al., 2020). AGDA
algorithm is variant of GDA with alternating updates of the primal-dual variables. c is a parameter
in the step size, β is a parameter in Assumption 2 and k := β/µ."
T,0.9873164218958611,Published as a conference paper at ICLR 2022
T,0.9879839786381842,"I
NUMERICAL EXPERIMENTS"
T,0.9886515353805073,"In this section, we report preliminary experimental results to verify our theoretical results by per-
forming numerical experiments on the simulated data. We study how the generalization error would
behave along the number of samples. To this aim, we consider an isotropic Gaussian data vector
Z ∼N(0, Id×d) with zero mean and identity covariance. We will draw n independent samples
from the underlying Gaussian distribution to form a training dataset S = {z1, ..., zn}. We set the
dimension d of Z as 50. Similar to the strongly-convex-strong-concave case of (Farnia & Ozdaglar,
2021), we consider the following minimax objective function"
T,0.9893190921228304,"f(x, y; z) = xT (z −y) + µ"
T,0.9899866488651535,2 (∥x∥2 −∥y∥2).
T,0.9906542056074766,"In the experiments, we set µ = 1 and constrain optimization variables x and y to satisfy ∥x∥, ∥y∥≤
100 which we enforced by projection. For this minimax objective function, one can verify that"
T,0.9913217623497997,"F(x, y) −FS(x, y) = xT (E[Z] −ES[Z]);
R(x) −RS(x) = xT (E[Z] −ES[Z]),"
T,0.9919893190921228,"where E[Z] = 0 since the mean of the underlying Gaussian distribution is 0, and where ES[Z] =
1
n
Pn
i=1 zi. For brevity, we call |xT (E[Z] −ES[Z])| the “generalization error”."
T,0.992656875834446,"We apply the above experimental settings to validate the theoretical results of GDA, SGDA, EG,
and OGDA. We evaluate the generalization error |xT (E[Z] −ES[Z])| and apply these algorithms
to S. For GDA and SGDA, we consider the stepsize parameter as 1/t. We iterate GDA with n2
times and SGDA with n4 times. The generalization error of GDA and SGDA with different sizes of
training data are reported in Figure 1. And for EG and OGDA, we select the stepsize parameter as
0.003. We run EG and OGDA n2 times. Similarly, the generalization error of EG and OGDA with
different sizes of training data are given in Figure 2. From the two ﬁgures, we can see that the line of
best ﬁt for the generalization error is log3/2 n"
T,0.9933244325767691,"n0.98
for GDA, log n"
T,0.9939919893190922,"n0.98 for SGDA, log0.99 n"
T,0.9946595460614153,"n0.98
for EG, and log n"
T,0.9953271028037384,"n1.02
for OGDA. These results match the predictive rates of the plain generalization error and the primal
generalization error in Table 1, i.e., log3/2 n"
T,0.9959946595460614,"n
for GDA, log n"
T,0.9966622162883845,"n
for SGDA, log n"
T,0.9973297730307076,"n
for EG, and log n"
T,0.9979973297730307,"n
for
OGDA, which veriﬁes our theoretical ﬁndings."
T,0.9986648865153538,Figure 1: |xT (E[Z] −ES[Z])| versus the number of samples on GDA (left) and SGDA (right).
T,0.9993324432576769,Figure 2: |xT (E[Z] −ES[Z])| versus the number of samples on EG (left) and OGDA (right).
