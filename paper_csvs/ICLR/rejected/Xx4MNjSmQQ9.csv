Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0017152658662092624,"A key challenge facing deep learning is that neural networks are often not robust
to shifts in the underlying data distribution. We study this problem from the
perspective of the statistical concept of parameter identiÔ¨Åcation. Generalization
bounds from learning theory often assume that the test distribution is close to the
training distribution. In contrast, if we can identify the ‚Äútrue‚Äù parameters, then
the model generalizes to arbitrary distribution shifts. However, neural networks
are typically over-parameterized, making parameter identiÔ¨Åcation impossible. We
show that for quadratic neural networks, we can identify the function represented
by the model even though we cannot identify its parameters. Thus, we can obtain
robust generalization bounds even in the over-parameterized setting. We leverage
this result to obtain new bounds for contextual bandits and transfer learning with
quadratic neural networks. Overall, our results suggest that we can improve
robustness of neural networks by designing models that can represent the true
data generating process. In practice, the true data generating process is often very
complex; thus, we study how our framework might connect to neural module
networks, which are designed to break down complex tasks into compositions
of simpler ones. We prove robust generalization bounds when individual neural
modules are identiÔ¨Åable."
INTRODUCTION,0.003430531732418525,"1
INTRODUCTION"
INTRODUCTION,0.005145797598627788,"Recent work has demonstrated that neural networks are not robust to shifts in the underlying data,
including both distribution shifts (i.e., where the data comes from a new distribution independent of the
neural network parameters) (Hendrycks & Dietterich, 2019; Taori et al., 2020) as well as adversarial
shifts (i.e., where the shift can depend on the neural network parameters) (Szegedy et al., 2013).
Accordingly, there has been a great deal of interest in better understanding why neural networks fail
to be robust (Tsipras et al., 2018; Ilyas et al., 2019) and on improving robustness (Goodfellow et al.,
2014; Raghunathan et al., 2018; Cohen et al., 2019)."
INTRODUCTION,0.00686106346483705,"From the perspective of learning theory, there is little reason to expect neural networks to be robust,
since generalization bounds typically assume that the test examples are from the same distribution as
the training examples. PAC-Bayesian generalization bounds allow for a limited amount of robustness,
but only if the support of the target distribution q is contained in that of the source distribution p,
since it requires that the KL divergence DKL(q ‚à•p) is Ô¨Ånite. Yet, distribution shifts (Hendrycks &
Dietterich, 2019) often shift probability mass to inputs completely outside the source distribution."
INTRODUCTION,0.008576329331046312,"Instead, the reason we might expect neural networks to be robust to these shifts is that humans are
robust to them; for instance, small pixel-level shifts considered in adversarial examples are typically
unnoticeable to humans, yet these shifts can move the image completely off of the distribution of
natural images. This fact indicates a gap in our theoretical understanding of neural networks. In
particular, the key question is understanding settings under which we may expect neural networks to
be robust to distribution shifts that are ‚Äúlarge‚Äù (e.g., in terms of KL divergence)."
INTRODUCTION,0.010291595197255575,"We study a strategy for closing this gap based on the statistical concept of identiÔ¨Åability (Hsu et al.,
2012). At a high level, this concept assumes that the true model belongs to the model family; then, in
the limit of inÔ¨Ånite training data, the learning algorithm can exactly recover the parameters of the true
model. For instance, in linear regression, the data is generated according to the model y = ‚ü®Œ∏‚àó, x‚ü©+Œæ,
where Œæ is œÉ-subgaussian noise. Then, under mild assumptions on the training data Z = (X, Y ), the"
INTRODUCTION,0.012006861063464836,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.0137221269296741,"ordinary least squares (OLS) estimator ÀÜŒ∏(Z) recovers the true parameter‚Äîi.e., in the limit of inÔ¨Ånite
data, ÀÜŒ∏(Z) = Œ∏‚àó. With Ô¨Ånite samples, OLS satisÔ¨Åes high-probability convergence rates of the form"
INTRODUCTION,0.015437392795883362,"‚à•ÀÜŒ∏(Z) ‚àíŒ∏‚àó‚à•2 ‚â§œµ.
(1)"
INTRODUCTION,0.017152658662092625,"The connection to robustness is that if (1) holds, then for any input x such that ‚à•x‚à•2 ‚â§xmax, we have"
INTRODUCTION,0.018867924528301886,"|‚ü®ÀÜŒ∏(Z), x‚ü©‚àí‚ü®Œ∏‚àó, x‚ü©| ‚â§‚à•ÀÜŒ∏(Z) ‚àíŒ∏‚àó‚à•2 ¬∑ ‚à•x‚à•2 ‚â§œµ ¬∑ xmax.
(2)"
INTRODUCTION,0.02058319039451115,"Thus, for any distribution q(x) with support on B2(0, xmax) = {x ‚ààX | ‚à•x‚à•2 ‚â§xmax}, ÀÜŒ∏(Z) obtains
bounded error‚Äîi.e., we have Eq(x)[(‚ü®ÀÜŒ∏(Z), x‚ü©‚àí‚ü®Œ∏‚àó, x‚ü©)2] ‚â§œµ2x2
max with high probability."
INTRODUCTION,0.022298456260720412,"Thus, a natural question is whether we can obtain similar kinds of parameter identiÔ¨Åcation bounds for
neural networks. A key complication is that practical neural networks are often over-parameterized,
possibly to facilitate optimization (Du & Lee, 2018; Jacot et al., 2018). In this setting, identiÔ¨Åcation
is impossible, since multiple parameters can yield the same model. Nevertheless, it may be possible
to obtain bounds of the form (2)‚Äîin particular, even if we do not recover the true parameters Œ∏‚àó, we
can still recover the function fŒ∏‚àó(x). We refer to this notion as function identiÔ¨Åcation. Furthermore,
we show that quadratic neural networks satisfy function identiÔ¨Åcation bounds under mild conditions."
INTRODUCTION,0.024013722126929673,"To demonstrate its utility, we show how function identiÔ¨Åcation can be leveraged to obtain regret
guarantees for a bandit (Rusmevichientong & Tsitsiklis, 2010) where each arm is a quadratic neural
network. Linear bandits fundamentally involve covariate shift since their ‚Äúcovariates‚Äù are arms, which
are adaptively chosen through the learning process as a function of past observations; thus, existing
approaches have all operated in the setting where there is a unique and identiÔ¨Åable global minimizer.
Similarly, we build on recent work proving bounds on transfer learning in the setting of bounded
label shift and unbounded covariate shift (Bastani, 2020; Xu et al., 2021); again, we show that we can
leverage function identiÔ¨Åcation to easily transfer learn quadratic neural networks."
INTRODUCTION,0.025728987993138937,"Our results suggest that one strategy for improving robustness of neural networks is to design models
that can represent the true data generating process. However, doing so can be challenging due to the
complexity of most real-world data generating processes mapping covariates to labels‚Äîe.g., mapping
natural language to semantic meaning or images to object detections and labels. As a consequence,
we study how our results can connect to neural module networks (Andreas et al., 2016), which are
designed to break down complex tasks into smaller ones that can each be solved by a neural network.
For instance, we may break down the task ‚Äúcount the number of red balls in image x‚Äù into (i) detecting
balls, (ii) detecting red objects, and (iii) intersecting the two sets, and (iv) summing the results."
INTRODUCTION,0.0274442538593482,"Intuitively, neural modules can generalize more robustly since (i) it is more likely that an individual
neural module designed to solve a simple task can be identiÔ¨Åed from training data, and (ii) even if
module composition is not itself identiÔ¨Åable, shifts in the compositional structure tend to be smaller
than shifts in the underlying data distribution. We study a simpliÔ¨Åed form of neural module networks,
where modules are quadratic neural networks composed in sequence according to a given input; for
simplicity, we assume they can be trained in a supervised way, ensuring robust generalization. Then,
we show that under certain conditions, compositions of these models are also robust, including the
case where there are shifts in the distribution over compositions."
INTRODUCTION,0.029159519725557463,"Related work. Prior work has connected misspeciÔ¨Åcation (i.e., the true model is in the model family)
and robustness to covariate shift (Shimodaira, 2000; Wen et al., 2014); however, having a correctly
speciÔ¨Åed model is insufÔ¨Åcient if the true parameters are not identiÔ¨Åable‚Äîe.g., in linear regression, if
the covariance matrix Œ£ = Ep(x)[xx‚ä§] is singular, then Œ∏ is not identiÔ¨Åable; thus, the estimated model
may not be robust. Quadratic neural networks cannot be identiÔ¨Åed even if the model is correctly
speciÔ¨Åed since the parameters have a continuous symmetry (i.e., orthogonal transformations)."
INTRODUCTION,0.030874785591766724,"Recent work has studied learning under adversarial examples (Goodfellow et al., 2014; Raghunathan
et al., 2018; Cohen et al., 2019) and corrupted training data (Steinhardt et al., 2017; Diakonikolas
et al., 2019). In contrast, we are interested in robustness to covariate shift; there has been recent work
empirically showing that neural networks are sensitive to distribution shift (Hendrycks & Dietterich,
2019; Taori et al., 2020; Ruis et al., 2020; Ribeiro et al., 2020; Koh et al., 2020). Distributionally
robust optimization enables training of models robust to small shifts (Duchi & Namkoong, 2018), but
we are interested in potentially large shifts. Unsupervised domain adaptation (Ben-David et al., 2007;
Blitzer et al., 2008) learns a model on a covariate shifted target distribution; however, they rely on
unlabeled examples from the target domain, whereas we do not. There has been recent theory on"
INTRODUCTION,0.032590051457975985,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.03430531732418525,"robustness to adversarial perturbations‚Äîe.g., showing there may be a tradeoff between robustness
and on-distribution generalization (Tsipras et al., 2018), and that non-robust algorithms tend to learn
predictive but brittle representations compared to adversarially robust ones (Ilyas et al., 2019). In
contrast, we show that these tradeoffs are mitigated when the true model function can be identiÔ¨Åed
despite over-parameterization. Furthermore, adversarial shifts are typically bounded (e.g., small ‚Ñì‚àû
norm), whereas the shifts we consider may be large."
INTRODUCTION,0.036020583190394515,"There has been a great deal of recent work on deep learning theory, including on quadratic neural
networks; however, it has largely focused on optimization (Ge et al., 2017b; Jacot et al., 2018;
Du et al., 2019; Gao et al., 2019; Soltanolkotabi et al., 2018; Li et al., 2018), and on-distribution
generalization (Neyshabur et al., 2017; Du & Lee, 2018; Jacot et al., 2018; Arora et al., 2018; Long
& Sedghi, 2019). In contrast, we are interested in out-of-distribution generalization."
INTRODUCTION,0.03773584905660377,"We discuss additional related work on matrix factorization and multi-armed bandits in Appendix A,
as well as a discussion of the novelty of our results."
PROBLEM FORMULATION,0.03945111492281304,"2
PROBLEM FORMULATION"
PROBLEM FORMULATION,0.0411663807890223,"We consider a model fŒ∏ : X ‚ÜíY, with covariates X ‚äÜRd, labels Y ‚äÜR, and parameters
Œ∏ ‚ààŒò ‚äÜRm. A generalization bound from learning theory typically has the form"
PROBLEM FORMULATION,0.04288164665523156,"Pp(Z)[Lp(ÀÜŒ∏(Z)) ‚â§œµ] ‚â•1 ‚àíŒ¥
where
Lp(Œ∏) = Ep(x)[(fŒ∏(x) ‚àífŒ∏‚àó(x))2],
(3)"
PROBLEM FORMULATION,0.044596912521440824,"where œµ, Œ¥ ‚ààR>0, Z = {(x1, y1), ..., (xn, yn)} ‚äÜX √ó Y with yi = fŒ∏‚àó(xi) + Œæi is a training set of
i.i.d. observations from a distribution p (i.e., p(Z) = p(x1, y1) ¬∑ ... ¬∑ p(xn, yn)), Œæi is bounded random
noise independent of xi with |Œæi| ‚â§Œæmax, Œ∏‚àó‚ààŒò are the true parameters, and"
PROBLEM FORMULATION,0.04631217838765009,"ÀÜŒ∏(Z) = arg min
Œ∏‚ààŒò
ÀÜL(Œ∏; Z)
where
ÀÜL(Œ∏; Z) = 1 n n
X"
PROBLEM FORMULATION,0.048027444253859346,"i=1
(fŒ∏(xi) ‚àíyi)2"
PROBLEM FORMULATION,0.04974271012006861,"is an estimator based on the training data Z.1 In particular, they assume that the training inputs
xi ‚àºp are i.i.d. samples from the same distribution as the test example x ‚àºp."
PROBLEM FORMULATION,0.051457975986277875,"DeÔ¨Ånition 2.1. The model fŒ∏ and distribution p satisfy function identiÔ¨Åcation if for any œµ, Œ¥ ‚ààR>0,
we have Pp(Z)[‚àÄx ‚ààX . (fÀÜŒ∏(Z)(x) ‚àífŒ∏‚àó(x))2 ‚â§œµ] ‚â•1 ‚àíŒ¥ for n = |Z| sufÔ¨Åciently large."
PROBLEM FORMULATION,0.05317324185248713,"Function identiÔ¨Åcation implies generalization bounds even when the test data comes from a different
distribution q. In particular, we say fŒ∏ robustly generalizes if for any q with support on X, we have"
PROBLEM FORMULATION,0.0548885077186964,"Pp(Z)[Lq(ÀÜŒ∏(Z)) ‚â§œµ] ‚â•1 ‚àíŒ¥,
(4)"
PROBLEM FORMULATION,0.05660377358490566,"where the difference from (3) has been highlighted in red. It is easy to see that function identiÔ¨Åcation
implies (4). Note that the true model fŒ∏‚àódoes not change, so there is no label shift."
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.058319039451114926,"3
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS"
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.060034305317324184,"Traditional statistical bounds on parameter identiÔ¨Åcation can provide guarantees for arbitrary covariate
shift. In particular, suppose we have a bound of the form"
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.06174957118353345,"Pp(Z)
h
‚à•ÀÜŒ∏(Z) ‚àíŒ∏‚àó‚à•2 ‚â§œµ
i
‚â•1 ‚àíŒ¥,
(5)"
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.0634648370497427,"and assume that the model family fŒ∏ is K-Lipschitz continuous in Œ∏; then, we have"
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.06518010291595197,"Lq(ÀÜŒ∏(Z)) ‚â§K2 ¬∑ ‚à•ÀÜŒ∏(Z) ‚àíŒ∏‚àó‚à•2
2 ‚â§K2œµ2
(6)"
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.06689536878216124,"with probability at least 1 ‚àíŒ¥ according to p(Z). In particular, this bound holds for any covariate
distribution q. Our goal is to extend these techniques to quadratic neural networks, which are
over-parameterized so we cannot identify the true parameters Œ∏‚àó‚Äîi.e., (5) does not hold."
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.0686106346483705,"1Note that in (3), the loss Lp omits the label errors Œæ; including it would result in an additive constant to Lp.
This choice ensures that the optimal parameters have zero loss‚Äîi.e., Lq(Œ∏‚àó) = 0 for any q."
FUNCTION IDENTIFICATION OF QUADRATIC NEURAL NETWORKS,0.07032590051457976,Under review as a conference paper at ICLR 2022
QUADRATIC NEURAL NETWORKS,0.07204116638078903,"3.1
QUADRATIC NEURAL NETWORKS"
QUADRATIC NEURAL NETWORKS,0.07375643224699828,"We consider a neural network fŒ∏, where Œ∏ ‚ààRd√ók, with a single hidden layer with k neurons‚Äîi.e.,
fŒ∏(x) = Pk
j=1 aj ¬∑ œÉ(‚ü®Œ∏j, x‚ü©). We consider the over-parameterization case where k can be much
larger than d. Following prior work (Du & Lee, 2018), we assume that fŒ∏ has quadratic activations
and output weights equal to one‚Äîi.e., œÉ(z) = z2 and aj = 1 for each j ‚àà[k], so we have"
QUADRATIC NEURAL NETWORKS,0.07547169811320754,"fŒ∏(x) = k
X"
QUADRATIC NEURAL NETWORKS,0.07718696397941681,"j=1
‚ü®Œ∏j, x‚ü©2."
QUADRATIC NEURAL NETWORKS,0.07890222984562607,"We assume the true (training) loss is the mean-squared error Lp(Œ∏) = Ep(x)[(fŒ∏(x) ‚àífŒ∏‚àó(x))2], and
we consider a model trained using an empirical estimate of this loss on the training dataset:"
QUADRATIC NEURAL NETWORKS,0.08061749571183534,"ÀÜŒ∏(Z) = arg min
Œ∏‚ààŒò
ÀÜL(Œ∏; Z)
where
ÀÜL(Œ∏; Z) = 1 n n
X"
QUADRATIC NEURAL NETWORKS,0.0823327615780446,"i=1
(fŒ∏(xi) ‚àíyi)2."
QUADRATIC NEURAL NETWORKS,0.08404802744425385,"Now, our goal is to obtain a bound of the form (6); to this end, we assume the following:
Assumption 3.1. ‚à•x‚à•2 ‚â§xmax and ‚à•Œ∏‚à•F ‚â§Œ∏max.
Assumption 3.2. There exists Œ± ‚ààR>0 such that Ep(x)[(x‚ä§‚àÜx)2] ‚â•Œ±‚à•‚àÜ‚à•2
F for any symmetric
‚àÜ‚ààRd√ód."
QUADRATIC NEURAL NETWORKS,0.08576329331046312,"Our second assumption is standard; in particular, it is closely related to the assumption in linear
regression that the minimum eigenvalue of the covariance matrix is lower bounded‚Äîi.e., Œ£ =
Ep(x)[xx‚ä§] ‚âª0. As an example, when x is i.i.d. uniform in each component, e.g., p(x) =
Qd
i=1 Uniform(xi; [‚àí1/2, 1/2]), then we can take Œ± = 1/180; we give a proof in Appendix B.1."
ROBUST GENERALIZATION,0.08747855917667238,"3.2
ROBUST GENERALIZATION"
ROBUST GENERALIZATION,0.08919382504288165,"Our approach leverages the fact that fŒ∏(x) = x‚ä§(Œ∏Œ∏‚ä§)x; thus, fŒ∏ resembles a matrix factorization
model. Recent work has leveraged this connection to translate matrix factorization theory to quadratic
neural networks (Du & Lee, 2018). We let g(Œ∏) = Œ∏Œ∏‚ä§and ÀúfœÜ(x) = x‚ä§œÜx, where œÜ ‚ààŒ¶ ‚äÜRd√ód, in
which case fŒ∏(x) = Àúfg(Œ∏)(x); in addition, we deÔ¨Åne ÀúLp(œÜ) = Ep(x)[( ÀúfœÜ(x)‚àíÀúfœÜ‚àó(x))2], where œÜ‚àó="
ROBUST GENERALIZATION,0.09090909090909091,"g(Œ∏‚àó), and ÀÜÀúL(œÜ; Z) = n‚àí1 Pn
i=1( ÀúfœÜ(xi) ‚àíyi)2, so Lp(Œ∏) = ÀúLp(g(Œ∏)) and ÀÜL(Œ∏; Z) = ÀÜÀúL(g(Œ∏); Z).
Finally, we assume that ‚à•œÜ‚à•F ‚â§œÜmax; in general, we have œÜmax ‚â§Œ∏2
max by Assumption 3.1."
ROBUST GENERALIZATION,0.09262435677530018,"We begin by stating several lemmas establishing the properties needed for function identiÔ¨Åcation.
Our Ô¨Årst lemma says that the loss is strongly convex in œÜ."
ROBUST GENERALIZATION,0.09433962264150944,"Lemma 3.3. Under Assumption 3.2, the loss ÀúLp(œÜ) is 2Œ±-strongly convex in œÜ."
ROBUST GENERALIZATION,0.09605488850771869,We give a proof in Appendix B.2. Our next lemma says that our model family is Lipschitz in œÜ.
ROBUST GENERALIZATION,0.09777015437392796,"Lemma 3.4. Under Assumptions 3.1 & 3.2, ÀúfœÜ and ÀúL are K-Lipschitz in œÜ, where K = 4œÜmaxx4
max."
ROBUST GENERALIZATION,0.09948542024013722,"We give a proof in Appendix B.3. Our Ô¨Ånal lemma says that our estimate of the loss function is a
uniformly good approximation of the true loss.
Lemma 3.5. Under Assumptions 3.1 & 3.2, for any Œ¥ ‚ààR>0, we have Pp(Z)"
ROBUST GENERALIZATION,0.10120068610634649,"
sup
Œ∏‚ààŒò
|Lp(Œ∏) ‚àíÀÜL(Œ∏; Z) ‚àíœÉ(Z)| ‚â§œµ

‚â•1 ‚àíŒ¥,"
ROBUST GENERALIZATION,0.10291595197255575,"where œÉ(Z) = n‚àí1 Pn
i=1 Œæ2
i , and letting ‚Ñìmax = 2x2
maxœÜmax be an upper bound on |fŒ∏(x) ‚àífŒ∏‚àó(x)|, œµ = s"
ROBUST GENERALIZATION,0.10463121783876501,18‚Ñì2max(‚Ñì2max + Œæ2max) n
ROBUST GENERALIZATION,0.10634648370497427,"
d2 max

1, log

1 + 8œÜmaxKn ‚Ñì2max"
ROBUST GENERALIZATION,0.10806174957118353,"
+ log 2 Œ¥"
ROBUST GENERALIZATION,0.1097770154373928,"
.
(7)"
ROBUST GENERALIZATION,0.11149228130360206,"We give a proof in Appendix B.4. Note that œµ ‚Üí0 as n ‚Üí‚àû. Next, we prove our main result, which
says that quadratic neural networks can be functionally identiÔ¨Åed."
ROBUST GENERALIZATION,0.11320754716981132,Under review as a conference paper at ICLR 2022
ROBUST GENERALIZATION,0.11492281303602059,"Theorem 3.6. Under Assumptions 3.1 & 3.2, we have Pp(Z)"
ROBUST GENERALIZATION,0.11663807890222985,"
‚àÄx ‚ààX . (fÀÜŒ∏(Z)(x) ‚àífŒ∏‚àó(x))2 ‚â§2K2œµ Œ±"
ROBUST GENERALIZATION,0.1183533447684391,"
‚â•1 ‚àíŒ¥."
ROBUST GENERALIZATION,0.12006861063464837,"Proof. By Lemma 3.3, and since ‚àáœÜ ÀúL(g(Œ∏‚àó)) = 0, we have"
ROBUST GENERALIZATION,0.12178387650085763,"Lp(ÀÜŒ∏(Z)) ‚àíLp(Œ∏‚àó) = ÀúLp(g(ÀÜŒ∏(Z))) ‚àíÀúLp(g(Œ∏‚àó)) ‚â•Œ±‚à•g(ÀÜŒ∏(Z)) ‚àíg(Œ∏‚àó)‚à•2
F .
(8)"
ROBUST GENERALIZATION,0.1234991423670669,"Next, by Lemma 3.5 and the fact that ÀÜŒ∏ minimizes ÀÜL(Œ∏; Z), we have"
ROBUST GENERALIZATION,0.12521440823327615,"Lp(ÀÜŒ∏(Z)) ‚â§ÀÜL(ÀÜŒ∏; Z) + œµ ‚àíœÉ(Z) ‚â§ÀÜL(Œ∏‚àó; Z) + œµ ‚àíœÉ(Z) ‚â§Lp(Œ∏‚àó) + 2œµ
(9)"
ROBUST GENERALIZATION,0.1269296740994854,"with probability at least 1 ‚àíŒ¥. Combining (8) and (9), we have"
ROBUST GENERALIZATION,0.12864493996569468,‚à•g(ÀÜŒ∏(Z)) ‚àíg(Œ∏‚àó)‚à•F ‚â§ r 2œµ
ROBUST GENERALIZATION,0.13036020583190394,"Œ±
with probability at least 1 ‚àíŒ¥. Finally, by Lemma 3.4, we have"
ROBUST GENERALIZATION,0.1320754716981132,"(fÀÜŒ∏(Z)(x) ‚àífŒ∏‚àó(x))2 = ( Àúfg(ÀÜŒ∏(Z))(x) ‚àíÀúfg(Œ∏‚àó)(x))2 ‚â§K2‚à•g(ÀÜŒ∏(Z)) ‚àíg(Œ∏‚àó)‚à•2
2 ‚â§2K2œµ"
ROBUST GENERALIZATION,0.13379073756432247,"Œ±
(‚àÄx ‚ààX)"
ROBUST GENERALIZATION,0.13550600343053174,"with probability at least 1 ‚àíŒ¥, as claimed."
ROBUST GENERALIZATION,0.137221269296741,"As a result, we provide a robust generalization error bound for quadratic neural networks with
potential distribution shifts.
Corollary 3.7. Under Assumptions 3.1 & 3.2, for any distribution q(x) with support on B2(0, xmax), Pp(Z)"
ROBUST GENERALIZATION,0.13893653516295026,"
Lq(ÀÜŒ∏(Z)) ‚â§2K2œµ Œ±"
ROBUST GENERALIZATION,0.14065180102915953,"
‚â•1 ‚àíŒ¥."
ROBUST GENERALIZATION,0.1423670668953688,"Finally, we also prove that gradient descent can Ô¨Ånd the global minima of ÀÜL(Œ∏; Z), which ensures that
gradient descent can perform function identiÔ¨Åcation in practice; we give a proof in Appendix B.5."
ROBUST GENERALIZATION,0.14408233276157806,Proposition 3.8. All local minima of ÀÜL(Œ∏; Z) are also global minima.
QUADRATIC NEURAL BANDITS,0.1457975986277873,"4
QUADRATIC NEURAL BANDITS"
QUADRATIC NEURAL BANDITS,0.14751286449399656,"A key application of robust generalization bounds is to parametric bandits; this is because, in bandit
learning, the distribution of inputs x used to estimate ÀÜŒ∏ ‚âàŒ∏‚àócan differ from the distribution under
which fÀÜŒ∏ is used. Thus, generalization bounds based on notions such as Rademacher complexity
cannot be used. Unlike prior literature in bandits, we consider an over-parameterized function that
does not admit a unique solution; in contrast, recent work on neural tangent kernel bandits (Zhou
et al., 2020) assumes that there is a unique, identiÔ¨Åable solution. Note that this assumption cannot
hold for quadratic neural networks because they are invariant to transformations such as rotations."
QUADRATIC NEURAL BANDITS,0.14922813036020582,"We consider a standard linear bandit (Rusmevichientong & Tsitsiklis, 2010; Abbasi-Yadkori et al.,
2011) with a Ô¨Åxed horizon T ‚ààN, but where the expected reward is parameterized by a quadratic
neural network instead of a linear function. At each time step t, the algorithm chooses among a
continuum of actions xt ‚ààX, and receives a reward"
QUADRATIC NEURAL BANDITS,0.1509433962264151,"yt = fŒ∏‚àó(xt) + Œæt = k
X"
QUADRATIC NEURAL BANDITS,0.15265866209262435,"j=1
‚ü®Œ∏‚àó
j , xt‚ü©2 + Œæt,
(10)"
QUADRATIC NEURAL BANDITS,0.15437392795883362,"where Œ∏‚àó‚ààRd√ók is an unknown parameter matrix, and Œæt are bounded i.i.d. random variables. For
simplicity, we assume that X = B2(0, 1) is the unit ball. Then, our goal is to bound the regret"
QUADRATIC NEURAL BANDITS,0.15608919382504288,"R(T) = T
X"
QUADRATIC NEURAL BANDITS,0.15780445969125215,"t=1
(Ep(Œæt)[yt] ‚àíy‚àó)
where
y‚àó= max
x‚ààX fŒ∏‚àó(x)."
QUADRATIC NEURAL BANDITS,0.1595197255574614,"We make the following assumption, which says that œÜ‚àó= Œ∏‚àóŒ∏‚àó‚ä§has a gap in its top eigenvalue:"
QUADRATIC NEURAL BANDITS,0.16123499142367068,Under review as a conference paper at ICLR 2022
QUADRATIC NEURAL BANDITS,0.16295025728987994,Algorithm 1 Explore-Then-Commit Algorithm for Quadratic Neural Network Bandit
QUADRATIC NEURAL BANDITS,0.1646655231560892,procedure QUADRATICNEURALBANDIT
QUADRATIC NEURAL BANDITS,0.16638078902229847,"Initialize Z ‚Üê‚àÖ
Let m be as in (11)
for t ‚àà{1, ..., m} do"
QUADRATIC NEURAL BANDITS,0.1680960548885077,"Sample i.i.d. action xt ‚àºp, where p is as in (12)
Take action xt and obtain reward yt as in (10)
Update Z ‚ÜêZ ‚à™{(xt, yt)}
end for
Compute ÀÜŒ∏ = arg minŒ∏ ÀÜL(Œ∏; Z), where ÀÜL(Œ∏; Z) = m‚àí1 Pm
i=1(fŒ∏(xi) ‚àíyi)2
Compute ÀÜx = arg maxx‚ààX fÀÜŒ∏(x)
for t ‚àà{m + 1, ..., T} do"
QUADRATIC NEURAL BANDITS,0.16981132075471697,"Take action xt = ÀÜx and obtain reward yt as in (10)
end for
end procedure"
QUADRATIC NEURAL BANDITS,0.17152658662092624,"Assumption 4.1. Let œÜ‚àó= Œ∏‚àóŒ∏‚àó‚ä§, and let Œª1 ‚â•Œª2 ‚â•... ‚â•Œªd be the eigenvalues of œÜ‚àó. There
exists a constant M ‚ààR>0 such that Œª1 ‚àíŒª2 ‚â•4/M."
QUADRATIC NEURAL BANDITS,0.1732418524871355,"This assumption ensures that the eigenvectors of œÜ‚àóto be stable under perturbations. The eigenvectors
of œÜ‚àócorrespond to the optimal action x‚àó= arg maxx‚ààX fŒ∏‚àó(x) since fŒ∏‚àó(x) = x‚ä§œÜ‚àóx; thus, this
assumption ensures that if ÀÜŒ∏ ‚âàŒ∏‚àó, then the optimal action ÀÜx = arg maxx‚ààX fÀÜŒ∏(x) satisÔ¨Åes ÀÜx ‚âàx‚àó."
QUADRATIC NEURAL BANDITS,0.17495711835334476,"Next, we describe our algorithm, summarized in Algorithm 1. We consider an explore-then-commit
strategy for simplicity, since it already achieves the asymptotically optimal regret rate (Rusmevichien-
tong & Tsitsiklis, 2010); our approach can similarly be applied to more sophisticated algorithms
such as UCB (Abbasi-Yadkori et al., 2011) and Thompson sampling (Agrawal & Goyal, 2013).
Our algorithm proceeds in two stages: (i) the exploration stage (for t ‚àà{1, ..., m}), and (ii) the
exploitation stage (for t ‚àà{m + 1, ..., T}), where m = Ô£Æ Ô£ØÔ£ØÔ£Ø"
QUADRATIC NEURAL BANDITS,0.17667238421955403,"135M(‚Ñìmax + Œæmax)2d3T
p"
QUADRATIC NEURAL BANDITS,0.1783876500857633,"log(3 + 8œÜmaxKT/‚Ñì2max)
œÜmax !2/3Ô£π"
QUADRATIC NEURAL BANDITS,0.18010291595197256,"Ô£∫Ô£∫Ô£∫
.
(11)"
QUADRATIC NEURAL BANDITS,0.18181818181818182,"In the exploration stage, we randomly choose actions xt ‚àºp, where"
QUADRATIC NEURAL BANDITS,0.1835334476843911,"p(x) = d
Y"
QUADRATIC NEURAL BANDITS,0.18524871355060035,"i=1
Uniform

xi;

‚àí1
‚àö"
QUADRATIC NEURAL BANDITS,0.18696397941680962,"d
, 1
‚àö d"
QUADRATIC NEURAL BANDITS,0.18867924528301888,"
.
(12)"
QUADRATIC NEURAL BANDITS,0.19039451114922812,"Note that ‚à•x‚à•2 ‚â§1 for x in the support of p, so xt ‚ààX. Following the discussion in Section 3, for
this choice of p, Assumption 3.2 holds for the dataset Z with Œ± = 4/(45d2)."
QUADRATIC NEURAL BANDITS,0.19210977701543738,"Next, we compute an estimate ÀÜŒ∏ of Œ∏‚àóbased on the data Z collected so far, and compute the optimal
action ÀÜx assuming ÀÜŒ∏ are the true parameters. Then, in the exploitation stage, we always use action ÀÜx."
QUADRATIC NEURAL BANDITS,0.19382504288164665,"The key challenge providing theoretical guarantees using traditional generalization bounds is handling
the optimization problem over x ‚ààX used to compute ÀÜx. Since ÀÜx is not sampled from the distribution
p, traditional bounds do not provide any guarantees about the accuracy of fÀÜŒ∏(ÀÜx) compared to fŒ∏‚àó(ÀÜx).
In contrast, Theorem 3.6 provides a uniform guarantee, and can therefore be used to bound the regret."
QUADRATIC NEURAL BANDITS,0.1955403087478559,"Theorem 4.2. Under Assumptions 3.1, 3.2 & 4.1, the expected regret of Algorithm 1 is"
QUADRATIC NEURAL BANDITS,0.19725557461406518,"R(T) ‚â§C0 + C1 ¬∑ T 2/3

log

3 + 8œÜmaxKT ‚Ñì2max"
QUADRATIC NEURAL BANDITS,0.19897084048027444,"1/3
,"
QUADRATIC NEURAL BANDITS,0.2006861063464837,where C0 and C1 do not depend on T (see Appendix C).
QUADRATIC NEURAL BANDITS,0.20240137221269297,"In particular, we have R(T) = ÀúO(T 2/3); we give a proof in Appendix C. Note that this is worse than
the usual ÀúO(
‚àö"
QUADRATIC NEURAL BANDITS,0.20411663807890223,T) regret because Theorem 3.6 only admits a n1/4 convergence rate.
QUADRATIC NEURAL BANDITS,0.2058319039451115,Under review as a conference paper at ICLR 2022
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.20754716981132076,"5
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.20926243567753003,"So far, we have considered shifts in the covariate distribution but not in the label distribution. Now,
we consider a transfer learning problem where there is additionally a small shift in the labels. In
particular, we assume we have proxy data Zp ‚äÜX √ó Y from the source domain of the form
yp,i = fŒ∏‚àóp(xp,i) + Œæp,i (for i ‚àà[np]), where Œ∏‚àó
p ‚ààŒò are the proxy parameters and p(xp) is the
source covariate distribution, along with gold data Zg ‚äÜX √ó Y from the target domain of the form
yg,i = fŒ∏‚àóg(xg,i) + Œæg,i (for i ‚àà[ng]), where Œ∏‚àó
g ‚ààŒò are the gold parameters and q(xg) is the target
covariate distribution. We are interested in the setting np ‚â´ng, and where ‚à•Œ∏‚àó
g ‚àíŒ∏‚àó
p‚à•F ‚â§B is small."
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.2109777015437393,"We consider a two-stage estimator (Bastani, 2020) that Ô¨Årst computes an estimate of the proxy
parameters ÀÜŒ∏p = arg minŒ∏‚ààŒò ÀÜL(Œ∏; Zp), and then computes an estimate of the gold parameters in a
way that is constrained towards the proxy parameters. First, note that we have Pp(Z)"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.21269296740994853,"
Lq(ÀÜŒ∏p) ‚â§2K2œµp Œ±"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.2144082332761578,"
‚â•1 ‚àíŒ¥ 2, where œµp = s"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.21612349914236706,18‚Ñì2max(‚Ñì2max + Œæ2max) np
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.21783876500857632,"
d2 max

1, log

1 + 8œÜmaxKnp ‚Ñì2max"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.2195540308747856,"
+ log 4 Œ¥ 
,"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.22126929674099485,"where we have highlighted the differences from œµ in (7) in red. Next, we make a technical assumption:
Assumption 5.1. For some œÉ0 ‚ààR>0, œÉmin(Œ∏‚àó
p) ‚â•œÉ0, where œÉmin(Œ∏) is the dth singular value of Œ∏."
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.22298456260720412,"Equivalently, the minimum eigenvalue of g(Œ∏‚àó
p) is positive; intuitively, this assumption ensures a good
estimate of Œ∏‚àó
pŒ∏‚àó‚ä§
p
implies a good estimate of Œ∏‚àó
p (up to an orthogonal transformation). Then, letting"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.22469982847341338,ÀÜB = B + 1 œÉ0 r 2œµp Œ±
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.22641509433962265,"be an expanded radius to account for error in our estimate of ÀÜŒ∏p, we use the estimator"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.2281303602058319,"ÀÜŒ∏g = arg min
Œ∏‚ààB2(ÀÜŒ∏p, ÀÜ
B)
ÀÜL(Œ∏; Zg)
where
B2(ÀÜŒ∏p, ÀÜB) = {Œ∏ ‚ààŒò | ‚à•Œ∏ ‚àíÀÜŒ∏p‚à•F ‚â§ÀÜB}."
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.22984562607204118,"Note that we have assume ÀÜB is known; in practice, this constraint can be included as an additive
regularization term. Intuitively, this formulation mirrors transfer learning algorithms based on Ô¨Åne-
tuning‚Äîi.e., initializing the parameters to the proxy data Œ∏p and then taking a small number of steps
of stochastic gradient descent (SGD) on the gold data Œ∏g. In particular, SGD can be interpreted as L2
regularization on the parameters (Ali et al., 2020), so Ô¨Åne-tuning L2-regularizes ÀÜŒ∏g towards Œ∏p.
Theorem 5.2. Under Assumptions 3.1, 3.2 & 5.1, for any q(x) with support on B2(0, xmax), Pp(Z)"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.23156089193825044,"
Lq(ÀÜŒ∏g) ‚â§2K2œµg Œ±"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.2332761578044597,"
‚â•1 ‚àíŒ¥, where"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.23499142367066894,œµg = ÀÜB ¬∑ s
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.2367066895368782,18K2(K2 ÀÜB2 + Œæ2max) ng
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.23842195540308747,"
d2 max

1, log

1 + 8œÜmaxKng ‚Ñì2max"
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.24013722126929674,"
+ log 4 Œ¥ 
."
TRANSFER LEARNING OF QUADRATIC NEURAL NETWORKS,0.241852487135506,"Thus, if B is small and np is large, fÀÜŒ∏g is accurate even if ng is small; we give a proof in Appendix D."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.24356775300171526,"6
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.24528301886792453,"While function identiÔ¨Åcation enables robust generalization, many data generating processes are
too complex to be identiÔ¨Åable. Neural module networks are designed to break complex prediction
problems into smaller tasks that are individually easier to solve. These models take two kinds of input:
(i) a sequence of tokens w (e.g., word embeddings) indicating the correct composition of modules,"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2469982847341338,Under review as a conference paper at ICLR 2022
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.24871355060034306,"and (ii) the input x to the modules. Then, the model predicts the sequence of modules j1...jT based
on w, and runs the modules in sequence to obtain output x‚Ä≤ = fjT (...(fj1(x))...)."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2504288164665523,"We study conditions under which neural module networks can robustly generalize. Rather than study
arbitrary distribution shifts, we consider two separate shifts:"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2521440823327616,"‚Ä¢ Module inputs: We assume that the individual modules are identiÔ¨Åable; as a consequence, we
assume the shift to the module input x can be arbitrary."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2538593481989708,"‚Ä¢ Module composition: We consider shifts to the token sequence w. If the model mapping w to
j1...jT is identiÔ¨Åable, then the entire model is identiÔ¨Åable. Instead, we show that when this model
is not identiÔ¨Åable, compositional structure can still aid generalization. Intuitively, we show that
while small shifts in the compositional structure can cause large shifts in the distribution p(w),
models that leverage the structure of p(w) can still generalize well."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2555746140651801,"In more detail, consider a simpliÔ¨Åed neural module network f, which includes (i) a set of neural
modules {fj : X ‚ÜíX}k
j=1, and (ii) a parser g : ZT ‚Üí[k]T , where Z ‚äÜRr, with model class
g ‚ààG. We assume each component of fj(x) is computed by a separate quadratic neural network;
we discuss the architecture of g below. Then, given an input x ‚ààX ‚äÜRd and w ‚ààW = ZT , the
corresponding neural module network f : X √ó W ‚ÜíX is deÔ¨Åned by"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.25728987993138935,"f(x, w) = (fjT ‚ó¶... ‚ó¶fj1)(x) = fjT (...(fj1(x))...)
where
j1...jT = g(w)."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.25900514579759865,"We assume that g has compositional structure‚Äîi.e., for some Àúg : [k] √ó Z ‚Üí[k], we have"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2607204116638079,"g(w) = j1...jT
where
jt =
0
if t = 0
Àúg(zt, jt‚àí1)
otherwise,"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2624356775300172,"where w = z1...zT . Intuitively, w is a sequence of word vectors; then, the current neural module
jt = Àúg(zt, jt‚àí1) depends both on the current word vector zt and the previous neural module jt‚àí1.
First, we assume that the individual modules have been functionally identiÔ¨Åed."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2641509433962264,"We assume we have fully labeled data we can use to train the neural modules‚Äîi.e., for each input x
and sequence w, we have both the desired sequence j1...jT of neural modules, as well as the entire
execution x0, x1, ..., xT , where x0 = x and xt+1 = fjt(xt) otherwise. Thus, we can use supervised
learning to train the neural modules;2 in particular, we can construct labeled examples (jt‚àí1, zt, jt)
used to train the parser Àúg, and labeled examples (xt, xt+1) to train the modules fjt. For simplicity,
we assume we have a uniform lower bound n on the number of training examples for the parser and
for each module. Then, we have the following straightforward result:"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2658662092624357,"Lemma 6.1. Under Assumptions 3.1 & 3.2, with probability at least 1 ‚àídkŒ¥, for each j ‚àà[k],"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.26758147512864494,"‚à•ÀÜfj(x) ‚àíf ‚àó
j (x)‚à•2 ‚â§ r 2dK2œµ"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2692967409948542,"Œ±
=: œµf
(‚àÄx ‚ààX),"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.27101200686106347,"where ÀÜfj is the estimated module and f ‚àó
j is the ground truth module."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2727272727272727,"This result follows straightforwardly from Theorem 3.6 along with a union bound. In contrast, we
do not assume the parsing model robustly generalizes, but only on distribution. For the subsequent
analysis, we can use any neural network models that satisfy the statement of Lemma 6.1."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.274442538593482,"Lemma 6.2. Under Assumptions 3.1 & 3.2, with probability at least 1 ‚àíŒ¥, we have"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.27615780445969124,"PÀúp(z,j)
h
ÀÜÀúg(z, j) Ã∏= Àúg‚àó(z, j)
i
‚â§4Rn(G) + r"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.27787307032590053,2 log(2/Œ¥)
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.27958833619210977,"n
=: œµg,"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.28130360205831906,"where Rn(G) is the Rademacher complexity of G (including its loss function), where p(z, j) =
T ‚àí1 PT
t=1 pt(z, j), and where"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2830188679245283,"Àúpt(z, j) ="
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2847341337907376,"(
1(j = 0) ¬∑ Àúp(z)
if t = 1
Pk
j‚Ä≤=1
R
1(j = Àúg‚àó(z‚Ä≤, j‚Ä≤)) ¬∑ Àúp(z | z‚Ä≤) ¬∑ Àúpt‚àí1(z‚Ä≤, j‚Ä≤)dz‚Ä≤
otherwise."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2864493996569468,"2Neural modules are often trained with only partial supervision (Andreas et al., 2016); we leave an analysis
of this strategy to future work since our focus is on understanding generalization rather than learning dynamics."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2881646655231561,Under review as a conference paper at ICLR 2022
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.28987993138936535,"This result is a standard Rademacher generalization bound (Bartlett & Mendelson, 2002). Note that
we have also assumed that the distribution over token sequences is structured, which is necessary for
our compositional implementation of g to generalize, even on distribution. Intuitively, the distribution
over (z, j) consists of both a unigram model over the word vectors:"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2915951972555746,"p(z1, ..., zT ) = T
Y"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2933104631217839,"t=1
Àúp(zt | zt‚àí1),"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2950257289879931,"where we deÔ¨Åne Àúp(z1 | z0) = Àúp(z1), as well as a unigram model over neural modules:"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.2967409948542024,"p(j1...jT | z1, ..., zT ) = T
Y"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.29845626072041165,"t=1
1(jt = Àúg‚àó(zt, jt‚àí1))."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.30017152658662094,"Next, we consider a shifted distribution Àúq(z | z‚Ä≤), which is close to Àúp(z | z‚Ä≤).
Assumption 6.3. We have ‚à•Àúq(¬∑ | z‚Ä≤) ‚àíÀúp(¬∑ | z‚Ä≤)‚à•TV ‚â§Œ±."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.3018867924528302,"Importantly, despite this assumption, the shift between the overall distributions p(z1, ..., zT ) and
q(z1, ..., zT ) can still be large since it compounds exponentially across the steps t ‚àà[T].
Proposition 6.4. There exist p and q that satisfy Assumption 6.3, but ‚à•p‚àíq‚à•TV = 2(1‚àí(1‚àíŒ±/2)T )."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.30360205831903947,"That is, even if the single step probabilities Àúp(z | z‚Ä≤) and Àúq(z | z‚Ä≤) have total variation (TV) distance
bounded as in Assumption 6.3, the overall distributions p and q can have TV distance exponentially
close to the maximum possible distance of 2 in T; we give a proof in Appendix E.1."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.3053173241852487,"We show that neural module networks generalize since ÀÜg leverages the compositional structure of p.
First, we show that under Assumption 6.3, the overall shift in the input distribution of ÀÜÀúg is bounded:
Lemma 6.5. Under Assumptions 3.1, 3.2 & 6.3, we have ‚à•Àúq ‚àíÀúp‚à•TV ‚â§TŒ±, where Àúp is deÔ¨Åned in
Lemma 6.2 and Àúq is deÔ¨Åned in Assumption 6.3."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.307032590051458,"That is, while the shift can compound across steps t, it does so only linearly; we give a proof in
Appendix E.2. Next, we show that as a consequence, the error of ÀÜg is bounded."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.30874785591766724,"Lemma 6.6. Under Assumptions 3.1, 3.2 & 6.3, and assuming that Pp(z,j)[ÀÜÀúg(z, j) Ã∏= Àúg‚àó(z, j)] ‚â§œµg,
we have that Pp(w)[ÀÜg(w) Ã∏= g‚àó(w)] ‚â§Tœµg."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.31046312178387653,"We give a proof in Appendix E.3. Finally, we have our main result.
Theorem 6.7. Under Assumptions 3.1, 3.2 & 6.3, with probability at least 1 ‚àí(dk + 1)Œ¥, we have"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.31217838765008576,"Pq(w)
h
‚à•ÀÜf(x, w) ‚àíf ‚àó(x, w)‚à•2 ‚â§Tœµf ¬∑ max{KT ‚àí1, 1}
i
‚â•1 ‚àíTœµg ‚àíT 2Œ±."
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.313893653516295,"We give a proof in Appendix E.4. Intuitively, Theorem 6.7 says that the error of the neural module
network is linear in T as long as K ‚â§1. Note that even if there is no distribution shift, its error is"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.3156089193825043,"Pp(w)
h
‚à•ÀÜf(x, w) ‚àíf ‚àó(x, w)‚à•2 ‚â§Tœµf ¬∑ max{KT ‚àí1, 1}
i
‚â•1 ‚àíTœµg,"
GENERALIZATION BOUNDS FOR NEURAL MODULE NETWORKS,0.31732418524871353,"by the same argument as the proof of Theorem 6.7. The exponential dependence on K is unavoidable
since K > 1 says that the modules fj can expand the input, which leads to exponential blowup in the
magnitude of the output as a function of T, which also makes the estimation error exponential in T.
Thus, the only cost to the distribution shift from p to q is the additional error probability T 2Œ±."
CONCLUSION,0.3190394511149228,"7
CONCLUSION"
CONCLUSION,0.32075471698113206,"We have presented a number of results demonstrating that over-parameterization does not funda-
mentally harm learning models that are robust to arbitrary distribution shifts. In particular, even
though we can no longer identify the true parameters for quadratic neural networks, we show that
we can identify the true function, thereby enabling us to prove new results in bandits and transfer
learning. Finally, we provide preliminary analysis extending these results to neural module networks
to handle complex data generating processes. A limitation of our work is that it is specialized to
quadratic neural networks; a key direction for future work is to explore how our results extend to
other activation functions and deeper architectures."
CONCLUSION,0.32246998284734135,Under review as a conference paper at ICLR 2022
REFERENCES,0.3241852487135506,REFERENCES
REFERENCES,0.3259005145797599,"Yasin Abbasi-Yadkori, D¬¥avid P¬¥al, and Csaba Szepesv¬¥ari. Improved algorithms for linear stochastic
bandits. In NIPS, volume 11, pp. 2312‚Äì2320, 2011."
REFERENCES,0.3276157804459691,"Shipra Agrawal and Navin Goyal. Thompson sampling for contextual bandits with linear payoffs. In
International Conference on Machine Learning, pp. 127‚Äì135. PMLR, 2013."
REFERENCES,0.3293310463121784,"Alnur Ali, Edgar Dobriban, and Ryan Tibshirani. The implicit regularization of stochastic gradient
Ô¨Çow for least squares. In International Conference on Machine Learning, pp. 233‚Äì244. PMLR,
2020."
REFERENCES,0.33104631217838765,"Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Neural module networks. In
Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 39‚Äì48, 2016."
REFERENCES,0.33276157804459694,"Sanjeev Arora, Rong Ge, Behnam Neyshabur, and Yi Zhang. Stronger generalization bounds for deep
nets via a compression approach. In International Conference on Machine Learning, pp. 254‚Äì263.
PMLR, 2018."
REFERENCES,0.3344768439108062,"Francis Bach, Julien Mairal, and Jean Ponce. Convex sparse matrix factorizations. arXiv preprint
arXiv:0812.1869, 2008."
REFERENCES,0.3361921097770154,"Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463‚Äì482, 2002."
REFERENCES,0.3379073756432247,"Hamsa Bastani. Predicting with proxies: Transfer learning in high dimension. Management Science,
2020."
REFERENCES,0.33962264150943394,"Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for
domain adaptation. In Advances in neural information processing systems, pp. 137‚Äì144, 2007."
REFERENCES,0.34133790737564323,"John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman. Learning
bounds for domain adaptation. In Advances in neural information processing systems, pp. 129‚Äì136,
2008."
REFERENCES,0.34305317324185247,"Emmanuel J Candes and Yaniv Plan. Tight oracle inequalities for low-rank matrix recovery from a
minimal number of noisy random measurements. IEEE Transactions on Information Theory, 57
(4):2342‚Äì2359, 2011."
REFERENCES,0.34476843910806176,"Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. CertiÔ¨Åed adversarial robustness via randomized
smoothing. In International Conference on Machine Learning, pp. 1310‚Äì1320. PMLR, 2019."
REFERENCES,0.346483704974271,"Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, and Alistair Stewart.
Robust estimators in high-dimensions without the computational intractability. SIAM Journal on
Computing, 48(2):742‚Äì864, 2019."
REFERENCES,0.3481989708404803,"Simon Du and Jason Lee. On the power of over-parametrization in neural networks with quadratic
activation. In International Conference on Machine Learning, pp. 1329‚Äì1338. PMLR, 2018."
REFERENCES,0.34991423670668953,"Simon Du, Jason Lee, Haochuan Li, Liwei Wang, and Xiyu Zhai. Gradient descent Ô¨Ånds global
minima of deep neural networks. In International Conference on Machine Learning, pp. 1675‚Äì1685.
PMLR, 2019."
REFERENCES,0.3516295025728988,"John Duchi and Hongseok Namkoong. Learning models with uniform performance via distributionally
robust optimization. arXiv preprint arXiv:1810.08750, 2018."
REFERENCES,0.35334476843910806,"Dylan Foster and Alexander Rakhlin. Beyond ucb: Optimal and efÔ¨Åcient contextual bandits with
regression oracles. In International Conference on Machine Learning, pp. 3199‚Äì3210. PMLR,
2020."
REFERENCES,0.35506003430531735,"Ruiqi Gao, Tianle Cai, Haochuan Li, Cho-Jui Hsieh, Liwei Wang, and Jason D Lee. Convergence
of adversarial training in overparametrized neural networks. Advances in Neural Information
Processing Systems, 32:13029‚Äì13040, 2019."
REFERENCES,0.3567753001715266,Under review as a conference paper at ICLR 2022
REFERENCES,0.3584905660377358,"Rong Ge, Chi Jin, and Yi Zheng. No spurious local minima in nonconvex low rank problems: A
uniÔ¨Åed geometric analysis. In International Conference on Machine Learning, pp. 1233‚Äì1242.
PMLR, 2017a."
REFERENCES,0.3602058319039451,"Rong Ge, Jason D Lee, and Tengyu Ma. Learning one-hidden-layer neural networks with landscape
design. arXiv preprint arXiv:1711.00501, 2017b."
REFERENCES,0.36192109777015435,"Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014."
REFERENCES,0.36363636363636365,"Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common
corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019."
REFERENCES,0.3653516295025729,"Daniel Hsu, Sham M Kakade, and Percy Liang. IdentiÔ¨Åability and unmixing of latent parse trees.
arXiv preprint arXiv:1206.3137, 2012."
REFERENCES,0.3670668953687822,"Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and Aleksander
Madry. Adversarial examples are not bugs, they are features. arXiv preprint arXiv:1905.02175,
2019."
REFERENCES,0.3687821612349914,"Arthur Jacot, Franck Gabriel, and Cl¬¥ement Hongler. Neural tangent kernel: Convergence and
generalization in neural networks. arXiv preprint arXiv:1806.07572, 2018."
REFERENCES,0.3704974271012007,"Maryia Kabanava, Richard Kueng, Holger Rauhut, and Ulrich Terstiege. Stable low-rank matrix
recovery via null space properties. Information and Inference: A Journal of the IMA, 5(4):405‚Äì441,
2016."
REFERENCES,0.37221269296740994,"Michael J Kearns, Umesh Virkumar Vazirani, and Umesh Vazirani. An introduction to computational
learning theory. MIT press, 1994."
REFERENCES,0.37392795883361923,"Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Bal-
subramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al. Wilds: A
benchmark of in-the-wild distribution shifts. arXiv preprint arXiv:2012.07421, 2020."
REFERENCES,0.37564322469982847,"Yuanzhi Li, Tengyu Ma, and Hongyang Zhang. Algorithmic regularization in over-parameterized
matrix sensing and neural networks with quadratic activations. In Conference On Learning Theory,
pp. 2‚Äì47. PMLR, 2018."
REFERENCES,0.37735849056603776,"Philip M Long and Hanie Sedghi. Generalization bounds for deep convolutional neural networks.
arXiv preprint arXiv:1905.12600, 2019."
REFERENCES,0.379073756432247,"Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nathan Srebro. Exploring general-
ization in deep learning. arXiv preprint arXiv:1706.08947, 2017."
REFERENCES,0.38078902229845624,"Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
CertiÔ¨Åed defenses against adversarial
examples. arXiv preprint arXiv:1801.09344, 2018."
REFERENCES,0.38250428816466553,"Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin, and Sameer Singh. Beyond accuracy:
Behavioral testing of nlp models with checklist. arXiv preprint arXiv:2005.04118, 2020."
REFERENCES,0.38421955403087477,"Laura Ruis, Jacob Andreas, Marco Baroni, Diane Bouchacourt, and Brenden M Lake.
A
benchmark for systematic generalization in grounded language understanding. arXiv preprint
arXiv:2003.05161, 2020."
REFERENCES,0.38593481989708406,"Paat Rusmevichientong and John N Tsitsiklis. Linearly parameterized bandits. Mathematics of
Operations Research, 35(2):395‚Äì411, 2010."
REFERENCES,0.3876500857632933,"Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-
likelihood function. Journal of statistical planning and inference, 90(2):227‚Äì244, 2000."
REFERENCES,0.3893653516295026,"Mahdi Soltanolkotabi, Adel Javanmard, and Jason D Lee. Theoretical insights into the optimization
landscape of over-parameterized shallow neural networks. IEEE Transactions on Information
Theory, 65(2):742‚Äì769, 2018."
REFERENCES,0.3910806174957118,Under review as a conference paper at ICLR 2022
REFERENCES,0.3927958833619211,"Jacob Steinhardt, Pang Wei Koh, and Percy Liang. CertiÔ¨Åed defenses for data poisoning attacks.
arXiv preprint arXiv:1706.03691, 2017."
REFERENCES,0.39451114922813035,"Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013."
REFERENCES,0.39622641509433965,"Rohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht, and Ludwig
Schmidt.
Measuring robustness to natural distribution shifts in image classiÔ¨Åcation.
arXiv
preprint arXiv:2007.00644, 2020."
REFERENCES,0.3979416809605489,"Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and Aleksander Madry.
Robustness may be at odds with accuracy. arXiv preprint arXiv:1805.12152, 2018."
REFERENCES,0.3996569468267582,"Roman Vershynin. High-dimensional probability: An introduction with applications in data science,
volume 47. Cambridge university press, 2018."
REFERENCES,0.4013722126929674,"Martin Wainwright.
High-dimensional statistics: A non-asymptotic viewpoint.
Book Draft
(Working Publication), 2016. URL https://www.stat.berkeley.edu/Àúwainwrig/
nachdiplom/Chap2_Sep10_2015.pdf."
REFERENCES,0.40308747855917665,"Junfeng Wen, Chun-Nam Yu, and Russell Greiner. Robust learning under uncertain test distributions:
Relating covariate shift to model misspeciÔ¨Åcation. In International Conference on Machine
Learning, pp. 631‚Äì639. PMLR, 2014."
REFERENCES,0.40480274442538594,"Kan Xu, Xuanyi Zhao, Hamsa Bastani, and Osbert Bastani. Group-sparse matrix factorization for
transfer learning of word embeddings. In International Conference on Machine Learning, 2021."
REFERENCES,0.4065180102915952,"Yi Yu, Tengyao Wang, and Richard J Samworth. A useful variant of the davis‚Äìkahan theorem for
statisticians. Biometrika, 102(2):315‚Äì323, 2015."
REFERENCES,0.40823327615780447,"Dongruo Zhou, Lihong Li, and Quanquan Gu. Neural contextual bandits with ucb-based exploration.
In International Conference on Machine Learning, pp. 11492‚Äì11502. PMLR, 2020."
REFERENCES,0.4099485420240137,Under review as a conference paper at ICLR 2022
REFERENCES,0.411663807890223,"A
ADDITIONAL RELATED WORK"
REFERENCES,0.41337907375643224,"Low-rank matrix factorization. Our notion of functional identiÔ¨Åcation for quadratic neural network
is related to the low-rank matrix factorization literature. However, they impose a low-rank structure
on the matrix to recover, and hence typically require extra conditions to identify the matrix‚Äîe.g., the
restricted isometry property (RIP) (Candes & Plan, 2011; Ge et al., 2017a), or bounded ‚Ñì2 norm of
noise vector (Kabanava et al., 2016). In contrast, we consider a more general case and do not assume
any underlying structure of the matrix; in particular, since our goal is to capture over-parameterization
of neural networks, our matrix is usually decomposed as œÜ = Œ∏Œ∏‚ä§, where Œ∏ ‚ààRd√ók and k ‚â•d (and
œÜ is not necessarily low-rank). Also, we study the prediction error of neural networks in the presence
of distribution shifts, whereas the goal of the low-rank literature is to recover the true matrix."
REFERENCES,0.41509433962264153,"Multi-armed bandits. Prior literature on parameterized bandits has considered a number of func-
tional forms, ranging from linear (Abbasi-Yadkori et al., 2011; Rusmevichientong & Tsitsiklis, 2010)
to neural tangent kernels (Zhou et al., 2020). Most of this work makes a realizability assumption that
the model family contains the true model;3 implicitly, they consider model families where there is a
unique, identiÔ¨Åable true parameter. These assumptions are necessary precisely due to the fact that the
test and training distributions are different; thus, much of the bandit literature has focused on proving
parameter identiÔ¨Åcation results to enable learning. In contrast, the identiÔ¨Åability assumption does
not hold for quadratic neural networks because they are invariant to parameter transformations. To
the best of our knowledge, we consider the Ô¨Årst over-parameterized bandit problem that considers a
model that is not parameter-identiÔ¨Åable; we Ô¨Ånd that similar regret results hold as long as the function
represented by the model can be identiÔ¨Åed. Separately, Foster & Rakhlin (2020) makes a general
connection between online regression oracles and the regret of a bandit algorithm; however, their
approach only provides good guarantees when the regression oracle returns a model that generalizes
off-distribution. Finally, recent work on UCB with neural tangent kernels (Zhou et al., 2020) provides
general regret bounds, but their bound is only sublinear under conditions such as the true reward
function having small RKHS norm (see Remark 4.8 in their paper), which amounts to assuming they
can recover the true parameters."
REFERENCES,0.41680960548885077,"Novelty. We brieÔ¨Çy discuss the novelty of our results compared to existing work. First, the results in
Section 3 are novel. To the best of our knowledge, the proof strategy in our main result, Theorem 3.6,
is novel, though we note that the preceding lemmas are based on standard arguments‚Äîe.g., bounding
the convexity of ÀúLp(œÜ) (Lemma 3.3) and the Lipschitz constant (Lemma 3.4) of ÀúfœÜ; also, Lemma 3.5
relies on a standard covering number argument. For our applications to bandits and transfer learning,
our key novel results are Lemma C.3 for bandits, which proves smoothed bounded response for
quadratic neural networks, and Lemma D.1 for transfer learning. Finally, to the best of our knowledge,
our arguments in Section 6 are novel."
REFERENCES,0.41852487135506006,"3Slightly different from realizability in PAC learning (Kearns et al., 1994), which says there is a model with
zero true loss."
REFERENCES,0.4202401372212693,Under review as a conference paper at ICLR 2022
REFERENCES,0.4219554030874786,"B
PROOFS FOR SECTION 3"
REFERENCES,0.4236706689536878,"B.1
PROOF OF MINIMUM EIGENVALUE FOR UNIFORM DISTRIBUTION"
REFERENCES,0.42538593481989706,"In this section, we prove the claim that Assumption 3.2 holds for the covariate distribution where xi
is an i.i.d. random variable with distribution Uniform(xi; [‚àí1/2, 1/2]). To this end, note that"
REFERENCES,0.42710120068610635,"Ep(x)[(x‚ä§‚àÜx)2] = Ep(x) Ô£Æ Ô£ØÔ£∞ Ô£´ Ô£≠
d
X"
REFERENCES,0.4288164665523156,"i,j=1
xixj‚àÜij Ô£∂ Ô£∏ 2Ô£π Ô£∫Ô£ª"
REFERENCES,0.4305317324185249,= Ep(x) Ô£Æ Ô£∞X
REFERENCES,0.4322469982847341,"i
x4
i ‚àÜ2
ii +
X"
REFERENCES,0.4339622641509434,"iÃ∏=j
x2
i x2
j‚àÜii‚àÜjj + 2
X"
REFERENCES,0.43567753001715265,"iÃ∏=j
x2
i x2
j‚àÜ2
ij Ô£π Ô£ª = 1 80 X"
REFERENCES,0.43739279588336194,"i
‚àÜ2
ii +
1
144 X"
REFERENCES,0.4391080617495712,"iÃ∏=j
‚àÜii‚àÜjj + 1 72 X"
REFERENCES,0.44082332761578047,"iÃ∏=j
‚àÜ2
ij =
 1"
REFERENCES,0.4425385934819897,"80 ‚àí
1
144  X"
REFERENCES,0.444253859348199,"i
‚àÜ2
ii +
1
144 X i
‚àÜii !2 + 1 72 X"
REFERENCES,0.44596912521440824,"iÃ∏=j
‚àÜ2
ij"
REFERENCES,0.44768439108061747,"‚â•
1
180‚à•‚àÜ‚à•2
F ,"
REFERENCES,0.44939965694682676,as claimed.
REFERENCES,0.451114922813036,"B.2
PROOF OF LEMMA 3.3"
REFERENCES,0.4528301886792453,"We use the notation U : ‚àá2f(œÜ) : V to denote the matrix inner product ‚ü®U, ‚àá2f(œÜ)(V )‚ü©for
U, V ‚ààRd√ód. The Hessian ‚àá2f(œÜ) can be viewed as a d2 √ó d2 matrix. As everything here is
bounded, we can exchange the expectation and differentiation. Therefore, the Hessian of our loss
function has for any symmetric matrix ‚àÜ
‚àÜ: ‚àá2 ÀúLp(œÜ) : ‚àÜ= 2Ep(x)[(x‚ä§‚àÜx)2] ‚â•2Œ±‚à•‚àÜ‚à•2
F ,
where the last inequality uses Assumption 3.2."
REFERENCES,0.45454545454545453,"B.3
PROOF OF LEMMA 3.4"
REFERENCES,0.4562607204116638,"By our deÔ¨Ånition, for any œÜ, œÜ‚Ä≤ ‚ààŒ¶,
| ÀúfœÜ(x) ‚àíÀúfœÜ‚Ä≤(x)| = |(x‚ä§(œÜ ‚àíœÜ‚Ä≤)x)2| ‚â§x2
max‚à•œÜ ‚àíœÜ‚Ä≤‚à•F .
Given our quadratic loss function, we have
|( ÀúfœÜ(x) ‚àíÀúfœÜ‚àó(x))2 ‚àí( ÀúfœÜ‚Ä≤(x) ‚àíÀúfœÜ‚àó(x))2|"
REFERENCES,0.45797598627787306,‚â§| ÀúfœÜ(x) ‚àíÀúfœÜ‚àó(x) + ÀúfœÜ‚Ä≤(x) ‚àíÀúfœÜ‚àó(x)|| ÀúfœÜ(x) ‚àíÀúfœÜ‚Ä≤(x)|
REFERENCES,0.45969125214408235,"‚â§4œÜmaxx4
max‚à•œÜ ‚àíœÜ‚Ä≤‚à•F .
Next, the true loss satisÔ¨Åes
|ÀúLp(œÜ) ‚àíÀúLp(œÜ‚Ä≤)| ‚â§Ep(x)[|( ÀúfœÜ(x) ‚àíÀúfœÜ‚àó(x))2 ‚àí( ÀúfœÜ‚Ä≤(x) ‚àíÀúfœÜ‚àó(x))2|] ‚â§4œÜmaxx4
max‚à•œÜ ‚àíœÜ‚Ä≤‚à•F .
Finally, the empirical loss satisÔ¨Åes"
REFERENCES,0.4614065180102916,|ÀÜÀúL(œÜ; Z) ‚àíÀÜÀúL(œÜ‚Ä≤; Z)| =
N,0.4631217838765009,"1
n n
X"
N,0.4648370497427101,"i=1
[( ÀúfœÜ(xi) ‚àíyi)2 ‚àí( ÀúfœÜ‚Ä≤(xi) ‚àíyi)2]  ‚â§1 n n
X"
N,0.4665523156089194,"i=1
|( ÀúfœÜ(xi) ‚àíÀúfœÜ‚àó(xi))2 ‚àí( ÀúfœÜ‚Ä≤(xi) ‚àíÀúfœÜ‚àó(xi))2| + 1 n n
X"
N,0.46826758147512865,"i=1
|Œæi| ¬∑ | ÀúfœÜ(xi) ‚àíÀúfœÜ‚Ä≤(xi)|"
N,0.4699828473413379,"‚â§(4œÜmaxx4
max + 2Œæmaxx2
max)‚à•œÜ ‚àíœÜ‚Ä≤‚à•F ,
as claimed."
N,0.4716981132075472,Under review as a conference paper at ICLR 2022
N,0.4734133790737564,"B.4
PROOF OF LEMMA 3.5"
N,0.4751286449399657,"First, we have the following results:
Lemma B.1 (Covering Number of Euclidean Ball). For a Euclidean ball in Rn1√ón2 with radius R
with respect to Frobenius norm, there exists an œµ-net E such that"
N,0.47684391080617494,"|E| ‚â§

1 + 2R œµ"
N,0.47855917667238423,"n1n2
."
N,0.48027444253859347,Proof. This claim follows by a direct application of Proposition 4.2.12 in Vershynin (2018).
N,0.48198970840480276,"Lemma B.2 (Hoeffding‚Äôs Inequality for Subgaussian Random Variables). Letting {zi}n
i=1 be a set
of independent œÉ-subgaussian random variables, then for all t ‚â•0, we have Pr ""
1
n n
X"
N,0.483704974271012,"i=1
zi ‚â•t #"
N,0.4854202401372213,"‚â§exp

‚àí2nt2 œÉ2 
."
N,0.48713550600343053,Proof. See Proposition 2.1 of Wainwright (2016).
N,0.4888507718696398,"Now, we prove Lemma 3.5. Consider an œµ/(4K)-net E. Then, for any œÜ ‚ààŒ¶, there exists œÜ‚Ä≤ ‚ààE
such that"
N,0.49056603773584906,|(ÀÜÀúL(œÜ; Z) ‚àíÀúLp(œÜ)) ‚àí(ÀÜÀúL(œÜ‚Ä≤; Z) ‚àíÀúLp(œÜ‚Ä≤))| ‚â§2K‚à•œÜ ‚àíœÜ‚Ä≤‚à•F ‚â§œµ 2.
N,0.4922813036020583,"Therefore, we have Pp(Z)"
N,0.4939965694682676,"
sup
Œ∏
|ÀÜL(g(Œ∏); Z) ‚àíLp(g(Œ∏)) ‚àíœÉ(Z)| ‚â•œµ
"
N,0.4957118353344768,"= Pp(Z) """
N,0.4974271012006861,"sup
œÜ‚ààŒ¶
|ÀÜÀúL(œÜ; Z) ‚àíÀúLp(œÜ) ‚àíœÉ(Z)| ‚â•œµ #"
N,0.49914236706689535,‚â§Pp(Z)
N,0.5008576329331046,"
max
œÜ‚ààE |ÀÜÀúL(œÜ; Z) ‚àíÀúLp(œÜ) ‚àíœÉ(Z)| ‚â•œµ 2  ‚â§
X"
N,0.5025728987993139,"œÜ‚ààE
Pp(Z)
h
|ÀÜÀúL(œÜ; Z) ‚àíÀúLp(œÜ) ‚àíœÉ(Z)| ‚â•œµ 2"
N,0.5042881646655232,"i
.
(13)"
N,0.5060034305317325,"Now, deÔ¨Åning"
N,0.5077186963979416,"¬ØÀúL(œÜ; Z) = 1 n n
X"
N,0.5094339622641509,"i=1
( ÀúfœÜ(xi) ‚àíÀúfœÜ‚àó(xi))2
and
ÀúŒ∑(œÜ; Z) = 1 n n
X"
N,0.5111492281303602,"i=1
( ÀúfœÜ(xi) ‚àíÀúfœÜ‚àó(xi))Œæi,"
N,0.5128644939965694,"and recalling that œÉ(Z) = n‚àí1 Pn
i=1 Œæ2
i , then we have"
N,0.5145797598627787,ÀÜÀúL(œÜ; Z) = ¬ØÀúL(œÜ; Z) + 2ÀúŒ∑(œÜ; Z) + œÉ(Z).
N,0.516295025728988,"Thus, continuing from (13), we have
X"
N,0.5180102915951973,"œÜ‚ààE
Pp(Z)
h
|ÀÜÀúL(œÜ; Z) ‚àíÀúLp(œÜ) ‚àíœÉ(Z)| ‚â•œµ 2 i ‚â§
X"
N,0.5197255574614065,"œÜ‚ààE
Pp(Z)
h
|¬ØÀúL(œÜ; Z) ‚àíÀúLp(œÜ)| + 2|ÀúŒ∑(œÜ; Z)| ‚â•œµ 2 i ‚â§
X œÜ‚ààE"
N,0.5214408233276158,"
Pp(Z)
h
|¬ØÀúL(œÜ; Z) ‚àíÀúLp(œÜ)| ‚â•œµ 6"
N,0.5231560891938251,"i
+ Pp(Z)
h
|ÀúŒ∑(œÜ; Z)| ‚â•œµ 6"
N,0.5248713550600344,"i
.
(14)"
N,0.5265866209262435,"For the Ô¨Årst term in (14), note that |( ÀúfœÜ(x) ‚àíÀúfœÜ‚àó(x))2| ‚â§‚Ñì2
max, so ( ÀúfœÜ(x) ‚àíÀúfœÜ‚àó(x))2 is ‚Ñì2
max-
subgaussian; thus, by Lemma B.2, we have
X"
N,0.5283018867924528,"œÜ‚ààE
Pp(Z)
h
|¬ØÀúL(œÜ; Z) ‚àíÀúLp(œÜ)| ‚â•œµ 6"
N,0.5300171526586621,"i
‚â§2|E| ¬∑ exp

‚àínœµ2"
N,0.5317324185248714,18‚Ñì4max
N,0.5334476843910806,"
.
(15)"
N,0.5351629502572899,Under review as a conference paper at ICLR 2022
N,0.5368782161234992,"Next, for the second term in (14), note that |( ÀúfœÜ(xi)‚àíÀúfœÜ‚àó(xi))Œæi| ‚â§‚ÑìmaxŒæmax, so ( ÀúfœÜ(xi)‚àíÀúfœÜ‚àó(xi))Œæi
is ‚ÑìmaxŒæmax-subgaussian; thus, by Lemma B.2, we have
X"
N,0.5385934819897084,"œÜ‚ààE
Pp(Z)
h
|ÀúŒ∑(œÜ; Z)| ‚â•œµ 6"
N,0.5403087478559176,"i
‚â§2|E| ¬∑ exp

‚àí
nœµ2"
N,0.5420240137221269,18‚Ñì2maxŒæ2max
N,0.5437392795883362,"
.
(16)"
N,0.5454545454545454,"Combining (15) & (16), continuing from (14), we have
X œÜ‚ààE"
N,0.5471698113207547,"
Pp(Z)
h
|¬ØÀúL(œÜ; Z) ‚àíÀúLp(œÜ)| ‚â•œµ 6"
N,0.548885077186964,"i
+ Pp(Z)
h
|ÀúŒ∑(œÜ; Z)| ‚â•œµ 6 i"
N,0.5506003430531733,"‚â§4|E| ¬∑ exp

‚àí
nœµ2"
N,0.5523156089193825,18‚Ñì2max(‚Ñì2max + Œæ2max) 
N,0.5540308747855918,"‚â§2

1 + 8œÜmaxK œµ d2"
N,0.5557461406518011,"¬∑ exp

‚àí
nœµ2"
N,0.5574614065180102,18‚Ñì2max(‚Ñì2max + Œæ2max) 
N,0.5591766723842195,"= 2 exp

‚àí
nœµ2"
N,0.5608919382504288,"18‚Ñì2max(‚Ñì2max + Œæ2max) + d2 log

1 + 8œÜmaxK œµ"
N,0.5626072041166381,"
,
(17)"
N,0.5643224699828473,"where for the Ô¨Årst inequality, we have used max{‚Ñì2
max, Œæ2
max} ‚â§‚Ñì2
max +Œæ2
max, and the second inequality
follows since by Lemma B.1, the covering number of the œµ-net E of Œ¶ satisÔ¨Åes"
N,0.5660377358490566,"|E| ‚â§

1 + 2œÜmax œµ d2 ."
N,0.5677530017152659,"Finally, we choose œµ so that (17) is smaller than Œ¥‚Äîin particular, letting œµ = s"
N,0.5694682675814752,18‚Ñì2max(‚Ñì2max + Œæ2max) n
N,0.5711835334476844,"
d2 max

1, log

1 + 8œÜmaxKn ‚Ñì2max"
N,0.5728987993138936,"
+ log 2 Œ¥ 
."
N,0.5746140651801029,"then continuing (17), we have"
EXP,0.5763293310463122,"2 exp

‚àí
nœµ2"
EXP,0.5780445969125214,"18‚Ñì2max(‚Ñì2max + Œæ2max) + d2 log

1 + 8œÜmaxK œµ"
EXP,0.5797598627787307,"
‚â§Œ¥,"
EXP,0.58147512864494,as claimed.
EXP,0.5831903945111492,"B.5
PROOF OF PROPOSITION 3.8"
EXP,0.5849056603773585,ÀÜÀúL(œÜ; Z) is twice differentiable and convex in œÜ. Note that the minimization problem of ÀÜL(Œ∏; Z) is
EXP,0.5866209262435678,"equivalent to that of ÀÜÀúL(g(ÀÜŒ∏); Z). We consider two cases. First, consider the case where ÀÜŒ∏ has rank d."
EXP,0.5883361921097771,"The Ô¨Årst order condition ‚àáÀÜL(Œ∏; Z) = 0 is the same as ‚àáÀÜÀúL(g(ÀÜŒ∏); Z) = 0, which gives"
EXP,0.5900514579759862,"‚àáÀÜÀúL(ÀÜœÜ; Z)ÀÜŒ∏ = 0.
(18)"
EXP,0.5917667238421955,"As ÀÜŒ∏ is of full row rank, there exists a matrix ÀÜŒ∏‚Ä† ‚ààRk√ód such that ÀÜŒ∏ÀÜŒ∏‚Ä† = I (e.g. ÀÜŒ∏‚Ä† = ÀÜŒ∏‚ä§(ÀÜŒ∏ÀÜŒ∏‚ä§)‚àí1).
We can right multiply the above equation by ÀÜŒ∏‚Ä† and obtain that"
EXP,0.5934819897084048,‚àáÀÜÀúL(ÀÜœÜ; Z) = 0.
EXP,0.5951972555746141,"As ÀÜÀúL(œÜ; Z) is convex in œÜ, the above implies ÀÜœÜ = g(ÀÜŒ∏) is a global minimum of ÀÜÀúL(œÜ; Z). Therefore,
ÀÜŒ∏ is a global minimum of ÀÜL(Œ∏; Z). Next, consider the case where the rank of ÀÜŒ∏ is smaller than d. In
this case, we follow the proof strategy in Proposition 4 in Bach et al. (2008); we provide here for
completeness. In this case, Equation (18) still holds, which implies"
EXP,0.5969125214408233,"0 = ‚àáÀÜÀúL(ÀÜœÜ; Z)ÀÜŒ∏ÀÜŒ∏‚ä§= ‚àáÀÜÀúL(ÀÜœÜ; Z)ÀÜœÜ.
(19)"
EXP,0.5986277873070326,The Hessian of ÀÜÀúL(g(ÀÜŒ∏); Z) has
EXP,0.6003430531732419,"‚àá2 ÀÜÀúL(g(ÀÜŒ∏); Z)(‚àÜ, ‚àÜ) = 2‚ü®‚àáÀÜÀúL(ÀÜœÜ; Z), ‚àÜ‚àÜ‚ä§‚ü©+ ‚àá2 ÀÜÀúL(ÀÜœÜ; Z)(ÀÜŒ∏‚àÜ‚ä§+ ‚àÜÀÜŒ∏‚ä§, ÀÜŒ∏‚àÜ‚ä§+ ‚àÜÀÜŒ∏‚ä§)."
EXP,0.6020583190394511,Under review as a conference paper at ICLR 2022
EXP,0.6037735849056604,"As ÀÜŒ∏R is also a local minimum for any orthogonal matrix R (i.e., RR‚ä§= R‚ä§R = I), we can Ô¨Ånd a
ÀÜŒ∏ with the last column being 0 by right multiplying certain R. Then, consider any ‚àÜwith the Ô¨Årst
k ‚àí1 columns being 0 and the last column being any u ‚ààRd. With this choice of ‚àÜand ÀÜŒ∏, ÀÜŒ∏‚àÜ‚ä§= 0.
Therefore,"
EXP,0.6054888507718696,"‚àá2 ÀÜÀúL(g(ÀÜŒ∏); Z)(‚àÜ, ‚àÜ) = 2u‚ä§‚àáÀÜÀúL(ÀÜœÜ; Z)u."
EXP,0.6072041166380789,"Since ÀÜŒ∏ is a local minimum of ÀÜÀúL(g(ÀÜŒ∏); Z), it holds that ‚àá2 ÀÜÀúL(g(ÀÜŒ∏); Z)(‚àÜ, ‚àÜ) ‚â•0, which implies"
EXP,0.6089193825042881,"‚àáÀÜÀúL(ÀÜœÜ; Z) ‚™∞0.
(20)"
EXP,0.6106346483704974,Equation (19) and (20) together comprise the Ô¨Årst order conditions of the convex minimization
EXP,0.6123499142367067,"problem minœÜ‚™∞0 ÀÜÀúL(œÜ; Z). Thus, ÀÜŒ∏ is also a global minimum."
EXP,0.614065180102916,"C
PROOFS FOR SECTION 4"
EXP,0.6157804459691252,"First, we provide the full statement of Theorem 4.2 (including constants).
Theorem C.1. The expected regret of Algorithm 1 is"
EXP,0.6174957118353345,"R(T) ‚â§C0 + C1 ¬∑ T 2/3

log

3 + 8œÜmaxKT ‚Ñì2max"
EXP,0.6192109777015438,"1/3
, where"
EXP,0.6209262435677531,"C0 =
64(œÜmax)"
EXP,0.6226415094339622,"2d2+2
2d2‚àí1"
EXP,0.6243567753001715,(135M(‚Ñìmax + Œæmax)2d3)
EXP,0.6260720411663808,"2d2+2
2d2‚àí1 (8œÜmaxK/‚Ñì2max) 3d2"
EXP,0.62778730703259,"2d2‚àí1
,"
EXP,0.6295025728987993,C1 = 162d2(M 2(‚Ñìmax + Œæmax)4œÜmax)1/3.
EXP,0.6312178387650086,"Before we prove Theorem C.1, we Ô¨Årst prove a preliminary result establishing an analog of the
smooth best arm response property Rusmevichientong & Tsitsiklis (2010) to our setting. First, we
have the following useful result:
Lemma C.2. Let œÜ, œÜ‚Ä≤ ‚ààRd√ód be symmetric matrices, let x, x‚Ä≤ ‚ààRd be eigenvectors of œÜ, œÜ‚Ä≤
corresponding to their top eigenvalue, such that ‚à•x‚à•2 = ‚à•x‚Ä≤‚à•2 = 1, and let Œª1 ‚â•Œª2 ‚â•... ‚â•Œªd be
the eigenvalues of œÜ‚Ä≤. Suppose that ‚ü®x, x‚Ä≤‚ü©‚â•0. Then, we have"
EXP,0.6329331046312179,‚à•x ‚àíx‚Ä≤‚à•2 ‚â§23/2‚à•œÜ ‚àíœÜ‚Ä≤‚à•2
EXP,0.6346483704974271,"Œª1 ‚àíŒª2
."
EXP,0.6363636363636364,Proof. See Corollary 3 of Yu et al. (2015).
EXP,0.6380789022298456,"Next, let œá : Rd√ód ‚Üí2X denote the subset of reward-maximizing arms for g(Œ∏) = Œ∏Œ∏‚ä§‚Äîi.e.,"
EXP,0.6397941680960549,"œá(œÜ) = arg max
x‚ààX
x‚ä§œÜx,"
EXP,0.6415094339622641,"where the argmax returns the set of all optimal values. Then, we have the following analog of smooth
best arm response:
Lemma C.3. For any œÜ ‚ààRd√ód, there exists x ‚ààœá(œÜ) and x‚àó‚ààœá(œÜ‚àó) such that"
EXP,0.6432246998284734,‚à•x ‚àíx‚àó‚à•2 ‚â§M‚à•œÜ ‚àíœÜ‚àó‚à•F .
EXP,0.6449399656946827,"Proof. First, note that x, x‚àóare eigenvectors of œÜ, œÜ‚àócorresponding to their top eigenvalues, re-
spectively. Next, note that if x‚àó‚ààœá(œÜ‚àó), then we also have ‚àíx‚àó‚ààœá(œÜ‚àó); thus, without loss of
generality, we can assume that ‚ü®x‚àó, x‚ü©‚â•0. Also, note that ‚à•x‚à•2 = ‚à•x‚àó‚à•2 = 1 since the optimizer
maximizes the magnitude of x. Thus, we have"
EXP,0.6466552315608919,‚à•x ‚àíx‚àó‚à•2 ‚â§23/2‚à•œÜ ‚àíœÜ‚àó‚à•2
EXP,0.6483704974271012,"Œª1 ‚àíŒª2
‚â§M‚à•œÜ ‚àíœÜ‚àó‚à•F ,"
EXP,0.6500857632933105,"where the second inequality follows by by Lemma C.2, and the third inequality follows by Assump-
tion 4.1, as claimed."
EXP,0.6518010291595198,Under review as a conference paper at ICLR 2022
EXP,0.6535162950257289,"Now, we prove Theorem C.1. The cumulative regret R(T) of a horizon of T has that"
EXP,0.6552315608919382,"R(T) = E "" T
X"
EXP,0.6569468267581475,"t=1
(fŒ∏‚àó(x‚àó) ‚àífŒ∏‚àó(xt)) # = E "" m
X"
EXP,0.6586620926243568,"t=1
(fŒ∏‚àó(x‚àó) ‚àífŒ∏‚àó(xt)) + T
X"
EXP,0.660377358490566,"t=m+1
(fŒ∏‚àó(x‚àó) ‚àífŒ∏‚àó(xt)) #"
EXP,0.6620926243567753,"‚â§2mœÜmax + E ""
T
X"
EXP,0.6638078902229846,"t=m+1
‚ü®g(ÀÜŒ∏) ‚àíg(Œ∏‚àó), ÀÜxÀÜx‚ä§‚àíx‚àóx‚àó‚ä§‚ü©+ T
X"
EXP,0.6655231560891939,"t=m+1
‚ü®g(ÀÜŒ∏), x‚àóx‚àó‚ä§‚àíÀÜxÀÜx‚ä§‚ü© # , (21)"
EXP,0.6672384219554031,"where ÀÜŒ∏ is an estimator that minimizes the empirical loss of the Ô¨Årst m samples, ÀÜx ‚ààœá(g(ÀÜŒ∏))
maximizes the estimated expected reward fÀÜŒ∏(x), and ‚ü®œÜ, œÜ‚Ä≤‚ü©= Pd
i,j=1 œÜijœÜ‚Ä≤
ij is the matrix inner
product. Since ÀÜx is a maximizer of fÀÜŒ∏(x) = ‚ü®g(ÀÜŒ∏), xx‚ä§‚ü©, we have ‚ü®g(ÀÜŒ∏), x‚àóx‚àó‚ä§‚àíÀÜxÀÜx‚ä§‚ü©‚â§0. Thus,
continuing from (21), we have"
EXP,0.6689536878216124,"R(T) ‚â§2mœÜmax + E ""
T
X"
EXP,0.6706689536878216,"t=m+1
‚ü®g(ÀÜŒ∏) ‚àíg(Œ∏‚àó), ÀÜxÀÜx‚ä§‚àíx‚àóx‚àó‚ä§‚ü© #"
EXP,0.6723842195540308,"‚â§2mœÜmax + (T ‚àím)E
h
‚à•g(ÀÜŒ∏) ‚àíg(Œ∏‚àó)‚à•F ‚à•ÀÜxÀÜx‚ä§‚àíx‚àóx‚àó‚ä§‚à•F
i
.
(22)"
EXP,0.6740994854202401,"To bound the second term in (22), note that"
EXP,0.6758147512864494,"‚à•ÀÜxÀÜx‚ä§‚àíx‚àóx‚àó‚ä§‚à•F ‚â§‚à•ÀÜxÀÜx‚ä§‚àíÀÜxx‚àó‚ä§‚à•F + ‚à•ÀÜxx‚àó‚ä§‚àíx‚àóx‚àó‚ä§‚à•F ‚â§2M‚à•g(ÀÜŒ∏) ‚àíg(Œ∏‚àó)‚à•F ,"
EXP,0.6775300171526587,"where the last step follows by Lemma C.3. Next, by Theorem 3.6, we have"
EXP,0.6792452830188679,‚à•g(ÀÜŒ∏) ‚àíg(Œ∏‚àó)‚à•F ‚â§ r 2œµ Œ±
EXP,0.6809605488850772,"= d
453‚Ñì2
max(‚Ñì2
max + Œæ2
max)
10m"
EXP,0.6826758147512865,"
d2 max

1, log

1 + 8œÜmaxKm ‚Ñì2max"
EXP,0.6843910806174958,"
+ log 2 Œ¥ 1/4"
EXP,0.6861063464837049,"with probability at least 1 ‚àíŒ¥. Now, deÔ¨Åning the event G = ("
EXP,0.6878216123499142,"‚à•g(ÀÜŒ∏) ‚àíg(Œ∏‚àó)‚à•F ‚â§ r 2œµ Œ± ) ,"
EXP,0.6895368782161235,letting
EXP,0.6912521440823327,"Œ¥ = 2 exp

‚àíd2 max

1, log

1 + 8œÜmaxKm ‚Ñì2max 
,"
EXP,0.692967409948542,"and continuing from (22), we have"
EXP,0.6946826758147513,"R(T) ‚â§2mœÜmax + T ¬∑ E
h
‚à•g(ÀÜŒ∏) ‚àíg(Œ∏‚àó)‚à•F ‚à•ÀÜxÀÜx‚ä§‚àíx‚àóx‚àó‚ä§‚à•F 1(G)
i
+ 4TœÜmax ¬∑ P(Gc)"
EXP,0.6963979416809606,"‚â§2mœÜmax + 2MT ¬∑ E
h
‚à•g(ÀÜŒ∏) ‚àíg(Œ∏‚àó)‚à•2
F
 G
i
+ 4TœÜmax ¬∑ P(Gc)"
EXP,0.6981132075471698,‚â§2mœÜmax + 270M(‚Ñìmax + Œæmax)2d3T r
EXP,0.6998284734133791,log(3 + 8œÜmaxKT/‚Ñì2max)
EXP,0.7015437392795884,"m
+
8TœÜmax
(8œÜmaxKm/‚Ñì2max)d2 . (23)"
EXP,0.7032590051457976,The third term in inequality (23) is smaller than the second term when m ‚â•
EXP,0.7049742710120068,"4œÜmax
135M(‚Ñìmax + Œæmax)2d3(8œÜmaxK/‚Ñì2max)d2p"
EXP,0.7066895368782161,log(3 + 8œÜmaxKT/‚Ñì2max)
EXP,0.7084048027444254,!1/(d2‚àí1/2)
EXP,0.7101200686106347,".
(24)"
EXP,0.7118353344768439,Under review as a conference paper at ICLR 2022
EXP,0.7135506003430532,"For a choice of m satisfying (24), continuing from (23), we have"
EXP,0.7152658662092625,R(T) ‚â§2mœÜmax + 540M(‚Ñìmax + Œæmax)2d3T r
EXP,0.7169811320754716,log(3 + 8œÜmaxKT/‚Ñì2max)
EXP,0.7186963979416809,"m
.
(25)"
EXP,0.7204116638078902,"Next, we choose m to minimize the upper bound in (24) for sufÔ¨Åciently large T‚Äîin particular, m = Ô£Æ Ô£ØÔ£ØÔ£Ø"
EXP,0.7221269296740995,"135M(‚Ñìmax + Œæmax)2d3T
p"
EXP,0.7238421955403087,"log(3 + 8œÜmaxKT/‚Ñì2max)
œÜmax ! 2 3 Ô£π"
EXP,0.725557461406518,"Ô£∫Ô£∫Ô£∫
.
(26)"
EXP,0.7272727272727273,"With this choice of m, we have"
EXP,0.7289879931389366,"R(T) ‚â§162(M 2(‚Ñìmax + Œæmax)4œÜmax)
1
3 d2T 2/3(log(3 + 8œÜmaxKT/‚Ñì2
max))
1
3 ."
EXP,0.7307032590051458,"Finally, note that (24) holds under the choice of m in (26) for T satisfying T
p"
EXP,0.7324185248713551,"log(3 + 8œÜmaxKT/‚Ñì2max) ‚â•
64(œÜmax)"
EXP,0.7341337907375644,"2d2+2
2d2‚àí1"
EXP,0.7358490566037735,(135M(‚Ñìmax + Œæmax)2d3)
EXP,0.7375643224699828,"2d2+2
2d2‚àí1 (8œÜmaxK/‚Ñì2max) 3d2"
EXP,0.7392795883361921,"2d2‚àí1
."
EXP,0.7409948542024014,The claim follows.
EXP,0.7427101200686106,"D
PROOF OF THEOREM 5.2"
EXP,0.7444253859348199,"First, we have the following key result:"
EXP,0.7461406518010292,"Lemma D.1. Let Œ∏, Œ∏‚Ä≤ ‚ààRd√ók, and let œÜ = Œ∏Œ∏‚ä§and œÜ‚Ä≤ = Œ∏‚Ä≤Œ∏‚Ä≤‚ä§. Assume that ‚à•œÜ ‚àíœÜ‚Ä≤‚à•F ‚â§Œ∑, and
that œÉmin(Œ∏) ‚â•œÉ0 > 0, where œÉmin(Œ∏) is the minimum singular value of Œ∏ (more precisely, the dth
largest singular value). Then, there exist orthogonal matrices R, R‚Ä≤ ‚ààRk√ók such that"
EXP,0.7478559176672385,‚à•Œ∏R ‚àíŒ∏‚Ä≤R‚Ä≤‚à•F ‚â§Œ∑
EXP,0.7495711835334476,"œÉ0
.
(27)"
EXP,0.7512864493996569,"Proof. Consider the SVDs Œ∏ = UŒ£V ‚ä§and Œ∏‚Ä≤ = U ‚Ä≤Œ£‚Ä≤V ‚Ä≤‚ä§, where U, U ‚Ä≤ ‚ààRd√ód, Œ£, Œ£‚Ä≤ ‚ààRd√ód,
and V, V ‚Ä≤ ‚ààRk√ód; then, we have œÜ = UŒ£2U ‚ä§and œÜ‚Ä≤ = U ‚Ä≤Œ£‚Ä≤2U ‚Ä≤‚ä§. Then, we claim that the choices
R = V U ‚ä§and R‚Ä≤ = V ‚Ä≤U ‚Ä≤‚ä§satisfy (27). In particular, note that Œ∏R = UŒ£U ‚ä§and Œ∏‚Ä≤R‚Ä≤ = U ‚Ä≤Œ£‚Ä≤U ‚Ä≤‚ä§,
since V ‚ä§V = V ‚Ä≤‚ä§V ‚Ä≤ = Id since k ‚â•d, where Id ‚ààRd√ód is the d-dimensional identity matrix.
Thus, it sufÔ¨Åces to show that"
EXP,0.7530017152658662,"œÉ0‚à•UŒ£U ‚ä§‚àíU ‚Ä≤Œ£‚Ä≤U ‚Ä≤‚ä§‚à•F ‚â§Œ∑.
(28)"
EXP,0.7547169811320755,"To this end, note that"
EXP,0.7564322469982847,"Œ∑ ‚â•‚à•œÜ ‚àíœÜ‚Ä≤‚à•F = ‚à•UŒ£2U ‚ä§‚àíU ‚Ä≤Œ£‚Ä≤2U ‚Ä≤‚ä§‚à•F = ‚à•U ‚Ä≤‚ä§UŒ£2 ‚àíŒ£‚Ä≤2U ‚Ä≤‚ä§U‚à•F ,
(29)"
EXP,0.758147512864494,"where in the last step, we have multiplied the expression inside the Frobenius norm by U ‚Ä≤‚ä§on the
left and by U on the right, using the fact that the Frobenius norm is invariant under multiplication by
orthogonal matrices. DeÔ¨Åning W = U ‚Ä≤‚ä§U, note that"
EXP,0.7598627787307033,"(WŒ£)ij = d
X"
EXP,0.7615780445969125,"k=1
WikŒ£kj = WijŒ£jj
(30)"
EXP,0.7632933104631218,"(Œ£W)ij = d
X"
EXP,0.7650085763293311,"k=1
Œ£‚Ä≤
ikWkj = WijŒ£‚Ä≤
ii
(31)"
EXP,0.7667238421955404,"(WŒ£2)ij = d
X"
EXP,0.7684391080617495,"k=1
Wik(Œ£2)kj = WijŒ£2
jj
(32)"
EXP,0.7701543739279588,"(Œ£2W)ij = d
X"
EXP,0.7718696397941681,"k=1
(Œ£‚Ä≤2)ikWkj = WijŒ£‚Ä≤2
ii.
(33)"
EXP,0.7735849056603774,Under review as a conference paper at ICLR 2022
EXP,0.7753001715265866,"Then, continuing from (29), we have"
EXP,0.7770154373927959,"Œ∑2 ‚â•‚à•WŒ£2 ‚àíŒ£‚Ä≤2W‚à•2
F = d
X"
EXP,0.7787307032590052,"i,j=1
W 2
ij(Œ£2
jj ‚àíŒ£‚Ä≤2
ii)2 = d
X"
EXP,0.7804459691252144,"i,j=1
W 2
ij(Œ£jj ‚àíŒ£‚Ä≤
ii)2(Œ£jj + Œ£‚Ä≤
ii)2 ‚â• d
X"
EXP,0.7821612349914236,"i,j=1
W 2
ij(Œ£jj ‚àíŒ£‚Ä≤
ii)2œÉ2
0"
EXP,0.7838765008576329,"= œÉ2
0‚à•WŒ£ ‚àíŒ£‚Ä≤W‚à•2
F
= œÉ2
0‚à•U ‚Ä≤‚ä§UŒ£ ‚àíŒ£‚Ä≤U ‚Ä≤‚ä§U‚à•2
F
= œÉ2
0‚à•UŒ£U ‚ä§‚àíU ‚Ä≤Œ£‚Ä≤U ‚Ä≤‚ä§‚à•2
F ,"
EXP,0.7855917667238422,"where on the Ô¨Årst line, we have used (32) & (33), on the third line we have used Œ£jj ‚â•œÉ0, on the
fourth line we have used (30) & (31), and on the last line we have multiplied on by U ‚Ä≤ on the left
U ‚ä§on the right, again using the fact that the Frobenius norm is invariant under multiplication by
orthogonal matrices. Thus, we have shown (28), so the claim follows."
EXP,0.7873070325900514,"We note here that our result provides an analog of Lemma 6 in Ge et al. (2017a) for quadratic neural
networks."
EXP,0.7890222984562607,"Now, we prove Theorem 5.2. First, by directly applying the arguments in the proof of Theorem 3.6,
we have"
EXP,0.79073756432247,"‚à•g(ÀÜŒ∏p) ‚àíg(Œ∏‚àó
p)‚à•F ‚â§ r 2œµp"
EXP,0.7924528301886793,"Œ±
with probability at least 1 ‚àíŒ¥/2. However, ÀÜŒ∏p itself may not be close to Œ∏‚àó
p. Instead, applying
Lemma D.1 with Œ∏ = ÀÜŒ∏p and Œ∏‚Ä≤ = Œ∏‚àó
p, and with Œ∑ =
p"
EXP,0.7941680960548885,"2œµp/Œ±, there exists an orthogonal matrix
Rp = R‚Ä≤R‚ä§that ‚Äúaligns‚Äù ÀÜŒ∏p with Œ∏‚àó
p, yielding"
EXP,0.7958833619210978,"‚à•ÀÜŒ∏p ‚àíŒ∏‚àó
pRp‚à•F ‚â§1 œÉ0 r 2œµp Œ± ,"
EXP,0.7975986277873071,"where œÉ0 is the minimum singular value of Œ∏‚àó
p. Now, let ÀúŒ∏g = Œ∏‚àó
gRp, and note that this is a global
minimizer (i.e., g(ÀúŒ∏g) = g(Œ∏‚àó
g)), since Rp is orthogonal. Then, we have"
EXP,0.7993138936535163,"‚à•ÀúŒ∏g ‚àíÀÜŒ∏p‚à•F ‚â§‚à•Œ∏‚àó
gRp ‚àíŒ∏‚àó
pRp‚à•F + ‚à•Œ∏‚àó
pRp ‚àíÀÜŒ∏p‚à•F"
EXP,0.8010291595197255,"‚â§‚à•Œ∏‚àó
g ‚àíŒ∏‚àó
p‚à•F + 1 œÉ0 r 2œµp Œ±"
EXP,0.8027444253859348,‚â§B + 1 œÉ0 r 2œµp
EXP,0.8044596912521441,"Œ±
(34)"
EXP,0.8061749571183533,"with probability at least 1 ‚àíŒ¥/2. In other words, an alternative global minimizer ÀúŒ∏g exists within a
small Frobenius norm of our proxy estimator ÀÜŒ∏p, even if ÀÜŒ∏p is not close to Œ∏‚àó
p."
EXP,0.8078902229845626,"Finally, on the event that (34) holds, note that for Œ∏ ‚ààB2(ÀÜŒ∏p, ÀÜB), we have the alternative upper bound"
EXP,0.8096054888507719,"|fŒ∏(x) ‚àífŒ∏‚àóg(x))| ‚â§K‚à•g(Œ∏) ‚àíg(Œ∏‚àó
g)‚à•F ‚â§K ÀÜB,"
EXP,0.8113207547169812,"where the Ô¨Årst inequality holds by Lemma 3.4; thus, we can take ‚Ñìmax = K ÀÜB. Thus, on the event that
(34) holds, by Theorem 3.6, we have Pp(Z)"
EXP,0.8130360205831904,"
Lq(ÀÜŒ∏g) ‚â§2K2œµg Œ±"
EXP,0.8147512864493996,"
‚â•1 ‚àíŒ¥ 2,"
EXP,0.8164665523156089,so the claim follows by a union bound.
EXP,0.8181818181818182,Under review as a conference paper at ICLR 2022
EXP,0.8198970840480274,"E
PROOFS FOR SECTION 6"
EXP,0.8216123499142367,"E.1
PROOF OF PROPOSITION 6.4"
EXP,0.823327615780446,"Suppose that zt ‚àà{0, 1} is binary, z0 = 0, and"
EXP,0.8250428816466552,"Àúp(z | z‚Ä≤) =
1
if z = z‚Ä≤"
EXP,0.8267581475128645,"0
otherwise."
EXP,0.8284734133790738,"In particular, since z0 = 0, p(w) = 1(w = w0) places all weight on the zero sequence w0 = 0...0.
Next, consider the shifted distribution"
EXP,0.8301886792452831,"Àúq(zt | zt‚àí1) = Ô£±
Ô£≤ Ô£≥"
EXP,0.8319039451114922,"1
if z = z‚Ä≤ = 1
1 ‚àíŒ±/2
if z = z‚Ä≤ = 0
Œ±/2
otherwise."
EXP,0.8336192109777015,"Note that ‚à•Àúp(¬∑ | z‚Ä≤) ‚àíÀúq(¬∑ | z‚Ä≤)‚à•TV ‚â§Œ±, so Assumption 6.3 is satisÔ¨Åed. Note that"
EXP,0.8353344768439108,"q(w0) = T
Y"
EXP,0.8370497427101201,"t=1
Àúq(0 | 0) = (1 ‚àíŒ±/2)T ."
EXP,0.8387650085763293,"As a consequence, we have"
EXP,0.8404802744425386,"‚à•p ‚àíq‚à•TV =
X"
EXP,0.8421955403087479,"w‚ààW
|p(w) ‚àíq(w)|"
EXP,0.8439108061749572,"= |p(w0) ‚àíq(w0)| +
X"
EXP,0.8456260720411664,"w‚ààW\{w0}
q(w)"
EXP,0.8473413379073756,= (1 ‚àí(1 ‚àíŒ±/2)T ) + (1 ‚àí(1 ‚àíŒ±/2)T )
EXP,0.8490566037735849,"= 2(1 ‚àí(1 ‚àíŒ±/2)T ),"
EXP,0.8507718696397941,as claimed.
EXP,0.8524871355060034,"E.2
PROOF OF LEMMA 6.5"
EXP,0.8542024013722127,Note that
EXP,0.855917667238422,"‚à•Àúqt ‚àíÀúpt‚à•TV = k
X j=1"
EXP,0.8576329331046312,"Z
|Àúqt(z, j) ‚àíÀúpt(z, j)|dz = k
X j=1 k
X j‚Ä≤=1"
EXP,0.8593481989708405,"Z
1(j = Àúg‚àó(z‚Ä≤, j‚Ä≤)) ¬∑ |Àúq(z | z‚Ä≤)Àúqt‚àí1(z‚Ä≤, j‚Ä≤) ‚àíÀúp(z | z‚Ä≤)Àúpt‚àí1(z‚Ä≤, j‚Ä≤)|dz‚Ä≤dz = k
X j‚Ä≤=1"
EXP,0.8610634648370498,"Z
|Àúq(z | z‚Ä≤)Àúqt‚àí1(z‚Ä≤, j‚Ä≤) ‚àíÀúp(z | z‚Ä≤)Àúpt‚àí1(z‚Ä≤, j‚Ä≤)|dz‚Ä≤dz ‚â§ k
X j‚Ä≤=1"
EXP,0.8627787307032591,"Z
|Àúq(z | z‚Ä≤) ‚àíÀúp(z | z‚Ä≤)| ¬∑ Àúqt‚àí1(z‚Ä≤, j‚Ä≤) + Àúp(z | z‚Ä≤) ¬∑ |Àúqt‚àí1(z‚Ä≤, j‚Ä≤) ‚àíÀúpt‚àí1(z‚Ä≤, j‚Ä≤)|dz‚Ä≤dz ‚â§ k
X j‚Ä≤=1"
EXP,0.8644939965694682,"Z
Œ± ¬∑ Àúqt‚àí1(z‚Ä≤, j‚Ä≤) + |Àúqt‚àí1(z‚Ä≤, j‚Ä≤) ‚àíÀúpt‚àí1(z‚Ä≤, j‚Ä≤)|dz‚Ä≤"
EXP,0.8662092624356775,‚â§Œ± + ‚à•Àúqt‚àí1 ‚àíÀúpt‚àí1‚à•TV.
EXP,0.8679245283018868,"Since q0(z, j) = p0(z, j) for all z ‚ààZ and j ‚àà[k], by induction, ‚à•Àúqt ‚àíÀúpt‚à•TV ‚â§tŒ±. Thus, we have"
EXP,0.869639794168096,"‚à•Àúq ‚àíÀúp‚à•TV ‚â§1 T T
X"
EXP,0.8713550600343053,"t=1
‚à•Àúqt ‚àíÀúpt‚à•‚â§TŒ±,"
EXP,0.8730703259005146,as claimed.
EXP,0.8747855917667239,Under review as a conference paper at ICLR 2022
EXP,0.8765008576329331,"E.3
PROOF OF LEMMA 6.6"
EXP,0.8782161234991424,"First, we prove the following lemma.
Lemma E.1. We have"
EXP,0.8799313893653516,"Àúpt(zt, jt‚àí1) = k
X"
EXP,0.8816466552315609,"j1,...,jt‚àí2"
EXP,0.8833619210977701,"Z  t‚àí1
Y"
EXP,0.8850771869639794,"œÑ=1
1(jœÑ = Àúg‚àó(zœÑ, jœÑ‚àí1)) !"
EXP,0.8867924528301887,"¬∑ p(z1, ..., zt)dz1...dzt‚àí1."
EXP,0.888507718696398,"Proof. For the base case, we have"
EXP,0.8902229845626072,"Àúp2(z2, j1) = k
X j0=1"
EXP,0.8919382504288165,"Z
1(j1 = Àúg‚àó(z1, j0)) ¬∑ Àúp(z2 | z1) ¬∑ Àúp1(z1, j0)dz1 = k
X j0=1"
EXP,0.8936535162950258,"Z
1(j1 = Àúg‚àó(z1, j0)) ¬∑ Àúp(z2 | z1) ¬∑ 1(j = 0) ¬∑ Àúp(z1)dz1"
EXP,0.8953687821612349,"=
Z
1(j1 = Àúg‚àó(z1, j0)) ¬∑ p(z1, z2)dz1,"
EXP,0.8970840480274442,"as claimed. For the inductive case, we have"
EXP,0.8987993138936535,"Àúpt(zt, jt‚àí1) = k
X"
EXP,0.9005145797598628,jt‚àí2=1
EXP,0.902229845626072,"Z
1(jt‚àí1 = Àúg‚àó(zt‚àí1, jt‚àí2)) ¬∑ Àúp(zt | zt‚àí1) ¬∑ Àúpt‚àí1(zt‚àí1, jt‚àí2)dzt‚àí1 = k
X"
EXP,0.9039451114922813,"j1,...,jt‚àí2=1"
EXP,0.9056603773584906,"Z  t‚àí1
Y"
EXP,0.9073756432246999,"œÑ=1
1(jœÑ‚àí1 = Àúg‚àó(zœÑ‚àí1, jœÑ‚àí2)) !"
EXP,0.9090909090909091,"¬∑ p(z1, ..., zt)dz1...dzt‚àí1."
EXP,0.9108061749571184,as claimed.
EXP,0.9125214408233276,"Now, we prove Lemma 6.6. First, note that for each t ‚àà[T], we have Pp(w) """
EXP,0.9142367066895368,"(ÀÜg(w)t Ã∏= g‚àó(w)t) ‚àß t‚àí1
^"
EXP,0.9159519725557461,"œÑ=1
ÀÜg(w)œÑ = g‚àó(w)œÑ !#"
EXP,0.9176672384219554,"=
Z
1(ÀÜg(w)t Ã∏= g‚àó(w)t) ¬∑ t‚àí1
Y"
EXP,0.9193825042881647,"œÑ=1
1(ÀÜg(w)œÑ = g‚àó(w)œÑ) !"
EXP,0.9210977701543739,"¬∑ p(w)dw = k
X"
EXP,0.9228130360205832,"j1,...,jt‚àí1=1"
EXP,0.9245283018867925,"Z
1(ÀÜg(w)t Ã∏= g‚àó(w)t) ¬∑ t‚àí1
Y"
EXP,0.9262435677530018,"œÑ=1
1(ÀÜg(w)œÑ = g‚àó(w)œÑ) !"
EXP,0.9279588336192109,"¬∑ p(j1...jt‚àí1 | w) ¬∑ p(w)dw = k
X"
EXP,0.9296740994854202,"j1,...,jt‚àí1=1"
EXP,0.9313893653516295,"Z
1(ÀÜg(w)t Ã∏= g‚àó(w)t) ¬∑ ¬∑ t‚àí1
Y"
EXP,0.9331046312178388,"œÑ=1
1(ÀÜg(w)œÑ = g‚àó(w)œÑ) ! ¬∑ t‚àí1
Y"
EXP,0.934819897084048,"œÑ=1
1(jœÑ = Àúg‚àó(zœÑ, jœÑ‚àí1)) !"
EXP,0.9365351629502573,"¬∑ p(w)dw = k
X"
EXP,0.9382504288164666,"j1,...,jt‚àí1=1"
EXP,0.9399656946826758,"Z
1(ÀÜÀúg(zœÑ, jœÑ‚àí1) Ã∏= Àúg‚àó(zœÑ, jœÑ‚àí1)) ¬∑ t‚àí1
Y"
EXP,0.9416809605488851,"œÑ=1
1(ÀÜÀúg(zœÑ, jœÑ‚àí1) = Àúg‚àó(zœÑ, jœÑ‚àí1)) ! ¬∑ t‚àí1
Y"
EXP,0.9433962264150944,"œÑ=1
1(jœÑ = Àúg‚àó(zœÑ, jœÑ‚àí1)) !"
EXP,0.9451114922813036,"¬∑ p(w)dw ‚â§ k
X"
EXP,0.9468267581475128,"j1,...,jt‚àí1=1"
EXP,0.9485420240137221,"Z
1(ÀÜÀúg(zœÑ, jœÑ‚àí1) Ã∏= Àúg‚àó(zœÑ, jœÑ‚àí1)) ¬∑ t‚àí1
Y"
EXP,0.9502572898799314,"œÑ=1
1(jœÑ = Àúg‚àó(zœÑ, jœÑ‚àí1)) !"
EXP,0.9519725557461407,"¬∑ p(w)dw = k
X"
EXP,0.9536878216123499,"j1,...,jt‚àí1=1"
EXP,0.9554030874785592,"Z
1(ÀÜÀúg(zœÑ, jœÑ‚àí1) Ã∏= Àúg‚àó(zœÑ, jœÑ‚àí1)) ¬∑ t‚àí1
Y"
EXP,0.9571183533447685,"œÑ=1
1(jœÑ = Àúg‚àó(zœÑ, jœÑ‚àí1)) !"
EXP,0.9588336192109777,"¬∑ p(z1, ..., zt)dz1...dzt"
EXP,0.9605488850771869,"= Ppt(z,j)
h
ÀÜÀúg(zœÑ, jœÑ‚àí1) Ã∏= Àúg‚àó(zœÑ, jœÑ‚àí1)
i
,"
EXP,0.9622641509433962,Under review as a conference paper at ICLR 2022
EXP,0.9639794168096055,"where the last step follows from Lemma E.1. Now, note that"
EXP,0.9656946826758147,"Pp(w)[ÀÜg(w) Ã∏= g‚àó(w)] = T
X"
EXP,0.967409948542024,"t=1
Pp(w) """
EXP,0.9691252144082333,"(ÀÜg(w)t Ã∏= g‚àó(w)t) ‚àß t‚àí1
^"
EXP,0.9708404802744426,"œÑ=1
ÀÜg(w)œÑ = g‚àó(w)œÑ !# ‚â§ T
X"
EXP,0.9725557461406518,"t=1
PÀúpt(z,j)
h
ÀÜÀúg(z, j) Ã∏= Àúg‚àó(z, j)
i ‚â§Tœµg,"
EXP,0.9742710120068611,as claimed.
EXP,0.9759862778730704,"E.4
PROOF OF THEOREM 6.7"
EXP,0.9777015437392796,"First, we show that Pq(z,j)[ÀÜÀúg(z, j) Ã∏= Àúg‚àó(z, j)] ‚â§œµg + TŒ±. To this end, note that"
EXP,0.9794168096054888,"Pq(z,j)[ÀÜÀúg(z, j) Ã∏= Àúg‚àó(z, j)]"
EXP,0.9811320754716981,"= Pp(z,j)[ÀÜÀúg(z, j) Ã∏= Àúg‚àó(z, j)] + Pq(z,j)[ÀÜÀúg(z, j) Ã∏= Àúg‚àó(z, j)] ‚àíPp(z,j)[ÀÜÀúg(z, j) Ã∏= Àúg‚àó(z, j)] ‚â§œµg + k
X j=1"
EXP,0.9828473413379074,"Z
1(ÀÜÀúg(z, j) Ã∏= Àúg‚àó(z, j)) ¬∑ |Àúq(z, j) ‚àíÀúp(z, j)|dz"
EXP,0.9845626072041166,"‚â§œµg + ‚à•Àúq ‚àíÀúp‚à•TV
‚â§œµg + TŒ±."
EXP,0.9862778730703259,"Next, by Lemma 6.6 with q in place of p and œµg +TŒ± in place of œµg, we have Pq(w)[ÀÜg(w) Ã∏= g‚àó(w)] ‚â§
Tœµg + T 2Œ±. Then, assuming that ÀÜg(w) = g‚àó(w), we have"
EXP,0.9879931389365352,"‚à•f ‚àó(x, w) ‚àíÀÜf(x, w)‚à•2"
EXP,0.9897084048027445,"= ‚à•(f ‚àó
jT ‚ó¶... ‚ó¶f ‚àó
j1)(x) ‚àí( ÀÜfjT ‚ó¶... ‚ó¶ÀÜfj1)(x)‚à•2 ‚â§ T
X"
EXP,0.9914236706689536,"t=1
‚à•(f ‚àó
jT ‚ó¶... ‚ó¶f ‚àó
jt+1 ‚ó¶f ‚àó
jt ‚ó¶ÀÜfjt‚àí1 ‚ó¶... ‚ó¶ÀÜfj1)(x) ‚àí(f ‚àó
jT ‚ó¶... ‚ó¶f ‚àó
jt+1 ‚ó¶ÀÜfjt ‚ó¶ÀÜfjt‚àí1 ‚ó¶... ‚ó¶ÀÜfj1)(x)‚à•2 ‚â§ T
X"
EXP,0.9931389365351629,"t=1
KT ‚àít ¬∑ ‚à•(f ‚àó
jt ‚ó¶ÀÜfjt‚àí1 ‚ó¶... ‚ó¶ÀÜfj1)(x) ‚àí( ÀÜfjt ‚ó¶ÀÜfjt‚àí1 ‚ó¶... ‚ó¶ÀÜfj1)(x)‚à•2 ‚â§ T
X"
EXP,0.9948542024013722,"t=1
KT ‚àítœµf"
EXP,0.9965694682675815,"‚â§Tœµf ¬∑ max{KT ‚àí1, 1}."
EXP,0.9982847341337907,The claim follows by a union bound.
