Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,"Abstract—As a highly effective method for generating test cases, 
adaptive random testing is widely utilized across various fields, 
including fuzzing and AI testing. Among the numerous functional 
testing approaches, random testing serves as the fundamental 
method. It involves the random selection of test cases from the 
input domain until a specific condition is met, such as identifying 
errors within a software system. However, due to its limited 
utilization of additional information, the effectiveness of random 
testing is constrained. Consequently, adaptive random testing has 
been proposed to ensure the randomness of test cases and their 
even distribution throughout the entire input domain. This project 
focuses on numerical programs with an aim to replicate existing 
classical adaptive random testing algorithms and compare their 
efficacy. After studying the source code of the framework and 
conducting a thorough review of relevant academic literature, our 
team incorporated their own insights into the process of 
reconstructing the work of predecessors. Subsequently, we 
independently developed a comprehensive framework that 
facilitated customized data transmission, test case generation and 
execution, as well as evaluation procedures. Additionally, we 
utilized echarts to generate visually intuitive charts on the front-
end."
INTRODUCTION,0.012195121951219513,"Index Terms—Adaptive random test, replication technology, 
numerical programs , frontend and backend development "
INTRODUCTION,0.024390243902439025,I. INTRODUCTION
INTRODUCTION,0.036585365853658534,"oftware testing is a crucial component of the software 
development life cycle, ensuring that the system adheres to 
specifications and minimizes errors. As software complexity 
and version iterations increase, maintaining quality and reliability 
in a time-efficient and cost-effective manner becomes paramount, 
particularly in large, fast-paced companies that adopt Continuous 
Integration (CI) strategies. CI facilitates early detection of system 
defects, provides developers with rapid feedback on code quality, 
shortens the software development cycle, and enhances product 
quality. Regression testing is essential for managing software 
changes and has become impractical to re-run entirely for large-
scale industrial systems due to the prevalence of continuous 
integration. To reduce regression testing costs and improve 
efficiency, various test case optimization techniques have been 
proposed."
INTRODUCTION,0.04878048780487805,"Regression testing, as one of the tools for managing software 
changes, becomes the most important part of practical software 
testing. And with the prevalence of continuous integration, it 
becomes impractical to re-run the entire test suite for large-scale 
industrial systems. In order to reduce the cost of regression testing 
and improve the efficiency of regression testing, a variety of test 
case optimization techniques have been proposed, such as test case 
identification and repair, test suite reduction, test suite expansion,"
INTRODUCTION,0.06097560975609756,test case selection and test case prioritization.
INTRODUCTION,0.07317073170731707,"Numerical program orientation in Adaptive Random Testing 
(ART) ensures that test cases are primarily focused on numerical 
programs, allowing for efficient and adaptive generation of evenly 
scattered test cases throughout the input domain. Nevertheless, 
ART applied to various fields has different points. Numerical 
program orientation means that the test cases we are primarily 
interested in should be related to numerical programs."
INTRODUCTION,0.08536585365853659,"Random testing is highly efficient in generating test cases; 
however, it has a fatal shortcoming: limited utilization of additional 
information beyond the given data, which can act as a constraint 
when testing diverse types of software. In contrast, Adaptive 
Random Testing (ART) ensures the randomness and even 
distribution of test cases throughout the entire input domain, 
making it ""adaptive"". ART has gained industry recognition for 
combining the strengths of random testing while mitigating its 
weaknesses. This indicates that adaptive random testing for 
numerical programs is a well-established yet dynamic field, 
offering valuable insights for further exploration."
INTRODUCTION,0.0975609756097561,"By delving into the source code of the framework and 
leveraging insights from literature reviews, this paper enriches the 
existing knowledge base by infusing its own perspectives into the 
recreation process. It constructs a comprehensive framework 
encompassing custom data transmission, test case generation, 
operation, and evaluation. Additionally, it employs echarts to 
create visually appealing charts in the frontend, enhancing the 
overall presentation of the research findings."
INTRODUCTION,0.10975609756097561,"From the aforementioned information, it is evident that 
adaptive random testing for numerical programs represents a well-
established yet dynamic field, from which we can continue to 
derive substantial insights. Our team leveraged the source code of 
the framework and integrated findings from relevant literature to 
enhance our understanding. Through this process, we incorporated 
original perspectives while reconstructing predecessor content, 
ultimately developing a customized framework encompassing data 
transmission, test case generation and execution, as well as 
evaluation capabilities. Additionally, we utilized echarts to 
generate visually intuitive charts on the front-end. ."
IMPLEMENTATION/METHODS,0.12195121951219512,II. PROJECT STRUCTURE
IMPLEMENTATION/METHODS,0.13414634146341464,A. Overall Architecture
IMPLEMENTATION/METHODS,0.14634146341463414,"The overall aechitecture of project is shown as figure 1.The 
frontend only interacts with the Controller and sends GET and 
POST requests wrapped in single and multiple request objects. 
Controller core functions consists of task distribution, receiving 
and sending requests.The primary functions of the two ART 
modules are as follows: The ART_Empirical module executes "
IMPLEMENTATION/METHODS,0.15853658536585366,"aspecific ART algorithm and validates the results produced by 
said algorithm; while the ART_Algorithm module conducts 
mutation testing and calculates compilation kill rate."
IMPLEMENTATION/METHODS,0.17073170731707318,Fig. 1. Overall architecture of project
IMPLEMENTATION/METHODS,0.18292682926829268,B. Frontend Architecture
IMPLEMENTATION/METHODS,0.1951219512195122,"The frontend adopts vue3 architecture, with utility class 
components folder components, modules network and router 
responsible for data transmission, and two independent pages 
views. Figure 2 reveals the brief structure of the front-end source 
code. The main function is page display, including ART form 
input information collection, ART results visualization, single or 
multiple ART algorithm switching."
IMPLEMENTATION/METHODS,0.2073170731707317,Fig. 2. Structure of the front-end source code
IMPLEMENTATION/METHODS,0.21951219512195122,C. Backend Architecture
IMPLEMENTATION/METHODS,0.23170731707317074,"The back end is mainly composed of three modules: 
Controller, ART_Algorithm and ART_Empirical."
IMPLEMENTATION/METHODS,0.24390243902439024,1) Controller
IMPLEMENTATION/METHODS,0.25609756097560976,"Con troller receives the front-end data, parses the 
request, sends the request to ART_Empirical to generate 
test cases and runs the simulation test. After the test"
IMPLEMENTATION/METHODS,0.2682926829268293,"cases are generated, ART_Algorithm is wakened to test the 
mutation kill rate.  
The structure of Controller is shown in figure 3. Spring 
Boot interacts with the frontend, encapsulating request 
objects and return objects, and stateless services. The 
Socket communicates with the backend and customizes the 
protocol interaction. For multi-TCP evaluation, the 
evaluation method is customized."
IMPLEMENTATION/METHODS,0.2804878048780488,Fig. 3. Structure of Controller
IMPLEMENTATION/METHODS,0.2926829268292683,2) ART_Algorithm
IMPLEMENTATION/METHODS,0.3048780487804878,"ART_Empirical takes the Controller command, extracts 
and parses the test request body, and returns a partial 
evaluation result. It implements a custom evaluation 
framework, custom data extraction methods with common, 
unified data encapsulation, 15+1 ART algorithms, custom 
data storageThe structure of ART_Algorithm is shown in 
figure 4."
IMPLEMENTATION/METHODS,0.3170731707317073,"Fig. 4. Structure of ART_Algorithm 
 
3) ART_Empirical "
IMPLEMENTATION/METHODS,0.32926829268292684,Fig. 4. Structure of ART_ Empirical
IMPLEMENTATION/METHODS,0.34146341463414637,III. ALGORITHM
IMPLEMENTATION/METHODS,0.35365853658536583,"We successfully archieved 18 ART algorithms.Their categories, 
names and source paper information are as follows:  "
IMPLEMENTATION/METHODS,0.36585365853658536,"TABLE I 
CATEGORIES, NAMES AND SOURCE PAPER INFORMATION OF"
IMPLEMENTATION/METHODS,0.3780487804878049,18 ART ALGORITHMS
IMPLEMENTATION/METHODS,0.3902439024390244,"Next we choose some important algorithms and explain their 
principle and code implementation."
IMPLEMENTATION/METHODS,0.4024390243902439,A. FSCS-ART-DNC
IMPLEMENTATION/METHODS,0.4146341463414634,"The flow chart of the algorithm is as follows, where the red 
box part is the addition of the algorithm based on FSCS.   "
IMPLEMENTATION/METHODS,0.4268292682926829,"D. Inverted FSCS-ART 
This algorithm is an improvement of FSCS-ART, which 
mainly solves the problem that FSCS-ART selects more test 
cases from the edge region than from the center region in the 
high-dimensional input domain. The method provided is to 
reverse the edge/center distribution of FSCS-ART test cases, 
so as to improve the fault detection efficiency. 
Function (5) maps the FSCS-ART test cases from the edge to 
the center region, or from the center to the edge region.  "
IMPLEMENTATION/METHODS,0.43902439024390244,E. Proportional Random Testing 
RESULTS/EXPERIMENTS,0.45121951219512196,IV. EXPERIMENT
RESULTS/EXPERIMENTS,0.4634146341463415,"The code provides a Main function that the user can interact 
with, allowing the user to select one or more ART algorithms to 
test."
RESULTS/EXPERIMENTS,0.47560975609756095,Fig. 4. Running screenshots
RESULTS/EXPERIMENTS,0.4878048780487805,A. Test Mode and Parameters
RESULTS/EXPERIMENTS,0.5,"We use simulation tests, and for each ART method, there will 
be 2 input domain dimensions, 4 failure rates, and 3 failure domain 
types. So for each method, we get 24 trials. We run each 1000 times 
and compute the average F-measure, F-art/F-rt, as well as the 
running time.  "
RESULTS/EXPERIMENTS,0.5121951219512195,B. Test Results
RESULTS/EXPERIMENTS,0.524390243902439,"The results are stored in 'ARTEmpirical-main/result', which 
contains a txt file with details for each method on 2D and 3D 
input fields, 0.001 failure rate, three failure field types, and an 
'ART_Result_Summary.csv' file with all the results. In the 
'ART_Result_Summary.csv' file, there are 24 pieces of data 
about each ART algorithm, for example for the DMART 
algorithm:"
RESULTS/EXPERIMENTS,0.5365853658536586,Fig. 5. DMART_Result_Summary.csv
RESULTS/EXPERIMENTS,0.5487804878048781,C. Comparison of Different Algorithms
RESULTS/EXPERIMENTS,0.5609756097560976,"Figure 6 and 7 reveals the F-measure and running time of 
different algorithms."
RESULTS/EXPERIMENTS,0.573170731707317,Fig. 6. F-measure of different algorithms
RESULTS/EXPERIMENTS,0.5853658536585366,Fig. 7. Running time of different algorithms
RESULTS/EXPERIMENTS,0.5975609756097561,D.  Web-based running
RESULTS/EXPERIMENTS,0.6097560975609756,"We choose the single ART analysis as example. the 
algorithm is FSCS, the numerical program is Bessj, and 
the running time is about 15 minutes with the case of 
block-level failure domains. 
Figure 7 and Figure 8 reveal the front-end page and 
back-end in the example experiment."
RESULTS/EXPERIMENTS,0.6219512195121951,Fig. 7. Front-end page   
RESULTS/EXPERIMENTS,0.6341463414634146,Fig. 8.  backend  page
CONCLUSION/DISCUSSION ,0.6463414634146342,V. CONCLUSION
CONCLUSION/DISCUSSION ,0.6585365853658537,"Adaptive random testing emerges as a highly effective 
approach for test case generation, widely adopted in diverse 
fields such as fuzzing and AI testing. While random testing 
serves as a fundamental method in functional testing, its 
effectiveness is limited by the lack of utilization of additional 
information beyond the input domain. To address this 
constraint, adaptive random testing has been introduced to 
ensure the randomness and uniform distribution of test cases 
throughout the input domain."
CONCLUSION/DISCUSSION ,0.6707317073170732,"In this article, we specifically focused on numerical 
programs, aiming to replicate classical adaptive random 
testing algorithms and assess their effectiveness. By 
examining the source code of the framework and conducting a 
comprehensive review of relevant academic literature, our 
team integrated their unique perspectives into the process of 
reconstructing the work of previous researchers. Subsequently, 
we developed a comprehensive framework that enabled 
customized data transmission, test case generation, execution, 
and evaluation processes. Furthermore, we leveraged echarts 
to create visually intuitive charts on the front-end, enhancing 
the presentation of our research findings."
REFERENCES,0.6829268292682927,REFERENCES
REFERENCES,0.6951219512195121,"[1]  M. Abdelkarim and R. ElAdawi, TCP-Net: Test ase Prioritization using"
REFERENCES,0.7073170731707317,"End-to-End  Deep  Neural  Networks//2022  IEEE  International 
[2]  Conference on Software Testing, Veriﬁcation and Validation Workshops"
REFERENCES,0.7195121951219512,"(ICSTW). Valencia, Spain, 2022: pp. 122-129.Antonia Bertolino,  Antonio  
Guerriero, BrenoMranda, Roberto Pietrantuono, and Stefano Russo. 
Learning-to-rank vs ranking-to-learn:trategies for regression testing in 
continuous integration//Proceedings of theACM/IEEE 42nd  International  
ew York, NY, USA. 2020. 1–12. 
[3]  Benjamin Busjaeger and Tao Xie. Learning for test prioritization: an"
REFERENCES,0.7317073170731707,"industrial case study//Proceedings of the 2016 24th ACM SIGSOFT  
International  Symposium  on  Foundations  of  Software Engineering (FSE 
2016). Association for Computing Machinery.ew York, NY, USA, 2016: 
975–980. 
[4]  J.  Chen,  Y.  Bai,  D.  Hao,  Y.  Xiong,  H.  Zhang nd  B.  Xie,  Learning"
REFERENCES,0.7439024390243902,"to Prioritize  Test  Programs  for  Compiler  Testing//2017  IEEE/ACM  39th  
International  Conference  on  Software Engineering  (ICSE).  Buenos Aires, 
Argentina, 2017: pp. 700-711. 
[5] E.  A.  Da  Roza,  J.  A.  P.  Lima,  R.  C.  Silva  and  S.Vergilio,  Machine"
REFERENCES,0.7560975609756098,"Learning Regression Techniques for Test Case Prioritization in Continuous 
Integration Environment//2022 IEEE International Conference on  
Software  Analysis,  Evolution  and  Reengineering (SANER). Honolulu, 
HI, USA, 2022: pp. 196-206. 
[6]  D. Di Nardo, N. Alshahwan, L. Briand and Y.Labiche, Coverage-Based"
REFERENCES,0.7682926829268293,"Test  Case  Prioritisation:n  Industrial  Case  Study//2013  IEEE  Sixth 
 International  Conference  on  Software  Testing,Veriﬁcation  and 
 Validation. Luxembourg, 2013: pp.02-311. 
[7]  D. Di Nardo, N. Alshahwan, L. Briand and Y.Labiche, Coverage-Based"
REFERENCES,0.7804878048780488,Test  Case  Prioritisation:n  Industrial  Case  Study//2013  IEEE  Sixth
REFERENCES,0.7926829268292683,"International  Conference  on  Software  Testing,Veriﬁcation  and 
 Validation. Luxembourg, 2013: pp.02-311. 
[8]    J. A. P. Lima and S. R. Vergilio, A Multi-Armed Bandit Approach for"
REFERENCES,0.8048780487804879,"Test Case Prioritization in Continuous Integration Environments. IEEE 
 Transactions on Software Engineering, 2022. vol. 48,no. 2: pp. 453-465, 
 1. 
[9]    V. H. S. Durelli et al., Machine Learning Appliedto Software Testing: A"
REFERENCES,0.8170731707317073,"Systematic Mapping Study.EEE Transactions on Reliability, 2019. vol. 
 68, no., pp. 1189-1212. 
[10]  Sebastian  Elbaum,  Alexey  Malishevsky,  and  GreggRothermel."
REFERENCES,0.8292682926829268,"Incorporating  varying  test  costs  and  faultseverities  into  test  case 
prioritization//Proceeding of he  23rd  International  Conference  on 
SoftwareEngineering(ICSE). Toronto, ON, Canada. 2001: pages 329–
338. 
[11]  Yang  Feng,  Qingkai  Shi,  Xinyu  Gao,  Jun  Wan,Chunrong  Fang,  and"
REFERENCES,0.8414634146341463,"Zhenyu  Chen.DeepGini:prioritizing  massive  tests  to  enhance  the 
 robustnessof  deep  neural  networks//Proceedings  of  the29th  ACM 
 SIGSOFT  International  Symposiumon  Software  Testing  and  Analysis 
 (ISSTA  2020).Association  for  Computing  Machinery.  New  York,NY, 
 USA, 2020: 177–188. 
[12]  Y.  Huang,  T.  Shu  and  Z.  Ding,  A  Learn-to-Rank  Method  for"
REFERENCES,0.8536585365853658,"Model-Based Regression Test CasePrioritization. IEEE Access, 2021,vol. 
9, pp. 16365-16382. 
[13] Jahan, Hosney et al. Version Speciﬁc Test CasePrioritization Approach"
REFERENCES,0.8658536585365854,"Based  on  Artiﬁcial  Neural Network, Intelligent  Fuzzy  Systems, 
2019,vol. 36, no. 6, pp. 6181-6194. 
[14]  Kandil,  P.,  Moussa,  S.,  and  Badr,  N.  Cluster-based  test  cases"
REFERENCES,0.8780487804878049,"prioritization  and  selection  techniquefor  agile  regression  testing. 
ournal Of Software-evolution And Process, 2017, 29: e1794. 
[15]  Z.  Khalid  and  U.  Qamar,  Weight  and  Cluster  BasedTest  case"
REFERENCES,0.8902439024390244,"Prioritization  Technique//2019  IEEE10th  Annual  Information 
Technology,  Electronicsand  Mobile  Communication  Conference 
(IEMCON).Vancouver, BC, Canada, 2019: pp. 1013-1022. 
[16]  R.  Lachmann,  S.  Schulze,  M.  Nieke,  C.  Seidl  and  I.Schaefer,"
REFERENCES,0.9024390243902439,"System-Level Test Case PrioritizationUsing Machine Learning// 2016 
15th  IEEEInternational  Conference  on  Machine  Learningand 
Applications (ICMLA). Anaheim, CA, USA,2016: pp. 361-368. 
[17] Jackson A. Prado Lima, Willian D. F. Mendonça,Silvia R. Vergilio, and"
REFERENCES,0.9146341463414634,"Wesley  K.  G.  Assunção.Learning-based  prioritization  of  test  cases 
incontinuous  integration  of  highly-conﬁgurablesoftware//Proceedings 
of the 24th ACM Conferenceon Systems and Software Product Line: 
Volume  A- Volume  A  (SPLC  ’20).  Association  for 
ComputingMachinery. New York, NY, USA, 2020: Article 31,1–11. 
[18]  C. -T.  Lin,  S. -H.  Yuan  and  J.  Intasara,  A  Learning-to-Rank  Based"
REFERENCES,0.926829268292683,"Approach  for  Improving  RegressionTest  Case  Prioritization//2021 
 28th  Asia-PaciﬁcSoftware  Engineering  Conference  (APSEC). 
 Taipei,China. 2021: pp. 576-577. 
[19] A.  Da  Roza,  J.  A.  P.  Lima,  R.  C.  Silva  and  S.Vergilio,  Machine"
REFERENCES,0.9390243902439024,"Learning  Regression  Techniques  for  Test  Case  Prioritization  in 
 Continuous  Integration  Environment//2022  IEEE  International 
 Conference  on  Software  Analysis,  Evolution  and  Reengineering 
 (SANER). Honolulu, HI, USA, 2022: pp. 196-206. 
[20] Mahdieh M, Mirian-Hosseinabadi S H, EtemadiK, et al. Incorporating"
REFERENCES,0.9512195121951219,"fault-proneness estimationsinto coverage-based test case prioritization 
 methods.Information and Software Technology, 2020, 121:106269. 
[21] N. Medhat, S. M. Moussa, N. L. Badr and M. F.Tolba, A Framework"
REFERENCES,0.9634146341463414,"for  Continuous  Regression  andIntegration  Testing  in  IoT  Systems 
 Based  on  DeepLearning  and  Search-Based  Techniques.  IEEE 
 Access,2020, vol. 8, pp. 215716-215726. 
[22]  Francis  Palma,  Tamer  Abdou,  Ayse  Bener,  JohnMaidens,  and  Stella"
REFERENCES,0.975609756097561,"Liu. An Improvement to TestCase Failure Prediction in the Context of 
 Test  CasePrioritization//Proceedings  of  the  14th 
 InternationalConference  on  Predictive  Models  and  Data  Analyticsin 
 Software  Engineering  (PROMISE’18).  Associationfor  Computing 
 Machinery. New York, NY, USA,2018: 80–89. 
[23] Pan, R., Bagherzadeh, M., Ghaleb, T.A. et al. Test case selection and"
REFERENCES,0.9878048780487805,prioritization  using machine learning: a  systematic literature  review.
