Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.00202020202020202,"Voice conversion is a common speech synthesis task which can be solved in differ-
ent ways depending on a particular real-world scenario. The most challenging one
often referred to as one-shot many-to-many voice conversion consists in copying
target voice from only one reference utterance in the most general case when
both source and target speakers do not belong to the training dataset. We present
a scalable high-quality solution based on diffusion probabilistic modeling and
demonstrate its superior quality compared to state-of-the-art one-shot voice con-
version approaches. Moreover, focusing on real-time applications, we investigate
general principles which can make diffusion models faster while keeping synthesis
quality at a high level. As a result, we develop a novel Stochastic Differential
Equations solver suitable for various diffusion model types and generative tasks as
shown through empirical studies and justify it by theoretical analysis."
INTRODUCTION,0.00404040404040404,"1
INTRODUCTION"
INTRODUCTION,0.006060606060606061,"Voice conversion (VC) is the task of copying the target speaker’s voice while preserving the linguistic
content of the utterance pronounced by the source speaker. Practical VC applications often require a
model which is able to operate in one-shot mode (i.e. when only one reference utterance is provided
to copy the target speaker’s voice) for any source and target speakers. Such models are usually
referred to as one-shot many-to-many models (or sometimes zero-shot many-to-many models, or just
any-to-any VC models). It is challenging to build such a model since it should be able to adapt to a
new unseen voice having only one spoken utterance pronounced with it, so it was not until recently
that successful one-shot VC solutions started to appear."
INTRODUCTION,0.00808080808080808,"Conventional one-shot VC models are designed as autoencoders whose latent space ideally contains
only the linguistic content of the encoded utterance while target voice identity information (usually
taking shape of speaker embedding) is fed to the decoder as conditioning. Whereas in the pioneering
AutoVC model (Qian et al., 2019) only speaker embedding from the pre-trained speaker veriﬁcation
network was used as conditioning, several other models improved on AutoVC enriching conditioning
with phonetic features such as pitch and loudness (Qian et al., 2020; Nercessian, 2020), or training
voice conversion and speaker embedding networks jointly (Chou & Lee, 2019). Also, several papers
(Lin et al., 2021; Ishihara & Saito, 2020; Liu et al., 2021b) made use of attention mechanism to
better fuse speciﬁc features of the reference utterance into the source utterance thus improving the
decoder performance. Apart from providing the decoder with sufﬁciently rich information, one of the
main problems autoencoder VC models face is to disentangle source speaker identity from speech
content in the encoder. Some models (Qian et al., 2019; 2020; Nercessian, 2020) solve this problem
by introducing an information bottleneck. Among other popular solutions of the disentanglement
problem one can mention applying vector quantization technique to the content information (Wu
et al., 2020; Wang et al., 2021), utilizing features of Variational AutoEncoders (Luong & Tran, 2021;
Saito et al., 2018; Chou & Lee, 2019), introducing instance normalization layers (Chou & Lee, 2019;
Chen et al., 2021b), and using Phonetic Posteriorgrams (PPGs) (Nercessian, 2020; Liu et al., 2021b)."
INTRODUCTION,0.010101010101010102,Published as a conference paper at ICLR 2022
INTRODUCTION,0.012121212121212121,"The model we propose in this paper solves the disentanglement problem by employing the encoder
predicting “average voice”: it is trained to transform mel features corresponding to each phoneme
into mel features corresponding to this phoneme averaged across a large multi-speaker dataset. As for
decoder, in our VC model, it is designed as a part of a Diffusion Probabilistic Model (DPM) since this
class of generative models has shown very good results in speech-related tasks like raw waveform
generation (Chen et al., 2021a; Kong et al., 2021) and mel feature generation (Popov et al., 2021;
Jeong et al., 2021). However, this decoder choice poses a problem of slow inference because DPM
forward pass scheme is iterative and to obtain high-quality results it is typically necessary to run it for
hundreds of iterations (Ho et al., 2020; Nichol & Dhariwal, 2021). Addressing this issue, we develop
a novel inference scheme that signiﬁcantly reduces the number of iterations sufﬁcient to produce
samples of decent quality and does not require model re-training. Although several attempts have
been recently made to reduce the number of DPM inference steps (Song et al., 2021a; San-Roman
et al., 2021; Watson et al., 2021; Kong & Ping, 2021; Chen et al., 2021a), most of them apply to some
particular types of DPMs. In contrast, our approach generalizes to all popular kinds of DPMs and has
a strong connection with likelihood maximization."
INTRODUCTION,0.014141414141414142,"This paper has the following structure: in Section 2 we present a one-shot many-to-many VC model
and describe DPM it relies on; Section 3 introduces a novel DPM sampling scheme and establishes
its connection with likelihood maximization; the experiments regarding voice conversion task as well
as those demonstrating the beneﬁts of the proposed sampling scheme are described in Section 4; we
conclude in Section 5."
VOICE CONVERSION DIFFUSION MODEL,0.01616161616161616,"2
VOICE CONVERSION DIFFUSION MODEL"
VOICE CONVERSION DIFFUSION MODEL,0.01818181818181818,"As with many other VC models, the one we propose belongs to the family of autoencoders. In fact,
any conditional DPM with data-dependent prior (i.e. terminal distribution of forward diffusion)
can be seen as such: forward diffusion gradually adding Gaussian noise to data can be regarded as
encoder while reverse diffusion trying to remove this noise acts as a decoder. DPMs are trained to
minimize the distance (expressed in different terms for different model types) between the trajectories
of forward and reverse diffusion processes thus, speaking from the perspective of autoencoders,
minimizing reconstruction error. Data-dependent priors have been proposed by Popov et al. (2021)
and Lee et al. (2021), and we follow the former paper due to the ﬂexibility of the continuous DPM
framework used there. Our approach is summarized in Figure 1."
VOICE CONVERSION DIFFUSION MODEL,0.020202020202020204,"Figure 1: VC model training and inference. Y stands for the training mel-spectrogram at training
and the target mel-spectrogram at inference. Speaker conditioning in the decoder is enabled by the
speaker conditioning network gt(Y ) where Y = {Yt}t∈[0,1] is the whole forward diffusion trajectory
starting at Y0. Dotted arrows denote operations performed only at training."
VOICE CONVERSION DIFFUSION MODEL,0.022222222222222223,Published as a conference paper at ICLR 2022
ENCODER,0.024242424242424242,"2.1
ENCODER"
ENCODER,0.026262626262626262,"We choose average phoneme-level mel features as speaker-independent speech representation. To
train the encoder to convert input mel-spectrograms into those of “average voice”, we take three steps:
(i) ﬁrst, we apply Montreal Forced Aligner (McAuliffe et al., 2017) to a large-scale multi-speaker
LibriTTS dataset (Zen et al., 2019) to align speech frames with phonemes; (ii) next, we obtain
average mel features for each particular phoneme by aggregating its mel features across the whole
LibriTTS dataset; (iii) the encoder is then trained to minimize mean square error between output
mel-spectrograms and ground truth “average voice” mel-spectrograms (i.e. input mel-spectrograms
where each phoneme mel feature is replaced with the average one calculated on the previous step)."
ENCODER,0.028282828282828285,"The encoder has exactly the same Transformer-based architecture used in Grad-TTS (Popov et al.,
2021) except that its inputs are mel features rather than character or phoneme embeddings. Note that
unlike Grad-TTS the encoder is trained separately from the decoder described in the next section."
DECODER,0.030303030303030304,"2.2
DECODER"
DECODER,0.03232323232323232,"Whereas the encoder parameterizes the terminal distribution of the forward diffusion (i.e. the prior),
the reverse diffusion is parameterized with the decoder. Following Song et al. (2021c) we use Itˆo
calculus and deﬁne diffusions in terms of stochastic processes rather than discrete-time Markov
chains."
DECODER,0.03434343434343434,"The general DPM framework we utilize consists of forward and reverse diffusions given by the
following Stochastic Differential Equations (SDEs):"
DECODER,0.03636363636363636,dXt = 1
DECODER,0.03838383838383838,"2βt( ¯X −Xt)dt +
p"
DECODER,0.04040404040404041,"βtd−→
Wt ,
(1)"
DECODER,0.04242424242424243,"d ˆXt =
1"
DECODER,0.044444444444444446,"2( ¯X −ˆXt) −sθ( ˆXt, ¯X, t)

βtdt +
p"
DECODER,0.046464646464646465,"βtd←−
Wt ,
(2)"
DECODER,0.048484848484848485,"where t ∈[0, 1], −→
W and ←−
W are two independent Wiener processes in Rn, βt is non-negative function
referred to as noise schedule, sθ is the score function with parameters θ and ¯X is n-dimensional
vector. It can be shown (Popov et al., 2021) that the forward SDE (1) allows for explicit solution:"
DECODER,0.050505050505050504,"Law(Xt|X0) = N

e−1"
R T,0.052525252525252523,"2
R t
0 βsdsX0 +

1 −e−1"
R T,0.05454545454545454,"2
R t
0 βsds
¯X,

1 −e−
R t
0 βsds
I

,
(3)"
R T,0.05656565656565657,"where I is n × n identity matrix. Thus, if noise follows linear schedule βt = β0 + t(β1 −β0) for β0
and β1 such that e−
R 1
0 βsds is close to zero, then Law (X1) is close to N( ¯X, I) which is the prior in
this DPM. The reverse diffusion (2) is trained by minimizing weighted L2 loss:"
R T,0.05858585858585859,"θ∗= arg min
θ
L(θ) = arg min
θ Z 1"
R T,0.06060606060606061,"0
λtEX0,Xt∥sθ(Xt, ¯X, t) −∇log pt|0(Xt|X0)∥2
2dt,
(4)"
R T,0.06262626262626263,"where pt|0(Xt|X0) is the probability density function (pdf) of the conditional distribution (3) and
λt = 1 −e−
R t
0 βsds. The distribution (3) is Gaussian, so we have"
R T,0.06464646464646465,∇log pt|0(Xt|X0) = −Xt −X0e−1
R T,0.06666666666666667,"2
R t
0 βsds −¯X(1 −e−1"
R T,0.06868686868686869,"2
R t
0 βsds)"
R T,0.0707070707070707,"1 −e−
R t
0 βsds
.
(5)"
R T,0.07272727272727272,"At training, time variable t is sampled uniformly from [0, 1], noisy samples Xt are generated according
to the formula (3) and the formula (5) is used to calculate loss function L on these samples. Note
that Xt can be sampled without the necessity to calculate intermediate values {Xs}0<s<t which
makes optimization task (4) time and memory efﬁcient. A well-trained reverse diffusion (2) has
trajectories that are close to those of the forward diffusion (1), so generating data with this DPM can
be performed by sampling ˆX1 from the prior N( ¯X, I) and solving SDE (2) backwards in time."
R T,0.07474747474747474,Published as a conference paper at ICLR 2022
R T,0.07676767676767676,"The described above DPM was introduced by Popov et al. (2021) for text-to-speech task and we
adapt it for our purposes. We put ¯X = ϕ(X0) where ϕ is the encoder, i.e. ¯X is the “average voice”
mel-spectrogram which we want to transform into that of the target voice. We condition the decoder
sθ = sθ( ˆXt, ¯X, gt(Y ), t) on some trainable function gt(Y ) to provide it with information about the
target speaker (Y stands for forward trajectories of the target mel-spectrogram at inference and the
ones of the training mel-spectrogram at training). This function is a neural network trained jointly
with the decoder. We experimented with three input types for this network:"
R T,0.07878787878787878,"• d-only – the input is the speaker embedding extracted from the target mel-spectrogram Y0
with the pre-trained speaker veriﬁcation network employed in (Jia et al., 2018);
• wodyn – in addition, the noisy target mel-spectrogram Yt is used as input;
• whole – in addition, the whole dynamics of the target mel-spectrogram under forward
diffusion {Ys|s = 0.5/15, 1.5/15, .., 14.5/15} is used as input."
R T,0.08080808080808081,"The decoder architecture is based on U-Net (Ronneberger et al., 2015) and is the same as in Grad-
TTS but with four times more channels to better capture the whole range of human voices. The
speaker conditioning network gt(Y ) is composed of 2D convolutions and MLPs and described in
detail in Appendix H. Its output is 128-dimensional vector which is broadcast-concatenated to the
concatenation of ˆXt and ¯X as additional 128 channels."
RELATED VC MODELS,0.08282828282828283,"2.3
RELATED VC MODELS"
RELATED VC MODELS,0.08484848484848485,"To the best of our knowledge, there exist two diffusion-based voice conversion models: VoiceGrad
(Kameoka et al., 2020) and DiffSVC (Liu et al., 2021a). The one we propose differs from them
in several important aspects. First, neither of the mentioned papers considers a one-shot many-to-
many voice conversion scenario. Next, these models take no less than 100 reverse diffusion steps at
inference while we pay special attention to reducing the number of iterations (see Section 3) achieving
good quality with as few as 6 iterations. Furthermore, VoiceGrad performs voice conversion by
running Langevin dynamics starting from the source mel-spectrogram, thus implicitly assuming that
forward diffusion trajectories starting from the mel-spectrogram we want to synthesize are likely
to pass through the neighborhood of the source mel-spectrogram on their way to Gaussian noise.
Such an assumption allowing to have only one network instead of encoder-decoder architecture is
too strong and hardly holds for real voices. Finally, DiffSVC performs singing voice conversion and
relies on PPGs as speaker-independent speech representation."
MAXIMUM LIKELIHOOD SDE SOLVER,0.08686868686868687,"3
MAXIMUM LIKELIHOOD SDE SOLVER"
MAXIMUM LIKELIHOOD SDE SOLVER,0.08888888888888889,"In this section, we develop a ﬁxed-step ﬁrst-order reverse SDE solver that maximizes the log-
likelihood of sample paths of the forward diffusion. This solver differs from general-purpose
Euler-Maruyama SDE solver (Kloeden & Platen, 1992) by inﬁnitesimally small values which can
however become signiﬁcant when we sample from diffusion model using a few iterations."
MAXIMUM LIKELIHOOD SDE SOLVER,0.09090909090909091,"Consider the following forward and reverse SDEs deﬁned in Euclidean space Rn for t ∈[0, 1]:"
MAXIMUM LIKELIHOOD SDE SOLVER,0.09292929292929293,dXt = −1
MAXIMUM LIKELIHOOD SDE SOLVER,0.09494949494949495,"2βtXtdt+
p"
MAXIMUM LIKELIHOOD SDE SOLVER,0.09696969696969697,"βtd−→
Wt (F),
d ˆXt =

−1"
MAXIMUM LIKELIHOOD SDE SOLVER,0.09898989898989899,"2βt ˆXt −βtsθ( ˆXt, t)

dt+
p"
MAXIMUM LIKELIHOOD SDE SOLVER,0.10101010101010101,"βtd←−
Wt (R), (6)"
MAXIMUM LIKELIHOOD SDE SOLVER,0.10303030303030303,"where −→
W is a forward Wiener process (i.e. its forward increments −→
Wt −−→
Ws are independent of −→
Ws
for t > s) and ←−
W is a backward Wiener process (i.e. backward increments ←−
Ws −←−
Wt are independent
of ←−
Wt for s < t). Following Song et al. (2021c) we will call DPM (6) Variance Preserving (VP).
For simplicity we will derive maximum likelihood solver for this particular type of diffusion models.
The equation (1) underlying VC diffusion model described in Section 2 can be transformed into the
equation (6-F) by a constant shift and we will call such diffusion models Mean Reverting Variance
Preserving (MR-VP). VP model analysis carried out in this section can be easily extended (see
Appendices D, E and F) to MR-VP model as well as to other common diffusion model types such as
sub-VP and VE described by Song et al. (2021c)."
MAXIMUM LIKELIHOOD SDE SOLVER,0.10505050505050505,Published as a conference paper at ICLR 2022
MAXIMUM LIKELIHOOD SDE SOLVER,0.10707070707070707,The forward SDE (6-F) allows for explicit solution:
MAXIMUM LIKELIHOOD SDE SOLVER,0.10909090909090909,"Law(Xt|Xs) = N(γs,tXs, (1 −γ2
s,t) I),
γs,t = exp

−1 2 Z t"
MAXIMUM LIKELIHOOD SDE SOLVER,0.1111111111111111,"s
βudu

,
(7)"
MAXIMUM LIKELIHOOD SDE SOLVER,0.11313131313131314,"for all 0 ≤s < t ≤1. This formula is derived by means of Itˆo calculus in Appendix A. The
reverse SDE (6-R) parameterized with a neural network sθ is trained to approximate gradient of the
log-density of noisy data Xt:"
MAXIMUM LIKELIHOOD SDE SOLVER,0.11515151515151516,"θ∗= arg min
θ Z 1"
MAXIMUM LIKELIHOOD SDE SOLVER,0.11717171717171718,"0
λtEXt∥sθ(Xt, t) −∇log pt(Xt)∥2
2dt,
(8)"
MAXIMUM LIKELIHOOD SDE SOLVER,0.1191919191919192,"where the expectation is taken with respect to noisy data distribution Law(Xt) with pdf pt(·) and λt
is some positive weighting function. Note that certain Lipschitz constraints should be satisﬁed by
coefﬁcients of SDEs (6) to guarantee existence of strong solutions (Liptser & Shiryaev, 1978), and
throughout this section we assume these conditions are satisﬁed as well as those from (Anderson,
1982) which guarantee that paths ˆX generated by the reverse SDE (6-R) for the optimal θ∗equal
forward SDE (6-F) paths X in distribution."
MAXIMUM LIKELIHOOD SDE SOLVER,0.12121212121212122,"The generative procedure of a VP DPM consists in solving the reverse SDE (6-R) backwards in
time starting from ˆX1 ∼N(0, I). Common Euler-Maruyama solver introduces discretization error
(Kloeden & Platen, 1992) which may harm sample quality when the number of iterations is small. At
the same time, it is possible to design unbiased (Henry-Labord`ere et al., 2017) or even exact (Beskos
& Roberts, 2005) numerical solvers for some particular SDE types. The Theorem 1 shows that in the
case of diffusion models we can make use of the forward diffusion (6-F) and propose a reverse SDE
solver which is better than the general-purpose Euler-Maruyama one in terms of likelihood."
MAXIMUM LIKELIHOOD SDE SOLVER,0.12323232323232323,The solver proposed in the Theorem 1 is expressed in terms of the values deﬁned as follows:
MAXIMUM LIKELIHOOD SDE SOLVER,0.12525252525252525,"µs,t = γs,t
1 −γ2
0,s
1 −γ2
0,t
,
νs,t = γ0,s
1 −γ2
s,t
1 −γ2
0,t
,
σ2
s,t = (1 −γ2
0,s)(1 −γ2
s,t)
1 −γ2
0,t
,
(9)"
MAXIMUM LIKELIHOOD SDE SOLVER,0.12727272727272726,"κ∗
t,h =νt−h,t(1 −γ2
0,t)
γ0,tβth
−1,
ω∗
t,h = µt−h,t −1"
MAXIMUM LIKELIHOOD SDE SOLVER,0.1292929292929293,"βth
+
1 + κ∗
t,h
1 −γ2
0,t
−1 2,"
MAXIMUM LIKELIHOOD SDE SOLVER,0.13131313131313133,"(σ∗
t,h)2 = σ2
t−h,t + 1"
MAXIMUM LIKELIHOOD SDE SOLVER,0.13333333333333333,"nν2
t−h,tEXt [Tr (Var (X0|Xt))] , (10)"
MAXIMUM LIKELIHOOD SDE SOLVER,0.13535353535353536,"where n is data dimensionality, Var (X0|Xt) is the covariance matrix of the conditional data distri-
bution Law(X0|Xt) (so, Tr(Var (X0|Xt)) is the overall variance across all n dimensions) and the
expectation EXt[·] is taken with respect to the unconditional noisy data distribution Law(Xt)."
MAXIMUM LIKELIHOOD SDE SOLVER,0.13737373737373737,"Theorem 1. Consider a DPM characterized by SDEs (6) with reverse diffusion trained till optimality.
Let N ∈N be any natural number and h = 1/N. Consider the following class of ﬁxed step size h
reverse SDE solvers parameterized with triplets of real numbers {(ˆκt,h, ˆωt,h, ˆσt,h)|t = h, 2h, .., 1}:"
MAXIMUM LIKELIHOOD SDE SOLVER,0.1393939393939394,"ˆXt−h = ˆXt + βth
1"
MAXIMUM LIKELIHOOD SDE SOLVER,0.1414141414141414,"2 + ˆωt,h"
MAXIMUM LIKELIHOOD SDE SOLVER,0.14343434343434344,"
ˆXt + (1 + ˆκt,h)sθ∗( ˆXt, t)

+ ˆσt,hξt,
(11)"
MAXIMUM LIKELIHOOD SDE SOLVER,0.14545454545454545,"where θ∗is given by (8), t = 1, 1 −h, .., h and ξt are i.i.d. samples from N(0, I). Then:"
MAXIMUM LIKELIHOOD SDE SOLVER,0.14747474747474748,"(i) Log-likelihood of sample paths X = {Xkh}N
k=0 under generative model ˆX is maximized
for ˆκt,h = κ∗
t,h, ˆωt,h = ω∗
t,h and ˆσt,h = σ∗
t,h."
MAXIMUM LIKELIHOOD SDE SOLVER,0.1494949494949495,"(ii) Assume that the SDE solver (11) starts from random variable ˆX1 ∼Law (X1). If X0 is a
constant or a Gaussian random variable with diagonal isotropic covariance matrix (i.e. δ2 I
for δ > 0), then generative model ˆX is exact for ˆκt,h = κ∗
t,h, ˆωt,h = ω∗
t,h and ˆσt,h = σ∗
t,h."
MAXIMUM LIKELIHOOD SDE SOLVER,0.15151515151515152,Published as a conference paper at ICLR 2022
MAXIMUM LIKELIHOOD SDE SOLVER,0.15353535353535352,Table 1: Input types for speaker conditioning gt(Y ) compared in terms of speaker similarity.
MAXIMUM LIKELIHOOD SDE SOLVER,0.15555555555555556,"Diff-LibriTTS
Diff-VCTK
d-only
wodyn
whole
d-only
wodyn
whole
Most similar
27.0%
38.0%
34.1%
27.2%
46.7%
23.6%
Least similar
28.9%
29.3%
38.5%
25.3%
23.9%
48.6%"
MAXIMUM LIKELIHOOD SDE SOLVER,0.15757575757575756,"The Theorem 1 provides an improved DPM sampling scheme which comes at no additional compu-
tational cost compared to standard methods (except for data-dependent term in σ∗as discussed in
Section 4.3) and requires neither model re-training nor extensive search on noise schedule space. The
proof of this theorem is given in Appendix C. Note that it establishes optimality of the reverse SDE
solver (11) with the parameters (10) in terms of likelihood of discrete paths X = {Xkh}N
k=0 while
the optimality of continuous model (6-R) on continuous paths {Xt}t∈[0,1] is guaranteed for a model
with parameters θ = θ∗as shown in (Song et al., 2021c)."
MAXIMUM LIKELIHOOD SDE SOLVER,0.1595959595959596,"The class of reverse SDE solvers considered in the Theorem 1 is rather broad: it is the class of all
ﬁxed-step solvers whose increments at time t are linear combination of ˆXt, sθ( ˆXt, t) and Gaussian
noise with zero mean and diagonal isotropic covariance matrix. As a particular case it includes
Euler-Maruyama solver (ˆκt,h ≡0, ˆωt,h ≡0, ˆσt,h ≡√βth) and for ﬁxed t and h →0 we have
κ∗
t,h = ¯o(1), ω∗
t,h = ¯o(1) and σ∗
t,h = √βth(1 + ¯o(1)) (the proof is given in Appendix B), so the
optimal SDE solver signiﬁcantly differs from general-purpose Euler-Maruyama solver only when
N is rather small or t has the same order as h, i.e. on the ﬁnal steps of DPM inference. Appendix
G contains toy examples demonstrating the difference of the proposed optimal SDE solver and
Euler-Maruyama one depending on step size."
MAXIMUM LIKELIHOOD SDE SOLVER,0.16161616161616163,"The result (ii) from the Theorem 1 strengthens the result (i) for some particular data distributions, but
it may seem useless since in practice data distribution is far from being constant or Gaussian. However,
in case of generation with strong conditioning (e.g. mel-spectrogram inversion) the assumptions
on the data distribution may become viable: in the limiting case when our model is conditioned on
c = ψ(X0) for an injective function ψ, random variable X0|c becomes a constant ψ−1(c)."
EXPERIMENTS,0.16363636363636364,"4
EXPERIMENTS"
EXPERIMENTS,0.16565656565656567,"We trained two groups of models: Diff-VCTK models on VCTK (Yamagishi et al., 2019) dataset
containing 109 speakers (9 speakers were held out for testing purposes) and Diff-LibriTTS models on
LibriTTS (Zen et al., 2019) containing approximately 1100 speakers (10 speakers were held out). For
every model both encoder and decoder were trained on the same dataset. Training hyperparameters,
implementation and data processing details can be found in Appendix I. For mel-spectrogram
inversion, we used the pre-trained universal HiFi-GAN vocoder (Kong et al., 2020) operating at
22.05kHz. All subjective human evaluation was carried out on Amazon Mechanical Turk (AMT)
with Master assessors to ensure the reliability of the obtained Mean Opinion Scores (MOS). In all
AMT tests we considered unseen-to-unseen conversion with 25 unseen (for both Diff-VCTK and
Diff-LibriTTS) speakers: 9 VCTK speakers, 10 LibriTTS speakers and 6 internal speakers. For
VCTK source speakers we also ensured that source phrases were unseen during training. We place
other details of listening AMT tests in Appendix J. A small subset of speech samples used in them
is available at our demo page https://diffvc-fast-ml-solver.github.io which we
encourage to visit. The code will soon be published at https://github.com/huawei-noah/
Speech-Backbones."
EXPERIMENTS,0.16767676767676767,"As for sampling, we considered the following class of reverse SDE solvers:"
EXPERIMENTS,0.1696969696969697,"ˆXt−h = ˆXt + βth
1"
EXPERIMENTS,0.1717171717171717,"2 + ˆωt,h"
EXPERIMENTS,0.17373737373737375,"
( ˆXt −¯X) + (1 + ˆκt,h)sθ( ˆXt, ¯X, gt(Y ), t)

+ ˆσt,hξt,
(12)"
EXPERIMENTS,0.17575757575757575,"where t = 1, 1 −h, .., h and ξt are i.i.d. samples from N(0, I). For ˆκt,h = κ∗
t,h, ˆωt,h = ω∗
t,h
and ˆσt,h = σ∗
t,h (where κ∗
t,h, ω∗
t,h and σ∗
t,h are given by (10)) it becomes maximum likelihood
reverse SDE solver for MR-VP DPM (1-2) as shown in Appendix D. In practice it is not trivial
to estimate variance of the conditional distribution Law (X0|Xt), so we skipped this term in σ∗
t,h"
EXPERIMENTS,0.17777777777777778,Published as a conference paper at ICLR 2022
EXPERIMENTS,0.1797979797979798,"Table 2: Subjective evaluation (MOS) of one-shot VC models trained on VCTK. Ground truth
recordings were evaluated only for VCTK speakers."
EXPERIMENTS,0.18181818181818182,"VCTK test (9 speakers, 54 pairs)
Whole test (25 speakers, 350 pairs)
Naturalness
Similarity
Naturalness
Similarity
AGAIN-VC
1.98 ± 0.05
1.97 ± 0.08
1.87 ± 0.03
1.75 ± 0.04
FragmentVC
2.20 ± 0.06
2.45 ± 0.09
1.91 ± 0.03
1.93 ± 0.04
VQMIVC
2.89 ± 0.06
2.60 ± 0.10
2.48 ± 0.04
1.95 ± 0.04
Diff-VCTK-ML-6
3.73 ± 0.06
3.47 ± 0.09
3.39 ± 0.04
2.69 ± 0.05
Diff-VCTK-ML-30
3.73 ± 0.06
3.57 ± 0.09
3.44 ± 0.04
2.71 ± 0.05
Ground truth
4.55 ± 0.05
4.52 ± 0.07
4.55 ± 0.05
4.52 ± 0.07"
EXPERIMENTS,0.18383838383838383,Table 3: Subjective evaluation (MOS) of one-shot VC models trained on large-scale datasets.
EXPERIMENTS,0.18585858585858586,"VCTK test (9 speakers, 54 pairs)
Whole test (25 speakers, 350 pairs)
Naturalness
Similarity
Naturalness
Similarity
Diff-LibriTTS-EM-6
1.68 ± 0.06
1.53 ± 0.07
1.57 ± 0.02
1.47 ± 0.03
Diff-LibriTTS-PF-6
3.11 ± 0.07
2.58 ± 0.11
2.99 ± 0.03
2.50 ± 0.04
Diff-LibriTTS-ML-6
3.84 ± 0.08
3.08 ± 0.11
3.80 ± 0.03
3.27 ± 0.05
Diff-LibriTTS-ML-30
3.96 ± 0.08
3.23 ± 0.11
4.02 ± 0.03
3.39 ± 0.05
BNE-PPG-VC
3.95 ± 0.08
3.27 ± 0.12
3.83 ± 0.03
3.03 ± 0.05"
EXPERIMENTS,0.18787878787878787,"assuming this variance to be rather small because of strong conditioning on gt(Y ) and just used
ˆσt,h = σt−h,t calling this sampling method ML-N (N = 1/h is the number of SDE solver steps).
We also experimented with Euler-Maruyama solver EM-N (i.e. ˆκt,h = 0, ˆωt,h = 0, ˆσt,h = √βth)
and “probability ﬂow sampling” from (Song et al., 2021c) which we denote by PF-N (ˆκt,h = −0.5,
ˆωt,h = 0, ˆσt,h = 0)."
SPEAKER CONDITIONING ANALYSIS,0.1898989898989899,"4.1
SPEAKER CONDITIONING ANALYSIS"
SPEAKER CONDITIONING ANALYSIS,0.1919191919191919,"For each dataset we trained three models – one for each input type for the speaker conditioning
network gt(Y ) (see Section 2.2). Although these input types had much inﬂuence neither on speaker
similarity nor on speech naturalness, we did two experiments to choose the best models (one for
each training dataset) in terms of speaker similarity for further comparison with baseline systems.
We compared voice conversion results (produced by ML-30 sampling scheme) on 92 source-target
pairs. AMT workers were asked which of three models (if any) sounded most similar to the target
speaker and which of them (if any) sounded least similar. For Diff-VCTK and Diff-LibriTTS models
each conversion pair was evaluated 4 and 5 times respectively. Table 1 demonstrates that for both
Diff-VCTK and Diff-LibriTTS the best option is wodyn, i.e. to condition the decoder at time t on the
speaker embedding together with the noisy target mel-spectrogram Yt. Conditioning on Yt allows
making use of diffusion-speciﬁc information of how the noisy target sounds whereas embedding
from the pre-trained speaker veriﬁcation network contains information only about the clean target.
Taking these results into consideration, we used Diff-VCTK-wodyn and Diff-LibriTTS-wodyn in the
remaining experiments."
ANY-TO-ANY VOICE CONVERSION,0.19393939393939394,"4.2
ANY-TO-ANY VOICE CONVERSION"
ANY-TO-ANY VOICE CONVERSION,0.19595959595959597,"We chose four recently proposed VC models capable of one-shot many-to-many synthesis as the
baselines:"
ANY-TO-ANY VOICE CONVERSION,0.19797979797979798,"• AGAIN-VC (Chen et al., 2021b), an improved version of a conventional autoencoder AdaIN-
VC solving the disentanglement problem by means of instance normalization;"
ANY-TO-ANY VOICE CONVERSION,0.2,"• FragmentVC (Lin et al., 2021), an attention-based model relying on wav2vec 2.0 (Baevski
et al., 2020) to obtain speech content from the source utterance;"
ANY-TO-ANY VOICE CONVERSION,0.20202020202020202,Published as a conference paper at ICLR 2022
ANY-TO-ANY VOICE CONVERSION,0.20404040404040405,Table 4: Reverse SDE solvers compared in terms of FID. N is the number of SDE solver steps.
ANY-TO-ANY VOICE CONVERSION,0.20606060606060606,"VP DPM
sub-VP DPM
VE DPM
N=10
N=100
N=10
N=100
N=10
N=100
Euler-Maruyama
229.6
19.68
312.3
19.83
462.1
24.77
Reverse Diffusion
679.8
65.95
312.2
19.74
461.1
303.2
Probability Flow
88.92
5.70
64.22
4.42
495.3
214.5
Ancestral Sampling
679.8
68.35
—
—
454.7
17.83
Maximum Likelihood (τ = 0.1)
260.3
4.34
317.0
6.63
461.9
23.63
Maximum Likelihood (τ = 0.5)
24.45
7.82
30.90
6.43
462.0
10.07
Maximum Likelihood (τ = 1.0)
41.78
7.94
48.02
6.51
48.51
12.37"
ANY-TO-ANY VOICE CONVERSION,0.2080808080808081,"• VQMIVC (Wang et al., 2021), state-of-the-art approach among those employing vector
quantization techniques;
• BNE-PPG-VC (Liu et al., 2021b), an improved variant of PPG-based VC models combining
a bottleneck feature extractor obtained from a phoneme recognizer with a seq2seq-based
synthesis module."
ANY-TO-ANY VOICE CONVERSION,0.2101010101010101,"As shown in (Kim et al., 2021), PPG-based VC models provide high voice conversion quality
competitive even with that of the state-of-the-art VC models taking text transcription corresponding
to the source utterance as input. Therefore, we can consider BNE-PPG-VC a state-of-the-art model in
our setting."
ANY-TO-ANY VOICE CONVERSION,0.21212121212121213,"Baseline voice conversion results were produced by the pre-trained VC models provided in ofﬁcial
GitHub repositories. Since only BNE-PPG-VC has the model pre-trained on a large-scale dataset
(namely, LibriTTS + VCTK), we did two subjective human evaluation tests: the ﬁrst one comparing
Diff-VCTK with AGAIN-VC, FragmentVC and VQMIVC trained on VCTK and the second one
comparing Diff-LibriTTS with BNE-PPG-VC. The results of these tests are given in Tables 2 and
3 respectively. Speech naturalness and speaker similarity were assessed separately. AMT workers
evaluated voice conversion quality on 350 source-target pairs on 5-point scale. In the ﬁrst test, each
pair was assessed 6 times on average both in speech naturalness and speaker similarity evaluation;
as for the second one, each pair was assessed 8 and 9 times on average in speech naturalness and
speaker similarity evaluation correspondingly. No less than 41 unique assessors took part in each test."
ANY-TO-ANY VOICE CONVERSION,0.21414141414141413,"Table 2 demonstrates that our model performs signiﬁcantly better than the baselines both in terms of
naturalness and speaker similarity even when 6 reverse diffusion iterations are used. Despite working
almost equally well on VCTK speakers, the best baseline VQMIVC shows poor performance on other
speakers perhaps because of not being able to generalize to different domains with lower recording
quality. Although Diff-VCTK performance also degrades on non-VCTK speakers, it achieves good
speaker similarity of MOS 3.6 on VCTK ones when ML-30 sampling scheme is used and only slightly
worse MOS 3.5 when 5x less iterations are used at inference."
ANY-TO-ANY VOICE CONVERSION,0.21616161616161617,"Table 3 contains human evaluation results of Diff-LibriTTS for four sampling schemes: ML-30 with
30 reverse SDE solver steps and ML-6, EM-6 and PF-6 with 6 steps of reverse diffusion. The three
schemes taking 6 steps achieved real-time factor (RTF) around 0.1 on GPU (i.e. inference was 10
times faster than real time) while the one taking 30 steps had RTF around 0.5. The proposed model
Diff-LibriTTS-ML-30 and the baseline BNE-PPG-VC show the same performance on the VCTK test
set in terms of speech naturalness the latter being slightly better in terms of speaker similarity which
can perhaps be explained by the fact that BNE-PPG-VC was trained on the union of VCTK and
LibriTTS whereas our model was trained only on LibriTTS. As for the whole test set containing
unseen LibriTTS and internal speakers also, Diff-LibriTTS-ML-30 outperforms BNE-PPG-VC model
achieving MOS 4.0 and 3.4 in terms of speech naturalness and speaker similarity respectively. Due to
employing PPG extractor trained on a large-scale ASR dataset LibriSpeech (Panayotov et al., 2015),
BNE-PPG-VC has fewer mispronunciation issues than our model but synthesized speech suffers
from more sonic artifacts. This observation makes us believe that incorporating PPG features in the
proposed diffusion VC framework is a promising direction for future research."
ANY-TO-ANY VOICE CONVERSION,0.21818181818181817,"Table 3 also demonstrates the beneﬁts of the proposed maximum likelihood sampling scheme over
other sampling methods for a small number of inference steps: only ML-N scheme allows us to"
ANY-TO-ANY VOICE CONVERSION,0.2202020202020202,Published as a conference paper at ICLR 2022
ANY-TO-ANY VOICE CONVERSION,0.2222222222222222,"use as few as N = 6 iterations with acceptable quality degradation of MOS 0.2 and 0.1 in terms of
naturalness and speaker similarity respectively while two other competing methods lead to much
more signiﬁcant quality degradation."
MAXIMUM LIKELIHOOD SAMPLING,0.22424242424242424,"4.3
MAXIMUM LIKELIHOOD SAMPLING"
MAXIMUM LIKELIHOOD SAMPLING,0.22626262626262628,"Figure 2: CIFAR-10 images randomly sampled from VP DPM by running 10 reverse diffusion steps
with the following schemes (from left to right): “euler-maruyama”, “probability ﬂow”, “maximum
likelihood (τ = 0.5)”, “maximum likelihood (τ = 1.0)”."
MAXIMUM LIKELIHOOD SAMPLING,0.22828282828282828,"To show that the maximum likelihood sampling scheme proposed in Section 3 generalizes to different
tasks and DPM types, we took the models trained by Song et al. (2021c) on CIFAR-10 image
generation task and compared our method with other sampling schemes described in that paper in
terms of Fr´echet Inception Distance (FID)."
MAXIMUM LIKELIHOOD SAMPLING,0.23030303030303031,"The main difﬁculty in applying maximum likelihood SDE solver is estimating data-dependent term
E[Tr (Var (X0|Xt))] in σ∗
t,h. Although in the current experiments we just set this term to zero, we
can think of two possible ways to estimate it: (i) approximate Var (X0|Xt) with Var ( ˆX0| ˆXt = Xt):
sample noisy data Xt, solve reverse SDE with sufﬁciently small step size starting from terminal
condition ˆXt = Xt several times, and calculate sample variance of the resulting solutions at initial
points ˆX0; (ii) use the formula (58) from Appendix C to calculate Var (X0|Xt) assuming that X0 is
distributed normally with mean and variance equal to sample mean and sample variance computed
on the training dataset. Experimenting with these techniques and exploring new ones seems to be an
interesting future research direction."
MAXIMUM LIKELIHOOD SAMPLING,0.23232323232323232,"Another important practical consideration is that the proposed scheme is proven to be optimal only
for score matching networks trained till optimality. Therefore, in the experiments whose results are
reported in Table 4 we apply maximum likelihood sampling scheme only when t ≤τ while using
standard Euler-Maruyama solver for t > τ for some hyperparameter τ ∈[0, 1]. Such a modiﬁcation
relies on the assumption that score matching network is closer to being optimal for smaller noise."
MAXIMUM LIKELIHOOD SAMPLING,0.23434343434343435,"Table 4 shows that despite likelihood and FID are two metrics that do not perfectly correlate (Song
et al., 2021b), in most cases our maximum likelihood SDE solver performs best in terms of FID. Also,
it is worth mentioning that although τ = 1 is always rather a good choice, tuning this hyperparameter
can lead to even better performance. One can ﬁnd randomly chosen generated images for various
sampling methods in Figure 2."
CONCLUSION,0.23636363636363636,"5
CONCLUSION"
CONCLUSION,0.2383838383838384,"In this paper, the novel one-shot many-to-many voice conversion model has been presented. Its
encoder design and powerful diffusion-based decoder made it possible to achieve good results both in
terms of speaker similarity and speech naturalness even on out-of-domain unseen speakers. Subjective
human evaluation veriﬁed that the proposed model delivers scalable VC solution with competitive
performance. Furthermore, aiming at fast synthesis, we have developed and theoretically justiﬁed the
novel sampling scheme. The main idea behind it is to modify the general-purpose Euler-Maruyama
SDE solver so as to maximize the likelihood of discrete sample paths of the forward diffusion. Due
to the proposed sampling scheme, our VC model is capable of high-quality voice conversion with as
few as 6 reverse diffusion steps. Moreover, experiments on the image generation task show that all
known diffusion model types can beneﬁt from the proposed SDE solver."
CONCLUSION,0.2404040404040404,Published as a conference paper at ICLR 2022
REFERENCES,0.24242424242424243,REFERENCES
REFERENCES,0.24444444444444444,"Brian D.O. Anderson. Reverse-time Diffusion Equation Models. Stochastic Processes and their
Applications, 12(3):313 – 326, 1982. ISSN 0304-4149."
REFERENCES,0.24646464646464647,"Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. wav2vec 2.0: A Framework
for Self-Supervised Learning of Speech Representations. In Advances in Neural Information
Processing Systems, volume 33, pp. 12449–12460. Curran Associates, Inc., 2020."
REFERENCES,0.24848484848484848,"Alexandros Beskos and Gareth O. Roberts. Exact Simulation of Diffusions. The Annals of Applied
Probability, 15(4):2422–2444, 2005. ISSN 10505164."
REFERENCES,0.2505050505050505,"Nanxin Chen, Yu Zhang, Heiga Zen, Ron J Weiss, Mohammad Norouzi, and William Chan. WaveG-
rad: Estimating Gradients for Waveform Generation. In International Conference on Learning
Representations, 2021a."
REFERENCES,0.25252525252525254,"Yen-Hao Chen, D. Wu, Tsung-Han Wu, and Hung yi Lee. Again-VC: A One-Shot Voice Conversion
Using Activation Guidance and Adaptive Instance Normalization. In ICASSP 2021 - 2021 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 5954–5958,
2021b."
REFERENCES,0.2545454545454545,"Ju-Chieh Chou and Hung-yi Lee. One-Shot Voice Conversion by Separating Speaker and Content
Representations with Instance Normalization. In Interspeech 2019, 20th Annual Conference of
the International Speech Communication Association, Graz, Austria, 15-19 September 2019, pp.
664–668. ISCA, 2019."
REFERENCES,0.25656565656565655,"Pierre Henry-Labord`ere, Xiaolu Tan, and Nizar Touzi. Unbiased Simulation of Stochastic Differential
Equations. The Annals of Applied Probability, 27(6):3305–3341, 2017. ISSN 10505164."
REFERENCES,0.2585858585858586,"Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising Diffusion Probabilistic Models. In Advances in
Neural Information Processing Systems 33: Annual Conference on Neural Information Processing
Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, volume 33. Curran Associates, Inc.,
2020."
REFERENCES,0.2606060606060606,"Aapo Hyv¨arinen. Estimation of Non-Normalized Statistical Models by Score Matching. Journal of
Machine Learning Research, 6(24):695–709, 2005."
REFERENCES,0.26262626262626265,"Tatsuma Ishihara and Daisuke Saito. Attention-Based Speaker Embeddings for One-Shot Voice Con-
version. In Interspeech 2020, 21st Annual Conference of the International Speech Communication
Association, Virtual Event, Shanghai, China, 25-29 October 2020, pp. 806–810. ISCA, 2020."
REFERENCES,0.26464646464646463,"Myeonghun Jeong, Hyeongju Kim, Sung Jun Cheon, Byoung Jin Choi, and Nam Soo Kim. Diff-TTS:
A Denoising Diffusion Model for Text-to-Speech. In Proc. Interspeech 2021, pp. 3605–3609,
2021."
REFERENCES,0.26666666666666666,"Ye Jia, Yu Zhang, Ron Weiss, Quan Wang, Jonathan Shen, Fei Ren, Zhifeng Chen, Patrick Nguyen,
Ruoming Pang, Ignacio Lopez Moreno, and Yonghui Wu. Transfer Learning from Speaker
Veriﬁcation to Multispeaker Text-To-Speech Synthesis.
In Advances in Neural Information
Processing Systems 31, pp. 4480–4490. Curran Associates, Inc., 2018."
REFERENCES,0.2686868686868687,"Hirokazu Kameoka, Takuhiro Kaneko, Kou Tanaka, Nobukatsu Hojo, and Shogo Seki. VoiceGrad:
Non-Parallel Any-to-Many Voice Conversion with Annealed Langevin Dynamics, 2020."
REFERENCES,0.27070707070707073,"Kang-wook Kim, Seung-won Park, and Myun-chul Joe. Assem-VC: Realistic Voice Conversion by
Assembling Modern Speech Synthesis Techniques, 2021."
REFERENCES,0.2727272727272727,"Diederik P. Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational Diffusion Models,
2021."
REFERENCES,0.27474747474747474,"Peter E. Kloeden and Eckhard Platen. Numerical Solution of Stochastic Differential Equations,
volume 23 of Stochastic Modelling and Applied Probability. Springer-Verlag Berlin Heidelberg,
1992."
REFERENCES,0.2767676767676768,Published as a conference paper at ICLR 2022
REFERENCES,0.2787878787878788,"Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae. HiFi-GAN: Generative Adversarial Networks
for Efﬁcient and High Fidelity Speech Synthesis. In Advances in Neural Information Processing
Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
December 6-12, virtual, 2020."
REFERENCES,0.2808080808080808,"Zhifeng Kong and Wei Ping. On Fast Sampling of Diffusion Probabilistic Models. In ICML Workshop
on Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models, 2021."
REFERENCES,0.2828282828282828,"Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro. DiffWave: A Versatile
Diffusion Model for Audio Synthesis. In International Conference on Learning Representations,
2021."
REFERENCES,0.28484848484848485,"Sang-gil Lee, Heeseung Kim, Chaehun Shin, Xu Tan, Chang Liu, Qi Meng, Tao Qin, Wei Chen,
Sungroh Yoon, and Tie-Yan Liu. PriorGrad: Improving Conditional Denoising Diffusion Models
with Data-Driven Adaptive Prior, 2021."
REFERENCES,0.2868686868686869,"Yist Y. Lin, Chung-Ming Chien, Jheng-Hao Lin, Hung-yi Lee, and Lin-Shan Lee. FragmentVC: Any-
To-Any Voice Conversion by End-To-End Extracting and Fusing Fine-Grained Voice Fragments
with Attention. In ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP), pp. 5939–5943, 2021."
REFERENCES,0.28888888888888886,"Robert S. Liptser and Albert N. Shiryaev. Statistics of Random Processes, volume 5 of Stochastic
Modelling and Applied Probability. Springer-Verlag, 1978."
REFERENCES,0.2909090909090909,"Songxiang Liu, Yuewen Cao, Dan Su, and Helen Meng. DiffSVC: A Diffusion Probabilistic Model
for Singing Voice Conversion, 2021a."
REFERENCES,0.29292929292929293,"Songxiang Liu, Yuewen Cao, Disong Wang, Xixin Wu, Xunying Liu, and Helen Meng. Any-to-
Many Voice Conversion With Location-Relative Sequence-to-Sequence Modeling. IEEE/ACM
Transactions on Audio, Speech, and Language Processing, 29:1717–1728, 2021b."
REFERENCES,0.29494949494949496,"Manh Luong and Viet Anh Tran. Many-to-Many Voice Conversion Based Feature Disentanglement
Using Variational Autoencoder. In Proc. Interspeech 2021, pp. 851–855, 2021."
REFERENCES,0.296969696969697,"Michael McAuliffe, Michaela Socolof, Sarah Mihuc, Michael Wagner, and Morgan Sonderegger.
Montreal Forced Aligner: Trainable Text-Speech Alignment Using Kaldi. In Proc. Interspeech
2017, pp. 498–502, 2017."
REFERENCES,0.298989898989899,"Shahan Nercessian. Improved Zero-Shot Voice Conversion Using Explicit Conditioning Signals. In
Interspeech 2020, 21st Annual Conference of the International Speech Communication Association,
Virtual Event, Shanghai, China, 25-29 October 2020, pp. 4711–4715. ISCA, 2020."
REFERENCES,0.301010101010101,"Alexander Quinn Nichol and Prafulla Dhariwal. Improved Denoising Diffusion Probabilistic Mod-
els. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of
Proceedings of Machine Learning Research, pp. 8162–8171. PMLR, 18–24 Jul 2021."
REFERENCES,0.30303030303030304,"Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. Librispeech: An ASR
Corpus Based on Public Domain Audio Books. In 2015 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), pp. 5206–5210, 2015."
REFERENCES,0.30505050505050507,"Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova, and Mikhail Kudinov. Grad-TTS:
A Diffusion Probabilistic Model for Text-to-Speech. In Proceedings of the 38th International
Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of
Proceedings of Machine Learning Research, pp. 8599–8608. PMLR, 2021."
REFERENCES,0.30707070707070705,"Kaizhi Qian, Yang Zhang, Shiyu Chang, Xuesong Yang, and Mark Hasegawa-Johnson. AutoVC: Zero-
Shot Voice Style Transfer with Only Autoencoder Loss. In Proceedings of the 36th International
Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp.
5210–5219. PMLR, 09–15 Jun 2019."
REFERENCES,0.3090909090909091,"Kaizhi Qian, Zeyu Jin, Mark Hasegawa-Johnson, and Gautham J. Mysore. F0-Consistent Many-To-
Many Non-Parallel Voice Conversion Via Conditional Autoencoder. In ICASSP 2020 - 2020 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6284–6288,
2020."
REFERENCES,0.3111111111111111,Published as a conference paper at ICLR 2022
REFERENCES,0.31313131313131315,"Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-Net: Convolutional Networks for Biomedical
Image Segmentation. In Medical Image Computing and Computer-Assisted Intervention – MICCAI
2015, pp. 234–241. Springer International Publishing, 2015."
REFERENCES,0.3151515151515151,"Yuki Saito, Yusuke Ijima, Kyosuke Nishida, and Shinnosuke Takamichi. Non-Parallel Voice Conver-
sion Using Variational Autoencoders Conditioned by Phonetic Posteriorgrams and D-Vectors. In
2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp.
5274–5278, 2018."
REFERENCES,0.31717171717171716,"Robin San-Roman, Eliya Nachmani, and Lior Wolf. Noise Estimation for Generative Diffusion
Models, 2021."
REFERENCES,0.3191919191919192,"Jiaming Song, Chenlin Meng, and Stefano Ermon.
Denoising Diffusion Implicit Models.
In
International Conference on Learning Representations, 2021a."
REFERENCES,0.3212121212121212,"Yang Song, Conor Durkan, Iain Murray, and Stefano Ermon. Maximum Likelihood Training of
Score-Based Diffusion Models, 2021b."
REFERENCES,0.32323232323232326,"Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and
Ben Poole. Score-Based Generative Modeling through Stochastic Differential Equations. In
International Conference on Learning Representations, 2021c."
REFERENCES,0.32525252525252524,"Pascal Vincent. A Connection Between Score Matching and Denoising Autoencoders. Neural
Computation, 23(7):1661–1674, 2011."
REFERENCES,0.32727272727272727,"Disong Wang, Liqun Deng, Yu Ting Yeung, Xiao Chen, Xunying Liu, and Helen Meng. VQMIVC:
Vector Quantization and Mutual Information-Based Unsupervised Speech Representation Disen-
tanglement for One-Shot Voice Conversion. In Proc. Interspeech 2021, pp. 1344–1348, 2021."
REFERENCES,0.3292929292929293,"Daniel Watson, Jonathan Ho, Mohammad Norouzi, and William Chan. Learning to Efﬁciently
Sample from Diffusion Probabilistic Models, 2021."
REFERENCES,0.33131313131313134,"Da-Yi Wu, Yen-Hao Chen, and Hung-yi Lee. VQVC+: One-Shot Voice Conversion by Vector
Quantization and U-Net Architecture. In Helen Meng, Bo Xu, and Thomas Fang Zheng (eds.),
Interspeech 2020, 21st Annual Conference of the International Speech Communication Association,
Virtual Event, Shanghai, China, 25-29 October 2020, pp. 4691–4695. ISCA, 2020."
REFERENCES,0.3333333333333333,"Junichi Yamagishi, Christophe Veaux, and Kirsten MacDonald. CSTR VCTK Corpus: English
Multi-speaker Corpus for CSTR Voice Cloning Toolkit (version 0.92), 2019."
REFERENCES,0.33535353535353535,"Heiga Zen, Rob Clark, Ron J. Weiss, Viet Dang, Ye Jia, Yonghui Wu, Yu Zhang, and Zhifeng Chen.
LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech. In Interspeech, 2019."
REFERENCES,0.3373737373737374,Published as a conference paper at ICLR 2022
REFERENCES,0.3393939393939394,"A
FORWARD VP SDE SOLUTION"
REFERENCES,0.3414141414141414,"Since function γ−1
0,t Xt is linear in Xt, taking its differential does not require second order derivative
term in Itˆo’s formula:"
REFERENCES,0.3434343434343434,"d(γ−1
0,t Xt) = d

e
1
2
R t
0 βuduXt
"
REFERENCES,0.34545454545454546,"= e
1
2
R t
0 βudu · 1"
REFERENCES,0.3474747474747475,"2βtXtdt + e
1
2
R t
0 βudu ·

−1"
REFERENCES,0.34949494949494947,"2βtXtdt +
p"
REFERENCES,0.3515151515151515,"βtd−→
Wt  =
p"
REFERENCES,0.35353535353535354,"βte
1
2
R t
0 βudud−→
Wt. (13)"
REFERENCES,0.35555555555555557,Integrating this expression from s to t results in an Itˆo’s integral:
REFERENCES,0.3575757575757576,"e
1
2
R t
0 βuduXt −e
1
2
R s
0 βuduXs =
Z t s p"
REFERENCES,0.3595959595959596,"βτe
1
2
R τ
0 βudud−→
Wτ,
(14) or"
REFERENCES,0.3616161616161616,Xt = e−1
R T,0.36363636363636365,"2
R t
s βuduXs +
Z t s p βτe−1"
R T,0.3656565656565657,"2
R t
τ βudud−→
Wτ.
(15)"
R T,0.36767676767676766,"The integrand on the right-hand side is deterministic and belongs to L2[0, 1] (for practical noise
schedule choices), so its Itˆo’s integral is a normal random variable, a martingale (meaning it has zero
mean) and satisﬁes Itˆo’s isometry which allows to calculate its variance:"
R T,0.3696969696969697,"Var(Xt|Xs) =
Z t"
R T,0.3717171717171717,"s
βτe−
R t
τ βudu I dτ =

1 −e−
R t
s βudu
I .
(16) Thus"
R T,0.37373737373737376,"Law(Xt|Xs) = N

e−1"
R T,0.37575757575757573,"2
R t
s βuduXs,

1 −e−
R t
s βudu
I

= N(γs,tXs, (1 −γ2
s,t) I)
(17)"
R T,0.37777777777777777,"B
THE OPTIMAL COEFFICIENTS ASYMPTOTICS"
R T,0.3797979797979798,First derive asymptotics for γ:
R T,0.38181818181818183,"γt−h,t = e−1"
R T,0.3838383838383838,"2
R t
t−h βudu = 1 −1"
R T,0.38585858585858585,"2βth + ¯o(h),
(18)"
R T,0.3878787878787879,"γ2
0,t−h = e−
R t−h
0
βudu = e−
R t
0 βudue
R t
t−h βudu = γ2
0,t(1 + βth) + ¯o(h),
(19)"
R T,0.3898989898989899,"γ0,t−h = e−1"
R T,0.39191919191919194,"2
R t−h
0
βudu = e−1"
R T,0.3939393939393939,"2
R t
0 βudue
1
2
R t
t−h βudu = γ0,t(1 + 1"
R T,0.39595959595959596,"2βth) + ¯o(h),
(20)"
R T,0.397979797979798,"γ2
t−h,t = e−
R t
t−h βudu = 1 −βth + ¯o(h).
(21)"
R T,0.4,"Then ﬁnd asymptotics for µ, ν and σ2:"
R T,0.402020202020202,"µt−h,t =

1 −1"
R T,0.40404040404040403,"2βth + ¯o(h)
 1 −γ2
0,t −γ2
0,tβth + ¯o(h)
1 −γ2
0,t
= 1−1"
R T,0.40606060606060607,"2βth−
γ2
0,t
1 −γ2
0,t
βth+¯o(h), (22)"
R T,0.4080808080808081,"νt−h,t = (γ0,t(1 + 1"
R T,0.4101010101010101,2βth) + ¯o(h))βth + ¯o(h)
R T,0.4121212121212121,"1 −γ2
0,t
=
γ0,t
1 −γ2
0,t
βth + ¯o(h),
(23)"
R T,0.41414141414141414,"σ2
t−h,t =
1
1 −γ2
0,t
(βth + ¯o(h))(1 −γ2
0,t(1 + βth) + ¯o(h)) = βth + ¯o(h).
(24)"
R T,0.4161616161616162,Published as a conference paper at ICLR 2022
R T,0.41818181818181815,"Finally we get asymptotics for κ∗, ω∗and σ∗:"
R T,0.4202020202020202,"κ∗
t,h = νt−h,t(1 −γ2
0,t)
γ0,tβth
−1 =
γ0,t−h(1 −γ2
t−h,t)
γ0,tβth
−1"
R T,0.4222222222222222,= (βth + ¯o(h))((1 + 1
R T,0.42424242424242425,"2βth)γ0,t + ¯o(h))
γ0,tβth
−1 = ¯o(1), (25)"
R T,0.4262626262626263,"βthω∗
t,h = µt−h,t −1 + νt−h,t"
R T,0.42828282828282827,"γ0,t
−1"
R T,0.4303030303030303,2βth = 1 −1
R T,0.43232323232323233,"2βth −
γ2
0,t
1 −γ2
0,t
βth −1 −1"
R T,0.43434343434343436,"2βth +
1
γ0,t
× ×"
R T,0.43636363636363634,"γ0,t
1 −γ2
0,t
βth + ¯o(h) !"
R T,0.4383838383838384,+ ¯o(h) = βth 
R T,0.4404040404040404,"−1 −
γ2
0,t
1 −γ2
0,t
+
1
1 −γ2
0,t !"
R T,0.44242424242424244,"+ ¯o(h) = ¯o(h), (26)"
R T,0.4444444444444444,"(σ∗
t,h)2 = σ2
t−h,t + ν2
t−h,tEXt [Tr (Var (X0|Xt))] /n = βth + ¯o(h)"
R T,0.44646464646464645,"+
γ2
0,t
(1 −γ2
0,t)2 β2
t h2EXt [Tr (Var (X0|Xt))] /n = βth(1 + ¯o(1)).
(27)"
R T,0.4484848484848485,"C
PROOF OF THE THEOREM 1"
R T,0.4505050505050505,"The key fact necessary to prove the Theorem 1 is established in the following
Lemma 1. Let p0|t(·|x) be pdf of conditional distribution Law (X0|Xt = x). Then for any t ∈[0, 1]
and x ∈Rn"
R T,0.45252525252525255,"sθ∗(x, t) = −
1
1 −γ2
0,t"
R T,0.45454545454545453,"
x −γ0,tEp0|t(·|x)X0

.
(28)"
R T,0.45656565656565656,"Proof of the Lemma 1. As mentioned in (Song et al., 2021c), an expression alternative to (8) can be
derived for θ∗under mild assumptions on the data density (Hyv¨arinen, 2005; Vincent, 2011):"
R T,0.4585858585858586,"θ∗= arg min
θ Z 1"
R T,0.46060606060606063,"0
λtEX0∼p0(·)EXt∼pt|0(·|X0)∥sθ(Xt, t) −∇log pt|0(Xt|X0)∥2
2dt,
(29)"
R T,0.4626262626262626,"where Law (X0) is data distribution with pdf p0(·) and Law (Xt|X0 = x0) has pdf pt|0(·|x0). By
Bayes formula we can rewrite this in terms of pdfs pt(·) and p0|t(·|xt) of distributions Law (Xt) and
Law (X0|Xt = xt) correspondingly:"
R T,0.46464646464646464,"θ∗= arg min
θ Z 1"
R T,0.4666666666666667,"0
λtEXt∼pt(·)EX0∼p0|t(·|Xt)∥sθ(Xt, t) −∇log pt|0(Xt|X0)∥2
2dt.
(30)"
R T,0.4686868686868687,"For any n-dimensional random variable ξ with ﬁnite second moment and deterministic vector a we
have"
R T,0.4707070707070707,"E∥ξ −a∥2
2 = E∥ξ −Eξ + Eξ −a∥2
2 = E∥ξ −Eξ∥2
2 + 2⟨E[ξ −Eξ], Eξ −a⟩"
R T,0.4727272727272727,"+ E∥Eξ −a∥2
2 = E∥ξ −Eξ∥2
2 + ∥Eξ −a∥2
2.
(31)"
R T,0.47474747474747475,"In our case ξ = ∇log pt|0(Xt|X0) and a = sθ(Xt, t), so E∥ξ −Eξ∥2
2 is independent of θ. Thus"
R T,0.4767676767676768,"θ∗= arg min
θ Z 1"
R T,0.47878787878787876,"0
λtEXt∼pt(·)∥sθ(Xt, t) −EX0∼p0|t(·|Xt)

∇log pt|0(Xt|X0)

∥2
2dt.
(32)"
R T,0.4808080808080808,"Therefore, the optimal score estimation network sθ∗can be expressed as"
R T,0.48282828282828283,Published as a conference paper at ICLR 2022
R T,0.48484848484848486,"sθ∗(x, t) = Ep0|t(·|x)

∇log pt|0(x|X0)

(33)"
R T,0.4868686868686869,"for all t ∈[0, 1] and x ∈supp {pt} = Rn."
R T,0.4888888888888889,"As proven in Appendix A, Law (Xt|X0) is Gaussian with mean vector γ0,tX0 and covariance matrix
(1 −γ2
0,t) I, so ﬁnally we obtain"
R T,0.4909090909090909,"sθ∗(x, t) = Ep0|t(·|x) """
R T,0.49292929292929294,"−
1
1 −γ2
0,t
(x −γ0,tX0) #"
R T,0.494949494949495,"= −
1
1 −γ2
0,t"
R T,0.49696969696969695,"
x −γ0,tEp0|t(·|x)X0

.
(34)"
R T,0.498989898989899,Now let us prove the Theorem 1.
R T,0.501010101010101,"Proof of the Theorem 1. The sampling scheme (11) consists in adding Gaussian noise to a linear
combination of ˆXt and sθ∗( ˆXt, t). Combining (11) and the Lemma 1 we get"
R T,0.503030303030303,"ˆXt−h = ˆσt,hξt + ˆXt + βth
1"
R T,0.5050505050505051,"2 + ˆωt,h"
R T,0.5070707070707071,"
ˆXt + (1 + ˆκt,h)sθ∗( ˆXt, t)

= ˆσt,hξt"
R T,0.509090909090909,"+

1 + βth
1"
R T,0.5111111111111111,"2 + ˆωt,h"
R T,0.5131313131313131,"
ˆXt + βth(1 + ˆκt,h) "
R T,0.5151515151515151,"−
1
1 −γ2
0,t"
R T,0.5171717171717172,"
ˆXt −γ0,tEp0|t(·| ˆ
Xt)X0
!"
R T,0.5191919191919192,"= ˆσt,hξt + "
R T,0.5212121212121212,1 + βth
R T,0.5232323232323233,"1
2 + ˆωt,h −1 + ˆκt,h"
R T,0.5252525252525253,"1 −γ2
0,t"
R T,0.5272727272727272,"!!
ˆXt + γ0,tβth(1 + ˆκt,h)"
R T,0.5292929292929293,"1 −γ2
0,t
Ep0|t(·| ˆ
Xt)X0, (35)"
R T,0.5313131313131313,"where ξt are i.i.d. random variables from standard normal distribution N(0, I) for t = 1, 1 −h, .., h.
Thus, the distribution ˆXt−h| ˆXt is also Gaussian:"
R T,0.5333333333333333,"Law ( ˆXt−h| ˆXt) = N

ˆµt,h(ˆκt,h, ˆωt,h) ˆXt + ˆνt,h(ˆκt,h)Ep0|t(·| ˆ
Xt)X0, ˆσ2
t,h I

,
(36)"
R T,0.5353535353535354,"ˆµt,h(ˆκt,h, ˆωt,h) = 1 + βth"
R T,0.5373737373737374,"1
2 + ˆωt,h −1 + ˆκt,h"
R T,0.5393939393939394,"1 −γ2
0,t !"
R T,0.5414141414141415,",
(37)"
R T,0.5434343434343434,"ˆνt,h(ˆκt,h) = γ0,tβth(1 + ˆκt,h)"
R T,0.5454545454545454,"1 −γ2
0,t
,
(38)"
R T,0.5474747474747474,which leads to the following formula for the transition densities of the reverse diffusion:
R T,0.5494949494949495,"ˆpt−h|t(xt−h|xt) =
1
√"
R T,0.5515151515151515,"2πˆσn
t,h
exp "
R T,0.5535353535353535,"−
∥xt−h −ˆµt,hxt −ˆνt,hEp0|t(·|xt)X0∥2
2
2ˆσ2
t,h !"
R T,0.5555555555555556,".
(39)"
R T,0.5575757575757576,"Moreover, comparing ˆµt,h and ˆνt,h with µt−h,t and νt−h,t deﬁned in (9) we deduce that"
R T,0.5595959595959596,"ˆνt,h = νt−h,t ⇔γ0,tβth(1 + ˆκt,h)"
R T,0.5616161616161616,"1 −γ2
0,t
= νt−h,t ⇔ˆκt,h = κ∗
t,h.
(40)"
R T,0.5636363636363636,"If we also want ˆµt,h = µt−h,t to be satisﬁed, then we should have"
R T,0.5656565656565656,Published as a conference paper at ICLR 2022
R T,0.5676767676767677,1 + βth
R T,0.5696969696969697,"1
2 + ˆωt,h −
1 + κ∗
t,h
1 −γ2
0,t !"
R T,0.5717171717171717,"= µt−h,t ⇔
µt−h,t −1"
R T,0.5737373737373738,"βth
−ω∗
t,h + ˆωt,h"
R T,0.5757575757575758,"
βth + 1 = µt−h,t, (41)"
R T,0.5777777777777777,"i.e. ˆνt,h = νt−h,t and ˆµt,h = µt−h,t iff ˆκt,h = κ∗
t,h and ˆωt,h = ω∗
t,h for the parameters κ∗
t,h and ω∗
t,h
deﬁned in (10)."
R T,0.5797979797979798,"As for the corresponding densities of the forward process X, they are Gaussian when conditioned on
the initial data point X0:"
R T,0.5818181818181818,"Law (Xt−h|Xt, X0) = N(µt−h,tXt + νt−h,tX0, σ2
t−h,t I),
(42)"
R T,0.5838383838383838,"where coefﬁcients µt−h,t, νt−h,t and σt−h,t are deﬁned in (9). This formula for Law (Xt−h|Xt, X0)
follows from the general fact about Gaussian distributions appearing in many recent works on
diffusion probabilistic modeling (Kingma et al., 2021): if Zt|Zs ∼N(αt|sZs, σ2
t|s I) and Zt|Z0 ∼
N(αt|0Z0, σ2
t|0 I) for 0 < s < t, then"
R T,0.5858585858585859,"Law (Zs|Zt, Z0) = N"
R T,0.5878787878787879,"σ2
s|0
σ2
t|0
αt|sZt +
σ2
t|s
σ2
t|0
αs|0Z0,
σ2
s|0σ2
t|s
σ2
t|0
I !"
R T,0.5898989898989899,".
(43)"
R T,0.591919191919192,"This fact is a result of applying Bayes formula to normal distributions. In our case αt|s = γs,t and
σ2
t|s = 1 −γ2
s,t."
R T,0.593939393939394,"To get an expression for the densities pt−h|t(xt−h|xt) similar to (39), we need to integrate out the
dependency on data X0 from Gaussian distribution Law (Xt−h|Xt, X0):"
R T,0.5959595959595959,"pt−h|t(xt−h|xt) =
Z
pt−h,0|t(xt−h, x0|xt)dx0 =
Z
pt−h|t,0(xt−h|xt, x0)p0|t(x0|xt)dx0"
R T,0.597979797979798,"= EX0∼p0|t(·|xt)[pt−h|t,0(xt−h|xt, X0)],
(44)"
R T,0.6,which implies the following formula:
R T,0.602020202020202,"pt−h|t(xt−h|xt) =
1
√"
R T,0.604040404040404,"2πσn
t−h,t
Ep0|t(·|xt) "" exp "
R T,0.6060606060606061,"−∥xt−h −µt−h,txt −νt−h,tX0∥2
2
2σ2
t−h,t !#"
R T,0.6080808080808081,".
(45)"
R T,0.6101010101010101,"Note that in contrast with the transition densities (39) of the reverse process ˆX, the corresponding
densities (45) of the forward process X are not normal in general."
R T,0.6121212121212121,"Our goal is to ﬁnd parameters ˆκ, ˆω and ˆσ that maximize log-likelihood of sample paths X under
probability measure with transition densities ˆp. Put tk = kh for k = 0, 1, .., N and write down this
log-likelihood:"
R T,0.6141414141414141,"Z
p(x1, x1−h, .., x0) N−1
X"
R T,0.6161616161616161,"k=0
log ˆptk|tk+1(xtk|xtk+1) + log ˆp1(x1) !"
R T,0.6181818181818182,"dx1dx1−h..dx0 = N−1
X k=0"
R T,0.6202020202020202,"Z
p(xtk, xtk+1) log ˆptk|tk+1(xtk|xtk+1)dxtk+1dxtk +
Z
p(x1) log ˆp1(x1)dx1. (46)"
R T,0.6222222222222222,"The last term does not depend on ˆκ, ˆω and ˆσ, so we can ignore it. Let Rk be the k-th term in the sum
above. Since we are free to have different coefﬁcients ˆκt,h, ˆωt,h and ˆσt,h for different steps, we can
maximize each Rk separately. Terms Rk can be expressed as"
R T,0.6242424242424243,Published as a conference paper at ICLR 2022
R T,0.6262626262626263,"Rk =
Z
p(xtk, xtk+1) log ˆptk|tk+1(xtk|xtk+1)dxtk+1dxtk"
R T,0.6282828282828283,"=
Z
p(xtk+1)ptk|tk+1(xtk|xtk+1) log ˆptk|tk+1(xtk|xtk+1)dxtk+1dxtk"
R T,0.6303030303030303,= EXtk+1
R T,0.6323232323232323,"Z
ptk|tk+1(xtk|Xtk+1) log ˆptk|tk+1(xtk|Xtk+1)dxtk 
. (47)"
R T,0.6343434343434343,"From now on we will skip subscripts of µ, ν, σ, ˆµ, ˆν, ˆσ, ˆκ, ˆω, κ∗and ω∗for brevity. Denote"
R T,0.6363636363636364,"Q(xtk, Xtk+1, X0) =
1
√"
R T,0.6383838383838384,"2πσn exp

−∥xtk −µXtk+1 −νX0∥2
2
2σ2"
R T,0.6404040404040404,"
log ˆptk|tk+1(xtk|Xtk+1). (48)"
R T,0.6424242424242425,"Using the formula (44) for the densities of X together with the explicit expression for the Gaussian
density ptk|tk+1,0(xtk|Xtk+1, X0) and applying Fubini’s theorem to change the order of integration,
we rewrite Rk as"
R T,0.6444444444444445,Rk = EXtk+1
R T,0.6464646464646465,"Z
ptk|tk+1(xtk|Xtk+1) log ˆptk|tk+1(xtk|Xtk+1)dxtk "
R T,0.6484848484848484,= EXtk+1
R T,0.6505050505050505,"Z
EX0∼p0|tk+1(·|Xtk+1)

ptk|tk+1,0(xtk|Xtk+1, X0) log ˆptk|tk+1(xtk|Xtk+1)

dxtk "
R T,0.6525252525252525,= EXtk+1
R T,0.6545454545454545,"Z
EX0∼p0|tk+1(·|Xtk+1)[Q(xtk, Xtk+1, X0)]dxtk "
R T,0.6565656565656566,= EXtk+1EX0∼p0|tk+1(·|Xtk+1)
R T,0.6585858585858586,"Z
Q(xtk, Xtk+1, X0)dxtk 
. (49)"
R T,0.6606060606060606,"The formula (48) implies that the integral of Q(xtk, Xtk+1, X0) with respect to xtk can be seen as
expectation of log ˆptk|tk+1(ξ|Xtk+1) with respect to normal random variable ξ with mean µXtk+1 +
νX0 and covariance matrix σ2 I. Plugging in the expression (39) into (48), we can calculate this
integral: Eξ """
R T,0.6626262626262627,"−log
√"
R T,0.6646464646464646,"2π −n log ˆσ −
∥ξ −ˆµXtk+1 −ˆνEX′
0∼p0|tk+1(·|Xtk+1)X′
0∥2
2
2ˆσ2 #"
R T,0.6666666666666666,"= −log
√"
R T,0.6686868686868687,"2π −n log ˆσ −
Eξ∥ξ −ˆµXtk+1 −ˆνEp0|tk+1(·|Xtk+1)X′
0∥2
2
2ˆσ2
. (50)"
R T,0.6707070707070707,"Thus, terms Rk we want to maximize equal"
R T,0.6727272727272727,"Rk = −log
√"
R T,0.6747474747474748,"2π−n log ˆσ−EXtk+1EX0∼p0|tk+1(·|Xtk+1)
Eξ∥ξ −ˆµXtk+1 −ˆνEp0|tk+1(·|Xtk+1)X′
0∥2
2
2ˆσ2
(51)"
R T,0.6767676767676768,"Maximizing Rk with respect to (ˆκ, ˆω, ˆσ) is equivalent to minimizing EXtk+1Sk where Sk is given by"
R T,0.6787878787878788,"Sk = n log ˆσ +
1
2ˆσ2 EX0∼p0|tk+1(·|Xtk+1)Eξ∥ξ −ˆµXtk+1 −ˆνEp0|tk+1(·|Xtk+1)X′
0∥2
2,
(52)"
R T,0.6808080808080809,"where the expectation with respect to ξ ∼N(µXtk+1 + νX0, σ2 I) can be calculated using the fact
that for every vector ˆa we can express Eξ∥ξ −ˆa∥2
2 as"
R T,0.6828282828282828,Published as a conference paper at ICLR 2022
R T,0.6848484848484848,"E∥ξ−Eξ+Eξ−ˆa∥2
2 = E∥ξ−Eξ∥2
2+2⟨E[ξ−Eξ], Eξ−ˆa⟩+E∥Eξ−ˆa∥2
2 = nσ2+∥Eξ−ˆa∥2
2. (53)"
R T,0.6868686868686869,"So, the outer expectation with respect to Law(X0|Xtk+1) in (52) can be simpliﬁed:"
R T,0.6888888888888889,"EX0∼p0|tk+1(·|Xtk+1)
h
nσ2 + ∥(µ −ˆµ)Xtk+1 + νX0 −ˆνEX′
0∼p0|tk+1(·|Xtk+1)X′
0∥2
2
i"
R T,0.6909090909090909,"= nσ2 + EX0∥((µ −ˆµ)Xtk+1 + νX0 −ˆνEX′
0X′
0∥2
2 = nσ2 + (µ −ˆµ)2∥Xtk+1∥2
2
+ 2⟨(µ −ˆµ)Xtk+1, (ν −ˆν)EX0X0⟩+ EX0∥νX0 −ˆνEX′
0X′
0∥2
2 = (µ −ˆµ)2∥Xtk+1∥2
2
+ 2⟨(µ −ˆµ)Xtk+1, (ν −ˆν)EX0X0⟩+ ν2EX0∥X0∥2
2 + ˆν2∥EX0X0∥2
2 + nσ2"
R T,0.692929292929293,"−2νˆν⟨EX0X0, EX′
0X′
0⟩= ∥(µ −ˆµ)Xtk+1 + (ν −ˆν)EX0X0)∥2
2 + ν2EX0∥X0∥2
2
−ν2∥EX0X0∥2
2 + nσ2, (54)"
R T,0.694949494949495,"where all the expectations in the formula above are taken with respect to the conditional data
distribution Law(X0|Xtk+1). So, the resulting expression for the terms Sk whose expectation with
respect to Law (Xtk+1) we want to minimize is"
R T,0.696969696969697,"Sk = n logˆσ +
1
2ˆσ2"
R T,0.6989898989898989,"
nσ2 + ∥(µ −ˆµ)Xtk+1 + (ν −ˆν)E[X0|Xtk+1]∥2
2"
R T,0.701010101010101,"+ ν2  
E

∥X0∥2
2|Xtk+1

−∥E[X0|Xtk+1]∥2
2

.
(55)"
R T,0.703030303030303,"Now it is clear that κ∗
tk+1,h and ω∗
tk+1,h are optimal because ˆµtk+1,h(κ∗
tk+1,h, ω∗
tk+1,h) = µtk,tk+1
and ˆνtk+1,h(κ∗
tk+1,h) = νtk,tk+1. For this choice of parameters we have"
R T,0.705050505050505,"EXtk+1Sk = n log ˆσ +
1
2ˆσ2"
R T,0.7070707070707071,"
nσ2 + ν2EXtk+1

E

∥X0∥2
2|Xtk+1

−∥E[X0|Xtk+1]∥2
2

.
(56)"
R T,0.7090909090909091,"Note that E

∥X0∥2
2|Xtk+1

−∥E[X0|Xtk+1]∥2
2 = Tr (Var (X0|Xtk+1)) is the overall variance of
Law (X0|Xtk+1) along all n dimensions. Differentiating EXtk+1Sk with respect to ˆσ shows that the
optimal σ∗
tk+1,h should satisfy"
R T,0.7111111111111111,"n
σ∗
tk+1,h
−
1
(σ∗
tk+1,h)3"
R T,0.7131313131313132,"
nσ2
tk,tk+1 + ν2
tk,tk+1EXtk+1

Tr (Var (X0|Xtk+1))

= 0,
(57)"
R T,0.7151515151515152,"which is indeed satisﬁed by the parameters σ∗
t,h deﬁned in (10). Thus, the statement (i) is proven."
R T,0.7171717171717171,"When it comes to proving that ˆX is exact, we have to show that Law ( ˆXtk) = Law (Xtk) for
every k = 0, 1, .., N. By the assumption that Law ( ˆX1) = Law (X1) it is sufﬁcient to prove
that ˆptk|tk+1(xtk|xtk+1) ≡ptk|tk+1(xtk|xtk+1) since the exactness will follow from this fact by
mathematical induction. If X0 is a constant random variable, Law(X0|Xt) = Law (X0) also
corresponds to the same constant, so Var (X0|Xt) = 0 meaning that σ∗
t,h = σt−h,t, and the formulae
(39) and (45) imply the desired result."
R T,0.7191919191919192,"Let us now consider the second case when X0 ∼N(¯µ, δ2 I).
It is a matter of simple but
lengthy computations to prove another property of Gaussian distributions similar to (43): if
Z0 ∼N(¯µ, δ2 I) and Zt|Z0 ∼N(atZ0, b2
t I), then Z0|Zt ∼N(
b2
t
b2
t +δ2a2
t ¯µ +
δ2at
b2
t +δ2a2
t Zt,
δ2b2
t
b2
t +δ2a2
t I)
and Zt ∼N(¯µat, (b2
t + δ2a2
t) I). In our case at = γ0,t and b2
t = 1 −γ2
0,t, therefore"
R T,0.7212121212121212,Law (X0|Xt) = N
R T,0.7232323232323232,"1 −γ2
0,t
1 −γ2
0,t + δ2γ2
0,t
¯µ +
δ2γ0,t
1 −γ2
0,t + δ2γ2
0,t
Xt,
δ2(1 −γ2
0,t)
1 −γ2
0,t + δ2γ2
0,t
I !"
R T,0.7252525252525253,".
(58)"
R T,0.7272727272727273,Published as a conference paper at ICLR 2022
R T,0.7292929292929293,"So, Var (X0|Xt) does not depend on Xt and"
R T,0.7313131313131314,"(σ∗
t,h)2 = σ2
t−h,t +
ν2
t−h,t"
R T,0.7333333333333333,"n
EXt [Tr (Var (X0|Xt))] = σ2
t−h,t + ν2
t−h,t
δ2(1 −γ2
0,t)
1 −γ2
0,t + δ2γ2
0,t
.
(59)"
R T,0.7353535353535353,"Since Law (Xt|Xt−h), Law (Xt−h) and Law (Xt) are Gaussian, Bayes formula implies that
Law (Xt−h|Xt) is Gaussian as well with the following mean and covariance matrix:"
R T,0.7373737373737373,"E[Xt−h|Xt] =
γ0,t−h(1 −γ2
t−h,t)
1 −γ2
0,t + δ2γ2
0,t
¯µ +
γt−h,t(1 −γ2
0,t−h + δ2γ2
0,t−h)
1 −γ2
0,t + δ2γ2
0,t
Xt,
(60)"
R T,0.7393939393939394,"Var (Xt−h|Xt) =
(1 −γ2
t−h,t)(1 −γ2
0,t−h + δ2γ2
0,t−h)
1 −γ2
0,t + δ2γ2
0,t
I .
(61)"
R T,0.7414141414141414,"The distribution Law ( ˆXt−h| ˆXt) is also Gaussian by the formula (39), so to conclude the proof
we just need to show that E[ ˆXt−h| ˆXt = x] = E[Xt−h|Xt = x] and Var ( ˆXt−h| ˆXt = x) =
Var (Xt−h|Xt = x) for every x ∈Rn for the optimal parameters (10). Recall that for κ∗
t,h and ω∗
t,h
we have ˆµt,h(κ∗
t,h, ω∗
t,h) = µt−h,t and ˆνt,h(κ∗
t,h) = νt−h,t. Utilizing the formulae (9), (39), (58) and
the fact that γ0,t−h · γt−h,t = γ0,t (following from the deﬁnition of γ in (7)) we conclude that"
R T,0.7434343434343434,"E[ ˆXt−h| ˆXt = x] = ˆµt,h(κ∗
t,h, ω∗
t,h)x + ˆνt,h(κ∗
t,h)Ep0|t(·|x)X0"
R T,0.7454545454545455,"= γt−h,t
1 −γ2
0,t−h
1 −γ2
0,t
x + γ0,t−h
1 −γ2
t−h,t
1 −γ2
0,t"
R T,0.7474747474747475,"""
1 −γ2
0,t
1 −γ2
0,t + δ2γ2
0,t
¯µ +
δ2γ0,t
1 −γ2
0,t + δ2γ2
0,t
x #"
R T,0.7494949494949495,"= γ0,t−h
1 −γ2
t−h,t
1 −γ2
0,t + δ2γ2
0,t
¯µ + γt−h,t
(1 −γ2
0,t−h)(1 −γ2
0,t) + δ2γ2
0,t(1 −γ2
0,t−h)
(1 −γ2
0,t)(1 −γ2
0,t + δ2γ2
0,t)
x"
R T,0.7515151515151515,"+ γt−h,t
δ2γ2
0,t−h(1 −γ2
t−h,t)
(1 −γ2
0,t)(1 −γ2
0,t + δ2γ2
0,t)x = γ0,t−h
1 −γ2
t−h,t
1 −γ2
0,t + δ2γ2
0,t
¯µ"
R T,0.7535353535353535,"+ γt−h,t
(1 −γ2
0,t−h)(1 −γ2
0,t) + δ2γ2
0,t−h(1 −γ2
0,t)
(1 −γ2
0,t)(1 −γ2
0,t + δ2γ2
0,t)
x = γ0,t−h
1 −γ2
t−h,t
1 −γ2
0,t + δ2γ2
0,t
¯µ"
R T,0.7555555555555555,"+ γt−h,t
1 −γ2
0,t−h + δ2γ2
0,t−h
1 −γ2
0,t + δ2γ2
0,t
x = E[Xt−h|Xt = x], (62)"
R T,0.7575757575757576,"Var ( ˆXt−h| ˆXt = x) = (σ∗
t,h)2 I = "
R T,0.7595959595959596,"σ2
t−h,t + ν2
t−h,t
δ2(1 −γ2
0,t)
1 −γ2
0,t + δ2γ2
0,t ! I ="
R T,0.7616161616161616,"(1 −γ2
0,t−h)(1 −γ2
t−h,t)
1 −γ2
0,t
+ γ2
0,t−h
δ2(1 −γ2
t−h,t)2"
R T,0.7636363636363637,"(1 −γ2
0,t)(1 −γ2
0,t + δ2γ2
0,t) ! I"
R T,0.7656565656565657,"=
1 −γ2
t−h,t
(1 −γ2
0,t)(1 −γ2
0,t + δ2γ2
0,t)
 
(1 −γ2
0,t−h)(1 −γ2
0,t) + δ2γ2
0,t(1 −γ2
0,t−h)

I"
R T,0.7676767676767676,"+
1 −γ2
t−h,t
(1 −γ2
0,t)(1 −γ2
0,t + δ2γ2
0,t)
 
δ2γ2
0,t−h(1 −γ2
t−h,t)

I"
R T,0.7696969696969697,"=
1 −γ2
t−h,t
(1 −γ2
0,t)(1 −γ2
0,t + δ2γ2
0,t)
 
(1 −γ2
0,t−h)(1 −γ2
0,t) + δ2γ2
0,t−h(1 −γ2
0,t)

I"
R T,0.7717171717171717,"=
(1 −γ2
t−h,t)(1 −γ2
0,t−h + δ2γ2
0,t−h)
1 −γ2
0,t + δ2γ2
0,t
I = Var (Xt−h|Xt = x). (63)"
R T,0.7737373737373737,Published as a conference paper at ICLR 2022
R T,0.7757575757575758,"D
REVERSE MR-VP SDE SOLVER"
R T,0.7777777777777778,MR-VP DPM is characterized by the following forward and reverse diffusions:
R T,0.7797979797979798,dXt = 1
R T,0.7818181818181819,"2βt( ¯X −Xt)dt +
p"
R T,0.7838383838383839,"βtd−→
Wt ,
(64)"
R T,0.7858585858585858,"d ˆXt =
1"
R T,0.7878787878787878,"2βt( ¯X −ˆXt) −βtsθ( ˆXt, ¯X, t)

dt +
p"
R T,0.7898989898989899,"βtd←−
Wt.
(65)"
R T,0.7919191919191919,"Using the same method as in Appendix A, we can show that for s < t"
R T,0.793939393939394,"Law (Xt|Xs) = N(γs,tXs + (1 −γs,t) ¯X, (1 −γ2
s,t) I),
γs,t = e−1"
R T,0.795959595959596,"2
R t
s βudu.
(66)"
R T,0.797979797979798,With the following notation:
R T,0.8,"µs,t = γs,t
1 −γ2
0,s
1 −γ2
0,t
,
νs,t = γ0,s
1 −γ2
s,t
1 −γ2
0,t
,
σ2
s,t = (1 −γ2
0,s)(1 −γ2
s,t)
1 −γ2
0,t
(67)"
R T,0.802020202020202,"we can write down the parameters of Gaussian distribution Xs|Xt, X0:"
R T,0.804040404040404,"E[Xs|Xt, X0] = ¯X + µs,t(Xt −¯X) + νs,t(X0 −¯X), Var (Xs|Xt, X0) = σ2
s,t I .
(68)"
R T,0.806060606060606,The Lemma 1 for MR-VP DPMs takes the following shape:
R T,0.8080808080808081,"sθ∗(x, ¯X, t) = −
1
1 −γ2
0,t"
R T,0.8101010101010101,"
x −(1 −γ0,t) ¯X −γ0,tEp0|t(·|x)X0
"
R T,0.8121212121212121,"= −
1
1 −γ2
0,t"
R T,0.8141414141414142,"
(x −¯X) −γ0,t

Ep0|t(·|x)X0 −¯X

.
(69)"
R T,0.8161616161616162,The class of reverse SDE solvers we consider is
R T,0.8181818181818182,"ˆXt−h = ˆXt + βth
1"
R T,0.8202020202020202,"2 + ˆωt,h"
R T,0.8222222222222222,"
( ˆXt −¯X) + (1 + ˆκt,h)sθ( ˆXt, ¯X, t)

+ ˆσt,hξt,
(70)"
R T,0.8242424242424242,"where t = 1, 1 −h, .., h and ξt are i.i.d. samples from N(0, I). Repeating the argument of the
Theorem 1 leads to the following optimal (in terms of likelihood of the forward diffusion sample
paths) parameters:"
R T,0.8262626262626263,"κ∗
t,h =νt−h,t(1 −γ2
0,t)
γ0,tβth
−1,
ω∗
t,h = µt−h,t −1"
R T,0.8282828282828283,"βth
+
1 + κ∗
t,h
1 −γ2
0,t
−1 2,"
R T,0.8303030303030303,"(σ∗
t,h)2 = σ2
t−h,t + 1"
R T,0.8323232323232324,"nν2
t−h,tEXt [Tr (Var (X0|Xt))] , (71)"
R T,0.8343434343434344,"which are actually the same as the optimal parameters (10) for VP DPM. It is of no surprise since
MR-VP DPM and VP-DPM differ only by a constant shift."
R T,0.8363636363636363,"E
REVERSE SUB-VP SDE SOLVER"
R T,0.8383838383838383,Sub-VP DPM is characterized by the following forward and reverse diffusions:
R T,0.8404040404040404,dXt = −1
R T,0.8424242424242424,"2βtXtdt +
q"
R T,0.8444444444444444,"βt(1 −e−2
R t
0 βudu)d−→
Wt ,
(72)"
R T,0.8464646464646465,Published as a conference paper at ICLR 2022
R T,0.8484848484848485,"d ˆXt =

−1"
R T,0.8505050505050505,"2βt ˆXt −βt

1 −e−2
R t
0 βudu
sθ( ˆXt, t)

dt +
q"
R T,0.8525252525252526,"βt(1 −e−2
R t
0 βudu)d←−
Wt.
(73)"
R T,0.8545454545454545,"Using the same method as in Appendix A, we can show that for s < t"
R T,0.8565656565656565,"Law (Xt|Xs) = N(γs,tXs,
 
1 + γ4
0,t −γ2
s,t(1 + γ4
0,s)

I),
γs,t = e−1"
R T,0.8585858585858586,"2
R t
s βudu.
(74)"
R T,0.8606060606060606,Note that for s = 0 this expression simpliﬁes to
R T,0.8626262626262626,"Law (Xt|X0) = N(γ0,tX0, (1 −γ2
0,t)2 I).
(75)"
R T,0.8646464646464647,With the following notation:
R T,0.8666666666666667,"µs,t =γs,t"
R T,0.8686868686868687,"1 −γ2
0,s
1 −γ2
0,t !2"
R T,0.8707070707070707,",
νs,t = γ0,s
1 + γ4
0,t −γ2
s,t(1 + γ4
0,s)
(1 −γ2
0,t)2
,"
R T,0.8727272727272727,"σ2
s,t = (1 −γ2
0,s)2(1 + γ4
0,t −γ2
s,t(1 + γ4
0,s))
(1 −γ2
0,t)2 (76)"
R T,0.8747474747474747,"we can write down the parameters of Gaussian distribution Xs|Xt, X0:"
R T,0.8767676767676768,"E[Xs|Xt, X0] = µs,tXt + νs,tX0, Var (Xs|Xt, X0) = σ2
s,t I .
(77)"
R T,0.8787878787878788,The Lemma 1 for sub-VP DPMs takes the following shape:
R T,0.8808080808080808,"sθ∗(x, t) = −
1
(1 −γ2
0,t)2"
R T,0.8828282828282829,"
x −γ0,tEp0|t(·|x)X0

.
(78)"
R T,0.8848484848484849,The class of reverse SDE solvers we consider is
R T,0.8868686868686869,"ˆXt−h = ˆXt + βth
1"
R T,0.8888888888888888,"2 + ˆωt,h"
R T,0.8909090909090909,"
ˆXt + (1 + ˆκt,h)

1 −e−2
R t
0 βudu
sθ( ˆXt, t)

+ ˆσt,hξt,
(79)"
R T,0.8929292929292929,"where t = 1, 1 −h, .., h and ξt are i.i.d. samples from N(0, I). Repeating the argument of the
Theorem 1 leads to the following optimal (in terms of likelihood of the forward diffusion sample
paths) parameters:"
R T,0.8949494949494949,"κ∗
t,h = νt−h,t(1 −γ2
0,t)
γ0,tβth(1 + γ2
0,t) −1,
ω∗
t,h = µt−h,t −1"
R T,0.896969696969697,"βth
+
(1 + κ∗
t,h)(1 + γ2
0,t)
1 −γ2
0,t
−1 2,"
R T,0.898989898989899,"(σ∗
t,h)2 = σ2
t−h,t + 1"
R T,0.901010101010101,"nν2
t−h,tEXt [Tr (Var (X0|Xt))] . (80)"
R T,0.9030303030303031,"F
REVERSE VE SDE SOLVER"
R T,0.9050505050505051,VE DPM is characterized by the following forward and reverse diffusions:
R T,0.907070707070707,"dXt =
q"
R T,0.9090909090909091,"(σ2
t )′d−→
Wt ,
(81)"
R T,0.9111111111111111,"d ˆXt = −
 
σ2
t
′ sθ( ˆXt, t)dt +
q"
R T,0.9131313131313131,"(σ2
t )′d←−
Wt.
(82)"
R T,0.9151515151515152,Published as a conference paper at ICLR 2022
R T,0.9171717171717172,Since for s < t
R T,0.9191919191919192,"Xt = Xs +
Z t s q"
R T,0.9212121212121213,"(σ2u)′d−→
Wu ,
(83)"
R T,0.9232323232323232,similar argument as in Appendix A allows showing that
R T,0.9252525252525252,"Law (Xt|Xs) = N

Xs, I ·
Z t s"
R T,0.9272727272727272," 
σ2
u
′ du

= N(Xs, (σ2
t −σ2
s) I).
(84)"
R T,0.9292929292929293,With the following notation:
R T,0.9313131313131313,"µs,t = σ2
s −σ2
0
σ2
t −σ2
0
,
νs,t = σ2
t −σ2
s
σ2
t −σ2
0
,
σ2
s,t = (σ2
t −σ2
s)(σ2
s −σ2
0)
σ2
t −σ2
0
,
(85)"
R T,0.9333333333333333,"we can write down the parameters of Gaussian distribution Xs|Xt, X0:"
R T,0.9353535353535354,"E[Xs|Xt, X0] = µs,tXt + νs,tX0, Var (Xs|Xt, X0) = σ2
s,t I .
(86)"
R T,0.9373737373737374,The Lemma 1 for VE DPMs takes the following shape:
R T,0.9393939393939394,"sθ∗(x, t) = −
1
σ2
t −σ2
0"
R T,0.9414141414141414,"
x −Ep0|t(·|x)X0

.
(87)"
R T,0.9434343434343434,"Repeating the argument of the Theorem 1 leads to the following optimal (in terms of likelihood of
the forward diffusion sample paths) reverse SDE solver:"
R T,0.9454545454545454,"ˆXt−h = ˆXt + (σ2
t −σ2
t−h)sθ( ˆXt, t) + σ∗
t,hξt,
(88) where"
R T,0.9474747474747475,"(σ∗
t,h)2 = (σ2
t −σ2
t−h)(σ2
t−h −σ2
0)
σ2
t −σ2
0
+ 1"
R T,0.9494949494949495,"nν2
t−h,tEXt [Tr (Var (X0|Xt))] ,
(89)"
R T,0.9515151515151515,"t = 1, 1 −h, .., h and ξt are i.i.d. samples from N(0, I)."
R T,0.9535353535353536,"G
TOY EXAMPLES"
R T,0.9555555555555556,"In this section we consider toy examples where data distribution X0 is represented by a single
point (corresponding to the case (ii) of the Theorem 1) and by two points (corresponding to more
general case (i)). In the ﬁrst case the point is unit vector i = (1, 1, .., 1) of dimensionality 100,
in the second one two points i and −2i have the same probability. We compare performance of
two solvers, Euler-Maruyama and the proposed Maximum Likelihood, depending on the number
N ∈{1, 2, 5, 10, 100, 1000} of solver steps. The output of the perfectly trained score matching
network sθ∗is computed analytically and Gaussian noise with variance ε ∈{0.0, 0.1, 0.5} is added
to approximate the realistic case when the network sθ we use is not trained till optimality. We
considered VP diffusion model (6) with β0 = 0.05 and β1 = 20.0."
R T,0.9575757575757575,The results of the comparison are given in Table 5 and can be summarized in the following:
R T,0.9595959595959596,"• for both methods, larger N means better quality;"
R T,0.9616161616161616,"• for both methods, more accurate score matching networks (smaller ε) means better quality;"
R T,0.9636363636363636,"• for large number of steps, both methods perform the same;"
R T,0.9656565656565657,"• it takes less number of steps for the proposed Maximum Likelihood solver to converge with
a good accuracy to data distribution than it does for Euler-Maruyama solver;"
R T,0.9676767676767677,Published as a conference paper at ICLR 2022
R T,0.9696969696969697,"Table 5: Maximum Likelihood (ML) and Euler-Maruyama (EM) solvers comparison in terms of
Mean Square Error (MSE). MSE < 0.001 is denoted by conv, MSE > 1.0 is denoted by div. N is the
number of SDE solver steps, ε is variance of Gaussian noise added to perfect scores sθ∗."
R T,0.9717171717171718,"MSE
X0 = {i}
X0 = {i, −2i}
ML / EM
ε = 0.0
ε = 0.1
ε = 0.5
ε = 0.0
ε = 0.1
ε = 0.5
N = 1
conv / div
div / div
div / div
div / div
div / div
div / div
N = 2
conv / div
div / div
div / div
0.15 / div
div / div
div / div
N = 5
conv / div
0.017 / div
0.085 / div
conv / div
0.017 / div
0.085 / div
N = 10
conv / 0.57
0.001/0.59
0.005/0.67
conv / 0.57
0.001/0.59
0.006/0.67
N = 100
conv / 0.01
conv / 0.01
conv / 0.01
conv / 0.01
conv / 0.01
conv / 0.01
N = 1000
conv / conv
conv / conv
conv / conv
conv / conv
conv / conv
conv / conv"
R T,0.9737373737373738,"• in accordance with the statement (ii) of the Theorem 1, the optimal Maximum Likelihood
solver leads to exact data reconstruction in the case when data distribution is constant and
score matching network is trained till optimality (i.e. ε = 0.0) irrespective of the number of
steps N."
R T,0.9757575757575757,"Also, in the second example where X0 ∈{i, −2i} the Maximum Likelihood SDE solver reconstructs
the probabilities of these two points better than Euler-Maruyama which tends to output “i-samples”
(which are closer to the origin) more frequently than “−2i-samples”. E.g. for ε = 0.0 and N = 10
the frequency of “i-samples” generated by Euler-Maruyama scheme is 54% while this frequency
for Maximum Likelihood scheme is 50% (500k independent runs were used to calculate these
frequencies)."
R T,0.9777777777777777,"H
SPEAKER CONDITIONING NETWORK"
R T,0.9797979797979798,"The function x · tanh(softplus(x)) is used as a non-linearity in the speaker conditioning network
gt(Y ). First, time embedding te is obtained by the following procedure: time t ∈[0, 1] is en-
coded with positional encoding (Song et al., 2021c), then resulting 256-dimensional vector t′ is
passed through the ﬁrst linear module with 1024 units, then a non-linearity is applied to it and
then it is passed through the second linear module with 256 units. Next, noisy mel-spectrogram
Yt for wodyn input type or Yt concatenated with {Ys|s = 0.5/15, 1.5/15, .., 14.5/15} for whole is
passed through 6 blocks consisting of 2D convolutional layers each followed by instance normal-
ization and Gated Linear Unit. The number of input and output channels of these convolutions is
(1, 64), (32, 64), (32, 128), (64, 128), (64, 256), (128, 256) for wodyn input type and the same but
with 16 input channels in the ﬁrst convolution for whole input type. After the 2nd and 4th blocks
MLP1(te) and MLP2(te) are broadcast-added where MLP1 (MLP2) are composed of a non-
linearity followed by a linear module with 32 (64) units. After the last 6th block the result is passed
through the ﬁnal convolution with 128 output channels and average pooling along both time and
frequency axes is applied resulting in 128-dimensional vector. All convolutions except for the ﬁnal
one have (kernel, stride, zero padding) = (3, 1, 1) while for the ﬁnal one the corresponding parameters
are (1, 0, 0). Denote the result of such processing of Y by c for wodyn and whole input types."
R T,0.9818181818181818,"Clean target mel-spectrogram Y0 is used to obtain 256-dimensional speaker embedding d with the
pre-trained speaker veriﬁcation network (Jia et al., 2018) which is not trained. Vectors d, c and t′ are
concatenated (except for d-only input type where we concatenate only d and t′), passed through a
linear module with 512 units followed by a non-linearity and a linear module with 128 units. The
resulting 128-dimensional vector is the output of the speaker conditioning network gt(Y )."
R T,0.9838383838383838,"I
TRAINING HYPERPARAMETERS AND OTHER DETAILS"
R T,0.9858585858585859,"Encoders and decoders were trained with batch sizes 128 and 32 and Adam optimizer with initial
learning rates 0.0005 and 0.0001 correspondingly. Encoders and decoders in VCTK models were
trained for 500 and 200 epochs respectively; as for LibriTTS models, they were trained for 300 and"
R T,0.9878787878787879,Published as a conference paper at ICLR 2022
R T,0.98989898989899,"110 epochs. The datasets were downsampled to 22.05kHz which was the operating rate of our VC
models. VCTK recordings were preprocessed by removing silence in the beginning and in the end of
utterances. To ﬁt GPU memory, decoders were trained on random speech segments of approximately
1.5 seconds rather than on the whole utterances. Training segments for reconstruction and the ones
used as input to the speaker conditioning network gt(Y ) were different random segments extracted
from the same training utterances. Noise schedule parameters β0 and β1 were set to 0.05 and 20.0."
R T,0.9919191919191919,"Our VC models operated on mel-spectrograms with 80 mel features and sampling rate 22.05kHz.
Short-Time Fourier Transform was used to calculate spectra with 1024 frequency bins. Hann window
of length 1024 was applied with hop size 256."
R T,0.9939393939393939,"For Diff-LibriTTS models we used simple spectral subtraction algorithm in mel domain with spectral
ﬂoor parameter β = 0.02 as post-processing to reduce background noise sometimes produced by
these models. Noise spectrum was estimated on speech fragments automatically detected as the ones
corresponding to silence in source mel-spectrogram."
R T,0.9959595959595959,"J
DETAILS OF AMT TESTS"
R T,0.997979797979798,"For fair comparison with the baselines all the recordings were downsampled to 16kHz; we also
normalized their loudness. In speech naturalness tests workers chosen by geographic criterion were
asked to assess the overall quality of the synthesized speech, i.e to estimate how clean and natural
(human-sounding) it was. Five-point Likert scale was used: 1 - “Bad”, 2 - “Poor”, 3 - “Fair”, 4 -
“Good”, 5 - “Excellent”. Assessors were asked to wear headphones and work in a quiet environment.
As for speaker similarity tests, workers were asked to assess how similar synthesized samples sounded
to target speech samples in terms of speaker similarity. Assessors were asked not to pay attention
to the overall quality of the synthesized speech (e.g. background noise or incorrect pronunciation).
Five-point scale was used: 1 - “Different: absolutely sure”, 2 - “Different: moderately sure”, 3 -
“Cannot decide more same or more different”, 4 - “Same: moderately sure”, 5 - “Same: absolutely
sure”."
