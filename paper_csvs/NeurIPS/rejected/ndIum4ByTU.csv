Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.001004016064257028,"Numerous biological and physical processes can be modeled as systems of interact-
1"
ABSTRACT,0.002008032128514056,"ing samples evolving continuously over time, e.g. the dynamics of communicating
2"
ABSTRACT,0.0030120481927710845,"cells or physical particles. Flow-based models allow for learning these dynamics at
3"
ABSTRACT,0.004016064257028112,"the population level — they model the evolution of the entire distribution of sam-
4"
ABSTRACT,0.0050200803212851405,"ples. However, current flow-based models are limited to a single initial population
5"
ABSTRACT,0.006024096385542169,"and a set of predefined conditions which describe different dynamics. We argue that
6"
ABSTRACT,0.007028112449799197,"multiple processes in natural sciences have to be represented as vector fields on the
7"
ABSTRACT,0.008032128514056224,"Wasserstein manifold of probability densities. That is, the change of the population
8"
ABSTRACT,0.009036144578313253,"at any moment in time depends on the population itself due to the interactions
9"
ABSTRACT,0.010040160642570281,"between samples. In particular, this is crucial for personalized medicine where the
10"
ABSTRACT,0.01104417670682731,"development of diseases and their treatments depend on the microenvironment of
11"
ABSTRACT,0.012048192771084338,"cells specific to each patient. We propose Meta Flow Matching (MFM), a practical
12"
ABSTRACT,0.013052208835341365,"approach to integrating along these vector fields on the Wasserstein manifold by
13"
ABSTRACT,0.014056224899598393,"amortizing the flow model over the initial populations. Namely, we embed the
14"
ABSTRACT,0.015060240963855422,"population of samples using a Graph Neural Network (GNN) and use these embed-
15"
ABSTRACT,0.01606425702811245,"dings to train a Flow Matching model. This gives Meta Flow Matching the ability
16"
ABSTRACT,0.01706827309236948,"to generalize over the initial distributions unlike previously proposed methods.
17"
ABSTRACT,0.018072289156626505,"Finally, we demonstrate the ability of MFM to improve prediction of individual
18"
ABSTRACT,0.019076305220883535,"treatment responses on a large scale multi-patient single-cell drug screen dataset.
19"
INTRODUCTION,0.020080321285140562,"1
Introduction
20"
INTRODUCTION,0.02108433734939759,"Understanding the dynamics of many-body problems is a central challenge across the natural sciences.
21"
INTRODUCTION,0.02208835341365462,"In the field of cell biology, a central focus is the understanding of the dynamic processes that cells
22"
INTRODUCTION,0.023092369477911646,"undergo in response to their environment, and in particular their response and interaction with other
23"
INTRODUCTION,0.024096385542168676,"cells. Cells communicate with one other in close proximity using cell signaling, exerting influence
24"
INTRODUCTION,0.025100401606425703,"over each other’s trajectories (Armingol et al., 2020; Goodenough and Paul, 2009). This signaling
25"
INTRODUCTION,0.02610441767068273,"presents an obstacle for modeling, but is essential for understanding and eventually controlling
26"
INTRODUCTION,0.02710843373493976,"cell dynamics during development (Gulati et al., 2020; Rizvi et al., 2017), in diseased states (Molè
27"
INTRODUCTION,0.028112449799196786,"et al., 2021; Binnewies et al., 2018; Zeng and Dai, 2019; Chung et al., 2017), and in response to
28"
INTRODUCTION,0.029116465863453816,"perturbations (Ji et al., 2021; Peidli et al., 2024).
29"
INTRODUCTION,0.030120481927710843,"The super-exponential decrease of sequencing costs and advances in microfluidics has enabled the
30"
INTRODUCTION,0.03112449799196787,"rapid advancement of single-cell sequencing and related technologies over the past decade. While
31"
INTRODUCTION,0.0321285140562249,"single-cell sequencing has been used to great effect to understand the heterogeneity in cell systems,
32"
INTRODUCTION,0.03313253012048193,"they are also destructive, making longitudinal measurements extremely difficult. Instead, most
33"
INTRODUCTION,0.03413654618473896,"approaches model cell dynamics at the population level (Hashimoto et al., 2016; Weinreb et al., 2018;
34"
INTRODUCTION,0.035140562248995984,"Schiebinger et al., 2019; Tong et al., 2020; Neklyudov et al., 2022; Bunne et al., 2023a). These
35"
INTRODUCTION,0.03614457831325301,"approaches involve the formalisms of optimal transport (Villani, 2009; Peyré and Cuturi, 2019) and
36"
INTRODUCTION,0.03714859437751004,"generative modeling (De Bortoli et al., 2021; Lipman et al., 2023) methods, which allow for learning
37"
INTRODUCTION,0.03815261044176707,"a map between empirical measures. While these methods are able to model the dynamics of the
38"
INTRODUCTION,0.0391566265060241,"population, they are fundamentally limited in that they model the evolution of cells as independent
39"
INTRODUCTION,0.040160642570281124,"particles evolving according to a shared dynamical system. Furthermore, these models can be trained
40"
INTRODUCTION,0.04116465863453815,"to match any given set of measures, but they are restricted to modeling of a single population and can
41"
INTRODUCTION,0.04216867469879518,"at best condition on a number of different dynamics that is available in the training data.
42"
INTRODUCTION,0.04317269076305221,"To address this we propose Meta Flow Matching (MFM) — the amortization of the Flow Matching
43"
INTRODUCTION,0.04417670682730924,"generative modeling framework (Lipman et al., 2023) over the input measures. In practice, our
44"
INTRODUCTION,0.045180722891566265,"method can be used to predict the time-evolution of distributions from a given dataset of the time-
45"
INTRODUCTION,0.04618473895582329,"evolved examples. Namely, we assume that the collected data undergoes a universal developmental
46"
INTRODUCTION,0.04718875502008032,"process, which depends only on the population itself as in the setting of the interacting particles or
47"
INTRODUCTION,0.04819277108433735,"communicating cells. Under this assumption, we learn the vector field model that takes samples from
48"
INTRODUCTION,0.04919678714859438,"the initial distribution as input and defines the push-forward map on the sample-space that maps the
49"
INTRODUCTION,0.050200803212851405,"initial distribution to the final distribution.
50"
INTRODUCTION,0.05120481927710843,"We showcase the utility of our approach on two applications. We first explore Meta Flow Matching on
51"
INTRODUCTION,0.05220883534136546,"a synthetic task of denoising letters. We show that MFM is able to generalize the denoising process
52"
INTRODUCTION,0.05321285140562249,"to letters in unseen orientations where a standard flow matching approach cannot. Next, we explore
53"
INTRODUCTION,0.05421686746987952,"how MFM can be applied to model single-cell perturbation data (Ji et al., 2021; Peidli et al., 2024).
54"
INTRODUCTION,0.055220883534136546,"We evaluate MFM on predicting the response of patient-derived cells to chemotherapy treatments
55"
INTRODUCTION,0.05622489959839357,"in a recently published large scale single-cell drug screening dataset where there are known to be
56"
INTRODUCTION,0.0572289156626506,"patient-specific responses (Ramos Zapatero et al., 2023). This dataset includes more than 25M cells
57"
INTRODUCTION,0.05823293172690763,"collected over ten patients under 2500 conditions. This is a challenging task due to the variance over
58"
INTRODUCTION,0.05923694779116466,"multiple patients, treatments applied and the local cell compositions, but it can be used to study the
59"
INTRODUCTION,0.060240963855421686,"tumor micro-environment (TME), thought to be essential in circumventing chemoresistance. We
60"
INTRODUCTION,0.06124497991967871,"demonstrate that Meta Flow Matching can successfully predict the development of cell populations
61"
INTRODUCTION,0.06224899598393574,"on replicated experiments, and, most importantly, it generalizes to previously unseen patients, thus,
62"
INTRODUCTION,0.06325301204819277,"capturing the patient-specific response to the treatment.
63"
BACKGROUND,0.0642570281124498,"2
Background
64"
GENERATIVE MODELING VIA FLOW MATCHING,0.06526104417670683,"2.1
Generative Modeling via Flow Matching
65"
GENERATIVE MODELING VIA FLOW MATCHING,0.06626506024096386,"Flow Matching is an approach to generative modeling recently proposed independently in different
66"
GENERATIVE MODELING VIA FLOW MATCHING,0.06726907630522089,"works: Rectified Flows (Liu et al., 2022), Flow Matching (Lipman et al., 2023), Stochastic Interpolants
67"
GENERATIVE MODELING VIA FLOW MATCHING,0.06827309236947791,"(Albergo and Vanden-Eijnden, 2022). It assumes a continuous interpolation between densities p0(x0)
68"
GENERATIVE MODELING VIA FLOW MATCHING,0.06927710843373494,"and p1(x1) in the sample space. That is, the sample from the intermediate density pt(xt) is produced
69"
GENERATIVE MODELING VIA FLOW MATCHING,0.07028112449799197,"as follows
70"
GENERATIVE MODELING VIA FLOW MATCHING,0.071285140562249,"xt = ft(x0, x1), (x0, x1) ∼π(x0, x1) ,
(1)"
GENERATIVE MODELING VIA FLOW MATCHING,0.07228915662650602,"where
Z
dx1 π(x0, x1) = p0(x0) ,
Z
dx0 π(x0, x1) = p1(x1) ,
(2)"
GENERATIVE MODELING VIA FLOW MATCHING,0.07329317269076305,"where ft is the time-continuous interpolating function such that ft=0(x0, x1)
=
x0 and
71"
GENERATIVE MODELING VIA FLOW MATCHING,0.07429718875502007,"ft=1(x0, x1) = x1 (e.g. linearly between x0 and x1 with ft(x0, x1) = (1 −t) · x0 + t · x1);
72"
GENERATIVE MODELING VIA FLOW MATCHING,0.07530120481927711,"π(x0, x1) is the density of the joint distribution, which is usually taken as a distribution of inde-
73"
GENERATIVE MODELING VIA FLOW MATCHING,0.07630522088353414,"pendent random variables π(x0, x1) = p0(x0)p1(x1), but can also be generalized to formulate the
74"
GENERATIVE MODELING VIA FLOW MATCHING,0.07730923694779117,"optimal transport problems (Pooladian et al., 2023; Tong et al., 2024). The corresponding density can
75"
GENERATIVE MODELING VIA FLOW MATCHING,0.0783132530120482,"be defined then as the following expectation
76"
GENERATIVE MODELING VIA FLOW MATCHING,0.07931726907630522,"pt(x) =
Z
dx0dx1 π(x0, x1)δ(x −ft(x0, x1)) .
(3)"
GENERATIVE MODELING VIA FLOW MATCHING,0.08032128514056225,"The essential part of Flow Matching is the continuity equation that describes the change of this
77"
GENERATIVE MODELING VIA FLOW MATCHING,0.08132530120481928,"density through the vector field on the state space, which admits vector field v∗
t (x) as a solution
78"
GENERATIVE MODELING VIA FLOW MATCHING,0.0823293172690763,∂pt(x)
GENERATIVE MODELING VIA FLOW MATCHING,0.08333333333333333,"∂t
= −⟨∇x, pt(x)v∗
t (x)⟩, v∗
t (ξ) =
1
pt(ξ)Eπ(x0,x1)"
GENERATIVE MODELING VIA FLOW MATCHING,0.08433734939759036,"
δ(ft(x0, x1) −ξ)∂ft(x0, x1) ∂t"
GENERATIVE MODELING VIA FLOW MATCHING,0.0853413654618474,"
.
(4)"
GENERATIVE MODELING VIA FLOW MATCHING,0.08634538152610442,"Flow Matching
Conditional Flow Matching
Vector Field on P2(X)"
GENERATIVE MODELING VIA FLOW MATCHING,0.08734939759036145,"Figure 1: Illustration of flow matching methods on the 2-Wasserstein manifold, P2(X), depicted as a two-
dimensional sphere. Flow Matching learns the tangent vectors to a single curve on the manifold. Conditional
generation corresponds to learning a finite set of curves on the manifold, e.g. classes c1 and c2 on the plot. Meta
Flow Matching learns to integrate a vector field on P2(X), i.e. for every starting density p0 Meta Flow Matching
defines a push-forward measure that integrates along the underlying vector field."
GENERATIVE MODELING VIA FLOW MATCHING,0.08835341365461848,"Relying on this formula, one can derive the tractable objective for learning v∗
t (x), i.e.
79"
GENERATIVE MODELING VIA FLOW MATCHING,0.0893574297188755,"LFM(ω) =
Z 1"
GENERATIVE MODELING VIA FLOW MATCHING,0.09036144578313253,"0
dt Ept(x)∥v∗
t (x) −vt(x; ω)∥2
(5)"
GENERATIVE MODELING VIA FLOW MATCHING,0.09136546184738956,"= Eπ(x0,x1) Z 1"
DT,0.09236947791164658,"0
dt

∂
∂tft(x0, x1) −vt(ft(x0, x1); ω)"
DT,0.09337349397590361,"2
+ constant .
(6)"
DT,0.09437751004016064,"Finally, the vector field vt(ξ, ω) ≈v∗
t (ξ) defines the push-forward density that approximately matches
80"
DT,0.09538152610441768,"pt=1, i.e. T#p0 ≈pt=1, where T is the flow corresponding to vector field vt(·, ω) with parameters ω.
81"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.0963855421686747,"2.2
Conditional Generative Modeling via Flow Matching
82"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.09738955823293173,"Conditional image generation is one of the most common applications of generative models nowadays;
83"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.09839357429718876,"it includes conditioning on the text prompts (Saharia et al., 2022b; Rombach et al., 2022) as well
84"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.09939759036144578,"as conditioning on other images (Saharia et al., 2022a). To learn the conditional generative process
85"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.10040160642570281,"with diffusion models, one merely has to pass the conditional variable (sampled jointly with the data
86"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.10140562248995984,"point) as an additional input to the parametric model of the vector field. The same applies for the
87"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.10240963855421686,"Flow Matching framework.
88"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.10341365461847389,"Conditional Generative Modeling via Flow Matching is independently introduced in several works
89"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.10441767068273092,"(Zheng et al., 2023; Dao et al., 2023; Isobe et al., 2024) and it operates as follows. Consider a family
90"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.10542168674698796,"of time-continuous densities pt(xt | c), which corresponds to the distribution of the following random
91"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.10642570281124498,"variable
92"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.10742971887550201,"xt = ft(x0, x1), (x0, x1) ∼π(x0, x1 | c) .
(7)"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.10843373493975904,"For every c, the density pt(xt | c) follows the continuity equation with the following vector field
93"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.10943775100401607,"v∗
t (ξ | c) =
1
pt(ξ | c)Eπ(x0,x1)δ(ft(x0, x1) −ξ)∂ft(x0, x1)"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.11044176706827309,"∂t
,
(8)"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.11144578313253012,"which depends on c. Thus, the training objective of the conditional model becomes
94"
CONDITIONAL GENERATIVE MODELING VIA FLOW MATCHING,0.11244979919678715,"LCGF M(ω) = Ep(c)Eπ(x0,x1 | c) Z 1"
DT,0.11345381526104417,"0
dt

∂
∂tft(x0, x1) −vt(ft(x0, x1) | c; ω)"
DT,0.1144578313253012,"2
,
(9)"
DT,0.11546184738955824,"where, compared to the original Flow Matching formulation, we first have to sample c, then produce
95"
DT,0.11646586345381527,"the samples from pt(xt | c) and pass c as input to the parametric model of the vector field.
96"
META FLOW MATCHING,0.11746987951807229,"3
Meta Flow Matching
97"
META FLOW MATCHING,0.11847389558232932,"In this paper, we propose the amortization of the Flow Matching framework over the marginal
98"
META FLOW MATCHING,0.11947791164658635,"distributions. Our model is based on the outstanding ability of the Flow Matching framework to
99"
META FLOW MATCHING,0.12048192771084337,"learn the push-forward map for any joint distribution π(x0, x1) given empirically. For the given joint
100"
META FLOW MATCHING,0.1214859437751004,"π(x0, x1), we denote the solution of the Flow Matching optimization problem as follows
101"
META FLOW MATCHING,0.12248995983935743,"v∗
t (·, π) = argmin
vt
LGF M(vt(·), π(x0, x1)) .
(10)"
META FLOW MATCHING,0.12349397590361445,"Analogously to the amortized optimization (Chen et al., 2022; Amos et al., 2023), we aim to learn the
102"
META FLOW MATCHING,0.12449799196787148,"model that outputs the solution of Eq. (10) based on the input data sampled from π, i.e.
103"
META FLOW MATCHING,0.12550200803212852,"vt(·, φ(π)) = v∗
t (·, π) ,
(11)
where φ(π) is the embedding model of π and the joint density π(· | c) is generated using some
104"
META FLOW MATCHING,0.12650602409638553,"unknown measure of the conditional variables c ∼p(c).
105"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.12751004016064257,"3.1
Modeling Process in Natural Sciences as Vector Fields on the Wasserstein Manifold
106"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1285140562248996,"We argue that numerous biological and physical processes cannot be modeled via the vector field
107"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.12951807228915663,"propagating the population samples independently. Thus, we propose to model these processes as
108"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.13052208835341367,"families of conditional vector fields where we amortize the conditional variable by embedding the
109"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.13152610441767068,"population via a Graph Neural Network (GNN).
110"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.13253012048192772,"To provide the reader with the necessary intuition, we are going to use the geometric formalism
111"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.13353413654618473,"developed by Otto (2001). That is, time-dependent densities pt(xt) define absolutely-continuous
112"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.13453815261044177,"curves on the 2-Wasserstein space of distributions P2(X) (Ambrosio et al., 2008). The tangent space
113"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1355421686746988,"of this manifold is defined by the gradient flows St = {∇st | st : X →R} on the state space X. In
114"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.13654618473895583,"the Flow Matching context, we are going to refer to the tangent vectors as vector fields since one
115"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.13755020080321284,"can always project the vector field onto the tangent space by parameterizing it as a gradient flow
116"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.13855421686746988,"(Neklyudov et al., 2022).
117"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1395582329317269,"Under the geometric formalism of the 2-Wasserstein manifold, Flow Matching can be considered
118"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.14056224899598393,"as learning the tangent vectors vt(·) along the density curve pt(xt) defined by the sampling process
119"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.14156626506024098,"in Eq. (2) (see the left panel in Fig. 1). Furthermore, the conditional generation processes pt(xt | c)
120"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.142570281124498,"would be represented as a finite set of curves if c is discrete (e.g. class-conditional generation of
121"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.14357429718875503,"images) or as a family of curves if c is continuous (see the middle panel in Fig. 1).
122"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.14457831325301204,"Finally, one can define a vector field on the 2-Wasserstein manifold via the continuity equation with
123"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.14558232931726908,"the vector field vt(x, pt(x)) on the state space X that depends on the current density pt(x) or its
124"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1465863453815261,"derivatives. Below we give two examples of processes defined as vector fields on the 2-Wasserstein
125"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.14759036144578314,"manifold.
126"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.14859437751004015,"Example 1 (Mean-field limit of interacting particles). In the limit of the infinite number of interacting
127"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1495983935742972,"particles one can describe their state with the density function pt(x). Consider the interaction
128"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.15060240963855423,"according to the first order dynamics with the velocity k(x, y) : Rd × Rd →Rd of the particles at
129"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.15160642570281124,"point x that interact with the particles at point y. Then the change of the density is described by the
130"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.15261044176706828,"following continuity equation
131 dx"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1536144578313253,"dt = Ept(y)k(x, y),
∂pt(x)"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.15461847389558234,"∂t
= −

∇x, pt(x)Ept(y)k(x, y)

.
(12)"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.15562248995983935,"Example 2 (Diffusion). Even when the physical particles evolve independently in nature, the
132"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1566265060240964,"deterministic vector field model might be dependent on the current density of the population. For
133"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1576305220883534,"instance, for the diffusion process, the change of the density is described by the Fokker-Planck
134"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.15863453815261044,"equation, which results in the density-dependent vector field when written as a continuity equation,
135"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.15963855421686746,"i.e.
136"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1606425702811245,∂pt(x)
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.16164658634538154,"∂t
= 1"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.16265060240963855,"2∆xpt(x) = −

∇x, pt(x)

−1"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1636546184738956,"2∇x log pt(x)

=⇒dx"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1646586345381526,dt = −1
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.16566265060240964,2∇x log pt(x) . (13)
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.16666666666666666,"Motivated by the examples above, we argue that using the information about the current or the initial
137"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1676706827309237,"density is crucial for the modeling of time-evolution of densities in natural processes, to capture this
138"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1686746987951807,"type of dependency one can model the change of the density as the following Cauchy problem
139"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.16967871485943775,∂pt(x)
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1706827309236948,"∂t
= −⟨∇x, pt(x)vt(x, pt)⟩, pt=0(x) = p0(x) ,
(14)"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1716867469879518,"where the state-space vector field vt(x, pt) depends on the density pt.
140"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.17269076305220885,"The dependency might vary across models, e.g. in Example 1 the vector field can be modeled as an
141"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.17369477911646586,"application of a kernel to the density function, while in Example 2 the vector field depends only on
142"
MODELING PROCESS IN NATURAL SCIENCES AS VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD,0.1746987951807229,"the local value of the density and its derivative.
143"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.1757028112449799,"3.2
Integrating Vector Fields on the Wasserstein Manifold via Meta Flow Matching
144"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.17670682730923695,"Consider the dataset of joint populations D = {(π(x0, x1 | i))}i, where, to simplify the notation,
145"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.17771084337349397,"we associate every i-th population with its density π(· | i) and the conditioning variable here is the
146"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.178714859437751,"index of this population in the dataset. We make the following assumptions regarding the ground
147"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.17971887550200802,"truth sampling process (i) we assume that the starting marginals p0(x0 | i) =
R
dx1 π(x0, x1 | i) are
148"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.18072289156626506,"sampled from some unknown distribution that can be parameterized with a large enough number of
149"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.1817269076305221,"parameters (ii) the endpoint marginals p1(x1 | i) =
R
dx0 π(x0, x1 | i) are obtained as push-forward
150"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.1827309236947791,"densities solving the Cauchy problem in Eq. (14), (iii) there exists unique solution to this Cauchy
151"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.18373493975903615,"problem.
152"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.18473895582329317,"One can learn a joint model of all the processes from the dataset D using the conditional version of
153"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.1857429718875502,"the Flow Matching algorithm (see Section 2.2) where the population index i plays the role of the
154"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.18674698795180722,"conditional variable. However, obviously, such a model will not generalize beyond the considered
155"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.18775100401606426,"data D and unseen indices i. We illustrate this empirically in Section 5.
156"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.18875502008032127,"To be able to generalize to previously unseen populations, we propose learning the density-dependent
157"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.1897590361445783,"vector field motivated by Eq. (14). That is, we propose to use an embedding function φ : P2(X) →
158"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.19076305220883535,"Rm to embed the starting marginal density p0, which we then input into the vector field model and
159"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.19176706827309237,"minimize the following objective over ω
160"
INTEGRATING VECTOR FIELDS ON THE WASSERSTEIN MANIFOLD VIA META FLOW MATCHING,0.1927710843373494,"LMFM(ω; φ) = Ei∼DEπ(x0,x1 | i) Z 1"
DT,0.19377510040160642,"0
dt

∂
∂tft(x0, x1) −vt(ft(x0, x1) | φ(p0); ω)"
DT,0.19477911646586346,"2
.
(15)"
DT,0.19578313253012047,"Note that the initial density p0 is enough to predict the push-forward density p1 since the Cauchy
161"
DT,0.19678714859437751,"problem for Eq. (14) has a unique solution. The embedding function φ(p0) can take different forms,
162"
DT,0.19779116465863453,"e.g. it can be the density value φ(p0) = p0(·), which is then used inside the vector field model to
163"
DT,0.19879518072289157,"evaluate at the current point (analogous to Example 2); a kernel density estimator (analogous to
164"
DT,0.19979919678714858,"Example 1); or a parametric model taking the samples from this density as an input.
165"
DT,0.20080321285140562,"Proposition 1. Meta Flow Matching recovers the Conditional Generation via Flow Matching
166"
DT,0.20180722891566266,"when the conditional dependence of the marginals p0(x0 | c) =
R
dx1π(x0, x1 | c) and p1(x1 | c) =
167
R
dx0π(x0, x1 | c) and the distribution p(c) are known, i.e. there exist φ : P2(X) →Rm such that
168"
DT,0.20281124497991967,"LMF M(ω) = LCGF M(ω).
169"
DT,0.20381526104417672,"Proof. Indeed, sampling from the dataset i ∼D becomes sampling of the conditional variable
170"
DT,0.20481927710843373,"c ∼p(c) and the embedding function becomes φ(p0(· | c)) = c.
171"
DT,0.20582329317269077,"Furthermore, for the parametric family of the embedding models φ(pt, θ), we show that the parameters
172"
DT,0.20682730923694778,"θ can be estimated by minimizing the objective in Eq. (15) in the joint optimization with the vector
173"
DT,0.20783132530120482,"field parameters ω. We formalize this statement in the following theorem.
174"
DT,0.20883534136546184,"Theorem 1. Consider a dataset of populations D = {(π(x0, x1 | i))}i generated from some unknown
175"
DT,0.20983935742971888,"conditional model π(x0, x1 | c)p(c). Then the following objective
176"
DT,0.21084337349397592,"L(ω, θ) = Ep(c) Z 1"
DT,0.21184738955823293,"0
dt Ept(xt | c)∥v∗
t (xt | c) −vt(xt | φ(p0, θ), ω)∥2
(16)"
DT,0.21285140562248997,"is equivalent to the Meta Flow Matching objective
177"
DT,0.21385542168674698,"LMFM(ω, θ) = Ei∼DEπ(x0,x1 | i) Z 1"
DT,0.21485943775100402,"0
dt

∂
∂tft(x0, x1) −vt(ft(x0, x1) | φ(p0, θ); ω)"
DT,0.21586345381526104,"2
(17)"
DT,0.21686746987951808,"up to an additive constant.
178"
DT,0.2178714859437751,"Proof. We postpone the proof to Appendix A.
179"
DT,0.21887550200803213,"3.3
Learning Population Embeddings via Graph Neural Networks (GNNs)
180"
DT,0.21987951807228914,"In many applications, the populations D = {(π(x0, x1 | i))}N
i=1 are given as empirical distributions,
181"
DT,0.22088353413654618,"i.e. they are represented as samples from some unknown density π
182"
DT,0.22188755020080322,"{(xj
0, xj
1)}Ni
j=1 , (xj
0, xj
1) ∼π(x0, x1 | i) ,
(18)"
DT,0.22289156626506024,"where Ni is the size of the i-th population. For instance, for the diffusion process considered in
183"
DT,0.22389558232931728,"Example 2, the samples from π(x0, x1 | i) can be generated by generating some marginal p1(x1 | i)
184"
DT,0.2248995983935743,"and then adding the Gaussian random variable to the samples xj
1. We use this model in our synthetic
185"
DT,0.22590361445783133,"experiments in Section 5.1.
186"
DT,0.22690763052208834,"Since the only available information about the populations is samples, we propose learning the
187"
DT,0.22791164658634538,"embedding of populations via a parametric model φ(p0, θ), i.e.
188"
DT,0.2289156626506024,"φ(p0, θ) = φ

{xj
0}Ni
j=1, θ

, (xj
0, xj
1) ∼π(x0, x1 | i) .
(19)"
DT,0.22991967871485944,"For this purpose, we employ GNNs, which recently have been successfully applied for simulation of
189"
DT,0.23092369477911648,"complicated many-body problems in physics (Sanchez-Gonzalez et al., 2020). To embed a population
190"
DT,0.2319277108433735,"{xj
0}Ni
j=1, we create a k-nearest neighbour graph Gi based on the metric in the state-space X, input it
191"
DT,0.23293172690763053,"into a GNN, which consists of several message-passing iterations (Gilmer et al., 2017) and the final
192"
DT,0.23393574297188754,"average-pooling across nodes to produce the embedding vector. Finally, we update the parameters of
193"
DT,0.23493975903614459,"the GNN jointly with the parameters of the vector field to minimize the loss function in Eq. (17).
194"
RELATED WORK,0.2359437751004016,"4
Related Work
195"
RELATED WORK,0.23694779116465864,"The meta-learning of probability measures was previously studied by Amos et al. (2022) where they
196"
RELATED WORK,0.23795180722891565,"demonstrate that the prediction of the optimal transport paths can be efficiently amortized over the
197"
RELATED WORK,0.2389558232931727,"input marginal measures. The main difference with our approach is that we are trying to learn the
198"
RELATED WORK,0.2399598393574297,"push-forward map without embedding the second marginal.
199"
RELATED WORK,0.24096385542168675,"Generative modeling for single cells. Single cell data has expanded to encompass multiple modalities
200"
RELATED WORK,0.2419678714859438,"of data profiling cell state and activities (Frangieh et al., 2021; Bunne et al., 2023b). Single-cell
201"
RELATED WORK,0.2429718875502008,"data presents multiple challenges in terms of noise, non-time resolved, and high dimension, and
202"
RELATED WORK,0.24397590361445784,"generative models have been used to counter those problems. Autoencoder has been used to embed
203"
RELATED WORK,0.24497991967871485,"and extrapolate data Out Of Distribution (OOD) with its latent state dimension (Lotfollahi et al., 2019;
204"
RELATED WORK,0.2459839357429719,"Lopez et al., 2018; Hetzel et al., 2022). Orthogonal non-negative matrix factorization (oNMF) has
205"
RELATED WORK,0.2469879518072289,"also been used for dimensionality reduction combined with mixture models for cell state prediction
206"
RELATED WORK,0.24799196787148595,"(Chen et al., 2020). Other approaches have tried to use Flow Matching (FM) (Tong et al., 2023, 2024;
207"
RELATED WORK,0.24899598393574296,"Neklyudov et al., 2023) or similar approaches such as the Monge gap (Uscidda and Cuturi, 2023) to
208"
RELATED WORK,0.25,"predict cell trajectories. Currently, the state of the art method uses the principle of Optimal Transport
209"
RELATED WORK,0.25100401606425704,"(OT) to predict cell trajectories with Input Convex Neural Network (ICNN) (Makkuva et al., 2020;
210"
RELATED WORK,0.2520080321285141,"Bunne et al., 2023b). What determines the significance of the method is its capability in generalizing
211"
RELATED WORK,0.25301204819277107,"out of distribution to a new population of cells, which may be from different culture or individuals.
212"
RELATED WORK,0.2540160642570281,"As of this time, our method is the only method that takes inter-cellular interactions into account.
213"
RELATED WORK,0.25502008032128515,"Generative modeling for physical processes. The closest approach to ours is the prediction of the
214"
RELATED WORK,0.2560240963855422,"many-body interactions in physics (Sanchez-Gonzalez et al., 2020) via GNNs. However, the problem
215"
RELATED WORK,0.2570281124497992,"there is very different since these models use the information about the individual trajectories of
216"
RELATED WORK,0.2580321285140562,"samples, which are not available for the single-cell prediction. Neklyudov et al. (2022) consider
217"
RELATED WORK,0.25903614457831325,"learning the vector field for any continuous time-evolution of a probability measure, however, their
218"
RELATED WORK,0.2600401606425703,"method is restricted to single curves and do not consider generalization to unseen data. Finally, the
219"
RELATED WORK,0.26104417670682734,"weather/climate forecast models generating the next state conditioned on the previous one (Price
220"
RELATED WORK,0.2620481927710843,"et al., 2023; Verma et al., 2024) are similar approaches to ours but operating on a much finer time
221"
RELATED WORK,0.26305220883534136,"resolution.
222"
EXPERIMENTS,0.2640562248995984,"5
Experiments
223"
EXPERIMENTS,0.26506024096385544,"To show the effectiveness of MFM to generalize under previously unseen populations for the task
224"
EXPERIMENTS,0.2660642570281124,"population prediction, we consider two experimental settings. (i) A synthetic experiment with well
225"
EXPERIMENTS,0.26706827309236947,"defined coupled populations, and (ii) experiments on a publicly available single-cell dataset consisting
226"
EXPERIMENTS,0.2680722891566265,"of populations from patient dependent treatment response trials. To quantify model performance,
227"
EXPERIMENTS,0.26907630522088355,"we consider three distributional distances metrics: the 1-Wasserstein distance (W1), 2-Wasserstein
228"
EXPERIMENTS,0.2700803212851406,"(W2) distance, and the radial basis kernel maximum-mean-discrepancy (MMD) distance (Gretton
229"
EXPERIMENTS,0.2710843373493976,"et al., 2012). We parameterize all vector field models vt(· | φ(p0); ω) using a Multi-Layer Perceptron
230"
EXPERIMENTS,0.2720883534136546,"(MLP). For MFM, we additionally parameterize φ(pt; θ, k) using a Graph Convolutional Network
231"
EXPERIMENTS,0.27309236947791166,"source
t=0.50
t=1.00
target"
EXPERIMENTS,0.2740963855421687,"Train
Test FM"
EXPERIMENTS,0.2751004016064257,"source
t=0.50
t=1.00
target CGFM"
EXPERIMENTS,0.2761044176706827,"source
t=0.50
t=1.00
target MFM"
EXPERIMENTS,0.27710843373493976,"Figure 2: Examples of model-generated samples for synthetic letters from the source distribution (t = 0) to
predicted target distribution (t = 1). See Fig. 4 in Appendix F for a larger set of examples."
EXPERIMENTS,0.2781124497991968,"Table 1: Results of the synthetic letters experiment for population prediction on seen train populations and
unseen test populations. We report the the 1-Wasserstein (W1), 2-Wasserstein (W2), and the maximum-mean-
discrepancy (MMD) distributional distances. We consider 4 settings for MFM with varying k."
EXPERIMENTS,0.2791164658634538,"Train
Test"
EXPERIMENTS,0.28012048192771083,"W1
W2
MMD (×10−3)
W1
W2
MMD (×10−3)"
EXPERIMENTS,0.28112449799196787,"FM
0.216 ± 0.000
0.280 ± 0.000
2.38 ± 0.00
0.237 ± 0.000
0.315 ± 0.000
3.28 ± 0.00
CGFM
0.093 ± 0.000
0.112 ± 0.000
0.34 ± 0.00
0.317 ± 0.000
0.397 ± 0.000
6.67 ± 0.00"
EXPERIMENTS,0.2821285140562249,"MFM (k = 0)
0.099 ± 0.000
0.128 ± 0.000
0.25 ± 0.00
0.221 ± 0.000
0.267 ± 0.000
3.77 ± 0.00
MFM (k = 1)
0.096 ± 0.003
0.124 ± 0.004
0.22 ± 0.04
0.217 ± 0.003
0.261 ± 0.003
3.80 ± 0.28
MFM (k = 10)
0.096 ± 0.003
0.124 ± 0.003
0.23 ± 0.04
0.213 ± 0.008
0.256 ± 0.008
3.68 ± 0.45
MFM (k = 50)
0.099 ± 0.003
0.127 ± 0.003
0.25 ± 0.05
0.226 ± 0.005
0.270 ± 0.007
4.38 ± 0.30"
EXPERIMENTS,0.28313253012048195,"(GCN) with a k-nearest neighbour graph edge pooling layer. We include details regarding model
232"
EXPERIMENTS,0.28413654618473894,"hyperparameters, training/optimization, and implementation in Appendix B and Appendix B.2. The
233"
EXPERIMENTS,0.285140562248996,"results for all the models are averaged over three random seeds.
234"
SYNTHETIC EXPERIMENT,0.286144578313253,"5.1
Synthetic Experiment
235"
SYNTHETIC EXPERIMENT,0.28714859437751006,"We curate a synthetic dataset of the joint distributions {(p0(x0, | i), p1(x1 | i))}N
i=1 by simulating a
236"
SYNTHETIC EXPERIMENT,0.28815261044176704,"diffusion process applied to a set of pre-defined target distributions p1(x1 | i) for i = 1, . . . , N. To get
237"
SYNTHETIC EXPERIMENT,0.2891566265060241,"a paired population p0(x0 | i) we simulate the forward diffusion process without drift x0 ∼N(x1, σ).
238"
SYNTHETIC EXPERIMENT,0.2901606425702811,"After this setup, for reasonable values of σ, we assume that one can reverse the diffusion process and
239"
SYNTHETIC EXPERIMENT,0.29116465863453816,"learn the push-forward map from p0(x0 | i) to p1(x1 | i) for every index i. For this task, given the i-th
240"
SYNTHETIC EXPERIMENT,0.2921686746987952,"population index we denote p0(x0 | i) as the source population p1(x1 | i) as the i-th target population.
241"
SYNTHETIC EXPERIMENT,0.2931726907630522,"To construct p1(x1 | i), we discretize samples from a defined silhouette; e.g. an image of a character,
242"
SYNTHETIC EXPERIMENT,0.29417670682730923,"where i indexes the respective character. We use upper case letters as the silhouette and generate
243"
SYNTHETIC EXPERIMENT,0.29518072289156627,"the corresponding samples x1 ∼p1(x1 | i) from the uniform distribution over the silhouette and run
244"
SYNTHETIC EXPERIMENT,0.2961847389558233,"the diffusion process for samples x1 to acquire x0. We construct the training data using 10 random
245"
SYNTHETIC EXPERIMENT,0.2971887550200803,"orientations of 24 letters, while only using the upright orientation for the remaining letters “X” and
246"
SYNTHETIC EXPERIMENT,0.29819277108433734,"“Y”. We construct the test data by using 10 random orientations of “X” and “Y” (validation and test,
247"
SYNTHETIC EXPERIMENT,0.2991967871485944,"respectively) that differ from the upright orientations of the same letters in the training data. We
248"
SYNTHETIC EXPERIMENT,0.3002008032128514,"do this to simplify the generalization task – the model will see the shapes of “X” and “Y” during
249"
SYNTHETIC EXPERIMENT,0.30120481927710846,"training, but the same letters under different orientations remain unseen.
250"
SYNTHETIC EXPERIMENT,0.30220883534136544,"We train FM, CGFM and 4 variants of MFM of varying k for the GCN population embedding model
251"
SYNTHETIC EXPERIMENT,0.3032128514056225,"φ(pt; θ, k). When k = 0, φ(pt; θ, k) becomes identical to the DeepSets model (Zaheer et al., 2017).
252"
SYNTHETIC EXPERIMENT,0.3042168674698795,"We compare MFM to Flow-Matching (FM) and Conditional Generation via Flow-Matching (CGFM).
253"
SYNTHETIC EXPERIMENT,0.30522088353413657,"FM does not have access to conditional information; hence will only learn an aggregated lens of the
254"
SYNTHETIC EXPERIMENT,0.30622489959839355,"distribution dynamics and will not be able to fit the training data, and consequently won’t generalize
255"
SYNTHETIC EXPERIMENT,0.3072289156626506,"to the test conditions. For the training data, CGFM vector field model takes in the distribution index
256"
SYNTHETIC EXPERIMENT,0.30823293172690763,"i as a one-hot input condition. On the test set, since none of these indices is present, we input the
257"
SYNTHETIC EXPERIMENT,0.3092369477911647,"normalized constant vector, which averages the learned embeddings of the indices. Because of this,
258"
SYNTHETIC EXPERIMENT,0.3102409638554217,"CGFM will fit the training data, however, will not be able to generalize to the unseen condition in
259"
SYNTHETIC EXPERIMENT,0.3112449799196787,"the test dataset. Note that the CGFM can be viewed as an idealized model for the train data since
260"
SYNTHETIC EXPERIMENT,0.31224899598393574,"Train
Test"
SYNTHETIC EXPERIMENT,0.3132530120481928,"Replica split
Learn cell-population-"
SYNTHETIC EXPERIMENT,0.3142570281124498,specific response
SYNTHETIC EXPERIMENT,0.3152610441767068,Treatment Conditioning
SYNTHETIC EXPERIMENT,0.31626506024096385,Patient split
SYNTHETIC EXPERIMENT,0.3172690763052209,"Learn patient-
specific response"
SYNTHETIC EXPERIMENT,0.31827309236947793,"Figure 3: Organoid drug-screen dataset overview. Left: a given replica consists of a control distribution p0 and
corresponding treatment response distribution p1 for treatment condition ci. Right: train and test data splits for
replica (top) and patients (bottom) splits, restively. For each experiment there are 11 treatments, 10 patients and
3 culture conditions."
SYNTHETIC EXPERIMENT,0.3192771084337349,"it gets perfect information regarding the population conditions. We use CGFM to assess if other
261"
SYNTHETIC EXPERIMENT,0.32028112449799195,"models are fitting the data. For MFM, we expect to both fit the training data and generalize to unseen
262"
SYNTHETIC EXPERIMENT,0.321285140562249,"distributional conditions.
263"
SYNTHETIC EXPERIMENT,0.32228915662650603,"In Fig. 2, we observe that indeed FM fails to adequately learn to sample from p1(x1 | i) in the training
264"
SYNTHETIC EXPERIMENT,0.3232931726907631,"set, and likewise fails to generalize, while CGFM is able to effectively sample from p1(x1 | i) in
265"
SYNTHETIC EXPERIMENT,0.32429718875502006,"the training set, but fails to generalize. We report results for the synthetic experiment in Table 1.
266"
SYNTHETIC EXPERIMENT,0.3253012048192771,"As expected, CGFM fits the training data, however, fails to generalize beyond its set of training
267"
SYNTHETIC EXPERIMENT,0.32630522088353414,"conditions. In contrast, we see that MFM is able to both fit the training data (approaching the
268"
SYNTHETIC EXPERIMENT,0.3273092369477912,"performance of CGFM) while also generalizing to the unseen test distributions. FM fails to fit the
269"
SYNTHETIC EXPERIMENT,0.32831325301204817,"train data and fails to generalize under the test conditions. Interestingly, although MFM performs
270"
SYNTHETIC EXPERIMENT,0.3293172690763052,"better for certain values of k versus others, overall performance does not vary significantly for the
271"
SYNTHETIC EXPERIMENT,0.33032128514056225,"range considered.
272"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3313253012048193,"5.2
Experiments on Organoid Drug-screen Data
273"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.33232931726907633,"Data. For experiments on biological data, we use the organoid drug-screen dataset from Ramos Zap-
274"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3333333333333333,"atero et al. (2023). This dataset is a single-cell mass-cytometry dataset collected over 10 patients.
275"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.33433734939759036,"Somewhat unique to this dataset, unlike many prior perturbation-screen datasets which have a single
276"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3353413654618474,"control population, this dataset has matched controls to each experimental condition. Populations from
277"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.33634538152610444,"each patient are treated with 11 different drug treatments of varying dose concentrations.1 We use the
278"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3373493975903614,"term replicate to define control-treatment population pairs, p0(x0 | ci) and p1(x1 | ci), respectively
279"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.33835341365461846,"(see Fig. 3-left). In each patient, cell population are categorized into 3 cell cultures: (i) cancer associ-
280"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3393574297188755,"ated Fibroblasts, (ii) patient-derived organoid cancer cells (PDO), and (iii) patient-derived organoid
281"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.34036144578313254,"cancer cells co-cultured fibroblasts (PDOF). We report results averaged over Fibroblast/PDO/PDOF
282"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3413654618473896,"cultures and results for the individual cultures (this is reported in Appendix F).
283"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.34236947791164657,"Pre-processing and data splits. We filter each cell population to contain at least 1000 cells and
284"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3433734939759036,"consider 43 bio-markers. We consider two data splits for the organoid drug-screen dataset (see
285"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.34437751004016065,"Fig. 3-right). (1) Replicate split; here we leave-out replicates evenly across all patients for testing. (2)
286"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3453815261044177,"Patients split; here we leave-out replicates fully in one patients – in this setting, we are testing the
287"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3463855421686747,"ability of of model to generalize population prediction of treatment response for unseen patients. In
288"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3473895582329317,"both settings, we normalize the data and embed it into a lower dimensional principle components
289"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.34839357429718876,"(PC) representation. We do this to reduce the dimensionality of the data and to extract the relevant
290"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3493975903614458,"information from the 43 bio-markers (features) of the ambient space. We train and evaluate all models
291"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.35040160642570284,"in the PC space. For all organoid drug-screen dataset experiments we use PC=10. Further details
292"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3514056224899598,"regarding data pre-processing and data splits are provided in Appendix B.2.
293"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.35240963855421686,"For the organoid drug-screen experiments, we consider an ICNN architecture in addition to the
294"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3534136546184739,"Flow-matching models. The ICNN model is based on CellOT (Bunne et al., 2023a); a method for
295"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.35441767068273095,"learning cell specific response to treatments. The ICNN (and likewise CellOT) counterparts our FM
296"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.35542168674698793,1We consider only the highest dosage and leave exploration of dose-dependent response to future work.
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.35642570281124497,"Table 2: Experimental results on the organoid drug-screen dataset for population prediction of treatment response
across replicate populations averaged over co-culture conditions. Results are reported for models trained on data
embedded into 10 principle components. We report the the 1-Wasserstein (W1), 2-Wasserstein (W2), and the
maximum-mean-discrepancy (MMD) distributional distances. We consider two settings for MFM with varying
nearest-neighbours parameter. For extended results in Table 4."
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.357429718875502,"Train
Test"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.35843373493975905,"W1
W2
MMD (×10−3)
W1
W2
MMD (×10−3)"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.35943775100401604,"FM
1.946 ± 0.083
2.178 ± 0.092
6.32 ± 0.36
2.087 ± 0.035
2.301 ± 0.043
9.29 ± 0.77
ICNN
2.112 ± 0.012
2.317 ± 0.011
190.17 ± 4.87
2.200 ± 0.011
2.395 ± 0.010
249.33 ± 4.67
CGFM
1.823 ± 0.126
2.009 ± 0.143
4.16 ± 1.00
2.213 ± 0.137
2.416 ± 0.154
13.91 ± 2.41
MFM (k = 0)
1.829 ± 0.050
2.012 ± 0.058
4.64 ± 0.66
1.959 ± 0.050
2.144 ± 0.059
7.35 ± 1.20
MFM (k = 10)
1.842 ± 0.049
2.020 ± 0.057
4.76 ± 0.66
1.954 ± 0.047
2.136 ± 0.052
7.34 ± 0.93"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3604417670682731,"Table 3: Experimental results on the organoid drug-screen dataset for population prediction of treatment response
across patient populations. Results shown in this table are broken out in Table 5."
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3614457831325301,"Train
Test"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.36244979919678716,"W1
W2
MMD (×10−3)
W1
W2
MMD (×10−3)"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3634538152610442,"FM
1.995 ± 0.138
2.246 ± 0.193
6.87 ± 2.65
2.607 ± 0.028
2.947 ± 0.050
21.58 ± 1.02
ICNN
2.163 ± 0.067
2.367 ± 0.070
192.67 ± 4.22
2.702 ± 0.027
2.996 ± 0.033
452.67 ± 19.14
CGFM
1.773 ± 0.072
1.954 ± 0.092
3.03 ± 0.69
2.675 ± 0.019
2.938 ± 0.020
23.75 ± 0.61
MFM (k = 0)
1.863 ± 0.056
2.048 ± 0.063
5.01 ± 0.53
2.393 ± 0.160
2.685 ± 0.122
16.66 ± 1.99
MFM (k = 10)
1.881 ± 0.071
2.074 ± 0.091
5.25 ± 0.78
2.326 ± 0.072
2.610 ± 0.073
14.30 ± 2.27"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3644578313253012,"model in that it does not take the population index i as a condition. Therefore, it will neither be able
297"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3654618473895582,"to fit the training data, nor generalize.
298"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.36646586345381527,"Predicting treatment response across replicates. We show results for generalization across repli-
299"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3674698795180723,"cates in Table 2. As expected, we observe that CGFM fits the training data, but does not generalize to
300"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3684738955823293,"the test replicates. With this, we can observe that the FM and ICNN models fail to fit the train data,
301"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.36947791164658633,"relative to CGFM, and also fail to generalize. MFM (k = 10) performs best on generalization to
302"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3704819277108434,"unseen replicates. We include results reported for the separate cell cultures in Table 4 in Appendix F.
303"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3714859437751004,"Predicting treatment response across patients. We show results for generalization across patients
304"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.37248995983935745,"in Table 3. Similar to the replicates data setting, we observe that CGFM fits the training data, but
305"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.37349397590361444,"does not generalize to the test replicates. Likewise, the FM and ICNN models fail to fit the train data,
306"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3744979919678715,"relative to CGFM, and also fail to generalize. MFM (k = 10) performs best on generalization to
307"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3755020080321285,"unseen replicates. We include results reported for the separate cell cultures in Table 5 in Appendix F.
308"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.37650602409638556,"Through the biological and synthetic experiments, we have shown that MFM is able to generalize
309"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.37751004016064255,"to unseen distributions/populations. The implication of our results suggest that MFM can learn
310"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3785140562248996,"population dynamics in unseen environments. In biological contexts, like the one we have shown
311"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3795180722891566,"in this work, this result indicates that we can learn population dynamics, of treatment response or
312"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.38052208835341367,"any arbitrary perturbation, in new/unseen patients. This works towards a model where it is possible
313"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3815261044176707,"to predict and design an individualized treatment regimen for each patient based on their individual
314"
EXPERIMENTS ON ORGANOID DRUG-SCREEN DATA,0.3825301204819277,"characteristics and tumor microenvironment.
315"
CONCLUSION AND FUTURE WORK,0.38353413654618473,"6
Conclusion and Future Work
316"
CONCLUSION AND FUTURE WORK,0.3845381526104418,"Our paper highlights the significance of modeling dynamics based on the entire distribution. While
317"
CONCLUSION AND FUTURE WORK,0.3855421686746988,"flow-based models offer a promising avenue for learning dynamics at the population level, they were
318"
CONCLUSION AND FUTURE WORK,0.3865461847389558,"previously restricted to a single initial population and predefined conditions.
319"
CONCLUSION AND FUTURE WORK,0.38755020080321284,"In this paper, we introduce Meta Flow Matching (MFM) as a practical solution to address these
320"
CONCLUSION AND FUTURE WORK,0.3885542168674699,"limitations. By integrating along vector fields of the Wasserstein manifold, MFM allows for a more
321"
CONCLUSION AND FUTURE WORK,0.3895582329317269,"comprehensive model of dynamical systems with interacting particles. Crucially, MFM leverages
322"
CONCLUSION AND FUTURE WORK,0.39056224899598396,"graph neural networks to embed the initial population, enabling the model to generalize over various
323"
CONCLUSION AND FUTURE WORK,0.39156626506024095,"initial distributions. MFM opens up new possibilities for understanding complex phenomena that
324"
CONCLUSION AND FUTURE WORK,0.392570281124498,"emerge from interacting systems in biological and physical systems.
325"
CONCLUSION AND FUTURE WORK,0.39357429718875503,"In practice, we demonstrate that MFM learns meaningful embeddings of single-cell populations along
326"
CONCLUSION AND FUTURE WORK,0.39457831325301207,"with the developmental model of these populations. Moreover, our empirical study demonstrates the
327"
CONCLUSION AND FUTURE WORK,0.39558232931726905,"possibility of modeling patient-specific response to treatments via the meta-learning.
328"
REFERENCES,0.3965863453815261,"References
329"
REFERENCES,0.39759036144578314,"Albergo, M. S. and Vanden-Eijnden, E. (2022). Building normalizing flows with stochastic inter-
330"
REFERENCES,0.3985943775100402,"polants. arXiv preprint arXiv:2209.15571.
331"
REFERENCES,0.39959839357429716,"Ambrosio, L., Gigli, N., and Savaré, G. (2008). Gradient flows: in metric spaces and in the space of
332"
REFERENCES,0.4006024096385542,"probability measures. Springer Science & Business Media.
333"
REFERENCES,0.40160642570281124,"Amos, B., Cohen, S., Luise, G., and Redko, I. (2022). Meta optimal transport. arXiv preprint
334"
REFERENCES,0.4026104417670683,"arXiv:2206.05262.
335"
REFERENCES,0.4036144578313253,"Amos, B. et al. (2023). Tutorial on amortized optimization. Foundations and Trends® in Machine
336"
REFERENCES,0.4046184738955823,"Learning, 16(5):592–732.
337"
REFERENCES,0.40562248995983935,"Armingol, E., Officer, A., Harismendy, O., and Lewis, N. E. (2020). Deciphering cell–cell interactions
338"
REFERENCES,0.4066265060240964,"and communication from gene expression. Nature Reviews Genetics, 22(2):71–88.
339"
REFERENCES,0.40763052208835343,"Benamou, J.-D. (2003). Numerical resolution of an “unbalanced” mass transport problem. ESAIM:
340"
REFERENCES,0.4086345381526104,"Mathematical Modelling and Numerical Analysis, 37(5):851–868.
341"
REFERENCES,0.40963855421686746,"Binnewies, M., Roberts, E. W., Kersten, K., Chan, V., Fearon, D. F., Merad, M., Coussens, L. M.,
342"
REFERENCES,0.4106425702811245,"Gabrilovich, D. I., Ostrand-Rosenberg, S., Hedrick, C. C., Vonderheide, R. H., Pittet, M. J., Jain,
343"
REFERENCES,0.41164658634538154,"R. K., Zou, W., Howcroft, T. K., Woodhouse, E. C., Weinberg, R. A., and Krummel, M. F. (2018).
344"
REFERENCES,0.4126506024096386,"Understanding the tumor immune microenvironment (time) for effective therapy. Nature Medicine,
345"
REFERENCES,0.41365461847389556,"24(5):541–550.
346"
REFERENCES,0.4146586345381526,"Bunne, C., Stark, S. G., Gut, G., Del Castillo, J. S., Levesque, M., Lehmann, K.-V., Pelkmans, L.,
347"
REFERENCES,0.41566265060240964,"Krause, A., and Rätsch, G. (2023a). Learning single-cell perturbation responses using neural
348"
REFERENCES,0.4166666666666667,"optimal transport. Nature Methods, 20(11):1759–1768.
349"
REFERENCES,0.41767068273092367,"Bunne, C., Stark, S. G., Gut, G., del Castillo, J. S., Levesque, M., Lehmann, K.-V., Pelkmans, L.,
350"
REFERENCES,0.4186746987951807,"Krause, A., and Rätsch, G. (2023b). Learning single-cell perturbation responses using neural
351"
REFERENCES,0.41967871485943775,"optimal transport. Nature Methods, 20(11):1759–1768.
352"
REFERENCES,0.4206827309236948,"Chen, S., Rivaud, P., Park, J. H., Tsou, T., Charles, E., Haliburton, J. R., Pichiorri, F., and Thomson,
353"
REFERENCES,0.42168674698795183,"M. (2020). Dissecting heterogeneous cell populations across drug and disease conditions with
354"
REFERENCES,0.4226907630522088,"popalign. Proceedings of the National Academy of Sciences, 117(46):28784–28794.
355"
REFERENCES,0.42369477911646586,"Chen, T., Chen, X., Chen, W., Heaton, H., Liu, J., Wang, Z., and Yin, W. (2022). Learning to optimize:
356"
REFERENCES,0.4246987951807229,"A primer and a benchmark. Journal of Machine Learning Research, 23(189):1–59.
357"
REFERENCES,0.42570281124497994,"Chizat, L., Peyré, G., Schmitzer, B., and Vialard, F.-X. (2018). Unbalanced optimal transport:
358"
REFERENCES,0.4267068273092369,"Dynamic and kantorovich formulations. Journal of Functional Analysis, 274(11):3090–3123.
359"
REFERENCES,0.42771084337349397,"Chung, W., Eum, H. H., Lee, H.-O., Lee, K.-M., Lee, H.-B., Kim, K.-T., Ryu, H. S., Kim, S., Lee, J. E.,
360"
REFERENCES,0.428714859437751,"Park, Y. H., Kan, Z., Han, W., and Park, W.-Y. (2017). Single-cell rna-seq enables comprehensive
361"
REFERENCES,0.42971887550200805,"tumour and immune cell profiling in primary breast cancer. Nature Communications, 8(1).
362"
REFERENCES,0.4307228915662651,"Dao, Q., Phung, H., Nguyen, B., and Tran, A. (2023). Flow matching in latent space. arXiv preprint
363"
REFERENCES,0.43172690763052207,"arXiv:2307.08698.
364"
REFERENCES,0.4327309236947791,"De Bortoli, V., Thornton, J., Heng, J., and Doucet, A. (2021). Diffusion schrödinger bridge with
365"
REFERENCES,0.43373493975903615,"applications to score-based generative modeling. Advances in Neural Information Processing
366"
REFERENCES,0.4347389558232932,"Systems, 34:17695–17709.
367"
REFERENCES,0.4357429718875502,"Frangieh, C. J., Melms, J. C., Thakore, P. I., Geiger-Schuller, K. R., Ho, P., Luoma, A. M., Cleary, B.,
368"
REFERENCES,0.4367469879518072,"Jerby-Arnon, L., Malu, S., Cuoco, M. S., Zhao, M., Ager, C. R., Rogava, M., Hovey, L., Rotem,
369"
REFERENCES,0.43775100401606426,"A., Bernatchez, C., Wucherpfennig, K. W., Johnson, B. E., Rozenblatt-Rosen, O., Schadendorf,
370"
REFERENCES,0.4387550200803213,"D., Regev, A., and Izar, B. (2021). Multimodal pooled perturb-cite-seq screens in patient models
371"
REFERENCES,0.4397590361445783,"define mechanisms of cancer immune evasion. Nature Genetics, 53(3):332–341.
372"
REFERENCES,0.4407630522088353,"Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., and Dahl, G. E. (2017). Neural message
373"
REFERENCES,0.44176706827309237,"passing for quantum chemistry. In International conference on machine learning, pages 1263–1272.
374"
REFERENCES,0.4427710843373494,"PMLR.
375"
REFERENCES,0.44377510040160645,"Goodenough, D. A. and Paul, D. L. (2009). Gap junctions. Cold Spring Harb Perspect Biol,
376"
REFERENCES,0.44477911646586343,"1(1):a002576.
377"
REFERENCES,0.4457831325301205,"Gretton, A., Borgwardt, K. M., Rasch, M. J., Schölkopf, B., and Smola, A. (2012). A kernel
378"
REFERENCES,0.4467871485943775,"two-sample test. The Journal of Machine Learning Research, 13(1):723–773.
379"
REFERENCES,0.44779116465863456,"Gulati, G. S., Sikandar, S. S., Wesche, D. J., Manjunath, A., Bharadwaj, A., Berger, M. J., Ilagan, F.,
380"
REFERENCES,0.44879518072289154,"Kuo, A. H., Hsieh, R. W., Cai, S., Zabala, M., Scheeren, F. A., Lobo, N. A., Qian, D., Yu, F. B.,
381"
REFERENCES,0.4497991967871486,"Dirbas, F. M., Clarke, M. F., and Newman, A. M. (2020). Single-cell transcriptional diversity is a
382"
REFERENCES,0.4508032128514056,"hallmark of developmental potential. Science, 367(6476):405–411.
383"
REFERENCES,0.45180722891566266,"Hashimoto, T. B., Gifford, D. K., and Jaakkola, T. S. (2016). Learning population-level diffusions
384"
REFERENCES,0.4528112449799197,"with generative recurrent networks. In Proceedings of the 33rd International Conference on
385"
REFERENCES,0.4538152610441767,"Machine Learning, pages 2417–2426.
386"
REFERENCES,0.45481927710843373,"Hetzel, L., Boehm, S., Kilbertus, N., Günnemann, S., Lotfollahi, M., and Theis, F. (2022). Predicting
387"
REFERENCES,0.45582329317269077,"cellular responses to novel drug perturbations at a single-cell resolution. In Koyejo, S., Mohamed,
388"
REFERENCES,0.4568273092369478,"S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A., editors, Advances in Neural Information
389"
REFERENCES,0.4578313253012048,"Processing Systems, volume 35, pages 26711–26722. Curran Associates, Inc.
390"
REFERENCES,0.45883534136546184,"Huguet, G., Magruder, D. S., Tong, A., Fasina, O., Kuchroo, M., Wolf, G., and Krishnaswamy, S.
391"
REFERENCES,0.4598393574297189,"(2022). Manifold interpolating optimal-transport flows for trajectory inference.
392"
REFERENCES,0.4608433734939759,"Huguet, G., Tong, A., Zapatero, M. R., Wolf, G., and Krishnaswamy, S. (2023). Geodesic sinkhorn:
393"
REFERENCES,0.46184738955823296,"Optimal transport for high-dimensional datasets. In IEEE MLSP.
394"
REFERENCES,0.46285140562248994,"Isobe, N., Koyama, M., Hayashi, K., and Fukumizu, K. (2024). Extended flow matching: a method
395"
REFERENCES,0.463855421686747,"of conditional generation with generalized continuity equation. arXiv preprint arXiv:2402.18839.
396"
REFERENCES,0.464859437751004,"Ji, Y., Lotfollahi, M., Wolf, F. A., and Theis, F. J. (2021). Machine learning for perturbational
397"
REFERENCES,0.46586345381526106,"single-cell omics. Cell Systems, 12(6):522–537.
398"
REFERENCES,0.46686746987951805,"Koshizuka, T. and Sato, I. (2023). Neural lagrangian schr\""odinger bridge. In ICLR.
399"
REFERENCES,0.4678714859437751,"Lipman, Y., Chen, R. T. Q., Ben-Hamu, H., Nickel, M., and Le, M. (2023). Flow matching for
400"
REFERENCES,0.46887550200803213,"generative modeling. In The Eleventh International Conference on Learning Representations.
401"
REFERENCES,0.46987951807228917,"Liu, G.-H., Vahdat, A., Huang, D.-A., Theodorou, E. A., Nie, W., and Anandkumar, A. (2023). I2sb:
402"
REFERENCES,0.4708835341365462,"Image-to-image schrödinger bridge. In ICML.
403"
REFERENCES,0.4718875502008032,"Liu, X., Gong, C., and Liu, Q. (2022). Flow straight and fast: Learning to generate and transfer data
404"
REFERENCES,0.47289156626506024,"with rectified flow. arXiv preprint arXiv:2209.03003.
405"
REFERENCES,0.4738955823293173,"Lopez, R., Regier, J., Cole, M. B., Jordan, M. I., and Yosef, N. (2018). Deep generative modeling for
406"
REFERENCES,0.4748995983935743,"single-cell transcriptomics. Nature Methods, 15(12):1053–1058.
407"
REFERENCES,0.4759036144578313,"Lotfollahi, M., Wolf, F. A., and Theis, F. J. (2019). scgen predicts single-cell perturbation responses.
408"
REFERENCES,0.47690763052208834,"Nature Methods, 16(8):715–721.
409"
REFERENCES,0.4779116465863454,"Makkuva, A. V., Taghvaei, A., Oh, S., and Lee, J. D. (2020). Optimal transport mapping via input
410"
REFERENCES,0.4789156626506024,"convex neural networks. In ICML.
411"
REFERENCES,0.4799196787148594,"Molè, M. A., Coorens, T. H. H., Shahbazi, M. N., Weberling, A., Weatherbee, B. A. T., Gantner,
412"
REFERENCES,0.48092369477911645,"C. W., Sancho-Serra, C., Richardson, L., Drinkwater, A., Syed, N., Engley, S., Snell, P., Christie,
413"
REFERENCES,0.4819277108433735,"L., Elder, K., Campbell, A., Fishel, S., Behjati, S., Vento-Tormo, R., and Zernicka-Goetz, M.
414"
REFERENCES,0.48293172690763053,"(2021). A single cell characterisation of human embryogenesis identifies pluripotency transitions
415"
REFERENCES,0.4839357429718876,"and putative anterior hypoblast centre. Nature Communications, 12(1).
416"
REFERENCES,0.48493975903614456,"Neklyudov, K., Brekelmans, R., Tong, A., Atanackovic, L., Liu, Q., and Makhzani, A. (2023). A com-
417"
REFERENCES,0.4859437751004016,"putational framework for solving wasserstein lagrangian flows. arXiv preprint arXiv:2310.10649.
418"
REFERENCES,0.48694779116465864,"Neklyudov, K., Severo, D., and Makhzani, A. (2022). Action matching: A variational method for
419"
REFERENCES,0.4879518072289157,"learning stochastic dynamics from samples.
420"
REFERENCES,0.48895582329317266,"Otto, F. (2001). The geometry of dissipative evolution equations: the porous medium equation.
421"
REFERENCES,0.4899598393574297,"Peidli, S., Green, T. D., Shen, C., Gross, T., Min, J., Garda, S., Yuan, B., Schumacher, L. J., Taylor-
422"
REFERENCES,0.49096385542168675,"King, J. P., Marks, D. S., et al. (2024). scperturb: harmonized single-cell perturbation data. Nature
423"
REFERENCES,0.4919678714859438,"Methods, pages 1–10.
424"
REFERENCES,0.4929718875502008,"Peyré, G. and Cuturi, M. (2019). Computational Optimal Transport. arXiv:1803.00567.
425"
REFERENCES,0.4939759036144578,"Pooladian, A.-A., Ben-Hamu, H., Domingo-Enrich, C., Amos, B., Lipman, Y., and Chen, R. T.
426"
REFERENCES,0.49497991967871485,"(2023). Multisample flow matching: Straightening flows with minibatch couplings. arXiv preprint
427"
REFERENCES,0.4959839357429719,"arXiv:2304.14772.
428"
REFERENCES,0.49698795180722893,"Price, I., Sanchez-Gonzalez, A., Alet, F., Ewalds, T., El-Kadi, A., Stott, J., Mohamed, S., Battaglia,
429"
REFERENCES,0.4979919678714859,"P., Lam, R., and Willson, M. (2023). Gencast: Diffusion-based ensemble forecasting for medium-
430"
REFERENCES,0.49899598393574296,"range weather. arXiv preprint arXiv:2312.15796.
431"
REFERENCES,0.5,"Ramos Zapatero, M., Tong, A., Opzoomer, J. W., O’Sullivan, R., Cardoso Rodriguez, F., Sufi, J.,
432"
REFERENCES,0.501004016064257,"Vlckova, P., Nattress, C., Qin, X., Claus, J., Hochhauser, D., Krishnaswamy, S., and Tape, C. J.
433"
REFERENCES,0.5020080321285141,"(2023). Trellis tree-based analysis reveals stromal regulation of patient-derived organoid drug
434"
REFERENCES,0.5030120481927711,"responses. Cell, 186(25):5606–5619.e24.
435"
REFERENCES,0.5040160642570282,"Rizvi, A. H., Camara, P. G., Kandror, E. K., Roberts, T. J., Schieren, I., Maniatis, T., and Rabadan, R.
436"
REFERENCES,0.5050200803212851,"(2017). Single-cell topological rna-seq analysis reveals insights into cellular differentiation and
437"
REFERENCES,0.5060240963855421,"development. Nature Biotechnology, 35(6):551–560.
438"
REFERENCES,0.5070281124497992,"Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B. (2022). High-resolution image
439"
REFERENCES,0.5080321285140562,"synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer
440"
REFERENCES,0.5090361445783133,"vision and pattern recognition, pages 10684–10695.
441"
REFERENCES,0.5100401606425703,"Saharia, C., Chan, W., Chang, H., Lee, C., Ho, J., Salimans, T., Fleet, D., and Norouzi, M. (2022a).
442"
REFERENCES,0.5110441767068273,"Palette: Image-to-image diffusion models. In ACM SIGGRAPH 2022 conference proceedings,
443"
REFERENCES,0.5120481927710844,"pages 1–10.
444"
REFERENCES,0.5130522088353414,"Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E. L., Ghasemipour, K., Gontijo Lopes,
445"
REFERENCES,0.5140562248995983,"R., Karagol Ayan, B., Salimans, T., et al. (2022b). Photorealistic text-to-image diffusion models
446"
REFERENCES,0.5150602409638554,"with deep language understanding. Advances in neural information processing systems, 35:36479–
447"
REFERENCES,0.5160642570281124,"36494.
448"
REFERENCES,0.5170682730923695,"Sanchez-Gonzalez, A., Godwin, J., Pfaff, T., Ying, R., Leskovec, J., and Battaglia, P. (2020). Learning
449"
REFERENCES,0.5180722891566265,"to simulate complex physics with graph networks. In International conference on machine learning,
450"
REFERENCES,0.5190763052208835,"pages 8459–8468. PMLR.
451"
REFERENCES,0.5200803212851406,"Schiebinger, G., Shu, J., Tabaka, M., Cleary, B., Subramanian, V., Solomon, A., Gould, J., Liu,
452"
REFERENCES,0.5210843373493976,"S., Lin, S., Berube, P., et al. (2019). Optimal-transport analysis of single-cell gene expression
453"
REFERENCES,0.5220883534136547,"identifies developmental trajectories in reprogramming. Cell, 176(4):928–943.
454"
REFERENCES,0.5230923694779116,"Somnath, V. R., Pariset, M., Hsieh, Y.-P., Martinez, M. R., Krause, A., and Bunne, C. (2023). Aligned
455"
REFERENCES,0.5240963855421686,"diffusion schr\""odinger bridges. In UAI.
456"
REFERENCES,0.5251004016064257,"Tong, A., FATRAS, K., Malkin, N., Huguet, G., Zhang, Y., Rector-Brooks, J., Wolf, G., and Bengio,
457"
REFERENCES,0.5261044176706827,"Y. (2024). Improving and generalizing flow-based generative models with minibatch optimal
458"
REFERENCES,0.5271084337349398,"transport. Transactions on Machine Learning Research. Expert Certification.
459"
REFERENCES,0.5281124497991968,"Tong, A., Huang, J., Wolf, G., Van Dijk, D., and Krishnaswamy, S. (2020). Trajectorynet: A dynamic
460"
REFERENCES,0.5291164658634538,"optimal transport network for modeling cellular dynamics. In International conference on machine
461"
REFERENCES,0.5301204819277109,"learning, pages 9526–9536. PMLR.
462"
REFERENCES,0.5311244979919679,"Tong, A., Malkin, N., Fatras, K., Atanackovic, L., Zhang, Y., Huguet, G., Wolf, G., and Bengio,
463"
REFERENCES,0.5321285140562249,"Y. (2023). Simulation-free schr\"" odinger bridges via score and flow matching. arXiv preprint
464"
REFERENCES,0.5331325301204819,"arXiv:2307.03672.
465"
REFERENCES,0.5341365461847389,"Uscidda, T. and Cuturi, M. (2023). The monge gap: A regularizer to learn all transport maps. In
466"
REFERENCES,0.535140562248996,"Krause, A., Brunskill, E., Cho, K., Engelhardt, B., Sabato, S., and Scarlett, J., editors, Proceedings
467"
REFERENCES,0.536144578313253,"of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine
468"
REFERENCES,0.5371485943775101,"Learning Research, pages 34709–34733. PMLR.
469"
REFERENCES,0.5381526104417671,"Verma, Y., Heinonen, M., and Garg, V. (2024). Climode: Climate and weather forecasting with
470"
REFERENCES,0.5391566265060241,"physics-informed neural odes. arXiv preprint arXiv:2404.10024.
471"
REFERENCES,0.5401606425702812,"Villani, C. (2009). Optimal transport: old and new, volume 338. Springer.
472"
REFERENCES,0.5411646586345381,"Weinreb, C., Wolock, S., Tusi, B. K., Socolovsky, M., and Klein, A. M. (2018). Fundamental limits
473"
REFERENCES,0.5421686746987951,"on dynamic inference from single-cell snapshots. 115(10):E2467–E2476.
474"
REFERENCES,0.5431726907630522,"Yang, K. D. and Uhler, C. (2019). Scalable unbalanced optimal transport using generative adversarial
475"
REFERENCES,0.5441767068273092,"networks. In 7th International Conference on Learning Representations, page 20.
476"
REFERENCES,0.5451807228915663,"Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R. R., and Smola, A. J. (2017).
477"
REFERENCES,0.5461847389558233,"Deep sets. Advances in neural information processing systems, 30.
478"
REFERENCES,0.5471887550200804,"Zeng, T. and Dai, H. (2019). Single-cell rna sequencing-based computational analysis to describe
479"
REFERENCES,0.5481927710843374,"disease heterogeneity. Frontiers in Genetics, 10.
480"
REFERENCES,0.5491967871485943,"Zheng, Q., Le, M., Shaul, N., Lipman, Y., Grover, A., and Chen, R. T. (2023). Guided flows for
481"
REFERENCES,0.5502008032128514,"generative modeling and decision making. arXiv preprint arXiv:2311.13443.
482"
REFERENCES,0.5512048192771084,"A
Proof of Theorem 1
483"
REFERENCES,0.5522088353413654,"Theorem 1. Consider a dataset of populations D = {(π(x0, x1 | i))}i generated from some unknown
484"
REFERENCES,0.5532128514056225,"conditional model π(x0, x1 | c)p(c). Then the following objective
485"
REFERENCES,0.5542168674698795,"L(ω, θ) = Ep(c) Z 1"
REFERENCES,0.5552208835341366,"0
dt Ept(xt | c)∥v∗
t (xt | c) −vt(xt | φ(p0, θ), ω)∥2
(16)"
REFERENCES,0.5562248995983936,"is equivalent to the Meta Flow Matching objective
486"
REFERENCES,0.5572289156626506,"LMFM(ω, θ) = Ei∼DEπ(x0,x1 | i) Z 1"
DT,0.5582329317269076,"0
dt

∂
∂tft(x0, x1) −vt(ft(x0, x1) | φ(p0, θ); ω)"
DT,0.5592369477911646,"2
(17)"
DT,0.5602409638554217,"up to an additive constant.
487"
DT,0.5612449799196787,"Proof. The loss function
488"
DT,0.5622489959839357,"L(ω, θ) = Ep(c) Z 1"
DT,0.5632530120481928,"0
dt Ept(xt | c)∥v∗
t (xt | c) −vt(xt | φ(pt, θ); ω)∥2
(20)"
DT,0.5642570281124498,= −2Ep(c)
DT,0.5652610441767069,"Z
dtdx ⟨pt(x | c)v∗
t (x | c), vt(x | φ(pt, θ); ω)⟩+
(21)"
DT,0.5662650602409639,+ Ep(c) Z 1
DT,0.5672690763052208,"0
dt Ept(xt | c)∥vt(xt | φ(pt, θ), ω)∥2+
(22)"
DT,0.5682730923694779,+ Ep(c) Z 1
DT,0.5692771084337349,"0
dt Ept(xt | c)∥v∗
t (xt | c)∥2 .
(23)"
DT,0.570281124497992,"The last term does not depend on θ, the second term we can estimate, for the first term, we use the
489"
DT,0.571285140562249,"formula for the (from Eq. (8))
490"
DT,0.572289156626506,"pt(ξ | c)v∗
t (ξ | c) = Eπ(x0,x1)δ(ft(x0, x1) −ξ)∂ft(x0, x1)"
DT,0.5732931726907631,"∂t
.
(24)"
DT,0.5742971887550201,"Thus, the loss is equivalent (up to a constant) to
491"
DT,0.5753012048192772,"L(ω, θ) = −2Ep(c)Eπ(x0,x1 | c)"
DT,0.5763052208835341,"Z
dt
∂ft(x0, x1)"
DT,0.5773092369477911,"∂t
, vt(ft(x0, x1) | φ(pt, θ); ω)

+
(25)"
DT,0.5783132530120482,"+ Ep(c)Eπ(x0,x1 | c) Z 1"
DT,0.5793172690763052,"0
dt ∥vt(ft(x0, x1) | φ(pt, θ), ω)∥2±
(26)"
DT,0.5803212851405622,"± Ep(c)Eπ(x0,x1 | c) Z 1"
DT,0.5813253012048193,"0
dt

∂ft(x0, x1) ∂t "
DT,0.5823293172690763,"2
(27)"
DT,0.5833333333333334,"= Ec∼p(c)Eπ(x0,x1 | c) Z 1"
DT,0.5843373493975904,"0
dt

∂
∂tft(x0, x1) −vt(ft(x0, x1) | φ(pt, θ); ω)"
DT,0.5853413654618473,"2
.
(28)"
DT,0.5863453815261044,"Note that in the final expression we do not need access to the probabilistic model of p(c) if the joints
492"
DT,0.5873493975903614,"π(x0, x1 | c) are already sampled in the data D. Thus, we have
493"
DT,0.5883534136546185,"L(ω, θ) = Ec∼p(c)Eπ(x0,x1 | c) Z 1"
DT,0.5893574297188755,"0
dt

∂
∂tft(x0, x1) −vt(ft(x0, x1) | φ(pt, θ); ω)"
DT,0.5903614457831325,"2
(29)"
DT,0.5913654618473896,"= Ei∼DEπ(x0,x1 | i) Z 1"
DT,0.5923694779116466,"0
dt

∂
∂tft(x0, x1) −vt(ft(x0, x1) | φ(pt, θ); ω)"
DT,0.5933734939759037,"2
(30)"
DT,0.5943775100401606,"= LMFM(ω, θ) .
(31) 494"
DT,0.5953815261044176,"B
Experimental Details
495"
DT,0.5963855421686747,"B.1
Synthetic letters data
496"
DT,0.5973895582329317,"The synthetic letters dataset contains 242 train populations a 10 test populations. Each population
497"
DT,0.5983935742971888,"contains roughly between 750 and 2700 samples. In this dataset.
498"
DT,0.5993975903614458,"B.2
Organoid drug-screen data
499"
DT,0.6004016064257028,"The organoid drug-screen dataset contains a total of 927 replicates (or coupled populations). In the
500"
DT,0.6014056224899599,"replicates split, we use 713 populations for training and 103 left-out populations for testing. In the
501"
DT,0.6024096385542169,"patients split, we use 861 populations for training and 33 left-out populations for testing.
502"
DT,0.6034136546184738,"B.3
Model architectures and hyperparameters
503"
DT,0.6044176706827309,"ICNN. The ICNN baseline was constructed with two networks ICNN network f(x) and g(x), with
504"
DT,0.6054216867469879,"non-negative leaky ReLU activation layers. f(x) is used to minimize the transport distance and g(x)
505"
DT,0.606425702811245,"is used to transport from source to target. It has four hidden units with width of 64, and a latent
506"
DT,0.607429718875502,"dimension of 50. Both networks uses Adam optimizer (lr=1e −4, β1=0.5, β2=0.9). g(x) is trained
507"
DT,0.608433734939759,"with an inner iteration of 10 for every iteration f(x) is trained.
508"
DT,0.6094377510040161,"Vector Field Models. All vector field models vt are parameterized 4 linear layers with 512 hidden
509"
DT,0.6104417670682731,"units and SELU activation functions. The FM vector field model additionally takes a conditional
510"
DT,0.6114457831325302,"input for the one-hot treatment encoding. CGFM takes the conditional input for the one-hot treatment
511"
DT,0.6124497991967871,"conditions as well as a one-hot encoding for the population index condition i. The MFM vector field
512"
DT,0.6134538152610441,"model takes population embedding conditions, that is output from the GCN, as input, as well as the
513"
DT,0.6144578313253012,"treatment one-hot encoding. All vector field models use temporal embeddings for time and positional
514"
DT,0.6154618473895582,"embeddings for the input samples. We did not sweep the size of this embeddings space and found
515"
DT,0.6164658634538153,"that a temporal embedding and positional embeddings sizes of 128 worked sufficiently well.
516"
DT,0.6174698795180723,"Graph Neural Network. We considered a GCN model that consists of a k-nearest neighbour graph
517"
DT,0.6184738955823293,"edge pooling layer and 3 graph convolution layers with 512 hidden units. The final GCN model
518"
DT,0.6194779116465864,"layer outputs an embedding representation e ∈Rd. For the Synthetic experiment, we found that
519"
DT,0.6204819277108434,"d = 256 performed well, and d = 128 performed well for the biological experiments. We normalize
520"
DT,0.6214859437751004,"and project embeddings onto a hyper-sphere, and find that this normalization helps improve training.
521"
DT,0.6224899598393574,"Additionally, the GCN takes a one-hot cell-type encoding (encoding for Fibroblast cells or PDO
522"
DT,0.6234939759036144,"cells) for the control populations p0. This may be beneficial for PDOF populations where both
523"
DT,0.6244979919678715,"Fibroblast cells and PDO cells are present. However, it is important to note that labeling which cells
524"
DT,0.6255020080321285,"are Fibroblasts versus PDOs withing the PDOF cultures is difficult and noisy in itself, hence such a
525"
DT,0.6265060240963856,"cell-type condition may yield no additive information/performance gain.
526"
DT,0.6275100401606426,"Optimization. We use the Adam optimizer with a learning rate of 0.0001 for all Flow-matching
527"
DT,0.6285140562248996,"models (FM, CGFM, MFM). We also used the Adam optimizer with a learning rate of 0.0001 for
528"
DT,0.6295180722891566,"the GCN model. To train the MFM (FM+GCN) models, we alternate between updating the vector
529"
DT,0.6305220883534136,"field model parameters ω and the GCN model parameters θ. We alternate between updating the
530"
DT,0.6315261044176707,"respective model parameters every epoch. FM and CGFM model were trained for 2000 epochs, while
531"
DT,0.6325301204819277,"MFM models were trained for 4000 epochs. Due to the alternating optimization, the MFM vector
532"
DT,0.6335341365461847,"field model receives half as many updates compared to its counterparts (FM and CGFM). Therefore,
533"
DT,0.6345381526104418,"training for the double the epochs is necessary for fair comparison.
534"
DT,0.6355421686746988,"The hyperparameters stated in this section were selected from brief and small grid search sweeps. We
535"
DT,0.6365461847389559,"did not conduct any thorough hyperparameter optimization.
536"
DT,0.6375502008032129,"C
Implementation Details
537"
DT,0.6385542168674698,"We implement all our experiments using PyTorch and PyTorch Geometric. We submitted our code as
538"
DT,0.6395582329317269,"supplementary material with our submission.
539"
DT,0.6405622489959839,"All experiments were conducted on a HPC cluster primarily on NVIDIA Tesla T4 16GB GPUs. Each
540"
DT,0.641566265060241,"individual seed experiment run required only 1 GPU. Each experiment ran between 3-11 hours and
541"
DT,0.642570281124498,"all experiments took approximately 500 GPU hours.
542"
DT,0.643574297188755,"D
Limitations
543"
DT,0.6445783132530121,"In this work we explored empirically the effect of conditioning the learned flow on the initial
544"
DT,0.6455823293172691,"distribution. We argue this is a more natural model for many biological systems. However, there
545"
DT,0.6465863453815262,"are many other aspects of modeling biological systems that we did not consider. In particular we
546"
DT,0.6475903614457831,"did not consider extensions to the manifold setting (Huguet et al., 2022, 2023), unbalanced optimal
547"
DT,0.6485943775100401,"transport (Benamou, 2003; Yang and Uhler, 2019; Chizat et al., 2018), aligned (Somnath et al., 2023;
548"
DT,0.6495983935742972,"Liu et al., 2023), or stochastic settings (Bunne et al., 2023a; Koshizuka and Sato, 2023) in this work.
549"
DT,0.6506024096385542,"E
Broader Impacts
550"
DT,0.6516064257028112,"This paper is primarily a theoretical and methodological contribution with little societal impact. MFM
551"
DT,0.6526104417670683,"can be used to better model dynamical systems of interacting particles and in particular cellular
552"
DT,0.6536144578313253,"systems. Better modeling of cellular systems can potentially be used for the development of malicious
553"
DT,0.6546184738955824,"biological agents. However, we do not see this as a significant risk at this time.
554"
DT,0.6556224899598394,"F
Extended Results
555"
DT,0.6566265060240963,"Table 4: Experimental results on the organoid drug-screen dataset for population prediction of treatment response
across replicate populations. Results are reported for models trained on data embedded into 10 principle
components. We report the the 1-Wasserstein (W1), 2-Wasserstein (W2), and the maximum-mean-discrepancy
(MMD) distributional distances. We consider 2 settings for MFM with varying nearest-neighbours parameter."
DT,0.6576305220883534,"Fibroblasts
Train
Test
W1
W2
MMD (×10−3)
W1
W2
MMD (×10−3)"
DT,0.6586345381526104,"FM
1.584 ± 0.022
1.730 ± 0.015
3.12 ± 0.59
1.612 ± 0.014
1.736 ± 0.024
3.62 ± 0.15
ICNN
1.613 ± 0.010
1.703 ± 0.010
52.4 ± 1.64
1.655 ± 0.008
1.746 ± 0.008
53.0 ± 5.00
CGFM
1.472 ± 0.046
1.548 ± 0.048
1.28 ± 0.74
1.633 ± 0.022
1.724 ± 0.023
4.95 ± 0.72"
DT,0.6596385542168675,"MFM (k = 0)
1.519 ± 0.034
1.599 ± 0.036
2.56 ± 0.56
1.574 ± 0.002
1.657 ± 0.003
3.31 ± 0.12
MFM (k = 10)
1.547 ± 0.027
1.617 ± 0.027
2.84 ± 0.56
1.576 ± 0.017
1.658 ± 0.019
3.44 ± 0.19
PDO
Train
Test
W1
W2
MMD (×10−3)
W1
W2
MMD (×10−3)"
DT,0.6606425702811245,"FM
2.002 ± 0.027
2.201 ± 0.025
6.40 ± 0.10
2.033 ± 0.015
2.210 ± 0.016
6.92 ± 0.65
ICNN
2.29 ± 0.005
2.458 ± 0.003
245.8 ± 9.18
2.247 ± 0.005
2.415 ± 0.004
153 ± 1.00
CGFM
1.818 ± 0.198
1.931 ± 0.229
3.78 ± 0.27
2.255 ± 0.216
2.434 ± 0.240
12.16 ± 3.87"
DT,0.6616465863453815,"MFM (k = 0)
1.817 ± 0.043
1.935 ± 0.040
3.61 ± 0.50
1.909 ± 0.076
2.057 ± 0.098
5.14 ± 0.92
MFM (k = 10)
1.805 ± 0.074
1.921 ± 0.078
3.68 ± 0.78
1.903 ± 0.068
2.051 ± 0.084
5.14 ± 0.90
PDOF
Train
Test
W1
W2
MMD (×10−3)
W1
W2
MMD (×10−3)"
DT,0.6626506024096386,"FM
2.252 ± 0.20
2.603 ± 0.236
9.43 ± 0.38
2.616 ± 0.076
2.958 ± 0.089
19.34 ± 1.51
ICNN
2.432 ± 0.021
2.791 ± 0.020
272.3 ± 3.80
2.699 ± 0.021
3.023 ± 0.019
542 ± 8.00
CGFM
2.179 ± 0.133
2.548 ± 0.153
7.42 ± 2.00
2.750 ± 0.173
3.089 ± 0.200
22.63 ± 2.64"
DT,0.6636546184738956,"MFM (k = 0)
2.150 ± 0.073
2.502 ± 0.099
7.75 ± 0.93
2.395 ± 0.071
2.717 ± 0.076
13.61 ± 2.56
MFM (k = 10)
2.174 ± 0.046
2.523 ± 0.067
7.75 ± 0.65
2.382 ± 0.055
2.699 ± 0.054
13.45 ± 1.69"
DT,0.6646586345381527,"Table 5: Experimental results on the organoid drug-screen dataset for population prediction of treatment
response across patient populations. Results are reported for models trained on data embedded into 10 principle
components. We report the the 1-Wasserstein (W1), 2-Wasserstein (W2), and the maximum-mean-discrepancy
(MMD) distributional distances. We consider 2 settings for MFM with varying nearest-neighbours parameter."
DT,0.6656626506024096,"Fibroblasts
Train
Test
W1
W2
MMD (×10−3)
W1
W2
MMD (×10−3)"
DT,0.6666666666666666,"FM
1.599 ± 0.071
1.761 ± 0.137
2.82 ± 0.34
1.667 ± 0.003
1.846 ± 0.064
7.85 ± 0.15
ICNN
1.695 ± 0.08
1.796 ± 0.09
48.2 ± 3.412
1.6 ± 0.009
1.68 ± 0.013
62.2 ± 1.32
CGFM
1.496 ± 0.019
1.572 ± 0.016
1.45 ± 0.14
1.566 ± 0.028
1.652 ± 0.026
6.46 ± 0.82"
DT,0.6676706827309237,"MFM (k = 0)
1.551 ± 0.037
1.632 ± 0.042
2.31 ± 0.71
1.453 ± 0.200
1.527 ± 0.022
3.66 ± 0.67
MFM (k = 10)
1.555 ± 0.034
1.635 ± 0.039
2.54 ± 0.42
1.441 ± 0.003
1.514 ± 0.001
3.37 ± 0.72
PDO
Train
Test
W1
W2
MMD (×10−3)
W1
W2
MMD (×10−3)"
DT,0.6686746987951807,"FM
1.996 ± 0.196
2.171 ± 0.243
6.79 ± 3.40
2.128 ± 0.064
2.312 ± 0.075
7.88 ± 1.26
ICNN
2.315 ± 0.060
2.478 ± 0.057
236.8 ± 0.006
2.538 ± 0.018
2.731 ± 0.027
232.8 ± 20.6
CGFM
1.662 ± 0.026
1.760 ± 0.023
1.74 ± 0.16
2.460 ± 0.018
2.533 ± 0.023
13.6 ± 0.25"
DT,0.6696787148594378,"MFM (k = 0)
1.837 ± 0.058
1.964 ± 0.059
3.74 ± 0.29
2.010 ± 0.142
2.168 ± 0.182
6.01 ± 1.77
MFM (k = 10)
1.838 ± 0.035
1.957 ± 0.038
3.75 ± 0.41
1.971 ± 0.082
2.114 ± 0.101
5.42 ± 1.11
PDOF
Train
Test
W1
W2
MMD (×10−3)
W1
W2
MMD (×10−3)"
DT,0.6706827309236948,"FM
2.390 ± 0.148
2.806 ± 0.198
11.0 ± 2.21
4.026 ± 0.018
4.683 ± 0.011
49.0 ± 1.66
ICNN
2.479 ± 0.06
2.826 ± 0.063
291 ± 9.24
3.968 ± 0.0554
4.579 ± 0.060
1263 ± 37.5
CGFM
2.160 ± 0.170
2.530 ± 0.237
7.90 ± 1.79
4.000 ± 0.010
4.629 ± 0.012
49.2 ± 0.76"
DT,0.6716867469879518,"MFM (k = 0)
2.202 ± 0.072
2.548 ± 0.089
8.98 ± 0.59
3.717 ± 0.138
4.360 ± 0.162
40.3 ± 3.52
MFM (k = 10)
2.251 ± 0.143
2.631 ± 0.197
9.45 ± 1.52
3.565 ± 0.132
4.201 ± 0.119
36.1 ± 4.97"
DT,0.6726907630522089,"source
t=0.50
t=1.00
target Train"
DT,0.6736947791164659,"source
t=0.50
t=1.00
target
source
t=0.50
t=1.00
target"
DT,0.6746987951807228,"source
t=0.50
t=1.00
target Test FM"
DT,0.6757028112449799,"source
t=0.50
t=1.00
target CGFM"
DT,0.6767068273092369,"source
t=0.50
t=1.00
target MFM"
DT,0.677710843373494,Figure 4: Model-generated samples for synthetic letters from the source (t = 0) to target (t = 1) distributions.
DT,0.678714859437751,"NeurIPS Paper Checklist
556"
CLAIMS,0.679718875502008,"1. Claims
557"
CLAIMS,0.6807228915662651,"Question: Do the main claims made in the abstract and introduction accurately reflect the
558"
CLAIMS,0.6817269076305221,"paper’s contributions and scope?
559"
CLAIMS,0.6827309236947792,"Answer: [Yes]
560"
CLAIMS,0.6837349397590361,"Justification: Claims and contributions introduced in abstract and introduction are sup-
561"
CLAIMS,0.6847389558232931,"ported with theoretical result in Section 3 and empirical results through synthetic and real
562"
CLAIMS,0.6857429718875502,"experiments in Section 5.
563"
CLAIMS,0.6867469879518072,"Guidelines:
564"
CLAIMS,0.6877510040160643,"• The answer NA means that the abstract and introduction do not include the claims
565"
CLAIMS,0.6887550200803213,"made in the paper.
566"
CLAIMS,0.6897590361445783,"• The abstract and/or introduction should clearly state the claims made, including the
567"
CLAIMS,0.6907630522088354,"contributions made in the paper and important assumptions and limitations. A No or
568"
CLAIMS,0.6917670682730924,"NA answer to this question will not be perceived well by the reviewers.
569"
CLAIMS,0.6927710843373494,"• The claims made should match theoretical and experimental results, and reflect how
570"
CLAIMS,0.6937751004016064,"much the results can be expected to generalize to other settings.
571"
CLAIMS,0.6947791164658634,"• It is fine to include aspirational goals as motivation as long as it is clear that these goals
572"
CLAIMS,0.6957831325301205,"are not attained by the paper.
573"
LIMITATIONS,0.6967871485943775,"2. Limitations
574"
LIMITATIONS,0.6977911646586346,"Question: Does the paper discuss the limitations of the work performed by the authors?
575"
LIMITATIONS,0.6987951807228916,"Answer: [Yes]
576"
LIMITATIONS,0.6997991967871486,"Justification: We discuss limitations in Appendix D.
577"
LIMITATIONS,0.7008032128514057,"Guidelines:
578"
LIMITATIONS,0.7018072289156626,"• The answer NA means that the paper has no limitation while the answer No means that
579"
LIMITATIONS,0.7028112449799196,"the paper has limitations, but those are not discussed in the paper.
580"
LIMITATIONS,0.7038152610441767,"• The authors are encouraged to create a separate ""Limitations"" section in their paper.
581"
LIMITATIONS,0.7048192771084337,"• The paper should point out any strong assumptions and how robust the results are to
582"
LIMITATIONS,0.7058232931726908,"violations of these assumptions (e.g., independence assumptions, noiseless settings,
583"
LIMITATIONS,0.7068273092369478,"model well-specification, asymptotic approximations only holding locally). The authors
584"
LIMITATIONS,0.7078313253012049,"should reflect on how these assumptions might be violated in practice and what the
585"
LIMITATIONS,0.7088353413654619,"implications would be.
586"
LIMITATIONS,0.7098393574297188,"• The authors should reflect on the scope of the claims made, e.g., if the approach was
587"
LIMITATIONS,0.7108433734939759,"only tested on a few datasets or with a few runs. In general, empirical results often
588"
LIMITATIONS,0.7118473895582329,"depend on implicit assumptions, which should be articulated.
589"
LIMITATIONS,0.7128514056224899,"• The authors should reflect on the factors that influence the performance of the approach.
590"
LIMITATIONS,0.713855421686747,"For example, a facial recognition algorithm may perform poorly when image resolution
591"
LIMITATIONS,0.714859437751004,"is low or images are taken in low lighting. Or a speech-to-text system might not be
592"
LIMITATIONS,0.7158634538152611,"used reliably to provide closed captions for online lectures because it fails to handle
593"
LIMITATIONS,0.7168674698795181,"technical jargon.
594"
LIMITATIONS,0.7178714859437751,"• The authors should discuss the computational efficiency of the proposed algorithms
595"
LIMITATIONS,0.7188755020080321,"and how they scale with dataset size.
596"
LIMITATIONS,0.7198795180722891,"• If applicable, the authors should discuss possible limitations of their approach to
597"
LIMITATIONS,0.7208835341365462,"address problems of privacy and fairness.
598"
LIMITATIONS,0.7218875502008032,"• While the authors might fear that complete honesty about limitations might be used by
599"
LIMITATIONS,0.7228915662650602,"reviewers as grounds for rejection, a worse outcome might be that reviewers discover
600"
LIMITATIONS,0.7238955823293173,"limitations that aren’t acknowledged in the paper. The authors should use their best
601"
LIMITATIONS,0.7248995983935743,"judgment and recognize that individual actions in favor of transparency play an impor-
602"
LIMITATIONS,0.7259036144578314,"tant role in developing norms that preserve the integrity of the community. Reviewers
603"
LIMITATIONS,0.7269076305220884,"will be specifically instructed to not penalize honesty concerning limitations.
604"
THEORY ASSUMPTIONS AND PROOFS,0.7279116465863453,"3. Theory Assumptions and Proofs
605"
THEORY ASSUMPTIONS AND PROOFS,0.7289156626506024,"Question: For each theoretical result, does the paper provide the full set of assumptions and
606"
THEORY ASSUMPTIONS AND PROOFS,0.7299196787148594,"a complete (and correct) proof?
607"
THEORY ASSUMPTIONS AND PROOFS,0.7309236947791165,"Answer: [Yes]
608"
THEORY ASSUMPTIONS AND PROOFS,0.7319277108433735,"Justification: Theory is provided in Section 2 and Section 3. Proofs are provide in Ap-
609"
THEORY ASSUMPTIONS AND PROOFS,0.7329317269076305,"pendix A
610"
THEORY ASSUMPTIONS AND PROOFS,0.7339357429718876,"Guidelines:
611"
THEORY ASSUMPTIONS AND PROOFS,0.7349397590361446,"• The answer NA means that the paper does not include theoretical results.
612"
THEORY ASSUMPTIONS AND PROOFS,0.7359437751004017,"• All the theorems, formulas, and proofs in the paper should be numbered and cross-
613"
THEORY ASSUMPTIONS AND PROOFS,0.7369477911646586,"referenced.
614"
THEORY ASSUMPTIONS AND PROOFS,0.7379518072289156,"• All assumptions should be clearly stated or referenced in the statement of any theorems.
615"
THEORY ASSUMPTIONS AND PROOFS,0.7389558232931727,"• The proofs can either appear in the main paper or the supplemental material, but if
616"
THEORY ASSUMPTIONS AND PROOFS,0.7399598393574297,"they appear in the supplemental material, the authors are encouraged to provide a short
617"
THEORY ASSUMPTIONS AND PROOFS,0.7409638554216867,"proof sketch to provide intuition.
618"
THEORY ASSUMPTIONS AND PROOFS,0.7419678714859438,"• Inversely, any informal proof provided in the core of the paper should be complemented
619"
THEORY ASSUMPTIONS AND PROOFS,0.7429718875502008,"by formal proofs provided in appendix or supplemental material.
620"
THEORY ASSUMPTIONS AND PROOFS,0.7439759036144579,"• Theorems and Lemmas that the proof relies upon should be properly referenced.
621"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7449799196787149,"4. Experimental Result Reproducibility
622"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7459839357429718,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
623"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7469879518072289,"perimental results of the paper to the extent that it affects the main claims and/or conclusions
624"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7479919678714859,"of the paper (regardless of whether the code and data are provided or not)?
625"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.748995983935743,"Answer: [Yes]
626"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.75,"Justification: All details for reproducing results and experiments can be found through
627"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.751004016064257,"the main text body and appendix. The details include: dataset resource Ramos Zapatero
628"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7520080321285141,"et al. (2023), data processing, model architecture and optimization details, and performance
629"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7530120481927711,"metrics.
630"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7540160642570282,"Guidelines:
631"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7550200803212851,"• The answer NA means that the paper does not include experiments.
632"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7560240963855421,"• If the paper includes experiments, a No answer to this question will not be perceived
633"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7570281124497992,"well by the reviewers: Making the paper reproducible is important, regardless of
634"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7580321285140562,"whether the code and data are provided or not.
635"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7590361445783133,"• If the contribution is a dataset and/or model, the authors should describe the steps taken
636"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7600401606425703,"to make their results reproducible or verifiable.
637"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7610441767068273,"• Depending on the contribution, reproducibility can be accomplished in various ways.
638"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7620481927710844,"For example, if the contribution is a novel architecture, describing the architecture fully
639"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7630522088353414,"might suffice, or if the contribution is a specific model and empirical evaluation, it may
640"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7640562248995983,"be necessary to either make it possible for others to replicate the model with the same
641"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7650602409638554,"dataset, or provide access to the model. In general. releasing code and data is often
642"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7660642570281124,"one good way to accomplish this, but reproducibility can also be provided via detailed
643"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7670682730923695,"instructions for how to replicate the results, access to a hosted model (e.g., in the case
644"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7680722891566265,"of a large language model), releasing of a model checkpoint, or other means that are
645"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7690763052208835,"appropriate to the research performed.
646"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7700803212851406,"• While NeurIPS does not require releasing code, the conference does require all submis-
647"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7710843373493976,"sions to provide some reasonable avenue for reproducibility, which may depend on the
648"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7720883534136547,"nature of the contribution. For example
649"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7730923694779116,"(a) If the contribution is primarily a new algorithm, the paper should make it clear how
650"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7740963855421686,"to reproduce that algorithm.
651"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7751004016064257,"(b) If the contribution is primarily a new model architecture, the paper should describe
652"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7761044176706827,"the architecture clearly and fully.
653"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7771084337349398,"(c) If the contribution is a new model (e.g., a large language model), then there should
654"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7781124497991968,"either be a way to access this model for reproducing the results or a way to reproduce
655"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7791164658634538,"the model (e.g., with an open-source dataset or instructions for how to construct
656"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7801204819277109,"the dataset).
657"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7811244979919679,"(d) We recognize that reproducibility may be tricky in some cases, in which case
658"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7821285140562249,"authors are welcome to describe the particular way they provide for reproducibility.
659"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7831325301204819,"In the case of closed-source models, it may be that access to the model is limited in
660"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.7841365461847389,"some way (e.g., to registered users), but it should be possible for other researchers
661"
EXPERIMENTAL RESULT REPRODUCIBILITY,0.785140562248996,"to have some path to reproducing or verifying the results.
662"
OPEN ACCESS TO DATA AND CODE,0.786144578313253,"5. Open access to data and code
663"
OPEN ACCESS TO DATA AND CODE,0.7871485943775101,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
664"
OPEN ACCESS TO DATA AND CODE,0.7881526104417671,"tions to faithfully reproduce the main experimental results, as described in supplemental
665"
OPEN ACCESS TO DATA AND CODE,0.7891566265060241,"material?
666"
OPEN ACCESS TO DATA AND CODE,0.7901606425702812,"Answer: [Yes]
667"
OPEN ACCESS TO DATA AND CODE,0.7911646586345381,"Justification: The data used in the empirical study is either synthetic or publicly available.
668"
OPEN ACCESS TO DATA AND CODE,0.7921686746987951,"The code reproducing all the experiments is attached to the paper.
669"
OPEN ACCESS TO DATA AND CODE,0.7931726907630522,"Guidelines:
670"
OPEN ACCESS TO DATA AND CODE,0.7941767068273092,"• The answer NA means that paper does not include experiments requiring code.
671"
OPEN ACCESS TO DATA AND CODE,0.7951807228915663,"• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
672"
OPEN ACCESS TO DATA AND CODE,0.7961847389558233,"public/guides/CodeSubmissionPolicy) for more details.
673"
OPEN ACCESS TO DATA AND CODE,0.7971887550200804,"• While we encourage the release of code and data, we understand that this might not be
674"
OPEN ACCESS TO DATA AND CODE,0.7981927710843374,"possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
675"
OPEN ACCESS TO DATA AND CODE,0.7991967871485943,"including code, unless this is central to the contribution (e.g., for a new open-source
676"
OPEN ACCESS TO DATA AND CODE,0.8002008032128514,"benchmark).
677"
OPEN ACCESS TO DATA AND CODE,0.8012048192771084,"• The instructions should contain the exact command and environment needed to run to
678"
OPEN ACCESS TO DATA AND CODE,0.8022088353413654,"reproduce the results. See the NeurIPS code and data submission guidelines (https:
679"
OPEN ACCESS TO DATA AND CODE,0.8032128514056225,"//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
680"
OPEN ACCESS TO DATA AND CODE,0.8042168674698795,"• The authors should provide instructions on data access and preparation, including how
681"
OPEN ACCESS TO DATA AND CODE,0.8052208835341366,"to access the raw data, preprocessed data, intermediate data, and generated data, etc.
682"
OPEN ACCESS TO DATA AND CODE,0.8062248995983936,"• The authors should provide scripts to reproduce all experimental results for the new
683"
OPEN ACCESS TO DATA AND CODE,0.8072289156626506,"proposed method and baselines. If only a subset of experiments are reproducible, they
684"
OPEN ACCESS TO DATA AND CODE,0.8082329317269076,"should state which ones are omitted from the script and why.
685"
OPEN ACCESS TO DATA AND CODE,0.8092369477911646,"• At submission time, to preserve anonymity, the authors should release anonymized
686"
OPEN ACCESS TO DATA AND CODE,0.8102409638554217,"versions (if applicable).
687"
OPEN ACCESS TO DATA AND CODE,0.8112449799196787,"• Providing as much information as possible in supplemental material (appended to the
688"
OPEN ACCESS TO DATA AND CODE,0.8122489959839357,"paper) is recommended, but including URLs to data and code is permitted.
689"
OPEN ACCESS TO DATA AND CODE,0.8132530120481928,"6. Experimental Setting/Details
690"
OPEN ACCESS TO DATA AND CODE,0.8142570281124498,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
691"
OPEN ACCESS TO DATA AND CODE,0.8152610441767069,"parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
692"
OPEN ACCESS TO DATA AND CODE,0.8162650602409639,"results?
693"
OPEN ACCESS TO DATA AND CODE,0.8172690763052208,"Answer: [Yes]
694"
OPEN ACCESS TO DATA AND CODE,0.8182730923694779,"Justification: The paper discusses the experimental setup necessary to understand the results
695"
OPEN ACCESS TO DATA AND CODE,0.8192771084337349,"in Section 5. Furthermore, the details of the empirical study are provided in Appendix B.
696"
OPEN ACCESS TO DATA AND CODE,0.820281124497992,"Guidelines:
697"
OPEN ACCESS TO DATA AND CODE,0.821285140562249,"• The answer NA means that the paper does not include experiments.
698"
OPEN ACCESS TO DATA AND CODE,0.822289156626506,"• The experimental setting should be presented in the core of the paper to a level of detail
699"
OPEN ACCESS TO DATA AND CODE,0.8232931726907631,"that is necessary to appreciate the results and make sense of them.
700"
OPEN ACCESS TO DATA AND CODE,0.8242971887550201,"• The full details can be provided either with the code, in appendix, or as supplemental
701"
OPEN ACCESS TO DATA AND CODE,0.8253012048192772,"material.
702"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8263052208835341,"7. Experiment Statistical Significance
703"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8273092369477911,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
704"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8283132530120482,"information about the statistical significance of the experiments?
705"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8293172690763052,"Answer: [Yes]
706"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8303212851405622,"Justification: All the results presented in the paper are averaged over multiple independent
707"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8313253012048193,"runs and the standard deviations are provided along the metrics.
708"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8323293172690763,"Guidelines:
709"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8333333333333334,"• The answer NA means that the paper does not include experiments.
710"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8343373493975904,"• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
711"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8353413654618473,"dence intervals, or statistical significance tests, at least for the experiments that support
712"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8363453815261044,"the main claims of the paper.
713"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8373493975903614,"• The factors of variability that the error bars are capturing should be clearly stated (for
714"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8383534136546185,"example, train/test split, initialization, random drawing of some parameter, or overall
715"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8393574297188755,"run with given experimental conditions).
716"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8403614457831325,"• The method for calculating the error bars should be explained (closed form formula,
717"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8413654618473896,"call to a library function, bootstrap, etc.)
718"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8423694779116466,"• The assumptions made should be given (e.g., Normally distributed errors).
719"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8433734939759037,"• It should be clear whether the error bar is the standard deviation or the standard error
720"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8443775100401606,"of the mean.
721"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8453815261044176,"• It is OK to report 1-sigma error bars, but one should state it. The authors should
722"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8463855421686747,"preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
723"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8473895582329317,"of Normality of errors is not verified.
724"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8483935742971888,"• For asymmetric distributions, the authors should be careful not to show in tables or
725"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8493975903614458,"figures symmetric error bars that would yield results that are out of range (e.g. negative
726"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8504016064257028,"error rates).
727"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8514056224899599,"• If error bars are reported in tables or plots, The authors should explain in the text how
728"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.8524096385542169,"they were calculated and reference the corresponding figures or tables in the text.
729"
EXPERIMENTS COMPUTE RESOURCES,0.8534136546184738,"8. Experiments Compute Resources
730"
EXPERIMENTS COMPUTE RESOURCES,0.8544176706827309,"Question: For each experiment, does the paper provide sufficient information on the com-
731"
EXPERIMENTS COMPUTE RESOURCES,0.8554216867469879,"puter resources (type of compute workers, memory, time of execution) needed to reproduce
732"
EXPERIMENTS COMPUTE RESOURCES,0.856425702811245,"the experiments?
733"
EXPERIMENTS COMPUTE RESOURCES,0.857429718875502,"Answer: [Yes]
734"
EXPERIMENTS COMPUTE RESOURCES,0.858433734939759,"Justification: The paper discuss the compute resources and reproducibility in Appendix C.
735"
EXPERIMENTS COMPUTE RESOURCES,0.8594377510040161,"Guidelines:
736"
EXPERIMENTS COMPUTE RESOURCES,0.8604417670682731,"• The answer NA means that the paper does not include experiments.
737"
EXPERIMENTS COMPUTE RESOURCES,0.8614457831325302,"• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
738"
EXPERIMENTS COMPUTE RESOURCES,0.8624497991967871,"or cloud provider, including relevant memory and storage.
739"
EXPERIMENTS COMPUTE RESOURCES,0.8634538152610441,"• The paper should provide the amount of compute required for each of the individual
740"
EXPERIMENTS COMPUTE RESOURCES,0.8644578313253012,"experimental runs as well as estimate the total compute.
741"
EXPERIMENTS COMPUTE RESOURCES,0.8654618473895582,"• The paper should disclose whether the full research project required more compute
742"
EXPERIMENTS COMPUTE RESOURCES,0.8664658634538153,"than the experiments reported in the paper (e.g., preliminary or failed experiments that
743"
EXPERIMENTS COMPUTE RESOURCES,0.8674698795180723,"didn’t make it into the paper).
744"
CODE OF ETHICS,0.8684738955823293,"9. Code Of Ethics
745"
CODE OF ETHICS,0.8694779116465864,"Question: Does the research conducted in the paper conform, in every respect, with the
746"
CODE OF ETHICS,0.8704819277108434,"NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
747"
CODE OF ETHICS,0.8714859437751004,"Answer: [Yes]
748"
CODE OF ETHICS,0.8724899598393574,"Justification: The research does conform with the NeurIPS Code of Ethics. The study
749"
CODE OF ETHICS,0.8734939759036144,"presented involves only public or synthetic data, which is freely available online. The
750"
CODE OF ETHICS,0.8744979919678715,"considered models do not impose risks of misuse or dual-use.
751"
CODE OF ETHICS,0.8755020080321285,"Guidelines:
752"
CODE OF ETHICS,0.8765060240963856,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
753"
CODE OF ETHICS,0.8775100401606426,"• If the authors answer No, they should explain the special circumstances that require a
754"
CODE OF ETHICS,0.8785140562248996,"deviation from the Code of Ethics.
755"
CODE OF ETHICS,0.8795180722891566,"• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
756"
CODE OF ETHICS,0.8805220883534136,"eration due to laws or regulations in their jurisdiction).
757"
BROADER IMPACTS,0.8815261044176707,"10. Broader Impacts
758"
BROADER IMPACTS,0.8825301204819277,"Question: Does the paper discuss both potential positive societal impacts and negative
759"
BROADER IMPACTS,0.8835341365461847,"societal impacts of the work performed?
760"
BROADER IMPACTS,0.8845381526104418,"Answer: [Yes]
761"
BROADER IMPACTS,0.8855421686746988,"Justification: The paper discusses the broader impact in Appendix E.
762"
BROADER IMPACTS,0.8865461847389559,"Guidelines:
763"
BROADER IMPACTS,0.8875502008032129,"• The answer NA means that there is no societal impact of the work performed.
764"
BROADER IMPACTS,0.8885542168674698,"• If the authors answer NA or No, they should explain why their work has no societal
765"
BROADER IMPACTS,0.8895582329317269,"impact or why the paper does not address societal impact.
766"
BROADER IMPACTS,0.8905622489959839,"• Examples of negative societal impacts include potential malicious or unintended uses
767"
BROADER IMPACTS,0.891566265060241,"(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
768"
BROADER IMPACTS,0.892570281124498,"(e.g., deployment of technologies that could make decisions that unfairly impact specific
769"
BROADER IMPACTS,0.893574297188755,"groups), privacy considerations, and security considerations.
770"
BROADER IMPACTS,0.8945783132530121,"• The conference expects that many papers will be foundational research and not tied
771"
BROADER IMPACTS,0.8955823293172691,"to particular applications, let alone deployments. However, if there is a direct path to
772"
BROADER IMPACTS,0.8965863453815262,"any negative applications, the authors should point it out. For example, it is legitimate
773"
BROADER IMPACTS,0.8975903614457831,"to point out that an improvement in the quality of generative models could be used to
774"
BROADER IMPACTS,0.8985943775100401,"generate deepfakes for disinformation. On the other hand, it is not needed to point out
775"
BROADER IMPACTS,0.8995983935742972,"that a generic algorithm for optimizing neural networks could enable people to train
776"
BROADER IMPACTS,0.9006024096385542,"models that generate Deepfakes faster.
777"
BROADER IMPACTS,0.9016064257028112,"• The authors should consider possible harms that could arise when the technology is
778"
BROADER IMPACTS,0.9026104417670683,"being used as intended and functioning correctly, harms that could arise when the
779"
BROADER IMPACTS,0.9036144578313253,"technology is being used as intended but gives incorrect results, and harms following
780"
BROADER IMPACTS,0.9046184738955824,"from (intentional or unintentional) misuse of the technology.
781"
BROADER IMPACTS,0.9056224899598394,"• If there are negative societal impacts, the authors could also discuss possible mitigation
782"
BROADER IMPACTS,0.9066265060240963,"strategies (e.g., gated release of models, providing defenses in addition to attacks,
783"
BROADER IMPACTS,0.9076305220883534,"mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
784"
BROADER IMPACTS,0.9086345381526104,"feedback over time, improving the efficiency and accessibility of ML).
785"
SAFEGUARDS,0.9096385542168675,"11. Safeguards
786"
SAFEGUARDS,0.9106425702811245,"Question: Does the paper describe safeguards that have been put in place for responsible
787"
SAFEGUARDS,0.9116465863453815,"release of data or models that have a high risk for misuse (e.g., pretrained language models,
788"
SAFEGUARDS,0.9126506024096386,"image generators, or scraped datasets)?
789"
SAFEGUARDS,0.9136546184738956,"Answer: [NA] .
790"
SAFEGUARDS,0.9146586345381527,"Justification: The models considered in the paper do not carry the risks of misuse or dual-use.
791"
SAFEGUARDS,0.9156626506024096,"Guidelines:
792"
SAFEGUARDS,0.9166666666666666,"• The answer NA means that the paper poses no such risks.
793"
SAFEGUARDS,0.9176706827309237,"• Released models that have a high risk for misuse or dual-use should be released with
794"
SAFEGUARDS,0.9186746987951807,"necessary safeguards to allow for controlled use of the model, for example by requiring
795"
SAFEGUARDS,0.9196787148594378,"that users adhere to usage guidelines or restrictions to access the model or implementing
796"
SAFEGUARDS,0.9206827309236948,"safety filters.
797"
SAFEGUARDS,0.9216867469879518,"• Datasets that have been scraped from the Internet could pose safety risks. The authors
798"
SAFEGUARDS,0.9226907630522089,"should describe how they avoided releasing unsafe images.
799"
SAFEGUARDS,0.9236947791164659,"• We recognize that providing effective safeguards is challenging, and many papers do
800"
SAFEGUARDS,0.9246987951807228,"not require this, but we encourage authors to take this into account and make a best
801"
SAFEGUARDS,0.9257028112449799,"faith effort.
802"
LICENSES FOR EXISTING ASSETS,0.9267068273092369,"12. Licenses for existing assets
803"
LICENSES FOR EXISTING ASSETS,0.927710843373494,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
804"
LICENSES FOR EXISTING ASSETS,0.928714859437751,"the paper, properly credited and are the license and terms of use explicitly mentioned and
805"
LICENSES FOR EXISTING ASSETS,0.929718875502008,"properly respected?
806"
LICENSES FOR EXISTING ASSETS,0.9307228915662651,"Answer: [Yes] .
807"
LICENSES FOR EXISTING ASSETS,0.9317269076305221,"Justification: We cite (Ramos Zapatero et al., 2023) that produced the dataset used in the
808"
LICENSES FOR EXISTING ASSETS,0.9327309236947792,"study. The dataset is available under the license CC BY 4.0.
809"
LICENSES FOR EXISTING ASSETS,0.9337349397590361,"Guidelines:
810"
LICENSES FOR EXISTING ASSETS,0.9347389558232931,"• The answer NA means that the paper does not use existing assets.
811"
LICENSES FOR EXISTING ASSETS,0.9357429718875502,"• The authors should cite the original paper that produced the code package or dataset.
812"
LICENSES FOR EXISTING ASSETS,0.9367469879518072,"• The authors should state which version of the asset is used and, if possible, include a
813"
LICENSES FOR EXISTING ASSETS,0.9377510040160643,"URL.
814"
LICENSES FOR EXISTING ASSETS,0.9387550200803213,"• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
815"
LICENSES FOR EXISTING ASSETS,0.9397590361445783,"• For scraped data from a particular source (e.g., website), the copyright and terms of
816"
LICENSES FOR EXISTING ASSETS,0.9407630522088354,"service of that source should be provided.
817"
LICENSES FOR EXISTING ASSETS,0.9417670682730924,"• If assets are released, the license, copyright information, and terms of use in the
818"
LICENSES FOR EXISTING ASSETS,0.9427710843373494,"package should be provided. For popular datasets, paperswithcode.com/datasets
819"
LICENSES FOR EXISTING ASSETS,0.9437751004016064,"has curated licenses for some datasets. Their licensing guide can help determine the
820"
LICENSES FOR EXISTING ASSETS,0.9447791164658634,"license of a dataset.
821"
LICENSES FOR EXISTING ASSETS,0.9457831325301205,"• For existing datasets that are re-packaged, both the original license and the license of
822"
LICENSES FOR EXISTING ASSETS,0.9467871485943775,"the derived asset (if it has changed) should be provided.
823"
LICENSES FOR EXISTING ASSETS,0.9477911646586346,"• If this information is not available online, the authors are encouraged to reach out to
824"
LICENSES FOR EXISTING ASSETS,0.9487951807228916,"the asset’s creators.
825"
NEW ASSETS,0.9497991967871486,"13. New Assets
826"
NEW ASSETS,0.9508032128514057,"Question: Are new assets introduced in the paper well documented and is the documentation
827"
NEW ASSETS,0.9518072289156626,"provided alongside the assets?
828"
NEW ASSETS,0.9528112449799196,"Answer: [NA] .
829"
NEW ASSETS,0.9538152610441767,"Justification: The paper does not release new assets.
830"
NEW ASSETS,0.9548192771084337,"Guidelines:
831"
NEW ASSETS,0.9558232931726908,"• The answer NA means that the paper does not release new assets.
832"
NEW ASSETS,0.9568273092369478,"• Researchers should communicate the details of the dataset/code/model as part of their
833"
NEW ASSETS,0.9578313253012049,"submissions via structured templates. This includes details about training, license,
834"
NEW ASSETS,0.9588353413654619,"limitations, etc.
835"
NEW ASSETS,0.9598393574297188,"• The paper should discuss whether and how consent was obtained from people whose
836"
NEW ASSETS,0.9608433734939759,"asset is used.
837"
NEW ASSETS,0.9618473895582329,"• At submission time, remember to anonymize your assets (if applicable). You can either
838"
NEW ASSETS,0.9628514056224899,"create an anonymized URL or include an anonymized zip file.
839"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.963855421686747,"14. Crowdsourcing and Research with Human Subjects
840"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.964859437751004,"Question: For crowdsourcing experiments and research with human subjects, does the paper
841"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9658634538152611,"include the full text of instructions given to participants and screenshots, if applicable, as
842"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9668674698795181,"well as details about compensation (if any)?
843"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9678714859437751,"Answer: [NA] .
844"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9688755020080321,"Justification: The empirical study presented in the paper is conducted on the synthetic or
845"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9698795180722891,"publicly available data.
846"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9708835341365462,"Guidelines:
847"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9718875502008032,"• The answer NA means that the paper does not involve crowdsourcing nor research with
848"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9728915662650602,"human subjects.
849"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9738955823293173,"• Including this information in the supplemental material is fine, but if the main contribu-
850"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9748995983935743,"tion of the paper involves human subjects, then as much detail as possible should be
851"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9759036144578314,"included in the main paper.
852"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9769076305220884,"• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
853"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9779116465863453,"or other labor should be paid at least the minimum wage in the country of the data
854"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9789156626506024,"collector.
855"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9799196787148594,"15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
856"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9809236947791165,"Subjects
857"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9819277108433735,"Question: Does the paper describe potential risks incurred by study participants, whether
858"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9829317269076305,"such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
859"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9839357429718876,"approvals (or an equivalent approval/review based on the requirements of your country or
860"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9849397590361446,"institution) were obtained?
861"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9859437751004017,"Answer: [NA]
862"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9869477911646586,"Justification: The empirical study presented in the paper is conducted on the synthetic or
863"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9879518072289156,"publicly available data.
864"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9889558232931727,"Guidelines:
865"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9899598393574297,"• The answer NA means that the paper does not involve crowdsourcing nor research with
866"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9909638554216867,"human subjects.
867"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9919678714859438,"• Depending on the country in which research is conducted, IRB approval (or equivalent)
868"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9929718875502008,"may be required for any human subjects research. If you obtained IRB approval, you
869"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9939759036144579,"should clearly state this in the paper.
870"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9949799196787149,"• We recognize that the procedures for this may vary significantly between institutions
871"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9959839357429718,"and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
872"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9969879518072289,"guidelines for their institution.
873"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.9979919678714859,"• For initial submissions, do not include any information that would break anonymity (if
874"
CROWDSOURCING AND RESEARCH WITH HUMAN SUBJECTS,0.998995983935743,"applicable), such as the institution conducting the review.
875"
