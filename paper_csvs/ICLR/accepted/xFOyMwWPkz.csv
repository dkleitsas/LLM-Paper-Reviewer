Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0017513134851138354,"Identifying the status of individual network units is critical for understanding the
mechanism of convolutional neural networks (CNNs). However, it is still chal-
lenging to reliably give a general indication of unit status, especially for units in
different network models. To this end, we propose a novel method for quantita-
tively clarifying the status of single unit in CNN using algebraic topological tools.
Unit status is indicated via the calculation of a deﬁned topological-based entropy,
called feature entropy, which measures the degree of chaos of the global spatial
pattern hidden in the unit for a category. In this way, feature entropy could pro-
vide an accurate indication of status for units in different networks with diverse
situations like weight-rescaling operation. Further, we show that feature entropy
decreases as the layer goes deeper and shares almost simultaneous trend with loss
during training. We show that by investigating the feature entropy of units on only
training data, it could give discrimination between networks with different gener-
alization ability from the view of the effectiveness of feature representations."
INTRODUCTION,0.0035026269702276708,"1
INTRODUCTION"
INTRODUCTION,0.005253940455341506,"Convolutional neural networks (CNNs) have achieved great success in various vision tasks (Szegedy
et al., 2016; Redmon et al., 2016; He et al., 2017a). The key to such success is the powerful ability
of feature representations to input images, where network units1 play a critical role. But impacted
by the diverse training deployments and huge hypothesis space, networks even with the same archi-
tecture may converge to different minima on a given task. Although units between these networks
could present similar function for the same task, yet they may have completely different activation
magnitudes. Consequently, this makes it fairly hard to give a general indication of the status for a
given network unit with respect to how well features are represented by it from images in the same
class."
INTRODUCTION,0.0070052539404553416,"Being rough indicators in practice, magnitude responses of units are usually chosen simply (Zhang
et al., 2018) or processed statistically (such as average mean) (Li et al., 2016; Luo et al., 2017)
based on the idea of matched ﬁltering. However, ﬁrstly these indicators are apparently sensitive to
rescaling operations in magnitude. If performing a simply rescaling operation to the weights such
as the strategy introduced in Neyshabur et al. (2015), the results of the network and the function
of each unit would all remain unchanged, but these indicators would vary along with the rescaling
coefﬁcient. Secondly, as the spatial information in the unit is completely discarded, they could not
give discrimination between units with and without random patterns, for example units separately
outputted by a well-trained and random-initialized CNN ﬁlter. Without a valid indication regard-
ing the mentioned situations, these indicators fail to ensure the universal applicability for units in
different network models."
INTRODUCTION,0.008756567425569177,"In this paper, we attempt to investigate the status of units from a new perspective. Roughly speak-
ing, natural images in the same class have common features, and meanwhile the locations of these
features are spatially correlated in global. For effective units, features are picked out and represented"
INTRODUCTION,0.010507880910683012,"1Regarding the term unit, a unit is the perceptive node in networks, which generally refers to the activated
feature map outputted by a convolutional ﬁlter in CNNs."
INTRODUCTION,0.012259194395796848,Published as a conference paper at ICLR 2022
INTRODUCTION,0.014010507880910683,"Images
Effective units
Birth distribution"
INTRODUCTION,0.01576182136602452,Low feature entropy
INTRODUCTION,0.017513134851138354,"Local 
operation"
INTRODUCTION,0.01926444833625219,Ineffective units
INTRODUCTION,0.021015761821366025,Regularized spatial pattern
INTRODUCTION,0.02276707530647986,Chaotic spatial pattern
INTRODUCTION,0.024518388791593695,Rescaling values
INTRODUCTION,0.02626970227670753,Rescaling values
INTRODUCTION,0.028021015761821366,Spatial pattern unchanged
INTRODUCTION,0.0297723292469352,Spatial pattern unchanged
INTRODUCTION,0.03152364273204904,"Topological 
characterization"
INTRODUCTION,0.03327495621716287,High feature entropy
INTRODUCTION,0.03502626970227671,Rescaling
INTRODUCTION,0.03677758318739054,Invariant
INTRODUCTION,0.03852889667250438,"Figure 1: Comparisons between the effective units and ineffective units. For effective units, since
the spatial pattern of the features in the images would be preserved, units should stably present
this regularized spatial pattern. We propose a topological-based quantity called feature entropy to
indicate the unit status, giving reliable indication in various situations like rescaling the values."
INTRODUCTION,0.040280210157618214,"by high activation values in the units. And due to the locality nature in feature extraction by convo-
lution, this global spatial pattern between the common features would be preserved synchronously
in the counterpart representations in the effective units. In contrast, for ineffective units, being in-
capability of effectively representing these common features, representations would be in chaos and
marks of this pattern is vague. This provides a valid road for performance assessment of individual
units, and critically it is rescaling-invariant and universally applicable to any CNN architecture."
INTRODUCTION,0.04203152364273205,"The investigation of such pattern could naturally lead to topological approaches because knowl-
edge of topological data analysis such as barcodes (Ghrist, 2008) provides valuable tools to resolve
the intrinsic patterns in raw data. Along this line, ﬁrstly we introduce a method for characterizing
the spatial pattern of feature representations in units for a single sample by incorporating with the
topological tools, and then use information entropy to evaluate the stability of this spatial character-
izations for various images sampled from the same class, where we call it feature entropy. In this
way, a unit is judged to be effective if its feature entropy is high, otherwise ineffective."
INTRODUCTION,0.043782837127845885,"In our experiments, we ﬁnd that feature entropy would gradually decrease as the layer goes deeper
and the evolution trends of feature entropy and losses are almost the same during network training.
We show that the feature entropy could provide reliable indication of unit status in situations like
weight-rescaling and the emergence of random pattern. Finally, we show the value of feature entropy
in giving discrimination between networks with different generalization ability by investigating only
the training set."
RELATED WORKS,0.04553415061295972,"2
RELATED WORKS"
RELATED WORKS,0.047285464098073555,"One line of research that attracts many researchers is seeking solutions in a way of visualizing what
features have learned by the units (Zeiler & Fergus, 2014; Zhou et al., 2014; Mahendran & Vedaldi,
2015; Simonyan et al., 2013). Status is generally identiﬁed depending on the degree of alignment
between the visualized features and the human-visual concepts (Bau et al., 2017; Zhou et al., 2018a;
Bau et al., 2020). On the one hand, they meanwhile give excellent visual interpretation of each unit;
on the other hand, it hinders its universal application to arbitrary tasks and models in which units’
functionalities may be unrecognized to human (Wang et al., 2020)."
RELATED WORKS,0.04903677758318739,"Another related research trace lies in the ﬁeld of network pruning, where they concentrate on using
simple methods to roughly select less important units within a network. Typical approaches include
the L1-Norm of units (Luo et al., 2017), Average Percentage of Zeros (APoZ) in units (Hu et al.,
2016), some sparse-based methods (Li et al., 2019; Yoon & Hwang, 2017), and so on. Despite
commonly used in practice, since without a speciﬁc processing on units in diverse situations, they
are unable to provide a general indication for units in different networks."
RELATED WORKS,0.050788091068301226,"Besides, Morcos et al. (2018) introduce the class selectivity from neuroscience to investigate the
selectivity over classes for a speciﬁc unit, on the basis of calculating the mean units. Alain &
Bengio (2016) propose linear classiﬁer probe, where they report the degree of linear classiﬁcation
of units in intermediate layers could somehow characterize the status of units."
RELATED WORKS,0.05253940455341506,Published as a conference paper at ICLR 2022
RELATED WORKS,0.0542907180385289,"Lastly, we would like to discuss some recent works related to topological approaches in deep learn-
ing. Naitzat et al. (2020) demonstrate the superiority of using ReLu activation by studying the
changes in Betti numbers of a two-class neural network. Mont´ufar et al. (2020) use neural networks
to predict the persistent homology features. In Gabrielsson & Carlsson (2019), by using barcode,
they show the topological structure changes during training which correlates to the generalization
of networks. Rieck et al. (2018) propose the neural persistence, a topological complexity measure
of network structure that could give a criterion on early stopping. Guss & Salakhutdinov (2018)
empirically investigate the connection between neural network expressivity and the complexity of
dataset in topology. In Hofer et al. (2017), topological signatures of data are evaluated and used to
improve the classiﬁcation of shapes."
METHOD,0.05604203152364273,"3
METHOD"
METHOD,0.05779334500875657,"In general, input images for a network model are commonly resized to be square for processing. For
input image sample I of a given class with size n×n to be represented by a unit U with size m×m
via feature extraction processing f in CNN, we have,
f : I →U
(1)"
METHOD,0.0595446584938704,"For image I, features are speciﬁcally arranged, where each feature has an associated spatial location
in the image. After perceived by U, features are represented by high activation values at the corre-
sponding locations in the unit. Basically, there are two steps in our assessment of unit performance:
ﬁrstly, characterize the spatial pattern hidden in these high activation values in a unit for a single
image; secondly, evaluate the stability of this characterization when giving multiple image samples."
CHARACTERIZING THE SPATIAL PATTERN OF FEATURE REPRESENTATIONS IN A UNIT,0.06129597197898424,"3.1
CHARACTERIZING THE SPATIAL PATTERN OF FEATURE REPRESENTATIONS IN A UNIT"
CHARACTERIZING THE SPATIAL PATTERN OF FEATURE REPRESENTATIONS IN A UNIT,0.06304728546409807,"For Ui,j with a grid structure, the location of an element generally refers to its coordinate index
(i, j). And intuitively, the spatial pattern hidden in the elements denotes certain regular relationship
among their coordinate indices. So, it is natural to model such relationship with graph structure and
tackle it with topological tools in the following."
CHARACTERIZING THE SPATIAL PATTERN OF FEATURE REPRESENTATIONS IN A UNIT,0.0647985989492119,"Unit and graph
We use the edge-weighted graphs (Mehmet et al., 2019) as our basic model and
construct the weighted graph G = (V, E) from unit Ui,j, where V is the vertex set and E is the edge
set. Deﬁne the adjacency matrix A of G as follows,
A ∈Rm×m : Ai,j = Ui,j
(2)
It should be noted that the individual element of A is the weight of edge in G, which conveys the
intensity of corresponding point in the U."
CHARACTERIZING THE SPATIAL PATTERN OF FEATURE REPRESENTATIONS IN A UNIT,0.06654991243432574,"A family of undirected graphs G(v) with adjacency matrices A(v) could be constructed by following
the typical implementation of the sublevel set,"
CHARACTERIZING THE SPATIAL PATTERN OF FEATURE REPRESENTATIONS IN A UNIT,0.06830122591943957,"A(v)
i,j = 1Ai,j≥a(v)
(3)"
CHARACTERIZING THE SPATIAL PATTERN OF FEATURE REPRESENTATIONS IN A UNIT,0.07005253940455342,"where a(v) is the vth value in the descend ordering of elements of A and 1(·) is indicator function.
Here, we take the adjustment of A(v) = max(A(v), (A(v))T ) to ensure the adjacency matrices A(v)
of undirected graphs to be symmetric."
CHARACTERIZING THE SPATIAL PATTERN OF FEATURE REPRESENTATIONS IN A UNIT,0.07180385288966724,"So G(v) = (V (v), E(v)) is the subgraph of G where V (v) = V and E(v) ⊂E only includes the
edges whose weights are greater than or equal to a(v). We have the following graph ﬁltration,
G1 ⊂G2 ⊂G3 ⊂· · · ⊂G
(4)
To be more speciﬁcally, in this sublevel set ﬁltration, it starts with the vertex set, then rank the edge
weights from the maximum amax to minimum amin, and let the threshold parameters decrease from
amax to amin. At each step, we add the corresponding edges to obtain the threshold subgraph G(v)."
CHARACTERIZING THE SPATIAL PATTERN OF FEATURE REPRESENTATIONS IN A UNIT,0.07355516637478109,"Fig.2 illustrates the construction of certain subgraph through a toy example. Consider the unit Ui,j.
We circle the locations of the top 4 largest elements in Ui,j (Fig.2A). Then the nonzero elements
in adjacency matrix A(4), {(1, 2), (4, 3), (2, 4), (3, 1)} , is located (Fig.2B) and corresponding sub-
graph G(4) is constructed (Fig.2C)."
CHARACTERIZING THE SPATIAL PATTERN OF FEATURE REPRESENTATIONS IN A UNIT,0.07530647985989491,Published as a conference paper at ICLR 2022 A
CHARACTERIZING THE SPATIAL PATTERN OF FEATURE REPRESENTATIONS IN A UNIT,0.07705779334500876,"1.3
15
0.6
3.5
2.7
2.1
1.6
9.1
7
1.9
3.2
0.2
1.1
0.5
10.6
2.7"
CHARACTERIZING THE SPATIAL PATTERN OF FEATURE REPRESENTATIONS IN A UNIT,0.07880910683012259,"










 unit"
TH,0.08056042031523643,1th
TH,0.08231173380035026,2th
TH,0.0840630472854641,3th
TH,0.08581436077057793,4th
TH,0.08756567425569177,"adjacency matrix 3 4
1 2"
TH,0.0893169877408056,"column 1
2
3
4
row 1 2 3 4 (1,2) (2,4)"
TH,0.09106830122591944,"(4,3)
(3,1)"
TH,0.09281961471103327,"clique complex B
C 1 2 4"
D,0.09457092819614711,"3
D"
D,0.09632224168126094,"undirect graph
(4)
{(1,2),(4,3),(2,4),(3,1)}
A

U
(4)
(4)
(4)
(
,
)
G
V
E

(4)
"
D,0.09807355516637478,Figure 2: Example of the conversion from a unit to its clique complex.
D,0.09982486865148861,"Complex ﬁltration
To further reveal the correlation structure in the graphs, they are typically
converted into certain kinds of topological objects, where topological invariants are calculated for
capturing the high-level abstraction of correlation structure. Here, by following the common method
in (Horak et al., 2009; Giovanni et al., 2013), each graph G(v) is converted to simplicial complex
(also called clique complex) τ (v), as shown in Fig.2D. In this way, we have complex ﬁltration
corresponding to graph ﬁltration (Eq.4)."
D,0.10157618213660245,"τ (1) ⊂τ (2) ⊂τ (3) ⊂· · · ⊂τ
(5)"
D,0.10332749562171628,"This ﬁltration describes the evolution of correlation structure in graph G along with the decreasing
of threshold parameter. Fig.3A shows the complex ﬁltration of the previous example (Fig.2). 1"
A,0.10507880910683012,"2
A
3 4 1 2 3 4
1 2 3 4
1 2 B"
A,0.10683012259194395,"0
2
4
6"
A,0.1085814360770578,birth point
A,0.11033274956217162,"(1)

(2)

(4)

(6)
"
A,0.11208406304728546,Figure 3: Instance of complex ﬁltration (A) and Betti curve (B).
A,0.1138353765323993,"So far, we have completed the characterization from unit to the topological objects. Other than
our strategy, we also discuss other alternative method, which maps the unit to the cubical complex
(Kaczynski et al., 2004). See Appendix for more details."
A,0.11558669001751314,"Betti curve and its charaterization
Next, kth Betti number (Hatcher, 2002) of each element in
the complex ﬁltration could be calculated using the typical computational approach of persistent
homology (Ninna et al., 2017).
τ (v) 7→β(τ (v))
(6)"
A,0.11733800350262696,"Intuitively, kth Betti number β(τ (v)) could be regarded as the number of k-dimensional ’circle’s or
’hole’s or some higher order structures in complex τ (v). On the other hand, many meaningful pat-
terns in the unit would lead to the ’circle’s or ’hole’s of complexes in the ﬁltration (Eq.5), see Fig.2
for illustration. In particular, the number of ’hole’s is typically used as an important quantitative
index for featuring such patterns. Hence, the kth Betti numbers β(τ (v)), v ∈{1, · · · , n} could be
arranged into so called kth Betti curves β(U, v, k) for the unit U. Fig.3B shows the 1th Betti curve
of ﬁltration in Fig.3A."
A,0.1190893169877408,"Once having obtained the Betti curve, one needs to interpret the Betti curve and extract its core char-
acterization. Although there exists many choices of distance between two topological diagrams such
as persistence images (Adams et al., 2017), persistence landscape (Bubenik et al., 2015) and persis-
tence entropy(Ninna et al., 2017), we ﬁnd that the simple birth time of the Betti curves β(U, v, k) is
sufﬁcient in this characterization,"
A,0.12084063047285463,"b(U, k) = inf{v|β(U, v, k) ̸= 0}
(7)"
A,0.12259194395796848,Published as a conference paper at ICLR 2022
A,0.1243432574430823,"We call b(U, k) the birth time. Birth time is the indication of the critical element in complex ﬁltration
that begins to carry ”hole” structure (Betti number is nonzero). It is an important sign that some
essential change has occurred in complex ﬁltration, which implies the appearance of regularized
spatial pattern of notable components in the unit. Meanwhile, in some cases, no spatial pattern
appear in the components in the unit, so β(U, v, k) constantly equals to zero, meaning that birth
time doesn’t exist. In general, this would happen when the unit is unable to give representations for
the image, where its values are almost all zeros."
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.12609457092819615,"3.2
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY"
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.12784588441331,"For image samples in the same class C, an ideal unit U could perceive their common features. So,
the spatial pattern of this unit should be similar between different image samples. In other words,
the birth time obtained from each realization of units should be relatively close. That is to say, the
performance of good unit for certain target class should be stable over all the samples of this class.
It is the key idea for performance assessment of network unit."
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.1295971978984238,"Birth distribution
Essentially, birth time bC(i, U, k) is a random variable since sampling images
from the speciﬁc class C could be regarded as statistical experiments. In fact, the probability space
(Ω, Σ, P) could be constructed. The elements in sample space Ωare the unit U resulted from the
image samples in dataset of class C. Σ could be set as common discrete σ-ﬁeld and probability
measure P is uniformly distributed on Ω. In other words, every image sample has an equal chance
to be chosen as the input of network model. Afterwards, bC(i, U, k) is deﬁned as a random variable
on Ω(where the argument is i, and U and k are parameters),
bC(i, U, k)(·) : Ω→Z
(8)
with the probability distribution"
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.13134851138353765,"PC,U,k(x) = P(bC(i, U, k) = x) =
bx
#(Ω),
(9) where bx ="
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.1330998248686515,"#(Ω)
X"
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.13485113835376533,"j=1
1bC(i,U,k)=x
(10)"
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.13660245183887915,"Here the composite mapping bC(i, U, k)(·) from Ωto Z is composed of all the operation mentioned
above, including construct weighted graphs, building complex ﬁltration, calculating Betti curve and
extracting birth time."
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.138353765323993,"The degree of concentration of PC,U,k(x) gives a direct view about the performance of unit U on
class C, as illustrated in Fig.1. More speciﬁcally, if the distribution presents close to a degenerate-
like style, it means that the underlying common features of the class C could be stably perceived
by the unit U. On the contrary, the distribution presents close to a uniform-like style when features
are perceived almost blindly, indicating that unit U is invalid for C. In summary, the degree of
concentration of PC,U,k(x) is supposed to be an effective indicator of the performance of unit U."
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.14010507880910683,"Feature entropy
To further quantize the degree of concentration of birth distribution PC,U,k(x),
we introduce its entropy HC,U,k and call it feature entropy,"
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.14185639229422067,"HC,U,k = −
X"
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.1436077057793345,"x
PC,U,k(x) log PC,U,k(x)
(11)"
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.14535901926444833,"It should be noted that the birth time in Eq.7 may not exist for some input images in class C and
unit U. For unit U, the percentage of images in class C having birth times, termed as selective rate
ϵC,U, is also a crucial factor to the effectiveness of U on C. If the ϵC,U is too low, it indicates that
the unit could not perceive most of the image samples in this class. In this situation, extremely low
ϵC,U would cause the feature entropy approach to zero, but the unit should be judged as completely
invalid. Therefore, we rule out this extreme case by setting a threshold p and for completeness, and
assign the feature entropy associated with the maximum of feature entropy Ωfor the set of samples,"
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.14711033274956217,"HC,U,k =

HC,U,k
ϵC,U ≥p
(1 −ϵC,U) · log |Ω|
ϵC,U < p
(12)"
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.14886164623467601,"Here, p is prescribed as 0.1 in our computation."
ASSESSING THE UNIT PERFORMANCE USING FEATURE ENTROPY,0.15061295971978983,Published as a conference paper at ICLR 2022
EXPERIMENTS,0.15236427320490367,"4
EXPERIMENTS"
EXPERIMENTS,0.15411558669001751,"For experiments, we use the VGG16 network architecture to perform the image classiﬁcation task on
the ImageNet dataset. Unless otherwise stated, the exampled VGG16 model is trained from scratch
with the hyperparameters deployed in Simonyan & Zisserman (2014). For clarity, we only calculate
birth times bC(i, U, 1) based on 1th betti curve for all the units. Also, it should be noted that our
method focuses on the behaviors of feature extraction operations and has not utilized any kind of
particular nature of VGG network architecture, and all our investigation could be applicable to other
network architectures effortlessly."
CALCULATION FLOW,0.15586690017513136,"4.1
CALCULATION FLOW"
CALCULATION FLOW,0.15761821366024517,"0
10
20
30
40
0.00 0.05 0.10 0.15 0.20 0.25 0.30"
CALCULATION FLOW,0.159369527145359,unit 227
CALCULATION FLOW,0.16112084063047286,percentange
CALCULATION FLOW,0.1628721541155867,birth point
CALCULATION FLOW,0.1646234676007005,"input image
units
complex filtration"
CALCULATION FLOW,0.16637478108581435,"over all 
images"
CALCULATION FLOW,0.1681260945709282,"birth point
birth distribution
feature entropy … 1.87 … …"
CALCULATION FLOW,0.16987740805604204,feature entropy
CALCULATION FLOW,0.17162872154115585,"0
5
10
15
20"
CALCULATION FLOW,0.1733800350262697,"0
5
10
15
20"
CALCULATION FLOW,0.17513134851138354,"0
5
10
15
20"
CALCULATION FLOW,0.17688266199649738,selective rate 31%
CALCULATION FLOW,0.1786339754816112,Figure 4: Calculation ﬂow of feature entropy.
CALCULATION FLOW,0.18038528896672504,"As an example, the class partridge (wnid n01807496) in ImageNet is chosen for illustration. Here,
we sample 100 images from its training set as the image set for building the birth distribution.
Fig.4 shows the calculation ﬂow. It starts from extracting all the units for each image sample. By
characterizing the unit with graph model, each unit corresponds to a speciﬁc ﬁltration. Then, using
formular 7, we can obtain the birth time of each unit. In this way, the distribution of birth time could
be set up via Eq.9 over the sampled images. Fig.4 shows the histogram of the birth time distribution
for a speciﬁc unit in the the last convolution layer ”block5 conv3”. Likewise, the feature entropy
can be calculated via Eq.11 for all other units."
LAYER AND TRAINING ANALYSIS,0.18213660245183888,"4.2
LAYER AND TRAINING ANALYSIS"
LAYER AND TRAINING ANALYSIS,0.18388791593695272,"Layer analysis
Here, we check the status of units in each convolutional layer, where we average
the feature entropy across all the units within the layer to indicate the overall status of units in this
layer. Using the same image set in the previous section, Fig.5A(1-2) give comparisons of results
between the convergence model and the random-initialized model."
LAYER AND TRAINING ANALYSIS,0.18563922942206654,"In Fig.5A(1), we could clearly see that for the convergence model, the feature entropy continually
decrease as the layers go deeper. This is as expected because as the layer goes deeper, units are
considered to perceive more advanced features than previous layers, so the spatial pattern in these
features would be more signiﬁcant. As for the random-initialized model, since units are incapable to
perceive the common features, we could not observe a clear decrease of feature entropy, and mean-
while the feature entropy in every layer is higher than that in the convergence model. In Fig.5A(2),
we could also ﬁnd that each layer in the convergence model would present a higher selective rate
than the corresponding layer in the random-initialized model, except for the last convolutional layer
”block5 conv3”. Also, the selective rate of the last convolutional layer is much more lower than
other layers. The low feature entropy and fairly high selective rate indicate that comparing to units
in other layers, units at the last convolutional layer in the convergence model would present strong
specialization and exhibit the most effective representations of features to this class."
LAYER AND TRAINING ANALYSIS,0.18739054290718038,"Then, we randomly choose 100 classes in ImageNet and average the feature entropy across all these
classes on the convergence model. Fig.5A(3) shows the results. We could see that the results are
very similar to Fig.5A(1-2), which conﬁrms the fact further."
LAYER AND TRAINING ANALYSIS,0.18914185639229422,Published as a conference paper at ICLR 2022 B A
LAYER AND TRAINING ANALYSIS,0.19089316987740806,"0
10
20
30
40
0 1 2 3 4 5 6"
"TRAINING LOSS
 TRAINING ACCURACY",0.19264448336252188,"7
 training loss
 training accuracy epoch"
"TRAINING LOSS
 TRAINING ACCURACY",0.19439579684763572,training loss 0.0 0.2 0.4 0.6 0.8 1.0
"TRAINING LOSS
 TRAINING ACCURACY",0.19614711033274956,conv2_1
"TRAINING LOSS
 TRAINING ACCURACY",0.1978984238178634,conv2_2
"TRAINING LOSS
 TRAINING ACCURACY",0.19964973730297722,conv3_1
"TRAINING LOSS
 TRAINING ACCURACY",0.20140105078809106,conv3_2
"TRAINING LOSS
 TRAINING ACCURACY",0.2031523642732049,conv3_3
"TRAINING LOSS
 TRAINING ACCURACY",0.20490367775831875,conv4_1
"TRAINING LOSS
 TRAINING ACCURACY",0.20665499124343256,conv4_2
"TRAINING LOSS
 TRAINING ACCURACY",0.2084063047285464,conv4_3
"TRAINING LOSS
 TRAINING ACCURACY",0.21015761821366025,conv5_1
"TRAINING LOSS
 TRAINING ACCURACY",0.2119089316987741,conv5_2
"TRAINING LOSS
 TRAINING ACCURACY",0.2136602451838879,conv5_3 2.0 2.5 3.0 3.5 4.0
"TRAINING LOSS
 TRAINING ACCURACY",0.21541155866900175,feature entropy
"TRAINING LOSS
 TRAINING ACCURACY",0.2171628721541156,"Convergence model
 Random-initialized model"
"TRAINING LOSS
 TRAINING ACCURACY",0.21891418563922943,conv2_1
"TRAINING LOSS
 TRAINING ACCURACY",0.22066549912434325,conv2_2
"TRAINING LOSS
 TRAINING ACCURACY",0.2224168126094571,conv3_1
"TRAINING LOSS
 TRAINING ACCURACY",0.22416812609457093,conv3_2
"TRAINING LOSS
 TRAINING ACCURACY",0.22591943957968477,conv3_3
"TRAINING LOSS
 TRAINING ACCURACY",0.2276707530647986,conv4_1
"TRAINING LOSS
 TRAINING ACCURACY",0.22942206654991243,conv4_2
"TRAINING LOSS
 TRAINING ACCURACY",0.23117338003502627,conv4_3
"TRAINING LOSS
 TRAINING ACCURACY",0.2329246935201401,conv5_1
"TRAINING LOSS
 TRAINING ACCURACY",0.23467600700525393,conv5_2
"TRAINING LOSS
 TRAINING ACCURACY",0.23642732049036777,conv5_3 0.4 0.6 0.8 1.0
"TRAINING LOSS
 TRAINING ACCURACY",0.2381786339754816,selective rate
"TRAINING LOSS
 TRAINING ACCURACY",0.23992994746059546,"Convergence model
 Random-initialized model"
"TRAINING LOSS
 TRAINING ACCURACY",0.24168126094570927,conv2_1
"TRAINING LOSS
 TRAINING ACCURACY",0.2434325744308231,conv2_2
"TRAINING LOSS
 TRAINING ACCURACY",0.24518388791593695,conv3_1
"TRAINING LOSS
 TRAINING ACCURACY",0.2469352014010508,conv3_2
"TRAINING LOSS
 TRAINING ACCURACY",0.2486865148861646,conv3_3
"TRAINING LOSS
 TRAINING ACCURACY",0.2504378283712785,conv4_1
"TRAINING LOSS
 TRAINING ACCURACY",0.2521891418563923,conv4_2
"TRAINING LOSS
 TRAINING ACCURACY",0.2539404553415061,conv4_3
"TRAINING LOSS
 TRAINING ACCURACY",0.25569176882662,conv5_1
"TRAINING LOSS
 TRAINING ACCURACY",0.2574430823117338,conv5_2
"TRAINING LOSS
 TRAINING ACCURACY",0.2591943957968476,conv5_3 2.0 2.5 3.0 3.5 4.0
"TRAINING LOSS
 TRAINING ACCURACY",0.2609457092819615,feature entropy
"TRAINING LOSS
 TRAINING ACCURACY",0.2626970227670753,Average over 100 classes 0.4 0.6 0.8 1.0
"TRAINING LOSS
 TRAINING ACCURACY",0.26444833625218916,selective rate
"TRAINING LOSS
 TRAINING ACCURACY",0.266199649737303,"0
10
20
30
40
0 1 2 3 4 5 6 7 8"
"TRAINING LOSS
 TRAINING ACCURACY",0.2679509632224168,training loss epoch
"TRAINING LOSS
 TRAINING ACCURACY",0.26970227670753066,"training loss
 training accuracy 0.0 0.2 0.4 0.6 0.8 1.0"
"TRAINING LOSS
 TRAINING ACCURACY",0.2714535901926445,"0
10
20
30
40 2.0 2.5 3.0"
"TRAINING LOSS
 TRAINING ACCURACY",0.2732049036777583,feature entropy epoch 0.4 0.5 0.6 0.7
"TRAINING LOSS
 TRAINING ACCURACY",0.27495621716287216,selective rate
"TRAINING LOSS
 TRAINING ACCURACY",0.276707530647986,"0
10
20
30
40 2.0 2.5 3.0"
"TRAINING LOSS
 TRAINING ACCURACY",0.27845884413309985,feature entropy epoch 0.4 0.5 0.6 0.7
"TRAINING LOSS
 TRAINING ACCURACY",0.28021015761821366,selective rate
"TRAINING LOSS
 TRAINING ACCURACY",0.2819614711033275,"(1)
(2)
(3)"
"TRAINING LOSS
 TRAINING ACCURACY",0.28371278458844135,"(1)
(2)
(3)
(4)"
"TRAINING LOSS
 TRAINING ACCURACY",0.28546409807355516,"Figure 5: (A) Comparisons of feature entropy (1) and selective rate (2) of different layers between
the convergence model and random-initialized model, where (3) shows the results over 100 classes.
(B) Simultaneous evolution of training loss and feature entropy during training for the chosen class
(1-2) and for the 100 classes (3-4)."
"TRAINING LOSS
 TRAINING ACCURACY",0.287215411558669,"Training analysis
Then, we investigate the variation of feature entropy of the last convolutional
layer during training. Fig.5B(1-2) show the results on the same example class used previously, and
Fig.5B(3-4) show the results across 100 classes chosen previously. In both situations, we could ﬁnd
that the feature entropy would decrease during training, indicating that units are gradually learned
to be able to perceive the common features in the class. And remarkably, the decreasing pattern
of feature entropy and that of training cross-entropy loss coincide approximately. Both of them
experience a comparable big drop in the ﬁrst epoch and gradually down to the convergence level.
This means that feature entropy is a valid indicator of network performance."
INDICATOR OF STATUS OF NETWORK UNIT,0.28896672504378285,"4.3
INDICATOR OF STATUS OF NETWORK UNIT"
INDICATOR OF STATUS OF NETWORK UNIT,0.29071803852889666,"To investigate the ability of feature entropy as indicator of unit status, we make comparisons with
some commonly-used analogous network indicators including L1-norm (Li et al., 2016), APoZ (He
et al., 2017b), and a more generalized form of class selectivity used in Zhou et al. (2018b). Here,
the unit and the image set in the previous subsection are still used in the following demonstration."
INDICATOR OF STATUS OF NETWORK UNIT,0.29246935201401053,"Rescaling investigation
The comparison is implemented by rescaling the magnitude of values to
half for all the input images or all the CNN ﬁlters connecting to the layer. Both the two implemen-
tations could potentially cause the values in units within the layer vary with the same scale, but in
general have no substantial impact on the network performance and the function of each unit. In
other words, units should be indicated as almost the same with or without such implementation."
INDICATOR OF STATUS OF NETWORK UNIT,0.29422066549912435,"Table 1: Comparisons of unit status by rescaling the values in images or CNN ﬁlters
Images
CNN ﬁlters
Accuracy
L1-norm
APoZ
Class selectivity
Feature entropy"
INDICATOR OF STATUS OF NETWORK UNIT,0.29597197898423816,"

0.83
29.5
17.14%
0.58
1.87
Half scale

0.81
14.7
17.15%
0.31
1.90

Half scale
0.83
14.6
17.14%
0.30
1.87
Half scale
Half scale
0.79
7.2
17.16%
0.03
1.92"
INDICATOR OF STATUS OF NETWORK UNIT,0.29772329246935203,"Table 1 shows the results where  denotes no rescaling operation for the item. As half scaling the
magnitude in input images or units, the performance of the model ﬂuctuates slightly. We could ﬁnd
that APoZ and feature entropy vary in the similar way with the performance, but L1-norm and class
selectivity vary terribly. Apparently, despite little effect for the network, rescaling operations would
have a major impact on these magnitude-based indicators, like L1-norm and class selectivity. These
indicators fail to give accurate and stable measure of unit status especially when facing images or
units with different value scales."
INDICATOR OF STATUS OF NETWORK UNIT,0.29947460595446584,Published as a conference paper at ICLR 2022
INDICATOR OF STATUS OF NETWORK UNIT,0.30122591943957966,Table 2: Comparisons of unit status with respect to well-trained units and random units
INDICATOR OF STATUS OF NETWORK UNIT,0.30297723292469353,"L1-norm
APoZ
Class selectivity
Feature entropy"
INDICATOR OF STATUS OF NETWORK UNIT,0.30472854640980734,"Well-trained unit
29.5
17.14%
0.58
1.87
Random initialized units
32.2(30.9)
41%(40%)
0.01(0.003)
2.87(0.21), 0.83(0.22)"
INDICATOR OF STATUS OF NETWORK UNIT,0.3064798598949212,"Detecting randomness in units
Next, we compare the status of this unit with random units (units
yielded by random-initialized models). Table 2 presents the results. The random units are sampled
100 times and the presented results are averaged over the 100 samples where the value in the brackets
denotes the standard deviation. Since random units are clearly incapable to perceive features well
like those trained units, they are expected to be indicated as ineffective units. We could see that when
using L1-norm and APoZ indicators, they are impossible to give a stable indication as the standard
deviation is extremely large. In some samples, the random units are judged as much ”better” than
the trained units, which is obviously incorrect. Accordingly, it could be also misleading using APoZ
as the indicator of unit status. In contrast, the feature entropy would consistently be very high when
random pattern exists in the unit, providing a well discrimination between trained units and random
ones."
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.30823117338003503,"4.4
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.30998248686514884,"In general, due to the large hypothesis space, CNNs could converge to a variety of minima on the
dataset. Since feature entropy could reliably indicate the status of network units, it is natural to use
it to discriminate which minima could provide more effective feature representations."
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3117338003502627,"Models
In this subsection, we prepare two sets of VGG16 models. Model set A consists of four
models trained from scratch with different hyperparameters on ImageNet dataset, and Model set B
consists of ﬁve models trained from scratch to almost zero training error with the same hyperparam-
eters but on ImageNet dataset with different fractions of randomly corrupted labels as introduced in
Zhang et al. (2017). Table 3 and 4 separately show the performance of models in the two model sets.
In model set B, we use Model AD in Model set A as the ﬁrst model Model BA with no corruption
rate. Besides, it should be noted that all the calculation in this section is based on the image sampled
from the training dataset."
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3134851138353765,Table 3: Model set A
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.31523642732049034,"Train Acc
Test Acc"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3169877408056042,"Model AA
0.732
0.657
Model AB
0.818
0.532
Model AC
0.828
0.444
Model AD
0.996
0.378"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.318739054290718,"Table 4: Model set B
Train Acc
Test Acc
Corrupted"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3204903677758319,"Model BA
0.996
0.378
0.0
Model BB
0.992
0.297
0.2
Model BC
0.994
0.166
0.4
Model BD
0.992
0.074
0.6
Model BE
0.993
0.010
0.8"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3222416812609457,"Model set A
Using the same image set in previous section, we start by investigating the feature
entropy of units at different layers in the four models. Here, we still use the averaged feature entropy
across all the units within a layer to indicate the overall level of how well the units in this layer could
perceive the features. Fig.6A(1-2) shows the results of this class. We could see in the ﬁgure that there
would not be signiﬁcant difference of feature entropy between these models in layers except for the
last convolutional layer. And in the last convolutional layer, for models with better generalization,
their feature entropy would be lower than those with poor generalization, indicating that they would
provide more effective feature representations. Besides, as for the selective rate, the four models are
quite close."
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3239929947460595,"Then, we randomly choose 100 classes in the ImageNet dataset and calculate the feature entropy
of the units in the last convolutional layer. Fig.6A(3) presents the scatter plot for the four models,
where each point stands for the feature entropy and selective rate of a speciﬁc class. For each model,
its points locate at an area separately from other models, giving a discrimination between models.
Also similarly, models with better generalization have points with lower feature entropy."
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3257443082311734,Published as a conference paper at ICLR 2022
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3274956217162872,"2.5
3.0
3.5
4.0
4.5
0.0 0.1 0.2 0.3 0.4"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.329246935201401,"Model BA
 Model BB
 Model BC
 Model BD
 Model BE"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3309982486865149,selective rate
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3327495621716287,feature entropy
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3345008756567426,conv3_1
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3362521891418564,conv3_2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3380035026269702,conv3_3
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3397548161120841,conv4_1
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3415061295971979,conv4_2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3432574430823117,conv4_3
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3450087565674256,conv5_1
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3467600700525394,conv5_2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.34851138353765326,conv5_3 0.0 0.2 0.4 0.6 0.8 1.0
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3502626970227671,selective rate
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3520140105078809,"Model BA
 Model BB
 Model BC
 Model BD
 Model BE"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.35376532399299476,"1.8
2.0
2.2
2.4
2.6
0.2 0.3 0.4 0.5"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3555166374781086,"Model AA
 Model AB
 Model AC
 Model AD"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3572679509632224,selective rate
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.35901926444833626,feature entropy
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3607705779334501,conv3_1
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.36252189141856395,conv3_2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.36427320490367776,conv3_3
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3660245183887916,conv4_1
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.36777583187390545,conv4_2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.36952714535901926,conv4_3
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3712784588441331,conv5_1
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.37302977232924694,conv5_2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.37478108581436076,conv5_3 0.2 0.4 0.6 0.8 1.0 1.2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.37653239929947463,selective rate
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.37828371278458844,"Model AA
 Model AB
 Model AC
 Model AD"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.38003502626970226,conv3_1
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.38178633975481613,conv3_2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.38353765323992994,conv3_3
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.38528896672504376,conv4_1
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.38704028021015763,conv4_2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.38879159369527144,conv4_3
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3905429071803853,conv5_1
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3922942206654991,conv5_2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.39404553415061294,conv5_3 2.0 2.5 3.0 3.5
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3957968476357268,feature entropy
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.3975481611208406,"Model AA
 Model AB
 Model AC
 Model AD A B"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.39929947460595444,"(1)
(2)
(3)"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.4010507880910683,"(1)
(2)
(3)"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.4028021015761821,conv3_1
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.404553415061296,conv3_2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.4063047285464098,conv3_3
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.4080560420315236,conv4_1
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.4098073555166375,conv4_2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.4115586690017513,conv4_3
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.4133099824868651,conv5_1
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.415061295971979,conv5_2
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.4168126094570928,conv5_3 2.0 2.5 3.0 3.5 4.0 4.5 5.0
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.4185639229422067,feature entropy
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.4203152364273205,"Model BA
 Model BB
 Model BC
 Model BD
 Model BE"
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.4220665499124343,"Figure 6: Comparisons between models in separately model set A (A) and model set B (B). Com-
pare the feature entropy (1) and selective rate (2) of units at different layers between models in the
corresponding model set on the exampled class. (3) shows the scatter plot between feature entropy
and selective rate of units at the last convolutional layer on the 100 sampled classes."
USING FEATURE ENTROPY TO INDICATE NETWORKS WITH DIFFERENT GENERALIZATION,0.4238178633975482,"Model set B
For model set B, we use the same implementation as applied previously in the model
set A, where the results are shown in Fig.6B. Comparing to the Model set A, since using the partially
corrupted labels, units in the Model Set B are unable to perceive the common features between
samples in the same class, which causes that the selective rate of most units are extremely low as
shown in Fig.6B(2). Due to such low selective rate, we could also ﬁnd in Fig.6B(1) that feature
entropy of the units in the last convolutional layer may abruptly reach to a very high point. The
more fraction the labels are corrupted, the higher feature entropy the units are and in the meantime
the lower the selective rate the units are. This could be observed as well in Fig.6B(3) where the 100
classes are used for calculation."
CONCLUSION,0.425569176882662,"5
CONCLUSION"
CONCLUSION,0.4273204903677758,"We propose a novel method that could give quantitative identiﬁcation of individual unit status, called
feature entropy, for a speciﬁc class using algebraic topological tools. We show that feature entropy
is a reliable indicator of unit status that could well cope with various cases such as rescaling values
or existence of randomness. Also we show that feature entropy behaves in the similar way as loss
during the training stage and presents a descending trend as convolutional layers go deeper. Using
feature entropy, we show that CNNs with different generalization could be discriminated by the
effectiveness of feature representations of the units in the last convolutional layer. We suppose this
would be helpful for further understanding the mechanism of convolutional neural networks."
CONCLUSION,0.4290718038528897,ACKNOWLEDGMENTS
CONCLUSION,0.4308231173380035,"We would like to thank Brain-Inspired Research Team at Tsinghua University for the discussions.
We would like to thank the reviewers for their helpful comments."
REFERENCES,0.43257443082311736,REFERENCES
REFERENCES,0.4343257443082312,"Henry Adams, Tegan Emerson, Michael Kirby, Rachel Neville, Chris Peterson, Patrick Shipman,
Sofya Chepushtanova, Eric Hanson, Francis Motta, and Lori Ziegelmeier. Persistence images: A"
REFERENCES,0.436077057793345,Published as a conference paper at ICLR 2022
REFERENCES,0.43782837127845886,"stable vector representation of persistent homology. Journal of Machine Learning Research, 18,
2017."
REFERENCES,0.4395796847635727,"Guillaume Alain and Yoshua Bengio.
Understanding intermediate layers using linear classiﬁer
probes. arXiv preprint arXiv:1610.01644, 2016."
REFERENCES,0.4413309982486865,"David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba. Network dissection:
Quantifying interpretability of deep visual representations. In Proceedings of the IEEE conference
on computer vision and pattern recognition, pp. 6541–6549, 2017."
REFERENCES,0.44308231173380036,"David Bau, Jun-Yan Zhu, Hendrik Strobelt, Agata Lapedriza, Bolei Zhou, and Antonio Torralba.
Understanding the role of individual units in a deep neural network. Proceedings of the National
Academy of Sciences, 117(48):30071–30078, 2020."
REFERENCES,0.4448336252189142,"Kay Henning Brodersen, Cheng Soon Ong, Klaas Enno Stephan, and Joachim M. Buhmann. The
balanced accuracy and its posterior distribution. 2010 20th International Conference on Pattern
Recognition, pp. 3121–3124, 2010."
REFERENCES,0.44658493870402804,"Peter Bubenik et al. Statistical topological data analysis using persistence landscapes. J. Mach.
Learn. Res., 16(1):77–102, 2015."
REFERENCES,0.44833625218914186,"Rickard Br¨uel Gabrielsson and Gunnar Carlsson. Exposition and interpretation of the topology
of neural networks. In 2019 18th IEEE International Conference On Machine Learning And
Applications (ICMLA), pp. 1069–1076. IEEE, 2019."
REFERENCES,0.4500875656742557,"Robert Ghrist. Barcodes: the persistent topology of data. Bulletin of the American Mathematical
Society, 45(1):61–75, 2008."
REFERENCES,0.45183887915936954,"Petri Giovanni, Scolamiero Martina, Donato Irene, and Vaccarino Francesco. Topological strata of
weighted complex networks. PLOS ONE, 8(6):1–9, 2013."
REFERENCES,0.45359019264448336,"William H Guss and Ruslan Salakhutdinov. On characterizing the capacity of neural networks using
algebraic topology. arXiv preprint arXiv:1802.04443, 2018."
REFERENCES,0.4553415061295972,"Hatcher. Algebraic Topology. Cambridge University Press, London, 2002."
REFERENCES,0.45709281961471104,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image
recognition.
In 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR
2016, Las Vegas, NV, USA, June 27-30, 2016, pp. 770–778. IEEE Computer Society, 2016. doi:
10.1109/CVPR.2016.90."
REFERENCES,0.45884413309982486,"Kaiming He, Georgia Gkioxari, Piotr Doll´ar, and Ross B. Girshick. Mask R-CNN. In IEEE In-
ternational Conference on Computer Vision, ICCV 2017, Venice, Italy, October 22-29, 2017, pp.
2980–2988. IEEE Computer Society, 2017a. doi: 10.1109/ICCV.2017.322."
REFERENCES,0.46059544658493873,"Yang He, Ping Liu, Ziwei Wang, Zhilan Hu, and Yi Yang. Filter pruning via geometric median for
deep convolutional neural networks acceleration. In Conference on Computer Vision and Pattern
Recognition, pp. 4340–4349, 2019."
REFERENCES,0.46234676007005254,"Yihui He, Xiangyu Zhang, and Jian Sun. Channel pruning for accelerating very deep neural net-
works. In Proceedings of the IEEE International Conference on Computer Vision, pp. 1389–1397,
2017b."
REFERENCES,0.46409807355516636,"Christoph Hofer, Roland Kwitt, Marc Niethammer, and Andreas Uhl. Deep learning with topologi-
cal signatures. In Advances in neural information processing systems, pp. 1634–1644, 2017."
REFERENCES,0.4658493870402802,"Danijela Horak, Slobodan Maleti´c, and Milan Rajkovi´c. Persistent homology of complex networks.
Journal of Statistical Mechanics: Theory and Experiment, 2009(03):P03034, 2009."
REFERENCES,0.46760070052539404,"Hengyuan Hu, Rui Peng, Yu-Wing Tai, and Chi-Keung Tang. Network trimming: A data-driven
neuron pruning approach towards efﬁcient deep architectures. arXiv preprint arXiv:1607.03250,
2016."
REFERENCES,0.46935201401050786,"Tomasz Kaczynski, Konstantin Michael Mischaikow, and Marian Mrozek. Computational homol-
ogy, volume 3. Springer, 2004."
REFERENCES,0.4711033274956217,Published as a conference paper at ICLR 2022
REFERENCES,0.47285464098073554,"Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning ﬁlters for
efﬁcient convnets. In Iternational Conference on Learning Representations, 2016."
REFERENCES,0.4746059544658494,"Yuchao Li, Shaohui Lin, Baochang Zhang, Jianzhuang Liu, David Doermann, Yongjian Wu, Feiyue
Huang, and Rongrong Ji. Exploiting kernel sparsity and entropy for interpretable cnn compres-
sion. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.
2800–2809, 2019."
REFERENCES,0.4763572679509632,"Jian-Hao Luo, Jianxin Wu, and Weiyao Lin. Thinet: A ﬁlter level pruning method for deep neural
network compression. In Proceedings of the IEEE international conference on computer vision,
pp. 5058–5066, 2017."
REFERENCES,0.47810858143607704,"Aravindh Mahendran and Andrea Vedaldi. Understanding deep image representations by inverting
them. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
5188–5196, 2015."
REFERENCES,0.4798598949211909,"Aktas Mehmet, Akbas Esra, and El Fatmaoui Ahmed. Persistence homology of networks: methods
and applications. Applied Network Science, 4(61):1–28, 2019."
REFERENCES,0.4816112084063047,"Guido Mont´ufar, Nina Otter, and Yuguang Wang. Can neural networks learn persistent homology
features? arXiv preprint arXiv:2011.14688, 2020."
REFERENCES,0.48336252189141854,"Ari S Morcos, David GT Barrett, Neil C Rabinowitz, and Matthew Botvinick. On the importance
of single directions for generalization. In Iternational Conference on Learning Representations,
2018."
REFERENCES,0.4851138353765324,"Gregory Naitzat, Andrey Zhitnikov, and Lek-Heng Lim. Topology of deep neural networks. arXiv
preprint arXiv:2004.06093, 2020."
REFERENCES,0.4868651488616462,"Behnam Neyshabur, Ruslan Salakhutdinov, and Nathan Srebro. Path-sgd: Path-normalized opti-
mization in deep neural networks. In Advances in Neural Information Processing, pp. 2422–2430,
2015."
REFERENCES,0.4886164623467601,"Otter Ninna, A Porter Mason, Tillmann Ulrick, Grindrod Peter, and A Harrington Heather.
A
roadmap for the computation of persistent homology. EPJ Data Science, 6(17):1–38, 2017."
REFERENCES,0.4903677758318739,"Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only look once: Uniﬁed,
real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pp. 779–788, 2016."
REFERENCES,0.4921190893169877,"Bastian Rieck, Matteo Togninalli, Christian Bock, Michael Moor, Max Horn, Thomas Gumbsch,
and Karsten Borgwardt. Neural persistence: A complexity measure for deep neural networks
using algebraic topology. arXiv preprint arXiv:1812.09764, 2018."
REFERENCES,0.4938704028021016,"Giorgio Roffo, Simone Melzi, and Marco Cristani. Inﬁnite feature selection. In International Con-
ference on Computer Vision, pp. 4202–4210, 2015. doi: 10.1109/ICCV.2015.478."
REFERENCES,0.4956217162872154,"Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556, 2014."
REFERENCES,0.4973730297723292,"Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Deep inside convolutional networks: Vi-
sualising image classiﬁcation models and saliency maps. arXiv preprint arXiv:1312.6034, 2013."
REFERENCES,0.4991243432574431,"Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Re-
thinking the inception architecture for computer vision. In 2016 IEEE Conference on Computer
Vision and Pattern Recognition, CVPR, pp. 2818–2826. IEEE Computer Society, 2016."
REFERENCES,0.500875656742557,"Haohan Wang, Xindi Wu, Zeyi Huang, and Eric P Xing. High-frequency component helps explain
the generalization of convolutional neural networks. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pp. 8684–8694, 2020."
REFERENCES,0.5026269702276708,"Jaehong Yoon and Sung Ju Hwang. Combined group and exclusive sparsity for deep neural net-
works. In International Conference on Machine Learning, pp. 3958–3966, 2017."
REFERENCES,0.5043782837127846,Published as a conference paper at ICLR 2022
REFERENCES,0.5061295971978984,"Ruichi Yu, Ang Li, Chun-Fu Chen, Jui-Hsin Lai, Vlad I. Morariu, Xintong Han, Mingfei Gao,
Ching-Yung Lin, and Larry S. Davis. NISP: pruning networks using neuron importance score
propagation. In 2018 Conference on Computer Vision and Pattern Recognition,, pp. 9194–9203,
2018. doi: 10.1109/CVPR.2018.00958."
REFERENCES,0.5078809106830122,"Matthew D Zeiler and Rob Fergus.
Visualizing and understanding convolutional networks.
In
European conference on computer vision, pp. 818–833. Springer, 2014."
REFERENCES,0.5096322241681261,"Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. In 5th International Conference on Learning
Representations, ICLR 2017, Toulon, France, April 24-26, 2017, 2017."
REFERENCES,0.51138353765324,"Quanshi Zhang, Ying Nian Wu, and Song-Chun Zhu. Interpretable convolutional neural networks.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 8827–
8836, 2018."
REFERENCES,0.5131348511383538,"Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Object detectors
emerge in deep scene cnns. arXiv preprint arXiv:1412.6856, 2014."
REFERENCES,0.5148861646234676,"Bolei Zhou, David Bau, Aude Oliva, and Antonio Torralba. Interpreting deep visual representations
via network dissection. IEEE transactions on pattern analysis and machine intelligence, 41(9):
2131–2145, 2018a."
REFERENCES,0.5166374781085814,"Bolei Zhou, Yiyou Sun, David Bau, and Antonio Torralba. Revisiting the importance of individual
units in cnns via ablation. arXiv preprint arXiv:1806.02891, 2018b."
REFERENCES,0.5183887915936952,"A
APPENDIX"
REFERENCES,0.5201401050788091,"A.1
IMPLEMENTATION DETAILS OF MODELS"
REFERENCES,0.521891418563923,"In our experiments, the networks we used are the standard VGG16 architecture. We simply resize
all the mentioned sample images to 224×224 without implementing any data augment (like random
crop) during all the experiments (including the feature entropy calculation and the reported perfor-
mance). The model used for demonstration in the experiment section (besides the last subsection) is
Model AA in model set A."
REFERENCES,0.5236427320490368,"For model set A, we use the following implementations,"
REFERENCES,0.5253940455341506,"• Model AA. The hyper-parameters are the same with them in the paper (Simonyan & Zis-
serman, 2014).
• Model AB. The hyper-parameters are the same with them in Model AA, except for chang-
ing the momentum to 0 and without using the data augmentation strategy.
• Model AC. The hyper-parameters are the same with them in Model AB, except for that
only the ﬁrst fully connected layer use the dropout with the rate of 0.3.
• Model AD. None of the conventional training enhancement technique is applied. Basically,
It is Model AC without using dropout and l2 regularization."
REFERENCES,0.5271453590192644,"For model set B, we use the following implementations,"
REFERENCES,0.5288966725043783,"• Model BA. It is actually the Model AD.
• Model BB. The hyper-parameters are the same with them in Model BA, except for corrupt-
ing the labels with 0.2 fraction.
• Model BC. The hyper-parameters are the same with them in Model BA, except for corrupt-
ing the labels with 0.4 fraction.
• Model BD. The hyper-parameters are the same with them in Model BA, except for corrupt-
ing the labels with 0.6 fraction.
• Model BE. The hyper-parameters are the same with them in Model BA, except for corrupt-
ing the labels with 0.8 fraction."
REFERENCES,0.5306479859894921,Published as a conference paper at ICLR 2022
REFERENCES,0.532399299474606,"A.2
SPATIAL CHARACTERIZATION USING CUBICAL COMPLEX"
REFERENCES,0.5341506129597198,"In our method, a unit is ﬁrstly convert to a set of graphs and then each graph could be converted
to the corresponding clique complex. In this way, a unit is characterized by the ﬁltration of clique
complexes. Alternatively, the unit could be directly modeled as a cubical complex (Kaczynski et al.,
2004), and then use the similar sublevel set implementation to acquire the ﬁltration of cubical com-
plexes. So here, we use cubical complex instead of clique complex and meanwhile keep the rest of
the methods unchanged."
REFERENCES,0.5359019264448336,"By investigating the birth distribution on the classes in the Imagenet with Model AA, we found that
for every unit especially at relatively deeper layers, almost 95% images would have no birth time. In
other words, no persistence homology emerges for almost all the units when using cubical complex.
Thus, it is impossible to give a further calculation of the stability for images in the same class."
REFERENCES,0.5376532399299475,"A.3
DISCUSSIONS OF USING BIRTH TIME"
REFERENCES,0.5394045534150613,"When characterizing the ﬁltration of topological complexes, we use the birth time of the ﬁltration.
Comparing to some other characterizations, we suppose that the advantages of using birth time may
lie in,"
REFERENCES,0.5411558669001751,"• Birth time is very easy to compute. In practice, when using birth time, it is not necessary to
go through the whole ﬁltration process, where we could stop the calculation when the birth
time emerges. In this way, we could largely save the computation especially when the size
of units is very high. This could be very helpful for calculating the large amount of units in
neural networks.
• Birth time is very convenient for the investigation of stability between samples because it
is an integer essentially. So, the discrete distribution could be set up effortlessly. Besides,
when using entropy to investigate the stability of birth times, the results are bounded strictly
in the range from 0 to log N.
• Birth time is suitable for the idea. Since the signiﬁcant features are generally represented
by the high activation values in the units, it is more expected that the regularized pattern
could be formed by these values. So it is natural to focus on these high activation values,
which leads to the use of birth time."
REFERENCES,0.542907180385289,"Then, considering the various topological features, we compare the effect of using birth time and
two other characterizations of the Betti curves which are its maximum value and its integration.
During calculation, we would only change birth time to the use of given characterization, where all
the other parts remain the same. Table 5 shows the results. We ﬁnd that the difference between using
birth time and using other characterization are acceptable. But when using other characterizations,
we need to calculate the whole Betti curve. The computation cost may be hundreds times than using
birth time."
REFERENCES,0.5446584938704028,Table 5: Comparisons of feature entropy by using different characterizations
REFERENCES,0.5464098073555166,"Birth time
Maximum
Integration"
REFERENCES,0.5481611208406305,"Reference unit
1.87
1.89
1.92
Last convolutional layer
2.01
2.09
2.11
Last convolutional layer (100 classes)
2.07
2.13
2.17"
REFERENCES,0.5499124343257443,"A.4
STUDY ON SAMPLE SIZE"
REFERENCES,0.5516637478108581,"For an efﬁcient computation in practice, we could use part of the training set for calculating the
feature entropy. In this section, we check the inﬂuence on the feature entropy when using different
sample sizes."
REFERENCES,0.553415061295972,"We test the sample size from the 50 to the full size of of the example class (about 1300 images) in the
training set on the reference model (Model AA) used in the paper. We ﬁrst investigate the variation
of feature entropy of a single unit when changing the sample size. We performed 100 times of"
REFERENCES,0.5551663747810858,Published as a conference paper at ICLR 2022
REFERENCES,0.5569176882661997,"sampling to investigate the stability of feature entropy, and each time randomly sample 500, 100
and 50 images from the training set. Fig.7 shows the histogram of feature entropy of the unit used
in Section 4.1 for the 100 times of sampling, where the x-axis is feature entropy and y-axis is the
frequency. We could see that for 500 and 100 samples, their feature entropy distribute closely to the
value of feature entropy for using the whole training set. However, as for 50 samples, the feature
entropy distribute scatteredly. Therefore, using 100 samples could give considerable feature entropy
of the class and in the meantime largely reduce the computation cost."
REFERENCES,0.5586690017513135,"1.8
1.9
2.0
0.00 0.05 0.10 0.15 0.20 0.25 0.30"
SAMPLES,0.5604203152364273,500 samples
SAMPLES,0.5621716287215411,percentange
SAMPLES,0.563922942206655,feature entropy
SAMPLES,0.5656742556917689,"1.8
1.9
2.0
0.00 0.05 0.10 0.15 0.20 0.25"
SAMPLES,0.5674255691768827,100 samples
SAMPLES,0.5691768826619965,percentange
SAMPLES,0.5709281961471103,feature entropy
SAMPLES,0.5726795096322241,"1.8
1.9
2.0
0.00 0.05 0.10 0.15"
SAMPLES,0.574430823117338,"0.20
 50 samples"
SAMPLES,0.5761821366024519,percentange
SAMPLES,0.5779334500875657,feature entropy
SAMPLES,0.5796847635726795,"1.8
1.9
2.0
0.0 0.2 0.4 0.6 0.8"
SAMPLES,0.5814360770577933,"1.0
 1300 samples"
SAMPLES,0.5831873905429071,percentange
SAMPLES,0.5849387040280211,feature entropy
SAMPLES,0.5866900175131349,Figure 7: Histogram of the feature entropy in 100 trials for different sample size.
SAMPLES,0.5884413309982487,"1.5
2.0
2.5
3.0
0.00 0.05 0.10"
SAMPLES,0.5901926444833625,percentange
SAMPLES,0.5919439579684763,feature entropy
SAMPLES,0.5936952714535902,500 samples
SAMPLES,0.5954465849387041,"1.5
2.0
2.5
3.0
0.00 0.05 0.10"
SAMPLES,0.5971978984238179,percentange
SAMPLES,0.5989492119089317,feature entropy
SAMPLES,0.6007005253940455,100 samples
SAMPLES,0.6024518388791593,"1.5
2.0
2.5
3.0
0.00 0.05 0.10"
SAMPLES,0.6042031523642732,percentange
SAMPLES,0.6059544658493871,feature entropy
SAMPLES,0.6077057793345009,1300 samples
SAMPLES,0.6094570928196147,"1.5
2.0
2.5
3.0
0.00 0.05 0.10 0.15 0.20"
SAMPLES,0.6112084063047285,percentange
SAMPLES,0.6129597197898424,feature entropy
SAMPLES,0.6147110332749562,1300 samples
SAMPLES,0.6164623467600701,"1.5
2.0
2.5
3.0
0.00 0.05 0.10 0.15 0.20"
SAMPLES,0.6182136602451839,percentange
SAMPLES,0.6199649737302977,feature entropy
SAMPLES,0.6217162872154116,500 samples
SAMPLES,0.6234676007005254,"0
400
800
1200 2.2 2.4 2.6"
SAMPLES,0.6252189141856392,feature entropy
SAMPLES,0.626970227670753,sample number
SAMPLES,0.6287215411558669,averaged feature entropy
SAMPLES,0.6304728546409807,Layer  block5_conv3
SAMPLES,0.6322241681260946,Layer  block5_conv2
SAMPLES,0.6339754816112084,"1.5
2.0
2.5
3.0
0.00 0.05 0.10 0.15 0.20"
SAMPLES,0.6357267950963222,percentange
SAMPLES,0.637478108581436,feature entropy
SAMPLES,0.6392294220665499,100 samples
SAMPLES,0.6409807355516638,"0
400
800
1200
1.8 2.0 2.2"
SAMPLES,0.6427320490367776,feature entropy
SAMPLES,0.6444833625218914,sample number
SAMPLES,0.6462346760070052,averaged feature entropy
SAMPLES,0.647985989492119,"(1)
(2)
(3)
(4)"
SAMPLES,0.649737302977233,"Figure 8:
(1-3) Histogram of the feature entropy of units in the layer ”block5 conv3” and
”block5 conv2” for different sample size.(4) Feature entropy averaged across all the units in the
layer with respect to the sample size. Error bars stand for performing the sampling 100 times."
SAMPLES,0.6514886164623468,"Next, we investigate the feature entropy of all the units at a layer when changing the sample size.
All the units at the layer ”block5 conv3” and ”block5 conv2” in the reference model are used, and
Fig.2A presents the results. As we could see in Fig.8(1-3), for 1300, 500 and 100 samples, their
distributions of feature entropy of the 512 units at the layer are very close. And in Fig.8(4), we
average the feature entropy across the 512 units, and we could see that the feature entropy vary
slightly from using 100 samples to 1300 samples. Besides, the error bar is acquired via performing
the 100 times of sampling. And we could see the error bars decrease as the sample sizes increase,
and even for 100 samples, its error bar is still very low."
SAMPLES,0.6532399299474606,"A.5
ADDITIONAL RESULTS ON RESNET"
SAMPLES,0.6549912434325744,"In this section, we perform the experiments on the ResNet34, which is trained from scratch with the
hyperparameters deployed in (He et al., 2016)."
SAMPLES,0.6567425569176882,Published as a conference paper at ICLR 2022
SAMPLES,0.658493870402802,"Rescaling and randomness comparison
For rescaling and randomness investigation, the experi-
ment setups are the same as those in Section 4.3. Here, the unit is chosen at the layer ”conv5 3 out”,
which is the last layer before global pooling layer. The sufﬁx ”out” stands for the output of a residual
convolutional block. Table 6 shows the corresponding results when performing rescaling operation."
SAMPLES,0.660245183887916,"Table 6: Comparisons of unit status by rescaling the values in images or CNN ﬁlters
Images
CNN ﬁlters
Accuracy
L1-norm
APoZ
Class selectivity
Feature entropy"
SAMPLES,0.6619964973730298,"

0.81
122.1
4.79%
0.47
1.71
Half scale

0.80
60.9
4.81%
0.23
1.72

Half scale
0.81
61.1
4.79%
0.24
1.71
Half scale
Half scale
0.77
30.4
4.83%
0.07
1.74"
SAMPLES,0.6637478108581436,Table 7 shows the corresponding results of trained units and random initialized units.
SAMPLES,0.6654991243432574,Table 7: Comparisons of unit status with respect to well-trained units and random units
SAMPLES,0.6672504378283712,"L1-norm
APoZ
Class selectivity
Feature entropy"
SAMPLES,0.6690017513134852,"Well-trained unit
122.1
4.79%
0.47
1.71
Random initialized units
678(317)
1.17%(1.54%)
0.02(0.013)
2.08(0.29)"
SAMPLES,0.670753064798599,"Just as the results on VGG16 (shown in Table 1 and 2), due to the advantages of using topology,
feature entropy could give stable indication of the status of units as expected, no matter with the
scaling operation or in the randomness situation."
SAMPLES,0.6725043782837128,"Layer and training analysis
We follow the implementation in the VGG16 network (Section 4.2)
and ﬁrst check the status of unit in each convolution layer in ResNet34. Fig.9 gives the comparisons
between the results of the convergence ResNet34 model and the random-initialized model. For
Fig.9A, it shows the variation of feature entropy with respect to the output of each convolutional
block in the ResNet34 model. We could see that the feature entropy continually decrease as the
layer goes deeper, similar to the results on VGG16. Besides, the feature entropy of each layer in the
random-initialized model are all larger than the corresponding layer in the convergence model."
SAMPLES,0.6742556917688266,"Then, we check the variation of feature entropy for layers in a convolutional block, where Fig.9B
shows the results. Typically, for ResNet34 architecture, a convolutional block consists of two con-
secutive convolutional layers and yields the output after the shortcut connection. We could see in
the ﬁgure that the feature entropy at the ﬁrst convolutional layer would increase at the second con-
volutional layer, which is because of the non-activation of units at the second convolutional layer.
After that, the shortcut connection would decrease the feature entropy even without being activated
and ﬁnally reach at a lower value than that at the ﬁrst convolutional layer. The shortcut connection
plays an important role in making the features more signiﬁcant, which leads to the decrease in the
feature entropy. A
B"
SAMPLES,0.6760070052539404,conv3_3_out
SAMPLES,0.6777583187390543,conv3_4_out
SAMPLES,0.6795096322241682,conv4_1_out
SAMPLES,0.681260945709282,conv4_2_out
SAMPLES,0.6830122591943958,conv4_3_out
SAMPLES,0.6847635726795096,conv4_4_out
SAMPLES,0.6865148861646234,conv4_5_out
SAMPLES,0.6882661996497373,conv4_6_out
SAMPLES,0.6900175131348512,conv5_1_out
SAMPLES,0.691768826619965,conv5_2_out
SAMPLES,0.6935201401050788,conv5_3_out 2.0 2.5 3.0
SAMPLES,0.6952714535901926,feature entropy
SAMPLES,0.6970227670753065,"Convergence model
 Random-initialized model Residual block"
SAMPLES,0.6987740805604203,Conv 1 (with activation)
SAMPLES,0.7005253940455342,Conv 2 (no activation)
SAMPLES,0.702276707530648,Output  (with activation)
SAMPLES,0.7040280210157618,"shortcut 
connection"
SAMPLES,0.7057793345008757,"conv 1
(activated)"
SAMPLES,0.7075306479859895,"conv 2
(deactivated)"
SAMPLES,0.7092819614711033,"output
(deactivated)"
SAMPLES,0.7110332749562172,"output
(activated) 1.8 2.0 2.2 2.4"
SAMPLES,0.712784588441331,feature entropy
SAMPLES,0.7145359019264448,"Convergence model
 Random-initialized model"
SAMPLES,0.7162872154115587,"conv5_3 block
conv5_2 block
conv4_6 block"
SAMPLES,0.7180385288966725,"conv 1
(activated)"
SAMPLES,0.7197898423817863,"conv 2
(deactivated)"
SAMPLES,0.7215411558669002,"output
(deactivated)"
SAMPLES,0.723292469352014,"output
(activated) 1.8 2.0 2.2 2.4"
SAMPLES,0.7250437828371279,feature entropy
SAMPLES,0.7267950963222417,"Convergence model
 Random-initialized model"
SAMPLES,0.7285464098073555,"conv 1
(activated)"
SAMPLES,0.7302977232924693,"conv 2
(deactivated)"
SAMPLES,0.7320490367775832,"output
(deactivated)"
SAMPLES,0.7338003502626971,"output
(activated) 2.6 2.8 3.0"
SAMPLES,0.7355516637478109,feature entropy
SAMPLES,0.7373029772329247,"Convergence model
 Random-initialized model"
SAMPLES,0.7390542907180385,"Figure 9: (A) Comparisons of feature entropy of different layers between the convergence model
and random-initialized model. (B) Comparisons of feature entropy of the layers in separately three
residual blocks between the convergence model and random-initialized model."
SAMPLES,0.7408056042031523,"Next, Fig.10 shows the variation of feature entropy during training. Similarly to those on the VGG16
model, the feature entropy decrease during training and behaves close to the training loss as well."
SAMPLES,0.7425569176882661,Published as a conference paper at ICLR 2022
SAMPLES,0.7443082311733801,"A
B
C
D
0
10
20
30
40
0 2 4 6 8 10 12"
SAMPLES,0.7460595446584939,training loss epoch
SAMPLES,0.7478108581436077,"training loss
 training accuracy 0.0 0.2 0.4 0.6 0.8 1.0"
SAMPLES,0.7495621716287215,"0
10
20
30
40
0 1 2 3 4 5 6"
SAMPLES,0.7513134851138353,training loss epoch
SAMPLES,0.7530647985989493,"training loss
 training accuracy 0.0 0.2 0.4 0.6 0.8 1.0"
SAMPLES,0.7548161120840631,"0
10
20
30
40 1.7 1.8 1.9 2.0 2.1"
SAMPLES,0.7565674255691769,feature entropy epoch 0.1 0.2 0.3 0.4 0.5 0.6
SAMPLES,0.7583187390542907,selective rate
SAMPLES,0.7600700525394045,"0
10
20
30
40
1.7 1.8 1.9 2.0 2.1"
SAMPLES,0.7618213660245184,feature entropy epoch 0.2 0.3 0.4 0.5 0.6
SAMPLES,0.7635726795096323,selective rate
SAMPLES,0.7653239929947461,"Figure 10: (B) Simultaneous evolution of training loss and feature entropy during training for the
chosen class (A-B) and for the 100 classes (C-D)."
SAMPLES,0.7670753064798599,"Indicating models with differnt generalization
Further, a set of ResNet34 models with different
generalization is trained via the same partially corrupted strategy as in Section 4.4. Table A.5 shows
the corresponding performance and Fig.11 gives the results of feature entropy. As we could see
in the ﬁgure, results on ResNet model are quite similar to those on VGG16 (Fig.4.4). The feature
entropy of models would gradually increase as the generalization become worse."
SAMPLES,0.7688266199649737,Table 8: Performance of model set R
SAMPLES,0.7705779334500875,"Train Acc
Test Acc
Corrupted"
SAMPLES,0.7723292469352014,"Model RA
0.823
0.714
0.0
Model RB
0.982
0.382
0.2
Model RC
0.991
0.229
0.4
Model RD
0.995
0.102
0.6
Model RE
0.991
0.036
0.8"
SAMPLES,0.7740805604203153,"(1)
(2)
(3)
2.0
2.5
3.0
3.5
4.0
0.0 0.1 0.2 0.3 0.4"
SAMPLES,0.7758318739054291,"Model RA
 Model RB
 Model RC
 Model RD
 Model RE"
SAMPLES,0.7775831873905429,selective rate
SAMPLES,0.7793345008756567,feature entropy
SAMPLES,0.7810858143607706,conv4_1_out
SAMPLES,0.7828371278458844,conv4_2_out
SAMPLES,0.7845884413309983,conv4_3_out
SAMPLES,0.7863397548161121,conv4_4_out
SAMPLES,0.7880910683012259,conv4_5_out
SAMPLES,0.7898423817863398,conv4_6_out
SAMPLES,0.7915936952714536,conv5_1_out
SAMPLES,0.7933450087565674,conv5_2_out
SAMPLES,0.7950963222416813,conv5_3_out 1.5 2.0 2.5 3.0 3.5 4.0 4.5
SAMPLES,0.7968476357267951,feature entropy
SAMPLES,0.7985989492119089,"Model RA
 Model RB
 Model RC
 Model RD
 Model RE"
SAMPLES,0.8003502626970228,conv4_1_out
SAMPLES,0.8021015761821366,conv4_2_out
SAMPLES,0.8038528896672504,conv4_3_out
SAMPLES,0.8056042031523643,conv4_4_out
SAMPLES,0.8073555166374781,conv4_5_out
SAMPLES,0.809106830122592,conv4_6_out
SAMPLES,0.8108581436077058,conv5_1_out
SAMPLES,0.8126094570928196,conv5_2_out
SAMPLES,0.8143607705779334,conv5_3_out 0.0 0.2 0.4 0.6 0.8 1.0
SAMPLES,0.8161120840630472,selective rate
SAMPLES,0.8178633975481612,"Model RA
 Model RB
 Model RC
 Model RD
 Model RE"
SAMPLES,0.819614711033275,"Figure 11: Comparisons between models in model set R. Compare the feature entropy (1) and
selective rate (2) of units at different layers between models in the corresponding model set on the
exampled class. (3) shows the scatter plot between feature entropy and selective rate of units at the
last residual block on the 100 sampled classes."
SAMPLES,0.8213660245183888,"A.6
COMPARISONS WITH OTHER RELATED METHODS USED IN PRUNING"
SAMPLES,0.8231173380035026,"In this section, we compare feature entropy with two other related strategies used in pruning. One is
ﬁlter pruning via geometric median (FPGM) (He et al., 2019), which uses the norm distance to the
geometric median of the set of ﬁlters as the indicator of the importance of a ﬁlter Fi at a layer (Eq.4
in He et al. (2019)),"
SAMPLES,0.8248686514886164,"g(Fi) =
X"
SAMPLES,0.8266199649737302,"Fj∈{Fk}N
k=0"
SAMPLES,0.8283712784588442,"∥Fi −Fj∥2
(13)"
SAMPLES,0.830122591943958,"where N denotes the total number of ﬁlters at the layer. A ﬁlter is considered as useless if its g(Fi)
is small."
SAMPLES,0.8318739054290718,Published as a conference paper at ICLR 2022
SAMPLES,0.8336252189141856,"The other one is called neuron importance score propagation (NISP) (Yu et al., 2018), which mea-
sures the importance of a unit by propagating the ﬁnal feature selection score backwards based on
coefﬁcients of network weights at a speciﬁc layer (Eq.19 in Yu et al. (2018)),"
SAMPLES,0.8353765323992994,"sk,i =
X"
SAMPLES,0.8371278458844134,"j
|W (k+l)
i,j
|sk+1,j
(14)"
SAMPLES,0.8388791593695272,"where | · | is the element-wise absolute value, sk,i denotes the importance score for unit i at layer k
and W (k+1)
i,j
denotes the weight matrix at layer (k+1). The method needs a base metric to score the
ﬁnal feature selection and use it to calculate units in other layers backwards via this formula. Here,
we follow the metric used in the original paper called inﬁnite feature selection (Roffo et al., 2015)."
SAMPLES,0.840630472854641,"We follow the same investigations of rescaling operations and randomness detection as deployed
previously in Section 4.3. Table 9 and Table 10 show the corresponding results. We could see in
the Table 9 that just as the other methods in Section 4.3, rescaling operations would have a major
impact on the two indicators. Apparently, from the above formulas of the two methods, we could
easily ﬁnd that they are still essentially based on the magnitude of weights. Therefore, it is nature
that they fail to give valid indication in these complicated situations."
SAMPLES,0.8423817863397548,Table 9: Comparisons of unit status by rescaling the values in images or CNN ﬁlters
SAMPLES,0.8441330998248686,"Images
CNN ﬁlters
Accuracy
FPGM
NISP
Feature entropy"
SAMPLES,0.8458844133099825,"

0.83
0.88
72.37
1.87
Half scale

0.81
0.88
36.04
1.90

Half scale
0.83
0.44
36.17
1.87
Half scale
Half scale
0.79
0.44
17.81
1.92"
SAMPLES,0.8476357267950964,"In addition to the rescaling operation, as we could see in Table 10, the FPGM method is also unable
to give correct discrimination between the well-trained units and the random-initialized units."
SAMPLES,0.8493870402802102,Table 10: Comparisons of unit status with respect to well-trained units and random units
SAMPLES,0.851138353765324,"FPGM
NISP
Feature entropy"
SAMPLES,0.8528896672504378,"Well-trained unit
0.88
72.37
1.87
Random initialized units
1.44(0.044)
19.27(2.98)
2.87(0.22)"
SAMPLES,0.8546409807355516,"A.7
STUDY OF PRUNING"
SAMPLES,0.8563922942206655,"In Section 4.4, feature entropy has shown the ability to reliably indicate the status of units between
different models in various situations, which is the core motivation of the paper. In addition, we
also show the effectiveness of feature entropy to give comparisons between different units in the
single model in a ﬁxed situation. In this situation, since units are generally in the comparable scale
(unless use some speciﬁc implementations on networks like Neyshabur et al. (2015)2), the mentioned
problems may be largely alleviated, so units would be compared directly via the typical methods like
L1-Norm, etc. Besides, we would consider feature entropy and selective rate both to represent its
effectiveness of units for an accurate estimation, where we would fuse these two factors by using
H/ϵ in the following calculations."
SAMPLES,0.8581436077057794,"Here we are going to investigate the units in the single model in two parts. The ﬁrst part is the cu-
mulative unit ablation and the second part is an example of the implementation of network pruning."
SAMPLES,0.8598949211908932,"A.7.1
CUMULATIVE UNIT ABLATION"
SAMPLES,0.861646234676007,"Ablation test setting
For a given class, cumulative unit ablation tests check the evolution of the
network performance by progressively removing each unit within a layer according to the order of"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8633975481611208,"2This implementation could somehow yield the same effect with performing the rescaling operation to the
magnitude of a speciﬁc unit in Section 4.3, without changing the results of networks and other units. For more
details about this implementation, please refer to the paper."
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8651488616462347,Published as a conference paper at ICLR 2022
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8669001751313485,"certain kind of sorted attribute of units. Typically, removing a unit refers to forcing the outputs of
the unit to all zeros. Here, the unit’s feature entropy is chosen as the attribute, and descending and
ascending orders are considered simultaneously. According to our idea, the unit with lower feature
entropy is more effective than that with higher feature entropy. The cumulative ablation tests reveal
the relation between feature entropy of unit’s output and its effectiveness on network performance,
where training sets are generally used for calculating the feature entropy of the units and testing sets
are used for checking their impact on the network performance. Besides, the investigations are still
using the last convolutional layer on the same image set in the previous section. In particular, for
each image in the set, it would be randomly rescaled within the ratio from 0.5 to 1.5. A B"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8686514886164624,"(1)
(2)
(3)
(4)"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8704028021015762,"(1)
(2)
(3)
(4)"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.87215411558669,"0
100
200
300
400
500
0 2 4 6 8 10 12"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8739054290718039,testing loss
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8756567425569177,number of units ablated
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8774080560420315,"0
100
200
300
400
500 0 2 4 6 8 10 12"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8791593695271454,testing loss
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8809106830122592,"number of units ablated
0
100
200
300
400
500
0.0 0.2 0.4 0.6 0.8"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.882661996497373,"1.0
(488, 1.0)"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8844133099824869,testing accuracy
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8861646234676007,number of units ablated
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8879159369527145,"0
100
200
300
400
500 0.0 0.2 0.4 0.6 0.8 1.0"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8896672504378283,"(38,0)"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8914185639229422,testing accuracy
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8931698774080561,number of units ablated
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8949211908931699,"0
100
200
300
400
500 2 4 6 8 10 12 14"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8966725043782837,testing loss
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.8984238178633975,number of units ablated
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9001751313485113,"Feature entropy
 L1-Norm
 Class selectivity
 Apoz
 NISP
 FPGM"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9019264448336253,"0
100
200
300
400
500
0 2 4 6 8 10"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9036777583187391,testing loss
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9054290718038529,number of units ablated
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9071803852889667,"Feature entropy
 L1-Norm
 Class selectivity
 Apoz
 NISP
 FPGM"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9089316987740805,"0
100
200
300
400
500 0.0 0.2 0.4 0.6 0.8 1.0"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9106830122591943,testing accuracy
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9124343257443083,number of units ablated
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9141856392294221,"Feature entropy
 L1-Norm
 Class selectivity
 Apoz
 NISP
 FPGM"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9159369527145359,"0
100
200
300
400
500 0.0 0.2 0.4 0.6 0.8 1.0"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9176882661996497,testing accuracy
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9194395796847635,number of units ablated
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9211908931698775,"Feature entropy
 L1-Norm
 Class selectivity
 Apoz
 NISP
 FPGM"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9229422066549913,"Figure 12:
Cumulative ablation curves of accuracy (1) and loss (2) according to the descending
rank (A) and the ascending rank (B), together with comparisons with other methods (3-4)."
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9246935201401051,"Results
The cumulative ablation is performed via ascending order of feature entropy ﬁrst. Fig.12A
shows the variation of the testing accuracy (1) and loss (2) during ablation. We can see the accuracy
drops rapidly in the beginning and arrives at zero after ablating about 38 units. On the other side, the
loss sharply increases in the beginning just like accuracy, afterwards slowly climbing and reaching
its peak value (12.32) during ablation. It should be mentioned that the peak value even exceeds that
of removing all the units (8.71). Being somehow counterintuitive, the ablation has generated a layer
even worse than the all-zero layer."
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9264448336252189,"We have also compared with the performance evolutions resulted from APoZ, class selectivity, L1-
norm, FPGM, NISP. We can see in Fig.12(3-4) that the accuracy drops (or the loss increases) more
rapidly using feature entropy (red line) than others during the ablation process. This implies that
those most effective units picked by feature entropy would be more impactful to the network perfor-
mance."
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9281961471103327,"Then, the cumulative ablation is performed via descending order of feature entropy. From Fig.12B,
instead of decreasing, the testing accuracy features a slow increase from 0.54 to surprising 1.0 when
96% of the units are removed. These units do not lie in the head part of feature entropy rank and are
considered as the less effective units. So removing them will promote the accuracy and enhance the
network performance. Remarkably, starting with removing a certain unit, the accuracy dramatically
drops to zero within only 30 units. It means that these units are critical and removing them will lead
to breakdown of network. Likewise, the comparisons are also implemented with other attributes in
Fig.12A. We could also ﬁnd that curve of feature entropy could reach much higher peak point in
accuracy, which shows the advantage of feature entropy."
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9299474605954466,"Interestingly, we could see that the testing performance could be largely enhanced via the cumula-
tive unit ablation for a single class. Then, all the 1000 classes in ImageNet are investigated in the
same way. On the one hand, we would check whether the testing performance could be enhanced"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9316987740805605,Published as a conference paper at ICLR 2022
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9334500875656743,Table 11: Performance enhancement via cumulative ablation when using different methods
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9352014010507881,"Unchanged
network
Ablated
network
Performance
enhanced"
THIS IMPLEMENTATION COULD SOMEHOW YIELD THE SAME EFFECT WITH PERFORMING THE RESCALING OPERATION TO THE,0.9369527145359019,"L1-Norm
0.7591
0.928
0.167
Apoz
0.759
0.873
0.114
Class selectivity
0.759
0.917
0.158
FPGM
0.759
0.789
0.030
NISP
0.759
0.838
0.079
Feature entropy
0.759
0.945
0.186"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9387040280210157,"1 All the performances are reported as balanced accuracy
(Brodersen et al., 2010)."
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9404553415061296,"in this way for the majority of the classes, on the other hand, we use this to give comparisons be-
tween different methods under this circumstance. Table 11 shows the corresponding results, which
is reported by averaging across all the classes. Note that all the results in the table are reported as
the balanced accuracy, which is commonly used for assessing the performance where the task is im-
balanced. We could see that after performing ablation on a single class, the network could generally
acquire performance enhancement to some extent. And compared to other methods, feature entropy
shows a larger performance enhancement, which again demonstrates the superiority of our method."
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9422066549912435,"A.7.2
IMPLEMENTATION OF NETWORK PRUNING"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9439579684763573,"In the previous paragraph, we perform the ablation test on a single class to show the effectiveness
of feature entropy. Here, we are going to give implementation of channel-level network pruning for
the whole dataset via feature entropy."
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9457092819614711,"Network pruning setting
The network is pruned by following the layer-by-layer strategy, which
prunes the channels from the shallow to the deep layers progressively in two stages. In the ﬁrst
stage, unimportant units at a layer are selected to be pruned based on a given pruning ratio via
feature entropy. For units at the layer, they are selected by averaging the feature entropy across
numbers of classes,"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9474605954465849,"H(Ui) = 1 K K
X"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9492119089316988,"k=1
Hk(Ui)
(15)"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9509632224168126,"where K is the total number of chosen classes. In this way, we would prune the corresponding
ﬁlters whose outputted units have higher feature entropy. In the meantime, since the unit is removed,
channels of the ﬁlters that connect this unit and units at next layer would also be pruned. Then in the
second stage, we would ﬁne-tune the pruned model. Here, we still use the reference VGG16 model
in the paper as our target network. In the conventional VGG architecture, after the convolutional
backbone, two fully connected layers are used as the classiﬁer for the following decision making.
Although parameters in the fully connected layers could account for over 80%, yet the majority of
computation cost lie on the convolutional operation. So here, we remain this classiﬁer and target to
prune all the convolutional layers for computation reduction."
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9527145359019265,"Additionally, during ﬁne-tuning stage, we use the SGD optimizer with a learning rate which is
initially set to 1e-3, decay 10 times after one epoch ﬁne-tuning and ﬁnally stop after 1e-5. All
implementations are deployed on the Nvidia-A100 station with a batch size of 512. Also, similar
to the setting in the paper, all the images are simply resized to 224 × 224. We use the FLOPs of
convolutional operation as the metric of computation cost and parameter counts as the metric of
storage cost."
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9544658493870403,"Results
We ﬁrst investigate the impact of the number of classes K to the pruning effect, where
the pruning ratio is set to 50%. Fig.13A shows the pruning results of VGG16 with remaining fully
connected layers. We could see that as we choose more amount of classes for the calculation of"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9562171628721541,Published as a conference paper at ICLR 2022
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.957968476357268,"feature entropy, the accuracy of the ﬁne-tuned model gradually increase. And compared to using
100 classes, using 150 and 200 classes would increase the accuracy slightly. Thus, for an efﬁcient
computation of feature entropy, we would use 100 classes for the following pruning implementation. A
B"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9597197898423818,"0.4
0.5
0.6
60 62 64 66 68"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9614711033274956,testing accuracy
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9632224168126094,pruning ratio
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9649737302977233,VGG16 with fc layers
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9667250437828371,"50
100
150
200
60 62 64 66"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.968476357267951,"68
 VGG16 with fc layers"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9702276707530648,number of classes K
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9719789842381786,testing accuracy
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9737302977232924,"Figure 13: (A) Accuracy of the ﬁne-tuned models with respect to the number chosen classes used
for feature entropy calculation. (B) Accuracy of the ﬁne-tuned models on different pruning ratios."
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9754816112084063,"Then, we give the results of ﬁne-tuned networks via the implementations of separately 40%, 50%,
60% pruning ratios, as shown in Fig.13B. We could see that as we keep more channels, the ﬁne-
tuned network could reach a higher accuracy and when the pruning ratio is 60%, the accuracy is
comparable to that of unchanged network."
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9772329246935202,"Finally, we make comparisons when using different methods with the pruning ratio of 50%. For
other methods, we use the same pruning implementation as feature entropy. Table 12 gives the ﬁnal
results. As we could see in the table, the model pruned via feature entropy could reach competitive
results compared to other methods. In conclusion, feature entropy shows the advantage of being an
effective indicator for not only network units between different models but units in a single model."
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.978984238178634,Table 12: Comparisons of the accuracy of ﬁne-tuned models when using different methods
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9807355516637478,"Accuracy ↓
(ﬁne-tuned)
Pruned
ratio
#Params1
FLOPs1
img/sec2"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9824868651488616,"Unchanged network
65.71%
-
138M
30.96B
2,178"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9842381786339754,"L1-Norm
Apoz
Class selectivity
FPGM
NISP"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9859894921190894,"1.03%
1.59%
0.38%
0.59%
0.92%"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9877408056042032,"50%
75.9M
7.87B
5,5413"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.989492119089317,"Feature entropy
0.09%
0.42%
0.89%"
ALL THE PERFORMANCES ARE REPORTED AS BALANCED ACCURACY,0.9912434325744308,"40%
50%
60%"
M,0.9929947460595446,"87.8M
75.9M
64.2M"
B,0.9947460595446584,"11.15B
7.87B
5.02B"
B,0.9964973730297724,"4,869
5,541
6,131"
B,0.9982486865148862,"1 ”M” and ”B” denote the million and billion separately.
2 Inference speed measured on Nvidia A100 GPU.
3 Since the pruned models are in the same architecture, their inference time are very
close in practice, so it is the average value across all the models."
