Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.001941747572815534,"A primary criticism towards language models (LMs) is their inscrutability. This
1"
ABSTRACT,0.003883495145631068,"paper presents evidence that, despite their size and complexity, LMs sometimes
2"
ABSTRACT,0.005825242718446602,"exploit a computational mechanism familiar from traditional word embeddings:
3"
ABSTRACT,0.007766990291262136,"the use of simple vector arithmetic in order to encode abstract relations (e.g.,
4"
ABSTRACT,0.009708737864077669,"Poland:Warsaw::China:Beijing). We investigate a range of language model sizes
5"
ABSTRACT,0.011650485436893204,"(from 124M parameters to 176B parameters) in an in-context learning setting, and
6"
ABSTRACT,0.013592233009708738,"ﬁnd that for a variety of tasks (involving capital cities, upper-casing, and past-
7"
ABSTRACT,0.015533980582524271,"tensing), a key part of the mechanism reduces to a simple linear update applied
8"
ABSTRACT,0.017475728155339806,"by the feedforward networks. We further show that this mechanism is speciﬁc
9"
ABSTRACT,0.019417475728155338,"to tasks that require retrieval from pretraining memory, rather than retrieval from
10"
ABSTRACT,0.021359223300970873,"local context. Our results contribute to a growing body of work on the mechanistic
11"
ABSTRACT,0.02330097087378641,"interpretability of LLMs, and offer reason to be optimistic that, despite the massive
12"
ABSTRACT,0.02524271844660194,"and non-linear nature of the models, the strategies they ultimately use to solve tasks
13"
ABSTRACT,0.027184466019417475,"can sometimes reduce to familiar and even intuitive algorithms.
14"
INTRO,0.02912621359223301,"1
Intro
15"
INTRO,0.031067961165048542,"The growing capabilities of large language models (LLMs) have led to an equally growing interest in
16"
INTRO,0.03300970873786408,"understanding how such models work under the hood. Such understanding is critical for ensuring that
17"
INTRO,0.03495145631067961,"LLMs are reliable and trustworthy once deployed. Recent work (often now referred to as “mechanistic
18"
INTRO,0.036893203883495145,"interpretability”) has contributed to this understanding by reverse-engineering the data structures and
19"
INTRO,0.038834951456310676,"algorithms that are implicitly encoded in the model’s weights, e.g., by identifying detailed circuits
20"
INTRO,0.040776699029126215,"[Wang et al., 2022, Elhage et al., 2021, Olsson et al., 2022] or by identifying mechanisms for factual
21"
INTRO,0.04271844660194175,"storage and retrieval which support intervention and editing [Geva et al., 2021b, Li et al., 2022, Meng
22"
INTRO,0.04466019417475728,"et al., 2022a,c, Dai et al., 2022].
23"
INTRO,0.04660194174757282,"Here, we contribute to this growing body of work by analyzing how LLMs recall information during
24"
INTRO,0.04854368932038835,"in-context learning. Speciﬁcally, we observe that the mechanism that LLMs use in order to retrieve
25"
INTRO,0.05048543689320388,"certain facts (e.g., mapping a country to its capital city) bears a striking resemblance to the type of
26"
INTRO,0.05242718446601942,"vector arithmetic operations associated with LLMs’ simpler, static word-embedding predecessors.
27"
INTRO,0.05436893203883495,"That is, early word embeddings such as word2vec [Mikolov et al., 2013] famously supported factual
28"
INTRO,0.05631067961165048,"recall via linear vector arithmetic–e.g., there existed some vector that, when added to the vector
29"
INTRO,0.05825242718446602,"for any country would produce the vector for its capital. Modern LLMs are based on a complex
30"
INTRO,0.06019417475728155,"transformer architecture [Vaswani et al., 2017] which produces contextualized word embeddings
31"
INTRO,0.062135922330097085,"[Peters et al., 2018, Devlin et al., 2019] connected via multiple non-linearities. Despite this, we ﬁnd
32"
INTRO,0.06407766990291262,"that LLMs implement a very similar vector-addition mechanism which plays an important role in a
33"
INTRO,0.06601941747572816,"number of in-context-learning tasks.
34"
INTRO,0.06796116504854369,"We study this phenomenon in three tasks–involving recalling capital cities, uppercasing tokens, and
35"
INTRO,0.06990291262135923,"past-tensing verbs. Our key ﬁndings are:
36"
INTRO,0.07184466019417475,"• We ﬁnd evidence of a distinct processing signature in the forward pass which characterizes
37"
INTRO,0.07378640776699029,"this mechanism. That is, if models need to perform the get_capital(x) function, which
38"
INTRO,0.07572815533980583,"takes an argument x and yields an answer y, they must ﬁrst surface the argument x in earlier
39"
INTRO,0.07766990291262135,"layers which enables them to apply the function and yield y as the ﬁnal output (Figure 2).
40"
INTRO,0.07961165048543689,"This signature generalizes across models and tasks, but appears to become sharper as models
41"
INTRO,0.08155339805825243,"increase in size.
42"
INTRO,0.08349514563106795,"• We take a closer look at GPT2-Medium, and ﬁnd that the vector arithmetic mechanism is
43"
INTRO,0.0854368932038835,"implemented by mid-to-late layer feedforward networks (FFNs) in a way that is modular
44"
INTRO,0.08737864077669903,"and supports intervention. That is, FFNs construct a vector that is not speciﬁc to context
45"
INTRO,0.08932038834951456,"or argument, such that the same vector which produces Warsaw given Poland in one context
46"
INTRO,0.0912621359223301,"can be dropped into an unrelated context to produce Beijing given China.
47"
INTRO,0.09320388349514563,"• We demonstrate that this mechanism is speciﬁc to recalling information from pretraining
48"
INTRO,0.09514563106796116,"memory. For settings in which the correct answer can be retrieved from the prompt, this
49"
INTRO,0.0970873786407767,"mechanism does not appear to play any role, and FFNs can be ablated entirely with relatively
50"
INTRO,0.09902912621359224,"minimal performance degradation. Thus, we present new evidence supporting the claim that
51"
INTRO,0.10097087378640776,"FFNs and attention specialize for different roles, with FFNs supporting factual recall and
52"
INTRO,0.1029126213592233,"attention copying and pasting from local context.
53"
INTRO,0.10485436893203884,"Taken together, our results offer new insights about one component of the complex algorithms
54"
INTRO,0.10679611650485436,"that underlie in-context learning. The simplicity of the mechanism, in itself surprising, raises the
55"
INTRO,0.1087378640776699,"possibility that other apparently complicated behaviors may be supported by a sequence of simple
56"
INTRO,0.11067961165048544,"operations under the hood. Moreover, our results suggest a distinct processing signature and hint
57"
INTRO,0.11262135922330097,"at a method for intervention. These ideas could support future work on detecting and preventing
58"
INTRO,0.1145631067961165,"unwanted behavior by LLMs at runtime.
59"
METHODS,0.11650485436893204,"2
Methods
60"
METHODS,0.11844660194174757,"In decoder-only transformer language models [Vaswani et al., 2017], a sentence is processed one
61"
METHODS,0.1203883495145631,"word at a time, from left to right. The token at the current timestep is passed into the input of the
62"
METHODS,0.12233009708737864,"model in order to predict the next, and so on. In this paper, we focus on the transformations that the
63"
METHODS,0.12427184466019417,"next-token prediction undergoes in order to predict the next word. At each layer, an attention module
64"
METHODS,0.1262135922330097,"and feed-forward network (FFN) module apply subsequent updates to this representation. Consider
65"
METHODS,0.12815533980582525,"the FFN update at layer i, where xi is the current next-token representation. The update applied by
66"
METHODS,0.13009708737864079,"the FFN here is calculated as FFN(~xi) = ~oi,
~
xi+1 = ~xi + ~oi where
~
xi+1 is the updated token for
67"
METHODS,0.13203883495145632,"the next layer. Note that due to the residual conncetion, the output vector ~oi is added to the input. ~x
68"
METHODS,0.13398058252427184,"is updated this way by the attention and FFNs until the end of the model, where the token is decoded
69"
METHODS,0.13592233009708737,"into the vocab space with the language modeling head E: softmax(E~x). From start to end, x is only
70"
METHODS,0.1378640776699029,"updated by additive updates, and because of this, is said to form a residual stream [Elhage et al.,
71"
METHODS,0.13980582524271845,"2021]. Thus, the token representation xi represents all of the additions made into the residual stream
72"
METHODS,0.141747572815534,"up to layer i.
73"
METHODS,0.1436893203883495,"The unembedding  
matrix projects into 
the vocabulary space."
METHODS,0.14563106796116504,"Attention
FFN"
METHODS,0.14757281553398058,"LM 
Head
Embed FFN"
METHODS,0.14951456310679612,"LM 
Head"
METHODS,0.15145631067961166,"+a18
+ofunc
+o18"
METHODS,0.1533980582524272,Attention +a19 …
METHODS,0.1553398058252427,"LM 
Head
LM 
Head"
METHODS,0.15728155339805824,"LM 
Head …"
METHODS,0.15922330097087378,Selected by example
METHODS,0.16116504854368932,"Figure 1: When decoding the next word, additive updates are made through the residual connections
of each attention/FFN sub-layer. To decode the running prediction at every layer, the pre-trained
language modeling head is applied at various points in each layer as in Geva et al. [2022a], nostalge-
braist [2020]. The ~o vector interventions we make (§4.1) are illustrated by removing one or more
FFN sub-layers, and replacing their updates with pre-deﬁned vectors extracted from other examples."
EARLY DECODING,0.16310679611650486,"2.1
Early Decoding
74"
EARLY DECODING,0.1650485436893204,"A key insight from the residual stream perspective is that we can decode the next token prediction
75"
EARLY DECODING,0.1669902912621359,"with the LM head before it reaches the ﬁnal layer. This effectively allows for “print statements”
76"
EARLY DECODING,0.16893203883495145,"throughout the model’s processing. The intuition behind this technique is that LMs incrementally
77"
EARLY DECODING,0.170873786407767,"update the token representation ~x to build and reﬁne an encoding of the vocabulary distribution.
78"
EARLY DECODING,0.17281553398058253,"This technique was initially introduced in nostalgebraist [2020] as the logit lens, and Geva et al.
79"
EARLY DECODING,0.17475728155339806,"[2022b] show that LMs do in fact reﬁne the output distribution over the course of the model. Figure 1
80"
EARLY DECODING,0.1766990291262136,"illustrates the process we use to decode hidden states into the vocabulary space, in which the hidden
81"
EARLY DECODING,0.1786407766990291,"state at each layer is decoded with the pre-trained language modeling head E. After decoding into
82"
EARLY DECODING,0.18058252427184465,"the vocabulary space, we apply a softmax to get a probability distribution over all tokens. When we
83"
EARLY DECODING,0.1825242718446602,"decode at some layer, we say that the most likely token in the resulting vocab distribution is currently
84"
EARLY DECODING,0.18446601941747573,"being represented in the residual stream. We examine several in-context learning tasks to understand
85"
EARLY DECODING,0.18640776699029127,"how the answers to these problems are discovered by a model over the course of the forward pass.
86"
TASKS,0.1883495145631068,"2.2
Tasks
87"
TASKS,0.19029126213592232,"Can we understand the subprocesses underlying how LMs solve simple problems? We apply early
88"
TASKS,0.19223300970873786,"decoding to suite of in-context learning tasks to explore the transformations the next token prediction
89"
TASKS,0.1941747572815534,"undergoes in order to predict the answer.
90"
TASKS,0.19611650485436893,"World Capitals Our World Capitals task requires the model to retrieve the capital city for various
91"
TASKS,0.19805825242718447,"states and countries in a few-shot setting. The dataset we use contains 248 countries and territories.
92"
TASKS,0.2,"A one-shot example is shown below:
93"
TASKS,0.20194174757281552,“Q: What is the capital of France?
TASKS,0.20388349514563106,"A: Paris
Q: What is the capital of Poland?
A:___"" Expected Answer: “ Warsaw"" 94"
TASKS,0.2058252427184466,"Reasoning about Colored Objects We focus on a subset of 200 of the reasoning about
95"
TASKS,0.20776699029126214,"colored objects dataset prompts (henceforth, the colored objects dataset) from BIG-Bench
96"
TASKS,0.20970873786407768,"[Srivastava et al., 2022], which gives the model a list of colored common objects and require
97"
TASKS,0.21165048543689322,"to simply state the color of a query object.
For the purposes of this paper, we focus only
98"
TASKS,0.21359223300970873,"on one aspect of this task–the model’s ability to output the ﬁnal answer in the correct format.1
99"
TASKS,0.21553398058252426,"“Q: On the ﬂoor, I see a silver keychain, a red pair of sunglasses, a gold sheet of paper, a black dog"
TASKS,0.2174757281553398,"leash, and a blue cat toy. What color is the keychain?
A: Silver
Q: On the table, you see a brown sheet of paper, a red ﬁdget spinner, a blue pair of sunglasses, a teal
dog leash, and a gold cup. What color is the sheet of paper?
A:___"" Expected answer: “ Brown"" 100"
TASKS,0.21941747572815534,"Past Tense Verb Mapping Lastly, we examine whether a language model can accurately recognize
101"
TASKS,0.22135922330097088,"a pattern and predict the past tense form of a verb given its present tense. The dataset used is the
102"
TASKS,0.22330097087378642,"combination of the regular and irregular partitions of the past tense linguistic mapping task in
103"
TASKS,0.22524271844660193,"BIG-Bench [Srivastava et al., 2022]. After ﬁltering verbs in which the present and past tense forms
104"
TASKS,0.22718446601941747,"start with the same token, we have a total of 1,567 verbs. An example one-shot example is given below:
105"
TASKS,0.229126213592233,"“Today I abandon. Yesterday I abandoned. Today I abolish. Yesterday I___"" Expected answer: “"
TASKS,0.23106796116504855,"abolished""
106"
MODELS,0.23300970873786409,"2.3
Models
107"
MODELS,0.23495145631067962,"We experiment exclusively on decoder-only transformer LMs across various sizes and pre-training
108"
MODELS,0.23689320388349513,"corpora. When not speciﬁed, results in ﬁgures are from GPT2-medium. We also include results
109"
MODELS,0.23883495145631067,"portraying the stages of processing signatures in the residual streams of the small, large, and extra
110"
MODELS,0.2407766990291262,"large variants [Radford et al.], the 6B parameter GPT-J model [Wang and Komatsuzaki, 2021], and
111"
MODELS,0.24271844660194175,"the 176B BLOOM model [Scao et al., 2022], either in the main paper or in the Appendix.
112"
MODELS,0.2446601941747573,"1The reason for this is that most of the results in this paper were originally observed as incidental ﬁndings
while studying the Reasoning about Colored Objects task more generally. We thus zoom in on this one component
for the purposes of the mechanism studied here, acknowledging that the full task involves many other steps that
will no doubt involve other types of mechanisms."
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.24660194174757283,"3
Stages of Processing in Predicting the Next Token
113"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.24854368932038834,"Layer
Top Token
0
(
1
A
2
A
3
A
4
A
5
A
6
No
7
C
8
A
9
A
10
A
11
A
12
Unknown
13
C
14
St
15
Poland
16
Poland
17
Poland
18
Poland
19
Warsaw
20
Warsaw
21
Warsaw
22
Warsaw
23
Warsaw A B C"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.2504854368932039,"Figure 2: We can decode the running next-token predic-
tion in an in-context learning task to reveal functionally
distinct stages of processing. The blue box (A) shows
where the model prepares an argument for transforma-
tion, the red box (B) shows the function application
phase during which the argument is transformed (here
with the capital_of function, and the yellow box
(C) shows a saturation event, in which the model has
found the answer, and stops updating the prediction."
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.2524271844660194,"First, we use the early decoding method
114"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.2543689320388349,"in order to investigate how the processing
115"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.2563106796116505,"proceeds over the course of a forward pass
116"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.258252427184466,"to the model. Each task requires the model
117"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.26019417475728157,"to infer some relation to recall some fact,
118"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.2621359223300971,"e.g., retrieving the capital of Poland. In
119"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.26407766990291265,"these experiments, we see several discrete
120"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.26601941747572816,"stages of processing that the next token un-
121"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.26796116504854367,"dergoes before reaching the ﬁnal answer.
122"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.26990291262135924,"These states together provide evidence that
123"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.27184466019417475,"the models ""apply"" the relevant functions
124"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.2737864077669903,"(e.g., get_capital) abruptly at some
125"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.2757281553398058,"mid-late layer to retrieve the answer. More-
126"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.27766990291262134,"over, in these cases, the model prepares the
127"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.2796116504854369,"argument to this function in the layers prior
128"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.2815533980582524,"to that in which the function is applied.
129"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.283495145631068,"In Figure 2 we illustrate an example of the
130"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.2854368932038835,"stages we observe across models. For the
131"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.287378640776699,"ﬁrst several layers, we see no movement
132"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.28932038834951457,"on the words of interest. Then, during Ar-
133"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.2912621359223301,"gument Formation, the model ﬁrst repre-
134"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.29320388349514565,"sents the argument to the desired relation
135"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.29514563106796116,"in the residual stream. This means that the
136"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.2970873786407767,"top token in the vocabulary distribution at
137"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.29902912621359223,"some intermediate layer(s) is the subject
138"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.30097087378640774,"the question inquires about (e.g., the x, in get_capital(x)). During Function Application
139"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.3029126213592233,"we ﬁnd that the model abruptly switches from the argument to the output of the function (the y, in
140"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.3048543689320388,"get_capital(x) = y). We ﬁnd that function application is typically applied by the FFN update
141"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.3067961165048544,"at that layer to the residual stream. This is done by adding the output vector ~o of the FFN to the
142"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.3087378640776699,"residual stream representation, thus transforming it with an additive update. We study these ~o vectors
143"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.3106796116504854,"in detail in Section 4. Finally, the model enters Saturation2, where the model recognizes it has solved
144"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.312621359223301,"the next token, and ceases updating the token representation for the remaining layers.
145"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.3145631067961165,"The trend can be characterized by an X-shaped pattern of the argument and ﬁnal output tokens
146"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.31650485436893205,"when plotting the ranks of the argument(x) and output (y) tokens. We refer to this behavior as
147"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.31844660194174756,"argument-function processing. Figure 3 shows that this same processing signature can be observed
148"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.32038834951456313,"consistently across tasks and models. Moreover, it appears to become more prominent as the models
149"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.32233009708737864,"increase in size. Interestingly, despite large differences in number of layers and overall size, models
150"
STAGES OF PROCESSING IN PREDICTING THE NEXT TOKEN,0.32427184466019415,"tend to undergo this process at similar points proportionally in the model.
151"
IMPLEMENTATION OF CONTEXT-INDEPENDENT FUNCTIONS IN FFN UPDATES,0.3262135922330097,"4
Implementation of Context-Independent Functions in FFN Updates
152"
IMPLEMENTATION OF CONTEXT-INDEPENDENT FUNCTIONS IN FFN UPDATES,0.32815533980582523,"The above results on processing signature suggest that the models “apply” a function about 2/3rds of
153"
IMPLEMENTATION OF CONTEXT-INDEPENDENT FUNCTIONS IN FFN UPDATES,0.3300970873786408,"the way through the network with the addition of an FFN update. Here, we investigate the mechanism
154"
IMPLEMENTATION OF CONTEXT-INDEPENDENT FUNCTIONS IN FFN UPDATES,0.3320388349514563,"via which that function is applied more closely. Speciﬁcally, focusing on GPT2-Medium3, we show
155"
IMPLEMENTATION OF CONTEXT-INDEPENDENT FUNCTIONS IN FFN UPDATES,0.3339805825242718,"that we can force the encoded function to be applied to new arguments in new contexts by isolating
156"
IMPLEMENTATION OF CONTEXT-INDEPENDENT FUNCTIONS IN FFN UPDATES,0.3359223300970874,"the responsible FFN output vector and then dropping into a forward pass on a new input.
157"
IMPLEMENTATION OF CONTEXT-INDEPENDENT FUNCTIONS IN FFN UPDATES,0.3378640776699029,"2Saturation events are described in Geva et al. [2022a] where detection of such events is used to “early-exit”
out of the forward pass"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.33980582524271846,"3We focus on one model because manual analysis was required in order to determine how to perform the
intervention. See Appendix for results on GPT-J and Section 7 for discussion."
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.341747572815534,"Figure 3: Argument formation and function application is characterized by a promotion of the
argument (red) followed by it being replaced with the answer token (blue), forming an X when
plotting reciprocal ranks. Across the three tasks we evaluate, we see that most of the models exhibit
these traces, and despite the major differences in model depths, the stages occur at similar points in
the models. Data shown is ﬁltered by examples in which the models got the correct answer."
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.34368932038834954,"4.1
~o Vector Interventions
158"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.34563106796116505,"Consider the example in Figure 2.
At layer 18,
the residual stream ( ~
x18) is in
159"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.34757281553398056,"argument
formation,
and
represents
the
“
Poland""
token.
At
the
end
of
layer
160"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.34951456310679613,"19,
a
function
is
applied,
transforming
~
x19
into
the
answer
token
“
Warsaw.
161"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.35145631067961164,"Figure 4: The gray area indicates layers where FFN
intervention was performed. We ﬁnd that even if
the input context is nonsense (repeating pattern of
“table mug free China""), if we can use “China"" as"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3533980582524272,"an argument in the residual stream, the
~
ocity vector
has the effect of promoting the correct capital city."
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3553398058252427,"As discussed in the previous section, we can
162"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3572815533980582,"isolate the function application in this case to
163"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3592233009708738,"FFN 19; let ˜
x19 represent the residual stream
164"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3611650485436893,"after the attention update, but before the FFN
165"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.36310679611650487,"update at layer 19 (which still represents Poland).
166"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3650485436893204,"Recall that the update made by FFN 19 is writ-
167"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.36699029126213595,"ten FFN19( ˜
x19) = ~
o19 and ~
x19 =
˜
x19 + ~
o19.
168"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.36893203883495146,"We ﬁnd that ~
o19 will apply the get_capital
169"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.37087378640776697,"function regardless of the content of ˜
x19. For
170"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.37281553398058254,"example, if we add ~
o19 to some ˜x which repre-
171"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.37475728155339805,"sents the “ China"" token, it will transform into
172"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3766990291262136,"“ Beijing"". Thus we refer to ~
o19 as
~
ocity since
173"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3786407766990291,"it retrieves the capital cities of locations stored
174"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.38058252427184464,"in the residual stream. We locate such ~o vectors
175"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3825242718446602,"in the uppercasing and past tense mapping tasks
176"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3844660194174757,"in the examples given in Section 2.2, which we
177"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3864077669902913,"refer to as
~
oupper and
~
opast, respectively.4
178"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3883495145631068,"We test whether these updates have the same
179"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.39029126213592236,"effect, and thus implement the same function, as
180"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.39223300970873787,"they do in the original contexts from which they
181"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.3941747572815534,"were extracted, which would imply a systematic
182"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.39611650485436894,"structure in the internal embedding space the
183"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.39805825242718446,"LM leverages. To do so, we replace entire FFN
184"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4,"layers with these vectors and run new inputs through the intervened model.5
185"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.40194174757281553,"4In Appendix A, we extend these results to GPT-J, for which the same procedure leads to strong effects on
uppercasing, but smaller overall positive effects on capital cities and past tensing (see Section 7)."
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.40388349514563104,"5Which FFNs to replace is a hyperparameter; we ﬁnd that replacing layers 18-23 in GPT2-Medium leads
to good results. It also appears necessary to replace multiple FFNs at a time. See additional experiments in
Appendix D. In summary, it is likely that the ~o vectors are added over the course of several layers, consistent"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4058252427184466,"Figure 5: We intervene on GPT2-Medium’s forward pass while it is predicting the completion of a
pattern. The control indicates normal model execution, while the gray boxes indicate which FFNs are
replaced with our selected ~o vectors. We can see a signiﬁcant increase in the reciprocal rank of the
output of the function implemented by the ~o vector used even though the context is completely absent
of any indication of the original task."
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4077669902912621,"Data: We are interested in whether the captured o vectors can be applied in a novel context,
186"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4097087378640777,"in particular, to a context that is otherwise devoid of cues as to the function of interest. Thus,
187"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4116504854368932,"we synthesize a new dataset where each entry is a string of three random tokens (with leading
188"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.41359223300970877,"spaces) followed by a token x which represents a potential argument to the function of interest.
189"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4155339805825243,"For example, in experiments involving ocity, we might include a sequence such as table mug
190"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4174757281553398,"free China table mug free China table mug free. This input primes the model
191"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.41941747572815535,"to produce “China” at the top of the residual stream, but provides no cues that the capital city is
192"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.42135922330097086,"relevant, and thus allows us to isolate the effect of ocity in promoting “Beijing” in the residual stream.
193"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.42330097087378643,"In addition to the original categories, we also include an “out-of-domain” dataset for each task: US
194"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.42524271844660194,"states and capitals, 100 non-color words, and 128 irregular verbs. These additional data test the
195"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.42718446601941745,"sensitivity of the ~o vectors to different types of arguments.
196"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.429126213592233,"Results: Figure 4 shows results for a single example. Here, we see that “Beijing” is promoted all the
197"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.43106796116504853,"way to the top of the distribution solely due to the injection of
~
ocity into the forward pass. Figure
198"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4330097087378641,"5 shows that this pattern holds in aggregate. In all settings, we see that the outputs of the intended
199"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4349514563106796,"functions are strongly promoted by adding the corresponding ~o vectors. By the last layer, for world
200"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4368932038834951,"and state capitals, the mean reciprocal rank of the target city name across all examples improves from
201"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4388349514563107,"roughly the 10th to the 4th-highest ranked word and 20th and 3rd-ranked words respectively.
202"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4407766990291262,"We also see the promotion of the proper past tense verbs by
~
opast. The reciprocal ranks improve
203"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.44271844660194176,"similarly for both regular (approx. 7th to 3rd rank) and irregular verbs (approx. 6th to 3rd), indicating
204"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4446601941747573,"that the relationship between tenses is encoded similarly by the model for these two types.
~
oupper
205"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.44660194174757284,"promotes the capitalized version of the test token almost every time, although the target word starts at
206"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.44854368932038835,"a higher rank (on average, rank 5). These results together show that regardless of the surrounding
207"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.45048543689320386,"context, and regardless of the argument to which it is applied, ~o vectors consistently apply the
208"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.4524271844660194,"expected functions. Since each vector was originally extracted from the model’s processing of
209"
WE FOCUS ON ONE MODEL BECAUSE MANUAL ANALYSIS WAS REQUIRED IN ORDER TO DETERMINE HOW TO PERFORM THE,0.45436893203883494,"a single naturalistic input, this generalizability suggests signiﬁcant structure and cross-context
210"
ABSTRACT,0.4563106796116505,"abstraction within the learned embedding-space.
211"
ABSTRACT,0.458252427184466,"Common Errors: While the above trend clearly holds on the aggregate, the intervention is not
212"
ABSTRACT,0.4601941747572815,"perfect for individual cases. The most common error is that the intervention has no real effect. In
213"
ABSTRACT,0.4621359223300971,"the in-domain (out-domain) settings, this occurred in about 37% (20%) of capital cities, 4% (5%)
214"
ABSTRACT,0.4640776699029126,"on uppercasing, and 19% (22%) for past tensing. We believe the rate is so much higher for world
215"
ABSTRACT,0.46601941747572817,"capitals because the model did not have a strong association between certain country-capital pairs
216"
ABSTRACT,0.4679611650485437,"from pretraining, e.g, for less frequently mentioned countries. Typically, in these cases, the top token
217"
ABSTRACT,0.46990291262135925,"remains the argument, but sometimes becomes some random other city, for example, predicting the
218"
ABSTRACT,0.47184466019417476,"capital of Armenia is Vienna. We also ﬁnd that the way tokenization splits the argument and target
219"
ABSTRACT,0.47378640776699027,"with the idea that residual connections encourage each layer to move gradually towards a point of lower loss
[Jastrzebski et al., 2017]."
ABSTRACT,0.47572815533980584,"words affects the ability of the ~o vector to work and is another source of errors. This is discussed
220"
ABSTRACT,0.47766990291262135,"further in Appendix E.
221"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.4796116504854369,"5
The Role of FFNs in Out-of-Context Retrieval
222"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.4815533980582524,"So far, we have shown that FFN output vectors can encode functions that transfer across contexts.
223"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.48349514563106794,"Here we investigate whether the mechanism we identify applies in general to associations of this
224"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.4854368932038835,"type, or rather if such functionality can be implemented by the attention mechanism instead. Shared
225"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.487378640776699,"among the tasks we study is the requirement to recall a token that does not appear in the given context
226"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.4893203883495146,"(abstractive tasks). In this section we show that mid-higher layer FFNs are crucial for this process.
227"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.4912621359223301,"When the answer to the question does appear in context (extractive tasks), we ﬁnd that ablating a
228"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.49320388349514566,"subset of FFNs has a comparatively minor effect on performance, indicating that they are relatively
229"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.49514563106796117,"modular and there is a learned division of labor within the model. This observation holds across the
230"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.4970873786407767,"decoder-only LMs tested in this paper, but is particularly salient in the larger/deeper networks. This
231"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.49902912621359224,"breakdown is consistent with previous work ﬁnding that FFNs store facts learned from pre-training
232"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.5009708737864078,"[Geva et al., 2021a, Meng et al., 2022b,c] and attention heads copy from the previous context [Wang
233"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.5029126213592233,"et al., Olsson et al., 2022].
234"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.5048543689320388,"5.1
Abstractive vs. Extractive Tasks
235"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.5067961165048543,"Extractive Tasks: Extractive tasks are those in which the exact tokens required to answer a prompt
236"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.5087378640776699,"can be found in the input context. These tasks can thus be solved by parsing the local context alone,
237"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.5106796116504855,"and thus do not necessarily require the model to apply a function of the type we have focused on in
238"
THE ROLE OF FFNS IN OUT-OF-CONTEXT RETRIEVAL,0.512621359223301,"this paper (e.g., a function like get_capital).
239"
ABSTRACT,0.5145631067961165,"Abstractive Tasks: Are those in which the answer to a prompt is not given in the input context
240"
ABSTRACT,0.516504854368932,"and must be retrieved from pretraining memory. Our results suggest this is done primarily through
241"
ABSTRACT,0.5184466019417475,"argument-function processing, requiring function application through (typically) FFN updates as
242"
ABSTRACT,0.5203883495145631,"described in Section 3.
243"
ABSTRACT,0.5223300970873787,"We provide examples with their associated GPT2-Medium layerwise decodings in Figure 6. We
244"
ABSTRACT,0.5242718446601942,"expect that the argument formation and function application stages of processing occur primarily in
245"
ABSTRACT,0.5262135922330097,"abstractive tasks. Indeed, in Appendix A, we show that the characteristic argument-answer X pattern
246"
ABSTRACT,0.5281553398058253,"disappears on extractive inputs. We hypothesize that applying out-of-context transformations to the
247"
ABSTRACT,0.5300970873786408,"predicted token representation is one of the primary functions of FFNs in the mid-to-late layers, and
248"
ABSTRACT,0.5320388349514563,"that removing them should only have a major effect on tasks that require out-of-context retrieval.
249"
ABSTRACT,0.5339805825242718,"Top Tokens per Layer
Abstractive Task
Extractive Task Layer"
ABSTRACT,0.5359223300970873,"Q: What is the capital
of Somalia?
A: Mogadishu
Q: What is the capital
of Poland?
A:"
ABSTRACT,0.537864077669903,"The capital of
Somalia is Mogadishu.
The capital of Poland
is Warsaw.
Q: What is the capital
of Somalia?
A: Mogadishu
Q: What is the capital
of Poland?
A:
...
...
...
14
St
St
15
Poland
St
16
Poland
Warsaw
17
Poland
Warsaw
18
Poland
Warsaw
19
Warsaw
Warsaw
20
Warsaw
Warsaw
21
Warsaw
Warsaw
22
Warsaw
Warsaw
23
Warsaw
Warsaw"
ABSTRACT,0.5398058252427185,"Figure 6: The abstractive task undergoes ar-
gument formation (blue) and function appli-
cation (red), while the extractive task imme-
diately saturates (yellow). 250"
EFFECT OF ABLATING FFNS,0.541747572815534,"5.2
Effect of Ablating FFNs
251"
EFFECT OF ABLATING FFNS,0.5436893203883495,"Data:
Consider the example shown in Section 2.2
252"
EFFECT OF ABLATING FFNS,0.545631067961165,"demonstrating the
~
oupper function. By providing the
253"
EFFECT OF ABLATING FFNS,0.5475728155339806,"answer to the in-context example as “ Silver"", we
254"
EFFECT OF ABLATING FFNS,0.5495145631067961,"make the task abstractive by requiring the in-context
255"
EFFECT OF ABLATING FFNS,0.5514563106796116,"token “ brown"" to be transformed to “ Brown"" in the
256"
EFFECT OF ABLATING FFNS,0.5533980582524272,"test example. However, if we provide the in-context
257"
EFFECT OF ABLATING FFNS,0.5553398058252427,"label as “ silver"", the task becomes extractive, as the
258"
EFFECT OF ABLATING FFNS,0.5572815533980583,"expected answer becomes “ brown"". We create an
259"
EFFECT OF ABLATING FFNS,0.5592233009708738,"extractive version of this dataset by lowercasing the
260"
EFFECT OF ABLATING FFNS,0.5611650485436893,"example answer. All data is presented to the model
261"
EFFECT OF ABLATING FFNS,0.5631067961165048,"with a single example (one-shot). Notice that the
262"
ABSTRACT,0.5650485436893203,"abstractive and extractive examples only differ by a
263"
ABSTRACT,0.566990291262136,"single character and are thus minimally different.
264"
ABSTRACT,0.5689320388349515,"We repeat this experiment on the world capitals task
265"
ABSTRACT,0.570873786407767,"by adding the preﬁx “The capital of A is B. The
266"
ABSTRACT,0.5728155339805825,"capital of C is D"" to each input. Notice, however,
267"
ABSTRACT,0.574757281553398,"that since the answer is provided explicitly, the task
268"
ABSTRACT,0.5766990291262136,"is much easier for the models in the extractive case.
269"
ABSTRACT,0.5786407766990291,"Figure 7: Removing FFNs negatively affects performance when the task is abstractive: the in-context
label is an out-of-context transformation of the in-context prompt (e.g., “ silver” in context, answer
given as “ Silver”). In comparison, on the extractive dataset, performance is robust to a large
proportion of FFNs being removed. Other models tested are shown in Appendix B"
ABSTRACT,0.5805825242718446,"Procedure:
We run the one-shot extractive and abstractive datasets on the full models, and then
270"
ABSTRACT,0.5825242718446602,"repeatedly remove an additional 1/6th of all FFNs from the top down (e.g., in 24 layer GPT2-Medium:
271"
ABSTRACT,0.5844660194174758,"removing the 20-24th FFNs, then the 15-24th, etc.).
272"
ABSTRACT,0.5864077669902913,"Results:
Our results are shown in Figure 7. Despite the fact that the inputs in the abstractive
273"
ABSTRACT,0.5883495145631068,"and extractive datasets only slightly differ (by a single character in the colored objects case) we
274"
ABSTRACT,0.5902912621359223,"ﬁnd that performance plummets on the abstractive task as FFNs are ablated, while accuracy on the
275"
ABSTRACT,0.5922330097087378,"extractive task drops much more slowly. For example, even after 24 FFN sublayers are removed from
276"
ABSTRACT,0.5941747572815534,"Bloom (totaling 39B parameters) extractive task accuracy for the colored objects dataset drops 17%
277"
ABSTRACT,0.596116504854369,"from the full model’s performance, while abstractive accuracy drops 73% (down to 1% accuracy).
278"
ABSTRACT,0.5980582524271845,"The case is similar across model sizes and pretraining corpora; we include results on additional
279"
ABSTRACT,0.6,"models in Appendix B. This indicates that we can isolate the effect of locating and retrieving out of
280"
ABSTRACT,0.6019417475728155,"context tokens in this setting to the FFNs. Additionally, because the model retains reasonably strong
281"
ABSTRACT,0.6038834951456311,"performance compared to using the full model, we do not ﬁnd convincing evidence that the later layer
282"
ABSTRACT,0.6058252427184466,"FFNs are contributing to the extractive task performance, supporting the idea of modularity within
283"
ABSTRACT,0.6077669902912621,"the network.
284"
RELATED WORK,0.6097087378640776,"6
Related Work
285"
RELATED WORK,0.6116504854368932,"Recent work has contributed to understanding language models by studying the role of different
286"
RELATED WORK,0.6135922330097088,"modules in the transformer architecture in language modeling. In particular, the attention layers
287"
RELATED WORK,0.6155339805825243,"[Olsson et al., 2022, Kobayashi et al., 2020, Wang et al.] and more notably for this work, the FFN
288"
RELATED WORK,0.6174757281553398,"modules, which are frequently associated with factual recall and knowledge storage [Geva et al.,
289"
RELATED WORK,0.6194174757281553,"2021a, Meng et al., 2022a,c]. Although how language models store and use knowledge has been
290"
RELATED WORK,0.6213592233009708,"studied more generally as well [Petroni et al., 2019, Cao et al., 2021, Dai et al., 2022, Bouraoui et al.,
291"
RELATED WORK,0.6233009708737864,"2019, Burns et al., 2022, Dalvi et al., 2022, Da et al., 2021] as well as in static embeddings [Dufter
292"
RELATED WORK,0.625242718446602,"et al., 2021]. Recent work in mechanistic interpretability aims to fully reverse engineer how LMs
293"
RELATED WORK,0.6271844660194175,"perform some behaviors. Our work builds on the ﬁnding that FFN layers promote concepts in the
294"
RELATED WORK,0.629126213592233,"vocabulary space [Geva et al., 2022a] by breaking down the process the model uses to do this in
295"
RELATED WORK,0.6310679611650486,"context. Bansal et al. [2022] perform ablation studies to test the importance of attention and FFN
296"
RELATED WORK,0.6330097087378641,"layers on in-context learning tasks, here we offer an explanation for their role in some cases. Other
297"
RELATED WORK,0.6349514563106796,"work analyze information ﬂow within an LM to study how representations are built through the layers
298"
RELATED WORK,0.6368932038834951,"[Voita et al., 2019, Tenney et al., 2019] and show distinct points of processing in the model. We also
299"
RELATED WORK,0.6388349514563106,"follow this approach, but our analysis focuses on interpreting how models use individual updates
300"
RELATED WORK,0.6407766990291263,"within the forward pass, rather than probing for what information is encoded and potentially used to
301"
RELATED WORK,0.6427184466019418,"make predictions. Ilharco et al. [2023] show that vector arithmetic can be performed with the weights
302"
RELATED WORK,0.6446601941747573,"of ﬁnetuned models to compose tasks, similar to how ~o vectors can induce functions in the activation
303"
RELATED WORK,0.6466019417475728,"space of the model.
304"
DISCUSSION,0.6485436893203883,"7
Discussion
305"
DISCUSSION,0.6504854368932039,"In this work, we describe a mechanism that is partially responsible for LMs ability to recall
306"
DISCUSSION,0.6524271844660194,"factual associations. We conceptualize these recalls as the application of some function (e.g.,
307"
DISCUSSION,0.654368932038835,"get_capital(x) = y and ﬁnd that the next-token prediction goes through several discrete
308"
DISCUSSION,0.6563106796116505,"stages of processing in which the prediction ﬁrst represents the argument x (e.g., Poland) before
309"
DISCUSSION,0.658252427184466,"applying that function with an additive update to get the ﬁnal answer y (Warsaw). A core challenge
310"
DISCUSSION,0.6601941747572816,"in interpreting neural networks is determining whether the information attributed to certain model
311"
DISCUSSION,0.6621359223300971,"components is actually used for that purpose during inference [Hase and Bansal, 2022, Leavitt and
312"
DISCUSSION,0.6640776699029126,"Morcos, 2020]. While previous work has implicated FFNs in recalling factual associations [Geva
313"
DISCUSSION,0.6660194174757281,"et al., 2022a, Meng et al., 2022a], we show through intervention experiments that we can manipulate
314"
DISCUSSION,0.6679611650485436,"the information ﬂowing through the model during these stages. Speciﬁcally, we show that it is
315"
DISCUSSION,0.6699029126213593,"possible to capture the output vector of an FFN from a single forward pass on a single in-context
316"
DISCUSSION,0.6718446601941748,"learning example, and that the captured vector can be used to apply the same function to new argu-
317"
DISCUSSION,0.6737864077669903,"ments (e.g., other countries) in totally different contexts. This process provides a surprisingly simple
318"
DISCUSSION,0.6757281553398058,"explanation for the internal subprocesses used by LMs to recall factual associations and resembles
319"
DISCUSSION,0.6776699029126214,"vector arithmetic observed in static word embeddings. Our ﬁndings invite future work aimed at
320"
DISCUSSION,0.6796116504854369,"understanding why, and under what conditions, LMs learn to use this mechanism when they are
321"
DISCUSSION,0.6815533980582524,"capable of solving such tasks using, e.g., adhoc memorization.
322"
DISCUSSION,0.683495145631068,"A limitation that we observe is that the process for carrying out the ~o intervention depends on
323"
DISCUSSION,0.6854368932038835,"hyperparameters which are often model-speciﬁc (i.e., the exact stimuli used to extract the intervention,
324"
DISCUSSION,0.6873786407766991,"and the layer(s) at which to perform the intervention). We provide our most detailed investigation on
325"
DISCUSSION,0.6893203883495146,"GPT2-Medium, which clearly illustrates the phenomenon. Our experiments on stages of processing
326"
DISCUSSION,0.6912621359223301,"with GPT-J suggest that the same phenomena is in play, although (as discussed in Section 4 and
327"
DISCUSSION,0.6932038834951456,"Appendix A), the procedures we derive for interventions on GPT2-Medium do not transfer perfectly.
328"
DISCUSSION,0.6951456310679611,"Speciﬁcally, we can strongly reproduce the intervention results on uppercasing for GPT-J; results on
329"
DISCUSSION,0.6970873786407767,"the other two tasks are positive but with overall weaker effects. This requirement of model-speciﬁc
330"
DISCUSSION,0.6990291262135923,"customization is common in similar mechanistic interpretability work, e.g., [Meng et al., 2022a, Wang
331"
DISCUSSION,0.7009708737864078,"et al., 2022, Geva et al., 2022b], and a prioritiy in future work must be to identify common patterns
332"
DISCUSSION,0.7029126213592233,"across these individual studies which reduce the need to repeat such effort on each new model. That
333"
DISCUSSION,0.7048543689320388,"said, in this work and other similar efforts, a single positive example as a proof of concept is often
334"
DISCUSSION,0.7067961165048544,"sufﬁcient to advance understanding and spur future work that improves robustness across models.
335"
DISCUSSION,0.7087378640776699,"In the long term, ﬁndings like those presented here have implications for improving the trustworthiness
336"
DISCUSSION,0.7106796116504854,"of LMs in production. If we can understand how models break down complex problems into simple
337"
DISCUSSION,0.7126213592233009,"and predictable subprocesses, we can help more readily audit their behavior. Interpreting the
338"
DISCUSSION,0.7145631067961165,"processing signatures of model behaviors might offer an avenue via which to audit and intervene
339"
DISCUSSION,0.7165048543689321,"at runtime in order to prevent unwanted behavior. Moreover, understanding which relations FFNs
340"
DISCUSSION,0.7184466019417476,"encode could aid work in fact location and editing. Contemporaneous work [Geva et al., 2023]
341"
DISCUSSION,0.7203883495145631,"has studied a different mechanism for factual recall in LMs, but it is unclear how and when these
342"
DISCUSSION,0.7223300970873786,"mechanisms interact.
343"
CONCLUSION,0.7242718446601941,"8
Conclusion
344"
CONCLUSION,0.7262135922330097,"We contribute to a growing body of work on interpreting how the internal processes of language
345"
CONCLUSION,0.7281553398058253,"models (LMs) produce some behavior. On three in-context learning tasks, we observe that the next-
346"
CONCLUSION,0.7300970873786408,"token prediction appears to undergo several stages of processing in which LMs represent arguments
347"
CONCLUSION,0.7320388349514563,"to functions in their residual streams. This process occurs in models ranging in size from 124M to
348"
CONCLUSION,0.7339805825242719,"176B parameters. On GPT2, We study instances where the additive update is made by the output
349"
CONCLUSION,0.7359223300970874,"vectors (~o vectors) of feed-forward networks (FFNs). We show that for all tasks we test, ~o vectors
350"
CONCLUSION,0.7378640776699029,"calculated by the model in the process of solving some task can be extracted and replace the FFN
351"
CONCLUSION,0.7398058252427184,"updates of the model to solve novel instances of that task, providing evidence that LMs can learn
352"
CONCLUSION,0.7417475728155339,"self-contained and context-independent functions from pretraining.
353"
REFERENCES,0.7436893203883496,"References
354"
REFERENCES,0.7456310679611651,"Hritik Bansal, Karthik Gopalakrishnan, Saket Dingliwal, Sravan Bodapati, Katrin Kirchhoff, and
355"
REFERENCES,0.7475728155339806,"Dan Roth. Rethinking the Role of Scale for In-Context Learning: An Interpretability-based Case
356"
REFERENCES,0.7495145631067961,"Study at 66 Billion Scale, December 2022. URL http://arxiv.org/abs/2212.09095.
357"
REFERENCES,0.7514563106796116,"arXiv:2212.09095 [cs].
358"
REFERENCES,0.7533980582524272,"Zied Bouraoui, Jose Camacho-Collados, and Steven Schockaert. Inducing Relational Knowledge
359"
REFERENCES,0.7553398058252427,"from BERT, November 2019. URL https://arxiv.org/abs/1911.12753v1.
360"
REFERENCES,0.7572815533980582,"Collin Burns, Haotian Ye, Dan Klein, and Jacob Steinhardt. Discovering Latent Knowledge in
361"
REFERENCES,0.7592233009708738,"Language Models Without Supervision, December 2022. URL http://arxiv.org/abs/
362"
REFERENCES,0.7611650485436893,"2212.03827. arXiv:2212.03827 [cs].
363"
REFERENCES,0.7631067961165049,"Boxi Cao, Hongyu Lin, Xianpei Han, Le Sun, Lingyong Yan, Meng Liao, Tong Xue, and Jin
364"
REFERENCES,0.7650485436893204,"Xu. Knowledgeable or Educated Guess? Revisiting Language Models as Knowledge Bases. In
365"
REFERENCES,0.7669902912621359,"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the
366"
REFERENCES,0.7689320388349514,"11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),
367"
REFERENCES,0.7708737864077669,"pages 1860–1874, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/
368"
REFERENCES,0.7728155339805826,"v1/2021.acl-long.146. URL https://aclanthology.org/2021.acl-long.146.
369"
REFERENCES,0.7747572815533981,"Jeff Da, Ronan Le Bras, Ximing Lu, Yejin Choi, and Antoine Bosselut. Analyzing Commonsense
370"
REFERENCES,0.7766990291262136,"Emergence in Few-shot Knowledge Models. September 2021. URL https://openreview.
371"
REFERENCES,0.7786407766990291,"net/forum?id=StHCELh9PVE.
372"
REFERENCES,0.7805825242718447,"Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, and Furu Wei. Knowledge neurons
373"
REFERENCES,0.7825242718446602,"in pretrained transformers. In Proceedings of the 60th Annual Meeting of the Association for
374"
REFERENCES,0.7844660194174757,"Computational Linguistics (Volume 1: Long Papers), pages 8493–8502, 2022.
375"
REFERENCES,0.7864077669902912,"Fahim Dalvi, Abdul Rafae Khan, Firoj Alam, Nadir Durrani, Jia Xu, and Hassan Sajjad. Discover-
376"
REFERENCES,0.7883495145631068,"ing Latent Concepts Learned in BERT, May 2022. URL http://arxiv.org/abs/2205.
377"
REFERENCES,0.7902912621359224,"07237. arXiv:2205.07237 [cs].
378"
REFERENCES,0.7922330097087379,"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep
379"
REFERENCES,0.7941747572815534,"bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of
380"
REFERENCES,0.7961165048543689,"the North American Chapter of the Association for Computational Linguistics: Human Language
381"
REFERENCES,0.7980582524271844,"Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota, June
382"
REFERENCES,0.8,"2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https:
383"
REFERENCES,0.8019417475728156,"//aclanthology.org/N19-1423.
384"
REFERENCES,0.8038834951456311,"Philipp Dufter, Nora Kassner, and Hinrich Schütze. Static Embeddings as Efﬁcient Knowledge
385"
REFERENCES,0.8058252427184466,"Bases? In Proceedings of the 2021 Conference of the North American Chapter of the Association
386"
REFERENCES,0.8077669902912621,"for Computational Linguistics: Human Language Technologies, pages 2353–2363, Online, June
387"
REFERENCES,0.8097087378640777,"2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.186. URL
388"
REFERENCES,0.8116504854368932,"https://aclanthology.org/2021.naacl-main.186.
389"
REFERENCES,0.8135922330097087,"N Elhage, N Nanda, C Olsson, T Henighan, N Joseph, B Mann, A Askell, Y Bai, A Chen, T Conerly,
390"
REFERENCES,0.8155339805825242,"et al. A mathematical framework for transformer circuits. Transformer Circuits Thread, 2021.
391"
REFERENCES,0.8174757281553398,"Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy. Transformer feed-forward layers are
392"
REFERENCES,0.8194174757281554,"key-value memories. In Proceedings of the 2021 Conference on Empirical Methods in Natural
393"
REFERENCES,0.8213592233009709,"Language Processing, pages 5484–5495, 2021a.
394"
REFERENCES,0.8233009708737864,"Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy. Transformer Feed-Forward Layers Are
395"
REFERENCES,0.8252427184466019,"Key-Value Memories. In Proceedings of the 2021 Conference on Empirical Methods in Natural
396"
REFERENCES,0.8271844660194175,"Language Processing, pages 5484–5495, Online and Punta Cana, Dominican Republic, November
397"
REFERENCES,0.829126213592233,"2021b. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.446. URL
398"
REFERENCES,0.8310679611650486,"https://aclanthology.org/2021.emnlp-main.446.
399"
REFERENCES,0.8330097087378641,"Mor Geva, Avi Caciularu, Kevin Ro Wang, and Yoav Goldberg. Transformer feed-forward layers
400"
REFERENCES,0.8349514563106796,"build predictions by promoting concepts in the vocabulary space. arXiv preprint arXiv:2203.14680,
401"
REFERENCES,0.8368932038834952,"2022a.
402"
REFERENCES,0.8388349514563107,"Mor Geva, Avi Caciularu, Kevin Ro Wang, and Yoav Goldberg. Transformer Feed-Forward Layers
403"
REFERENCES,0.8407766990291262,"Build Predictions by Promoting Concepts in the Vocabulary Space, October 2022b. URL http:
404"
REFERENCES,0.8427184466019417,"//arxiv.org/abs/2203.14680. arXiv:2203.14680 [cs].
405"
REFERENCES,0.8446601941747572,"Mor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson. Dissecting recall of factual
406"
REFERENCES,0.8466019417475729,"associations in auto-regressive language models, 2023.
407"
REFERENCES,0.8485436893203884,"Peter Hase and Mohit Bansal. When can models learn from explanations? a formal framework for
408"
REFERENCES,0.8504854368932039,"understanding the roles of explanation data. In Proceedings of the First Workshop on Learning
409"
REFERENCES,0.8524271844660194,"with Natural Language Supervision, pages 29–39, Dublin, Ireland, May 2022. Association for
410"
REFERENCES,0.8543689320388349,"Computational Linguistics. doi: 10.18653/v1/2022.lnls-1.4. URL https://aclanthology.
411"
REFERENCES,0.8563106796116505,"org/2022.lnls-1.4.
412"
REFERENCES,0.858252427184466,"Gabriel Ilharco, Marco Tulio Ribeiro, Mitchell Wortsman, Suchin Gururangan, Ludwig Schmidt,
413"
REFERENCES,0.8601941747572815,"Hannaneh Hajishirzi, and Ali Farhadi. Editing models with task arithmetic. ICLR, 2023.
414"
REFERENCES,0.8621359223300971,"Stanisław Jastrzebski, Devansh Arpit, Nicolas Ballas, Vikas Verma, Tong Che, and Yoshua Bengio.
415"
REFERENCES,0.8640776699029126,"Residual connections encourage iterative inference. In International Conference on Learning
416"
REFERENCES,0.8660194174757282,"Representations, 2017.
417"
REFERENCES,0.8679611650485437,"Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, and Kentaro Inui. Attention is not only a weight:
418"
REFERENCES,0.8699029126213592,"Analyzing transformers with vector norms. In Proceedings of the 2020 Conference on Empirical
419"
REFERENCES,0.8718446601941747,"Methods in Natural Language Processing (EMNLP), pages 7057–7075, Online, November 2020.
420"
REFERENCES,0.8737864077669902,"Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.574. URL https:
421"
REFERENCES,0.8757281553398059,"//aclanthology.org/2020.emnlp-main.574.
422"
REFERENCES,0.8776699029126214,"Matthew L Leavitt and Ari Morcos. Towards falsiﬁable interpretability research. arXiv preprint
423"
REFERENCES,0.8796116504854369,"arXiv:2010.12016, 2020.
424"
REFERENCES,0.8815533980582524,"Kenneth Li, Aspen K Hopkins, David Bau, Fernanda Viégas, Hanspeter Pﬁster, and Martin Watten-
425"
REFERENCES,0.883495145631068,"berg. Emergent world representations: Exploring a sequence model trained on a synthetic task.
426"
REFERENCES,0.8854368932038835,"arXiv preprint arXiv:2210.13382, 2022.
427"
REFERENCES,0.887378640776699,"Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov.
Locating and Editing Fac-
428"
REFERENCES,0.8893203883495145,"tual Associations in GPT, October 2022a. URL http://arxiv.org/abs/2202.05262.
429"
REFERENCES,0.8912621359223301,"arXiv:2202.05262 [cs] version: 4.
430"
REFERENCES,0.8932038834951457,"Kevin Meng, David Bau, Alex J Andonian, and Yonatan Belinkov. Locating and editing factual
431"
REFERENCES,0.8951456310679612,"associations in gpt. In Advances in Neural Information Processing Systems, 2022b.
432"
REFERENCES,0.8970873786407767,"Kevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov, and David Bau. Mass editing
433"
REFERENCES,0.8990291262135922,"memory in a transformer. arXiv preprint arXiv:2210.07229, 2022c.
434"
REFERENCES,0.9009708737864077,"Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efﬁcient estimation of word representa-
435"
REFERENCES,0.9029126213592233,"tions in vector space. arXiv preprint arXiv:1301.3781, 2013.
436"
REFERENCES,0.9048543689320389,"nostalgebraist. interpreting GPT: the logit lens. 2020. URL https://www.lesswrong.com/
437"
REFERENCES,0.9067961165048544,"posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens.
438"
REFERENCES,0.9087378640776699,"Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan,
439"
REFERENCES,0.9106796116504854,"Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Dawn Drain, Deep Ganguli,
440"
REFERENCES,0.912621359223301,"Zac Hatﬁeld-Dodds, Danny Hernandez, Scott Johnston, Andy Jones, Jackson Kernion, Liane
441"
REFERENCES,0.9145631067961165,"Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish,
442"
REFERENCES,0.916504854368932,"and Chris Olah. In-context learning and induction heads. Transformer Circuits Thread, 2022.
443"
REFERENCES,0.9184466019417475,"https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html.
444"
REFERENCES,0.920388349514563,"Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and
445"
REFERENCES,0.9223300970873787,"Luke Zettlemoyer. Deep contextualized word representations. In Proceedings of the 2018 Confer-
446"
REFERENCES,0.9242718446601942,"ence of the North American Chapter of the Association for Computational Linguistics: Human
447"
REFERENCES,0.9262135922330097,"Language Technologies, Volume 1 (Long Papers), pages 2227–2237, New Orleans, Louisiana,
448"
REFERENCES,0.9281553398058252,"June 2018. Association for Computational Linguistics.
doi: 10.18653/v1/N18-1202.
URL
449"
REFERENCES,0.9300970873786408,"https://aclanthology.org/N18-1202.
450"
REFERENCES,0.9320388349514563,"Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu,
451"
REFERENCES,0.9339805825242719,"and Alexander Miller. Language Models as Knowledge Bases?
In Proceedings of the 2019
452"
REFERENCES,0.9359223300970874,"Conference on Empirical Methods in Natural Language Processing and the 9th International Joint
453"
REFERENCES,0.9378640776699029,"Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2463–2473, Hong Kong,
454"
REFERENCES,0.9398058252427185,"China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1250.
455"
REFERENCES,0.941747572815534,"URL https://aclanthology.org/D19-1250.
456"
REFERENCES,0.9436893203883495,"Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language
457"
REFERENCES,0.945631067961165,"models are unsupervised multitask learners.
458"
REFERENCES,0.9475728155339805,"Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ili´c, Daniel Hesslow, Roman
459"
REFERENCES,0.9495145631067962,"Castagné, Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al. Bloom: A 176b-
460"
REFERENCES,0.9514563106796117,"parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100, 2022.
461"
REFERENCES,0.9533980582524272,"Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam
462"
REFERENCES,0.9553398058252427,"Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. Beyond the
463"
REFERENCES,0.9572815533980582,"imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint
464"
REFERENCES,0.9592233009708738,"arXiv:2206.04615, 2022.
465"
REFERENCES,0.9611650485436893,"Ian Tenney, Dipanjan Das, and Ellie Pavlick. Bert rediscovers the classical nlp pipeline. In Pro-
466"
REFERENCES,0.9631067961165048,"ceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages
467"
REFERENCES,0.9650485436893204,"4593–4601, 2019.
468"
REFERENCES,0.9669902912621359,"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
469"
REFERENCES,0.9689320388349515,"Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing
470"
REFERENCES,0.970873786407767,"systems, 30, 2017.
471"
REFERENCES,0.9728155339805825,"Elena Voita, Rico Sennrich, and Ivan Titov. The Bottom-up Evolution of Representations in the
472"
REFERENCES,0.974757281553398,"Transformer: A Study with Machine Translation and Language Modeling Objectives. In Pro-
473"
REFERENCES,0.9766990291262136,"ceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the
474"
REFERENCES,0.9786407766990292,"9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages
475"
REFERENCES,0.9805825242718447,"4396–4406, Hong Kong, China, November 2019. Association for Computational Linguistics. doi:
476"
REFERENCES,0.9825242718446602,"10.18653/v1/D19-1448. URL https://aclanthology.org/D19-1448.
477"
REFERENCES,0.9844660194174757,"Ben Wang and Aran Komatsuzaki. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model.
478"
REFERENCES,0.9864077669902913,"https://github.com/kingoflolz/mesh-transformer-jax, May 2021.
479"
REFERENCES,0.9883495145631068,"Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt. Inter-
480"
REFERENCES,0.9902912621359223,"pretability in the Wild: a Circuit for Indirect Object Identiﬁcation in GPT-2 small, November 2022.
481"
REFERENCES,0.9922330097087378,"arXiv:2211.00593 [cs].
482"
REFERENCES,0.9941747572815534,"Kevin Ro Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt.
483"
REFERENCES,0.996116504854369,"Interpretability in the wild: a circuit for indirect object identiﬁcation in gpt-2 small. In NeurIPS
484"
REFERENCES,0.9980582524271845,"ML Safety Workshop.
485"
