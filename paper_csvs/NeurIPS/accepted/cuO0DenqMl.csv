Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.002109704641350211,"Gradient boosting is a sequential ensemble method that fits a new weaker learner
to pseudo residuals at each iteration. We propose Wasserstein gradient boosting, a
novel extension of gradient boosting, which fits a new weak learner to alternative
pseudo residuals that are Wasserstein gradients of loss functionals of probability
distributions assigned at each input. It solves distribution-valued supervised learn-
ing, where the output values of the training dataset are probability distributions.
In classification and regression, a model typically returns, for each input, a point
estimate of a parameter of a noise distribution specified for a response variable,
such as the class probability parameter of a categorical distribution specified for a
response label. A main application of Wasserstein gradient boosting in this paper
is tree-based evidential learning, which returns a distributional estimate of the
response parameter for each input. We empirically demonstrate the competitive
performance of the probabilistic prediction by Wasserstein gradient boosting in
comparison with existing uncertainty quantification methods."
INTRODUCTION,0.004219409282700422,"1
Introduction"
INTRODUCTION,0.006329113924050633,"Gradient boosting is a celebrated machine learning algorithm that has achieved considerable success
with tabular data [1]. Gradient boosting has been extensively used for point forecasts and probabilistic
classification, yet a relatively small number of studies have been concerned with the predictive
uncertainty of gradient boosting. Predictive uncertainty of machine learning models plays a growing
role in today’s real-world production systems [2]. It is vital for safety-critical systems, such as
medical diagnoses [3] and autonomous driving [4], to assess the potential risk of their actions that
partially or entirely rely on predictions from their models. Gradient boosting has already been applied
in a diverse range of real-world applications, including click prediction [5], ranking systems [6],
scientific discovery [7], and data competition [8]. There is a pressing need for methodology to harness
the power of gradient boosting to predictive uncertainty quantification."
INTRODUCTION,0.008438818565400843,"In classification and regression, we typically specify a noise distribution p(y | θ) of a response
variable y and use a model to return a point estimate θ(x) of the response parameter for each input x.
In recent years, the importance of capturing uncertainty in the model output θ(x) has increasingly
been emphasised [2]. A variety of approaches have been proposed to obtain a distributional estimate
p(θ | x) of the response parameter for each input x [e.g. 9, 10, 11]. For example, Bayesian neural
networks (BNNs) quantify uncertainty in network weights and propagate it to the space of network
outputs. Marginalising the predictive distribution p(y | θ) over the distributional estimate p(θ | x)
has been demonstrated to confer enhanced predictive accuracy and robustness against adversarial
attacks [11]. Furthermore, the dispersion of the distributional estimate has been used as a powerful
indicator for out-of-distribution (OOD) detection [12]."
INTRODUCTION,0.010548523206751054,"(a) 0 weak learner trained
(b) 15 weak learners trained
(c) 100 weak learners trained"
INTRODUCTION,0.012658227848101266,"Figure 1: Illustration of WGBoost trained on a set {xi, µi}10
i=1 whose inputs are 10 grid points in
[−3.5, 3.5] and each output distribution is a normal distribution µi(θ) = N(θ | sin(xi), 0.5) over
θ ∈R. The blue area indicates the 95% high probability region of the conditional distribution
N(θ | sin(x), 0.5). WGBoost returns N = 10 particles (red lines) to predict the output distribution
for each input x. This illustration uses the Gaussian kernel regressor for every weaker learner."
INTRODUCTION,0.014767932489451477,"In this context, a line of research based on the concept of evidential learning has recently gained
significant attention [11, 13, 14, 15]. The idea can be broadly interpreted as making use of the
‘individual-level’ posterior p(θ | yi) of the response parameter θ conditional on each individual datum
yi, which arises from the response-distribution likelihood p(yi | θ) and a user-specified prior p(θ). If
each individual-level posterior falls into a closed form characterised by some hyperparameter, neural
networks can be trained by using the finite-dimensional hyperparameter as a target value for each
input. Outstanding performance and computational efficiency of the existing approaches have been
delivered in a wide spectrum of engineering and medical applications [16, 17, 18, 19]. However,
the existing approaches are limited to neural networks and to the case where every individual-level
posterior is in closed form so that the finite-dimensional hyperparameter can be predicted by proxy.
In general, posterior distributions are known only up to their normalising constants and, therefore,
require an approximation typically by particles [20]."
INTRODUCTION,0.016877637130801686,"Without closed-form expression, each individual-level posterior needs to be treated as an infinite-
dimensional output for each input. This challenge poses the following fundamental question:"
INTRODUCTION,0.0189873417721519,"Consider a supervised learning setting whose outputs are probability distributions.
Given a training set of input values and output distributions {xi, µi}D
i=1, can we
build a model that receives an input x and returns a nonparametric prediction of
the output distribution?"
INTRODUCTION,0.02109704641350211,"Motivated by this question, we propose a general framework of Wasserstein gradient boosting
(WGBoost). WGBoost receives an input and returns a particle approximation of the output distribution.
Figure 1 illustrates inputs and outputs of WGBoost. In this paper, we focus on application of WGBoost
to evidential learning, where the individual-level posterior p(θ | yi) of the response parameter θ is
used as the output distribution µi for each input xi in the training set. Figure 2 compares the pipeline
of evidential learning based on WGBoost with that of Bayesian learning."
INTRODUCTION,0.023206751054852322,Contributions Our contributions are summarised as follows:
INTRODUCTION,0.02531645569620253,"1. Methodology of WGBoost: Section 2 establishes the general framework of WGBoost. It
is a novel family of gradient boosting that returns a set of particles that approximates an
output distribution assigned at each input. In contrast to standard gradient boosting that
fits a weak learner to the gradient of a loss function, WGBoost fits a weak learner to the
estimated Wasserstein gradient of a loss functional over probability distributions.
2. Application to Evidential Learning: Section 3 establishes tree-based evidential learning
based on WGBoost, with the loss functional specified by the Kullback–Leibler (KL) diver-
gence. Following modern gradient-boosting libraries [21, 22] that uses second-order gradient
boosting (c.f. Section 2.2), we implement a concrete second-order WGBoost algorithm built
on an approximate Wasserstein gradient and Hessian of the KL divergence.
3. Experiment on Real-world Data: Section 4 demonstrates the performance of probabilistic
regression, and classification with OOD detection, on real-world tabular datasets. To the
author’s knowledge, WGBoost is the first framework that enables evidential learning for (i)
boosted tree models and (ii) cases without closed form of individual-level posteriors."
INTRODUCTION,0.027426160337552744,"(a) Bayesian learning of a model f(x, w)
(b) Evidential learning based on WGBoost"
INTRODUCTION,0.029535864978902954,"Figure 2: Comparison of the pipeline of (a) Bayesian learning and (b) evidential learning based on
WGBoost. The former uses the (global-level) posterior p(w | {xi, yi}D
i=1) of the model parameter
w conditional on all data, and samples multiple models from it. The latter uses the individual-level
posterior p(θ | yi) of the response parameter θ as the output distribution of the training set, and trains
WGBoost that returns a particle-based distributional estimate p(θ | x) of θ for each input x."
WASSERSTEIN GRADIENT BOOSTING,0.03164556962025317,"2
Wasserstein Gradient Boosting"
WASSERSTEIN GRADIENT BOOSTING,0.03375527426160337,"This section establishes the general formulation of WGBoost. Section 2.1 recaps the notion of
Wasserstein gradient flows, a ‘gradient’ system of probability distributions that minimises an objective
functional in the space of probability distributions. Section 2.2 recaps the notion of gradient boosting,
a sequential ensemble method that fits a new weak learner to the ‘gradient’ of the remaining loss at
each iteration. Section 2.3 combines the above two notions to establish WGBoost, a novel family of
gradient boosting that enables to solve distribution-valued supervised learning."
WASSERSTEIN GRADIENT BOOSTING,0.035864978902953586,"Notation and Setting Let X and Y denote the space of inputs and responses in classification
and regression. Suppose Θ = Rd. Let P2 be the 2-Wasserstein space i.e. a set of all probability
distributions on Θ with finite second moment equipped with the Wasserstein metric [23]. We
identify a probability distribution in P2 with its density whenever it exits. Denote by ⊙and ⊘,
respectively, elementwise multiplication and elementwise division of two vectors in Rd. Let ∇be the
gradient operator. Let ∇2
d be a second-order gradient operator that takes the second derivative at each
coordinate i.e. ∇2
df(θ) = [∂2f(θ)/∂θ2
1, . . . , ∂2f(θ)/∂θ2
d]T ∈Rd."
WASSERSTEIN GRADIENT FLOW,0.0379746835443038,"2.1
Wasserstein Gradient Flow"
WASSERSTEIN GRADIENT FLOW,0.04008438818565401,"In the Euclidean space, a gradient flow of a function f means a curve of points xt that solves a
differential equation (d/dt)xt = −∇f(xt) from some initial value x0. That is the continuous-time
limit of gradient descent, which minimises the function f as t →∞. A Wasserstein gradient flow
means a curve of probability distributions µt minimising a given functional F on the 2-Wasserstein
space P2 from some initial distribution µ0. The Wasserstein gradient flow µt is characterised as a
solution of a partial differential equation, known as the continuity equation:
d
dtµt = −∇· (µt∇W F(µt))
given
µ0 ∈P2,
(1)"
WASSERSTEIN GRADIENT FLOW,0.04219409282700422,"where ∇W F(µ) : Θ →Θ denotes the Wasserstein gradient of F at µ [24, 25]. Appendix A recaps
the derivation of the Wasserstein gradient, presenting the examples for several functionals."
WASSERSTEIN GRADIENT FLOW,0.04430379746835443,"One of the elegant properties of the Wasserstein gradient flow is casting the infinite-dimensional
optimisation of the functional F as a finite-dimensional particle update [23]. The continuity equation
(1) can be reformulated as a dynamical system of a random variable θt ∼µt, such that
d
dtθt = −[∇W F(µt)] (θt)
given
θ0 ∼µ0,
(2)"
WASSERSTEIN GRADIENT FLOW,0.046413502109704644,"in the sense that the law µt of such a random variable θt is a weak solution of the continuity equation.
Consider the case where the initial measure µ0 is set to the empirical distribution ˆµ0 of N particles
{θn
0 }N
n=1. Discretising the continuous-time system (2) by the Euler method with a small step size
ν > 0 yields an iterative update scheme of N particles {θn
m}N
n=1 from step m = 0:
 "
WASSERSTEIN GRADIENT FLOW,0.04852320675105485,"θ1
m+1
...
θN
m+1  =  "
WASSERSTEIN GRADIENT FLOW,0.05063291139240506,"θ1
m...
θN
m  + ν  "
WASSERSTEIN GRADIENT FLOW,0.052742616033755275,"−[∇W F(ˆµm)](θ1
m)
...
−[∇W F(ˆµm)](θN
m) "
WASSERSTEIN GRADIENT FLOW,0.05485232067510549,",
(3)"
WASSERSTEIN GRADIENT FLOW,0.056962025316455694,"where ˆµm denotes the empirical distribution of the particles {θn
m}N
n=1 at step m."
WASSERSTEIN GRADIENT FLOW,0.05907172995780591,"In practice, it is common that the Wasserstein gradient of a chosen functional F is not well-defined for
empirical distributions. In such case, the particle update scheme (3) is not directly applicable because
it depends on the Wasserstein gradient ∇W F(ˆµm) at the empirical distribution ˆµm. For example, the
KL divergence F(µ) = KL(µ | π) with a reference distribution π leads to the Wasserstein gradient
[∇W F(µ)](θ) = −(∇log π(θ) −∇log µ(θ)) ill-defined if µ is an empirical distribution. Hence,
the particle update scheme (3) is often performed with the estimated or approximated Wasserstein
gradient well-defined for empirical distributions [e.g. 26, 27, 28, 29, 30]. A main application of
WGBoost in Section 3 uses the ‘smoothed’ Wasserstein gradient of the KL divergence [26]."
GRADIENT BOOSTING,0.06118143459915612,"2.2
Gradient Boosting"
GRADIENT BOOSTING,0.06329113924050633,"Gradient boosting [31] is a sequential ensemble method of M weak learners f1, . . . , fM. It iteratively
constructs an ensemble Fm of m weak learners f1, . . . , fm from step m = 0 to M. Given the current
ensemble Fm at step m, it trains a new weak learner fm+1 to construct the next ensemble by"
GRADIENT BOOSTING,0.06540084388185655,"Fm+1(x) = Fm(x) + νfm+1(x),
(4)"
GRADIENT BOOSTING,0.06751054852320675,"where ν is a shrinkage hyperparameter called a learning rate. The initial state of the ensemble F0(x)
at step m = 0 is typically set to a constant that best fits the data. Any learning algorithm can be used
as a weak learner in principle, although tree-based algorithms are most used [32]."
GRADIENT BOOSTING,0.06962025316455696,"The fundamental idea of gradient boosting is to train the new weak learner fm+1 to approximate the
negative gradient of the remaining error of the current ensemble Fm. Suppose that a loss function L
measures the remaining error Ri(Fm(xi)) := L(Fm(xi), yi) for each output vector yi ∈Rd. The
new weak learner fm+1 is fitted to the set {xi, gi}D
i=1 whose target variable gi is each specified by"
GRADIENT BOOSTING,0.07172995780590717,gi := −∇Ri(Fm(xi)) ∈Rd.
GRADIENT BOOSTING,0.07383966244725738,"The target gi is often called a pseudo residual. For each data input xi, the boosting scheme (4) updates
the output of the current ensemble Fm(xi) in the steepest descent direction of the error Ri(Fm(xi)).
Although [31] originally suggested an additional line search to determine a scaling constant of each
weak learner, the line search has been reported to have a negligible influence on performance [33]."
GRADIENT BOOSTING,0.0759493670886076,"In modern gradient-boosting libraries, such as XGBoost [21] and LightGBM [22], the standard
practice is to use the diagonal (coordinatewise) Newton direction of the remaining error Ri(Fm(xi))
in lieu of the negative gradient gi. The new base leaner fm+1 is instead fitted to the set {xi, gi⊘hi}n
i=1,
where the negative gradient gi is divided elementwise by the Hessian diagonal hi given by"
GRADIENT BOOSTING,0.07805907172995781,"hi := ∇2
dRi(Fm(xi)) ∈Rd."
GRADIENT BOOSTING,0.08016877637130802,"The target variable gi ⊘hi is the diagonal Newton direction that minimises the second-order Taylor
approximation of the remaining error Ri(Fm(xi)) for each coordinate independently. Combining
the second-order gradient boosting framework with tree-based weak learners has demonstrated
exceptional scalability and performance [34, 35]. Although it is possible to use the ‘full’ Newton
direction as the target variable of each weak learner, the impracticality of the full Newton direction
has been pointed out [e.g. 36, 37]. In addition, the coordinatewise computability of the diagonal
Newton direction is suitable for popular gradient-boosting tree algorithms [36]."
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.08227848101265822,"2.3
General Formulation of Wasserstein Gradient Boosting"
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.08438818565400844,"Now we consider the setting of distribution-valued supervised learning, where we are given a training
set of input vectors and output distributions {xi, µi}D
i=1 ⊂X × P2. Our goal is to construct a model
that receives an input and returns a set of N particles whose empirical distribution approximates the
output distribution. We specify a loss functional D(· | ·) between two probability distributions—such
as the KL divergence—to measure the remaining error Fi(·) = D(· | µi) for each i-th training
output distribution µi. Our idea is to combine gradient boosting with Wasserstein gradient, where we
iteratively construct a set of N boosting ensembles F 1
m, . . . , F N
m from step m = 0 to M."
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.08649789029535865,"Here, the output F n
m(x) of each n-th boosting ensemble represents the n-th output particle for an
input x. Given the current set of N ensembles F 1
m, . . . , F N
m at step m, WGBoost trains a set of N"
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.08860759493670886,"new weak learners f 1
m+1, . . . , f N
m+1 and computes the next set of N ensembles by
 "
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.09071729957805907,"F 1
m+1(x)
...
F N
m+1(x)  =  "
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.09282700421940929,"F 1
m(x)
...
F N
m (x)  + ν  "
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.0949367088607595,"f 1
m+1(x)
...
f N
m+1(x) "
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.0970464135021097,"
(5)"
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.09915611814345991,"where ν is a learning rate. Similarly to standard gradient boosting, we specify the initial state of
N ensembles F 1
0 , . . . , F N
0 at step m = 0 by a set of constants. Throughout, denote by ˆµm,i the
empirical distribution of the N output particles F 1
m(xi), . . . , F N
m (xi) for each i-th training input xi."
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.10126582278481013,"As discussed in Section 2.1, the Wasserstein gradient often needs to be estimated for empirical
distributions. For better presentation, let Gi(µ) denote an estimate of the Wasserstein gradient
∇W Fi(µ) of the i-th remaining error Fi(µ), which is well-defined for any distribution µ. If the
Wasserstein gradient ∇W Fi(µ) is originally well-defined for any distribution µ, it is a trivial choice
of the estimate, i.e., Gi(µ) = ∇W Fi(µ). Otherwise, any suitable estimate can be used as Gi(µ). The
foundamental idea of WGBoost is to train the n-th new learner f n
m+1 to approximate the estimated
Wasserstein gradient −Gi(ˆµm,i) evaluated at the n-th boosting output F n
m(xi) for each xi, so that,
 "
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.10337552742616034,"f 1
m+1(xi)
...
f N
m+1(xi)  ≈  "
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.10548523206751055,"−[Gi (ˆµm,i)]
 
F 1
m(xi)
"
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.10759493670886076,"...
−[Gi (ˆµm,i)]
 
F N
m (xi)
  ."
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.10970464135021098,"For each data input xi, the boosting scheme (5) approximates the particle update scheme (3) for the
output particles F 1
m(xi), . . . , F N
m (xi) under the estimated Wasserstein gradient. The output particles
are updated in the direction to decrease the remianing error Fi(ˆµm,i) = D(ˆµm,i | µi) at each step m."
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.11181434599156118,"Algorithm 1 summarises the general procedure of WGBoost. See Figure 1 for illustration of WGBoost.
In Section 3, we choose the KL divergence as a loss functional D and use a kernel smoothing estimate
of the Wasserstein gradient. See Appendix A for the Wasserstein gradient of other divergences.
Remark 1 (Stochastic WGBoost). Stochastic gradient boosting [38] uses only a randomly sampled
subset of data to fit a new weak learner at each step m to reduce the computational cost. The same
subsampling approach can be applied for WGBoost whenever the dataset is large.
Remark 2 (Second-Order WGBoost). If any estimate of the Wasserstein ‘Hessian’ of the remaining
error Fi is available, the Newton direction of Fi may also be computable [e.g. 39, 40]. Implemention
of a second-order WGBoost algorithm is immediate by plugging such a Newton direction into Gi(µ)
in Algorithm 1. Our default WGBoost algorithm for tree-based evidential learning is built on a
diagonal approximate Newton direction of the KL divergence, aligning with the standard practice in
modern gradient-boosting libraries to use the diagonal Newton direction."
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.11392405063291139,Algorithm 1: Wasserstein Gradient Boosting
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.1160337552742616,"Input: training set {xi, µi}D
i=1 of input xi ∈X and output distribution µi ∈P2
Parameter :loss D, estimate Gi(µ) of the Wasserstein gradient ∇W D(µ | µi), particle number
N, iteration M, learning rate ν, weak learner f, initial constants (ϑ1
0, . . . , ϑN
0 )
Output: set of N boosting ensembles (F 1
M, . . . , F N
M) at final step M
(F 1
0 (·), . . . , F N
0 (·)) ←(ϑ1
0, . . . , ϑN
0 )
▷set initial state of N boosting ensembles
for m ←0, . . . , M −1 do"
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.11814345991561181,"for i ←1, . . . , D do"
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.12025316455696203,"ˆµm,i ←empirical distribution of output values (F 1
m(xi), . . . , F N
m (xi)) for input xi
for n ←1, . . . , N do"
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.12236286919831224,"gn
i ←−[Gi(ˆµm,i)] (F n
m(xi))
▷compute target value of n-th new weak learner
end
end
for n ←1, . . . , N do"
GENERAL FORMULATION OF WASSERSTEIN GRADIENT BOOSTING,0.12447257383966245,"f n
m+1 ←fit
 
{xi, gn
i }D
i=1

▷fit n-th new weak learner
F n
m+1(·) ←F n
m(·) + νf n
m+1(·)
▷set next state of n-th boosting ensemble
end
end"
APPLICATION TO EVIDENTIAL LEARNING,0.12658227848101267,"3
Application to Evidential Learning"
APPLICATION TO EVIDENTIAL LEARNING,0.12869198312236288,"This section provides our default setting to implement a concrete WGBoost algorithm for evidential
learning, which enables classification and regression with predictive uncertainty. The individual-level
posterior p(θ | yi) of a response distribution p(y | θ) is used as the output distribution µi of the
training set {xi, µi}D
i=1. Section 3.1 recaps derivation of the individual-level posterior p(θ | yi),
followed by Section 3.2 discussing the default choice of the prior. We choose the KL divergence as a
loss functional of WGBoost. Section 3.3 recaps a widely-used estimate of the Wasserstein gradient
of the KL divergence based on kernel smoothing [26]. A further advantage of the kernel smoothing
estimate is that the approximate Wasserstein Hessian is available, with which Section 3.4 establishes
a second-order WGBoost algorithm similarly to modern gradient-boosting libraries."
DERIVATION OF INDIVIDUAL-LEVEL POSTERIORS AND PREDICTIVE DISTRIBUTION,0.1308016877637131,"3.1
Derivation of Individual-Level Posteriors and Predictive Distribution"
DERIVATION OF INDIVIDUAL-LEVEL POSTERIORS AND PREDICTIVE DISTRIBUTION,0.13291139240506328,"Suppose that a response distribution p(y | θ) of a response variable y is specified, as is typically done
for probabilistic prediction. Suppose also that a prior distribution pi(θ) of the response parameter
θ is specified for each individual data input xi. For each individual data pair (xi, yi), the response-
distribution likelihood p(yi | θ) and the prior pi(θ) determine the individual-level posterior"
DERIVATION OF INDIVIDUAL-LEVEL POSTERIORS AND PREDICTIVE DISTRIBUTION,0.1350210970464135,p(θ | yi) ∝p(yi | θ)pi(θ)
DERIVATION OF INDIVIDUAL-LEVEL POSTERIORS AND PREDICTIVE DISTRIBUTION,0.1371308016877637,"by Bayes’ theorem. This individual-level posterior is set to the output distribution µi of the training
set {xi, µi}D
i=1 of WGBoost. The framework of WGBoost then constructs a model that returns a
particle approximation of the output distribution µi(·) = p(· | yi) for each data input xi."
DERIVATION OF INDIVIDUAL-LEVEL POSTERIORS AND PREDICTIVE DISTRIBUTION,0.13924050632911392,"For a new input x, the constructed WGBoost model provides a set of particles (θ1(x), . . . , θN(x))
as a distributional prediction p(θ | x) of the response parameter θ. We can define a predictive
distribution p(y | x) of the response y for the new input x via marginalisation of the output particles:"
DERIVATION OF INDIVIDUAL-LEVEL POSTERIORS AND PREDICTIVE DISTRIBUTION,0.14135021097046413,"p(y | x) =
Z"
DERIVATION OF INDIVIDUAL-LEVEL POSTERIORS AND PREDICTIVE DISTRIBUTION,0.14345991561181434,"Θ
p(y | θ)p(θ | x)dθ = 1 N N
X"
DERIVATION OF INDIVIDUAL-LEVEL POSTERIORS AND PREDICTIVE DISTRIBUTION,0.14556962025316456,"i=1
p
 
y | θi(x)

.
(6)"
DERIVATION OF INDIVIDUAL-LEVEL POSTERIORS AND PREDICTIVE DISTRIBUTION,0.14767932489451477,"We can also define a point prediction ˆy for the new input x via the individual-level Bayes action
ˆy = argminy∈Y
R"
DERIVATION OF INDIVIDUAL-LEVEL POSTERIORS AND PREDICTIVE DISTRIBUTION,0.14978902953586498,"Θ U(y, θ)p(θ | x)dθ, which minimises the average of some error U : Y × Θ →R.
For example, the Bayes action ˆy is simply the mean of the output particles if U(y, θ) = (y −θ)2."
DERIVATION OF INDIVIDUAL-LEVEL POSTERIORS AND PREDICTIVE DISTRIBUTION,0.1518987341772152,"In general, the explicit form of the individual-level posterior p(θ | yi) is known only up to the
normalising constant. Our full algorithm in Section 3.4 requires no normalising constant of the
individual-level posterior p(θ | yi). Our algorithm depends only on the log-gradient of the individual-
level posterior ∇log p(θ | yi) that cancels any constant term by the gradient. Hence, knowing the
form of the response-distribution likelihood p(yi | θ) and the prior pi(θ) suffices.
Remark 3 (Difference from Bayesian Learning). Given a response distribution p(y | θ) and a
model θ = f(x, w) with the parameter w, Bayesian learning of the model f means the use of the
posterior p(w | {xi, yi}D
i=1) over w conditional on all data. The predictive distribution p(y | x) of
the response y is defined via marginalisation over w:
R"
DERIVATION OF INDIVIDUAL-LEVEL POSTERIORS AND PREDICTIVE DISTRIBUTION,0.1540084388185654,"Θ p(y | θ = f(x, w))p(w | {xi, yi}D
i=1)dw.
In contrast, WGBoost returns a distributional prediction p(θ | x) of the response parameter θ,
circumventing the marginalisation over the model parameter w that can be ultra-high dimensional."
CHOICE OF INDIVIDUAL-LEVEL PRIORS,0.15611814345991562,"3.2
Choice of Individual-Level Priors"
CHOICE OF INDIVIDUAL-LEVEL PRIORS,0.15822784810126583,"The prior distribution pi(θ) of the response parameter θ is specified at each individual data input xi.
The approach to eliciting the prior may differ, depending on whether past data are available. If past
data are available, they can be utilised to elicit a reasonable prior for unobserved data. If no past data
are available, we recommend the use of a noninformative prior that have been developed as a sensible
choice of prior in the absence of past data; see [e.g. 41] for the introduction. To avoid numerical
errors, if a noninformative prior is improper (i.e. nonintegrable), we recommend the use of a proper
probability distribution that approximates the noninformative prior sufficiently well.
Example 1 (Normal Location-Scale Response). Consider a scalar-valued response variable y ∈R
for regression. A normal location-scale response distribution N(y | m, σ) has the mean and scale
parameters m ∈R and σ ∈(0, ∞). A typical noninformative prior of m and σ are given by,"
CHOICE OF INDIVIDUAL-LEVEL PRIORS,0.16033755274261605,"respectively, 1 and 1/σ which are improper. At every data point (xi, yi), we use a normal prior
N(m | 0, σ0) over m and an inverse gamma prior IG(σ | α0, β0) over σ, with the hyperparameters
σ0 = 10 and α0 = β0 = 0.01, which approximate the non-informative priors.
Example 2 (Categorical Response). Consider a label response variable y ∈{1, . . . , k} for k-class
classification. A categorical response distribution C(y | q) has the class probability parameter
q = (q1, . . . , qk) in the k-dimensional simplex ∆k. If k = 2, it corresponds to the Bernoulli
distribution. A typical noninformative prior of q is given by 1/(q1 × · · · × qk) which are improper.
At every data point (xi, yi), we use the logistic normal prior—a multivariate generalisation of the
logit normal distribution [42]—over q with the mean 0 and identity covariance matrix scaled by 10.
Remark 4 (Reparametrisation and Standardisation). Section 2 supposed Θ = Rd for some
dimension d without no loss of generality. Any parameter that lies in a subset of the Euclidean space
(e.g. σ in Example 1) can be reparametrised as one in the Euclidean space (e.g. log σ). Appendix D
details the reparametrisation used for Examples 1 and 2. In addition, if one’s dataset has scalar
outputs of a low or high order of magnitude, we recommend standardising the outputs."
APPROXIMATE WASSERSTEIN GRADIENT OF KL DIVERGENCE,0.16244725738396623,"3.3
Approximate Wasserstein Gradient of KL Divergence"
APPROXIMATE WASSERSTEIN GRADIENT OF KL DIVERGENCE,0.16455696202531644,"We consider the KL divergence KL(µ | µi) as a loss functional of WGBoost. One challenge of the KL
divergence is that the resulting Wasserstein gradient

GKL
i (µ)

(θ) := −(∇log µi(θ) −∇log µ(θ))
is not well-defined when µ is an empirical distribution. A particularly successful solution—which
originates in [43] and has been applied in wide contexts [26, 44, 45]—is to smooth the Wasserstein
gradient through a kernel integral operator
R"
APPROXIMATE WASSERSTEIN GRADIENT OF KL DIVERGENCE,0.16666666666666666,"Θ[GKL
i (µ)](θ∗)k(θ, θ∗)dµ(θ∗) [46]. By integration-by-
part (see [e.g. 43]), the smoothed Wasserstein gradient, denoted G∗
i (µ), falls into the following form
that is well-defined for any distribution µ:"
APPROXIMATE WASSERSTEIN GRADIENT OF KL DIVERGENCE,0.16877637130801687,"[G∗
i (µ)] (θ) := −Eθ∗∼µ
h
∇log µi(θ∗)k(θ∗, θ) + ∇k(θ∗, θ)
i
∈Rd,
(7)"
APPROXIMATE WASSERSTEIN GRADIENT OF KL DIVERGENCE,0.17088607594936708,"where ∇k(θ∗, θ) denotes the gradient of k with respect to the first argument θ∗. An approximate
Wasserstein gradient flow based on the smoothed Wasserstein gradient G∗
i (µ) is called the Stein
variational gradient descent [43] or kernelised Wasserstein gradient flow [47]. In most cases, the kernel
k is set to the Gaussian kernel k(θ, θ∗) = exp(−∥θ −θ∗∥2/h) with the scale h > 0. Appendix B
discusses a choice of kernel. This work uses the Gaussian kernel with h = 0.1 throughout."
APPROXIMATE WASSERSTEIN GRADIENT OF KL DIVERGENCE,0.1729957805907173,"Another common approach to approximating the Wasserstein gradient flow of the KL divergence
is the Langevin diffusion approach [48]. The discretised algorithm, called the unadjusted Langevin
algorithm [49], is a stochastic particle update scheme that adds a Gaussian noise at every iteration.
However, several known challenges, such as asymptotic bias and slow convergence, often necessitate
an ad-hoc adjustment of the algorithm [48]. Appendix B discusses a variant of WGBoost built on the
Langevin algorithm, although it is not considered the default implementation."
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.1751054852320675,"3.4
Second-Order Implementation of WGBoost"
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.17721518987341772,"We use a diagonal (coordinatewise) approximate Wasserstein Newton direction of the KL divergence,
following the standard practice in modern gradient-boosting libraries [21, 22] to use the diagonal
Newton direction of a loss. Similarly to smoothed Wasserstein gradient G∗
i (µ), the approximate
Wasserstein Hessian of the KL divergence KL(µ | µi) can be obtained through the kernel smoothing.
The diagonal of the approximate Wasserstein Hessian, denoted H∗
i (µ), is defined by"
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.17932489451476794,"[H∗
i (µ)] (θ) := Eθ∗∼µ
h
−∇2
d log µi(θ∗)k(θ, θ∗)2 + ∇k(θ, θ∗) ⊙∇k(θ, θ∗)
i
∈Rd.
(8)"
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.18143459915611815,"The diagonal approximate Wasserstein Newton direction of the KL divergence is then defined by
−[G∗
i (µ)] (·) ⊘[H∗
i (µ)] (·). Appendix C provides the derivation based on [39] who derived the
Newton direction of the KL divergence in the context of nonparametric variational inference."
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.18354430379746836,"The second-order WGBoost algorithm is established by plugging it into Gi(µ) in Algorithm 1, that is,"
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.18565400843881857,"[Gi(µ)] (·) = [G∗
i (µ)] (·) ⊘[H∗
i (µ)] (·).
(9)"
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.1877637130801688,"Algorithm 1 under the choice (9) is considered our default WGBoost algorithm for evidential learning.
We refer this algorithm to as the Wasserstein-boosted evidential learning (WEvidential). The explicit
pseudocode is provided in Algorithm 2 for full clarity."
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.189873417721519,Algorithm 2: Wasserstein-Boosted Evidential Learning
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.19198312236286919,"Input: dataset {xi, yi}D
i=1 of input xi and response yi of classification or regression
Parameter :individual-level posterior p(θ | yi) of response distribution p(y | θ), particle number
N, iteration M, learning rate ν, weak learner f, initial constants {ϑn
0}N
n=1
Output: set of N boosting ensembles (F 1
M, . . . , F N
M) at final step M
(F 1
0 (·), . . . , F N
0 (·)) ←(ϑ1
0, . . . , ϑN
0 )
▷set initial state of N boostings
for m ←0, . . . , M −1 do"
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.1940928270042194,"for i ←1, . . . , D do"
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.1962025316455696,"(θ1
i , . . . , θN
i ) ←(F 1
m(xi), . . . , F N
m (xi))
▷get output particles for i-th data input
for n ←1, . . . , N do"
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.19831223628691982,"gn
i ←1"
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.20042194092827004,"N
PN
k=1 ∇log p(θk
i | yi)k(θk
i , θn
i ) + ∇k(θk
i , θn
i )
hn
i ←1"
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.20253164556962025,"N
PN
k=1 −∇2
d log p(θk
i | yi)k(θk
i , θn
i )2 + ∇k(θk
i , θn
i ) ⊙∇k(θk
i , θn
i )
end
end
for n ←1, . . . , N do"
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.20464135021097046,"f n
m+1 ←fit
 
{xi, gn
i ⊘hn
i }D
i=1

▷fit n-th new weak learner
F n
m+1(·) ←F n
m(·) + νf n
m+1(·)
▷set next state of n-th boosting
end
end"
SECOND-ORDER IMPLEMENTATION OF WGBOOST,0.20675105485232068,"Remark 5 (Computation). The diagonal Newton direction (9) has the computational complexity
O(N ×d) same as that of the smoothed Wasserstein gradient. Hence, there is essentially no reason not
to use the diagonal Newton direction (9) instead of the smoothed Wasserstein gradient. Although it is
possible to use the full Newton direction with no diagonal approximation, the computation requires
the inverse and product of (N ×d)×(N ×d) matrices that result in the complexity up to O(N 3 ×d3).
Appendix D presents a simulation study to compare computational time and convergence speed of
four WGBoost algorithms built on different estimates of the Wasserstein gradient."
EXPERIMENT ON REAL-WORLD TABULAR DATA,0.2088607594936709,"4
Experiment on Real-world Tabular Data"
EXPERIMENT ON REAL-WORLD TABULAR DATA,0.2109704641350211,"We empirically demonstrate the performance of the WGBoost algorithm through three experiments
using real-world tabular data. The first application illustrates the output of WGBoost through a simple
conditional density estimation. The second application benchmarks the probabilistic regression
performance. The third application demonstrates the classification and OOD detection performance.
The source code is available in https://github.com/takuomatsubara/WGBoost."
EXPERIMENT ON REAL-WORLD TABULAR DATA,0.21308016877637131,"Common Hyperparameters Throughout, we set the number of output particles N to 10 and set
each weak learner f to the decision tree regressor [50] with maximum depth 1 for Section 4.1 and 3
for the rest. We set the learning rate ν to 0.1 for regression and 0.4 for classification, unless otherwise
stated. Appendix E contains further details, including a choice of the initial constant {ϑn
0}N
n=1."
ILLUSTRATIVE CONDITIONAL DENSITY ESTIMATION,0.21518987341772153,"4.1
Illustrative Conditional Density Estimation"
ILLUSTRATIVE CONDITIONAL DENSITY ESTIMATION,0.21729957805907174,"We illustrate the output of WEvidential by estimating a conditional density p(y | x) from one-
dimensional scalar inputs and outputs {xi, yi}D
i=1. The normal output distribution N(y | m, σ) and
the prior pi(m, σ) in Example 1 were used to define the individual-level posterior p(m, σ | yi), in
which case the output of the WGBoost algorithm is a set of 10 particles {(mn(x), σn(x))}10
n=1 of the
mean and scale parameters for each input x. We chose the number of weak learners M, drawing on
an early-stopping approach used in [32], where we held out 20% of the training set as a validation set
and chose the number 1 ≤M ≤4000 achieving the least validation error. Once the number M was
chosen, WEvidential was trained again using all the entire training set."
ILLUSTRATIVE CONDITIONAL DENSITY ESTIMATION,0.21940928270042195,"The conditional density is estimated using the predictive distribution (6) by WEvidential. We used two
real-world datasets, bone mineral density [51] and old faithful geyser [52]. Figure 3 depicts the result
for the former dataset, demonstrating that the WGBoost algorithm captures the heterogeneity of the
conditional density on each input well. The result for the latter dataset is contained in Appendix E.1."
ILLUSTRATIVE CONDITIONAL DENSITY ESTIMATION,0.22151898734177214,"Figure 3: Conditional density estimation for the bone mineral density dataset (grey dots) by WEvi-
dential, where the normal response distribution N(y | m, σ) is used for the response variable y. Left:
distributional estimate (10 particles) of the location parameter {mn(x)}10
n=1 for each input. Right: es-
timated conditional density (6) through marginalisation of the output particles {(mn(x), σn(x))}10
n=1."
PROBABILISTIC REGRESSION BENCHMARK,0.22362869198312235,"4.2
Probabilistic Regression Benchmark"
PROBABILISTIC REGRESSION BENCHMARK,0.22573839662447256,"We examine the regression performance of WEvidential using a standard benchmark protocol that
originated in [53] and has been used in a number of subsequent works [10, 9, 32]. The benchmark
protocol uses real-world tabular datasets from the UCI machine learning repository [54], each with
one-dimensional scalar responses. As in Section 4.1, the normal response distribution N(y | m, σ)
and the prior pi(m, σ) in Example 1 were used to define the individual-level posterior p(m, σ | yi)."
PROBABILISTIC REGRESSION BENCHMARK,0.22784810126582278,"We followed the data splitting protocol in [53] and randomly held out 10% of each dataset as a test
set. The negative log likelihood (NLL) is measured by using the predictive distribution (6). The
root mean squared error (RMSE) is measured by using the point prediction by the mean value of
the predictive distribution. We chose the number of weak learners M by the same approach as in
Section 4.1. We repeated this procedure 20 times for each dataset, except the protein and year msd
datasets for which we repeated five times and once. For the year msd dataset only, we subsampled
10% of data to fit each weak learner and used the learning rate 0.01 due to the large dataset size."
PROBABILISTIC REGRESSION BENCHMARK,0.229957805907173,"Table 1 compares the performance of WEvidential with five other methods: Monte Carlo Dropout
(MCDropout) [9], Deep Ensemble (DEnsemble) [10], Concrete Dropout (CDropout) [55], Natural
Gradient Boosting (NGBoost) [32], and Deep Evidential Regression (DEvidential) [13]. Appendix E
provides further details on the experiment and a limited yet additional comparison. The WGBoost
algorithm achieves the best score or a score sufficiently close to the best score most often."
PROBABILISTIC REGRESSION BENCHMARK,0.2320675105485232,"Table 1: The NLLs and RMSEs for each dataset, where the best score is underlined and the scores
whose standard deviation ranges include the best score are in bold. Results of MCDropout, DEnsem-
bles, CDropout, NGBoost, and DEvidential were reported in [9], [10], [55], [32] and [13] respectively."
PROBABILISTIC REGRESSION BENCHMARK,0.23417721518987342,"Dataset
Criteria
WEvidential
MCDropout
DEnsemble
CDropout
NGBoost
DEvidential"
PROBABILISTIC REGRESSION BENCHMARK,0.23628691983122363,boston NLL
PROBABILISTIC REGRESSION BENCHMARK,0.23839662447257384,"2.47 ± 0.16
2.46 ± 0.06
2.41 ± 0.25
2.72 ± 0.01
2.43 ± 0.15
2.35 ± 0.06
concrete
2.83 ± 0.11
3.04 ± 0.02
3.06 ± 0.18
3.51 ± 0.00
3.04 ± 0.17
3.01 ± 0.02
energy
0.53 ± 0.08
1.99 ± 0.02
1.38 ± 0.22
2.30 ± 0.00
0.60 ± 0.45
1.39 ± 0.06
kin8nm
-0.44 ± 0.03
-0.95 ± 0.01
-1.20 ± 0.02
-0.65 ± 0.00
-0.49 ± 0.02
-1.24 ± 0.01
naval
-5.47 ± 0.03
-3.80 ± 0.01
-5.63 ± 0.05
-5.87 ± 0.05
-5.34 ± 0.04
-5.73 ± 0.07
power
2.60 ± 0.04
2.80 ± 0.01
2.79 ± 0.04
2.75 ± 0.01
2.79 ± 0.11
2.81 ± 0.07
protein
2.70 ± 0.01
2.89 ± 0.00
2.83 ± 0.02
2.81 ± 0.00
2.81 ± 0.03
2.63 ± 0.00
wine
0.95 ± 0.08
0.93 ± 0.01
0.94 ± 0.12
1.70 ± 0.00
0.91 ± 0.06
0.89 ± 0.05
yacht
0.16 ± 0.24
1.55 ± 0.03
1.18 ± 0.21
1.75 ± 0.00
0.20 ± 0.26
1.03 ± 0.19
year msd
3.50 ± NA
3.59 ± NA
3.35 ± NA
NA± NA
3.43 ± NA
NA ± NA"
PROBABILISTIC REGRESSION BENCHMARK,0.24050632911392406,boston RMSE
PROBABILISTIC REGRESSION BENCHMARK,0.24261603375527427,"2.78 ± 0.60
2.97 ± 0.19
3.28 ± 1.00
2.65 ± 0.17
2.94 ± 0.53
3.06 ± 0.16
concrete
4.15 ± 0.52
5.23 ± 0.12
6.03 ± 0.58
4.46 ± 0.16
5.06 ± 0.61
5.85 ± 0.15
energy
0.42 ± 0.07
1.66 ± 0.04
2.09 ± 0.29
0.46 ± 0.02
0.46 ± 0.06
2.06 ± 0.10
kin8nm
0.15 ± 0.00
0.10 ± 0.00
0.09 ± 0.00
0.07 ± 0.00
0.16 ± 0.00
0.09 ± 0.00
naval
0.00 ± 0.00
0.01 ± 0.00
0.00 ± 0.00
0.00 ± 0.00
0.00 ± 0.00
0.00 ± 0.00
power
3.19 ± 0.25
4.02 ± 0.04
4.11 ± 0.17
3.70 ± 0.04
3.79 ± 0.18
4.23 ± 0.09
protein
4.09 ± 0.02
4.36 ± 0.01
4.71 ± 0.06
3.85 ± 0.02
4.33 ± 0.03
4.64 ± 0.03
wine
0.61 ± 0.05
0.62 ± 0.01
0.64 ± 0.04
0.62 ± 0.00
0.63 ± 0.04
0.61 ± 0.02
yacht
0.48 ± 0.18
1.11 ± 0.09
1.58 ± 0.48
0.57 ± 0.05
0.50 ± 0.20
1.57 ± 0.56
year msd
9.11 ± NA
8.85 ± NA
8.89 ± NA
NA± NA
8.94 ± NA
NA ± NA"
PROBABILISTIC REGRESSION BENCHMARK,0.24472573839662448,"Table 2: The classification accuracies and OOD detection PR-AUCs for each dataset, where the best
score is underlined and in bold. The results other than WEvidential were reported in [14]."
PROBABILISTIC REGRESSION BENCHMARK,0.2468354430379747,"Dataset
Criteria
WEvidential
MCDropout
DEnsemble
DDistillation
PNetwork"
PROBABILISTIC REGRESSION BENCHMARK,0.2489451476793249,"segment
Accuracy
96.57 ± 0.6
95.25 ± 0.1
97.27 ± 0.1
96.21 ± 0.1
96.92 ± 0.1
OOD
99.67 ± 0.2
43.11 ± 0.6
58.13 ± 1.7
35.83 ± 0.4
96.74 ± 0.9"
PROBABILISTIC REGRESSION BENCHMARK,0.2510548523206751,"sensorless
Accuracy
99.54 ± 0.1
89.32 ± 0.2
99.37 ± 0.0
93.66 ± 1.5
99.52 ± 0.0
OOD
81.13 ± 5.3
40.61 ± 0.7
50.62 ± 0.1
31.17 ± 0.2
88.65 ± 0.4"
CLASSIFICATION AND OUT-OF-DISTRIBUTION DETECTION,0.25316455696202533,"4.3
Classification and Out-of-Distribution Detection"
CLASSIFICATION AND OUT-OF-DISTRIBUTION DETECTION,0.2552742616033755,"We examine the classification and anomaly OOD detection performance of WEvidential on two real-
world tabular datasets, segment and sensorless, following the protocol used in [14]. The categorical
response distribution C(y | q) and the prior pi(q) in Example 2 were used to define the individual-
level posterior p(q | yi), in which case the output of the WGBoost algorithm is a set of 10 particles
{qn}10
n=1 of the class probability parameter q in the simplex ∆k for each input x. We set the number
of weak learners M to 4000 without early stopping to reduce the computational cost."
CLASSIFICATION AND OUT-OF-DISTRIBUTION DETECTION,0.25738396624472576,"The segment and sensorless datasets have 7 and 11 classes in total. For the segment dataset, the data
subset that belongs to the last class was kept as the OOD samples. For the sensorless dataset, the data
subset that belongs to the last two classes was kept as the OOD samples. For each dataset, 20% of the
non-OOD samples is held out as a test set to measure the classification accuracy. There exist several
ways of defining a OOD score for each input [56]. For the WGBoost algorithm, the inverse of the
maximum norm of the output-particle variance was used as the OOD score. We measured the OOD
detection performance by the area under the precision recall curve (PR-AUC), viewing non-OOD test
data as the positive class and OOD data as the negative class. We repeated this procedure five times."
CLASSIFICATION AND OUT-OF-DISTRIBUTION DETECTION,0.25949367088607594,"Table 2 compares the performance of WEvidential with four other methods: MCDropout, DEnsem-
ble, and Distributional Distillation (DDistillation) [57], and Posterior Network (PNetwork) [14].
Appendix E provides further details on the experiment. Figure 4 exemplifies how the dispersion of
the output particles differ between OOD and non-OOD inputs. WEvidential demonstrates a high
classification and OOD detection accuracy simultaneously. Although PNetwork has the best OOD
detection performance for the sensorless dataset, the performance of the WGBoost algorithm also
exceeds 80%, which is distinct from MCDropout, DEnsemble, and DDistillation."
CLASSIFICATION AND OUT-OF-DISTRIBUTION DETECTION,0.2616033755274262,"(a) non-OOD input in class 4
(b) OOD input"
CLASSIFICATION AND OUT-OF-DISTRIBUTION DETECTION,0.26371308016877637,"Figure 4: Examples of the output particles (red dot) of WEvidential on the segment dataset, where
the coloured area indicate the kernel density estimation of the output particles for each class."
DISCUSSION,0.26582278481012656,"5
Discussion"
DISCUSSION,0.2679324894514768,"This work established the general framework of WGBoost and developed the concrete algorithm
WEvidential for evidential learning. The established framework of WGBoost offers exciting avenues
for future research. Important directions for future study include (i) exploring alternative loss
functionals to the KL divergence, (ii) investigating the convergence properties, and (iii) evaluating
robustness of obtained predictive uncertainty in comparison to other methods. A particular limitation
of WGBoost may arise when data are not tabular, as is the case of standard gradient boosting. These
questions require careful examination and are critical for future study."
REFERENCES,0.270042194092827,References
REFERENCES,0.2721518987341772,"[1] Ravid Shwartz-Ziv and Amitai Armon. Tabular data: Deep learning is not all you need.
Information Fusion, 81:84–90, 2022."
REFERENCES,0.2742616033755274,"[2] Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad
Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U. Rajendra Acharya, Vladimir
Makarenkov, and Saeid Nahavandi. A review of uncertainty quantification in deep learning:
Techniques, applications and challenges. Information Fusion, 76:243–297, 2021."
REFERENCES,0.27637130801687765,"[3] Eric Topol. High-performance medicine: the convergence of human and artificial intelligence.
Nature Medicine, 25:44–56, 2019."
REFERENCES,0.27848101265822783,"[4] Sorin Grigorescu, Bogdan Trasnea, Tiberiu Cocias, and Gigel Macesanu. A survey of deep
learning techniques for autonomous driving. Journal of Field Robotics, 37(3):362–386, 2020."
REFERENCES,0.2805907172995781,"[5] Matthew Richardson, Ewa Dominowska, and Robert Ragno. Predicting clicks: estimating the
click-through rate for new ads. In Proceedings of the 16th International Conference on World
Wide Web, page 521–530, 2007."
REFERENCES,0.28270042194092826,"[6] Christopher Burges. From ranknet to lambdarank to lambdamart: An overview. Learning, 11,
2010."
REFERENCES,0.2848101265822785,"[7] Byron P. Roe, Hai-Jun Yang, Ji Zhu, Yong Liu, Ion Stancu, and Gordon McGregor. Boosted
decision trees as an alternative to artificial neural networks for particle identification. Nuclear
Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors
and Associated Equipment, 543(2):577–584, 2005."
REFERENCES,0.2869198312236287,"[8] James Bennett and Stan Lanning. The Netflix prize. In Proceedings of the KDD Cup Workshop
2007, pages 3–6, 2007."
REFERENCES,0.2890295358649789,"[9] Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian approximation: Representing model
uncertainty in deep learning. In Proceedings of The 33rd International Conference on Machine
Learning, volume 48 of Proceedings of Machine Learning Research, pages 1050–1059. PMLR,
2016."
REFERENCES,0.2911392405063291,"[10] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable
predictive uncertainty estimation using deep ensembles. In Advances in Neural Information
Processing Systems, volume 30, 2017."
REFERENCES,0.29324894514767935,"[11] Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential deep learning to quantify
classification uncertainty. In Advances in Neural Information Processing Systems, volume 31,
2018."
REFERENCES,0.29535864978902954,"[12] Jakob Gawlikowski, Cedrique Rovile Njieutcheu Tassi, Mohsin Ali, Jongseok Lee, Matthias
Humt, Jianxiang Feng, Anna Kruspe, Rudolph Triebel, Peter Jung, Ribana Roscher, Muhammad
Shahzad, Wen Yang, Richard Bamler, and Xiao Xiang Zhu. A survey of uncertainty in deep
neural networks. Artificial Intelligence Review, 56:1513–1589, 2023."
REFERENCES,0.2974683544303797,"[13] Alexander Amini, Wilko Schwarting, Ava Soleimany, and Daniela Rus. Deep evidential
regression. In Advances in Neural Information Processing Systems, volume 33, pages 14927–
14937, 2020."
REFERENCES,0.29957805907172996,"[14] Bertrand Charpentier, Daniel Zügner, and Stephan Günnemann. Posterior network: Uncertainty
estimation without OOD samples via density-based pseudo-counts. In Advances in Neural
Information Processing Systems, volume 33, pages 1356–1367. Curran Associates, Inc., 2020."
REFERENCES,0.30168776371308015,"[15] Dennis Thomas Ulmer, Christian Hardmeier, and Jes Frellsen. Prior and posterior networks:
A survey on evidential deep learning methods for uncertainty estimation. Transactions on
Machine Learning Research, 2023."
REFERENCES,0.3037974683544304,"[16] Edouard Capellier, Franck Davoine, Veronique Cherfaoui, and You Li. Evidential deep learning
for arbitrary lidar object classification in the context of autonomous driving. In 2019 IEEE
Intelligent Vehicles Symposium (IV), pages 1304–1311, 2019."
REFERENCES,0.3059071729957806,"[17] Patrick Hemmer, Niklas Kühl, and Jakob Schöffer. Deal: Deep evidential active learning for
image classification. In 2020 19th IEEE International Conference on Machine Learning and
Applications (ICMLA), pages 865–870, 2020."
REFERENCES,0.3080168776371308,"[18] Ava P. Soleimany, Alexander Amini, Samuel Goldman, Daniela Rus, Sangeeta N. Bhatia, and
Connor W. Coley. Evidential deep learning for guided molecular property prediction and
discovery. ACS Central Science, 7(8):1356–1367, 2021."
REFERENCES,0.310126582278481,"[19] Jakob Gawlikowski, Sudipan Saha, Anna Kruspe, and Xiao Xiang Zhu. An advanced Dirichlet
prior network for out-of-distribution detection in remote sensing.
IEEE Transactions on
Geoscience and Remote Sensing, 60:1–19, 2022."
REFERENCES,0.31223628691983124,"[20] Andrew Gelman, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B.
Rubin. Bayesian Data Analysis. Chapman and Hall/CRC, 3rd ed. edition, 2013."
REFERENCES,0.3143459915611814,"[21] Tianqi Chen and Carlos Guestrin. XGBoost: A scalable tree boosting system. In Proceedings of
the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
KDD ’16, page 785–794, 2016."
REFERENCES,0.31645569620253167,"[22] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and
Tie-Yan Liu. LightGBM: A highly efficient gradient boosting decision tree. In Advances in
Neural Information Processing Systems, volume 30, 2017."
REFERENCES,0.31856540084388185,"[23] C’edric Villani. Topics in Optimal Transportation. Americal Mathematical Society, 2003."
REFERENCES,0.3206751054852321,"[24] Luigi Ambrosio, Nicola Gigli, and Giuseppe Savaré. Gradient Flows In Metric Spaces and in
the Space of Probability Measures. Birkhäuser Basel, 2005."
REFERENCES,0.3227848101265823,"[25] Filippo Santambrogio. {Euclidean, metric, and Wasserstein} gradient flows: an overview.
Bulletin of Mathematical Sciences, 7:87–154, 2017."
REFERENCES,0.32489451476793246,"[26] Qiang Liu. Stein variational gradient descent as gradient flow. In Advances in Neural Information
Processing Systems, volume 30, 2017."
REFERENCES,0.3270042194092827,"[27] Jos’e Antonio Carrillo, Katy Craig, and Francesco S. Patacchini. A blob method for diffusion.
Calculus of Variations and Partial Differential Equations, 58(53), 2019."
REFERENCES,0.3291139240506329,"[28] Yifei Wang, Peng Chen, and Wuchen Li. Projected Wasserstein gradient descent for high-
dimensional Bayesian inference. SIAM/ASA Journal on Uncertainty Quantification, 10(4):1513–
1532, 2022."
REFERENCES,0.33122362869198313,"[29] Dimitra Maoutsa, Sebastian Reich, and Manfred Opper. Interacting particle solutions of
Fokker-Planck equations through gradient-log-density estimation. Entropy (Basel), 22(8):802,
2020."
REFERENCES,0.3333333333333333,"[30] Ye He, Krishnakumar Balasubramanian, Bharath K. Sriperumbudur, and Jianfeng Lu. Regular-
ized Stein variational gradient flow. arXiv:2211.07861, 2022."
REFERENCES,0.33544303797468356,"[31] Jerome H. Friedman. Greedy function approximation: A gradient boosting machine. The
Annals of Statistics, 29(5):1189–1232, 2001."
REFERENCES,0.33755274261603374,"[32] Tony Duan, Avati Anand, Daisy Yi Ding, Khanh K. Thai, Sanjay Basu, Andrew Ng, and Alejan-
dro Schuler. NGBoost: Natural gradient boosting for probabilistic prediction. In Proceedings
of the 37th International Conference on Machine Learning, volume 119 of Proceedings of
Machine Learning Research, pages 2690–2700. PMLR, 2020."
REFERENCES,0.339662447257384,"[33] Peter Bühlmann and Torsten Hothorn. Boosting Algorithms: Regularization, Prediction and
Model Fitting. Statistical Science, 22(4):477 – 505, 2007."
REFERENCES,0.34177215189873417,"[34] Leo Grinsztajn, Edouard Oyallon, and Gael Varoquaux. Why do tree-based models still
outperform deep learning on typical tabular data? In Advances in Neural Information Processing
Systems, volume 35, pages 507–520, 2022."
REFERENCES,0.3438818565400844,"[35] Piotr Florek and Adam Zagda´nski. Benchmarking state-of-the-art gradient boosting algorithms
for classification. arXiv:2305.17094, 2023."
REFERENCES,0.3459915611814346,"[36] Zhendong Zhang and Cheolkon Jung. GBDT-MO: Gradient-boosted decision trees for multiple
outputs. IEEE Transactions on Neural Networks and Learning Systems, 32(7):3156–3167,
2021."
REFERENCES,0.34810126582278483,"[37] Tianqi Chen, Sameer Singh, Ben Taskar, and Carlos Guestrin. Efficient Second-Order Gradient
Boosting for Conditional Random Fields. In Proceedings of the Eighteenth International
Conference on Artificial Intelligence and Statistics, volume 38 of Proceedings of Machine
Learning Research, pages 147–155. PMLR, 2015."
REFERENCES,0.350210970464135,"[38] Jerome H. Friedman. Stochastic gradient boosting. Computational Statistics & Data Analysis,
38(4):367–378, 2002."
REFERENCES,0.35232067510548526,"[39] Gianluca Detommaso, Tiangang Cui, Youssef Marzouk, Alessio Spantini, and Robert Scheichl.
A Stein variational Newton method. In Advances in Neural Information Processing Systems,
volume 31, 2018."
REFERENCES,0.35443037974683544,"[40] Yifei Wang and Wuchen Li. Information Newton’s flow: second-order optimization method in
probability space. arXiv:2001.04341, 2020."
REFERENCES,0.35654008438818563,"[41] Malay Ghosh. Objective priors: An introduction for frequentists. Statistical Science, 26(2):187–
202, 2011."
REFERENCES,0.35864978902953587,"[42] J. Aitchison and S. M. Shen.
Logistic-normal distributions: Some properties and uses.
Biometrika, 67(2):261–272, 1980."
REFERENCES,0.36075949367088606,"[43] Qiang Liu and Dilin Wang. Stein variational gradient descent: A general purpose Bayesian
inference algorithm. In Advances in Neural Information Processing Systems, volume 29, 2016."
REFERENCES,0.3628691983122363,"[44] Dilin Wang, Zhe Zeng, and Qiang Liu. Stein variational message passing for continuous
graphical models. In Proceedings of the 35th International Conference on Machine Learning,
volume 80 of Proceedings of Machine Learning Research, pages 5219–5227. PMLR, 2018."
REFERENCES,0.3649789029535865,"[45] Alexander Lambert, Fabio Ramos, Byron Boots, Dieter Fox, and Adam Fishman. Stein
variational model predictive control. In Proceedings of the 2020 Conference on Robot Learning,
volume 155 of Proceedings of Machine Learning Research, pages 1278–1297. PMLR, 2021."
REFERENCES,0.3670886075949367,"[46] Anna Korba, Adil Salim, Michael Arbel, Giulia Luise, and Arthur Gretton. A non-asymptotic
analysis for Stein variational gradient descent. In Advances in Neural Information Processing
Systems, volume 33, pages 4672–4682, 2020."
REFERENCES,0.3691983122362869,"[47] Sinho Chewi, Thibaut Le Gouic, Chen Lu, Tyler Maunu, and Philippe Rigollet. SVGD as a
kernelized Wasserstein gradient flow of the chi-squared divergence. In Advances in Neural
Information Processing Systems, volume 33, pages 2098–2109, 2020."
REFERENCES,0.37130801687763715,"[48] Andre Wibisono. Sampling as optimization in the space of measures: The Langevin dynamics
as a composite optimization problem. In Proceedings of the 31st Conference On Learning
Theory, volume 75 of Proceedings of Machine Learning Research, pages 2093–3027. PMLR,
2018."
REFERENCES,0.37341772151898733,"[49] Gareth O. Roberts and Richard L. Tweedie. Exponential convergence of Langevin distributions
and their discrete approximations. Bernoulli, 2(4):341 – 363, 1996."
REFERENCES,0.3755274261603376,"[50] Leo Breiman, Jerome Friedman, R.A. Olshen, and Charles J. Stone. Classification and Regres-
sion Trees. Chapman and Hall/CRC, 1984."
REFERENCES,0.37763713080168776,"[51] Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning.
Springer New York, 2009."
REFERENCES,0.379746835443038,"[52] Sanford Weisberg. Applied Linear Regression. John Wiley & Sons, 1985."
REFERENCES,0.3818565400843882,"[53] Jose Miguel Hernandez-Lobato and Ryan Adams. Probabilistic backpropagation for scalable
learning of Bayesian neural networks. In Proceedings of the 32nd International Conference on
Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 1861–1869.
PMLR, 2015."
REFERENCES,0.38396624472573837,"[54] Dheeru Dua and Casey Graff. UCI machine learning repository, 2017."
REFERENCES,0.3860759493670886,"[55] Yarin Gal, Jiri Hron, and Alex Kendall. Concrete dropout. In Advances in Neural Information
Processing Systems, volume 30, 2017."
REFERENCES,0.3881856540084388,"[56] Jingkang Yang, Kaiyang Zhou, Yixuan Li, and Ziwei Liu. Generalized out-of-distribution
detection: A survey. arXiv:2110.11334, 2024."
REFERENCES,0.39029535864978904,"[57] Andrey Malinin, Bruno Mlodozeniec, and Mark Gales. Ensemble distribution distillation. In
International Conference on Learning Representations, 2020."
REFERENCES,0.3924050632911392,"[58] Filippo Santambrogio. Optimal Transport for Applied Mathematicians. Birkhäuser Cham,
2015."
REFERENCES,0.39451476793248946,"[59] Mingxuan Yi and Song Liu. Bridging the gap between variational inference and Wasserstein
gradient flows, 2023."
REFERENCES,0.39662447257383965,"[60] Michael Arbel, Anna Korba, Adil Salim, and Arthur Gretton. Maximum mean discrepancy
gradient flow. In Advances in Neural Information Processing Systems, volume 32, 2019."
REFERENCES,0.3987341772151899,"[61] Richard Jordan, David Kinderlehrer, and Felix Otto. The variational formulation of the Fokker–
Planck equation. SIAM Journal on Mathematical Analysis, 29(1):1–17, 1998."
REFERENCES,0.4008438818565401,"[62] Grigorios A. Pavliotis. Stochastic Processes and Applications. Springer New York, 2014."
REFERENCES,0.4029535864978903,"[63] Vern I. Paulsen and Mrinal Raghupathi. An Introduction to the Theory of Reproducing Kernel
Hilbert Spaces. Cambridge University Press, 2016."
REFERENCES,0.4050632911392405,"[64] Alex Leviyev, Joshua Chen, Yifei Wang, Omar Ghattas, and Aaron Zimmerman. A stochastic
Stein variational Newton method. arXiv:2204.09039, 2022."
REFERENCES,0.40717299578059074,"[65] Alex Smola, Arthur Gretton, Le Song, and Bernhard Schölkopf. A Hilbert space embedding for
distributions."
REFERENCES,0.4092827004219409,"[66] Shun ichi Amari. Information Geometry and Its Applications. Springer Tokyo, 2016."
REFERENCES,0.41139240506329117,"[67] Pavel Izmailov, Wesley J. Maddox, Polina Kirichenko, Timur Garipov, Dmitry Vetrov, and
Andrew Gordon Wilson. Subspace inference for bayesian deep learning. In Proceedings of 35th
Conference on Uncertainty in Artificial Intelligence, 2019."
REFERENCES,0.41350210970464135,Appendix
REFERENCES,0.41561181434599154,"This appendix contains the technical and experiment details referred to in the main text. Appendix A
recaps derivation of the Wasserstein gradient. Appendix B discusses the variant of WGBoost built
on the unadjusted Langevin algorithm. Appendix C derives the diagonal approximate Wasserstein
Newton direction used for WEvidential. Appendix D provides simulation studies on kernel choice of
WEvidential and comparison of WGBoost algorithms built on different estimate of the Wasserstein
gradient. Appendix E contains the additional details of the experiment presented in the main text."
REFERENCES,0.4177215189873418,"A
Derivation and Example of Wasserstein Gradient"
REFERENCES,0.41983122362869196,"This section recaps derivation of the Wasserstein gradient of a functional F, with examples of
common divergences. The Wasserstein gradient depends on a function on Θ called the first variation
[24]. The first variation δF(µ)/δµ of the functional F at µ is a function on Θ that satisfies"
REFERENCES,0.4219409282700422,"lim
ϵ→0+
F(µ + ϵν) −F(µ) ϵ
=
Z Θ δF(µ)"
REFERENCES,0.4240506329113924,"δµ
(θ)ν(θ)dθ"
REFERENCES,0.42616033755274263,"for all signed measure ν s.t. µ + ϵν ∈P2 for all ϵ sufficiently small. The Wasserstein gradient
∇W F(µ) of the functional F at µ is derived as the gradient of the first variation (see [e.g. 24]):"
REFERENCES,0.4282700421940928,[∇W F(µ)](θ) := ∇δF(µ)
REFERENCES,0.43037974683544306,"δµ
(θ)."
REFERENCES,0.43248945147679324,"It is common to suppose that the functional F consists of three energies, which are determined by
functions U : R →R, V : Θ →R, and W : Θ →R respectively, such that"
REFERENCES,0.4345991561181435,"F(µ) =
Z"
REFERENCES,0.43670886075949367,"Θ
U(µ(θ))dθ
|
{z
}
internal energy +
Z"
REFERENCES,0.4388185654008439,"Θ
V (θ)µ(θ)dθ
|
{z
}
potential energy + 1 2 Z"
REFERENCES,0.4409282700421941,"Θ×Θ
W(θ −θ′)µ(θ)dθµ(θ′)dθ′"
REFERENCES,0.4430379746835443,"|
{z
}
interaction energy ."
REFERENCES,0.4451476793248945,"For a functional F that falls into the above form, the Wasserstein gradient is derived as"
REFERENCES,0.4472573839662447,"[∇W F(µ)] (θ) = ∇U ′(µ(θ)) + ∇V (θ) +
Z"
REFERENCES,0.44936708860759494,"Θ
∇W(θ −θ′)µ(θ′)dθ′"
REFERENCES,0.45147679324894513,"where U ′ is the derivative of U : R →R [23]. The KL divergence F(µ) = KL(µ | π) of a
distribution π falls into the form with U(x) = x log x, V (θ) = −log π(θ), and W(θ) = 0, where"
REFERENCES,0.45358649789029537,"KL(µ | π) =
Z"
REFERENCES,0.45569620253164556,"Θ
log µ(θ)µ(θ)dθ +
Z"
REFERENCES,0.4578059071729958,"Θ
−log π(θ)µ(θ)dθ."
REFERENCES,0.459915611814346,Table 3 presents examples of Wasserstein gradients of common divergences F(µ) = D(µ | π).
REFERENCES,0.4620253164556962,"In the context of Bayesian inference, the KL divergence is particularly useful among many divergences.
The Wasserstein gradient of the KL divergence requires no normalising constant of a posterior
distribution π. This is because the Wasserstien gradient depends only on the log-gradient of the
posterior ∇log π(θ) = ∇π(θ)/π(θ) of the target π, in which case the normalising constant of the
target π is cancelled out by fraction. Hence, any posterior known only up to the normalising constant
can be used as the target distribution π in the Wasserstein gradient of the KL divergence."
REFERENCES,0.4641350210970464,"Table 3: Wasserstein gradients of four divergences: the KL divergence [58], the chi-squared diver-
gence [47], the alpha divergence [59], and the maximum mean discrepancy [60]."
REFERENCES,0.46624472573839665,"Divergence F(µ) = D(µ | π)
Wasserstein gradient [∇W F(µ)] (θ)"
REFERENCES,0.46835443037974683,"KL(µ | π)
−(∇log π(θ) −∇log µ(θ))
Chi2(µ | π)
2∇(µ(θ)/π(θ))
Alpha(µ | π)
(µ(θ)/π(θ))α−1∇(µ(θ)/π(θ))
MMD(µ | π)
R"
REFERENCES,0.4704641350210971,"Θ ∇k(θ, θ′)µ(θ)dθ −
R"
REFERENCES,0.47257383966244726,"Θ ∇k(θ, θ′)π(θ)dθ"
REFERENCES,0.47468354430379744,"B
Langevin Gradient Boosting for KL Divergence"
REFERENCES,0.4767932489451477,"If a chosen functional F on P2 is the KL divergence F(µ) = KL(µ | π) of a target distribution π,
the continuity equation (1) admits an equivalent representation as the Fokker-Planck equation [61]:
d
dtµt = ∇· (µt∇log π) + ∆µt
given
µ0 ∈P2
(10)"
REFERENCES,0.47890295358649787,"where ∆denotes the Laplacian operator. Recall that the original continuity equation (1) can be
reformulated as the deterministic differential equation (2) of a random variable θt ∼µt. In contrast,
the Fokker-Planck equation (10) can be reformulated as a stochastic differential equation of a random
variable θt ∼µt, known as the overdamped Langevin dynamics [62]:"
REFERENCES,0.4810126582278481,"dθt = ∇log π(θt)dt +
√"
"DBT
GIVEN",0.4831223628691983,"2dBt
given
θ0 ∼µ0,
(11)
where Bt denotes a standard Brownian motion. Note that the deterministic system (2) in the case of
the KL divergence and the above stochastic system (11) are equivalent at population level, in a sense
that the law of the random variable θt in both the systems solves the two equivalent equations."
"DBT
GIVEN",0.48523206751054854,"At the algorithmic level, however, discretisation of each system leads to different particle update
schemes. Set the initial distribution µ0 in (11) to the empirical distribution ˆµ0 of N initial particles
{θn
0 }N
n=1. Discretising the stochastic system (11) by the Euler-Maruyama method with a step size
ν > 0 yields a stochastic update scheme of particles {θn
m}N
n=1 from step m = 0:
 "
"DBT
GIVEN",0.4873417721518987,"θ1
m+1
...
θN
m+1  =  "
"DBT
GIVEN",0.48945147679324896,"θ1
m...
θN
m  + ν  "
"DBT
GIVEN",0.49156118143459915,"∇log π(θ1
m) +
p"
"DBT
GIVEN",0.4936708860759494,"2/ν ξ1
...
∇log π(θN
m) +
p"
"DBT
GIVEN",0.4957805907172996,"2/ν ξN  ,"
"DBT
GIVEN",0.4978902953586498,"where each ξn denotes a realisation from a standard normal distribution on Rd. The above updating
scheme of each n-th particle is known as the unadjusted Langevin algorithm [49]. We can define a
variant of WGBoost by replacing the term Gi(µ) in Algorithm 1 with ∇log µi(·) +
p"
"DBT
GIVEN",0.5,"2/ν ξi where
µi is an output distribution at each xi and ξi is a realisation from a standard normal distribution. The
procedure is summarised in Algorithm 3, which we call Langevin gradient boosting (LGBoost)."
"DBT
GIVEN",0.5021097046413502,Algorithm 3: Langevin Gradient Boosting
"DBT
GIVEN",0.5042194092827004,"Input: training set {xi, µi}D
i=1 of input xi ∈X and output distribution µi ∈P2
Parameter :particle number N, iteration M, rate ν, weak learner f, initial constants
(ϑ1
0, . . . , ϑN
0 )
Output: set of N boosting ensembles (F 1
M, . . . , F N
M) at final step M
(F 1
0 (·), . . . , F N
0 (·)) ←(ϑ1
0, . . . , ϑN
0 )
for m ←0, . . . , M −1 do"
"DBT
GIVEN",0.5063291139240507,"for n ←1, . . . , N do"
"DBT
GIVEN",0.5084388185654009,"for i ←1, . . . , D do"
"DBT
GIVEN",0.510548523206751,"gn
i ←∇log µi(F n
m(xi)) +
p"
"DBT
GIVEN",0.5126582278481012,"2/ν ξn
i
where
ξn
i ∼N(0, Id)
end"
"DBT
GIVEN",0.5147679324894515,"f n
m+1 ←fit

{xi, gn
i }D
i=1
"
"DBT
GIVEN",0.5168776371308017,"F n
m+1(·) ←F n
m(·) + νf n
m+1(·)
end
end"
"DBT
GIVEN",0.5189873417721519,"C
Derivation of Approximate Wasserstein Newton Direction"
"DBT
GIVEN",0.5210970464135021,"This section derives the diagonal approximate Wasserstein Newton direction based on the kernel
smoothing. The approximate Wasserstein Newton direction of the KL divergence was derived in [39]
under a different terminology—simply, the Newton direction—from a viewpoint of nonparametric
variational inference. We place their result in the context of approximate Wasserstein gradient flows.
Appendix C.1 shows the derivation of the smoothed Wasserstein gradient and Hessian. Appendix C.2
defines the Newton direction built upon the smoothed Wasserstein gradient and Hessian, following
the derivation in [39]. Appendix C.3 derives the diagonal approximation of the Newton direction."
"DBT
GIVEN",0.5232067510548524,"C.1
Smoothed Wasserstein Gradient and Hessian"
"DBT
GIVEN",0.5253164556962026,"Consider the one-dimensional case Θ = R for simplicity. For a map T : R →R and a distribution
µ ∈P2, let µt be the pushforward of µ under the transform θ 7→θ + tT(θ) defined with a time-
variable t ∈R. This means that µt is a distribution obtained by change-of-variable applied for µ. The
Wasserstein gradient of a functional F(µ) can be associated with the time derivative (d/dt)F(µt)
[23]. In what follows, we focus on the KL divergence F(µ) = KL(µ | π) as a loss functional. Under
a condition T ∈L2(µ), the time derivative at t = 0 satisfies the following equality"
"DBT
GIVEN",0.5274261603375527,"d
dt KL(µt | π)

t=0 =
Z"
"DBT
GIVEN",0.5295358649789029,"Θ
T(θ)

GKL(µ)

(θ) dµ(θ) =

T, GKL(µ)"
"DBT
GIVEN",0.5316455696202531,"L2(µ) ,
(12)"
"DBT
GIVEN",0.5337552742616034,"where GKL(µ) denotes the Wasserstein gradient of F(µ) = KL(µ | π) with the target distribution π
made implicit. It gives an interpretation of the Wasserstein gradient as the steepest-descent direction
because the decay of the KL divergence at t = 0 is maximised when T = −GKL(µ)."
"DBT
GIVEN",0.5358649789029536,"The ‘smoothed’ Wasserstein gradient can be derived by restricting the transform map T to a more
regulated Hilbert space than L2(µ). A reproducing kernel Hilbert space (RKHS) H associated with a
kernel function k : R × R →R is the most common choice of such a Hilbert space [e.g. 26]. An
important property of the RKHS H is that any function f ∈H satisfies the reproducing property
f(θ) = ⟨f(·), k(θ, ·)⟩H under the associated kernel k and inner product ⟨·, ·⟩H [63]. As discussed in
[e.g. 46], applying the reproducing property in (12) under the condition T ∈H and exchanging the
integral order, the time derivative satisfies an alternative equality as follows:"
"DBT
GIVEN",0.5379746835443038,"d
dt KL(µt | π)

t=0 =
Z"
"DBT
GIVEN",0.540084388185654,"Θ
⟨T(·), k(θ, ·)⟩H

GKL(µ)

(θ) dµ(θ)"
"DBT
GIVEN",0.5421940928270043,"=

T(·),
Z Θ"
"DBT
GIVEN",0.5443037974683544,"
GKL(µ)

(θ)k(θ, ·)dµ(θ)"
"DBT
GIVEN",0.5464135021097046,"H
= ⟨T, G∗(µ)⟩H
(13)"
"DBT
GIVEN",0.5485232067510548,"where [G∗(µ)](·) :=
R"
"DBT
GIVEN",0.5506329113924051,"Θ[GKL(µ)](θ)k(θ, ·)dµ(θ) corresponds to the smoothed Wasserstein gradient
used in the main text. The decay of the KL divergence at t = 0 is maximised by T = −G∗(µ)."
"DBT
GIVEN",0.5527426160337553,"Similarly, the Wasserstein Hessian of the functional F(µ) can be associated with the second time
derivative (d2/dt2)F(µt) [23]. As discussed in [e.g. 46], the Wasserstein Hessian of the KL diver-
gence, denoted Hess(µ), is an operator over functions T ∈L2(µ) that satisfies d2"
"DBT
GIVEN",0.5548523206751055,"dt2 KL(µt | π)

t=0 = ⟨T, Hess(µ)T⟩L2(µ) .
(14)"
"DBT
GIVEN",0.5569620253164557,"See [46] for the explicit form of the Wasserstein Hessian. In the same manner as the smoothed
Wasserstein gradient, applying the reproducing property in (14) under the condition T ∈H and
exchanging the integral order, the second time derivative satisfies an alternative equality as follows: d2"
"DBT
GIVEN",0.5590717299578059,"dt2 KL(µt | π)

t=0 =
D
T(⋆1),

[Hess∗(µ)] (⋆1, ⋆2), T(⋆2) H E"
"DBT
GIVEN",0.5611814345991561,"H
(15)"
"DBT
GIVEN",0.5632911392405063,"where [Hess∗(µ)](⋆1, ⋆2) := ⟨k(⋆1, ·), Hess(µ)k(⋆2, ·)⟩L2(µ) is the smoothed Wasserstein Hessian
and the symbols ⋆1 and ⋆2 denote the variables to which each of the two inner products is taken."
"DBT
GIVEN",0.5654008438818565,"In the multidimensional case Θ = Rd, the transport map T is a vector-valued function T : Rd →Rd,
where a similar derivation can be repeated by replacing L2(µ) and H with the product space of d
independent copies of L2(µ) and H. It follows from Proposition 1 and Theorem 1 in [39]—which
derives the explicit form of (13) and (15) under their terminology, first and second variations—that
the explicit form of the smoothed Wasserstein gradient and Hessian is given by"
"DBT
GIVEN",0.5675105485232067,"[G∗(µ)] (·) = Eθ∼µ
h
−∇log π(θ)k(θ, ·) −∇k(θ, ·)
i
∈Rd,"
"DBT
GIVEN",0.569620253164557,"[Hess∗(µ)] (⋆1, ⋆2) = Eθ∼µ
h
−∇2 log π(θ)k(θ, ⋆1)k(θ, ⋆2) + ∇k(θ, ⋆1) ⊗∇k(θ, ⋆2)
i
∈Rd×d"
"DBT
GIVEN",0.5717299578059072,"where ∇2 denotes an operator to take the Jacobian of the gradient—i.e., ∇2f(θ) is the Hessian matrix
of f at θ—and ⊗denotes the outer product of two vectors. Note that both the smoothed Wasserstein
gradient and Hessian are well-defined for any distribution µ including empirical distributions."
"DBT
GIVEN",0.5738396624472574,"C.2
Approximate Wasserstein Newton Direction"
"DBT
GIVEN",0.5759493670886076,"In the Euclidean space, the Newton direction of an objective function is a direction s.t. the second-
order Taylor approximation of the function is minimised. Similarly, [39] characterised the Newton
direction T ∗: Rd →Rd of the KL divergence KL(µ | π) as a solution of the following equation
D
[Hess∗(µ)](⋆1, ⋆2), T ∗(⋆2)"
"DBT
GIVEN",0.5780590717299579,"H + [G∗(µ)](⋆1), V (⋆1)
E"
"DBT
GIVEN",0.580168776371308,"H = 0
for all
V ∈H."
"DBT
GIVEN",0.5822784810126582,"Here Θ = Rd and H is the product space of d independent copies of the RKHS of a kernel k. To
obtain a closed-form solution, [39] supposed that the Newton direction T ∗can be expressed in a form
T ∗(·) = Pn
i=1 W nk(·, θn) dependent on a set of each particle θn ∈Θ and associated vector-valued
coefficient W n ∈Rd. Once the set of the particles is given, the set of the associated vector-valued
coefficients is determined by solving the following simultaneous linear equation
 "
"DBT
GIVEN",0.5843881856540084,"PN
n=1[Hess∗(µ)](θ1, θn) · W n
...
PN
n=1[Hess∗(µ)](θN, θn) · W n  =  "
"DBT
GIVEN",0.5864978902953587,"−[G∗(µ)](θ1)
...
−[G∗(µ)](θN) "
"DBT
GIVEN",0.5886075949367089,".
(16)"
"DBT
GIVEN",0.5907172995780591,"These equations (16) can be rewritten in a matrix form [64]. Let K := N × d. Define a block matrix
H ∈RK×K and a block vector G ∈RK by the following partitioning H =  
"
"DBT
GIVEN",0.5928270042194093,"H11
· · ·
H1N
...
...
...
HN1
· · ·
HNN "
"DBT
GIVEN",0.5949367088607594,"

and
G =  
 G1"
"DBT
GIVEN",0.5970464135021097,"...
GN  
"
"DBT
GIVEN",0.5991561181434599,"with each block specified as Hij := [Hess∗(µ)](θi, θj) ∈Rd×d and Gi := [G∗(µ)](θi) ∈Rd.
Define a block matrix K ∈RK×K and a block vector W ∈RK by the following partitioning K :=  
"
"DBT
GIVEN",0.6012658227848101,"K11
· · ·
K1N
...
...
...
KN1
· · ·
KNN "
"DBT
GIVEN",0.6033755274261603,"

and
W :=  
 W 1"
"DBT
GIVEN",0.6054852320675106,"...
W N  
"
"DBT
GIVEN",0.6075949367088608,"with each block of K specified as Kij := Id × k(θi, θj) ∈Rd×d, where Id denotes the d × d identity
matrix. Notice that W is a block vector that aligns the vector-valued coefficients {W n}N
n=1. Using
these notations, the optimal coefficients that solve (16) is simply written as W = −H−1G [64]."
"DBT
GIVEN",0.609704641350211,"Given the optimal coefficients W = −H−1G, the Newton direction T ∗(θn) evaluated at the given
particle θn for each n = 1, . . . , N can be written in the following block vector form
 
"
"DBT
GIVEN",0.6118143459915611,T ∗(θ1)
"DBT
GIVEN",0.6139240506329114,"...
T ∗(θN) "
"DBT
GIVEN",0.6160337552742616,"
= −  
"
"DBT
GIVEN",0.6181434599156118,"K11
· · ·
K1N
...
...
...
KN1
· · ·
KNN  
  
"
"DBT
GIVEN",0.620253164556962,"H11
· · ·
H1N
...
...
...
HN1
· · ·
HNN  
 −1  
 G1"
"DBT
GIVEN",0.6223628691983122,"...
GN "
"DBT
GIVEN",0.6244725738396625,"

(17)"
"DBT
GIVEN",0.6265822784810127,"To distinguish from the standard Newton direction in the Euclidean space, we call (17) the ap-
proximate Wasserstein Newton direction. The approximate Wasserstein Newton direction yields a
second-order particle update scheme. Suppose we have particles {θn
m}N
n=1 to be updated at each step
m. At each step m, define the above matrices H and G with the empirical distribution µ = ˆπm of
the particles {θn
m}N
n=1. Replacing the Wasserstein gradient in the particle update scheme (3) by the
approximate Wasserstein Newton direction (17) provides the second-order update scheme in [39]."
"DBT
GIVEN",0.6286919831223629,"C.3
Diagonal Approximate Wasserstein Newton Direction"
"DBT
GIVEN",0.630801687763713,"We derive the diagonal approximation of the approximate Wasserstein Newton direction, which we
used for our second-order WGBoost algorithm. A few approximations of the approximate Wasserstein
Newton direction were discussed in [39] for better performance of their particle algorithm. We derive
the diagonal approximation so that no matrix product and inversion will be involved. Specifically, we
replace the matrices K and H in (17) by the diagonal approximations ˆK and ˆH, that is, ˆK =  
"
"DBT
GIVEN",0.6329113924050633,"Id
· · ·
0
...
...
...
0
· · ·
Id "
"DBT
GIVEN",0.6350210970464135,"

and
ˆH =  
"
"DBT
GIVEN",0.6371308016877637,"h11
· · ·
0
...
...
...
0
· · ·
hNN  
,"
"DBT
GIVEN",0.6392405063291139,"where Knn = Id × k(θn, θn) = Id for the Gaussian kernel k used in this work, and the matrix
hnn ∈Rd×d denotes the diagonal approximation of the diagonal block Hnn of H."
"DBT
GIVEN",0.6413502109704642,"Recall that Hnn = [Hess∗(µ)](θn, θn). Denote by Diag(A) the diagonal of a square matrix A.
The diagonal approximation hnn is a diagonal matrix whose diagonal is Diag(Hnn). We plug the
diagonal approximations ˆK and ˆH in (17). It follows from inverse and multiplication properties of
diagonal matrices that the approximate Wasserstein Newton direction turns into a form
 
"
"DBT
GIVEN",0.6434599156118144,T ∗(θ1)
"DBT
GIVEN",0.6455696202531646,"...
T ∗(θN) "
"DBT
GIVEN",0.6476793248945147,"
= −  
"
"DBT
GIVEN",0.6497890295358649,"h11
· · ·
0
...
...
...
0
· · ·
hNN  
 −1  
 G1"
"DBT
GIVEN",0.6518987341772152,"...
GN  
=  
"
"DBT
GIVEN",0.6540084388185654,−G1 ⊘Diag (H11)
"DBT
GIVEN",0.6561181434599156,"...
−GN ⊘Diag (HNN) "
"DBT
GIVEN",0.6582278481012658,"
. (18)"
"DBT
GIVEN",0.6603375527426161,"At an arbitrary particle location θ, denote by [H∗(µ)](θ) the diagonal of the smoothed Wasserstein
Hessian [Hess∗(µ)](θ, θ). It is straightforward to see that the diagonal can be written as"
"DBT
GIVEN",0.6624472573839663,"[H∗(µ)] (·) = Eθ∼µ
h
−∇2
d log π(θ)k(θ, ·)2 + ∇k(θ, ·) ⊙∇k(θ, ·)
i
."
"DBT
GIVEN",0.6645569620253164,"Notice that Diag (Hnn) = [H∗(µ)] (θn) by definition. It therefore follows from the formula (18)
with Gn = [G∗(µ)](θn) and Diag (Hnn) = [H∗(µ)] (θn) that the diagonal approximate Wasserstein
Newton direction at an arbitrary particle location θ can be independently computed by"
"DBT
GIVEN",0.6666666666666666,−[G∗(µ)](θ) ⊘[H∗(µ)] (θ).
"DBT
GIVEN",0.6687763713080169,"We used this direction in Section 3. In the main text, the diagonal approximate Wasserstein Newton
direction is defined for each loss functional Fi(·) = D(· | µi), with π = µi, using the smoothed
Wasserstein gradient G∗
i (µ) and the diagonal of the smoothed Wasserstein Hessian H∗
i (µ) for each
i-th output distribution µi."
"DBT
GIVEN",0.6708860759493671,"D
Simulation Study for WEvidential"
"DBT
GIVEN",0.6729957805907173,"This section provides simulation studies on kernel choice of WEvidential and comparison of different
estimate of the Wasserstein gradient to use in the WGBoost framework."
"DBT
GIVEN",0.6751054852320675,"D.1
Choice of Kernel"
"DBT
GIVEN",0.6772151898734177,"We used the kernel smoothing estimate of the Wasserstein gradient of the KL divergence in order
to built WEvidential. The smoothed Wasserstein gradient originates in an approximate Wasserstein
gradient flow called Stein variational gradient descent (SVGD) [43]. It is fairly common in SVGD
in practice to use the Gaussian kernel k(θ, θ∗) = exp(−∥θ −θ∗∥2/h) with the scale h > 0. For
WEvidential, the scale h may be viewed as a hyperparameter to choose. We recommend using the
value of the scale s.t. 0.01 ≤h ≤1.0 in general. This work uses the value h = 0.1 throughout the
experiments in the main text. One may opt for performing more advanced tuning of the scale h."
"DBT
GIVEN",0.679324894514768,"We provide a simulation study to examine sensitivity to the scale value. We prepared a synthetic
dataset {xi, µi}D
i=1 whose inputs are 200 gird points on the interval [−3.5, 3.5] and output distri-
butions are normal distributions µi(θ) = N(θ | sin(xi), 0.5) conditional on each xi. We used
WEvidential with different kernel scales h = 0.001, 0.01, 0.1, 1.0, 10, 100 and fitted it to the syn-
thetic dataset {xi, µi}D
i=1. The decision tree regressor with the maximum depth 3 was used for each
weak learner. The learning rate and the number of weak learners were set to 0.1 and 100. The initial
constant {ϑn}10
n=1 of WEvidential was set to 10 grid points in the interval [−10, 10]."
"DBT
GIVEN",0.6814345991561181,"We computed the output of WEvidential for 500 grid points in the interval [−3.5, 3.5]. We used the
maximum mean discrepancy (MMD) [65] to measure the approximation error between the empirical
distribution ˆµi of the output of WEvidential and the output distribution µi:"
"DBT
GIVEN",0.6835443037974683,"MMD2 (ˆµi, µi) = Eθ∼ˆµi,θ′∼ˆµi[kD(θ, θ′)] −2Eθ∼ˆµi,θ′∼µi[kD(θ, θ′)] + Eθ∼µi,θ′∼µi[kD(θ, θ′)]"
"DBT
GIVEN",0.6856540084388185,"where kD is a Gaussian kernel kD(θ, θ′) = exp(−(θ −θ′)2/s) with the scale s = 0.025. The total
approximation error was measured by the MMD averaged over all the inputs. Figure 5 shows the
total approximation error of WEvidential for each scale value h in the common log scale, together
with examples of the output of WEvidential for different values of h. It demonstrates that the total
error is minimised by h = 0.1 and stays in a relatively small value range for 0.01 ≤h ≤1.0."
"DBT
GIVEN",0.6877637130801688,"(a) The total error
(b) h = 0.10"
"DBT
GIVEN",0.689873417721519,"(c) h = 0.01
(d) h = 100"
"DBT
GIVEN",0.6919831223628692,"Figure 5: The total MMD error and example outputs of WEvidential for different kernel scales. Panel
(a): the total MMD error for different scale values h = 0.001, 0.01, 0.1, 1.0, 10, 100 both plotted in
the common log scale. Panel (b): the output of WEvidential for h = 0.1. Panel (c): the output of
WEvidential for h = 0.01. Panel (d): the output of WEvidential for h = 100."
"DBT
GIVEN",0.6940928270042194,"D.2
Comparison of Different Wasserstein Gradient Estimates"
"DBT
GIVEN",0.6962025316455697,"We compare four WGBoost algorithms built on different estimates of the Wasserstein gradient of the
KL divergence. The first three algorithms set the estimate Gi(µ) in Algorithm 1 to, respectively,"
"DBT
GIVEN",0.6983122362869199,"1. the smoothed Wasserstein gradient in (7);
2. the diagonal approximate Wasserstein Newton direction in (8);
3. the full approximate Wasserstein Newton direction in (17)."
"DBT
GIVEN",0.70042194092827,"The fourth algorithm is LGBoost in Appendix B which is rather a variant of WGBoost. The first and
third algorithms are called the first-order WEvidential and the full-Newton WEvidential, respectively.
The second algorithm is our default WEvidential presented in Section 3. The first-order WEvidential
is implemented by removing hn
i and replacing gn
i ⊘hn
i with gn
i in Algorithm 2. The full-Newton
WEvidential is implemented by replacing gn
i ⊘hn
i in Algorithm 2 with vn
i computed by the following
Algorithm 4, where ∇2f(θ) denotes the Hessian matrix of a function f : Θ →R at θ."
"DBT
GIVEN",0.7025316455696202,"We prepared the same synthetic dataset {xi, µi}D
i=1 as Appendix D.1 and fitted each algorithm to the
dataset. We computed the output of each algorithm for 500 grid points in the interval [−3.5, 3.5] and
measured the approximation error by the MMD in the same manner as Appendix D.1. The decision
tree regressor with the maximum depth 3 was used for each weak learner, and the learning rate was
set to 0.1. We used an increasing number of weak leaners up to 100 weak learners, in order to observe
the decay of the approximation error and the increase of the computational time. The initial constant
{ϑn}10
n=1 for each algorithm was set to 10 grid points in the interval [−10, 10], which sufficiently
differs from the output distributions so that the decay of the approximation error is clear."
"DBT
GIVEN",0.7046413502109705,"Figure 6 shows the approximation error and the computational time of each algorithm with respect
to the increasing number of weak learners, together with the output of each algorithm with 100
weak learners trained. It demonstrates that WEvidential and full-Newton WEvidential reduce the
approximation error most efficiently, while full-Newton WEvidential takes the longest computational
time among others. As in Algorithm 4, the computation of the full approximate Wasserstein Newton
direction requires the inverse and product of the (N × d) × (N × d) block matrices, where N denotes
the particle number N and d denotes the particle dimension. The error decay of LGBoost is not
only slow but also shows stochasticity due to the Gaussian noise used in the algorithm. We therefore
recommend our default WEvidential for better performance and efficient computation."
"DBT
GIVEN",0.7067510548523207,Algorithm 4: Computation of Full Approximate Wasserstein Newton Direction
"DBT
GIVEN",0.7088607594936709,"Input: input xi, output distribution µi, outputs of N boostings (F 1
m(xi), . . . , F N
m (xi))
Output: Wasserstein Newton direction (v1
i , . . . , vN
i ) evaluated at (F 1
m(xi), . . . , F N
m (xi))
(θ1
i , . . . , θN
i ) ←(F 1
m(xi), . . . , F N
m (xi))
for n ←1, . . . , N do"
"DBT
GIVEN",0.7109704641350211,"gn
i ←1"
"DBT
GIVEN",0.7130801687763713,"N
PN
j=1 ∇log µi(θj
i )k(θj
i , θn
i ) + ∇k(θj
i , θn
i )
for k ←1, . . . , N do"
"DBT
GIVEN",0.7151898734177216,"Hnk
i
←1"
"DBT
GIVEN",0.7172995780590717,"N
PN
j=1 −∇2 log µi(θj
i )k(θj
i , θn
i )k(θj
i , θk
i ) + ∇k(θj
i , θn
i ) ⊗∇k(θj
i , θk
i )
Knk
i
←Id · k(θn
i , θk
i )
end
end
 
"
"DBT
GIVEN",0.7194092827004219,"v1
i
...
vN
i  
←  
"
"DBT
GIVEN",0.7215189873417721,"K11
i
· · ·
K1N
i
...
...
...
KN1
i
· · ·
KNN
i  
  
"
"DBT
GIVEN",0.7236286919831224,"H11
i
· · ·
H1N
i
...
...
...
HN1
i
· · ·
HNN
i  
 −1  
"
"DBT
GIVEN",0.7257383966244726,"g1
i
...
gN
i  
"
"DBT
GIVEN",0.7278481012658228,"(a) Approximation Error
(b) Computational Time"
"DBT
GIVEN",0.729957805907173,"(c) First-order
(d) Diagonal-Newton
(e) Full-Newton
(f) LGBoost"
"DBT
GIVEN",0.7320675105485233,"Figure 6: The approximation error and computational time of the four different WGBoost algorithms.
Panel (a): the approximation error of each algorithm measured by the MMD averaged over the inputs
with respect to the number of weak learners. Panel (b): the computational time with respect to the
number of weak learners in common logarithm scale. Panel (c)-(f): the outputs of the four algorithms
each with 100 weak learners used."
"DBT
GIVEN",0.7341772151898734,"E
Additional Details of Main Experiments"
"DBT
GIVEN",0.7362869198312236,"This section describes additional details of the applications in Section 4. All the experiments were
performed with x86-64 CPUs, where some of them were parallelised up to 10 CPUs and the rest uses
1 CPU. The scripts to reproduce all the experiments are provided in the source code. Appendices E.1
to E.3 describe additional details of the applications in Sections 4.1 to 4.3 respectively. Appendix E.4
describes a choice of initial constants {ϑn
0}N
n=1 for the WGBoost algorithm used in Section 4."
"DBT
GIVEN",0.7383966244725738,"E.1
Detail of Section 4.1"
"DBT
GIVEN",0.740506329113924,"The normal response distribution N(y | m, σ) in Example 1 was used in Section 4.1. The normal
response distribution has the scale parameter σ that lies only in the positive domain of the Euclidean
space R. We reparametrised it as one in the Euclidean space R by the log transform σ′ := log(σ),
which is the standard practice in Bayesian computation [20]. The inverse of the log transform"
"DBT
GIVEN",0.7426160337552743,"is the exponential transform σ = exp(σ′). The change of variable formula tells the form of the
individual-level posterior on (m, σ′) up to the normalising constant. Under the prior in Example 1,
the individual-level posterior on (m, σ′) conditional on each individual response yi is given by"
"DBT
GIVEN",0.7447257383966245,"p(m, σ′ | yi) ∝exp

−1"
"DBT
GIVEN",0.7468354430379747,"2
(yi −m)2"
"DBT
GIVEN",0.7489451476793249,exp(σ′)2
"DBT
GIVEN",0.7510548523206751,"
× exp

−1 2
m2 102"
"DBT
GIVEN",0.7531645569620253,"
×
1
exp(σ′)1.01 exp

−
0.01
exp(σ′) 
,"
"DBT
GIVEN",0.7552742616033755,"where the Jacobian determinant |dσ/dσ′| = exp(σ′) is used for the change of variable. Figure 7
shows the output of WEvidential for the old faithful geyser dataset and the conditional density
estimated through (6)."
"DBT
GIVEN",0.7573839662447257,"Figure 7: Conditional density estimation for the old faithful geyser dataset (grey dots) by WEvidential.
Left: distributional estimate (10 particles) of the location parameter for each input. Right: estimated
density by the predictive distribution (6) based on the output particles."
"DBT
GIVEN",0.759493670886076,"E.2
Detail of Section 4.2"
"DBT
GIVEN",0.7616033755274262,"Section 4.2 used the same reparametrisation of the normal response parameter (m, σ) as that of
Appendix E.2. The NLL and RMSE of each algorithm on test data {xi, yi}D
i=1 were computed by"
"DBT
GIVEN",0.7637130801687764,"NLL = −1 D D
X"
"DBT
GIVEN",0.7658227848101266,"i=1
log p(yi | xi)
and
RMSE ="
"DBT
GIVEN",0.7679324894514767,"v
u
u
t 1 D D
X"
"DBT
GIVEN",0.770042194092827,"i=1
(yi −ˆyi)2"
"DBT
GIVEN",0.7721518987341772,"where p(yi | xi) and ˆyi denote the predictive distribution and the point prediction provided by
the algorithm. For WEvidential, we standardised the responses in the training data, in which case
standardisation of test data were performed as y′
i = (yi −ytrain
mean)/ytrain
std
with the mean ytrain
mean and
standard deviation ytrain
std
of the training responses. Hence WEvidential provided the predictive
distribution p(y′
i | xi) and the point prediction ˆy′
i for the standardised responses y′
i. With no loss of
generality, the NLL and RMSE for the original responses yi can be computed as follows:"
"DBT
GIVEN",0.7742616033755274,"NLL = −1 D D
X"
"DBT
GIVEN",0.7763713080168776,"i=1
log p(yi | xi) = −1 D D
X"
"DBT
GIVEN",0.7784810126582279,"i=1
log p(y′
i | xi) + log ytrain
std ,
(19)"
"DBT
GIVEN",0.7805907172995781,RMSE =
"DBT
GIVEN",0.7827004219409283,"v
u
u
t 1 D D
X"
"DBT
GIVEN",0.7848101265822784,"i=1
(yi −(ytrain
mean + ytrain
std × ˆy′
i))2 = ytrain
std"
"DBT
GIVEN",0.7869198312236287,"v
u
u
t 1 D D
X"
"DBT
GIVEN",0.7890295358649789,"i=1
(y′
i −ˆy′
i)2,
(20)"
"DBT
GIVEN",0.7911392405063291,"where the equality of the NLL follows from the change of variable p(yi | xi) = p(y′
i | xi)/ytrain
std
and
the equality of the RMSE follows from rearranging the terms."
"DBT
GIVEN",0.7932489451476793,"We provide a brief description of each algorithm used in Section 4.2. For all the algorithms, the normal
response distribution p(y | m, σ) was specified as the response distribution, where the algorithm
produces a point or distributional estimate of the response parameter (m, σ) at each input x."
"DBT
GIVEN",0.7953586497890295,"• MCDropout [9] trains a single neural network F while dropping out each network weight
with some Bernoulli probability. It can be interpreted as a variational approximation of a
Bayesian neural network. It generates multiple subnetworks {F n}N
n=1 by subsampling the
network weights by the dropout. The predictive distribution p(y | x) is given by the model
averaging (1/N) PN
i=1 p(y | (m, σ) = F n(x)) for each input x."
"DBT
GIVEN",0.7974683544303798,"• DEnsemble [10] simply trains independent copies {F n}N
n=1 of a neural network F in
parallel. It is one of the mainstream approaches to uncertainty quantification based on deep
learning. The predictive distribution is given by the model averaging as in MCDropout."
"DBT
GIVEN",0.79957805907173,"• CDropout [55] consider a continuous relaxation of the Bernoulli random variable used in
MCDropout to optimise the Bernoulli probability of the dropout. It generates multiple sub-
networks {F n}N
n=1 by subsampling the network weights by the dropout with the optimised
probability. The predictive distribution is the same as MCDropout."
"DBT
GIVEN",0.8016877637130801,"• NGBoosting [32] is a family of gradient booting that use the natural gradient [66] of the
response distribution as a target variable of each weak learner. In contrast to other methods,
NGBoost outputs a single value F(x) to be plugged into the response-distribution parameter.
The predictive distribution p(y | x) is given by p(y | (m, σ) = F(x)) for each input x."
"DBT
GIVEN",0.8037974683544303,"• DEvidential [13] extends deep evidential learning [11], originally proposed in classification
settings, to regression settings. It considers the case where the individual-level posterior of
the response distribution falls into a conjugate parametric form, and predicts the hyperpa-
rameter of the individual-level posterior by a neural network. The predictive distribution is
also given in a conjugate closed-form."
"DBT
GIVEN",0.8059071729957806,"The algorithms used in Section 4.2 are computationally efficient uncertainty quantification methods
that are commonly-used in practice. In the following, we provide a limited yet additional comparison
of WEvidential with other Bayesian neural networks (BNNs) and a kernel-based model, Gaussian
process (GP). We used a subset of the datasets in Section 4, which were used in [67] who employed
BNNs with one hidden layer of 50 units. We additionally used a large-scale dataset, keggd. For the
keggd dataset only, we reported the NLL and RMSE of the normalised outputs without the adjustment
(19) and (20), in line with [67]. WEvidential was compared with BNNs learned by variational
inference with the reparametrisation trick (VI), deterministic variational inference (DVI), stochastic
weight averaging Gaussian (SWAG), principal component analysis subspace inference (PCA+VI),
and two-layer deep Gaussian process with 50 induced points trained via expectation propagation
(DGP1-50). Table 1 summarises the result."
"DBT
GIVEN",0.8080168776371308,"Table 4: The NLLs and RMSEs for each dataset, where the best score is underlined. The results other
than that of WEvidential were reported in [67]."
"DBT
GIVEN",0.810126582278481,"Dataset
Criteria
WEvidential
VI
DVI
SWAG
PCA+VI
DGP1-50"
"DBT
GIVEN",0.8122362869198312,boston NLL
"DBT
GIVEN",0.8143459915611815,"2.47 ± 0.16
2.43 ± 0.03
2.41 ± 0.02
2.76 ± 0.13
2.72 ± 0.13
2.33 ± 0.06
concrete
2.83 ± 0.11
3.04 ± 0.02
3.06 ± 0.01
3.01 ± 0.09
2.99 ± 0.10
3.13 ± 0.03
energy
0.53 ± 0.08
2.38 ± 0.02
1.01 ± 0.06
1.70 ± 1.50
1.72 ± 1.59
1.32 ± 0.03
naval
-5.47 ± 0.03
-5.87 ± 0.29
-6.29 ± 0.04
-6.71 ± 0.11
-6.71 ± 0.11
-3.60 ± 0.33
yacht
0.16 ± 0.24
1.68 ± 0.04
0.47 ± 0.03
0.40 ± 0.42
0.40 ± 0.42
1.39 ± 0.14
keggd
-0.91 ± 0.04
-
-
-1.08 ± 0.04
-1.09 ± 0.03
-
boston RMSE"
"DBT
GIVEN",0.8164556962025317,"2.78 ± 0.60
-
-
3.52 ± 0.98
3.46 ± 0.95
-
concrete
4.15 ± 0.52
-
-
5.23 ± 0.42
5.14 ± 0.42
-
energy
0.42 ± 0.07
-
-
1.59 ± 0.27
1.59 ± 0.27
-
naval
0.00 ± 0.00
-
-
0.00 ± 0.00
0.00 ± 0.00
-
yacht
0.48 ± 0.18
-
-
0.97 ± 0.38
0.97 ± 0.38
-
keggd
0.24 ± 0.01
-
-
0.13 ± 0.03
0.13 ± 0.03
-"
"DBT
GIVEN",0.8185654008438819,"E.3
Detail of Section 4.3"
"DBT
GIVEN",0.820675105485232,"We reparametrised the parameter of the categorical response distribution C(y | q) used in Section 4.3,
similarly to the normal response distribution used in Sections 4.1 and 4.2. The categorical response
distribution has a class probability parameter q = [q1, . . . , qk] in the simplex ∆k. We applied the
log-ratio transform q′ := [log(q1/qk), . . . , log(qk−1/qk)] ∈Rk−1 that maps from the simplex ∆k to
the Euclidean space Rk−1 [42]. The inverse of the log-ratio transform is the logistic transform"
"DBT
GIVEN",0.8227848101265823,"q =
exp(q′
1)
zk
, . . . , exp(q′
k−1)
zk
, 1 zk"
"DBT
GIVEN",0.8248945147679325,"
∈∆k
where
zk = 1 + k−1
X"
"DBT
GIVEN",0.8270042194092827,"j=1
exp(q′
j)."
"DBT
GIVEN",0.8291139240506329,"The logistic normal distribution on the original parameter q corresponds to a normal distribution on
the transformed parameter q′ [42]. The change of variable formula tells the individual-level posterior
on q′ up to the normalising constant. Under the prior in Example 2, the individual-level posterior"
"DBT
GIVEN",0.8312236286919831,p(q′ | yi) conditional on each individual observed response yi is given by
"DBT
GIVEN",0.8333333333333334,"p(q′ | yi) ∝
 1 zk"
"DBT
GIVEN",0.8354430379746836,"[yi=k]
× k−1
Y j=1"
"DBT
GIVEN",0.8375527426160337,"exp(q′
j)
zk"
"DBT
GIVEN",0.8396624472573839,"[yi=j]
× exp

−1"
"DBT
GIVEN",0.8417721518987342,"2
∥q′∥2 102 
,"
"DBT
GIVEN",0.8438818565400844,where [yi = j] is 1 if yi is the j-th class label and 0 otherwise.
"DBT
GIVEN",0.8459915611814346,"We provide a brief description of each algorithm used in Section 4.3. MCDropout and DEnsemble
are described in Appendix E.2."
"DBT
GIVEN",0.8481012658227848,"• DDistillation [57] predicts the parameter of a Dirichlet distribution over the simplex ∆k
by a neural network using the output of DEnsemble. The output of multiple networks in
DEnsemble is distilled into the Dirichlet distribution controlled by one single network."
"DBT
GIVEN",0.8502109704641351,"• PNetwork [14] considers the case where the individual-level posterior of the categorical
response distribution falls into a Dirichlet distribution similarly to deep evidential learning
[11]. It predicts the hyperparameter of the individual-level posterior given in the form of the
Dirichlet distribution."
"DBT
GIVEN",0.8523206751054853,"For the OOD detection, the OOD score we used was the inverse of the maximum norm of the variance
of the WEvidential output. There are other quantities that are possible to use as the OOD score. For
example, the entropy of the predictive distribution p(y | x) is a quantity computable for any proba-
bilistic classification method. We compared the OOD detection performance of WEvidential with that
of NGBoost and Random Forest (RForest) based on the entropy of their predictive distributions. For
reference, we also computed the OOD detection performance of WEvidential based on the entropy of
the predictive distribution. For NGBoost, the decision tree regressor was used for each weak learner
and 4000 weak learners were trained with the learning rate 0.01. For RForest, the maximum depth 3
was used. Table 5 shows the result on the segment dataset, demonstrating that the performance of
WEvidential is higher, to a large margin, than that of NGBoost and RForest based on the entropy."
"DBT
GIVEN",0.8544303797468354,"Table 5: The OOD detection performance of WEvidential, NGBoost, and RForest on the segment
dataset, where WEvidential (Entropy) indicates the result of WEvidential based on the entropy."
"DBT
GIVEN",0.8565400843881856,"Dataset
Criteria
WEvidential
WEvidential (Entropy)
NGBoost
RForest"
"DBT
GIVEN",0.8586497890295358,"segment
Accuracy
96.57 ± 0.6
96.57 ± 0.6
94.09 ± 0.6
88.18 ± 1.6
OOD
99.67 ± 0.2
98.96 ± 0.4
89.96 ± 1.3
66.51 ± 1.1"
"DBT
GIVEN",0.8607594936708861,"To investigate on the effective learning rate of WEvidential for classification, we performed a simple
simulation study of WEvidential using the synthetic madelon dataset. We created 600 data points of
three-dimensional inputs and three-class labels. The data subset that belongs to the last class was
kept as the OOD samples. We randomly held out 20% of non-OOD samples as a test set to measure
the test classification accuracy. We trained WEvidential using different learning rates from 0.1 to 1.0
while fixing the number of weak learners to 4000. Table 6 shows that the result for the learning rate
0.4 demonstrates the best classification accuracy and the third best OOD detection performance. We
also trained WEvidential using different numbers of weak learners from 1000 to 4000 while fixing the
learning rate to 0.4. Table 7 shows that the result for the number of weak learners 4000 demonstrates
the best classification accuracy and the second best OOD detection performance. While the most
effective learning rate differs depending on each dataset, we drew on the insight obtained from the
simulation study and set the learning rate to 0.4 for classification."
"DBT
GIVEN",0.8628691983122363,"Table 6: The classification accuracy and OOD detection performance of WEvidential on the synthetic
dataset for different learning rates, where the number of weak learners is fixed to 4000."
"DBT
GIVEN",0.8649789029535865,"Criteria
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0"
"DBT
GIVEN",0.8670886075949367,"Accuracy
92.50
92.50
92.50
93.75
91.25
86.25
90.00
75.00
85.00
80.00
OOD
29.85
34.79
35.26
41.77
40.52
42.69
35.21
35.58
42.04
36.05"
"DBT
GIVEN",0.869198312236287,"Table 7: The classification accuracy and OOD detection performance of WEvidential on the synthetic
dataset for different numbers of weak learners, where the learning rate is fixed to 0.4."
"DBT
GIVEN",0.8713080168776371,"Criteria
1000
2000
3000
4000"
"DBT
GIVEN",0.8734177215189873,"Accuracy
91.25
92.50
91.25
93.75
OOD
43.96
37.70
39.84
41.77"
"DBT
GIVEN",0.8755274261603375,"E.4
Choice of Initial State of WGBoost"
"DBT
GIVEN",0.8776371308016878,"In standard gradient boosting, the initial state at step m = 0 is specified by a constant that most fits
given data. Similarly, we specified the initial state {ϑn
0}N
n=1 of WEvidential by a set of constants
that most fits the output distributions in average. We find such a set of constants by performing
an approximate Wasserstein gradient flow averaged over all the output distributions. Specifically,
given the term Gi(µ) in Algorithm 1, we define ¯G(µ) := (1/D) PD
i=1 Gi(µ) and perform the update
scheme of a set of N particles {¯ϑn
m}N
n=1:
 "
"DBT
GIVEN",0.879746835443038,"¯ϑ1
m+1
...
¯ϑN
m+1  =  "
"DBT
GIVEN",0.8818565400843882,"¯ϑ1
m...
¯ϑN
m "
"DBT
GIVEN",0.8839662447257384,+ ν0  
"DBT
GIVEN",0.8860759493670886,"−[ ¯G(ˆπm)](¯ϑ1
m)
...
−[ ¯G(ˆπm)](¯ϑN
m)  "
"DBT
GIVEN",0.8881856540084389,"with the learning rate ν0 = 0.01 up to the maximum step number m = 5000. The initial particle
locations for this update scheme were sampled from a standard normal distribution. We specified the
initial state {ϑn
0}N
n=1 by the set of particles {¯ϑn
m}N
n=1 obtained though this scheme at m = 5000."
"DBT
GIVEN",0.890295358649789,NeurIPS Paper Checklist
CLAIMS,0.8924050632911392,1. Claims
CLAIMS,0.8945147679324894,"Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?"
CLAIMS,0.8966244725738397,"Answer: [Yes]
Justification: The claim made in the abstract and introduction were elaborated in the
subsequent section and empirically demonstrated through the experiments."
CLAIMS,0.8987341772151899,Guidelines:
CLAIMS,0.9008438818565401,"• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper."
LIMITATIONS,0.9029535864978903,2. Limitations
LIMITATIONS,0.9050632911392406,Question: Does the paper discuss the limitations of the work performed by the authors?
LIMITATIONS,0.9071729957805907,"Answer: [Yes]
Justification: A concise discussion on the important remaining questions and the potential
limitation were provided in the last section."
LIMITATIONS,0.9092827004219409,Guidelines:
LIMITATIONS,0.9113924050632911,"• The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ""Limitations"" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations."
THEORY ASSUMPTIONS AND PROOFS,0.9135021097046413,3. Theory Assumptions and Proofs
THEORY ASSUMPTIONS AND PROOFS,0.9156118143459916,"Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?"
THEORY ASSUMPTIONS AND PROOFS,0.9177215189873418,"Answer: [NA] .
Justification: This work primarily focused on the methodological development of the
proposed algorithm, empirically demonstrating the performance on the various benchmarks.
Guidelines:"
THEORY ASSUMPTIONS AND PROOFS,0.919831223628692,"• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4. Experimental Result Reproducibility"
THEORY ASSUMPTIONS AND PROOFS,0.9219409282700421,"Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: The computational procedure of the proposed algorithm was clarified in the
main text and appendix, with the setting to reproduce the experiments detailed.
Guidelines:"
THEORY ASSUMPTIONS AND PROOFS,0.9240506329113924,"• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5. Open access to data and code"
THEORY ASSUMPTIONS AND PROOFS,0.9261603375527426,"Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?"
THEORY ASSUMPTIONS AND PROOFS,0.9282700421940928,Answer: [Yes]
THEORY ASSUMPTIONS AND PROOFS,0.930379746835443,"Justification: The source code is available online with the instruction, and also submitted in
the supplementary file. For the blind review process, the source code URL was masked in
the manuscript. The source code URL will be unmasked after the review process."
THEORY ASSUMPTIONS AND PROOFS,0.9324894514767933,Guidelines:
THEORY ASSUMPTIONS AND PROOFS,0.9345991561181435,"• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy) for more details.
• While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted."
THEORY ASSUMPTIONS AND PROOFS,0.9367088607594937,6. Experimental Setting/Details
THEORY ASSUMPTIONS AND PROOFS,0.9388185654008439,"Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?"
THEORY ASSUMPTIONS AND PROOFS,0.9409282700421941,Answer: [Yes]
THEORY ASSUMPTIONS AND PROOFS,0.9430379746835443,Justification: All the experimental setting was clarified in the main text and appendix.
THEORY ASSUMPTIONS AND PROOFS,0.9451476793248945,Guidelines:
THEORY ASSUMPTIONS AND PROOFS,0.9472573839662447,"• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9493670886075949,7. Experiment Statistical Significance
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9514767932489452,"Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9535864978902954,Answer: [Yes]
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9556962025316456,"Justification: All the experiments to measure the predictive performance of the proposed
algorithm were repeated several times to estimate the standard deviation of the score."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9578059071729957,Guidelines:
EXPERIMENT STATISTICAL SIGNIFICANCE,0.959915611814346,"• The answer NA means that the paper does not include experiments.
• The authors should answer ""Yes"" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9620253164556962,"• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8. Experiments Compute Resources"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9641350210970464,"Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: The computer resource was clarified in the appendix.
Guidelines:"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9662447257383966,"• The answer NA means that the paper does not include experiments.
• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9. Code Of Ethics"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9683544303797469,"Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
Answer: [Yes]
Justification: The conducted research conforms the NeurIPS Code of Ethics.
Guidelines:"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9704641350210971,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10. Broader Impacts"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9725738396624473,"Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: This work proposed a generic algorithm that is not tied to specific applications.
Guidelines:"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9746835443037974,"• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9767932489451476,"• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11. Safeguards"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9789029535864979,"Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: This work proposed a generic algorithm.
Guidelines:"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9810126582278481,"• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12. Licenses for existing assets"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9831223628691983,"Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: The credit and license were appropriately included in the text and source code.
Guidelines:"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9852320675105485,"• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
• If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset."
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9873417721518988,"• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13. New Assets"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.989451476793249,"Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [Yes] .
Justification: The documentation and license were included in the source code.
Guidelines:"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9915611814345991,"• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used.
• At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14. Crowdsourcing and Research with Human Subjects"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9936708860759493,"Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: This work does not involve crowdsourcing nor research with human subjects.
Guidelines:"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9957805907172996,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: This work does not involve crowdsourcing nor research with human subjects.
Guidelines:"
EXPERIMENT STATISTICAL SIGNIFICANCE,0.9978902953586498,"• The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
• Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review."
