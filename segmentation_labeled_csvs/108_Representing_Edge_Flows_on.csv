Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.00273224043715847,"Obtaining sparse, interpretable representations of observable data is crucial in
many machine learning and signal processing tasks. For data representing flows
along the edges of a graph, an intuitively interpretable way to obtain such repre-
sentations is to lift the graph structure to a simplicial complex: The eigenvectors
of the associated Hodge-Laplacian, respectively the incidence matrices of the cor-
responding simplicial complex then induce a Hodge decomposition, which can be
used to represent the observed data in terms of gradient, curl, and harmonic flows.
In this paper, we generalize this approach to cellular complexes and introduce
the flow representation learning problem, i.e., the problem of augmenting the
observed graph by a set of cells, such that the eigenvectors of the associated
Hodge Laplacian provide a sparse, interpretable representation of the observed
edge flows on the graph. We show that this problem is NP-hard and introduce an
efficient approximation algorithm for its solution. Experiments on real-world and
synthetic data demonstrate that our algorithm outperforms state-of-the-art meth-
ods with respect to approximation error, while being computationally efficient."
INTRODUCTION,0.00546448087431694,"1
Introduction"
INTRODUCTION,0.00819672131147541,"In a wide range of applications, we are confronted with data that can be described by flows supported
on the edges of a graph [1, 2]. Some particularly intuitive and important examples include traffic
flows within a street network [3], flows of money between economic agents [4, 5], or flows of data
between routers in a computer network [6]. However, many other scenarios in which some energy,
mass, or information flows along the edges of a graph may be abstracted in a similar way [7]."
INTRODUCTION,0.01092896174863388,"As is the case for many other setups in machine learning and signal processing [8–10], finding
a compact and interpretable approximate representation of the overall pattern of such flows is an
important task to assess qualitative features of the observed flow data. In the context of flows on
graphs, the so-called (discrete) Hodge-decomposition [11–16] has recently gained prominence to
process such flow signals, as it can be employed to represent any flow on a graph (or more generally,
cellular complex) as a sum of a gradient, curl and harmonic components, which can be intuitively
interpreted. This representation of the data may then be used in a variety of downstream tasks [17],
such as prediction of flow patterns [18–20], classification of trajectories [21–23], or to smooth or
interpolate (partially) observed flow data [24, 25]. Furthermore, deep learning approaches on cell
complexes that need or infer cells are currently gaining traction [26–29]."
INTRODUCTION,0.01366120218579235,"Commonly considered mathematical problem formulations to find a compact representation of data
are (variants of) sparse dictionary learning [10], in which the aim is to find a sparse linear combination
of a set of fundamental atoms to approximate the observed data. Accordingly, such types of dictionary
learning problems have also been considered to learn representations of flows on the edges of a
graph [14, 30–33]. Since the Hodge-decomposition yields an orthogonal decomposition of the flows
into non-cyclic (gradient) flows and cyclic flows, these signal components can be approximated via
separate dictionaries, and as any gradient flow component can be induced by a potential function
supported on the vertices of the graph, the associated problem of fitting the gradient flows can be
solved via several standard techniques, e.g., by considering the associated eigenvectors of the graph
Laplacian. To find a corresponding representation of the cyclic flows, in contrast, it has been proposed"
INTRODUCTION,0.01639344262295082,Representing Edge Flows on Graphs via Sparse Cell Complexes
INTRODUCTION,0.01912568306010929,"to lift the observed graph to a simplicial or cellular complex, and then identifying which simplices (or
more generally, cells) need to be included in the complex to obtain a good sparse approximation of
the circular components of the observed flows [14, 30–32]."
INTRODUCTION,0.02185792349726776,"Such inferred cell complexes can moreover be useful for a variety of downstream tasks, e.g., data
analysis based on as neural networks [26, 27]. In fact, even augmenting graphs by adding randomly
selected simplices can lead to significant improvements [34] for certain learning tasks. Arguably,
having more principled selection methods available could thus be beneficial. For instance, the
approach of [28] could potentially be improved by replacing the selection from a pre-defined set
of cells with our approach, reducing its input data demands. Simplicial and cellular complex
based representations have also gained interest in neuroscience recently to desribe the topology of
interactions in the brain [35]."
INTRODUCTION,0.02459016393442623,"However, previous approaches for the inference of cells from edge flow data limit themselves to
simplicial complexes or effectively assume that the set of possible cells to be included is known
beforehand. Triangles are not sufficient to model all cells that occur in real-world networks: For
example, grid-like road networks contain virtually no triangles, necessitating the generalization to
cell complexes. In other applications, triangles may be able to approximate longer 2-cells, which still
results in a unnecessarily complex representation. In this work, we consider a general version of this
problem which might be called flow representation learning problem: given a set of edge-flows on a
graph, find a lifting of this graph into a regular cell-complex with a small number of 2-cells, such
that the observed (cyclic) edge-flows can be well-approximated by potential functions associated to
the 2-cells. As the solution of this problem naturally leads to the construction of an associated cell
complex, we may alternatively think of the problem as inferring an (effective) cell-complex from
observed flow patterns."
INTRODUCTION,0.0273224043715847,"Our main contributions are as follows: First, we provide a formal introduction of the flow representa-
tion learning problem and its relationships to other problem formulations. Second, we prove that the
general form of flow representation learning we consider here is NP hard. Third, we provide heuristics
to solve this problem and characterize their computational complexity. Finally, we demonstrate that
our algorithms outperform current state of the art approaches in this context."
INTRODUCTION,0.030054644808743168,"Outline The remainder of this article is structured as follows. In Section 2, we provide a brief recap
of notions from algebraic topology, as well as ideas from graph and topological signal processing.
Section 3 then provides a formal statement of the problem considered, followed by our proposed
algorithmic solution (see Section 4). Our theoretical hardness results are given in Section 5. We
demonstrate the utility of our approach with numerical experiments in Section 6, before providing a
brief conclusion."
INTRODUCTION,0.03278688524590164,"1.1
Related work"
INTRODUCTION,0.03551912568306011,"Finding cycle bases. The cycle space of an undirected graph G is the set of all even-degree subgraphs
of G. Note that the cycle space is orthogonal to the space of gradient flows and (for unweighted
graphs) isomorphic to the space of cyclic flows. A lot of research has been conducted on finding both
general and specific cycle bases [36–38]. Our algorithm uses the central idea that the set of all cycles
induced by combining a spanning tree with all non-tree edges is a cycle basis. However, since we
aim for a sparse representation instead of a complete cycle basis, this paper has a different focus. In
this paper, you may therefore think of a cycle basis as a set of simple cycles that covers all edges."
INTRODUCTION,0.03825136612021858,"Graph Signal Processing and Topological Signal Processing. The processing of signals defined
on graphs has received large attention over the last decade [39–41]. The extension of these ideas to
topological spaces defined via simplicial or cellular complexes has recently gained attention [14, 15,
17, 25, 28, 30, 31, 33], with a particular focus on the processing of flows on graphs [25]."
INTRODUCTION,0.040983606557377046,"The problem we consider here is closely related to a sparse dictionary learning problem [10] for
edge-flows. In contrast to previous formulations [14, 28, 30, 31], we do not assume that set of cells
(the dictionary) is given, which creates a more computationally difficult problem we need to tackle."
INTRODUCTION,0.04371584699453552,"Compressive Sensing Compressive Sensing (CS) [42, 43] may be interpreted as a variant of sparse
dictionary learning that finds a sparse approximation from an underdetermined system of equations.
Although different in both methodology and goals, it is noteworthy that it has been successfully
applied in the context of graphs [44]. A CS application of the graph Laplacian [45] indicates that the
lifting to a higher-dimensional Hodge Laplacian could also be used in this context."
INTRODUCTION,0.04644808743169399,Representing Edge Flows on Graphs via Sparse Cell Complexes
LIT REVIEW,0.04918032786885246,"2
Background and Preliminaries"
LIT REVIEW,0.05191256830601093,"In this section, we recap common concepts from algebraic topology and set up some notation. In this
paper we only consider cell complexes with cells of dimension two or lower, so we will only introduce
the required parts of the theory. However, in general, cell complexes have no such limitation, and our
methodology can be adapted to also work on cells of higher dimensions [46]."
LIT REVIEW,0.0546448087431694,"Cell Complexes. At an intuitive level, cell complexes are extensions of graphs that not only
have vertices (0-dimensional cells) and edges (1-dimensional cells), but also (polygonal) faces
(2-dimensional cells). Such faces can be defined by a closed, non-intersecting path (or simple
cycle) along the graph, such that the path forms the boundary of the polygonal cell. Simplicial
complexes may be seen as a special case of of cell complexes, in which only triangles are allowed as
2-dimensional cells. We refer to [46] for a general introduction to algebraic topology. Our exposition
of the background on cell complexes in the whole section below is adapted from [33]."
LIT REVIEW,0.05737704918032787,"Within the scope of this paper, a cell complex (CC) C consists of a set of so-called cells of different
dimensions k ∈{0, 1, 2}. For our complex C , we denote the set k-cells by Ck. The k-skeleton of C
is the cell complex consisting of all l-cells in C with dimension l ≤k. Akin to graphs, we call the
elements of C0 the nodes and denote them by vi for i ∈1, . . . , |C0|. Analogously, the elements ei for
i ∈1, . . . , |C1| included in C1 are called the edges of the cell complex, and we call the elements θi
for i ∈1 . . . , |C2| included in C2 the polygons of the complex."
LIT REVIEW,0.060109289617486336,"Oriented Cells. To facilitate computations we assign a reference orientation to each edge and
polygon within a cell complex. We use the notation ⃗ek = [vi, vj] to indicate the k-th oriented edge
from node vi to node vj, and denote its oppositely oriented counterpart as ⃗"
LIT REVIEW,0.06284153005464481,"ek = [vj, vi]. The k-th
oriented 2-cell, labeled as ⃗θk, is defined by the ordered sequence ⃗ei, . . . ,⃗ej of oriented edges, forming
a non-intersecting closed path. Note that within the sequence ⃗θk some edges ⃗"
LIT REVIEW,0.06557377049180328,"eℓmay appear opposite
their reference orientation. Any cyclic permutation of the ordered tuple ⃗θk defines the same 2-cell; a
flip of both the orientation and ordering of all the edges defining ⃗θk corresponds to a change in the
orientation of the 2-cell, i.e., ⃗"
LIT REVIEW,0.06830601092896176,θk = [ ⃗
LIT REVIEW,0.07103825136612021,"ej, . . . , ⃗ ei]."
LIT REVIEW,0.07377049180327869,"Chains and cochains. Given a reference orientation for each cell, for each k, we can define a
finite-dimensional vector space Ck with coefficients in R whose basis elements are the oriented
k-cells. An element φk ∈Ck is called a k-chain and may be thought of as a formal linear combination
of these basis elements. For instance, a 1-chain may be written as φ1 = P"
LIT REVIEW,0.07650273224043716,"i ai⃗ei for some ai ∈R.
We further impose that an orientation change of the basis elements corresponds to a change in the sign
of the coefficient ai. Hence, flipping the orientation of a basis element, corresponds to multiplying the
corresponding coefficient ai by −1, e.g., a1⃗e1 = −a1 ⃗"
LIT REVIEW,0.07923497267759563,"e1. As for any k the space Ck is isomorphic to
R|Ck|, we may compactly represent each element φk ∈Ck by a vector c = (a1, ..., a|Ck|)⊤. Further,
we endow each space Ck with the standard ℓ2 inner product ⟨c1, c2⟩= c⊤
1 c2, and thus give Ck the
structure of a finite-dimensional Hilbert space."
LIT REVIEW,0.08196721311475409,"The space of k-cochains is the dual space of the space of k-chains and denoted as Ck := C∗
k. In the
finite case, these spaces are isomorphic and so we will not distinguish between those two spaces in
the following for simplicity. (Co-)chains may also be thought of as assigning a scalar value to each
cell, representing a signal supported on the cells. In the following, we concentrate on edge-signals
on CCs, which we will think of as flows. These can be conveniently described by cochains and
represented by a vector."
LIT REVIEW,0.08469945355191257,"Boundary maps. Chains of different dimensions can be related via boundary maps ∂k : Ck →Ck−1,
which map a chain to a sum of its boundary components. In terms of their action on the respective basis
elements, these maps are defined as: ∂1(⃗e) = ∂([vi, vj]) = vi −vj and ∂2(⃗θ) = ∂2([⃗ei1, . . . ,⃗eim]) =
Pm
j=1 ⃗eij. Since all the spaces involved are finite dimensional we can represent these boundary
maps via matrices B1 and B2, respectively, which act on the corresponding vector representations
of the chains. Figure 6 shows a simple CC and its boundary maps. The dual co-boundary maps
∂⊤
k : Ck−1 →Ck, map cochains of lower to higher-dimensions. Given the inner-product of Ck, these
are the adjoint maps to ∂k and their matrix representation is thus given by B⊤
1 and B⊤
2 , respectively."
LIT REVIEW,0.08743169398907104,"The Hodge Laplacian and the Hodge decomposition Given a regular CC C with boundary matrices
as defined above, we define the k-th combinatorial Hodge Laplacian [12, 13, 15] by:"
LIT REVIEW,0.09016393442622951,"Lk = B⊤
k Bk + Bk+1B⊤
k+1
(1)"
LIT REVIEW,0.09289617486338798,Representing Edge Flows on Graphs via Sparse Cell Complexes
LIT REVIEW,0.09562841530054644,"Specifically, the 0-th Hodge Laplacian operator, is simply the graph Laplacian L0 = B1B⊤
1 of the
graph corresponding to the 1-skeleton of the CC (note that B0 := 0 by convention)."
LIT REVIEW,0.09836065573770492,"Using the fact that the boundary of a boundary is empty, i.e., ∂k ◦∂k+1 = 0 and the definition of
Lk, it can be shown that the space of k-cochains on C admits a so-called Hodge-decomposition
[12, 13, 15]:
Ck = Im(∂k+1) ⊕Im(∂⊤
k ) ⊕ker(Lk).
(2)"
LIT REVIEW,0.10109289617486339,"In the context of 1-cochains, i.e., flows, this decomposition is the discrete equivalent of the celebrated
Helmholtz decomposition for a continuous vector fields [15]. Specifically, we can create any gradient
signal via a 0-cochain ϕ ∈C0 assigning a potential ϕi to each node i in the complex, and then
applying the co-boundary map ∂⊤
1 . Likewise, any curl flow can be created by applying the boundary
map ∂2 to a 2-chain η ∈C2 of 2-cell potentials."
LIT REVIEW,0.10382513661202186,"Importantly, it can be shown that each of the above discussed three subspaces is spanned by a
set of eigenvectors of the Hodge Laplacian. Namely, the eigenvectors of the lower Laplacian
Llow
k
= B⊤
k Bk precisely span Im(B⊤
k ) (the gradient space); the eigenvectors of the upper Laplacian
Lup
k = Bk+1B⊤
k+1 span Im(Bk+1) (curl space), and the eigenvectors associated to zero eigenvalues
span the harmonic subspace."
LIT REVIEW,0.10655737704918032,"We denote the projection of any edge flow f ∈C1 into the gradient, curl, or harmonic subspace of C
by gradC (f) = BT
1 (BT
1 )†f, curlC (f) = B2(B2)†f, or harmC (f) = (I −L1L†
1)f respectively. Here
(·)† denotes the Moore-Penrose Pseudoinverse."
IMPLEMENTATION/METHODS,0.1092896174863388,"3
Problem Formulation"
IMPLEMENTATION/METHODS,0.11202185792349727,"Consider a given a Graph G with N ∈N nodes and E ∈N edges, which are each endowed with an
(arbitrary but fixed) reference orientation, as encoded in an node-to-edge incidence matrix B1. We
assume that we can observe s ∈N sampled flow vectors fi, for i = 1, . . . , s defined on the edges.
We assemble these vectors into the matrix F = [f1, . . . , fs] ∈RE×s."
IMPLEMENTATION/METHODS,0.11475409836065574,"Our task is now to find a good approximation of F in terms of a (sparse) set of gradient and curl
flows, respectively. Leveraging the Hodge-decomposition, this problem can be decomposed into two
orthogonal problems. The problem of finding a suitably sparse set of gradient flows can be formulated
as a (sparse) regression problem, that aims to find a suitable set of node potentials ϕ such that B⊤
1 ϕ
approximates the observed flows under a suitably chosen norm (or more general cost function). This
type of problem has been considered in the literature in various forms [40]. We will thus focus here
on the second aspect of the problem, i.e., we aim to find a sparse set of circular flows that approximate
the observed flows F. Without loss of generality we will thus assume in the following that fi are
gradient free flows (otherwise, we may simply project out the gradient component using B1)."
IMPLEMENTATION/METHODS,0.11748633879781421,This task may be phrased in terms of the following dictionary learning problem:
IMPLEMENTATION/METHODS,0.12021857923497267,"min
ξ,B2 s
X"
IMPLEMENTATION/METHODS,0.12295081967213115,"i=1
∥fi −B2ξ∥2
2
s.t.
∥ξ∥0 < k1, ∥B2∥0 < k2 and B2 ∈B2,
(3)"
IMPLEMENTATION/METHODS,0.12568306010928962,"where B2 is the set of valid edge-to-cell incidence matrices of cell complexes C whose 1-skeleton is
equivalent to G, and k1, k2 are some positive chosen integers. Note that the above problem may be
seen as trying to infer a cellular complex with a sparse set of polygonal cells, such that the orginally
observed flows have a small projection into the harmonic space of the cell complex — in other words,
we want to infer a cellular complex, that leads to a good sparse representation of the edge flows."
IMPLEMENTATION/METHODS,0.1284153005464481,"In the following, we thus adopt a problem in which are concerned with the following loss function"
IMPLEMENTATION/METHODS,0.13114754098360656,"loss(C , F) = ∥harmC (F)∥F ="
IMPLEMENTATION/METHODS,0.13387978142076504,"v
u
u
t s
X"
IMPLEMENTATION/METHODS,0.1366120218579235,"i=1
||harmC (fi)||2
2,
s.t.
C has G as 1-skeleton
(4)"
IMPLEMENTATION/METHODS,0.13934426229508196,"There are two variants of the optimization problem we look at. First, we investigate a variant with a
constraint on the approximation loss:"
IMPLEMENTATION/METHODS,0.14207650273224043,"min
C |C2|
s.t.
loss(C , F) < ε
(P1)"
IMPLEMENTATION/METHODS,0.1448087431693989,Representing Edge Flows on Graphs via Sparse Cell Complexes
IMPLEMENTATION/METHODS,0.14754098360655737,"max. spanning tree
& possible 2-cells"
IMPLEMENTATION/METHODS,0.15027322404371585,(Loss: 0.44)
IMPLEMENTATION/METHODS,0.15300546448087432,add 2-cell to complex
IMPLEMENTATION/METHODS,0.1557377049180328,"Loss: 0.44
Loss: 1.68"
IMPLEMENTATION/METHODS,0.15846994535519127,evaluate cell candidates via harmonic flows
IMPLEMENTATION/METHODS,0.16120218579234974,Loss: 2.4
IMPLEMENTATION/METHODS,0.16393442622950818,harmonic flows
IMPLEMENTATION/METHODS,0.16666666666666666,"loss < ε or
|2-cells| = n?"
IMPLEMENTATION/METHODS,0.16939890710382513,Input: Flows
IMPLEMENTATION/METHODS,0.1721311475409836,"Outputs:
Inferred cell complex
& sparse approximation
Calculate harmonic flows on updated complex"
IMPLEMENTATION/METHODS,0.17486338797814208,"Yes
No"
IMPLEMENTATION/METHODS,0.17759562841530055,"Figure 1: Overview of cell complex inference: Our approach starts with a graph and flows supported
on its edges. It iteratively adds 2-cells until it fulfills the termination condition. In each iteration,
the algorithm projects the flows into the (new) harmonic subspace, selecting cell candidates using a
spanning-tree-based heuristic, and adding the cell that minimizes the harmonic flow."
IMPLEMENTATION/METHODS,0.18032786885245902,"Second, we consider a variant with a sparsity constraint on the number of 2-cells:"
IMPLEMENTATION/METHODS,0.1830601092896175,"min
C loss(C , F)
s.t.
|C2| ≤n
(P2)"
IMPLEMENTATION/METHODS,0.18579234972677597,"Finally, to assess the computational complexity of the problem, we introduce the decision problem:
Given a graph and edge flows, can it be augmented with n cells s.t. the loss is below a threshold ε?"
IMPLEMENTATION/METHODS,0.1885245901639344,"DCS(G, F, n, ε) := ∃C ⊇G : |C2| ≤n,
loss(C , F) < ε?
(DCS)"
IMPLEMENTATION/METHODS,0.1912568306010929,"4
Algorithmic Approach"
IMPLEMENTATION/METHODS,0.19398907103825136,"We now present a greedy algorithm that approximates a solution for both minimization problems
(see Figure 1). It starts with a cell complex C (0) equivalent to G and iteratively adds a new 2-cell θi:"
IMPLEMENTATION/METHODS,0.19672131147540983,"C (i) := C (i−1) ∪{θi},
θi :=
min
θ∈cs(C (i−1),F,m) loss(C (i−1) ∪{θ}, F)"
IMPLEMENTATION/METHODS,0.1994535519125683,"until i = n or loss(C (i), F) < ε, respectively. Here, cs(·) denotes a candidate search heuristic, a
function that, given a CC and corresponding flows, returns a set of up to m ∈N cell candidates."
IMPLEMENTATION/METHODS,0.20218579234972678,"4.1
Candidate search heuristics"
IMPLEMENTATION/METHODS,0.20491803278688525,"Our algorithm requires a heuristic to select cell candidates because the number of valid cells, i.e.,
simple cycles, can be in Ω(e|C0|) in the worst case (see appendix B.1). To reduce the number of cells
considered, the heuristics we introduce here consider one or a small number of cycle bases instead of
all cycles. Since each cycle basis has a size of |C1| −|C0| + 1, it would be inefficient to construct and
evaluate all cycles in the cycle basis. Instead, we approximate the change in loss via the harmonic
flow around a cycle, normalized by the length of the cycle."
IMPLEMENTATION/METHODS,0.20765027322404372,"Recall that a cycle basis can be constructed from any spanning tree T: Each edge (u, v) /∈T induces
a simple cycle by closing the path from u to v through T. Both heuristics efficiently calculate the flow
using the spanning tree and select the m cycles with the largest flow as candidates. Since the selection
of spanning trees is so crucial, we introduce two different criteria as discussed below. Appendix B.2
discusses the heuristics in more detail and provides an example of one iteration for each heuristic."
IMPLEMENTATION/METHODS,0.2103825136612022,Representing Edge Flows on Graphs via Sparse Cell Complexes
IMPLEMENTATION/METHODS,0.21311475409836064,"Maximum spanning tree. The maximum spanning tree heuristic is based on the idea that cycles with
large overall flows also have large flows on most edges (when projected into the harmonic subspace).
Since harmonic flows are cyclic flows, the directions tend to be consistent. However, there may
be variations in the signs of the sampled flows fi. Therefore, the maximum spanning tree heuristic
constructs a spanning tree that is maximal w.r.t. the sum of absolute harmonic flows. See Algorithm 1
for pseudocode."
IMPLEMENTATION/METHODS,0.21584699453551912,"Similarity spanning trees. The maximum spanning tree heuristic does not account for the fact that
there might be similar pattern within the different samples. Given flows F ∈RE×s, we can represent
an edge e using its corresponding row vector Fe,_. To account for orientation, we insert an edge in
both orientations, i.e., both Fe,_ and −Fe,_. This makes it possible to detect common patterns using
k-means clustering. Our similarity spanning trees heuristic exploits this by constructing one spanning
tree per cluster center, using the most similar edges. See Algorithm 2 for pseudocode."
IMPLEMENTATION/METHODS,0.2185792349726776,"5
Theoretical Considerations"
IMPLEMENTATION/METHODS,0.22131147540983606,"5.1
NP-Hardness of Cell Selection"
IMPLEMENTATION/METHODS,0.22404371584699453,Theorem 1. The decision variant of cell selection is NP-hard.
IMPLEMENTATION/METHODS,0.226775956284153,We give a quick sketch of the proof here; you can find the complete proof in appendix D.
IMPLEMENTATION/METHODS,0.22950819672131148,"For the proof, we reduce 1-in-3-SAT to DCS. 1-in-3-SAT is a variant of the satisfiability problem in
which all clauses have three literals, and exactly one of these literals must be true."
IMPLEMENTATION/METHODS,0.23224043715846995,"The high-level idea is to represent each clause cj with a cycle γj, and each variable xi with two
possible cells χi and χi containing a long path πi and the clauses that contain xi and xi respectively.
Through constructed flows, we ensure that every solution with approximation error below ε has to (i)
add either χi or χi for every xi, and (ii) contain cells that, combined, cover all clauses exactly once."
IMPLEMENTATION/METHODS,0.23497267759562843,"This is possible if and only if there is a valid truth value assignment for the 1-in-3-SAT instance.
Consequently, if an algorithm can decide DCS, it can be used to decide 1-in-3-SAT."
IMPLEMENTATION/METHODS,0.23770491803278687,Theorem 1 follows with the NP-Hardness [47] of 1-in-3-SAT.
IMPLEMENTATION/METHODS,0.24043715846994534,"5.2
Worst-case time complexity of our approach"
IMPLEMENTATION/METHODS,0.24316939890710382,"The time complexity of one maximum spanning tree candidate search is O(m log m); for a detailed
analysis see appendix E."
IMPLEMENTATION/METHODS,0.2459016393442623,"For the similarity spanning trees, having k spanning trees multiplies the time complexity by k.
k-means also adds an additive component that depends on the number of iterations required for
convergence, but is otherwise in O(nk). Furthermore, k-means is efficient in practical applications."
IMPLEMENTATION/METHODS,0.24863387978142076,"To select a cell from given candidates, we construct B2 and project the flows into the harmonic
subspace. This computation can be efficiently performed by LSMR [48] since the matrix is sparse.
However, due to its iterative and numerical nature, a uniform upper bound for its runtime complexity
is difficult to obtain. Instead, we examine the runtime empirically in Section 6.4."
RESULTS/EXPERIMENTS,0.25136612021857924,"6
Numerical Experiments"
RESULTS/EXPERIMENTS,0.2540983606557377,"We evaluated our approach on both synthetic and real-world data sets. To compare our approach to
previous work, we adapt the simplicial-complex-based approach from [14]. For this, we exchanged
our heuristic based on spanning trees with a heuristic that returns the most significant triangles
according to the circular flow around its edges. Wherever used, this approach is labeled trian-
gles. All code for the evaluation and plotting is available at https://github.com/josefhoppe/
edge-flow-cell-complexes."
RESULTS/EXPERIMENTS,0.2568306010928962,"When evaluating the sparsity of an approximation, there are conflicting metrics. Our algorithm
optimizes for the definition used in Section 3, i.e., for a small number of 2-cells, |C2|. However,
cells with more edges have an inherent advantage over cells with fewer edges simply because the
corresponding column in the incidence matrix B2 has more non-zero entries. Therefore, we also
consider ∥B2∥0, the number of non-zero entries in B2, where appropriate."
RESULTS/EXPERIMENTS,0.25956284153005466,Representing Edge Flows on Graphs via Sparse Cell Complexes
RESULTS/EXPERIMENTS,0.26229508196721313,"0.0
0.5
1.0
1.5
2.0
edge noise (
n) 0.0 0.5 1.0"
RESULTS/EXPERIMENTS,0.2650273224043716,correct
RESULTS/EXPERIMENTS,0.2677595628415301,cell_len
RESULTS/EXPERIMENTS,0.27049180327868855,"3
5
10
method"
RESULTS/EXPERIMENTS,0.273224043715847,"max
similarity (a)"
RESULTS/EXPERIMENTS,0.27595628415300544,"0.0
0.5
1.0
1.5
2.0
edge noise (
n) 0.0 0.5 1.0"
RESULTS/EXPERIMENTS,0.2786885245901639,correct
RESULTS/EXPERIMENTS,0.2814207650273224,cell_len
RESULTS/EXPERIMENTS,0.28415300546448086,"3
5
10
method"
RESULTS/EXPERIMENTS,0.28688524590163933,"max
similarity (b)"
RESULTS/EXPERIMENTS,0.2896174863387978,"Figure 2: (a) Fraction of ground-truth cells present in cell candidates (first iteration); |C2| = 5;
average over 20 runs, 20 flows. (b) Inference accuracy of our approach with both heuristics."
RESULTS/EXPERIMENTS,0.2923497267759563,"On synthetic data sets, we also have a ground truth of cells. We use this information to create a third
heuristic (true_cells) that always returns all ground-truth cells as candidates. Since our approach aims
to recover ground-truth cells, we expect true_cells to outperform it. If our approach works the way
we intend, the difference between it and true_cells should be relatively small. For the cell inference
problem, we use the ground-truth cells to measure the accuracy of recovering cells."
RESULTS/EXPERIMENTS,0.29508196721311475,We construct the cell complexes for the synthetic dataset the following way:
RESULTS/EXPERIMENTS,0.2978142076502732,"1. Draw a two-dimensional point cloud uniformly at random
2. Construct the Delauney triangulation to get a graph of triangles
3. Add 2-cells according to parameters by finding cycles of appropriate length
4. Select edges and nodes that do not belong to any 2-cell uniformly at random and delete them"
RESULTS/EXPERIMENTS,0.3005464480874317,"We construct edge flows fi = Xi + B2Yi from cell flows Xi ∈C2 ∼NC2(0, I σc) and edge noise
Yi ∈C1 ∼NC2(0, I σn) sampled i.i.d. from multivariate normal distributions with mean µ = 0,
standard deviation σc = 1, and varying standard deviation σn ∈[0, 2]."
RESULTS/EXPERIMENTS,0.30327868852459017,"6.1
Evaluation of cell inference heuristic"
RESULTS/EXPERIMENTS,0.30601092896174864,"To evaluate the interpretability of results, we compare them to the ground-truth cells we also used to
generate the flows: The cells represent underlying patterns we expect to see in real-world applications."
RESULTS/EXPERIMENTS,0.3087431693989071,"Before looking at the inference performance of the complete algorithm, we will check that our
heuristic works as expected. Figure 2a shows that, unsurprisingly, the heuristics work better for
shorter cells and if more flows are available. However, it is not necessary to detect all cells at once as
adding one cell results in a new projection into the harmonic space, making it easier to detect further
cells."
RESULTS/EXPERIMENTS,0.3114754098360656,"To evaluate the inference accuracy of the complete algorithm, we determined the percentage of cells
detected after 5 iterations (with five ground-truth 2-cells to detect)."
RESULTS/EXPERIMENTS,0.31420765027322406,"Figure 2b confirms that the overall algorithm works significantly better than the heuristic. Even for
noise with σn = 1, the similarity spanning tree heuristic detects the vast majority of ground-truth cells.
Overall, the experiments on synthetic data indicate that our approach detects underlying patterns,
leading to a meaningful and interpretable cell complex."
RESULTS/EXPERIMENTS,0.31693989071038253,"6.2
Evaluation of flow approximation quality"
RESULTS/EXPERIMENTS,0.319672131147541,"As explained before, the triangles heuristic serves as a benchmark representing previous work whereas
true_cells is an idealized version of our approach."
RESULTS/EXPERIMENTS,0.3224043715846995,"Figure 3a shows that our approach with the similarity spanning trees heuristic performs close to
true_cells, slightly outperforming the maximum spanning trees, with both significantly outperforming
triangles. Notably, triangles cannot form a complete cycle basis, so only our approach reaches an
approximation error of 0. However, since we are interested in sparse representations, retrieving a
complete cycle basis is not our goal. Instead, we will focus on the behavior for greater sparsity, where
the qualitative results depend on the parameter selection."
RESULTS/EXPERIMENTS,0.3251366120218579,Representing Edge Flows on Graphs via Sparse Cell Complexes
RESULTS/EXPERIMENTS,0.32786885245901637,"0
100
200
300
400
B2 0 0 20 40"
RESULTS/EXPERIMENTS,0.33060109289617484,"loss( , F)"
RESULTS/EXPERIMENTS,0.3333333333333333,method
RESULTS/EXPERIMENTS,0.3360655737704918,"triangles
max
similarity
true_cells (a)"
RESULTS/EXPERIMENTS,0.33879781420765026,"0.0
0.5
1.0
1.5
2.0
edge noise (
n) 0 20 40"
RESULTS/EXPERIMENTS,0.34153005464480873,"loss( , F)"
RESULTS/EXPERIMENTS,0.3442622950819672,method
RESULTS/EXPERIMENTS,0.3469945355191257,"triangles
max
similarity
true_cells (b)"
RESULTS/EXPERIMENTS,0.34972677595628415,"Figure 3: Comparison of approximation error for our approach, triangles, and ground-truth cells.
(a) depending on sparsity; σn = 0.75. (b) depending on edge noise σn; best approximation with
∥B2∥0 ≤200. Note that true_cells has a disadvantage because ∥Bground truth
2
∥0 = 100."
RESULTS/EXPERIMENTS,0.3524590163934426,"0
250
500
750
B2 0 102 103"
RESULTS/EXPERIMENTS,0.3551912568306011,"loss( , F)"
RESULTS/EXPERIMENTS,0.35792349726775957,method
RESULTS/EXPERIMENTS,0.36065573770491804,"triangles
max
similarity
cell_candidates"
RESULTS/EXPERIMENTS,0.3633879781420765,"1
5
20"
RESULTS/EXPERIMENTS,0.366120218579235,(a) TransportationNetworks [3]: Anaheim.
RESULTS/EXPERIMENTS,0.36885245901639346,"0
100
200
300
B2 0 104"
RESULTS/EXPERIMENTS,0.37158469945355194,"4 × 103
6 × 103"
RESULTS/EXPERIMENTS,0.3743169398907104,"2 × 104
3 × 104"
RESULTS/EXPERIMENTS,0.3770491803278688,"loss( , F)"
RESULTS/EXPERIMENTS,0.3797814207650273,method
RESULTS/EXPERIMENTS,0.3825136612021858,"triangles
max
similarity
cell_candidates"
RESULTS/EXPERIMENTS,0.38524590163934425,"1
5
20"
RESULTS/EXPERIMENTS,0.3879781420765027,"(b) New York City taxi trips [49, 50]."
RESULTS/EXPERIMENTS,0.3907103825136612,Figure 4: Comparison of our approach and triangles. See Figure 14 for more examples.
RESULTS/EXPERIMENTS,0.39344262295081966,"In general, the longer the cells are, the more significant the difference between the three heuristics
becomes. The approach tends to detect cells with fewer edges than the correct ones in this experiment.
However, smaller cells can be combined to explain the data well for the approximation. We argue that
this is the case with the cells that are found by the algorithm when using the max heuristic: Compared
to true_cells and similarity, it requires a larger number of cells, but the resulting incidence matrix B2
has a similar sparsity. However, it still outperforms the triangle heuristic, likely because it may take
many triangles to approximate a 2-cell."
RESULTS/EXPERIMENTS,0.39617486338797814,"The amount of noise fundamentally changes the observed behavior, as shown in Figure 3b, especially
when the incidence matrix B2 is less sparse. To explain this, we need to look at both the sparsity
and dimension of flows. The vector space of the (harmonic) edge noise has the same dimension as
the harmonic space. Since our approach results in cells with longer boundaries, it reaches the same
sparsity with fewer cells than the triangles approach. With its higher-dimensional approximation, the
triangles approach is able to approximate even high-dimensional noise. If we instead consider the
dimension of the approximation |C2|, our approach outperforms triangles in nearly any configuration
with either heuristic (compare Figure 13)."
RESULTS/EXPERIMENTS,0.3989071038251366,"In conclusion, with both sparsity measures, our approach has an advantage for sparse representations.
This observation is consistent with our expectation that the approach can detect the 2-cells of the
original cell complex1. After detecting the ground-truth cells, the error decreases at a significantly
lower rate. We also expected this change in behavior as the approach now starts to approximate the
patterns in the noise, which is bound to be less effective."
RESULTS/EXPERIMENTS,0.4016393442622951,"6.3
Experiments on real-world data"
RESULTS/EXPERIMENTS,0.40437158469945356,"For our evaluation on real-world data, we considered traffic patterns from TransportationNetworks
[3], where we extract a single flow per network by calculating the net flow along a link. For an
experiment with multiple flows, we grouped trips of New York City taxis [49, 50] and counted the
difference in transitions between neighborhoods."
RESULTS/EXPERIMENTS,0.40710382513661203,"We observe a similar, but less pronounced behavior as in synthetic data. On the Anaheim network in
Figure 4a, we see that our approach consistently outperforms the triangle-based simplicial complex"
RESULTS/EXPERIMENTS,0.4098360655737705,1Or at least similar cells if the noise makes those more relevant.
RESULTS/EXPERIMENTS,0.412568306010929,Representing Edge Flows on Graphs via Sparse Cell Complexes
RESULTS/EXPERIMENTS,0.41530054644808745,"inference. For the taxi dataset, Figure 4b shows that, like on synthetic data, the triangle based
inference performs well as the sparsity decreases. Note that the apparent effect that more cell
candidates lead to a worse performance only exists when measuring sparsity by ∥B2∥0 whereas a
comparison based on |C2| shows a significantly smaller error when considering more candidates in
all experiments on real-world data. Similarly, our approach significantly outperforms a triangle based
cell-search heuristic when considering |C2|."
RESULTS/EXPERIMENTS,0.4180327868852459,"In addition to its better performance, we believe that general cell-based representations are easier
to interpret when analyzing patterns. Indeed, the relative success in recovering the correct cells in
synthetic data (for real data we don’t have a ground truth) and the general good approximation of the
flows, may be seen as an indication that cells detected by our approach are more representative of real
underlying patterns. For the taxi example, at 300 entries in B2, our heuristic has added 55 polygonal
2-cells in the best case, whereas a triangles based inference approach adds one-hundred 2-cells.
Similar to what we observed on synthetic data, the triangles heuristic can lead to a higher-dimensional
approximation that is also inherently better at approximating noise. Conversely, our approximation is
lower-dimensional which may also make it more suitable for de-noising data."
RESULTS/EXPERIMENTS,0.4207650273224044,"6.4
Runtime complexity"
RESULTS/EXPERIMENTS,0.42349726775956287,"Finally, we considered the runtime of our algorithm on graphs of different size and gen-
eration methods.
Firstly, we randomly generated cell complexes, with four 2-cells each,
as described before (triangulation).
Secondly, we also generated cell complexes simi-
lar to the Watts-Strogatz small-world network construction [51], but with a fixed probabil-
ity of 1% for any additional edge and without removing edges on the circle (smallworld)."
RESULTS/EXPERIMENTS,0.4262295081967213,"102
103
104
105"
RESULTS/EXPERIMENTS,0.42896174863387976,"size (|
0|) 10
1 100 101 102"
RESULTS/EXPERIMENTS,0.43169398907103823,time [s]
RESULTS/EXPERIMENTS,0.4344262295081967,"model
triangulation
smallworld
method
max
similarity"
RESULTS/EXPERIMENTS,0.4371584699453552,Figure 5: Runtime on graphs of different sizes.
RESULTS/EXPERIMENTS,0.43989071038251365,"For the recovery, we generated five synthetic
flows and let the algorithm run until it had de-
tected four 2-cells, with five candidates consid-
ered in each step. From our theoretical analysis,
we expect the runtime to grow in O(m log m)
for the number of edges m. Figure 5 indicates
a slightly superlinear time complexity. We hy-
pothesize that this stems from the runtime com-
plexity of LSMR, which is hard to assess due to
its iterative nature. In the triangulation graphs,
the number of edges is linear in the number of
vertices. In the small-world graphs, the number
of edges grows quadratically in the number of vertices, corresponding to faster growth in execu-
tion time. Our algorithm took less than 100s for a small-world graph with 10000 vertices and a
triangulation graph with 100000 vertices, respectively."
CONCLUSION/DISCUSSION ,0.4426229508196721,"7
Conclusion"
CONCLUSION/DISCUSSION ,0.4453551912568306,"We formally introduced the flow representation learning problem and showed that the inherent cell
selection problem is NP-hard. Therefore, we proposed a greedy algorithm to efficiently approximate
it. Our evaluation showed that our approaches surpasses current state of the art on both synthetic and
real-world data while being computationally feasible on large graphs."
CONCLUSION/DISCUSSION ,0.44808743169398907,"Apart from further investigation of the inference process and improvements of its accuracy, we see
multiple avenues for future research. A current limitation is that our approach infers cells with a
shorter boundary with reasonable accuracy, while cells with a longer boundary have lower inference
accuracy. We may improve this for example by introducing another spanning-tree-based heuristic
or de-noising the flows before running it a second time. On a higher level, the algorithm could be
adapted to optimize for sparsity of the boundary map ||B2||0 instead of the number of two cells |C2|."
CONCLUSION/DISCUSSION ,0.45081967213114754,"Finally, an analysis of the expressivity of the results on real-world data warrants further investigation.
Given our improvement in approximation over the state of the art, we also expect a better expressivity.
However, since such an analysis does not currently exist, the acutal applicability is hard to assess. The
downstream tasks and improvements to related methods discussed in the introduction could serve as
a proxy for this, showing the usefulness of the inferred cells beyond the filtered flow representation."
CONCLUSION/DISCUSSION ,0.453551912568306,Representing Edge Flows on Graphs via Sparse Cell Complexes
CONCLUSION/DISCUSSION ,0.4562841530054645,Acknowledgements
CONCLUSION/DISCUSSION ,0.45901639344262296,"Funded by the European Union (ERC, HIGH-HOPeS, 101039827). Views and opinions expressed
are however those of the author(s) only and do not necessarily reflect those of the European Union
or the European Research Council Executive Agency. Neither the European Union nor the granting
authority can be held responsible for them."
CONCLUSION/DISCUSSION ,0.46174863387978143,Code Availability Statement
CONCLUSION/DISCUSSION ,0.4644808743169399,"The code produced to evaluate this work is divided into two components: The PyPI package cell-
flower (https://github.com/josefhoppe/cell-flower) and the evaluation code (https://
github.com/josefhoppe/edge-flow-cell-complexes). Both are open source under the MIT
license."
REFERENCES,0.4672131147540984,References
REFERENCES,0.46994535519125685,"[1] Daan Mulder and Ginestra Bianconi. Network geometry and complexity. Journal of Statistical
Physics, 173:783–805, 2018. 1"
REFERENCES,0.4726775956284153,"[2] Mariana Altoé Mendes, Marcia Helena Moreira Paiva, and Oureste Elias Batista. Signal
processing on graphs for estimating load current variability in feeders with high integration of
distributed generation. Sustainable Energy, Grids and Networks, 34:101032, 2023. 1"
REFERENCES,0.47540983606557374,[3] Transportation Networks for Research Core Team. Transportation networks for research. URL
REFERENCES,0.4781420765027322,"https://github.com/bstabler/TransportationNetworks. Accessed: 2023-08-18. 1,
8, 22"
REFERENCES,0.4808743169398907,"[4] Giulia Iori, Giulia De Masi, Ovidiu Vasile Precup, Giampaolo Gabbi, and Guido Caldarelli. A
network analysis of the italian overnight money market. Journal of Economic Dynamics and
Control, 32(1):259–278, 2008. 1"
REFERENCES,0.48360655737704916,"[5] Stephen P Borgatti and Xun Li. On social network analysis in a supply chain context. Journal
of supply chain management, 45(2):5–22, 2009. 1"
REFERENCES,0.48633879781420764,"[6] Sang-Woo Lee, Jun-Sang Park, Hyun-Shin Lee, and Myung-Sup Kim. A study on smart-phone
traffic analysis. In 2011 13th Asia-Pacific Network Operations and Management Symposium,
pages 1–7. IEEE, 2011. 1"
REFERENCES,0.4890710382513661,"[7] Jacob Billings, Manish Saggar, Jaroslav Hlinka, Shella Keilholz, and Giovanni Petri. Simplicial
and topological descriptions of human brain dynamics. Network Neuroscience, 5(2):549–568,
2021. 1"
REFERENCES,0.4918032786885246,"[8] Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and
new perspectives. IEEE transactions on pattern analysis and machine intelligence, 35(8):
1798–1828, 2013. 1"
REFERENCES,0.49453551912568305,"[9] William L Hamilton, Rex Ying, and Jure Leskovec. Representation learning on graphs: Methods
and applications. arXiv preprint arXiv:1709.05584, 2017."
REFERENCES,0.4972677595628415,"[10] Ivana Toši´c and Pascal Frossard. Dictionary learning. IEEE Signal Processing Magazine, 28(2):
27–38, 2011. 1, 2"
REFERENCES,0.5,"[11] Danijela Horak and Jürgen Jost. Spectra of combinatorial laplace operators on simplicial
complexes. Advances in Mathematics, 244:303–336, 2013. 1"
REFERENCES,0.5027322404371585,"[12] Lek-Heng Lim. Hodge laplacians on graphs. Siam Review, 62(3):685–715, 2020. 3, 4"
REFERENCES,0.505464480874317,"[13] Michael T Schaub, Austin R Benson, Paul Horn, Gabor Lippner, and Ali Jadbabaie. Random
walks on simplicial complexes and the normalized hodge 1-laplacian. SIAM Review, 62(2):
353–391, 2020. 3, 4"
REFERENCES,0.5081967213114754,"[14] Sergio Barbarossa and Stefania Sardellitti. Topological signal processing: Making sense of data
building on multiway relations. IEEE Signal Processing Magazine, 37(6):174–183, 2020. 1, 2,
6"
REFERENCES,0.5109289617486339,"[15] Leo J Grady and Jonathan R Polimeni. Discrete calculus: Applied analysis on graphs for
computational science, volume 3. Springer, 2010. 2, 3, 4"
REFERENCES,0.5136612021857924,Representing Edge Flows on Graphs via Sparse Cell Complexes
REFERENCES,0.5163934426229508,"[16] Takaaki Aoki, Shota Fujishima, and Naoya Fujiwara. Urban spatial structures from human flow
by hodge–kodaira decomposition. Scientific reports, 12(1):11258, 2022. 1
[17] Michael T Schaub, Yu Zhu, Jean-Baptiste Seby, T Mitchell Roddenberry, and Santiago Segarra.
Signal processing on higher-order networks: Livin’on the edge... and beyond. Signal Processing,
187:108149, 2021. 1, 2
[18] T Mitchell Roddenberry and Santiago Segarra. Hodgenet: Graph neural networks for edge data.
In 2019 53rd Asilomar Conference on Signals, Systems, and Computers, pages 220–224. IEEE,
2019. 1
[19] T Mitchell Roddenberry, Nicholas Glaze, and Santiago Segarra. Principled simplicial neural
networks for trajectory prediction. In International Conference on Machine Learning, pages
9020–9029. PMLR, 2021.
[20] Kevin D Smith, Francesco Seccamonte, Ananthram Swami, and Francesco Bullo. Physics-
informed implicit representations of equilibrium network flows. Advances in Neural Information
Processing Systems, 35:7211–7221, 2022. 1
[21] Abhirup Ghosh, Benedek Rozemberczki, Subramanian Ramamoorthy, and Rik Sarkar. Topo-
logical signatures for fast mobility analysis. In Proceedings of the 26th ACM SIGSPATIAL
International Conference on Advances in Geographic Information Systems, pages 159–168,
2018. 1
[22] Florian Frantzen, Jean-Baptiste Seby, and Michael T Schaub. Outlier detection for trajectories
via flow-embeddings. In 2021 55th Asilomar Conference on Signals, Systems, and Computers,
pages 1568–1572. IEEE, 2021.
[23] Florian T Pokorny, Majd Hawasly, and Subramanian Ramamoorthy. Topological trajectory
classification with filtrations of simplicial complexes and persistent homology. The International
Journal of Robotics Research, 35(1-3):204–223, 2016. 1
[24] Junteng Jia, Michael T Schaub, Santiago Segarra, and Austin R Benson. Graph-based semi-
supervised & active learning for edge flows.
In Proceedings of the 25th ACM SIGKDD
international conference on knowledge discovery & data mining, pages 761–771, 2019. 1
[25] Michael T Schaub and Santiago Segarra. Flow smoothing and denoising: Graph signal process-
ing in the edge-space. In 2018 IEEE Global Conference on Signal and Information Processing
(GlobalSIP), pages 735–739. IEEE, 2018. 1, 2
[26] Cristian Bodnar, Fabrizio Frasca, Nina Otter, Yuguang Wang, Pietro Lio, Guido F Montufar,
and Michael Bronstein. Weisfeiler and lehman go cellular: Cw networks. Advances in Neural
Information Processing Systems, 34:2625–2640, 2021. 1, 2
[27] Lorenzo Giusti, Claudio Battiloro, Lucia Testa, Paolo Di Lorenzo, Stefania Sardellitti, and
Sergio Barbarossa. Cell attention networks. In 2023 International Joint Conference on Neural
Networks (IJCNN), pages 1–8. IEEE, 2023. 2
[28] Claudio Battiloro, Indro Spinelli, Lev Telyatnikov, Michael Bronstein, Simone Scardapane, and
Paolo Di Lorenzo. From latent graph to latent topology inference: Differentiable cell complex
module. arXiv preprint arXiv:2305.16174, 2023. 2
[29] Mustafa Hajij, Kyle Istvan, and Ghada Zamzmi. Cell complex neural networks. In TDA &
Beyond, 2020. URL https://openreview.net/forum?id=6Tq18ySFpGU. 1
[30] Sergio Barbarossa and Stefania Sardellitti. Topological signal processing over simplicial
complexes. IEEE Transactions on Signal Processing, 68:2992–3007, 2020. 1, 2
[31] Stefania Sardellitti and Sergio Barbarossa. Topological signal representation and processing
over cell complexes. arXiv preprint arXiv:2201.08993, 2022. 2
[32] Stefania Sardellitti, Sergio Barbarossa, and Lucia Testa. Topological signal processing over
cell complexes. In 2021 55th Asilomar Conference on Signals, Systems, and Computers, pages
1558–1562. IEEE, 2021. 2
[33] T Mitchell Roddenberry, Michael T Schaub, and Mustafa Hajij. Signal processing on cell
complexes. In ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP), pages 8852–8856. IEEE, 2022. 1, 2, 3
[34] Thomas F Burns and Tomoki Fukai. Simplicial hopfield networks. In International Con-
ference on Learning Representations, 2023. URL https://openreview.net/forum?id=
_QLsH8gatwx. 2"
REFERENCES,0.5191256830601093,Representing Edge Flows on Graphs via Sparse Cell Complexes
REFERENCES,0.5218579234972678,"[35] Chad Giusti, Robert Ghrist, and Danielle S Bassett. Two’s company, three (or more) is a simplex:
Algebraic-topological tools for understanding higher-order structure in neural data. Journal of
computational neuroscience, 41:1–14, 2016. 2
[36] Maciej Marek Sysło. On cycle bases of a graph. Networks, 9(2):123–132, 1979. 2
[37] Joseph Douglas Horton. A polynomial-time algorithm to find the shortest cycle basis of a graph.
SIAM Journal on Computing, 16(2):358–366, 1987.
[38] Telikepalli Kavitha, Christian Liebchen, Kurt Mehlhorn, Dimitrios Michail, Romeo Rizzi,
Torsten Ueckerdt, and Katharina A Zweig. Cycle bases in graphs characterization, algorithms,
complexity, and applications. Computer Science Review, 3(4):199–243, 2009. 2
[39] David I Shuman, Sunil K Narang, Pascal Frossard, Antonio Ortega, and Pierre Vandergheynst.
The emerging field of signal processing on graphs: Extending high-dimensional data analysis to
networks and other irregular domains. IEEE signal processing magazine, 30(3):83–98, 2013. 2
[40] Antonio Ortega, Pascal Frossard, Jelena Kovaˇcevi´c, José MF Moura, and Pierre Vandergheynst.
Graph signal processing: Overview, challenges, and applications. Proceedings of the IEEE, 106
(5):808–828, 2018. 4
[41] Xiaowen Dong, Dorina Thanou, Laura Toni, Michael Bronstein, and Pascal Frossard. Graph
signal processing for machine learning: A review and new perspectives. IEEE Signal processing
magazine, 37(6):117–127, 2020. 2
[42] Emmanuel J Candès et al. Compressive sampling. In Proceedings of the international congress
of mathematicians, volume 3, pages 1433–1452. Madrid, Spain, 2006. 2
[43] Emmanuel J Candes, Justin K Romberg, and Terence Tao. Stable signal recovery from incom-
plete and inaccurate measurements. Communications on Pure and Applied Mathematics: A
Journal Issued by the Courant Institute of Mathematical Sciences, 59(8):1207–1223, 2006. 2
[44] Weiyu Xu, Enrique Mallada, and Ao Tang.
Compressive sensing over graphs.
In 2011
Proceedings IEEE INFOCOM, pages 2087–2095. IEEE, 2011. 2
[45] Xiaofan Zhu and Michael Rabbat. Graph spectral compressed sensing for sensor networks. In
2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),
pages 2865–2868. IEEE, 2012. 2
[46] Allen Hatcher. Algebraic Topology. Cambridge University Press, 2002. 3
[47] Thomas J Schaefer. The complexity of satisfiability problems. In Proceedings of the tenth
annual ACM symposium on Theory of computing, pages 216–226, 1978. 6, 19
[48] David Chin-Lung Fong and Michael Saunders. Lsmr: An iterative algorithm for sparse least-
squares problems. SIAM Journal on Scientific Computing, 33(5):2950–2971, 2011. 6
[49] Austin R. Benson, David F. Gleich, and Lek-Heng Lim. The spacey random walk: A stochastic
process for higher-order data. SIAM Review, 59(2):321–345, 2017. doi: 10.1137/16m1074023.
URL https://doi.org/10.1137/16m1074023. 8
[50] Chris Whong.
Foiling nyc’s taxi trip data, 2014.
URL https://chriswhong.com/
open-data/foil_nyc_taxi/. 8
[51] Duncan J Watts and Steven H Strogatz. Collective dynamics of ‘small-world’networks. nature,
393(6684):440–442, 1998. 9
[52] Robert Endre Tarjan. Applications of path compression on balanced trees. Journal of the ACM
(JACM), 26(4):690–715, 1979. 18, 22"
REFERENCES,0.5245901639344263,Representing Edge Flows on Graphs via Sparse Cell Complexes
OTHER,0.5273224043715847,"A
Cell Complex Illustrations B1 = "
OTHER,0.5300546448087432,"


"
OTHER,0.5327868852459017,"1 →2
1 →4
1 →5
2 →3
3 →4
4 →5
1
−1
−1
−1
0
0
0
2
1
0
0
−1
0
0
3
0
0
0
1
−1
0
4
0
1
0
0
1
−1
5
0
0
1
0
0
1 "
OTHER,0.5355191256830601,"



B2 = "
OTHER,0.5382513661202186,"





"
OTHER,0.5409836065573771,"1 →2
0
1
1 →4
1
−1
1 →5
−1
0
2 →3
0
1
3 →4
0
1
4 →5
1
0 "
OTHER,0.5437158469945356,"





"
OTHER,0.546448087431694,"Figure 6: A small cell complex and its boundary maps B1 and B2; columns and rows are annotated
with corresponding cells. Flipping the arbitrary orientations of edges and polygons corresponds to
multiplying the corresponding rows and columns with −1."
OTHER,0.5491803278688525,"B
Heuristics"
OTHER,0.5519125683060109,"In this section, we will discuss heuristics in more detail. We start with theoretical considerations
why heuristics are necessary and what high-level properties they should have. Then, we provide an
example iteration for each heuristic to showcase the most important concepts of each and differences
between the heuristics. Finally, we will discuss advantages and potential pitfalls for each of the
heuristics."
OTHER,0.5546448087431693,"B.1
Theoretical Considerations"
OTHER,0.5573770491803278,"This section discusses the necessity of heuristics and gives some intuition of properties a heuristic
should have. It is supplementary to section 4.1; for more information on the two heuristics introduced
by us, please refer to appendix B.2."
OTHER,0.5601092896174863,"2-cells are essentially simple cycles, i.e., cycles without repeating nodes. Any tuple of nodes that is
at least three nodes long can be converted to a cycle. Since cycles are invariant under shifting and
reversing the order of nodes, a cycle of length l can be represented by exactly 2l different tuples:
There are l nodes that can be the first node in the tuple. For each of these, there are two possible
orders of the other nodes."
OTHER,0.5628415300546448,"Therefore, on a complete graph, the number of possible two-cells C ′
2 is:"
OTHER,0.5655737704918032,"|C ′
2| ="
OTHER,0.5683060109289617,"|C0|
X l=3 1
2l"
OTHER,0.5710382513661202,"|C0|
l"
OTHER,0.5737704918032787,"
= Ω

e|C0|
(5)"
OTHER,0.5765027322404371,"Please note that while this is the worst case, the number of possible 2-cells is still very large on both
randomly generated and real-world graphs with sufficiently many edges; however, this is not trivial to
show as the exact number depends heavily on the structure of the given graph."
OTHER,0.5792349726775956,"In general, considering all cells would result in an exponential runtime of our algorithm. Instead,
we introduce heuristics that look at a (relatively speaking) small number of cells. Accordingly, the
heuristic should also not consider all possible cells. The cells it does consider, however, should
include all relevant flows in some meaningful way."
OTHER,0.5819672131147541,"This property is fulfilled by a cycle basis. A cycle basis spans the subspace of all eulerian subgraphs
and is able to model any flow. While we do not aim to add the complete cycle basis, it can generate a"
OTHER,0.5846994535519126,Representing Edge Flows on Graphs via Sparse Cell Complexes
OTHER,0.587431693989071,"minimal input that considers all flows. Even though this can theoretically model any harmonic flow,
there are cycle bases that are better suited to this task than others. Since every spanning tree induces
a cycle basis, instead of trying to find a suitable cycle basis, we can think of it as finding a good
spanning tree."
OTHER,0.5901639344262295,"Furthermore, if the heuristic fully constructs the cycle basis, i.e., enumerates all edges for all elements
of the cycle basis, this will result in a realtively high polynomial runtime. Given that the number
of edges may already be quadratic in the number of nodes, this could severely limit the scalability
of the approach. As we show in appendix E, we can execute one iteration of the whole heuristic in
O(m log m) if we utilize the structure of the spanning tree."
OTHER,0.592896174863388,"Accordingly, the main difference between the two heuristics we introduce lies in the construction of
one or multiple spanning trees."
OTHER,0.5956284153005464,"B.2
Comparison of the two heuristics in an example run"
OTHER,0.5983606557377049,"Figure 7: The heuristic examples will use a five by three grid graph with three cells. This figure
illustrates each cell separately. The cells will be referred to as red, green, and blue; and will be
colored accordingly."
OTHER,0.6010928961748634,"This section contains a simple example for one iteration of both heuristics presented in this paper.
Appendix B.3 discusses the importance, advantages, and disadvantages of the heuristics."
OTHER,0.6038251366120219,"Figure 7 shows the cell complex we will use for the example; it contains fifteen nodes and three
2-cells. Firstly, we generate two flows by assigning a flow to each of the cells and adding noise
according to a normal distribution. Note that the flows in this section are purely for illustrative
purposes and do not necessarily reflect the performance on randomly generated synthetic data or
real-world data. The graph structure, 2-cells, and the flows were deliberatly designed to show a case
where the maximum spanning tree heuristic does not result in any ground-truth cell as a candidate
while the similarity spanning tree does. The example flows we use throughout this section are shown
in fig. 8."
OTHER,0.6065573770491803,"Figure 8: The generated flows projected into the harmonic sub-
space, called flow 1 (left) and flow 2 (right). Note that the blue
cell is not visible in either of the flows, making it harder to detect."
OTHER,0.6092896174863388,"Figure 9: The maximum span-
ning tree as used by the corre-
sponding heuristic."
OTHER,0.6120218579234973,"B.2.1
Maximum Spanning Tree"
OTHER,0.6147540983606558,"The maximum spanning tree heuristic calculates the total flow value for each edge and constructs a
maximum spanning tree, shown in fig. 9. In this particular example, the maximum spanning tree does
not induce any of the three ground-truth cells. However, it still induces reasonable approximations
for both the blue and green cell that each only miss three out of the eight edges."
OTHER,0.6174863387978142,"B.2.2
Similarity Spanning Tree"
OTHER,0.6202185792349727,"The similarity spanning tree heuristic is more complicated. Firstly, it clusters the edges by their flows.
An optimal clustering can be seen in fig. 10. Each of the clusters then induces a similarity spanning
tree by adding the edges with the smallest euclidean distance to the cluster center."
OTHER,0.6229508196721312,Representing Edge Flows on Graphs via Sparse Cell Complexes
OTHER,0.6256830601092896,"1.5
1.0
0.5
0.0
0.5
1.0
1.5
Flow 1 1.0 0.5 0.0 0.5 1.0"
OTHER,0.6284153005464481,Flow 2
OTHER,0.6311475409836066,"Figure 10: The edges, represented by their flow values. Because the orientation is arbitrary, each
edge appears twice: Once with the original flow values and once with all flow values multiplied by
−1, representing the possibility of the edge being traversed in the opposite direction. The dots in the
scatterplot are colored by combining the colors of all cells they belong to. This coloring is illustrated
on the right, where it is applied to the edges in the graph."
OTHER,0.6338797814207651,"Figure 11: Similarity spanning trees obtained from the cyan (blue + green), green, and red cluster
respectively (left to right, colored accordingly)."
OTHER,0.6366120218579235,"Three examples of this are shown in fig. 11. While not every spanning tree induces a ground-truth cell,
both the red cell and the green cell are induced by one of these example trees each. In accordance with
a visual examinations of the flows (fig. 8), the blue cell is again the hardest to detect. Since it is also
the least significant cell in terms of assigned flow, it is not necessary to detect it as a candidate in the
first iterations. After the first iteration, the most significant cell is added and the flow is re-projected
into the harmonic space. Since this removes interference effects, a future iteration is likely to detect
the blue cell."
OTHER,0.639344262295082,"B.3
Discussion of heuristics"
OTHER,0.6420765027322405,"As the example shows, the selection of appropriate spanning trees is crucial to detecting true cells.
If this does not succeed, the resulting cell complex could still result in a good approximation of the
flows. In the example above, many induced cycles consisted of edges that are part of the same cell.
While this would also like be the case for a random spanning tree on the example graph, an increasing
number of edges would make it more crucial to select good edges for a spanning tree. Should both
heuristics fail for a particular application or scale, one could develop an alternative heuristic and
easily integrate it to adapt our approach. With that in mind, we will now discuss potential advantages
and pitfalls of the two heuristics we introduced."
OTHER,0.644808743169399,"B.3.1
Maximum spanning tree"
OTHER,0.6475409836065574,"As we can see above, the maximum spanning tree heuristic is susceptible to interference effects from
adjacent cells. On the other hand, the heuristic is very fast since it only constructs a single spanning
tree (compare fig. 5) and requires minimal processing of the data. Furthermore, our experiments in
section 6 show that it provides both good approximations and detects correct cells in many cases
(depending on the noise)."
OTHER,0.6502732240437158,Representing Edge Flows on Graphs via Sparse Cell Complexes
OTHER,0.6530054644808743,"B.3.2
Similarity spanning tree"
OTHER,0.6557377049180327,"The central idea behind the similarity spanning tree heuristic is that edges that are part of the same
cell will have similar flow values in all flows. Since edges can belong to multiple cells, a cell does
not correspond to a cluster of edges in general, but will, on average, have a smaller distance to the
main cluster than others that do not belong to the cell. The outperformance of the maximum spanning
tree heuristic in section 6.1 supports this assumption, although it does not always hold. In fig. 10, the
green cluster is much closer to the blue cluster than any other cluster, and it is even closer to the red
cluster than to all points of the cyan cluster. This results in a spanning tree that does not prefer all
edges of the green cell over other edges, as can be seen in fig. 11. However, the cyan cluster results in
a spanning tree that induces the green cell, albeit not the blue cell."
OTHER,0.6584699453551912,"In our example, this is the result of very similar flows on the green and blue cells. Translated to a
real-world context, this correlation could indicate a real pattern that may merit further investigation.
In either case, the similarity spanning tree heuristic is able to mitigate this issue by constructing
spanning trees from a larger selection of clusters."
OTHER,0.6612021857923497,"Another issue that may arise is the curse of dimensionality if we consider a very large number of
flows, rendering the euclidean distance metric less useful. This is, however, not an inherent property
of the heuristic, but more a specific issue exhibited by k-means. Consequently, common mitigation
strategies, such as dimensionality reduction using PCR or SVD, may be employed if this becomes an
issue for the application of our approach to real-world data."
OTHER,0.6639344262295082,"Other known issues of k-means, such as a bad initialization leading to an inaccurate clustering or the
difficulty of choosing k, are less of a concern: We are more interested in general trends and even a
perfect clustering does not necessarily lead to a perfect result as shown in figs. 10 and 11."
OTHER,0.6666666666666666,"Similarly, the choice of k-means is not fixed. Given its good results and computational performance
in a wide variety of fields, we decided to use k-means for our implementation. For the distance metric,
we decided to use the euclidean distance because k-means also optimizes for it. Intuitively, many
metrics seem appropriate. However, we specifically decided against angle-based similarity measures
as they would give a high similarity to edges that belong to no cluster, but have a similar angle due
to noise. Given the more theoretical and high-level focus of this paper, a thorough comparison of
methods for these details would have been out of scope."
OTHER,0.6693989071038251,"C
Algorithms"
OTHER,0.6721311475409836,"This section provides pseudocode for some of the algorithms mentioned in the main text. The
implementation is available at https://github.com/josefhoppe/cell-flower."
OTHER,0.674863387978142,"Data: G = (V, E), F, m
edges ←[(||F_,e||1, e) : e ∈E];
sort(edges);
tree_edges, cycle_edges ←find_spanning_tree(edges);
p, d, P = spanning_tree(V, tree_edges, F);
h ←Heap();
evaluate_tree(h, p, d, P, F, cycle_edges);
C ←∅;
repeat"
OTHER,0.6775956284153005,"f, p, u, v ←pop(h);
c ←cycle(p, u, v);
C ←C ∪{c};
until |C| = m;
return C
Algorithm 1: Maximum spanning tree heuristic. The input consists of the graph G, also repre-
sented as its set of nodes V and edges E; the harmonic flows F; and the number of candidates
to provide m. After calculating the maximum spanning tree, it evaluates the induced cycles and
returns the best m cycles as cell candidates. See also algorithms 3 to 5."
OTHER,0.680327868852459,Representing Edge Flows on Graphs via Sparse Cell Complexes
OTHER,0.6830601092896175,"Data: G = (V, E), F, k, m
h ←Heap();
centers ←k-means(k, {{F_,e : e ∈E}});
for c ∈centers do"
OTHER,0.6857923497267759,"edges ←[(||F_,e −c||2, e) : e ∈E];
sort_ascending(edges);
tree_edges, cycle_edges ←find_spanning_tree(edges);
p, d, P ←spanning_tree(V, tree_edges, F);
evaluate_tree(h, p, d, P, F, cycle_edges);
end
C ←∅;
repeat"
OTHER,0.6885245901639344,"f, p, u, v ←pop(h);
c ←cycle(p, u, v);
C ←C ∪{c};
until |C| = m;
return C
Algorithm 2: Similarity spanning tree heuristic. The input consists of the graph G, also repre-
sented as its set of nodes V and edges E; the harmonic flows F; and the number of candidates
to provide m. After calculating the maximum spanning tree, it evaluates the induced cycles and
returns the best m cycles as cell candidates. See also algorithms 3 to 5."
OTHER,0.6912568306010929,"Data: edges
tree_edges ←∅;
cycle_edges ←∅;
uf ←UnionFind(|V |);
for (_, (u, v)) ∈edges do"
OTHER,0.6939890710382514,if uf(u) ̸= uf(v) then
OTHER,0.6967213114754098,"uf.join(u, v);
tree_edges ←tree_edges ∪{(u, v)};
else"
OTHER,0.6994535519125683,"cycle_edges ←cycle_edges ∪{(u, v)}
end
end
return tree_edges, cycle_edges
Algorithm 3: find_spanning_tree. Given a sorted list edges, find_spanning_tree finds a set of
edges that form a spanning tree, preferring edges that appear earlier in the list. For example, if the
list is sorted descendingly by some edge weight, it returns the edges for the maximum spanning
tree."
OTHER,0.7021857923497268,Representing Edge Flows on Graphs via Sparse Cell Complexes
OTHER,0.7049180327868853,"Data: V, E, F
p ←(−1)v∈V ;
p[0] ←0;
d ←(0)v∈V ;
P ←0 ∈Rs×|V |;
q ←Queue({0});
while |q| > 0 do"
OTHER,0.7076502732240437,"v ←pop(q);
N ←neighbors(V, E, v) \ {p[v]};
for u ∈N do"
OTHER,0.7103825136612022,"p[u] ←v;
d[u] ←d[v] + 1;
P_,u ←P_,v + F_,(u,v);
push(q, u);
end
end
return p, d, P
Algorithm 4: spanning_tree constructs a spanning tree from E, using the node labeled 0 as a
root. The return values are the parents p, the depth in the tree d, and the potentials P for all nodes.
The potential for a node n is defined as the sum of all flows on the path from the root to n."
OTHER,0.7131147540983607,"Data: h, p, d, P, F, other_edges
for (u, v) ∈other_edges do"
OTHER,0.7158469945355191,"f ←P_,u −P_,v + F_,(u,v);
l ←d[u] + d[v] −2d[lca(p, u, v)];
push(h, (f/l, p, u, v))
end
Algorithm 5: evaluate_tree evaluates all simple cycles induced by a given spanning tree given by
the parent list p, node depth d, and node potentials P. The potential for a node n is defined as the
sum of all flows on the path from the root to n. It calculates the flow of the cycle induced by an
edge (u, v) from its flow and the node potentials of u and v. The cycle length can be efficiently
calculated via the lowest common ancestor [52]. evaluate_tree pushes each edge onto the given
heap h, weighted by its normalized flow."
OTHER,0.7185792349726776,Representing Edge Flows on Graphs via Sparse Cell Complexes
OTHER,0.7213114754098361,"D
NP-Hardness Proof"
OTHER,0.7240437158469946,"Proof of Theorem 1. To show that the cell selection problem is NP-hard, we reduce 1-in-3-SAT to
cell selection. 1-in-3-SAT is a variant of the satisfiability problem in which all clauses have three
literals, and exactly one of these literals must be true. 1-in-3-SAT is NP-complete [47]."
OTHER,0.726775956284153,"Given an instance S = (V, C) of 1-in-3-SAT consisting of variables V = {x1, ..., xl} and clauses
C = {c1, ..., ck}, we now construct an instance of cell selection DCS(G, F, n, ε)."
OTHER,0.7295081967213115,"In this proof, we use the squared error instead of the 2-norm because the fact that it is additive
simplifies the notation. It is possible to apply the square root to ε and all lower and upper bounds for
it with the same qualitative results to show that it also holds for the original definition."
OTHER,0.73224043715847,"Without limiting generality, we can assume that no clause contains a variable xi twice, either in
positiv or negative form. Such a clause xi ∨xi ∨xj evaluates to true if and only if xj is false.
Therefore, we can remove the clause and the possibility for xj to be true and continue."
OTHER,0.7349726775956285,"We set n := |V |, i.e., for each variable in S, a cell has to be selected. As an intuition, each added cell
represents the decision for the value of one xi. The literal cell representing xi (xi) is called χi (χi).
A clause cj ∈C is represented by a cycle γj in G. Analogous to 1-in-3-SAT, the literal cells cover
the clause cycles; each γj has to be covered exactly once in a valid solution. We first construct an
appropriate base graph G. Then, we design 2l + 1 flows F on this base graph and select a threshold ε
for the decision problem to ensure that:"
OTHER,0.7377049180327869,"1. To result in an approximation error below ε, for each xi ∈V either χi or χi must be added, and"
OTHER,0.7404371584699454,2. a solution with approximation error below ε exists ⇔S is satisfiable.
OTHER,0.7431693989071039,"We set p := 2l + 2k + 3. For each variable xi, we create a unique path πi of length p7, including
its nodes. The first and last nodes on πi are ui,in and ui,out respectively. We also add a loop edge
(ui,in, ui,out) to construct flows later. For each clause cj = (α ∨β ∨γ) and literal a ∈{α, β, γ},
we create vertices vj,a,in, vj,a,out, edges (vj,a,in, vj,a,out), and paths of length p (inserting new nodes)
from vj,α,out to vj,β,in etc., thus forming a cycle γj of length 3p + 3."
OTHER,0.7459016393442623,"Next, we connect variables to clauses. For each xi and a ∈{xi, xi}, let j1 < j2 < ... < jl be
the indices of clauses where a occurs. We add edges (ui,out, vj1,a,in), (vjk,a,out, vkk+1,a,in) for all
0 < k < l, and (vil,a,out, ii,in)."
OTHER,0.7486338797814208,"With paths πi, clause cycles γj, and connecting edges, G is complete. A literal a = xi (xi) is
represented by a possible cell χi (χi) with boundary ui,out →vi1,a,in ⇝vi1,β,out →vi1,β,in ⇝
vi1,γ,out →vi1,γ,in ⇝vi1,a,out →vi2,a,in ⇝... ⇝vip,a,out →vxi,in ⇝vxi,out. See also fig. 12 for a
visual illustration of a cell representing xi in blue. γ0 γ1 χi χi"
OTHER,0.7513661202185792,Clause cycle γj (left)
OTHER,0.7540983606557377,Cell χi (right)
OTHER,0.7568306010928961,"egress node vj,a,out"
OTHER,0.7595628415300546,"ingress node vj,a,in"
OTHER,0.7622950819672131,path of length p
OTHER,0.7650273224043715,path πi of length p7
OTHER,0.76775956284153,"ui,in
ui,out"
OTHER,0.7704918032786885,"(ui,in, ui,out)"
OTHER,0.773224043715847,Boundary of χi
OTHER,0.7759562841530054,"Figure 12: Schematic of the Graph for the NP-hardness proof. Arrows indicate the direction of all
non-zero flows."
OTHER,0.7786885245901639,Representing Edge Flows on Graphs via Sparse Cell Complexes
OTHER,0.7814207650273224,"In order to analyze the flows, we need to determine an upper bound for the effect the projections into
B2 have on the error. More specifically: How much can cells that include a πi with flow 0 affect the
overall error, assuming the edges that do not belong to πi have a flow value of at most √p. There are
2l + 6k + 3kp < p2 other edges. Therefore, the effect of one cell on one flow is bounded from above
by a hypothetical projection with one cell where p2 edges have flow √p and p7 edges have flow 0. In
this case, the least squares projection results in a flow of"
OTHER,0.7841530054644809,"g′ =
√p ∗p2 + 0 ∗p7"
OTHER,0.7868852459016393,"p2 + p7
=
√p
p5 + 1
(6)"
OTHER,0.7896174863387978,"If we were to ignore the cell completely, the approximation error is √p2 · p2 + 02 · p6 = p3. With the
cell, the approximation error is"
OTHER,0.7923497267759563,"e =
√p

1 −
1
(p5 + 1)2"
OTHER,0.7950819672131147,"2
p2 +
√p2"
OTHER,0.7978142076502732,(p5 + 1)2 p7 = p13 + p8
OTHER,0.8005464480874317,"(p5 + 1)2 =
p8"
OTHER,0.8032786885245902,"p5 + 1
(7)"
OTHER,0.8060109289617486,"As a result, the reduction in error is"
OTHER,0.8087431693989071,"e′ = p3 −
p8"
OTHER,0.8114754098360656,p5 + 1 = p8 + p3 −p8
OTHER,0.8142076502732241,"p5 + 1
=
p3"
OTHER,0.8169398907103825,p5 + 1 < 1
OTHER,0.819672131147541,"p2
(8)"
OTHER,0.8224043715846995,"This upper bound for the reduction in error can be summed up over all n = l < p cells and all
2l + 1 < p flows for a total of n·(2l+1)"
OTHER,0.825136612021858,"p2
< 1. In other words, if z′ is the error assuming all cells are
assigned the flow of their πi, the correct projection error z can be bounded by z′ −1 < z ≤z′."
OTHER,0.8278688524590164,"We will now construct the aforementioned 2|V | + 1 flows. The first 2|V | flows ensure that if a
solution to DSC exists, its cells are either χi or χi for each xi ∈V , representing a valid assignment
of truth values to variables in S. The last flow emulates the evaluation of S for the given truth value
assignment, i.e., the approximation error for this flow is below a certain threshold if and only if the
selected cells correspond to a truth value assignment s.t. S evaluates to true."
OTHER,0.8306010928961749,"To ensure only cells representing literals can be selected with an error smaller than ε, we construct
flows fi,1, fi,0 ∈C1 for each cell χi and χi. It has a positive flow value √p) on the boundary of χi
(χi) and a flow of 0 on all other edges."
OTHER,0.8333333333333334,"Since cell boundaries are cycles, a boundary can either contain all or no edges belonging to each πi.
We observe that for each πi, a linear combination of cells that includes πi but not πj, j ̸= i has to
exist: If no such linear combination exists, there has to be at least one i where the best approximation
of fi,0 includes at most n −1 < p other πj, j ̸= i. On at least one πj, the flow value has to deviate"
OTHER,0.8360655737704918,"by at least
√p"
OTHER,0.8387978142076503,"p , resulting in an error of at least
 √p"
OTHER,0.8415300546448088,"p
2
p7 = p6 > ε. If necessary, we can change the
basis for the vector space to the linear combinations resulting in each πi belonging to a different cell;
therefore, we will assume this from now on."
OTHER,0.8442622950819673,"We can now analyze the cell that includes πi regarding its approximation error on fi,0, fi,1. If the cell
is χi (χi), it has an approximation error of ||fi,0 −fi,1||2
2. Only πi is shared and the approximation
will assign all edges in the boundary a value of √p. All other edges deviate either on fi,0 or on fi,1
because the value on πi fixes the flow to √p. Note that theoretically, this error could be achieved by a
cell only covering πi and none of the other edges. However, if the cell boundary contains any edge
that has a flow value of 0 in both fi,0 and fi,1, this will result in an additional approximation error of
√p2 = p. Furthermore, since no variable can occur twice in the same clause, the only vertices shared
by χi and χi are on πi; i.e., the only cells that close πi and don’t include an edge that is not covered
by fi,0 or fi,1 are χi and χi."
OTHER,0.8469945355191257,We set
OTHER,0.8497267759562842,"ε := p −2 + l
X"
OTHER,0.8524590163934426,"i=1
||fi,0 −fi,1||2
2
(9)"
OTHER,0.855191256830601,Representing Edge Flows on Graphs via Sparse Cell Complexes
OTHER,0.8579234972677595,"and observe that the error for all fi,0, fi,1 is at most Pl
i=1 ||fi,0 −fi,1||2
2 < ε if cells are selected as
designed and at least p −1 + Pl
i=1 ||fi,0 −fi,1||2
2 > ε if they are not (already accounting for the
projection of other cells)."
OTHER,0.860655737704918,"Finally, we construct the flow fd that mimics the evaluation of S for a given truth value assignment.
For this, we set the flow for all variable paths, loop edges, and all clause cycles to 1. Since the
variable paths and loop edges form a cycle, grad(fd) = 0."
OTHER,0.8633879781420765,"If S is satisfiable, i.e., a valid truth value assignment exists, we can use it to construct a solution to
DCS. We select cells according to the truth values of all variables. Since these truth values cover
each clause exactly once, the same is true for cells and clause cycles. The flow for each cell is 1 and
we can calculate an upper bound for the approximation error: For each literal a ∈{xi, xi} that is
evaluated to true, the corresponding cell has an error of 1 on"
OTHER,0.8661202185792349,"1. edges that end in vj,a,in for all clauses cj ∈C,"
OTHER,0.8688524590163934,"2. edges (vj,a,out, vj,a,in) for all clauses cj ∈C, and"
OTHER,0.8715846994535519,"3. one edge per cell that connects the last clause to vxi,in."
OTHER,0.8743169398907104,"The total number of these edges is l + 2k. In combination with l the loop edges (ui,out, ui,in), this
results in an upper bound of 2l+2k for fd and 2l+2k+Pl
i=1 ||fi,0−fi,1||2
2 < p−2+Pl
i=1 ||fi,0−
fi,1||2
2 = ε for the error if the 1-in-3-SAT instance is satisfiable."
OTHER,0.8770491803278688,"If S is not satisfiable, every solution has at least one clause that is not covered or covered at least twice.
In both cases, the approximation is off by at least 1 on every edge of the cell, resulting in an error of
3p+3 on fd. Overall, this results in a lower bound for the error of 3p+3−1+Pl
i=1 ||fi,0−fi,1||2
2 >
p −2 + Pl
i=1 ||fi,0 −fi,1||2
2 = ε (already accounting for the projection of other cells). Therefore,
DCS(G, F, n, ε) is equivalent to S."
OTHER,0.8797814207650273,"By using this reduction and the NP-Completeness of 1-in-3-SAT, we have shown that the decision
variant of the cell inference problem is NP-Hard."
OTHER,0.8825136612021858,Representing Edge Flows on Graphs via Sparse Cell Complexes
OTHER,0.8852459016393442,"E
Time Complexity for Heuristics"
OTHER,0.8879781420765027,"The time complexity of one maximum spanning tree candidate search is O(m log m): Using the
Union-Find data structure, we can construct a maximum spanning tree in O(m log m) by first
sorting the edges by total flow and then subsequently adding edges iff their nodes are not already
connected (using UnionFind [52] in O(α(n)) per edge2). For each node, we calculate its flow
potential as the sum of all edge flows on the path between it and the root (considering the direction).
To get the total flow along a cycle induced by a new edge (u, v), we add the flows for the edge
to the difference between the potentials at u and v. The length of the cycle induced by (u, v) is
d(u) + d(v) −2 ∗d(lca(u, v)) + 1, where d(u) is the depth of node u in the tree and lca denotes
the lowest common ancestor of two nodes. The length of all induced cycles can be obtained in
O(mα(m)) by using Tarjan’s off-line lowest common ancestors algorithm [52]."
OTHER,0.8907103825136612,"F
Additional Numerical Experiments"
OTHER,0.8934426229508197,"0
20
40
60
80
|
2| 0 20 40"
OTHER,0.8961748633879781,"loss( , F)"
OTHER,0.8989071038251366,method
OTHER,0.9016393442622951,"triangles
max
similarity
true_cells"
OTHER,0.9043715846994536,"(a) Approximation error for different sparsity con-
straints. Noise with σ = 0.75."
OTHER,0.907103825136612,"0.0
0.5
1.0
1.5
2.0
edge noise (
n) 0 25 50 75"
OTHER,0.9098360655737705,"loss( , F)"
OTHER,0.912568306010929,method
OTHER,0.9153005464480874,"triangles
max
similarity
true_cells"
OTHER,0.9180327868852459,"(b) Approximation error for noise with different σ. Best
approximation with |C2| ≤20; the ground-truth cell
complex has a larger error because |C2| = 10."
OTHER,0.9207650273224044,"Figure 13: Comparison of our approach, triangles, and ground-truth cells. Sparsity measured by
|C2|."
OTHER,0.9234972677595629,"0
1000
2000
B2 0 102 103"
OTHER,0.9262295081967213,"loss( , F)"
OTHER,0.9289617486338798,method
OTHER,0.9316939890710383,"triangles
max
similarity
cell_candidates"
OTHER,0.9344262295081968,"1
5
20"
OTHER,0.9371584699453552,(a) Barcelona.
OTHER,0.9398907103825137,"0
1000
2000
3000
B2 0 102"
OTHER,0.9426229508196722,"8 × 101
9 × 101"
OTHER,0.9453551912568307,"loss( , F)"
OTHER,0.9480874316939891,method
OTHER,0.9508196721311475,"triangles
max
similarity
cell_candidates"
OTHER,0.953551912568306,"1
5
20"
OTHER,0.9562841530054644,(b) Berlin-Center.
OTHER,0.9590163934426229,"0
1000
2000
3000
B2 0 101"
OTHER,0.9617486338797814,"loss( , F)"
OTHER,0.9644808743169399,method
OTHER,0.9672131147540983,"triangles
max
similarity
cell_candidates"
OTHER,0.9699453551912568,"1
5
20"
OTHER,0.9726775956284153,(c) Berlin-Mitte-Prenzlauerberg-Friedrichshain-Center.
OTHER,0.9754098360655737,"0
1000
2000
3000
B2 0 103"
OTHER,0.9781420765027322,"2 × 102
3 × 102
4 × 102
6 × 102"
OTHER,0.9808743169398907,"loss( , F)"
OTHER,0.9836065573770492,method
OTHER,0.9863387978142076,"triangles
max
similarity
cell_candidates"
OTHER,0.9890710382513661,"1
5
20"
OTHER,0.9918032786885246,(d) Winnipeg.
OTHER,0.994535519125683,Figure 14: Experiments on TransportationNetworks [3] datasets.
OTHER,0.9972677595628415,2Where α is the inverse of the Ackermann function
