Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.001072961373390558,"Machine learning (ML) robustness and generalization are fundamentally corre-
lated: they essentially concern about data distribution shift under adversarial and
natural settings, respectively. Thus, it is critical to uncover their underlying con-
nections to tackle one based on the other. On one hand, recent studies show that
more robust (adversarially trained) models are more generalizable to other do-
mains. On the other hand, there lacks of theoretical understanding of such phe-
nomenon, and it is not clear whether there are counterexamples. In this paper, we
aim to provide sufÔ¨Åcient conditions for this phenomenon considering different fac-
tors that could affect both, such as norm of the last layer, Jacobian norm, and data
augmentations (DA). In particular, we propose a general theoretical framework
indicating factors that can be reformed as a function class regularization process,
which could lead to improvements of domain generalization. Our analysis, for the
Ô¨Årst time, shows that ‚Äúrobustness‚Äù is actually not the causation for domain gener-
alization; rather, robustness induced by adversarial training is a by-product of such
function class regularization. We then discuss in details about different properties
of DA and we prove that under certain conditions, DA can be viewed as regular-
ization and therefore improve generalization. We conduct extensive experiments
to verify our theoretical Ô¨Åndings and show several counterexamples where robust-
ness and generalization are negatively correlated when the sufÔ¨Åcient conditions
are not satisÔ¨Åed."
INTRODUCTION,0.002145922746781116,"1
INTRODUCTION"
INTRODUCTION,0.003218884120171674,"Domain generalization (or transferability) is the task of training machine learning models with
data from one or more source domains that can be adapted to a target domain, often via low-
cost Ô¨Åne-tuning.
Thus, domain generalization refers to approaches designed to address the
natural data distribution shift problem (Muandet et al., 2013; Rosenfeld et al., 2021). A wide array of
approaches have been proposed to address domain transferability, including Ô¨Åne-tuning the last layer
of DNNs (Huang et al., 2018), invariant feature optimization (Muandet et al., 2013), efÔ¨Åcient model
selection for Ô¨Åne-tuning (You et al., 2019), and optimal transport based domain adaptation (Courty
et al., 2016). Improving domain generalization has emerged as an important task in the machine
learning community: for instance, it is among the key technologies to enable an autonomous driving
vehicle trained in city scenarios to make correct decisions in the countryside as well."
INTRODUCTION,0.004291845493562232,"On
the
other
hand,
robust
machine
learning
aims
to
tackle
the
problem
of
adversarial data distribution shift.
Both empirical and certiÔ¨Åed robust learning approaches
have been proposed, such as empirical adversarial training (Madry et al., 2018) and certiÔ¨Åed
defenses based on deterministic and probabilistic approaches (Cohen et al., 2019)."
INTRODUCTION,0.00536480686695279,"As domain transferability and robust machine learning tackle different kinds of data distribution
shifts, this work seeks to uncover their underlying connections and tradeoffs. For instance, recent
studies suggest that adversarially robust models are more domain transferable (Salman et al., 2020),
which, in turn, provides new insights on improving domain generalization. However, a theoretical
analysis of their relationship is still lacking, and it is unclear whether such positive correlations al-"
INTRODUCTION,0.006437768240343348,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.0075107296137339056,(c) Last-Layer norm
INTRODUCTION,0.008583690987124463,"Adversarially robust models may
not transfer better"
INTRODUCTION,0.009656652360515022,Sufficient conditions for domain transferability
INTRODUCTION,0.01072961373390558,"(b) Jacobian norm
(a) Data augmentations"
INTRODUCTION,0.011802575107296138,"Source
Domain
Feature Extractor
Last Layer"
INTRODUCTION,0.012875536480686695,"(a)
(b)
(c) ‚Ä¶"
INTRODUCTION,0.013948497854077254,Figure 1: Illustration of robustness and domain transferability in different conditions.
INTRODUCTION,0.015021459227467811,"ways hold. In this paper, we take the Ô¨Årst steps towards formally analyzing the relationship between
model robustness and domain transferability to answer the following questions: What are sufÔ¨Åcient
conditions for domain transferability? Is model robustness the cause of domain transferability? Can
robustness and domain transferability be negatively correlated?"
INTRODUCTION,0.016094420600858368,"To answer the above questions and uncover the underlying relationship between robustness and
domain transferability, we propose a general theoretical framework that characterizes sufÔ¨Åcient con-
ditions for domain transferability from the view of function class regularization. Our analysis shows
that if the function class of feature extractors is more regularized, the model based on a feature
extractor trained from the function class, composed with a Ô¨Åne-tuned last layer, can be more trans-
ferable. Formally, we prove that there is a monotone relation between the regularization strength
and a tight upper bound on the relative domain transfer loss."
INTRODUCTION,0.017167381974248927,"Under the proposed framework, we analyze several common factors for model training, including
the Jacobian norm, the last layer norm, data augmentation, and adversarial training as shown in
Fig. 1. In particular, controlling the Jacobian norm and last layer norm can be viewed as function-
class regularization, thus can be analyzed in our framework. We also analyze how other common
regularization operations can be mapped to function class regularization. For instance, we consider
noise-dependent and independent data augmentation procedures based on feature average and loss
average aggregation algorithms."
INTRODUCTION,0.018240343347639486,"We conduct extensive experiments on ImageNet (CIFAR-10 as target domain) and CIFAR-10
(SVHN as target domain) based on different models to verify our analysis. We show that regulariza-
tion can control domain transferability, and robustness and domain transferability can be negatively
correlated, which are counter-examples against Salman et al. (2020). Taken together, this indicates
that robustness is not a cause of transferability."
INTRODUCTION,0.019313304721030045,"Technical Contributions. We aim to uncover the underlying relationship between robustness and
domain transferability and lay out the sufÔ¨Åcient conditions for transferability from the view of reg-
ularization. We make both theoretical and empirical contributions."
INTRODUCTION,0.0203862660944206,"‚Ä¢ We propose a theoretical framework to analyze the sufÔ¨Åcient conditions for domain transferability
from the view of function class regularization. We provably show that stronger regularization
on the feature extractor implies a decreased tight upper bound on the relative transferability loss;
while model robustness could be arbitrary."
INTRODUCTION,0.02145922746781116,"‚Ä¢ We prove the tightness of our transferability upper bound, and provide the generalization bound
of the relative transferability loss from the view of regularization."
INTRODUCTION,0.022532188841201718,"‚Ä¢ We analyze several factors such as different data augmentations (e.g., rotation and Gaussian) under
the framework, and show how they can be mapped to function class regularization and therefore
affect transferability."
INTRODUCTION,0.023605150214592276,"‚Ä¢ We conduct extensive experiments on different datasets and model architectures to verify our theo-
retical claims. We also show several counterexamples that indicate signiÔ¨Åcant negative correlation
between robustness and the relative domain transferability."
RELATED WORK,0.02467811158798283,"2
RELATED WORK"
RELATED WORK,0.02575107296137339,"Domain Transferability has been analyzed in different settings. Muandet et al. present a gener-
alization bound for classiÔ¨Åcation task based on the properties of the assumed prior over training
environments. Rosenfeld et al. model domain transferability/generalization as an online game and
show that generalizing beyond the convex hull of training environments is NP-hard, and Zhang et al.
provides a generalization bound for distributions with sufÔ¨Åciently small H-divergence. Given the"
RELATED WORK,0.02682403433476395,Under review as a conference paper at ICLR 2022
RELATED WORK,0.027896995708154508,"complexity of domain transferability analysis, recent empirical studies show that adversarially ro-
bust models transfer better (Salman et al., 2020). In this paper, we aim to relax the assumptions and
focus on understanding the domain transferability from the view of regularization and theoretically
show whether ‚Äúrobustness‚Äù is indeed a causation for transferability or not."
RELATED WORK,0.028969957081545063,"Model Robustness is an important topic given recent diverse adversarial attacks (Goodfellow et al.,
2014; Carlini & Wagner, 2017). These attacks may be launched without access to model param-
eters (Tu et al., 2019) or even with the model predicted label alone (Chen et al., 2020). Different
approaches have been proposed to improve model robustness against adversarial attack. Adversar-
ial training has been shown to be effective empirically (Madry et al., 2018; Zhang et al., 2019a;
Miyato et al., 2018). Some studies have shown that robustness is property related to other model
characteristics, such as transferability and invertibility (Engstrom et al., 2019)."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.030042918454935622,"3
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.03111587982832618,"In this section, we theoretically analyze the problem of domain transferability from the view of
regularization and discuss some sufÔ¨Åcient conditions for good transferability. All of the proofs are
provided in Section A in the appendix."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.032188841201716736,"Notations. We denote the input space as X; the feature space as Z and the output space as Y. Let
the Ô¨Åne-tuning function class be g ‚ààG. Given a feature extractor f : X ‚ÜíZ and a Ô¨Åne-tuning
function g : Z ‚ÜíY, the full model is g ‚ó¶f : X ‚ÜíY. We denote PX√óY as the set of distributions
on X √ó Y. The loss function is denoted by ‚Ñì: Y √ó Y ‚ÜíR+, and the population loss based on data
distribution D ‚ààPX√óY and a model g ‚ó¶f is deÔ¨Åned as"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.033261802575107295,"‚ÑìD(g ‚ó¶f) := E(x,y)‚àºD[‚Ñì(g ‚ó¶f(x), y)]."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.034334763948497854,"Before diving into the details, we Ô¨Årst provide the following example to illustrate why one might
investigate domain transferability from the view of regularization."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.03540772532188841,"3.1
EXAMPLE: ROBUSTNESS AND TRANSFERABILITY ARE INDEPENDENT"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.03648068669527897,"In this subsection, we construct a simple example where domain transferability depends on regular-
ization, yet domain transferability and robustness are independent. Moreover, this example serves
as motivation to consider domain transferability from the view of regularization."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.03755364806866953,"Given the source and target distributions DS, DT ‚ààPX√óY, we denote their marginal distributions
on the input space X as DX
S and DX
T , respectively. We consider the case that X ‚äÇRm being a
low-dimensional manifold in Rm, and Y = Rd. Given an input x ‚ààX, the ground truth target for
the source domain is yS(x) generated by a function yS : Rm ‚ÜíRd. Similarly, we deÔ¨Åne yT for
the target domain. In this example, for simplicity, we neglect the Ô¨Åne-tuning process but directly
consider learning a function f : Rm ‚ÜíRd with a norm ‚à•¬∑ ‚à•on Rd. For the source domain we have
the population loss:"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.03862660944206009,"‚ÑìDS(f) = Ex‚àºDX
S [‚à•f(x) ‚àíyS(x)‚à•]."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.03969957081545064,"A distribution D ‚ààPX on the input space X, deÔ¨Ånes a norm of a function f : Rm ‚ÜíRd as"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.0407725321888412,"‚à•f‚à•D := Ex‚àºD[‚à•f(x)‚à•],"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.04184549356223176,"where we view two functions f1, f2 as the same if ‚à•f1 ‚àíf2‚à•D = 0. Therefore, we can deÔ¨Åne the
source domain loss ‚ÑìDS(f) = ‚à•f ‚àíyS‚à•DX
S and the target domain loss ‚ÑìDT (f) = ‚à•f ‚àíyT ‚à•DX
T ."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.04291845493562232,"For the sake of illustration, we consider the simple case where the input distributions DX
S , DX
T are
the same, and hence we denote D = DX
S = DX
T . Note that yS and yT are different."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.043991416309012876,"Denoting a function space F = {f : Rm ‚ÜíRd | ‚à•f‚à•D < ‚àû}, we assume that yS, yT ‚ààF and we
can compare f, yS, yT in the same space. Therefore, given c > 0 as a regularization parameter, the
domain transferability problem can be deÔ¨Åned as:"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.045064377682403435,"Learning a source model:
f DS
c
‚ààarg min
f‚ààF
‚ÑìDS(f),
s.t. ‚à•f‚à•D ‚â§c;
(1)"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.046137339055793994,"Testing on a target domain:
‚ÑìDT (f DS
c
),"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.04721030042918455,Under review as a conference paper at ICLR 2022
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.048283261802575105,"where the minimizer f DS
c
:= yS min{1,
c
‚à•yS‚à•D }, the source domain loss is ‚ÑìDS(f) = ‚à•f ‚àíyS‚à•D,
and the target domain loss is ‚ÑìDT (f) = ‚à•f ‚àíyT ‚à•D. We prove in Proposition 3.1 that f DS
c
is indeed
a minimizer of (1) and provide an intuitive illustration in Figure 2."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.04935622317596566,"We show that the robustness can be independent to domain transferability as follows. Consider the
adversarial robustness of f DS
c
on an input x ‚ààX (e.g., maxŒ¥:‚à•Œ¥‚à•2‚â§œµ ‚Ñì(f DS
c
(x + Œ¥), yS(x))). Since
the transferred loss ‚ÑìDT (f DS
c
) only evaluates f DS
c
on X which is a low-dimensional manifold in
Rm, an adversarial perturbation Œ¥ ‚ààRm could make x + Œ¥ ‚ààRm\X when the loss function is
sufÔ¨Åciently big outside the manifold X. Therefore, the robustness could be arbitrarily bad without
changing the value of ‚ÑìDT (f DS
c
), i.e., the performance of the source model on the target domain."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.05042918454935622,"As we can see, the robustness is independent to domain transferability in this example. On the
contrary, if we change the perspective to consider the the regularization parameter c, we have the
following interesting Ô¨Ånding. An illustration of the Ô¨Ånding is shown in Figure 2, and a more formal
statement is provided in Proposition 3.1. ‚Ñ±"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.05150214592274678,"||ùëì||ùíü‚â§ùëê ùëìùëê ùíüùëÜ ùë¶ùëÜ
ùë¶ùëá 0 ùëê"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.05257510729613734,‚ÑìùíüùëÜ(ùëìùëê
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.0536480686695279,"ùíüùëÜ)
‚Ñìùíüùëá(ùëìùëê ùíüùëÜ)"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.05472103004291846,Source Training Function Class Size ùëê
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.055793991416309016,Source Loss = ‚ÑìùíüùëÜ(ùëìùëê ùíüùëÜ)
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.05686695278969957,Transferred Loss = ‚Ñìùíüùëá(ùëìùëê
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.05793991416309013,"ùíüùëÜ)
Relative Domain 
Transferability Loss = 
‚Ñìùíüùëá(ùëìùëê"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.059012875536480686,ùíüùëÜ) ‚àí‚ÑìùíüùëÜ(ùëìùëê
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.060085836909871244,"ùíüùëÜ)
Different ùëê"
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.0611587982832618,"Figure 2: The left Ô¨Ågure illustrates the example in the function space F given a regularization parameter c.
The right Ô¨Ågure shows the relations between domain transferability and the c. In this example, the weaker the
regularization effect (greater c) is, the greater the relative domain transferability loss (violet arrow becomes)."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.06223175965665236,"Proposition 3.1. Given the problem deÔ¨Åned above, f DS
c
is a minimizer of equation 1. If c ‚â•c‚Ä≤ ‚â•0,
then the relative domain transferability loss ‚ÑìDT (f DS
c
) ‚àí‚ÑìDS(f DS
c
) ‚â•‚ÑìDT (f DS
c‚Ä≤ ) ‚àí‚ÑìDS(f DS
c‚Ä≤ )."
SUFFICIENT CONDITIONS FOR DOMAIN TRANSFERABILITY,0.06330472103004292,"We can see that robustness is not sufÔ¨Åcient to characterize domain transferability. However, there is
a monotone relation between the regularization strength and the relative transferability loss, where
adversarial robustness could be arbitrary. Similar behavior is also observed in our experiments, as
we will discuss in Section 4. Naturally, these Ô¨Åndings motivate the study of the connections between
the regularization of the training process and domain transferability in general, as we consider next."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.06437768240343347,"3.2
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY"
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.06545064377682404,"In this subsection, we consider the general transferability problem with Ô¨Åne-tuning. We prove that
there is a monotone relationship between the regularization strength and relative domain transfer-
ability loss. We also present a tight upper bound on the relative domain transferability loss. Denote
the training algorithm as A that takes a data distribution D and outputs a feature extractor f D
A ‚ààFA
chosen from a function class FA and a Ô¨Åne-tuning function gD
A ‚ààG. Next we formally deÔ¨Åne
relative domain transferability.
DeÔ¨Ånition 1 (Relative Domain Transferability Loss). Given the training algorithm A and a pair of
distributions DS, DT ‚ààPX√óY, the relative domain transferability loss between DS, DT is deÔ¨Åned
to be the difference of Ô¨Åne-tuned losses, i.e.,"
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.06652360515021459,"œÑ(A; DS, DT ) := inf
g‚ààG ‚ÑìDT (g ‚ó¶f DS
A ) ‚àí‚ÑìDS(gDS
A
‚ó¶f DS
A )."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.06759656652360516,"Note that the training algorithm A is not required to be optimal, i.e., it could be the case that
‚ÑìDS(gDS
A
‚ó¶f DS
A ) > infg‚ààG,f‚ààFA ‚ÑìDS(g ‚ó¶f). As we can see, the smaller œÑ(A; DS, DT ) is, the
better the model‚Äôs relative performance becomes on the target domain."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.06866952789699571,"Another perspective of DeÔ¨Ånition 1 is that infg‚ààG ‚ÑìDT (g‚ó¶f DS
A ) = ‚ÑìDS(gDS
A ‚ó¶f DS
A )+œÑ(A; DS, DT ).
From this perspective, the transferred loss is the source loss plus an additional term to be upper
bounded by a certain distance metric between the source and target distributions ‚Äì as is common
in the literature of domain adaptation (e.g., Ben-David et al. (2007); Zhao et al. (2019)). The key
question of the ‚Äúdistance metric‚Äù remains unanswered. To this end, we propose the following."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.06974248927038626,Under review as a conference paper at ICLR 2022
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07081545064377683,"DeÔ¨Ånition 2 ((G, F)-pseudometric). Given a Ô¨Åne-tuning function class G, a feature extractor func-
tion class F and distributions DS, DT ‚ààPX√óY, the (G, F)-pseudometric between DS, DT is
dG,F(DS, DT ) := sup
f‚ààF
| inf
g‚ààG ‚ÑìDS(g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìDT (g ‚ó¶f)|."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07188841201716738,"Since the Ô¨Åne-tuning function class is usually simple and Ô¨Åxed, we will use dF as an abbreviation in
the context where G is clear."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07296137339055794,"It can be easily veriÔ¨Åed that dG,F is a pseudometric that measures the distance between two distri-
butions, as shown in the following proposition.
Proposition 3.2. dG,F(¬∑, ¬∑) : PX√óY √ó PX√óY ‚ÜíR+ satisÔ¨Åes the following properties; (Symme-
try) dG,F(DS, DT ) = dG,F(DT , DS); (Triangle Inequality) ‚àÄD‚Ä≤ ‚ààPX√óY : dG,F(DS, DT ) ‚â§
dG,F(DS, D‚Ä≤) + dG,F(D‚Ä≤, DT ); (Weak Zero Property) ‚àÄD ‚ààPX√óY : dG,F(D, D) = 0."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.0740343347639485,"In this section, we consider a Ô¨Åxed Ô¨Åne-tuning function class G and feature extractor function class
FA given by the training algorithm A. Thus, we denote dG,F as dFA for the remainder of the paper.
With the deÔ¨Ånition of dFA, we can derive the following result.
Theorem 3.1. Given a training algorithm A, for ‚àÄDS, DT ‚ààPX√óY we have
œÑ(A; DS, DT ) ‚â§dFA(DS, DT ),"
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07510729613733906,"or equivalently,
inf
g‚ààG ‚ÑìDT (g ‚ó¶f DS
A ) ‚â§‚ÑìDS(gDS
A
‚ó¶f DS
A ) + dFA(DS, DT )."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07618025751072961,"Interpretation: As we can see, the above theorem provides sufÔ¨Åcient conditions for good domain
transferability. There is a monotone relation between the regularization strength and dFA(DS, DT ),
i.e., the upper bound on the relative domain transferability loss œÑ(A; DS, DT ). More explicitly, if
a training algorithm A‚Ä≤ has FA‚Ä≤ ‚äÜFA, then dFA‚Ä≤(DS, DT ) ‚â§dFA(DS, DT ). Moreover, small
dFA(DS, DT ) implies good relative domain transferability. From this perspective, we can see that
we need both small dFA(DS, DT ) and small source loss ‚ÑìDS(gDS
A
‚ó¶f DS
A ) to guarantee good ab-
solute domain transferability. Note that there is a possible trade-off, i.e., with FA being smaller,
dFA(DS, DT ) decreases but possibly ‚ÑìDS(gDS
A
‚ó¶f DS
A ) increases due to the limited power of FA.
On the other hand, there may not be such trade-off if DS and DT are close enough such that
dFA(DS, DT ) is small."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07725321888412018,"To make the upper bound more meaningful, we need to study the tightness of it.
Theorem 3.2. Given any source distribution DS ‚ààPX√óRd, any Ô¨Åne-tuning function class G where
G includes the zero function, and any training algorithm A, denote"
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07832618025751073,"œµ := ‚ÑìDS(gDS
A
‚ó¶f DS
A ) ‚àí
inf
g‚ààG,f‚ààFA ‚ÑìDS(g ‚ó¶f)."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.07939914163090128,"We assume some properties of the loss function ‚Ñì: Rd √ó Rd ‚ÜíR+: it is differentiable and strictly
convex w.r.t. its Ô¨Årst argument; ‚Ñì(y, y) = 0 for any y ‚ààRd; and limr‚Üí‚àûinfy:‚à•y‚à•2=r ‚Ñì(‚Éó0, y) = ‚àû,
where ‚Éó0 is the zero vector. Then, for any distribution DX on X, there exist some distributions
DT ‚ààPX√óRd with its marginal on X being DX such that
œÑ(A; DS, DT ) ‚â§dFA(DS, DT ) ‚â§œÑ(A; DS, DT ) + œµ,
or equivalently dFA(DS, DT ) ‚àíœµ ‚â§œÑ(A; DS, DT ) ‚â§dFA(DS, DT )."
UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08047210300429185,"Interpretation: In the above theorem, we show that given any A, DS, and the marginal DX , there
exists some conditional distributions of y|x such that by composing it with the given DX we have
a distribution DT to make the bound in Theorem 3.1 œµ-tight. Note that œµ is the difference between
the source loss and the its inÔ¨Åmum, i.e., with a good enough algorithm A, the œµ could be arbitrarily
small."
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.0815450643776824,"3.3
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08261802575107297,"Here we investigate the proposed theory on relative transferability with Ô¨Ånite samples. For a distri-
bution D ‚ààPX√óY, we denote its empirical distribution with n samples as bDn. That being said,"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08369098712446352,"‚Ñìb
Dn(g ‚ó¶f) = E(x,y)‚àºb
Dn[‚Ñì(g ‚ó¶f(x), y)] = 1 n n
X"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08476394849785408,"i=1
‚Ñì(g ‚ó¶f(xi), yi),"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08583690987124463,Under review as a conference paper at ICLR 2022
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08690987124463519,"where (xi, yi) are i.i.d. samples from D. Therefore, given two distributions DS, DT ‚ààPX√óY, the
empirical (G, F)-pseudometric between them is dG,F( bDn
S, bDn
T )."
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.08798283261802575,"Note that dG,F is not only a pseudometric of distributions, but also a complexity measure, and we
will Ô¨Årst connect it with the Rademacher complexity.
DeÔ¨Ånition 3 (Empirical Rademacher Complexity (Bartlett & Mendelson, 2002; Koltchinskii,
2001)). Denote the loss function class induced by G, F as"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.0890557939914163,"LG,F := {hg,f : X √ó Y ‚ÜíR+ | g ‚ààG, f ‚ààF},
where hg,f(x, y) := ‚Ñì(g ‚ó¶f(x), y)."
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09012875536480687,"Given an empirical distribution bDn (i.e., n data samples), the Rademacher complexity of it is"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09120171673819742,"Rad b
Dn(LG,F) := 1 nEŒæ """
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09227467811158799,"sup
h‚ààLG,F n
X"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09334763948497854,"i=1
Œæih(xi, yi) # ,"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.0944206008583691,"where Œæ ‚ààRn are Rademacher variables, i.e., each Œæi is i.i.d. uniformly distributed on {‚àí1, 1}."
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09549356223175966,"We can see that if there is a F‚Ä≤ ‚äÜF, then Rad b
Dn(LG,F‚Ä≤) ‚â§Rad b
Dn(LG,F). With the above deÔ¨Åni-
tions, we have the following lemma connecting the (G, F)-pseudometric to Rademacher complexity.
Lemma 3.1. Assuming the individual loss function ‚Ñì: Y √ó Y ‚Üí[0, c], given any distribution
D ‚ààPX√óY and ‚àÄŒ¥ > 0, with probability ‚â•1 ‚àíŒ¥ we have"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09656652360515021,"dG,F(D, bDn) ‚â§2Rad b
Dn(LG,F) + 3c r"
GENERALIZATION UPPER BOUND OF THE RELATIVE DOMAIN TRANSFERABILITY,0.09763948497854077,ln(4/Œ¥)
N,0.09871244635193133,"2n
."
N,0.09978540772532189,"Therefore, denoting again dFA as dG,FA, the empirical version of Theorem 3.1 is as follows.
Theorem 3.3. Assuming the individual loss function ‚Ñì: Y √ó Y ‚Üí[0, c], given ‚àÄDS, DT ‚ààPX√óY,
for ‚àÄŒ¥ > 0 with probability ‚â•1 ‚àíŒ¥ we have"
N,0.10085836909871244,"œÑ(A; bDn
S, DT ) ‚â§dFA( bDn
S, bDn
T ) + 2Rad b
Dn
T (LG,FA) + 4Rad b
Dn
S(LG,FA) + 9c r"
N,0.10193133047210301,ln(8/Œ¥)
N,0.10300429184549356,"2n
."
N,0.10407725321888411,"We can see that a smaller feature extractor function class FA implies both a smaller dFA and the
Rademacher complexity. Therefore, the monotone relation between the regularization strength and
the upper bound on the relative domain transferability loss also holds for the empirical settings."
N,0.10515021459227468,"Other than direct regularization, empirically we Ô¨Ånd that the transferability is also related to the use
of data augmentation. Can we explain such phenomena from the view of regularization again? We
discuss this question next."
N,0.10622317596566523,"3.4
WHEN CAN DATA AUGMENTATION BE VIEWED AS REGULARIZATION?"
N,0.1072961373390558,"In this subsection, we discuss the connections between data augmentation (DA) and regularization.
We present the results and their interpretation in this subsection, while deferring the detailed discus-
sion to the Section B in the appendix."
N,0.10836909871244635,"Empirical research has shown evidence of the regularization effect of DA (Hern¬¥andez-Garc¬¥ƒ±a &
K¬®onig, 2018a;b). However, there is a lack of theoretical understanding on when can data augmen-
tation be viewed as regularization in general. In an attempt to address this question, we consider a
general DA setting of afÔ¨Åne transformation (Perez & Wang, 2017) with parameters (W‚ãÜ, b‚ãÜ) whose
distribution represents speciÔ¨Åc DA."
N,0.10944206008583691,"General Settings. We consider the Ô¨Åne-tuning function g : Rd ‚ÜíR as a linear layer, which will
be concatenated to the feature extractor f : Rm ‚ÜíRd. Given a model g ‚ó¶f, we use the squared
loss ‚Ñì(g ‚ó¶f(x), y) = (g ‚ó¶f(x) ‚àíy)2, and accordingly apply second-order Taylor expansion to the
objective function to study the effect of data augmentation."
N,0.11051502145922747,"DA categories. We discuss two categories of DA, feature-level DA and data-level DA. Feature-level
DA (Wong et al., 2016; DeVries & Taylor, 2017) requires the transformation to be performed in the
learned feature space: given a data sample x ‚ààRm and a feature extractor f, the augmented feature
is W‚ãÜf(x) + b‚ãÜwhere W‚ãÜ‚ààRd√ód, b‚ãÜ‚ààRd are sampled from a distribution. On the other hand,"
N,0.11158798283261803,Under review as a conference paper at ICLR 2022
N,0.11266094420600858,"data-level DA requires the transformation to be performed in the input space: given a data sample x,
the augmented sample is W‚ãÜx + b‚ãÜwhere W‚ãÜ‚ààRm√óm, b‚ãÜ‚ààRm are sampled from a distribution."
N,0.11373390557939914,"Intuition on sufÔ¨Åcient conditions. For either the feature-level or the data-level DA, the intuitions
given by our analysis are similar. Our results (Theorem B.1&B.2) suggest that the following condi-
tions indicate the regularization effects of a data augmentation: 1) EW‚ãÜ[W‚ãÜ] = I; 2) Eb‚ãÜ[b‚ãÜ] = ‚Éó0;
3) W‚ãÜand b‚ãÜare independent, where I is the identity matrix and ‚Éó0 is the zero vector; 4) W‚ãÜis not a
constant if it is the feature-level DA; 5) DA is of a small magnitude if it is the data-level DA."
N,0.1148068669527897,"Empirical veriÔ¨Åcation. Combining with Theorem 3.3, it suggests that DA satisfying the conditions
above may improve the relative domain transferability. In fact, it matches the empirical observa-
tions in Section 4. Concretely, 1) Gaussian noise satisÔ¨Åes the four conditions, and empirically the
Gaussian noise improves domain transferability while robustness decreases a bit (Figure 5); 2) Ro-
tation, which rotates input image with a predeÔ¨Åned Ô¨Åxed angle with predeÔ¨Åned Ô¨Åxed probability,
violates EW‚ãÜ[W‚ãÜ] = I, and empirically the rotation barely affects domain transferability (Figure 14
in Appendix D.3); 3) Translation, which moves the input image for a predeÔ¨Åned distance along a
pre-selected axis with Ô¨Åxed probability, violates Eb‚ãÜ[b‚ãÜ] = ‚Éó0, and empirically the translation dis-
tance barely co-relates to the domain transferability (Figure 14 in Appendix D.3)."
EVALUATION,0.11587982832618025,"4
EVALUATION"
EXPERIMENTAL SETTING,0.11695278969957082,"4.1
EXPERIMENTAL SETTING"
EXPERIMENTAL SETTING,0.11802575107296137,"Source model training
We train our model on two source domains: CIFAR-10 and ImageNet.
Unless speciÔ¨Åed, we will use the training setting as follows1. For CIFAR-10, we train the model
with 200 epochs using the momentum SGD optimizer with momentum 0.9, weight decay 0.0005,
an initial learning rate 0.1 which decays by a factor of 10 at the 100-th and 150-th epoch. For
ImageNet, we train the model with 90 epochs using the momentum SGD optimizer with momentum
0.9, weight decay 0.0001, an initial learning rate 0.1 which decays by a factor of 10 at the 30-th and
60-th epoch. We use the standard cross entropy loss denote as LCE(hs, x, y), where hs = gs ‚ó¶f
is the trained model and x, y are the input and label respectively. To evaluate the robustness on the
source domain, we follow the evaluation setting in Ilyas et al. (2019) and perform the PGD attack
with 20 steps using œµ = 0.25. We also evaluate the robustness using AutoAttack in Appendix D.4.
For both tasks we use ResNet-18 as the model structure. We provide results of other model structures
in appendix D.2."
EXPERIMENTAL SETTING,0.11909871244635194,"Domain Transferability
We evaluate the transferability from CIFAR-10 to SVHN and from Im-
ageNet to CIFAR-10. For the ImageNet transferability, we focus on CIFAR as the target domain,
since it is the domain that is the most positively correlated with robustness as shown in Salman et al.
(2020). We evaluate the Ô¨Åxed-feature transfer where only the last fully-connected layer is Ô¨Åne-tuned
following our theoretical framework. We Ô¨Åne-tune the last layer with 40 epochs using momentum
SGD optimizer with momentum 0.9, weight decay 0.0005, an initial learning rate 0.01 which de-
cays by a factor of 10 at the 20-th and 30-th epoch. To mitigate the impact of benign accuracy,
we evaluate the relative domain transfer accuracy (DT Acc) as follows. Let accsrc and acctgt be
the accuracy of the a Ô¨Åne-tuned model on source and target domain, and accv
src and accv
tgt be the
accuracy of vanilla model (i.e., models trained with standard setting) on source and target domain,
then the relative DT accuracy is deÔ¨Åned as:"
EXPERIMENTAL SETTING,0.12017167381974249,"DT Acc = (acctgt ‚àíaccsrc) ‚àí(accv
tgt ‚àíaccv
src)"
EXPERIMENTAL SETTING,0.12124463519313304,We also provide the results of absolute DT accuracy in Appendix D.1.
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1223175965665236,"4.2
RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.12339055793991416,"We train the model under different controllable conditions to validate our analysis. In particular,
we train the methods by controlling different regularization or data augmentations to evaluate the
change of model robustness and transferability."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.12446351931330472,"1These settings are inherited from the standard training algorithms for CIFAR-10 (https://github.
com/kuangliu/pytorch-cifar) and ImageNet (https://github.com/pytorch/examples/
tree/master/imagenet)."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1255364806866953,Under review as a conference paper at ICLR 2022
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.12660944206008584,"10
20
30
Robust Acc (%) 10 5 0 5"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1276824034334764,Relative DT Acc (%)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.12875536480686695,R: -0.782
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1298283261802575,CIFAR10 -> SVHN
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13090128755364808,"LLR(
l)
-0.1
0
0.1
1.0"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13197424892703863,"18
20
22
24
Robust Acc (%) 3 0 3"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13304721030042918,R: -0.918
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13412017167381973,ImageNet -> CIFAR10
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1351931330472103,"LLR(
l)
-0.01
0
0.01
0.1"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13626609442060086,"10
20
30
Robust Acc (%) 10 5 0"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13733905579399142,R: -0.916
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13841201716738197,CIFAR10 -> SVHN
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.13948497854077252,LLOT(||gs||2)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1405579399141631,"0.01
0.1
1.0
10.0"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.14163090128755365,"20
30
40
Robust Acc (%) 2 0 2"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1427038626609442,R: -0.954
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.14377682403433475,ImageNet -> CIFAR10
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.14484978540772533,LLOT(||gs||2)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1459227467811159,"0.5
1
2
5"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.14699570815450644,"Figure 3: Relationship between robustness and transferability under different norms of last layer,
via training with last-layer regularization (LLR) and last-layer orthogonalization (LLOT)."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.148068669527897,"Controlling the norm of last layer
As shown in our framework, domain transferability is related
with the regularization on the feature extractor. Here we regularize the transferability by controlling
the norm of last linear layer gs. Intuitively, when we force the norm of gs to be large during training,
the corresponding norm of f will be regularized to be small. We use two approaches to control the
last layer norm:"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.14914163090128754,"‚Ä¢ Last-layer regularization (LLR): we impose a strong l2-regularizer with parameter Œªl speciÔ¨Åcally
on the weight of gs and therefore our training loss becomes: LLLR(hs, x, y) = LCE(hs, x, y) +
Œªl ¬∑ ||gs||F , where ||gs||F is the frobenius norm of the weight matrix of gs.
‚Ä¢ Last-layer orthogonal training (LLOT): we directly control the l2-norm of gs with orthogonal
training (Huang et al. (2020)). The orthogonal training will enforce the weight to become a 1-
norm matrix and we multiply a constant to obtain the desired norm ||gs||2."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15021459227467812,"The result of LLR and LLOT are shown in Figure 3. We observe that when we regularize the norm
of last layer to be large (i.e. smaller Œª in LLR and larger ||gs||2 in LLOT), the domain transferability
will increase while the model robustness will decrease (their negative correlation is signiÔ¨Åcant with
Pearson‚Äôs coefÔ¨Åcient around ‚àí0.9). This is because larger last layer norm will produce a feature
extractor f with smaller norm, which, according to our analysis, leads to a better domain transfer-
ability. On the other hand, the model gs ‚ó¶f will have a larger norm and therefore becomes less
robust under adversarial attacks."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15128755364806867,"Controlling the norm of feature extractor
We directly regularize the feature extractor f and
check the impact on domain transferability. We implement two regularization as follows:"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15236051502145923,"‚Ä¢ Jacobian regularization (JR): we follow the approach in Hoffman et al. (2019) to apply JR on
the feature extractor. Given model hs = gs ‚ó¶f, the training loss becomes: LJR(hs, x, y) =
LCE(hs, x, y) + Œªj ¬∑ ||J(f, x)||2
F , where J(f, x) denotes the Jacobian matrix of f on x and || ¬∑ ||F
is the frobenius norm.
‚Ä¢ Weight Decay (WD): we impose a strong weight decay with factor Œªw on the feature extractor
f during training. This is equivalent to imposing a strong l2-regularizer with factor Œªw on the
feature extractor (excluding the last layer)."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15343347639484978,"The results under JR and WD are shown in Figure 4. We observe that with larger regularization on
the feature extractor, the model shows higher domain transferability, which matches our analysis.
Meanwhile, the robustness decreases signiÔ¨Åcantly with large regularizer. This is because a large
regularization will harm the model performance on source domain and lead to low model robustness."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15450643776824036,"20
30
40
50
60
70
Robust Acc (%) 0 5 10 15"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1555793991416309,Relative DT Acc (%)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15665236051502146,R: 0.313
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.157725321888412,CIFAR10 -> SVHN
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15879828326180256,"JR(
j)
0
100
1000"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.15987124463519314,"15
25
35
45
55
Robust Acc (%) 0 10 20 30 40"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1609442060085837,R: 0.105
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.16201716738197425,ImageNet -> CIFAR10
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1630901287553648,"JR(
j)
0
0.01
0.1
1.0"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.16416309012875535,"10
20
Robust Acc (%) 0 20 40"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.16523605150214593,R: -0.734
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.16630901287553648,CIFAR10 -> SVHN
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.16738197424892703,"WD(
w)
0.0005
0.001
0.005
0.01"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1684549356223176,"10
15
20
Robust Acc (%) 0 5 10 15"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.16952789699570817,R: -0.984
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.17060085836909872,ImageNet -> CIFAR10
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.17167381974248927,"WD(
w)
0.0001
0.0005
0.001"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.17274678111587982,"Figure 4: Relationship between robustness and transferability when we regularize the feature ex-
tractor with Jacobian Regularization (JR) and weight decay (WD)."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.17381974248927037,Under review as a conference paper at ICLR 2022
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.17489270386266095,"20
30
40
50
60
70
Robust Acc (%) 0 10 20 30 40"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1759656652360515,Relative DT Acc (%)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.17703862660944206,R: 0.168
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1781115879828326,CIFAR10 -> SVHN
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1791845493562232,Gauss( )
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18025751072961374,"0
0.05
0.25
1.0"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1813304721030043,"20
30
Robust Acc (%) 0 20 40 60"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18240343347639484,R: -0.384
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1834763948497854,ImageNet -> CIFAR10
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18454935622317598,Gauss( )
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18562231759656653,"0
0.05
0.25"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18669527896995708,"20
30
40
50
Robust Acc (%) 0 5 10"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18776824034334763,R: 0.566
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1888412017167382,CIFAR10 -> SVHN
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.18991416309012876,"Pos(b) 1
4
8"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.19098712446351931,"20
25
30
Robust Acc (%) 0 2 4"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.19206008583690987,R: 0.880
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.19313304721030042,ImageNet -> CIFAR10
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.194206008583691,"Pos(b) 1
4
8"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.19527896995708155,"Figure 5: Relationship between robustness and transferability when we use Gaussian noise (Gauss)
and posterize (Pos) as data augmentations."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1963519313304721,"0
10
20
Robust Acc (%) 0 20 40 60 80"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.19742489270386265,Relative DT Acc (%)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.1984978540772532,R: -0.917
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.19957081545064378,ResNet18
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20064377682403434,Rescale(m)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.2017167381974249,"1
2
4
8"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20278969957081544,"15
20
Robust Acc (%) 0 5 10 15"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20386266094420602,R: -0.842
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20493562231759657,ResNet18
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20600858369098712,Blur(k)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20708154506437768,"1
5
11"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.20815450643776823,"0
10
20
Robust Acc (%) 0 20 40 60 80"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.2092274678111588,R: -0.931
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21030042918454936,WideResNet-50
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.2113733905579399,Rescale(m)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21244635193133046,"1
2
4
8"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21351931330472104,"22
24
Robust Acc (%) 0 5 10"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.2145922746781116,R: -0.852
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21566523605150215,WideResNet-50
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.2167381974248927,Blur(k)
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21781115879828325,"1
5
11"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21888412017167383,"Figure 6: Relationship between robustness and transferability on ImageNet when we use rescale and
blur as data augmentations."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.21995708154506438,"Data augmentation
As shown in Section 3.4, data augmentation can be viewed as a type of reg-
ularization during training and thus affects the domain transferability. Here we consider both noise
dependent and independent data augmentations."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22103004291845493,Noise-dependent data augmentation We include two noise-dependent augmentations:
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22210300429184548,"‚Ä¢ Gaussian Noise data augmentation (Gauss): we add zero-mean Gaussian noise with variance œÉ2
to the input image.
‚Ä¢ Posterize (Pos): we truncate each channel of one pixel value into b bits (originally they are 8 bits)."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22317596566523606,"The results of Gauss and Pos are shown in Figure 5. We observe that the domain transferability
of trained model keeps improving with larger data augmentation, which matches our theory. The
robustness also beneÔ¨Åts from a small data augmentation, but decreases when it becomes large."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22424892703862662,"Resolution-related (noise-independent) data augmentation.
SpeciÔ¨Åcally, for ImageNet to
CIFAR-10 transferability, we consider two resolution-related data augmentations. The intuition is
that when the target domain has a lower resolution than the source domain (ImageNet is 224 √ó 224
while CIFAR-10 is 32√ó32), the data augmentations that down-sample the inputs during the training
on source domain will help transferability. We consider the below resolution-related augmentations:"
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22532188841201717,"‚Ä¢ Rescale: we rescale the input to be m times smaller (i.e., shape ImageNet as (224/m)√ó(224/m))
and then rescale them back to the original size."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22639484978540772,"‚Ä¢ Blur: we apply Gaussian blurring with kernel size k on the input. The Gaussian kernel is created
with a standard deviation randomly sampled from [0.1, 2.0]."
"RELATIONSHIP BETWEEN ROBUSTNESS AND TRANSFERABILITY UNDER
CONTROLLABLE CONDITIONS",0.22746781115879827,"We show the results of rescaling and blurring in Figure 6. The experiments are evaluated only
for ImageNet to CIFAR-10, and we include the results of both ResNet18 (the default model) and
WideResNet50. We can see that these data augmentations help with transferability to target domain,
although the robustness on the source domain decreases since these augmentations do not include
any robustness-related operations."
CONCLUSIONS,0.22854077253218885,"5
CONCLUSIONS"
CONCLUSIONS,0.2296137339055794,"In this work, we theoretically analyze the sufÔ¨Åcient conditions for domain transferability based on
the view of function class regularization. We also conduct experiments to verify our claims and
observe some counterexamples that shows a negative correlation between robustness and domain
transferability. These results are helpful in the domain generalization of machine learning models."
CONCLUSIONS,0.23068669527896996,Under review as a conference paper at ICLR 2022
ETHICS STATEMENT,0.2317596566523605,ETHICS STATEMENT
ETHICS STATEMENT,0.23283261802575106,"Our work focuses on theoretically and empirically studying the domain transferability of a machine
learning model. All the datasets and packages we use are open-sourced. We do not have ethical
concerns in our paper."
REPRODUCIBILITY STATEMENT,0.23390557939914164,REPRODUCIBILITY STATEMENT
REPRODUCIBILITY STATEMENT,0.2349785407725322,"We have tried our best to provide training details to facilitate reproducing our results. In Section 4.1
we provide detailed results on how to train the model and how to transfer the trained model to target
domain, as well as how we evaluate our model. We also upload the zip Ô¨Åle of our code with the
submission. We will open-source our code once accepted."
REFERENCES,0.23605150214592274,REFERENCES
REFERENCES,0.2371244635193133,"Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463‚Äì482, 2002."
REFERENCES,0.23819742489270387,"Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, et al. Analysis of representations
for domain adaptation. Advances in neural information processing systems, 19:137, 2007."
REFERENCES,0.23927038626609443,"Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In 2017
ieee symposium on security and privacy (sp), pp. 39‚Äì57. IEEE, 2017."
REFERENCES,0.24034334763948498,"Jianbo Chen, Michael I Jordan, and Martin J Wainwright. Hopskipjumpattack: A query-efÔ¨Åcient
decision-based attack. In 2020 ieee symposium on security and privacy (sp), pp. 1277‚Äì1294.
IEEE, 2020."
REFERENCES,0.24141630901287553,"Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. CertiÔ¨Åed adversarial robustness via randomized
smoothing. In International Conference on Machine Learning, pp. 1310‚Äì1320. PMLR, 2019."
REFERENCES,0.24248927038626608,"Nicolas Courty, R¬¥emi Flamary, Devis Tuia, and Alain Rakotomamonjy. Optimal transport for do-
main adaptation. IEEE transactions on pattern analysis and machine intelligence, 39(9):1853‚Äì
1865, 2016."
REFERENCES,0.24356223175965666,"Terrance DeVries and Graham W Taylor. Dataset augmentation in feature space. arXiv preprint
arXiv:1702.05538, 2017."
REFERENCES,0.2446351931330472,"Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Brandon Tran, and Alek-
sander Madry.
Adversarial robustness as a prior for learned representations.
arXiv preprint
arXiv:1906.00945, 2019."
REFERENCES,0.24570815450643776,"Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014."
REFERENCES,0.24678111587982832,"Alex Hern¬¥andez-Garc¬¥ƒ±a and Peter K¬®onig. Data augmentation instead of explicit regularization. arXiv
preprint arXiv:1806.03852, 2018a."
REFERENCES,0.2478540772532189,"Alex Hern¬¥andez-Garc¬¥ƒ±a and Peter K¬®onig. Further advantages of data augmentation on convolutional
neural networks. In International Conference on ArtiÔ¨Åcial Neural Networks, pp. 95‚Äì103. Springer,
2018b."
REFERENCES,0.24892703862660945,"Judy Hoffman, Daniel A Roberts, and Sho Yaida. Robust learning with jacobian regularization.
arXiv preprint arXiv:1908.02729, 2019."
REFERENCES,0.25,"Haoshuo Huang, Qixing Huang, and Philipp Krahenbuhl. Domain transfer through deep activation
matching. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 590‚Äì605,
2018."
REFERENCES,0.2510729613733906,"Lei Huang, Li Liu, Fan Zhu, Diwen Wan, Zehuan Yuan, Bo Li, and Ling Shao. Controllable orthog-
onalization in training dnns. In Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pp. 6429‚Äì6438, 2020."
REFERENCES,0.2521459227467811,Under review as a conference paper at ICLR 2022
REFERENCES,0.2532188841201717,"Andrew Ilyas, Shibani Santurkar, Logan Engstrom, Brandon Tran, and Aleksander Madry. Ad-
versarial examples are not bugs, they are features. Advances in neural information processing
systems, 32, 2019."
REFERENCES,0.2542918454935622,"Vladimir Koltchinskii. Rademacher penalties and structural risk minimization. IEEE Transactions
on Information Theory, 47(5):1902‚Äì1914, 2001."
REFERENCES,0.2553648068669528,"Clare Lyle, Marta Kwiatkowksa, and Yarin Gal. An analysis of the effect of invariance on gen-
eralization in neural networks. In International conference on machine learning Workshop on
Understanding and Improving Generalization in Deep Learning, volume 1, 2019."
REFERENCES,0.25643776824034337,"Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. In International Conference on
Learning Representations, 2018."
REFERENCES,0.2575107296137339,"Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a
regularization method for supervised and semi-supervised learning. IEEE transactions on pattern
analysis and machine intelligence, 41(8):1979‚Äì1993, 2018."
REFERENCES,0.25858369098712447,"Krikamol Muandet, David Balduzzi, and Bernhard Sch¬®olkopf. Domain generalization via invariant
feature representation. In International Conference on Machine Learning, pp. 10‚Äì18. PMLR,
2013."
REFERENCES,0.259656652360515,"Luis Perez and Jason Wang. The effectiveness of data augmentation in image classiÔ¨Åcation using
deep learning. arXiv preprint arXiv:1712.04621, 2017."
REFERENCES,0.2607296137339056,"Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. An online learning approach to interpo-
lation and extrapolation in domain generalization. arXiv preprint arXiv:2102.13128, 2021."
REFERENCES,0.26180257510729615,"Kevin Roth, Yannic Kilcher, and Thomas Hofmann. Adversarial training is a form of data-dependent
operator norm regularization. arXiv preprint arXiv:1906.01527, 2020."
REFERENCES,0.2628755364806867,"Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry. Do adver-
sarially robust imagenet models transfer better? arXiv preprint arXiv:2007.08489, 2020."
REFERENCES,0.26394849785407726,"Chun-Chen Tu, Paishun Ting, Pin-Yu Chen, Sijia Liu, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh, and
Shin-Ming Cheng. Autozoom: Autoencoder-based zeroth order optimization method for attack-
ing black-box neural networks. In Proceedings of the AAAI Conference on ArtiÔ¨Åcial Intelligence,
volume 33, pp. 742‚Äì749, 2019."
REFERENCES,0.26502145922746784,"Sebastien C Wong, Adam Gatt, Victor Stamatescu, and Mark D McDonnell. Understanding data
augmentation for classiÔ¨Åcation: when to warp? In 2016 international conference on digital image
computing: techniques and applications (DICTA), pp. 1‚Äì6. IEEE, 2016."
REFERENCES,0.26609442060085836,"Kaichao You, Ximei Wang, Mingsheng Long, and Michael Jordan. Towards accurate model selec-
tion in deep unsupervised domain adaptation. In International Conference on Machine Learning,
pp. 7124‚Äì7133. PMLR, 2019."
REFERENCES,0.26716738197424894,"Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan.
Theoretically principled trade-off between robustness and accuracy. In International Conference
on Machine Learning, pp. 7472‚Äì7482. PMLR, 2019a."
REFERENCES,0.26824034334763946,"Linjun Zhang, Zhun Deng, Kenji Kawaguchi, Amirata Ghorbani, and James Zou. How does mixup
help with robustness and generalization? arXiv preprint arXiv:2010.04819, 2020."
REFERENCES,0.26931330472103004,"Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan. Bridging theory and algorithm for
domain adaptation. In International Conference on Machine Learning, pp. 7404‚Äì7413. PMLR,
2019b."
REFERENCES,0.2703862660944206,"Han Zhao, Remi Tachet Des Combes, Kun Zhang, and Geoffrey Gordon. On learning invariant
representations for domain adaptation. In International Conference on Machine Learning, pp.
7523‚Äì7532. PMLR, 2019."
REFERENCES,0.27145922746781115,Under review as a conference paper at ICLR 2022
REFERENCES,0.27253218884120173,Appendix
REFERENCES,0.27360515021459225,"A
PROOFS"
REFERENCES,0.27467811158798283,"Proposition A.1 (Proposition 3.1 Restated). Given the problem deÔ¨Åned in subsection 3.1, f DS
c
is a
minimizer of equation 1. Moreover, if c ‚â•c‚Ä≤ ‚â•0, then the relative domain transfer loss ‚ÑìDT (f DS
c
)‚àí
‚ÑìDS(f DS
c
) ‚â•‚ÑìDT (f DS
c‚Ä≤ ) ‚àí‚ÑìDS(f DS
c‚Ä≤ )."
REFERENCES,0.2757510729613734,"Proof. Recall that ‚ÑìDS(f) = ‚à•f ‚àíyS‚à•D, ‚ÑìDT (f) = ‚à•f ‚àíyT ‚à•D and f DS
c
:= yS min{1,
c
‚à•yS‚à•D }.
First, let‚Äôs verify that"
REFERENCES,0.27682403433476394,"f DS
c
‚ààarg min
f‚ààF
‚ÑìDS(f),
s.t. ‚à•f‚à•D ‚â§c."
REFERENCES,0.2778969957081545,"If c ‚â•‚à•yS‚à•D, then f DS
c
:= yS achieves the minimum. If c < ‚à•yS‚à•D, then for any f ‚ààF : ‚à•f‚à•D ‚â§
c, we have"
REFERENCES,0.27896995708154504,‚ÑìDS(f) = ‚à•f ‚àíyS‚à•D ‚â•‚à•yS‚à•D ‚àí‚à•f‚à•D ‚â•‚à•yS‚à•D ‚àíc
REFERENCES,0.2800429184549356,"= ‚à•(1 ‚àí
c
‚à•yS‚à•D )yS‚à•D = ‚à•yS ‚àí
c
‚à•yS‚à•D yS‚à•D = ‚ÑìDS(f DS
c
)."
REFERENCES,0.2811158798283262,"Therefore, f DS
c
indeed achieves the minimum."
REFERENCES,0.2821888412017167,"Now, let‚Äôs prove the proposition. For any c ‚â•‚à•yS‚à•D, we have ‚ÑìDS(f DS
c
) = 0 and ‚ÑìDT (f DS
c
)
is a constant. Therefore, there is no difference for all c ‚â•‚à•yS‚à•D, and the proposition holds for
c ‚â•c‚Ä≤ ‚â•‚à•yS‚à•D. Then, We only need to verify the case for ‚à•yS‚à•‚â•c ‚â•c‚Ä≤:"
REFERENCES,0.2832618025751073,"‚ÑìDS(f DS
c‚Ä≤ ) ‚àí‚ÑìDS(f DS
c
) = c ‚àíc‚Ä≤ = ‚à•
c
‚à•yS‚à•D yS ‚àí
c‚Ä≤
‚à•yS‚à•D yS‚à•D"
REFERENCES,0.2843347639484979,"= ‚à•f DS
c‚Ä≤
‚àíf DS
c
‚à•D = ‚à•f DS
c‚Ä≤
‚àíyT + yT ‚àíf DS
c
‚à•D"
REFERENCES,0.2854077253218884,"‚â•|‚à•f DS
c‚Ä≤
‚àíyT ‚à•D ‚àí‚à•yT ‚àíf DS
c
‚à•D|"
REFERENCES,0.286480686695279,"‚â•‚à•f DS
c‚Ä≤
‚àíyT ‚à•D ‚àí‚à•yT ‚àíf DS
c
‚à•D"
REFERENCES,0.2875536480686695,"= ‚ÑìDT (f DS
c‚Ä≤ ) ‚àí‚ÑìDT (f DS
c
)."
REFERENCES,0.2886266094420601,Rearranging the above inequality gives the proposition.
REFERENCES,0.28969957081545067,"Proposition A.2 (Proposition 3.2 Restated). dG,F(¬∑, ¬∑) : PX√óY √óPX√óY ‚ÜíR+ satisÔ¨Åes the follow-
ing three properties."
REFERENCES,0.2907725321888412,"1. (Symmetry) dG,F(DS, DT ) = dG,F(DT , DS)."
REFERENCES,0.2918454935622318,"2. (Triangle Inequality) For ‚àÄD‚Ä≤ ‚ààPX√óY: dG,F(DS, DT ) ‚â§dG,F(DS, D‚Ä≤)+dG,F(D‚Ä≤, DT )."
REFERENCES,0.2929184549356223,"3. (Weak Zero Property) For ‚àÄD ‚ààPX√óY: dG,F(D, D) = 0."
REFERENCES,0.2939914163090129,Proof. Recall that
REFERENCES,0.29506437768240346,"dG,F(DS, DT ) := sup
f‚ààF
| inf
g‚ààG ‚ÑìDS(g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìDT (g ‚ó¶f)|."
REFERENCES,0.296137339055794,"We can see that the symmetry and weak zero property are obvious. For triangle inequality, given
‚àÄD‚Ä≤ ‚ààPX√óY:"
REFERENCES,0.29721030042918456,"dG,F(DS, DT ) = sup
f‚ààF
| inf
g‚ààG ‚ÑìDS(g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìDT (g ‚ó¶f)|"
REFERENCES,0.2982832618025751,"= sup
f‚ààF
| inf
g‚ààG ‚ÑìDS(g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìD‚Ä≤(g ‚ó¶f) + inf
g‚ààG ‚ÑìD‚Ä≤(g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìDT (g ‚ó¶f)|"
REFERENCES,0.29935622317596566,"‚â§sup
f‚ààF
(| inf
g‚ààG ‚ÑìDS(g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìD‚Ä≤(g ‚ó¶f)| + | inf
g‚ààG ‚ÑìD‚Ä≤(g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìDT (g ‚ó¶f)|)"
REFERENCES,0.30042918454935624,"‚â§sup
f‚ààF
| inf
g‚ààG ‚ÑìDS(g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìD‚Ä≤(g ‚ó¶f)| + sup
f‚ààF
| inf
g‚ààG ‚ÑìD‚Ä≤(g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìDT (g ‚ó¶f)|"
REFERENCES,0.30150214592274677,"= dG,F(DS, D‚Ä≤) + dG,F(D‚Ä≤, DT )."
REFERENCES,0.30257510729613735,Under review as a conference paper at ICLR 2022
REFERENCES,0.30364806866952787,Proposition A.3. Denote the function class
REFERENCES,0.30472103004291845,"LG,F := {hg,f : X √ó Y ‚ÜíR+ | g ‚ààG, f ‚ààF},
where hg,f(x, y) := ‚Ñì(g ‚ó¶f(x), y)."
REFERENCES,0.30579399141630903,"Let d : X √ó Y ‚ÜíR+ be a metric on X √ó Y, and assume ‚àÄh ‚ààLG,F is L-Lipschitz continuous with
respect to the metric d. Then, we have"
REFERENCES,0.30686695278969955,"dFA(DS, DT ) ‚â§L ¬∑ W(DS, DT ),"
REFERENCES,0.30793991416309013,"where W(DS, DT ) is the Wasserstein distance:"
REFERENCES,0.3090128755364807,"W(DS, DT ) =
sup
œÜ:X√óY‚ÜíR
E(x,y)‚àºDS[œÜ(x, y)] ‚àíE(x,y)‚àºDT [œÜ(x, y)]
s.t. œÜ is 1-Lipschitz."
REFERENCES,0.31008583690987124,Proof. Recall that
REFERENCES,0.3111587982832618,"dG,F(DS, DT ) := sup
f‚ààF
| inf
g‚ààG ‚ÑìDS(g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìDT (g ‚ó¶f)|."
REFERENCES,0.31223175965665234,"By the deÔ¨Ånition of inf, for ‚àÄœµ > 0 there exist gS,œµ, gT,œµ ‚ààG such that"
REFERENCES,0.3133047210300429,"inf
g‚ààG ‚ÑìDS(g ‚ó¶fœµ) ‚â•‚ÑìDS(gS,œµ ‚ó¶fœµ) ‚àíœµ"
REFERENCES,0.3143776824034335,"inf
g‚ààG ‚ÑìDT (g ‚ó¶fœµ) ‚â•‚ÑìDT (gT,œµ ‚ó¶fœµ) ‚àíœµ."
REFERENCES,0.315450643776824,"By the deÔ¨Ånition of sup, there exists fœµ ‚ààF such that"
REFERENCES,0.3165236051502146,"dG,F(DS, DT ) ‚â§| inf
g‚ààG ‚ÑìDS(g ‚ó¶fœµ) ‚àíinf
g‚ààG ‚ÑìDT (g ‚ó¶fœµ)| + œµ"
REFERENCES,0.31759656652360513,"= max{inf
g‚ààG ‚ÑìDS(g ‚ó¶fœµ) ‚àíinf
g‚ààG ‚ÑìDT (g ‚ó¶fœµ), inf
g‚ààG ‚ÑìDT (g ‚ó¶fœµ) ‚àíinf
g‚ààG ‚ÑìDS(g ‚ó¶fœµ)} + œµ"
REFERENCES,0.3186695278969957,"‚â§max{‚ÑìDS(gT,œµ ‚ó¶fœµ) ‚àíinf
g‚ààG ‚ÑìDT (g ‚ó¶fœµ), ‚ÑìDT (gS,œµ ‚ó¶fœµ) ‚àíinf
g‚ààG ‚ÑìDS(g ‚ó¶fœµ)} + œµ"
REFERENCES,0.3197424892703863,"‚â§max{‚ÑìDS(gT,œµ ‚ó¶fœµ) ‚àí‚ÑìDT (gT,œµ ‚ó¶fœµ), ‚ÑìDT (gS,œµ ‚ó¶fœµ) ‚àí‚ÑìDS(gS,œµ ‚ó¶fœµ)} + 2œµ.
(2)"
REFERENCES,0.3208154506437768,"Let‚Äôs Ô¨Årst consider the Ô¨Årst term in the max{¬∑, ¬∑} above."
REFERENCES,0.3218884120171674,"‚ÑìDS(gT,œµ ‚ó¶fœµ) ‚àí‚ÑìDT (gT,œµ ‚ó¶fœµ)"
REFERENCES,0.3229613733905579,= L ¬∑ ( 1
REFERENCES,0.3240343347639485,"L‚ÑìDS(gT,œµ ‚ó¶fœµ) ‚àí1"
REFERENCES,0.3251072961373391,"L‚ÑìDT (gT,œµ ‚ó¶fœµ))"
REFERENCES,0.3261802575107296,"= L ¬∑ (E(x,y)‚àºDS[ 1"
REFERENCES,0.3272532188841202,"L‚Ñì(gT,œµ ‚ó¶fœµ(x), y)] ‚àíE(x,y)‚àºDT [ 1"
REFERENCES,0.3283261802575107,"L‚Ñì(gT,œµ ‚ó¶fœµ(x), y)])"
REFERENCES,0.3293991416309013,"‚â§L ¬∑ W(DS, DT ),"
REFERENCES,0.33047210300429186,where the inequality is due to that both 1
REFERENCES,0.3315450643776824,"L‚Ñì(gS,œµ ‚ó¶fœµ(x), y) and 1"
REFERENCES,0.33261802575107297,"L‚Ñì(gT,œµ ‚ó¶fœµ(x), y) are 1-Lipschitz
w.r.t. (x, y) and the metric d."
REFERENCES,0.33369098712446355,"Similarly, we also have"
REFERENCES,0.33476394849785407,"‚ÑìDT (gS,œµ ‚ó¶fœµ) ‚àí‚ÑìDS(gS,œµ ‚ó¶fœµ) ‚â§L ¬∑ W(DS, DT )."
REFERENCES,0.33583690987124465,"Therefore, equation 2 implies"
REFERENCES,0.3369098712446352,"dG,F(DS, DT ) ‚â§L ¬∑ W(DS, DT ) + 2œµ."
REFERENCES,0.33798283261802575,Letting œµ ‚Üí0 completes the proof.
REFERENCES,0.33905579399141633,"Proposition A.4. Consider multi-class classiÔ¨Åcation where Y = [k] for some k ‚â•2. DeÔ¨Åne the
loss function ‚Ñìas"
REFERENCES,0.34012875536480686,"‚Ñì(g ‚ó¶f(x), y) = 1{arg max
j‚àà[k](g ‚ó¶f(x))j Ã∏= y}"
REFERENCES,0.34120171673819744,"Let Œ¥T V (DS, DT ) denote the total variation distance. Then we have"
REFERENCES,0.34227467811158796,"dFA(DS, DT ) ‚â§Œ¥T V (DS, DT )"
REFERENCES,0.34334763948497854,Under review as a conference paper at ICLR 2022
REFERENCES,0.3444206008583691,"Proof. Fix f ‚ààF. By the deÔ¨Ånition of inf, there exists gT,œµ such that"
REFERENCES,0.34549356223175964,"| inf
g‚ààG ‚ÑìDS(g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìDT (g ‚ó¶f)|"
REFERENCES,0.3465665236051502,"‚â§| inf
g‚ààG ‚ÑìDS(g ‚ó¶f) ‚àí‚ÑìDT (gT,œµ ‚ó¶f)| + œµ"
REFERENCES,0.34763948497854075,"‚â§|‚ÑìDS(gT,œµ ‚ó¶f) ‚àí‚ÑìDT (gT,œµ ‚ó¶f)| + œµ
= |E(x,y)‚àºDS[‚Ñì(gT,œµ ‚ó¶f(x), y)] ‚àíE(x,y)‚àºDT [‚Ñì(gT,œµ ‚ó¶f(x), y)]| + œµ"
REFERENCES,0.3487124463519313,"= |P(x,y)‚àºDS[1{arg max
j‚àà[k](gT,œµ ‚ó¶f(x))j Ã∏= y}] ‚àíP(x,y)‚àºDT [1{arg max
j‚àà[k](gT,œµ ‚ó¶f(x))j Ã∏= y}]| + œµ (3)"
REFERENCES,0.3497854077253219,"Let A be the event such that A = {(x, y) : arg maxj‚àà[k](gT,œµ ‚ó¶f(x))j Ã∏= y}. Then we can write
equation 3 as"
REFERENCES,0.35085836909871243,"(3) = |P(x,y)‚àºDS[A] ‚àíP(x,y)‚àºDT [A]| + œµ"
REFERENCES,0.351931330472103,"‚â§sup
B
|P(x,y)‚àºDS[B] ‚àíP(x,y)‚àºDT [B]| + œµ"
REFERENCES,0.3530042918454936,"= Œ¥T V (DS, DT ) + œµ"
REFERENCES,0.3540772532188841,"Send œµ ‚Üí0. Noting that f ‚ààF was arbitrary, apply sup to both sides gives us the desired inequality."
REFERENCES,0.3551502145922747,"Theorem 3.1 can be proved easily by deÔ¨Ånition.
Theorem A.1 (Theorem 3.1 Restated). Given a training algorithm A, for ‚àÄDS, DT ‚ààPX√óY we
have"
REFERENCES,0.3562231759656652,"œÑ(A; DS, DT ) ‚â§dFA(DS, DT ),"
REFERENCES,0.3572961373390558,"or equivalently,
inf
g‚ààG ‚ÑìDT (g ‚ó¶f DS
A ) ‚â§‚ÑìDS(gDS
A
‚ó¶f DS
A ) + dFA(DS, DT )."
REFERENCES,0.3583690987124464,"Proof. By deÔ¨Ånition,"
REFERENCES,0.3594420600858369,"œÑ(A; DS, DT ) = inf
g‚ààG ‚ÑìDT (g ‚ó¶f DS
A ) ‚àí‚ÑìDS(gDS
A
‚ó¶f DS
A )"
REFERENCES,0.3605150214592275,"‚â§inf
g‚ààG ‚ÑìDT (g ‚ó¶f DS
A ) ‚àíinf
g‚ààG ‚ÑìDS(g ‚ó¶f DS
A )"
REFERENCES,0.361587982832618,"‚â§| inf
g‚ààG ‚ÑìDT (g ‚ó¶f DS
A ) ‚àíinf
g‚ààG ‚ÑìDS(g ‚ó¶f DS
A )|"
REFERENCES,0.3626609442060086,"‚â§sup
f‚ààFA
| inf
g‚ààG ‚ÑìDT (g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìDS(g ‚ó¶f)|"
REFERENCES,0.36373390557939916,"= dFA(DS, DT )."
REFERENCES,0.3648068669527897,"To prove Theorem 3.2, we Ô¨Årst prove the following interesting lemma.
Lemma A.1. Let Sd‚àí1
r
:= {y ‚ààRd | ‚à•y‚à•2 = r} denotes the (d‚àí1)-dimensional sphere in Rd with
radius r > 0. If a function h : Sd‚àí1
r
‚ÜíRd satisÔ¨Åes"
REFERENCES,0.36587982832618027,"‚àÄy ‚ààSd‚àí1
r
:
‚ü®h(y), y‚ü©< 0,
(4)"
REFERENCES,0.3669527896995708,"then we have
‚Éó0 ‚ààconv(h(Sd‚àí1
r
)),"
REFERENCES,0.36802575107296137,"i.e., ‚Éó0 is in the convex hull of {h(y) | y ‚ààSd‚àí1
r
}."
REFERENCES,0.36909871244635195,"Proof. We assume that ‚Éó0 /‚ààconv(h(Sd‚àí1
r
)) and prove by contradiction. Since ‚Éó0 /‚ààconv(h(Sd‚àí1
r
)),
we can Ô¨Ånd a hyperplane that separates ‚Éó0 and the convex set conv(h(Sd‚àí1
r
)). By the separating
hyperplane theorem there exists a nonzero vector v ‚ààRd and c ‚â•0 such that"
REFERENCES,0.3701716738197425,"‚àÄz ‚ààconv(h(Sd‚àí1
r
)) :
‚ü®z, v‚ü©‚â•c ‚â•0.
(5)"
REFERENCES,0.37124463519313305,Under review as a conference paper at ICLR 2022
REFERENCES,0.3723175965665236,"We choose y = rv/‚à•v‚à•2 and observe that h(y) ‚ààconv(h(Sd‚àí1
r
)). Hence, by equation 5 we have"
REFERENCES,0.37339055793991416,"‚ü®h(y), y‚ü©‚â•0,"
REFERENCES,0.37446351931330474,"which contradicts to the condition of equation 4. Therefore, it must be that ‚Éó0 ‚ààconv(h(Sd‚àí1
r
))."
REFERENCES,0.37553648068669526,"Theorem A.2 (Theorem 3.2 Restated). Given any source distribution DS ‚ààPX√óRd, any Ô¨Åne-tuning
function class G where G includes the zero function, and any training algorithm A, denote"
REFERENCES,0.37660944206008584,"œµ := ‚ÑìDS(gDS
A
‚ó¶f DS
A ) ‚àí
inf
g‚ààG,f‚ààFA ‚ÑìDS(g ‚ó¶f)."
REFERENCES,0.3776824034334764,"We assume some properties of the sample individual loss function ‚Ñì: Rd √ó Rd ‚ÜíR+: it is
differentiable and strictly convex w.r.t.
its Ô¨Årst argument; ‚Ñì(y, y) = 0 for any y ‚ààRd; and
limr‚Üí‚àûinfy:‚à•y‚à•2=r ‚Ñì(‚Éó0, y) = ‚àû. Then, for any distribution DX on X, there exist some distri-
butions DT ‚ààPX√óY with its marginal on X being DX such that"
REFERENCES,0.37875536480686695,"œÑ(A; DS, DT ) ‚â§dFA(DS, DT ) ‚â§œÑ(A; DS, DT ) + œµ."
REFERENCES,0.3798283261802575,"Proof. The œÑ(A; DS, DT ) ‚â§dFA(DS, DT ) is proved by Theorem 3.1, we only need to prove that
there exists some DT ‚ààPX√óY with its marginal on X being DX such that"
REFERENCES,0.38090128755364805,"dFA(DS, DT ) ‚â§œÑ(A; DS, DT ) + œµ = inf
g‚ààG ‚ÑìDT (g ‚ó¶f DS
A ) ‚àí
inf
g‚ààG,f‚ààFA ‚ÑìDS(g ‚ó¶f)."
REFERENCES,0.38197424892703863,"We begin by observing that limr‚Üí‚àûinfy:‚à•y‚à•2=r ‚Ñì(‚Éó0, y) = ‚àû, and thus there exists r > 0 such that"
REFERENCES,0.3830472103004292,"‚àÄy ‚ààSd‚àí1
r
:
‚Ñì(‚Éó0, y) ‚â•‚ÑìDS(‚Éó0) = E(x,y)‚àºDS[‚Ñì(‚Éó0, y)],
(6)"
REFERENCES,0.38412017167381973,"where Sd‚àí1
r
:= {y ‚ààRd | ‚à•y‚à•2 = r} denotes the (d ‚àí1)-dimensional sphere with radius r. Note
the we abuse the notion a bit to let ‚Éó0 also denotes the zero function (i.e., maps all input to zero).
Now, let us deÔ¨Åne at the following set"
REFERENCES,0.3851931330472103,"V := {‚àá1‚Ñì(‚Éó0, y) | y ‚ààSd‚àí1
r
},"
REFERENCES,0.38626609442060084,"where ‚àá1 is taking the gradient w.r.t. the Ô¨Årst argument of ‚Ñì(¬∑, ¬∑). By the strict convexity of ‚Ñì(¬∑, y),
we have"
REFERENCES,0.3873390557939914,"‚Ñì(y, y) ‚àí‚Ñì(‚Éó0, y) > ‚ü®‚àá1‚Ñì(‚Éó0, y), y‚ü©."
REFERENCES,0.388412017167382,"Noting that ‚Ñì(y, y) = 0 is the unique minimum of ‚Ñì(¬∑, y), we have ‚Ñì(‚Éó0, y) > 0. Accordingly,"
REFERENCES,0.3894849785407725,"‚àÄy ‚ààSd‚àí1
r
:
0 > ‚àí‚Ñì(‚Éó0, y) > ‚ü®‚àá1‚Ñì(‚Éó0, y), y‚ü©."
REFERENCES,0.3905579399141631,"Having the above property, and noting that ‚àá1‚Ñì(‚Éó0, ¬∑) : Sd‚àí1
r
‚ÜíRd, we can invoke Lemma A.1 to
see that"
REFERENCES,0.3916309012875536,‚Éó0 ‚ààconv(V).
REFERENCES,0.3927038626609442,"Therefore, there exists n points {yi}n
i=1 ‚äÇSd‚àí1
r
such that ‚Éó0 = n
X"
REFERENCES,0.3937768240343348,"i=1
ci‚àá1‚Ñì(‚Éó0, yi),
(7)"
REFERENCES,0.3948497854077253,"where ci > 0 and Pn
i=1 ci = 1."
REFERENCES,0.3959227467811159,"Therefore, we can deÔ¨Åne the target distribution DT as the following. Given any x ‚àºDX , the
distribution of y conditioned on x is: y = yi with probability ci. Now we verify the distribution DT
indeed makes the bound œµ-tight. Denote a strictly convex function h : Rd ‚ÜíR+ as the following"
REFERENCES,0.3969957081545064,"h(¬∑) := n
X"
REFERENCES,0.398068669527897,"i=1
ci‚Ñì(¬∑, yi)."
REFERENCES,0.39914163090128757,Under review as a conference paper at ICLR 2022
REFERENCES,0.4002145922746781,"Since h is strictly convex and ‚àáh(‚Éó0) = ‚Éó0 (equation 7), we can see that h(‚Éó0) achieves the unique
global minimum of h on Rd."
REFERENCES,0.4012875536480687,"Therefore, given the DT , for any ‚àÄf ‚ààFA we have
inf
g‚ààG ‚ÑìDT (g ‚ó¶f) = inf
g‚ààG E(x,y)‚àºDT [‚Ñì(g ‚ó¶f(x), y)]"
REFERENCES,0.40236051502145925,"= inf
g‚ààG Ex‚àºDX "" n
X"
REFERENCES,0.4034334763948498,"i=1
ci‚Ñì(g ‚ó¶f(x), yi) #"
REFERENCES,0.40450643776824036,"= inf
g‚ààG Ex‚àºDX [h(g ‚ó¶f(x))]"
REFERENCES,0.4055793991416309,"= h(‚Éó0)
(G contains the zero function) = n
X"
REFERENCES,0.40665236051502146,"i=1
ci‚Ñì(‚Éó0, yi).
(8)"
REFERENCES,0.40772532188841204,"Recall that dFA(DS, DT ) = supf‚ààFA | infg‚ààG ‚ÑìDT (g ‚ó¶f) ‚àíinfg‚ààG ‚ÑìDS(g ‚ó¶f)|, we can see that"
REFERENCES,0.40879828326180256,"dFA(DS, DT ) = sup
f‚ààFA
| n
X"
REFERENCES,0.40987124463519314,"i=1
ci‚Ñì(‚Éó0, yi) ‚àíinf
g‚ààG ‚ÑìDS(g ‚ó¶f)|
(9)"
REFERENCES,0.41094420600858367,"By equation 6, for ‚àÄf ‚ààFA, we have
n
X"
REFERENCES,0.41201716738197425,"i=1
ci‚Ñì(‚Éó0, yi) ‚â•‚ÑìDS(‚Éó0) = ‚ÑìDS(‚Éó0 ‚ó¶f) ‚â•inf
g‚ààG ‚ÑìDS(g ‚ó¶f)."
REFERENCES,0.4130901287553648,"Hence, we can continue as"
REFERENCES,0.41416309012875535,"(9) = sup
f‚ààFA n
X"
REFERENCES,0.41523605150214593,"i=1
ci‚Ñì(‚Éó0, yi) ‚àíinf
g‚ààG ‚ÑìDS(g ‚ó¶f) ! = n
X"
REFERENCES,0.41630901287553645,"i=1
ci‚Ñì(‚Éó0, yi) ‚àí
inf
g‚ààG,f‚ààFA ‚ÑìDS(g ‚ó¶f)"
REFERENCES,0.41738197424892703,"= inf
g‚ààG ‚ÑìDT (g ‚ó¶f DS
A ) ‚àí
inf
g‚ààG,f‚ààFA ‚ÑìDS(g ‚ó¶f)
(by equation 8)"
REFERENCES,0.4184549356223176,"= inf
g‚ààG ‚ÑìDT (g ‚ó¶f DS
A ) ‚àí‚ÑìDS(gDS
A
‚ó¶f DS
A ) + ‚ÑìDS(gDS
A
‚ó¶f DS
A ) ‚àí
inf
g‚ààG,f‚ààFA ‚ÑìDS(g ‚ó¶f)"
REFERENCES,0.41952789699570814,"= œÑ(A; DS, DT ) + œµ.
Therefore, it holds that dFA(DS, DT ) ‚â§œÑ(A; DS, DT ) + œµ, and thus the theorem."
REFERENCES,0.4206008583690987,"Lemma A.2 (Lemma 3.1 Restated). Assuming the individual loss function ‚Ñì: Y √óY ‚Üí[0, c], given
any distribution D ‚ààPX√óY and ‚àÄŒ¥ > 0, with probability ‚â•1 ‚àíŒ¥ we have"
REFERENCES,0.4216738197424893,"dG,F(D, bDn) ‚â§2Rad b
Dn(LG,F) + 3c r"
REFERENCES,0.4227467811158798,ln(4/Œ¥)
N,0.4238197424892704,"2n
."
N,0.4248927038626609,"Proof. Given any Œ¥ > 0, f ‚ààF, g ‚ààG, D ‚ààPX√óY, and taking any hg,f ‚ààLG,F (DeÔ¨Ånition 3),
with probability ‚â•1 ‚àíŒ¥ we have"
N,0.4259656652360515,"‚ÑìD(g ‚ó¶f) ‚àí‚Ñìb
Dn(g ‚ó¶f) = E(x,y)‚àºD[hg,f(x, y)] ‚àí1 n n
X"
N,0.4270386266094421,"i=1
hg,f(xi, yi)"
N,0.4281115879828326,"‚â§2Rad b
Dn(LG,F) + 3c r"
N,0.4291845493562232,ln(2/Œ¥)
N,0.4302575107296137,"2n
,
(10)"
N,0.4313304721030043,"where the inequality is by the well-known Rademacher complexity uniform bound. Similarly,"
N,0.43240343347639487,"‚Ñìb
Dn(g ‚ó¶f) ‚àí‚ÑìD(g ‚ó¶f) = E(x,y)‚àºD[‚àíhg,f(x, y)] ‚àí1 n n
X"
N,0.4334763948497854,"i=1
‚àíhg,f(xi, yi)"
N,0.434549356223176,"‚â§2Rad b
Dn(‚àíLG,F) + 3c r"
N,0.4356223175965665,ln(2/Œ¥)
N,0.4366952789699571,2n
N,0.43776824034334766,"= 2Rad b
Dn(LG,F) + 3c r"
N,0.4388412017167382,ln(2/Œ¥)
N,0.43991416309012876,"2n
.
(11)"
N,0.4409871244635193,Under review as a conference paper at ICLR 2022
N,0.44206008583690987,"The probability that both events equation 10 and equation 11 happen can be upper bounded by union
bound, i.e.,"
N,0.44313304721030045,Pr((10) ‚àß(11)) = 1 ‚àíPr((10)c ‚à®(11)c) ‚â•1 ‚àí(Pr((10)c) + Pr((11)c)) ‚â•1 ‚àí2Œ¥.
N,0.44420600858369097,"Therefore, combining the above with probability ‚â•1 ‚àíŒ¥ we have"
N,0.44527896995708155,"|‚ÑìD(g ‚ó¶f) ‚àí‚Ñìb
Dn(g ‚ó¶f)| ‚â§2Rad b
Dn(LG,F) + 3c r"
N,0.44635193133047213,ln(4/Œ¥)
N,0.44742489270386265,"2n
.
(12)"
N,0.44849785407725323,"With equation 12, we can prove the lemma as the following. Given ‚àÄœµ > 0, by the deÔ¨Ånition of
inÔ¨Åmum there exists a gœµ ‚ààG such that"
N,0.44957081545064376,"‚ÑìD(gœµ ‚ó¶f) < inf
g‚ààG ‚ÑìD(g ‚ó¶f) + œµ."
N,0.45064377682403434,"By equation 12, with probability ‚â•1 ‚àíŒ¥ we have"
N,0.4517167381974249,"‚Ñìb
Dn(gœµ ‚ó¶f) ‚â§‚ÑìD(gœµ ‚ó¶f) + 2Rad b
Dn(LG,F) + 3c r"
N,0.45278969957081544,ln(4/Œ¥)
N,0.453862660944206,"2n
."
N,0.45493562231759654,"Moreover, by deÔ¨Ånition"
N,0.4560085836909871,"inf
g‚ààG ‚Ñìb
Dn(g ‚ó¶f) ‚â§‚Ñìb
Dn(gœµ ‚ó¶f)."
N,0.4570815450643777,Combining the above three inequalities we have
N,0.4581545064377682,"inf
g‚ààG ‚Ñìb
Dn(g ‚ó¶f) < inf
g‚ààG ‚ÑìD(g ‚ó¶f) + œµ + 2Rad b
Dn(LG,F) + 3c r"
N,0.4592274678111588,ln(4/Œ¥)
N,0.46030042918454933,"2n
."
N,0.4613733905579399,"Letting œµ ‚Üí0, we can see that"
N,0.4624463519313305,"inf
g‚ààG ‚Ñìb
Dn(g ‚ó¶f) ‚â§inf
g‚ààG ‚ÑìD(g ‚ó¶f) + 2Rad b
Dn(LG,F) + 3c r"
N,0.463519313304721,ln(4/Œ¥)
N,0.4645922746781116,"2n
."
N,0.4656652360515021,"Similarly, we can derive the above inequality again but with D and bDn switched. Therefore,"
N,0.4667381974248927,"| inf
g‚ààG ‚Ñìb
Dn(g ‚ó¶f) ‚àíinf
g‚ààG ‚ÑìD(g ‚ó¶f)| ‚â§2Rad b
Dn(LG,F) + 3c r"
N,0.4678111587982833,ln(4/Œ¥)
N,0.4688841201716738,"2n
."
N,0.4699570815450644,"Since the above inequality holds for ‚àÄf ‚ààF, taking the supremum over f ‚ààF gives the lemma."
N,0.47103004291845496,"Lemma A.3. Assuming the individual loss function ‚Ñì: Y √ó Y ‚Üí[0, c], given any distributions
DS, DT ‚ààPX√óY and ‚àÄŒ¥ > 0, with probability ‚â•1 ‚àíŒ¥ we have"
N,0.4721030042918455,"dFA(DS, DT ) ‚â§dFA( bDn
S, bDn
T ) + 2(Rad b
Dn
S(LG,FA) + Rad b
Dn
T (LG,FA)) + 6c r"
N,0.47317596566523606,ln(8/Œ¥)
N,0.4742489270386266,"2n
."
N,0.47532188841201717,"Proof. By Proposition 3.2, we apply the triangle inequality to derive"
N,0.47639484978540775,"dFA(DS, DT ) ‚â§dFA(DS, bDn
T ) + dFA( bDn
T , DT )"
N,0.47746781115879827,"‚â§dFA( bDn
S, bDn
T ) + dFA( bDn
T , DT ) + dFA( bDn
S, DS)."
N,0.47854077253218885,"By Lemma 3.1, we can apply the union bound argument (e.g., see the proof of Lemma 3.1) to bound
dFA( bDn
T , DT ) and dFA( bDn
S, DS). That being said, ‚àÄŒ¥‚Ä≤ > 0 with probability ‚â•1 ‚àí2Œ¥‚Ä≤ we have"
N,0.4796137339055794,"dFA( bDn
S, DS) ‚â§2Rad b
Dn
S(LG,FA) + 3c r"
N,0.48068669527896996,ln(4/Œ¥‚Ä≤)
N,0.48175965665236054,2n
N,0.48283261802575106,"dFA( bDn
T , DT ) ‚â§2Rad b
Dn
T (LG,FA) + 3c r"
N,0.48390557939914164,ln(4/Œ¥‚Ä≤)
N,0.48497854077253216,"2n
."
N,0.48605150214592274,"Therefore,"
N,0.4871244635193133,"dFA( bDn
T , DT ) + dFA( bDn
S, DS) ‚â§2(Rad b
Dn
S(LG,FA) + Rad b
Dn
T (LG,FA)) + 6c r"
N,0.48819742489270385,ln(4/Œ¥‚Ä≤)
N,0.4892703862660944,"2n
."
N,0.490343347639485,Denoting Œ¥ = 2Œ¥‚Ä≤ gives the lemma.
N,0.49141630901287553,Under review as a conference paper at ICLR 2022
N,0.4924892703862661,"Theorem A.3 (Theorem 3.3 Restated). Given ‚àÄDS, DT ‚ààPX√óY, for ‚àÄŒ¥ > 0 with probability
‚â•1 ‚àíŒ¥ we have"
N,0.49356223175965663,"œÑ(A; bDn
S, DT ) ‚â§dFA( bDn
S, bDn
T ) + 2Rad b
Dn
T (LG,FA) + 4Rad b
Dn
S(LG,FA) + 9c r"
N,0.4946351931330472,ln(8/Œ¥)
N,0.4957081545064378,"2n
."
N,0.4967811158798283,"Proof. For ‚àÄŒ¥ > 0, from the proof of Lemma A.3 we can see that with probability ‚â•1 ‚àíŒ¥:"
N,0.4978540772532189,"dFA( bDn
S, DS) ‚â§2Rad b
Dn
S(LG,FA) + 3c r"
N,0.4989270386266094,ln(8/Œ¥)
N,0.5,"2n
(13)"
N,0.5010729613733905,"dFA( bDn
T , DT ) ‚â§2Rad b
Dn
T (LG,FA) + 3c r"
N,0.5021459227467812,ln(8/Œ¥)
N,0.5032188841201717,"2n
,"
N,0.5042918454935622,and Lemma A.3 holds. Therefore
N,0.5053648068669528,"œÑ(A; bDn
S, DT ) = inf
g‚ààG ‚ÑìDT (g ‚ó¶f
b
Dn
S
A ) ‚àí‚Ñìb
Dn
S(g
b
Dn
S
A
‚ó¶f
b
Dn
S
A )"
N,0.5064377682403434,"‚â§inf
g‚ààG ‚ÑìDT (g ‚ó¶f
b
Dn
S
A ) ‚àíinf
g‚ààG ‚Ñìb
Dn
S(g ‚ó¶f
b
Dn
S
A )"
N,0.5075107296137339,"= inf
g‚ààG ‚ÑìDT (g ‚ó¶f
b
Dn
S
A ) ‚àíinf
g‚ààG ‚ÑìDS(g ‚ó¶f
b
Dn
S
A ) + inf
g‚ààG ‚ÑìDS(g ‚ó¶f
b
Dn
S
A ) ‚àíinf
g‚ààG ‚Ñìb
Dn
S(g ‚ó¶f
b
Dn
S
A )"
N,0.5085836909871244,"‚â§dFA(DS, DT ) + dFA( bDn
S, DS)"
N,0.509656652360515,"‚â§dFA(DS, DT ) + 2Rad b
Dn
S(LG,FA) + 3c r"
N,0.5107296137339056,ln(8/Œ¥)
N,0.5118025751072961,2n
N,0.5128755364806867,"‚â§dFA( bDn
S, bDn
T ) + 2Rad b
Dn
T (LG,FA) + 4Rad b
Dn
S(LG,FA) + 9c r"
N,0.5139484978540773,ln(8/Œ¥)
N,0.5150214592274678,"2n
,"
N,0.5160944206008584,"where the Ô¨Årst inequality is by deÔ¨Ånition of inÔ¨Åmum, the second inequality is by the DeÔ¨Ånition 2,
the third inequality is by equation 13 and the last inequality is by Lemma A.3."
N,0.5171673819742489,"B
DATA AUGMENTATION (DA) AS REGULARIZATION"
N,0.5182403433476395,"In this section, we discuss data augmentation (DA) as a concrete example of regularization for train-
ing feature extractor f DS
A , and explore its impact on the function class FA discussed in Section 3."
N,0.51931330472103,"Empirical research has shown evidence of the regularization effect of DA (Hern¬¥andez-Garc¬¥ƒ±a &
K¬®onig, 2018a;b). However, there is a lack of theoretical analysis, and thus we aim to construct a
theoretical framework to understand under what sufÔ¨Åcient conditions DA can be viewed as regu-
larization on the feature extractor function class FA. We categorize DA into feature-level DA and
data-level DA, and for each category, we analyze different DA algorithms to characterize the suf-
Ô¨Åcient conditions under which DA regularizes the function class FA. Combined with analysis in
Theorem 3.3, we also provide concrete sufÔ¨Åcient conditions to tighten the upper bound of relative
transferability œÑ(A; bDn, DT )."
N,0.5203862660944206,"General Settings. For the following discussion we apply a general DA setting of afÔ¨Åne transfor-
mation (Perez & Wang, 2017), taking the form of x‚ãÜ= W ‚ä§
‚ãÜx + b‚ãÜ, where (x, x‚ãÜ) is a pair of the
original and augmented samples, (W‚ãÜ, b‚ãÜ) are parameters representing speciÔ¨Åc DA policies. We set
g : Rd ‚ÜíR as the linear layer corresponding to the weight matrix Wg, which will be composed with
the feature extractor f : Rm ‚ÜíRd. We use squared loss for ‚Ñì: R √ó R ‚ÜíR, and let ‚Ñìb
Dn,A(g ‚ó¶f)
be the objective function given by training algorithm A from Theorem 3.3."
N,0.5214592274678111,"B.1
FEATURE-LEVEL DA (AF L)"
N,0.5225321888412017,"Feature-level DA (Wong et al., 2016; DeVries & Taylor, 2017) requires the transformation to be
performed in the learned feature space, which gives us an augmented feature W‚ãÜf(x) + b‚ãÜ. We
use Loss-Averaging algorithm where we take an average of the loss over augmented features for"
N,0.5236051502145923,Under review as a conference paper at ICLR 2022
N,0.5246781115879828,"training. Denote the training algorithm based on feature-level DA as AF L, the objective function is
as below."
N,0.5257510729613734,"‚Ñìb
Dn,AF L(g ‚ó¶f) = 1 n n
X"
N,0.526824034334764,"i=1
EW‚ãÜ,b‚ãÜ‚Ñì

g ‚ó¶
 
W‚ãÜf(xi) + b‚ãÜ

, yi

."
N,0.5278969957081545,"Theorem B.1. Apply feature-level DA with afÔ¨Åne transformation parameters (W‚ãÜ, b‚ãÜ) s.t.
1)
EW‚ãÜ[W‚ãÜ] = Im; 2) W‚ãÜÃ∏‚â°Im (i.e., W‚ãÜis not an identity matrix); 3) Eb‚ãÜ[b‚ãÜ] = ‚Éó0m; 4) W‚ãÜand
b‚ãÜare independent. Set ‚Ñì: R √ó R ‚ÜíR as squared loss; DeÔ¨Åne ‚àÜW‚ãÜ:= W‚ãÜ‚àíIm, then we have"
N,0.528969957081545,"‚Ñìb
Dn,AF L(g ‚ó¶f) = ‚Ñìb
Dn,A(g ‚ó¶f) + ‚Ñ¶AF L,"
N,0.5300429184549357,where ‚Ñ¶AF L = 1
N,0.5311158798283262,"n
Pn
i=1 EW‚ãÜ
hf(xi)‚ä§‚àÜW‚ãÜWg
2
2"
N,0.5321888412017167,"i
+ Eb‚ãÜ
hb‚ä§
‚ãÜWg
2
2 i
."
N,0.5332618025751072,"Proof. ‚Ñì‚Ä≤‚Ä≤(W ‚ä§
g ‚ó¶f(xi)) = 2 for ‚Ñìas squared loss. Apply Taylor expansion to ‚Ñì

g ‚ó¶
 
W‚ãÜf(xi) +"
N,0.5343347639484979,"b‚ãÜ

, yi

around f(xi), all higher-than-two order terms will vanish:"
N,0.5354077253218884,"EW‚ãÜ,b‚ãÜ"
N,0.5364806866952789,"
‚Ñì

g ‚ó¶
 
W‚ãÜf(xi) + b‚ãÜ

, yi
"
N,0.5375536480686696,"=EW‚ãÜ,b‚ãÜ"
N,0.5386266094420601,"
‚Ñì

W ‚ä§
g ‚ó¶f(xi), yi

+ W ‚ä§
g (‚àÜW‚ãÜf(xi) + b‚ãÜ)‚Ñì‚Ä≤(W ‚ä§
g ‚ó¶f(xi), yi)+"
N,0.5396995708154506,"1
2W ‚ä§
g (‚àÜW‚ãÜf(xi) + b‚ãÜ)(‚àÜW‚ãÜf(xi) + b‚ãÜ)‚ä§‚Ñì‚Ä≤‚Ä≤(W ‚ä§
g ‚ó¶f(xi), yi)Wg "
N,0.5407725321888412,"=‚Ñì

W ‚ä§
g ‚ó¶f(xi), yi

+ EW‚ãÜ,b‚ãÜ
h
W ‚ä§
g (‚àÜW‚ãÜf(xi) + b‚ãÜ)(‚àÜW‚ãÜf(xi) + b‚ãÜ)‚ä§Wg
i"
N,0.5418454935622318,"=‚Ñì

W ‚ä§
g ‚ó¶f(xi), yi

+ EW‚ãÜ
hf(xi)‚ä§‚àÜW‚ãÜWg
2
2"
N,0.5429184549356223,"i
+ Eb‚ãÜ
hb‚ä§
‚ãÜWg
2
2 i
;"
N,0.5439914163090128,"The second equality holds since E‚àÜW‚ãÜ= EW‚ãÜ[W‚ãÜ‚àíIm] = 0(m,m) and Eb‚ãÜ= ‚Éó0m; The third"
N,0.5450643776824035,"equality holds since Wi and bi are independent. Therefore, ‚Ñìb
Dn,AF L(g‚ó¶f) := 1"
N,0.546137339055794,"n
Pn
i=1"
N,0.5472103004291845,"
EW‚ãÜ,b‚ãÜ‚Ñì

g‚ó¶"
N,0.5482832618025751," 
W‚ãÜf(xi) + b‚ãÜ

, yi

= ‚Ñìb
Dn,A(g ‚ó¶f) + ‚Ñ¶AF L."
N,0.5493562231759657,"Interpretation. ‚Ñ¶AF L is composed of two segments: 1) l2 regularization to an f-dependent scalar
averaged over W‚ãÜand xi; 2) l2 regularization to an f-independent scalar averaged over b‚ãÜ. Due to
the regularization effect on f from the Ô¨Årst segment of ‚Ñ¶AF L, we can reasonably expect the function
class FA‚Ä≤ enabled by AF L to be a subset of that enabled by a general training algorithm A."
N,0.5504291845493562,"SufÔ¨Åcient conditions. Combined with Theorem 3.3, the sufÔ¨Åcient conditions to tighten the upper
bound dFA( bDn
S, bDn
T ) for the relative transferability œÑ(A; bDS, DT ) are: feature-level DA (AF L) with
parameters satisfying: 1) EW‚ãÜ[W‚ãÜ] = Im; 2) W‚ãÜÃ∏‚â°Im; 3) Eb‚ãÜ[b‚ãÜ] = ‚Éó0m; 4) W‚ãÜand b‚ãÜare
independent."
N,0.5515021459227468,"B.2
DATA-LEVEL DA (ADL)"
N,0.5525751072961373,"Data-level DA requires that the transformation to be performed in the input space to generate aug-
mented samples W‚ãÜx + b‚ãÜ. We cover analysis on two ubiquitous algorithms for data-level DA
training: Prediction-Averaging (ADL
P ) (Lyle et al., 2019) and Loss-Averaging (ADL
L ) (Wong et al.,
2016). The difference between ADL
P
and ADL
L
lies in whether we take the average of the prediction
or the losses:"
N,0.5536480686695279,"‚Ñìb
Dn,ADL
P (g ‚ó¶f) := 1 n n
X"
N,0.5547210300429185,"i=1
‚Ñì
 
EW‚ãÜ,b‚ãÜ

g ‚ó¶f(W‚ãÜxi + b‚ãÜ)

, yi

;
(14)"
N,0.555793991416309,"‚Ñìb
Dn,ADL
L (g ‚ó¶f) := 1 n n
X"
N,0.5568669527896996,"i=1
EW‚ãÜ,b‚ãÜ

‚Ñì
 
g ‚ó¶f(W‚ãÜxi + b‚ãÜ), yi

."
N,0.5579399141630901,Under review as a conference paper at ICLR 2022
N,0.5590128755364807,"Theorem B.2. DeÔ¨Åne the data-level deviation caused by data-level DA ADL ‚àà{ADL
P , ADL
L } with
parameters (W‚ãÜ, b‚ãÜ) from the original data sample as ‚àÜxi := (W‚ãÜ‚àíIm)xi + b‚ãÜ, and deÔ¨Åne ‚àÜ3
x :="
N,0.5600858369098712,"Exi,W‚ãÜ,b‚ãÜ
h‚àÜxi
3
2"
N,0.5611587982832618,"i
. Suppose we apply data-level DA s.t. 1) EW‚ãÜ[W‚ãÜ] = Im; 2) Eb‚ãÜ[b‚ãÜ] = ‚Éó0m; 3)"
N,0.5622317596566524,"O(‚àÜj
x) ‚âà0, ‚àÄj ‚ààN+, j ‚â•3; 4) W‚ãÜand b‚ãÜare independent. DeÔ¨Åne ‚àÜW‚ãÜ:= W‚ãÜ‚àíIm ‚ààRm√óm,
‚àÜbyi := W ‚ä§
g f(xi) ‚àíyi ‚ààR. Let W (k)
g
‚ààR be the kth dimension component of Wg and then deÔ¨Åne"
N,0.5633047210300429,"wi,(k) := W (k)
g
‚àÜbyi ‚ààR; Denote the Hessian matrix of the kth dimension component in f(xi) as"
N,0.5643776824034334,"H(k),i
f
; Let ‚àáf be the Jacobian matrix of f, then we have"
N,0.5654506437768241,"‚Ñìb
Dn,ADL(g ‚ó¶f) = ‚Ñìb
Dn,A(g ‚ó¶f) + ‚Ñ¶ADL + O(‚àÜ3
x),"
N,0.5665236051502146,"where ‚Ñ¶ADL
P
= 1"
N,0.5675965665236051,"n
Pn
i=1
Pd
k=1 wi,(k)
h
tr

EW‚ãÜ[‚àÜxi‚àÜ‚ä§
xi]H(k),i
f
i
, where ‚àÜxi = (W‚ãÜ‚àíI)‚ä§xi +b‚ãÜ;"
N,0.5686695278969958,"‚Ñ¶ADL
L
= ‚Ñ¶ADL
P
+ 1"
N,0.5697424892703863,"n
Pn
i=1
h
EW‚ãÜ
x‚ä§
i ‚àÜW‚ãÜ‚àáf(xi)Wg
2
2 + Eb‚ãÜ
b‚ä§
‚ãÜ‚àáf(xi)Wg
2
2 i
."
N,0.5708154506437768,"Proof. Let ‚àÜfi,ADL
P
:= EW‚ãÜ,b‚ãÜf(W ‚ä§
‚ãÜxi + b‚ãÜ) ‚àíf(xi), then"
N,0.5718884120171673,"‚àÜfi,ADL
P
:=EW‚ãÜ,b‚ãÜf(W ‚ä§
‚ãÜxi + b‚ãÜ) ‚àíf(xi)"
N,0.572961373390558,"=EW‚ãÜ,b‚ãÜ
h
‚àáf(xi)‚ä§(‚àÜxi)
i
+ 1"
N,0.5740343347639485,"2EW‚ãÜ,b‚ãÜ
h
‚àÜ‚ä§
xiH(k),i
f
(xi)‚àÜxi
i"
N,0.575107296137339,"d + O(EW‚ãÜ,b‚ãÜ‚à•‚àÜxi‚à•3
2) =1"
N,0.5761802575107297,"2EW‚ãÜ,b‚ãÜ
h
‚àÜ‚ä§
xiH(k),i
f
(xi)‚àÜxi
i"
N,0.5772532188841202,"d + O(EW‚ãÜ,b‚ãÜ‚à•‚àÜxi‚à•3
2),
(15)"
N,0.5783261802575107,"where [¬∑(k)]d denotes a d-dimensional vector and k denotes the kth dimension element. Since ‚Ñì
is squared loss, the third-and-higher derivative are 0, therefore, the third-and-higher order terms in
Taylor expansion to ‚Ñì
 
EW‚ãÜ,b‚ãÜ

g ‚ó¶f(W‚ãÜxi + b‚ãÜ)

, yi

around f(xi) will vanish:"
N,0.5793991416309013,"‚Ñì
 
EW‚ãÜ,b‚ãÜ

g ‚ó¶f(W‚ãÜxi + b‚ãÜ)

, yi
"
N,0.5804721030042919,"=‚Ñì
 
g ‚ó¶f(xi), yi

+ W ‚ä§
g (‚àÜfi,ADL
P )‚Ñì‚Ä≤ 
g ‚ó¶f(xi), yi

+"
N,0.5815450643776824,"1
2W ‚ä§
g (‚àÜfi,ADL
P )(‚àÜfi,ADL
P )‚ä§Wg‚Ñì‚Ä≤‚Ä≤ 
g ‚ó¶f(xi), yi
"
N,0.5826180257510729,"=‚Ñì
 
g ‚ó¶f(xi), yi

+ W ‚ä§
g (‚àÜfi,ADL
P )‚Ñì‚Ä≤ 
g ‚ó¶f(xi), yi

+ O(EW‚ãÜ,b‚ãÜ‚à•‚àÜxi‚à•4
2)
(16)"
N,0.5836909871244635,"Substitute Eq. (15) into the Ô¨Årst-order term in Eq. (16), we have"
N,0.5847639484978541,"W ‚ä§
g (‚àÜfi,ADL
P )‚Ñì‚Ä≤ 
g ‚ó¶f(xi), yi

=W ‚ä§
g EW‚ãÜ,b‚ãÜ
h
‚àÜ‚ä§
xiH(k),i
f
‚àÜxi
i"
N,0.5858369098712446,"d‚àÜbyi + O(EW‚ãÜ,b‚ãÜ‚à•‚àÜxi‚à•3
2) =‚àÜbyi d
X"
N,0.5869098712446352,"k=1
W (k)
g
EW‚ãÜ,b‚ãÜ
h
‚àÜ‚ä§
xiH(k),i
f
‚àÜxi
i
+ O(EW‚ãÜ,b‚ãÜ‚à•‚àÜxi‚à•3
2) = d
X"
N,0.5879828326180258,"k=1
wi,(k)tr
 
EW‚ãÜ,b‚ãÜ[‚àÜxi‚àÜ‚ä§
xi]H(k),i
f

+ O(EW‚ãÜ,b‚ãÜ‚à•‚àÜxi‚à•3
2). (17)"
N,0.5890557939914163,"Substitute Eq. (17) into Eq. (16), we have"
N,0.5901287553648069,"‚Ñì
 
EW‚ãÜ,b‚ãÜ

g ‚ó¶f(W‚ãÜxi + b‚ãÜ)

, yi

=‚Ñì
 
g ‚ó¶f(xi), yi

+ d
X"
N,0.5912017167381974,"k=1
wi,(k)tr
 
EW‚ãÜ,b‚ãÜ[‚àÜxi‚àÜ‚ä§
xi]H(k),i
f

+"
N,0.592274678111588,"O(EW‚ãÜ,b‚ãÜ‚à•‚àÜxi‚à•3
2).
(18)"
N,0.5933476394849786,"Substitute Eq. (18) into Eq. (14) which is the deÔ¨Ånition of ‚Ñìb
Dn,ADL
P (g ‚ó¶f), and recall that ‚àÜ3
x :="
N,0.5944206008583691,"Exi,W‚ãÜ,b‚ãÜ
h‚àÜxi
3
2"
N,0.5954935622317596,"i
, we have"
N,0.5965665236051502,"‚Ñìb
Dn,ADL
P (g ‚ó¶f) := 1 n n
X"
N,0.5976394849785408,"i=1
‚Ñì
 
EW‚ãÜ,b‚ãÜ

g ‚ó¶f(W‚ãÜxi + b‚ãÜ)

, yi

= ‚Ñìb
Dn,A(g ‚ó¶f) + ‚Ñ¶ADL
P
+ O(‚àÜ3
x). (19)"
N,0.5987124463519313,Under review as a conference paper at ICLR 2022
N,0.5997854077253219,"Let ‚àÜfi,ADL
L
:= f(W ‚ä§
‚ãÜxi + b‚ãÜ) ‚àíf(xi) = ‚àáf(xi)‚ä§(‚àÜW‚ãÜxi + b‚ãÜ) + O(‚à•‚àÜxi‚à•2
2)."
N,0.6008583690987125,"Applying Taylor expansion to EW‚ãÜ,b‚ãÜ

‚Ñì
 
g ‚ó¶f(W‚ãÜxi + b‚ãÜ), yi

around f(xi) will give us"
N,0.601931330472103,"EW‚ãÜ,b‚ãÜ

‚Ñì
 
g ‚ó¶f(W‚ãÜxi + b‚ãÜ), yi

=‚Ñì
 
g ‚ó¶f(xi), yi

+ W ‚ä§
g EW‚ãÜ,b‚ãÜ

‚àÜfi,ADL
L

‚Ñì‚Ä≤ 
g ‚ó¶f(xi), yi

+"
N,0.6030042918454935,"1
2W ‚ä§
g EW‚ãÜ,b‚ãÜ

(‚àÜfi,ADL
L )(‚àÜfi,ADL
L )‚ä§
Wg‚Ñì‚Ä≤‚Ä≤ 
g ‚ó¶f(xi), yi
 (20)"
N,0.6040772532188842,"Since EW‚ãÜ,b‚ãÜ‚àÜfi,ADL
L
= ‚àÜfi,ADL
P , the Ô¨Årst-order term in Eq. (20) is exactly Eq. (17):"
N,0.6051502145922747,"W ‚ä§
g EW‚ãÜ,b‚ãÜ

‚àÜfi,ADL
L

‚Ñì‚Ä≤ 
g ‚ó¶f(xi), yi
"
N,0.6062231759656652,"=W ‚ä§
g ‚àÜfi,ADL
P ‚Ñì‚Ä≤ 
g ‚ó¶f(xi), yi
 = d
X"
N,0.6072961373390557,"k=1
wi,(k)tr
 
EW‚ãÜ,b‚ãÜ[‚àÜxi‚àÜ‚ä§
xi]H(k),i
f

+ O(EW‚ãÜ,b‚ãÜ‚à•‚àÜxi‚à•3
2)
(21)"
N,0.6083690987124464,"The second-order term in Eq. (20) is
1
2W ‚ä§
g EW‚ãÜ,b‚ãÜ

(‚àÜfi,ADL
L )(‚àÜfi,ADL
L )‚ä§
Wg‚Ñì‚Ä≤‚Ä≤ 
g ‚ó¶f(xi), yi
"
N,0.6094420600858369,"=W ‚ä§
g EW‚ãÜ,b‚ãÜ

(‚àáf(xi)‚ä§(‚àÜW‚ãÜxi + b‚ãÜ)(‚àÜW‚ãÜxi + b‚ãÜ)‚ä§‚àáf(xi)

Wg + O(EW‚ãÜ,b‚ãÜ‚à•‚àÜxi‚à•4
2)"
N,0.6105150214592274,"=EW‚ãÜ
x‚ä§
i ‚àÜ‚ä§
W‚ãÜ‚àáf(xi)Wg
2
2 + Eb‚ãÜ
b‚ä§
‚ãÜ‚àáf(xi)Wg
2
2 + O(EW‚ãÜ,b‚ãÜ‚à•‚àÜxi‚à•4
2)
(22)"
N,0.6115879828326181,"Substituting Eq. (21) and Eq. (22) into Eq. (20), we have
EW‚ãÜ,b‚ãÜ

‚Ñì
 
g ‚ó¶f(W‚ãÜxi + b‚ãÜ), yi
"
N,0.6126609442060086,"=‚Ñì
 
g ‚ó¶f(xi), yi

+ d
X"
N,0.6137339055793991,"k=1
wi,(k)tr
 
EW‚ãÜ,b‚ãÜ[‚àÜxi‚àÜ‚ä§
xi]H(k),i
f

+"
N,0.6148068669527897,"EW‚ãÜ
x‚ä§
i ‚àÜW‚ãÜ‚àáf(xi)Wg
2
2 + Eb‚ãÜ
b‚ä§
‚ãÜ‚àáf(xi)Wg
2
2 + O(EW‚ãÜ,b‚ãÜ‚à•‚àÜxi‚à•4
2)
(23)"
N,0.6158798283261803,"Substitute Eq. (23) into the deÔ¨Ånition of ‚Ñìb
Dn,ADL
L (g ‚ó¶f), then"
N,0.6169527896995708,"‚Ñìb
Dn,ADL
L (g ‚ó¶f) := 1 n n
X"
N,0.6180257510729614,"i=1
EW‚ãÜ,b‚ãÜ

‚Ñì
 
g ‚ó¶f(W‚ãÜxi + b‚ãÜ), yi

= ‚Ñìb
Dn,A(g ‚ó¶f) + ‚Ñ¶ADL
L
+ O(‚àÜ3
x) (24)"
N,0.619098712446352,The proof is complete by Eq. (19) and Eq. (24).
N,0.6201716738197425,"Interpretation. ‚Ñ¶ADL
P
and ‚Ñ¶ADL
L
turn out to be: 1) ‚Ñ¶ADL
P
is a weighted trace expectation dependent
on the Hessian matrix of f; 2) ‚Ñ¶ADL
L
is equivalent to ‚Ñ¶ADL
P
together with the summation of two
norm expectations dependent on ‚àáf. Therefore, the data-level DA algorithms ADL
P
and ADL
L
are
expected to regularize f so that the f function class FDL
A
enabled by ADL ‚àà{ADL
P , ADL
L } would
be reasonably expected as a subset of FA enabled by general training algorithm A."
N,0.621244635193133,"SufÔ¨Åcient conditions.
Combined with Theorem 3.3, the sufÔ¨Åcient conditions indicated here to
tighten the upper bound dFA( bDn
S, bDn
T ) of the relative transferability œÑ(A; bDS, DT ) are: data-
level DA (ADL) with DA parameters satisfying that 1) EW‚ãÜ[W‚ãÜ] = Im; 2) Eb‚ãÜ[b‚ãÜ] = ‚Éó0m; 3)
O(‚àÜj
x) ‚âà0, ‚àÄj ‚ààN+, j ‚â•3; 4) W‚ãÜand b‚ãÜare independent."
N,0.6223175965665236,"Empirical veriÔ¨Åcation. We further provide empirical veriÔ¨Åcation in Section 4 for the sufÔ¨Åcient
conditions above, investigating the concrete cases of DA methods: 1) Gaussian noise satisÔ¨Åes the
sufÔ¨Åcient conditions, then we empirically show that Gaussian noise improves domain transferability
while robustness decreases a bit (Figure 5); 2) Rotation, which rotates input image with a predeÔ¨Åned
Ô¨Åxed angle with predeÔ¨Åned Ô¨Åxed probability, violates EW‚ãÜ[W‚ãÜ] = Im, and we empirically show that
rotation barely affect domain transferability (Figure 14 in Appendix D.3); Translation, which moves
the input image for a predeÔ¨Åned distance along a pre-selected axis with Ô¨Åxed probability, violates
Eb‚ãÜ[b‚ãÜ] = ‚Éó0m (Figure 14 in Appendix D.3)."
N,0.6233905579399142,Under review as a conference paper at ICLR 2022
N,0.6244635193133047,"Corollary B.2.1. If the neural network in Theorem B.2 is activated by Relu or Max-pooling, then
Theorem B.2 becomes"
N,0.6255364806866953,"‚Ñìb
Dn,ADL(g ‚ó¶f) = ‚Ñìb
Dn,A(g ‚ó¶f) + ‚Ñ¶ADL + O(‚àÜ3
x),"
N,0.6266094420600858,"where ‚Ñ¶ADL
P
= 0; ‚Ñ¶ADL
L
= 1"
N,0.6276824034334764,"n
Pn
i=1
h
EW‚ãÜ
x‚ä§
i ‚àÜW‚ãÜ‚àáf(xi)Wg
2
2 + Eb‚ãÜ
b‚ä§
‚ãÜ‚àáf(xi)Wg
2
2 i
."
N,0.628755364806867,"Proof. Denote an L‚àílayer NN g ‚ó¶f(x) := W ‚ä§
g ¬∑ z[L‚àí1], where z[l] := œÉ[l‚àí1](W ‚ä§
[l‚àí1] ¬∑ z[l‚àí1]),
l = 1, 2, 3, ..., L ‚àí1; DeÔ¨Åne that œÉ[0](W ‚ä§
[0] ¬∑ z[0]) := x, then ‚àá2 
g ‚ó¶f(x)

= 0 (B.2 of Zhang et al.
(2020)). Since ‚àá2 
g ‚ó¶f(x)

= W ‚ä§
g ¬∑ ‚àá2f(x), we have ‚àá2f(x) = 0."
N,0.6298283261802575,"Combine this with Theorem B.2, we have"
N,0.630901287553648,"‚Ñ¶ADL
P
= 1 n n
X i=1 d
X"
N,0.6319742489270386,"k=1
wi,(k)
h
tr

EW‚ãÜ[‚àÜxi‚àÜ‚ä§
xi]H(k),i
f
i
= 0;"
N,0.6330472103004292,"‚Ñ¶ADL
L
= ‚Ñ¶ADL
P
+ 1 n n
X i=1"
N,0.6341201716738197,"h
EW‚ãÜ
x‚ä§
i ‚àÜW‚ãÜ‚àáf(xi)Wg
2
2 + Eb‚ãÜ
b‚ä§
‚ãÜ‚àáf(xi)Wg
2
2 i = 1 n n
X i=1"
N,0.6351931330472103,"h
EW‚ãÜ
x‚ä§
i ‚àÜW‚ãÜ‚àáf(xi)Wg
2
2 + Eb‚ãÜ
b‚ä§
‚ãÜ‚àáf(xi)Wg
2
2 i
."
N,0.6362660944206009,"Remark. Corollary B.2.1 analyzes special cases (Relu/ Max-pooling activation) of Theorem B.2,
giving notably different regularization effect: in these cases the ADL
P
(average the prediction) fails as
a regularizer, therefore, doesn‚Äôt fulÔ¨Åll our sufÔ¨Åcient conditions for improving domain transferability
(Theorem 3.3); ADL
L
(average the loss) only reserves the regularization on ‚àáf-dependent norms,
but no longer regularizes Hf(x). Since ADL
L
still induces regularization, the induced sufÔ¨Åcient
conditions analyzed after Theorem B.2 for promoting domain transferability won‚Äôt be affected."
N,0.6373390557939914,"C
ADVERSARIAL TRAINING AS A REGULARIZER"
N,0.6384120171673819,"In this section, we show, under certain conditions, why adversarial training may improve domain
generalization by viewing adversarial training as a function class regularizer."
N,0.6394849785407726,We Ô¨Årst provide some notation. Let
N,0.6405579399141631,F = {fŒ∏(¬∑) = W LœÜL‚àí1(W L‚àí1œÜL‚àí2(. . . ) + bL‚àí1) + bL}
N,0.6416309012875536,"where œÜj are activations, W j, bj are weight matrix and bias vector, Œ∏ is the collection of parameters
(i.e. Œ∏ = (W 1, b1, . . . , W L, bL). For the rest of the article, assume that œÜj are just ReLUs."
N,0.6427038626609443,Now Ô¨Åx x ‚ààX. DeÔ¨Åne the preactivation as
N,0.6437768240343348,ex1 := W 1x + b1
N,0.6448497854077253,"exj := W jœÜj‚àí1(exj‚àí1) + bj , j ‚â•2"
N,0.6459227467811158,"DeÔ¨Åne the activation pattern œÜx := (œÜ1
x, . . . , œÜL‚àí1
x
) ‚àà{0, 1}m such that for each j ‚àà[L ‚àí1]"
N,0.6469957081545065,"œÜj
x = 1(exj > 0)"
N,0.648068669527897,where 1 is applied elementwise.
N,0.6491416309012875,"Now, given an activation pattern œÜ ‚àà{0, 1}m, we deÔ¨Åne the preimage X(œÜ) := {x ‚ààRd : œÜx = œÜ}
Theorem C.1. (In the proof of theorem 1 in (Roth et al., 2020))"
N,0.6502145922746781,"Let œµ > 0 s.t. Bp
œµ (x) ‚äÇX(œÜx) where Bp
œµ (x) denotes the lp ball centered at x with radius œµ. Let
p = {1, 2, ‚àû} and q be the Holder conjugate of p (i.e. 1 p + 1"
N,0.6512875536480687,q = 1). Then
N,0.6523605150214592,"E(x,y)‚àºP [l(y, f(x)) + Œª
max
x‚àó‚ààBp
œµ (x) ‚à•f(x) ‚àíf(x‚àó)‚à•q] = E(x,y)‚àºP [l(y, f(x)) + Œª ¬∑ œµ
max
v‚àó: ‚à•v‚àó‚à•p‚â§1"
N,0.6534334763948498,"Jf(x)v

q]"
N,0.6545064377682404,Under review as a conference paper at ICLR 2022
N,0.6555793991416309,"Interpretation: This theorem provides an equivalence between the objective functions for adversar-
ial training (left term) and jacobian regularization (right term). We give some intuition on the size of
œµ. Let us Ô¨Årst consider a shallow 2 layer network f(x) = W 2œÜ(W 1x+b1). Suppose W 2 ‚ààRm2√óm1
and W 1 ‚ààRm1√ód. Given a matrix M, let Mj denote the jth row of M. We study the activation
pattern œÜx which equals"
N,0.6566523605150214,"œÜx = (œÜ1
x) = Ô£´ Ô£¨
Ô£≠"
N,0.657725321888412,"1{W 1
1 x + b1
1}
...
1{W 1
m1x + b1
m1} Ô£∂ Ô£∑
Ô£∏"
N,0.6587982832618026,"We wish to compute the largest radius œµ such that the activation pattern œÜx is constant within B2
œµ (x).
This is simply the distance from x to the closest hyperplane of the form HW 1
j ,b1
j = {x ‚ààRd :
W 1
j x + b1
j = 0} where j = 0, . . . , m1 (i.e. œµ = minj dist(x, HW 1
j ,b1
j)). In particular, if W 1 = Id√ód
and b1 = 0, œµ = minj‚ààd|xj|."
N,0.6598712446351931,"Furthermore, we note that œµ is nondecreasing as a function of the number of layers. However, it has
been observed empirically in (Roth et al., 2020) that approximate correspondence holds in a much
larger ball.
DeÔ¨Ånition 4. (source and target function class) Let GS, GT be Ô¨Åne tuning function classes for source
and target domains, respectively. We deÔ¨Åne the class of source models as"
N,0.6609442060085837,"HS = GS ‚ó¶F = {gS ‚ó¶fŒ∏ : gS ‚ààGS, fŒ∏ ‚ààF}"
N,0.6620171673819742,and the class of target models as
N,0.6630901287553648,"HT = GT ‚ó¶F = {gT ‚ó¶fŒ∏ : gT ‚ààGT , fŒ∏ ‚ààF}"
N,0.6641630901287554,"DeÔ¨Ånition 5. (empirical training objective with jacobian regularization) Let Œª, œµ > 0. Take any
hypothesis hŒ∏ = gS ‚ó¶fŒ∏ ‚ààHS. Let ÀÜR(hŒ∏) = 1"
N,0.6652360515021459,"n
Pn
i=1 ‚Ñì(hŒ∏(xi), yi) denote the empirical risk where
l(ÀÜy, y) = ‚à•ÀÜy ‚àíy‚à•2. We deÔ¨Åne the empirical training objective with jacobian regularization as"
N,0.6663090128755365,"ObjA
Œª (hŒ∏) = ÀÜR(hŒ∏) + Œª ¬∑ œµ n n
X"
N,0.6673819742489271,"i=1
‚à•JhŒ∏(xi)‚à•2"
N,0.6684549356223176,Theorem C.2. Fix regularization strength Œª > 0. DeÔ¨Åne
N,0.6695278969957081,"FA
Œª = {f A
Œ∏ ‚ààF : ‚àÉgS ‚ààGS s.t. ObjA
Œª (gS ‚ó¶f A
Œ∏ ) ‚â§ObjA
Œª (0)}"
N,0.6706008583690987,"where 0 denotes the zero function (i.e. the class of feature extractors that outperform the zero
function). Suppose (x, y) ‚ààX √ó Y is bounded such that max (‚à•x‚à•‚àû, ‚à•y‚à•2) ‚â§R. Fix Œ¥ > 0.
Suppose we additionally restrict our Ô¨Åne tuning class models to linear models where"
N,0.6716738197424893,"GS = {W : W ‚ààRd√ón, n ‚â•1, min
j
‚à•Wj‚à•2 ‚â•Œ¥}"
N,0.6727467811158798,(where Wj is the jth column of W) and
N,0.6738197424892703,"GT = {W : W ‚ààRd√ón, n ‚â•1}"
N,0.674892703862661,"(Here we are abusing notation to let gS ‚ààGS to denote the last linear layer as well as the Ô¨Åne
tuning function)."
N,0.6759656652360515,"Then for 0 ‚â§Œª1 < Œª2
FA
Œª2 ‚ääFA
Œª1 ‚ääF"
N,0.677038626609442,"(where ‚äädenotes proper subset). In particular, if HA,T
Œª
= GT ‚ó¶FA
Œª , we have"
N,0.6781115879828327,"HA,T
Œª2
‚ääHA,T
Œª1
‚ääHT"
N,0.6791845493562232,Interpretation:
N,0.6802575107296137,"At the high level, this theorem captures the idea that minimizing the empirical risk with jacobian
regularization puts a constraint on the set of feature extractors. In particular, FA
Œª1 represents the
potential class of feature extractors we select after training with jacobian regularization. Therefore,"
N,0.6813304721030042,Under review as a conference paper at ICLR 2022
N,0.6824034334763949,"the class of Ô¨Åne tuned models HA,T
Œª1
with feature extractors trained with jacobian regularization for
the target domain is smaller than the class of Ô¨Åne tuned models H with feature extractors trained
without any regularization. Furthermore, we show that the space of feature extractors shrinks as we
increase the regularization stength Œª. Since we showed in section 3.3 that smaller function classes
have smaller dFA, this theorem shows that jacobian regularization reduces dFA. To connect back to
adversarial training, if œµ satisÔ¨Åes the hypothesis in theorem C.1, we have that
E(x,y)‚àºP [l(y, f(x)) + Œª
max
x‚àó‚ààBp
œµ (x) ‚à•f(x) ‚àíf(x‚àó)‚à•q] = E(x,y)‚àºP [l(y, f(x)) + Œª ¬∑ œµ
max
v‚àó: ‚à•v‚àó‚à•p‚â§1"
N,0.6834763948497854,"Jf(x)v

q]"
N,0.6845493562231759,"Therefore, minimizing the training objective with jacobian regularization is equivalent to minimizing
the adversarial training objective. Using this connection, this theorem essentially shows that, given
sufÔ¨Åcient number of samples, adversarial training reduces the class of feature extractors which in
turn reduces dFA."
N,0.6856223175965666,"Finally, we comment on the assumption that
gS > Œ¥. Since Œ¥ > 0 is arbitrary, we can make it as
small as we like and thus we are essentially excluding the 0 last layer which is hardly a constraint on
the function class. This assumption is necessary as we are considering regularization on the whole
model g‚ó¶f as opposed to regularization on just the feature extractor. Thus, this assumption prevents
the scenario where only the last linear layer is regularized."
N,0.6866952789699571,"Proof. We Ô¨Årst show that if 0 ‚â§Œª1 < Œª2, we have that
FA
Œª2 ‚ääFA
Œª1 ‚ääF"
N,0.6877682403433476,We Ô¨Årst prove the following lemma
N,0.6888412017167382,"Lemma C.1. Suppose the conditions of theorem C.2 are satisÔ¨Åed. Suppose additionally we have
that y :=
1
n
Pd
i=1 yi Ã∏= 0 (note this occurs with probability 1 if marginal distribution over Y is
continuous). Then for every Œª ‚â•0, there exists a function fŒ∏ ‚ààFA
Œª and a Ô¨Åne tuning layer g‚àó‚ààGS
such that
ObjA
Œª (g‚àó‚ó¶fŒ∏) = inf
g‚ààGS ObjA
Œª (g ‚ó¶fŒ∏) = ObjA
Œª (0)"
N,0.6899141630901288,"Choose another Œª‚Ä≤ ‚â•0 (can equal Œª). Then there exists a g‚àó‚Ä≤ ‚ààGS be the Ô¨Åne tuning layer such
that infg‚ààGS ObjA
Œª‚Ä≤(g ‚ó¶fŒ∏) = ObjA
Œª‚Ä≤(g‚àó‚Ä≤ ‚ó¶fŒ∏) and"
N,0.6909871244635193,"1
n n
X"
N,0.6920600858369099,"i=1
‚à•Jg‚àó‚Ä≤‚ó¶fŒ∏(xi)‚à•2 > 0"
N,0.6931330472103004,"Proof. Fix Œ± ‚â•0 and c > Œ± ¬∑ R. Set biases b1 = Ô£´ Ô£¨
Ô£¨
Ô£≠"
N,0.694206008583691,"c
0
...
0 Ô£∂"
N,0.6952789699570815,"Ô£∑
Ô£∑
Ô£∏bj = 0 , j ‚â•2"
N,0.6963519313304721,"and weights W 1 = Ô£´ Ô£¨
Ô£¨
Ô£≠"
N,0.6974248927038627,"Œ±
0
. . .
0
0
0
. . .
0
...
...
...
...
0
. . .
. . .
0 Ô£∂"
N,0.6984978540772532,"Ô£∑
Ô£∑
Ô£∏W j = Ô£´ Ô£¨
Ô£¨
Ô£≠"
N,0.6995708154506438,"1
0
. . .
0
0
0
. . .
0
...
...
...
...
0
. . .
. . .
0 Ô£∂"
N,0.7006437768240343,"Ô£∑
Ô£∑
Ô£∏, j ‚â•2"
N,0.7017167381974249,"DeÔ¨Åne xi,j be the jth entry of the data point xi. DeÔ¨Åne
Œ±i := Œ± ¬∑ xi,1"
N,0.7027896995708155,"Œ± := 1 n d
X"
N,0.703862660944206,"i=1
Œ±i"
N,0.7049356223175965,"y := 1 n d
X"
N,0.7060085836909872,"i=1
yi"
N,0.7070815450643777,Under review as a conference paper at ICLR 2022
N,0.7081545064377682,"Now we observe that for a Ô¨Åxed Œª ‚â•0 and any g ‚ààGS, we have that"
N,0.7092274678111588,"ObjA
Œª (g ‚ó¶fŒ∏) = ÀÜR(g ‚ó¶fŒ∏) + Œª ¬∑ œµ 1 n n
X"
N,0.7103004291845494,"i=1
‚à•Jg‚ó¶fŒ∏(xi)‚à•2 = 1 n n
X i=1"
N,0.7113733905579399,"(Œ±xi,1 + c) Ô£´ Ô£¨
Ô£≠"
N,0.7124463519313304,"g11
...
gd1 Ô£∂"
N,0.7135193133047211,"Ô£∑
Ô£∏‚àíyi  2 2"
N,0.7145922746781116,"+ Œª ¬∑ œµ 1 n n
X i=1  g Ô£´ Ô£¨
Ô£¨
Ô£≠"
N,0.7156652360515021,"Œ±
0
. . .
0
0
0
. . .
0
...
...
...
...
0
. . .
. . .
0 Ô£∂ Ô£∑
Ô£∑
Ô£∏ 2 = 1 n n
X"
N,0.7167381974248928,"i=1
‚à•(Œ±i + c)g1 ‚àíyi‚à•2
2 + Œª ¬∑ œµ 1 n n
X"
N,0.7178111587982833,"i=1
Œ± ‚à•g1‚à•2 = 1 n n
X"
N,0.7188841201716738,"i=1
‚à•(Œ±i + c)g1 ‚àíyi‚à•2
2 + Œª ¬∑ œµŒ± ‚à•g1‚à•2"
N,0.7199570815450643,"Therefore,"
N,0.721030042918455,"inf
g‚ààGS ObjA
Œª (g ‚ó¶fŒ∏)"
N,0.7221030042918455,is equivalent to solving
N,0.723175965665236,"inf
w‚ààRd : ‚à•w‚à•2‚â•Œ¥
1
n n
X"
N,0.7242489270386266,"i=1
‚à•(Œ±i + c)w ‚àíyi‚à•2
2 + Œª ¬∑ œµŒ± ‚à•w‚à•2
(25)"
N,0.7253218884120172,"Utilizing lagrange multipliers, we Ô¨Ånd the minimizer is"
N,0.7263948497854077,"w = Œ¥ ¬∑
y
‚à•y‚à•
(26)"
N,0.7274678111587983,when c ‚â•‚à•y‚à•2 Œ¥ .
N,0.7285407725321889,Now consider the function
N,0.7296137339055794,"S(c, Œ±) = 1 n n
X"
N,0.73068669527897,"i=1
‚à•(Œ± ¬∑ xi,1 + c)g1 ‚àíyi‚à•2
2 + Œª ¬∑ œµŒ± ‚à•g1‚à•2"
N,0.7317596566523605,"Note that this function is continuous with respect to the input (c, Œ±). Now Ô¨Åx Œ± = 0, c = ‚à•y‚à•2"
N,0.7328326180257511,"Œ¥ . Set
w = Œ¥ ¬∑
y
‚à•y‚à•. Then we have that"
N,0.7339055793991416,S(‚à•y‚à•2
N,0.7349785407725322,"Œ¥
, 0) = 1 n n
X"
N,0.7360515021459227,"i=1
‚à•y ‚àíyi‚à•2
2 < 1 n n
X"
N,0.7371244635193133,"i=1
‚à•yi‚à•2
2 = ObjA
Œª (0)"
N,0.7381974248927039,"The inequality comes from the fact that we assumed y Ã∏= 0 and noting that y is the minimizer of the
function p(z) = 1"
N,0.7392703862660944,"n ‚à•z ‚àíyi‚à•2
2. Continuity of S ensures that there exists Œ±0 > 0 such that"
N,0.740343347639485,S(‚à•y‚à•2
N,0.7414163090128756,"Œ¥
, Œ±0) < 1 n n
X"
N,0.7424892703862661,"i=1
‚à•yi‚à•2
2 = ObjA
Œª (0)"
N,0.7435622317596566,Now consider U(t) = S((1 + t) ‚à•y‚à•2
N,0.7446351931330472,"Œ¥ , (1 + t)Œ±0) for t ‚â•0. Note that U is continuous with respect
to t. Furthermore, we note that t ‚Üí‚àûimplies U(t) ‚Üí‚àûwhich implies there exists some time
t = Tf such that U(Tf) > ObjA
Œª (0). Therefore, by the intermediate value theorem, there exists a
time t = T such that U(T) = ObjA
Œª (0). Finally, set c = (T + 1) ‚à•y‚à•2"
N,0.7457081545064378,"Œ¥ , Œ± = (T + 1)Œ±0, and g‚àóas
the matrix where g‚àó
1 = Œ¥ ¬∑
y
‚à•y‚à•and 0 for the other columns. By equation 25 and equation 26 we have"
N,0.7467811158798283,"ObjA
Œª (g‚àó‚ó¶fŒ∏) = inf
g‚ààGS ObjA
Œª (g ‚ó¶fŒ∏) = U(T) = ObjA
Œª (0)"
N,0.7478540772532188,"Furthermore, if we choose another Œª‚Ä≤ ‚â•0, since c = (T + 1) ‚à•y‚à•2"
N,0.7489270386266095,"Œ¥
> ‚à•y‚à•2"
N,0.75,"Œ¥
by equation 26, we have
that"
N,0.7510729613733905,"ObjA
Œª‚Ä≤(g‚àó‚Ä≤ ‚ó¶fŒ∏) = inf
g‚ààGS ObjA
Œª‚Ä≤(g ‚ó¶fŒ∏)"
N,0.7521459227467812,Under review as a conference paper at ICLR 2022 and
N,0.7532188841201717,"1
n n
X"
N,0.7542918454935622,"i=1
‚à•Jg‚àó‚Ä≤‚ó¶fŒ∏(xi)‚à•2 = Œ±
g‚àó‚Ä≤
2 = Œ±Œ¥"
N,0.7553648068669528,which is nonzero as Œ¥ > 0 and Œ± = (T + 1)Œ±0 > 0.
N,0.7564377682403434,"Clearly, we have FA
Œª2 ‚äÇFA
Œª1. If we can show that fŒ∏1 Ã∏‚ààFA
Œª2 then we have FA
Œª2 ‚ääFA
Œª1."
N,0.7575107296137339,"Using lemma C.1 we can Ô¨Ånd fŒ∏1 ‚ààFA
Œª1 such that"
N,0.7585836909871244,"inf
g‚ààGS ObjA
Œª1(g ‚ó¶fŒ∏1) = ObjA
Œª1(0)"
N,0.759656652360515,"In addition lemma C.1 guarantees minimizers g‚àó
1 and g‚àó
2 such that"
N,0.7607296137339056,"ObjA
Œª1(g‚àó
1 ‚ó¶fŒ∏1) = inf
g‚ààGS ObjA
Œª1(g ‚ó¶fŒ∏1) and 1 n n
X i=1"
N,0.7618025751072961,"Jg‚àó
1‚ó¶fŒ∏(xi)

2 > 0"
N,0.7628755364806867,"ObjA
Œª2(g‚àó
2 ‚ó¶fŒ∏1) = inf
g‚ààGS ObjA
Œª2(g ‚ó¶fŒ∏1) and 1 n n
X i=1"
N,0.7639484978540773,"Jg‚àó
2‚ó¶fŒ∏1(xi)

2 > 0"
N,0.7650214592274678,"Thus, we have that"
N,0.7660944206008584,"ObjA
Œª1(g‚àó
2 ‚ó¶fŒ∏1) = ÀÜR(g‚àó
2 ‚ó¶fŒ∏1) + Œª2 ¬∑ œµ 1 n n
X i=1"
N,0.7671673819742489,"Jg‚àó
2‚ó¶fŒ∏1(xi)

2"
N,0.7682403433476395,"> ÀÜR(g‚àó
2 ‚ó¶fŒ∏1) + Œª1 ¬∑ œµ 1 n n
X i=1"
N,0.76931330472103,"Jg‚àó
2‚ó¶fŒ∏1(xi)

2
since Œª2 > Œª1"
N,0.7703862660944206,"‚â•ÀÜR(g‚àó
1 ‚ó¶fŒ∏1) + Œª1 ¬∑ œµ 1 n n
X i=1"
N,0.7714592274678111,"Jg‚àó
1‚ó¶fŒ∏1(xi)

2
def of g‚àó
1"
N,0.7725321888412017,"= ObjA
Œª1(0)
lemma C.1"
N,0.7736051502145923,"Thus fŒ∏1 Ã∏‚ààFA
Œª2 which implies FA
Œª2 ‚ääFA
Œª1. It remains to show for Œª1 ‚â•0, we have that FA
Œª1 ‚ääF."
N,0.7746781115879828,"Consider any g ‚ààGS. For j ‚àà[L], deÔ¨Åne W j as the weight matrix where W j = Id√ód (identity
matrix) for j ‚àà[L ‚àí1] and let the Ô¨Ånal weight W L = B ¬∑ Id√ód for some constant B > 0. Set the
bias vectors bj = 0 for j ‚â•2. Let the Ô¨Årst bias equal b1 = R ¬∑ 1 where 1 is the vector of all 1‚Äôs and
R is the upper bound such that ‚à•x‚à•‚àû‚â§R. Set Œ∏ = (W 1, b1, . . . , W L, bL) and let hŒ∏ = g ‚ó¶fŒ∏"
N,0.7757510729613734,We compute
N,0.776824034334764,"ObjA
Œª1(hŒ∏) = ÀÜR(hŒ∏) + Œª1 ¬∑ œµ 1 n n
X"
N,0.7778969957081545,"i=1
‚à•JhŒ∏(xi)‚à•2 = 1 n n
X"
N,0.778969957081545,"i=1
‚à•B(xi + R1) ‚àíyi‚à•2 + 1 n n
X"
N,0.7800429184549357,"i=1
‚à•JhŒ∏(xi)‚à•2 = 1 n n
X"
N,0.7811158798283262,"i=1
‚à•B(xi + R1) ‚àíyi‚à•2 + B ‚à•g‚à•2 ‚â•1 n n
X"
N,0.7821888412017167,"i=1
‚à•B(xi + R1) ‚àíyi‚à•2 + BŒ¥"
N,0.7832618025751072,"We note that sending B ‚Üí‚àûwe get ObjA
Œª1(hŒ∏) ‚Üí‚àûwhich implies that there exists a B = B‚Ä≤"
N,0.7843347639484979,"such that ObjA
Œª1(hŒ∏) > ObjA
Œª1(0). Setting B = B‚Ä≤ implies fŒ∏ Ã∏‚ààFA
Œª1."
N,0.7854077253218884,Under review as a conference paper at ICLR 2022
N,0.7864806866952789,"D
EXTRA EXPERIMENT RESULTS"
N,0.7875536480686696,"D.1
ABSOLUTE TRANSFERABILITY"
N,0.7886266094420601,"We show the results with absolute transferability in Figure 7,8,9 and 10 respectively."
N,0.7896995708154506,"10
20
30
Robust Acc (%) 30 35 40"
N,0.7907725321888412,Domain Transfer Acc (%)
N,0.7918454935622318,R: -0.798
N,0.7929184549356223,CIFAR10 -> SVHN
N,0.7939914163090128,"LLR(
l)
-0.1
0
0.1
1.0"
N,0.7950643776824035,"18
20
22
24
Robust Acc (%) 70 72 74 76"
N,0.796137339055794,R: -0.922
N,0.7972103004291845,ImageNet -> CIFAR10
N,0.7982832618025751,"LLR(
l)
-0.01
0
0.01
0.1"
N,0.7993562231759657,"10
20
30
Robust Acc (%) 20 25 30 35 40"
N,0.8004291845493562,R: -0.904
N,0.8015021459227468,CIFAR10 -> SVHN
N,0.8025751072961373,LLOT(||gs||2)
N,0.8036480686695279,"0.01
0.1
1.0
10.0"
N,0.8047210300429185,"20
30
40
Robust Acc (%) 72 74 76"
N,0.805793991416309,R: -0.929
N,0.8068669527896996,ImageNet -> CIFAR10
N,0.8079399141630901,LLOT(||gs||2)
N,0.8090128755364807,"0.5
1
2
5"
N,0.8100858369098712,"Figure 7: Robustness and absolute transferability when we control the norm of last layer with last-
layer regularization (LLR) and last-layer orthogonal training (LLOT) with different parameters."
N,0.8111587982832618,"20
30
40
50
60
70
Robust Acc (%) 20 25 30 35"
N,0.8122317596566524,Domain Transfer Acc (%)
N,0.8133047210300429,R: -0.619
N,0.8143776824034334,CIFAR10 -> SVHN
N,0.8154506437768241,"JR(
j)
0
10
100
1000"
N,0.8165236051502146,"15
25
35
45
55
Robust Acc (%) 70 75 80 85 90"
N,0.8175965665236051,R: 0.902
N,0.8186695278969958,ImageNet -> CIFAR10
N,0.8197424892703863,"JR(
j)
0
0.001
0.01
1.0"
N,0.8208154506437768,"10
20
Robust Acc (%) 30 35"
N,0.8218884120171673,R: 0.889
N,0.822961373390558,CIFAR10 -> SVHN
N,0.8240343347639485,"WD(
w)
0.0005
0.001
0.005
0.01"
N,0.825107296137339,"10
15
20
Robust Acc (%) 65 70 75"
N,0.8261802575107297,R: 0.909
N,0.8272532188841202,ImageNet -> CIFAR10
N,0.8283261802575107,"WD(
w)
0.0001
0.0005
0.001"
N,0.8293991416309013,"Figure 8: Robustness and absolute transferability when we regularize the feature extractor with
Jacobian Regularization (JR) and weight decay (WD) with different parameters."
N,0.8304721030042919,"20
30
40
50
60
70
Robust Acc (%) 30 35 40 45"
N,0.8315450643776824,Domain Transfer Acc (%)
N,0.8326180257510729,R: 0.768
N,0.8336909871244635,CIFAR10 -> SVHN
N,0.8347639484978541,Gauss( )
N,0.8358369098712446,"0
0.05
0.25
1.0"
N,0.8369098712446352,"20
30
Robust Acc (%) 75 80"
N,0.8379828326180258,R: -0.306
N,0.8390557939914163,ImageNet -> CIFAR10
N,0.8401287553648069,Gauss( )
N,0.8412017167381974,"0
0.05
0.25"
N,0.842274678111588,"20
30
40
50
Robust Acc (%) 35 40 45"
N,0.8433476394849786,R: 0.629
N,0.8444206008583691,CIFAR10 -> SVHN
N,0.8454935622317596,"Pos(b) 1
4
8"
N,0.8465665236051502,"20
25
30
Robust Acc (%) 73 75 77"
N,0.8476394849785408,R: 0.963
N,0.8487124463519313,ImageNet -> CIFAR10
N,0.8497854077253219,"Pos(b) 1
4
8"
N,0.8508583690987125,"Figure 9: Robustness and absolute transferability when we use Gaussian noise (Gauss) and posterize
(Pos) as data augmentations with different parameters."
N,0.851931330472103,"D.2
RESULTS OF OTHER MODEL STRUCTURES"
N,0.8530042918454935,"To further validate our evaluation results, we evaluate the experiments on another model structure.
We use a simpler CNN model for CIFAR-10 to SVHN and a more complicated WideResNet-50 for
ImageNet to CIFAR-10. The CNN model consists of four convolutional layer with 3√ó3 kernels and
32,32,64,64 channels respectively, followed by two hidden layer with size 256. A 2√ó2 max pooling
is calculated after the second and fourth layer. Other settings are the same as in the main text. Note
that in some settings the new model cannot converge, and therefore we will omit the result. In
addition, Jacobian regularization cannot be applied on WideResNet-50 because of the large memory
cost, so we do not include it in the Ô¨Ågures. The results are shown in Figure 11, 12 and 13."
N,0.8540772532188842,Under review as a conference paper at ICLR 2022
N,0.8551502145922747,"0
10
20
Robust Acc (%) 80 90"
N,0.8562231759656652,Domain Transfer Acc (%)
N,0.8572961373390557,R: -0.981
N,0.8583690987124464,ImageNet -> CIFAR10
N,0.8594420600858369,Rescale(m)
N,0.8605150214592274,"1
2
4
8"
N,0.8615879828326181,"15
20
Robust Acc (%) 75 80"
N,0.8626609442060086,R: -0.557
N,0.8637339055793991,ImageNet -> CIFAR10
N,0.8648068669527897,Blur(k)
N,0.8658798283261803,"1
5
11"
N,0.8669527896995708,"Figure 10: Robustness and absolute transferability when we use rescale and blur as data augmenta-
tions with different parameters."
N,0.8680257510729614,"16
18
20
22
Robust Acc (%) 5 0"
N,0.869098712446352,Relative DT Acc (%)
N,0.8701716738197425,R: -0.468
N,0.871244635193133,CIFAR10 -> SVHN
N,0.8723175965665236,"LLR(
l)
-0.1
0
0.1"
N,0.8733905579399142,"24
28
32
Robust Acc (%) 5 0"
N,0.8744635193133047,R: -0.890
N,0.8755364806866953,ImageNet -> CIFAR10
N,0.8766094420600858,"LLR(
l)
-0.01
0
0.01
0.1"
N,0.8776824034334764,"15
25
35
Robust Acc (%) 10 5 0 5"
N,0.878755364806867,R: -0.994
N,0.8798283261802575,CIFAR10 -> SVHN
N,0.880901287553648,LLOT(||gs||2)
N,0.8819742489270386,"0.01
0.1
1.0"
N,0.8830472103004292,"25
27
Robust Acc (%) 0 3"
N,0.8841201716738197,R: -0.977
N,0.8851931330472103,ImageNet -> CIFAR10
N,0.8862660944206009,"LLOT(||gs||2) 1
2
5"
N,0.8873390557939914,"Figure 11: Robustness and transferability for the other model structure when we control the norm
of last layer with last-layer regularization (LLR) and last-layer orthogonal training (LLOT) with
different parameters."
N,0.8884120171673819,"D.3
DATA AUGMENTATIONS THAT VIOLATE SUFFICIENT CONDITION"
N,0.8894849785407726,"We study rotation and translation, the two data augmentations that violate the sufÔ¨Åcient condition
for regularization. The result is shown in Figure 14. We observe that these augmentations do not
have an obvious impact on domain transferability."
N,0.8905579399141631,"D.4
ROBUSTNESS EVALUATION WITH AUTOATTACK"
N,0.8916309012875536,"Besides PGD attack, we also evaluate the model robustness using the stronger AutoAttack. We
use APGD-CE, APGD-T and FAB-T as the sub-attacks in AutoAttack with 100 steps. Since the
accuracy will decrease after the stronger attack, we use a slightly smaller œµ = 0.2 to better visualize
the trend. The results are shown in Fig. 15. We can observe that the trend is similar with what we
observed before when we used the PGD attack - domain generalization is an effect of regularization
and data augmentation, and it is sometimes negatively correlated with model robustness. Also,"
N,0.8927038626609443,"20
40
60
Robust Acc (%) 20 10 0"
N,0.8937768240343348,Relative DT Acc (%)
N,0.8948497854077253,R: -0.832
N,0.8959227467811158,CIFAR10 -> SVHN
N,0.8969957081545065,"JR(
j)
0
10
100
1000"
N,0.898068669527897,"10
20
Robust Acc (%) 0 10 20 30"
N,0.8991416309012875,R: -0.607
N,0.9002145922746781,CIFAR10 -> SVHN
N,0.9012875536480687,"WD(
w)
0.0005
0.001
0.005
0.01"
N,0.9023605150214592,"10
15
20
25
Robust Acc (%) 0 5 10"
N,0.9034334763948498,R: -0.941
N,0.9045064377682404,ImageNet -> CIFAR10
N,0.9055793991416309,"WD(
w)
0.0001
0.0005
0.001"
N,0.9066523605150214,"Figure 12: Robustness and transferability for the other model structure when we regularize the fea-
ture extractor with Jacobian Regularization (JR) and weight decay (WD) with different parameters."
N,0.907725321888412,Under review as a conference paper at ICLR 2022
N,0.9087982832618026,"20
30
40
50
Robust Acc (%) 0 5 10 15"
N,0.9098712446351931,Relative DT Acc (%)
N,0.9109442060085837,R: 0.358
N,0.9120171673819742,CIFAR10 -> SVHN
N,0.9130901287553648,Gauss( )
N,0.9141630901287554,"0
0.05
0.25
1.0"
N,0.9152360515021459,"20
30
40
Robust Acc (%) 0 20 40 60"
N,0.9163090128755365,R: -0.505
N,0.9173819742489271,ImageNet -> CIFAR10
N,0.9184549356223176,Gauss( )
N,0.9195278969957081,"0
0.05
0.25"
N,0.9206008583690987,"20
30
40
Robust Acc (%) 5 0 5"
N,0.9216738197424893,R: 0.776
N,0.9227467811158798,CIFAR10 -> SVHN
N,0.9238197424892703,"Pos(b) 1
4
8"
N,0.924892703862661,"20
30
40
Robust Acc (%) 0 2 4"
N,0.9259656652360515,R: 0.472
N,0.927038626609442,ImageNet -> CIFAR10
N,0.9281115879828327,"Pos(b) 1
4
8"
N,0.9291845493562232,"Figure 13: Robustness and transferability for the other model structure when we use Gaussian noise
(Gauss) and posterize (Pos) as data augmentations with different parameters."
N,0.9302575107296137,"20
25
Robust Acc (%) 0 5"
N,0.9313304721030042,Relative DT Acc (%)
N,0.9324034334763949,R: 0.012
N,0.9334763948497854,CIFAR10 -> SVHN
N,0.9345493562231759,Rotate( )
N,0.9356223175965666,"0
15
45"
N,0.9366952789699571,"20
25
Robust Acc (%) 0 5"
N,0.9377682403433476,R: 0.978
N,0.9388412017167382,ImageNet -> CIFAR10
N,0.9399141630901288,Rotate( )
N,0.9409871244635193,"0
15
45"
N,0.9420600858369099,"10
15
20
Robust Acc (%) 6 3 0"
N,0.9431330472103004,R: 0.716
N,0.944206008583691,CIFAR10 -> SVHN
N,0.9452789699570815,Translate(d)
N,0.9463519313304721,"0
0.05
0.1
0.25"
N,0.9474248927038627,"17
20
23
Robust Acc (%) 3 0 3"
N,0.9484978540772532,R: 0.238
N,0.9495708154506438,ImageNet -> CIFAR10
N,0.9506437768240343,Translate(d)
N,0.9517167381974249,"0
0.05
0.1
0.25"
N,0.9527896995708155,"Figure 14: Relationship between robustness and transferability when we use rotation and translation
as data augmentations."
N,0.953862660944206,"augmentations like rotation and translation, which violates the sufÔ¨Åcient condition, do not improve
the domain generalization."
N,0.9549356223175965,Under review as a conference paper at ICLR 2022
N,0.9560085836909872,"10
15
20
Robust Acc (%) 10 5 0 5"
N,0.9570815450643777,Relative DT Acc (%)
N,0.9581545064377682,R: -0.846
N,0.9592274678111588,CIFAR10 -> SVHN
N,0.9603004291845494,"LLR(
l)
-0.1
0
0.1
1.0"
N,0.9613733905579399,"10
15
20
Robust Acc (%) 10 5 0"
N,0.9624463519313304,R: -0.947
N,0.9635193133047211,CIFAR10 -> SVHN
N,0.9645922746781116,LLOT(||gs||2)
N,0.9656652360515021,"0.01
0.1
1.0
10.0"
N,0.9667381974248928,20 30 40 50 60 70
N,0.9678111587982833,Robust Acc (%) 0 5 10 15
N,0.9688841201716738,R: 0.316
N,0.9699570815450643,CIFAR10 -> SVHN
N,0.971030042918455,"JR(
j)
0
100
1000"
N,0.9721030042918455,"5
10
Robust Acc (%) 0 20 40"
N,0.973175965665236,R: -0.724
N,0.9742489270386266,CIFAR10 -> SVHN
N,0.9753218884120172,"WD(
w)
0.0005
0.001
0.005
0.01"
N,0.9763948497854077,20 30 40 50 60 70
N,0.9774678111587983,Robust Acc (%) 0 10 20 30 40
N,0.9785407725321889,Relative DT Acc (%)
N,0.9796137339055794,R: 0.146
N,0.98068669527897,CIFAR10 -> SVHN
N,0.9817596566523605,Gauss( )
N,0.9828326180257511,"0
0.05
0.25
1.0"
N,0.9839055793991416,"20
30
40
50
Robust Acc (%) 0 5 10"
N,0.9849785407725322,R: 0.579
N,0.9860515021459227,CIFAR10 -> SVHN
N,0.9871244635193133,"Pos(b) 1
4
8"
N,0.9881974248927039,"15
20
Robust Acc (%) 0 5"
N,0.9892703862660944,R: 0.439
N,0.990343347639485,CIFAR10 -> SVHN
N,0.9914163090128756,Rotate( )
N,0.9924892703862661,"0
15
45"
N,0.9935622317596566,"8
10
12
Robust Acc (%) 6 3 0"
N,0.9946351931330472,R: 0.680
N,0.9957081545064378,CIFAR10 -> SVHN
N,0.9967811158798283,Translate(d)
N,0.9978540772532188,"0
0.05
0.1
0.25"
N,0.9989270386266095,"Figure 15: Relationship between robustness and transferability on CIFAR-10 when we use AutoAt-
tack to evaluate model robustness."
