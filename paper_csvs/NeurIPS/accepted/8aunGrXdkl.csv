Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0010638297872340426,"Classical analysis of convex and non-convex optimization methods often requires
the Lipschitz continuity of the gradient, which limits the analysis to functions
bounded by quadratics. Recent work relaxed this requirement to a non-uniform
smoothness condition with the Hessian norm bounded by an affine function of the
gradient norm, and proved convergence in the non-convex setting via gradient
clipping, assuming bounded noise.
In this paper, we further generalize this
non-uniform smoothness condition and develop a simple, yet powerful analysis
technique that bounds the gradients along the trajectory, thereby leading to stronger
results for both convex and non-convex optimization problems. In particular,
we obtain the classical convergence rates for (stochastic) gradient descent and
Nesterovâ€™s accelerated gradient method in the convex and/or non-convex setting
under this general smoothness condition. The new analysis approach does not
require gradient clipping and allows heavy-tailed noise with bounded variance in
the stochastic setting."
INTRODUCTION,0.002127659574468085,"1
Introduction"
INTRODUCTION,0.0031914893617021275,"In this paper, we study the following unconstrained optimization problem"
INTRODUCTION,0.00425531914893617,"minxâˆˆX f(x),
(1)"
INTRODUCTION,0.005319148936170213,"where X âŠ†Rd is the domain of f. Classical textbook analyses [Nemirovskij and Yudin, 1983,
Nesterov, 2003] of (1) often require the Lipschitz smoothness condition, which assumes
âˆ‡2f(x)
 â‰¤
L almost everywhere for some L â‰¥0 called the smoothness constant. This condition, however, is
rather restrictive and only satisfied by functions that are both upper and lower bounded by quadratic
functions."
INTRODUCTION,0.006382978723404255,"Recently, Zhang et al. [2019] proposed the more general (L0, L1)-smoothness condition, which
assumes
âˆ‡2f(x)
 â‰¤L0 + L1 âˆ¥âˆ‡f(x)âˆ¥for some constants L0, L1 â‰¥0, motivated by their
extensive language model experiments. This notion generalizes the standard Lipschitz smoothness
condition and also contains e.g. univariate polynomial and exponential functions. For non-convex and
(L0, L1)-smooth functions, they prove convergence of gradient descent (GD) and stochastic gradient
descent (SGD) with gradient clipping and also provide a complexity lower bound for constant-stepsize
GD/SGD without clipping. Based on these results, they claim gradient clipping or other forms of
adaptivity provably accelerate the convergence for (L0, L1)-smooth functions. Perhaps due to the"
INTRODUCTION,0.007446808510638298,âˆ—Equal contribution.
INTRODUCTION,0.00851063829787234,"lower bound, all the follow-up works under this condition that we are aware of limit their analyses to
adaptive methods. Most of these focus on non-convex functions. See Section 2 for more discussions
of related works."
INTRODUCTION,0.009574468085106383,"In this paper, we significantly generalize the (L0, L1)-smoothness condition to the â„“-smoothness
condition which assumes
âˆ‡2f(x)
 â‰¤â„“(âˆ¥âˆ‡f(x)âˆ¥) for some non-decreasing continuous function
â„“. We develop a simple, yet powerful approach, which allows us to obtain stronger results for both
convex and non-convex optimization problems when â„“is sub-quadratic (i.e., limuâ†’âˆâ„“(u)/u2 = 0)
or even more general. The â„“-smooth function class with a sub-quadratic â„“also contains e.g. univariate
rational and double exponential functions. In particular, we prove the convergence of constant-stepsize
GD/SGD and Nesterovâ€™s accelerated gradient method (NAG) in the convex or non-convex settings.
For each method and setting, we obtain the classical convergence rate, under a certain requirement of
â„“. In addition, we relax the assumption of bounded noise to the weaker one of bounded variance with
the simple SGD method. See Table 1 for a summary of our results and assumptions for each method
and setting. At first glance, our results â€œcontradictâ€ the lower bounds on constant-stepsize GD/SGD
in [Zhang et al., 2019, Wang et al., 2022]; this will be reconciled in Section 5.3."
INTRODUCTION,0.010638297872340425,"Our approach analyzes boundedness of gradients along the optimization trajectory. The idea behind
it can be informally illustrated by the following â€œcircularâ€ reasoning. On the one hand, if gradients
along the trajectory are bounded by a constant G, then the Hessian norms are bounded by the constant
â„“(G). Informally speaking, we essentially have the standard Lipschitz smoothness condition2 and
can apply classical textbook analyses to prove convergence, which implies that gradients converge to
zero. On the other hand, if gradients converge, they must be bounded, since any convergent sequence
is bounded. In other words, the bounded gradient condition implies convergence, and convergence
also implies the condition back, which forms a circular argument. If we can break this circularity of
reasoning in a rigorous way, both the bounded gradient condition and convergence are proved. In
this paper, we will show how to break the circularity using induction or contradiction arguments for
different methods and settings in Sections 4 and 5. We note that the idea of bounding gradients can
be applied to the analysis of other optimization methods, e.g., the concurrent work [Li et al., 2023] by
subset of the authors, which uses a similar idea to obtain a rigorous and improved analysis of the
Adam method [Kingma and Ba, 2014]."
INTRODUCTION,0.011702127659574468,"Contributions. In light of the above discussions, we summarize our main contributions as follows."
INTRODUCTION,0.01276595744680851,"â€¢ We generalize the standard Lipschitz smoothness and also the (L0, L1)-smoothness condition to
the â„“-smoothness condition, and develop a new approach for analyzing convergence under this
condition by bounding the gradients along the optimization trajectory.
â€¢ We prove the convergence of constant-stepsize GD/SGD/NAG in the convex and non-convex
settings, and obtain the classical rates for all of them, as summarized in Table 1."
INTRODUCTION,0.013829787234042552,"Besides the generalized smoothness condition and the new approach, our results are also novel in the
following aspects."
INTRODUCTION,0.014893617021276596,"â€¢ The convergence results of constant-stepsize methods challenge the folklore belief on the necessity
of adaptive stepsize for generalized smooth functions.
â€¢ We obtain new convergence results for GD and NAG in the convex setting under the generalized
smoothness condition.
â€¢ We relax the assumption of bounded noise to the weaker one of bounded variance of noise in the
stochastic setting with the simple SGD method."
RELATED WORK,0.015957446808510637,"2
Related work"
RELATED WORK,0.01702127659574468,"Gradient-based optimizaiton. The classical gradient-based optimization problems for the standard
Lipschitz smooth functions have been well studied for both convex [Nemirovskij and Yudin, 1983,"
RELATED WORK,0.018085106382978722,"2This statement is informal because we can only bound Hessian norms along the trajectory, rather than
almost everywhere within a convex set as in the standard Lipschitz smoothness condition. For example, even if
the Hessian norm is bounded at both xt and xt+1, it does not directly mean the Hessian norm is also bounded
over the line segment between them, which is required in classical analysis. A more formal statement will need
Lemma 3.3 presented later in the paper."
RELATED WORK,0.019148936170212766,"Table 1: Summary of the results. Ïµ denotes the sub-optimality gap of the function value in convex
settings, and the gradient norm in non-convex settings. â€œâˆ—â€ denotes optimal rates."
RELATED WORK,0.02021276595744681,"Method
Convexity
â„“-smoothness
Gradient complexity GD"
RELATED WORK,0.02127659574468085,"Strongly convex
No requirement
O(log(1/Ïµ)) (Theorem 4.3)
Convex
O(1/Ïµ) (Theorem 4.2 )"
RELATED WORK,0.022340425531914895,"Non-convex
Sub-quadratic â„“
O(1/Ïµ2)* (Theorem 5.2)"
RELATED WORK,0.023404255319148935,"Quadratic â„“
â„¦(exp. in cond #) (Theorem 5.4 )"
RELATED WORK,0.02446808510638298,"NAG
Convex
Sub-quadratic â„“
O(1/âˆšÏµ)* (Theorem 4.4 )"
RELATED WORK,0.02553191489361702,"SGD
Non-convex
Sub-quadratic â„“
O(1/Ïµ4)* (Theorem 5.3)"
RELATED WORK,0.026595744680851064,"Nesterov, 2003, dâ€™Aspremont et al., 2021] and non-convex functions. In the convex setting, the goal is
to reach an Ïµ-sub-optimal point x satisfying f(x) âˆ’infx f(x) â‰¤Ïµ. It is well known that GD achieves
the O(1/Ïµ) gradient complexity and NAG achieves the accelerated O(1/âˆšÏµ) complexity which is
optimal among all gradient-based methods. For strongly convex functions, GD and NAG achieve
the O(Îº log(1/Ïµ)) and O(âˆšÎº log(1/Ïµ)) complexity respectively, where Îº is the condition number
and the latter is again optimal. In the non-convex setting, the goal is to find an Ïµ-stationary point x
satisfying âˆ¥âˆ‡f(x)âˆ¥â‰¤Ïµ, since finding a global minimum is NP-hard in general. It is well known
that GD achieves the optimal O(1/Ïµ2) complexity which matches the lower bound in [Carmon et al.,
2017]. In the stochastic setting for unbiased stochastic gradient with bounded variance, SGD achieves
the optimal O(1/Ïµ4) complexity [Ghadimi and Lan, 2013], matching the lower bound in [Arjevani
et al., 2019]. In this paper, we obtain the classical rates in terms of Ïµ for all the above-mentioned
methods and settings, under a far more general smoothness condition."
RELATED WORK,0.027659574468085105,"Generalized smoothness. The (L0, L1)-smoothness condition proposed by Zhang et al. [2019]
was studied by many follow-up works. Under the same condition, [Zhang et al., 2020] considers
momentum in the updates and improves the constant dependency of the convergence rate for SGD with
clipping derived in [Zhang et al., 2019]. [Qian et al., 2021] studies gradient clipping in incremental
gradient methods, [Zhao et al., 2021] studies stochastic normalized gradient descent, and [Crawshaw
et al., 2022] studies a generalized SignSGD method, under the (L0, L1)-smoothess condition.
[Reisizadeh et al., 2023] studies variance reduction for (L0, L1)-smooth functions. [Chen et al.,
2023] proposes a new notion of Î±-symmetric generalized smoothness, which is roughly as general
as (L0, L1)-smoothness. [Wang et al., 2022] analyzes convergence of Adam and provides a lower
bound which shows non-adaptive SGD may diverge. In the stochastic setting, the above-mentioned
works either consider the strong assumption of bounded gradient noise or require a very large batch
size that depends on Ïµ, which essentially reduces the analysis to the deterministic setting. [Faw et al.,
2023] proposes an AdaGrad-type algorithm in order to relax the bounded noise assumption. Perhaps
due to the lower bounds in [Zhang et al., 2019, Wang et al., 2022], all the above works study methods
with an adaptive stepsize. In this and our concurrent work [Li et al., 2023], we further generalize
the smoothness condition and analyze various methods under this condition through bounding the
gradients along the trajectory."
FUNCTION CLASS,0.02872340425531915,"3
Function class"
FUNCTION CLASS,0.029787234042553193,"In this section, we discuss the function class of interest where the objective function f lies. We start
with the following two standard assumptions in the literature of unconstrained optimization, which
will be assumed throughout Sections 4 and 5 unless explicitly stated."
FUNCTION CLASS,0.030851063829787233,Assumption 1. The objective function f is differentiable and closed within its open domain X.
FUNCTION CLASS,0.031914893617021274,"Assumption 2. The objective function f is bounded from below, i.e., f âˆ—:= infxâˆˆX f(x) > âˆ’âˆ."
FUNCTION CLASS,0.03297872340425532,"A function f is said to be closed if its sub-level set {x âˆˆdom(f) | f(x) â‰¤a} is closed for
each a âˆˆR. A continuous function f with an open domain is closed if and only f(x) tends to
positive infinity when x approaches the boundary of its domain [Boyd and Vandenberghe, 2004].
Assumption 1 is necessary for our analysis to ensure that the iterates of a method with a reasonably
small stepsize stays within the domain X. Note that for X = Rd considered in most unconstrained"
FUNCTION CLASS,0.03404255319148936,"optimization papers, the assumption is trivially satisfied as all continuous functions over Rd are
closed. We consider a more general domain which may not be the whole space because that is the
case for some interesting examples in our function class of interest (see Section 3.1.3). However, it
actually brings us some additional technical difficulties especially in the stochastic setting, as we
need to make sure the iterates do not go outside of the domain."
GENERALIZED SMOOTHNESS,0.035106382978723406,"3.1
Generalized smoothness"
GENERALIZED SMOOTHNESS,0.036170212765957444,"In this section, we formally define the generalized smoothness condition, and present its properties
and examples."
DEFINITIONS,0.03723404255319149,"3.1.1
Definitions"
DEFINITIONS,0.03829787234042553,"Definitions 1 and 2 below are two equivalent ways of stating the definition, where we use B(x, R) to
denote the Euclidean ball with radius R centered at x."
DEFINITIONS,0.039361702127659576,"Definition 1 (â„“-smoothness). A real-valued differentiable function f : X â†’R is â„“-smooth for some
non-decreasing continuous function â„“: [0, +âˆ) â†’(0, +âˆ) if
âˆ‡2f(x)
 â‰¤â„“(âˆ¥âˆ‡f(x)âˆ¥) almost
everywhere (with respect to the Lebesgue measure) in X."
DEFINITIONS,0.04042553191489362,"Remark 3.1. Definition 1 reduces to the classical L-smoothness when â„“â‰¡L is a constant function. It
reduces to the (L0, L1)-smoothness proposed in [Zhang et al., 2019] when â„“(u) = L0 + L1u is an
affine function.
Definition 2 ((r, â„“)-smoothness). A real-valued differentiable function f : X â†’R is (r, â„“)-smooth
for continuous functions r, â„“: [0, +âˆ) â†’(0, +âˆ) where â„“is non-decreasing and r is non-increasing,
if it satisfies 1) for any x âˆˆX, B(x, r(âˆ¥âˆ‡f(x)âˆ¥)) âŠ†X, and 2) for any x1, x2 âˆˆB(x, r(âˆ¥âˆ‡f(x)âˆ¥)),
âˆ¥âˆ‡f(x1) âˆ’âˆ‡f(x2)âˆ¥â‰¤â„“(âˆ¥âˆ‡f(x)âˆ¥) Â· âˆ¥x1 âˆ’x2âˆ¥."
DEFINITIONS,0.04148936170212766,"The requirements that â„“is non-decreasing and r is non-increasing do not cause much loss in generality.
If these conditions are not satisfied, one can replace â„“and r with the non-increasing function
Ëœr(u) := inf0â‰¤vâ‰¤u r(v) â‰¤r(u) and non-decreasing function Ëœâ„“(u) := sup0â‰¤vâ‰¤u â„“(v) â‰¥â„“(u) in
Definitions 1 and 2. Then the only requirement is Ëœr > 0 and Ëœâ„“< âˆ."
DEFINITIONS,0.0425531914893617,"Next, we prove that the above two definitions are equivalent in the following proposition, whose
proof is involved and deferred to Appendix A.2."
DEFINITIONS,0.043617021276595745,"Proposition 3.2. An (r, â„“)-smooth function is â„“-smooth; and an â„“-smooth function satisfying Assump-
tion 1 is (r, m)-smooth where m(u) := â„“(u + a) and r(u) := a/m(u) for any a > 0."
DEFINITIONS,0.04468085106382979,"The condition in Definition 1 is simple and one can easily check whether it is satisfied for a given
example function. On the other hand, Definition 2 is a local Lipschitz condition on the gradient that
is harder to verify. However, it is useful for deriving several useful properties in the next section."
PROPERTIES,0.045744680851063826,"3.1.2
Properties"
PROPERTIES,0.04680851063829787,"First, we provide the following lemma which is very useful in our analyses of all the methods
considered in this paper. Its proof is deferred to Appendix A.3."
PROPERTIES,0.047872340425531915,"Lemma 3.3. If f is (r, â„“)-smooth, for any x âˆˆX satisfying âˆ¥âˆ‡f(x)âˆ¥â‰¤G, we have 1) B(x, r(G)) âŠ†
X, and 2) for any x1, x2 âˆˆB(x, r(G)),"
PROPERTIES,0.04893617021276596,"âˆ¥âˆ‡f(x1)âˆ’âˆ‡f(x2)âˆ¥â‰¤L âˆ¥x1âˆ’x2âˆ¥,
f(x1)â‰¤f(x2)+

âˆ‡f(x2), x1âˆ’x2

+ L"
PROPERTIES,0.05,"2 âˆ¥x1âˆ’x2âˆ¥2 ,
(2)"
PROPERTIES,0.05106382978723404,"where L := â„“(G) is the effective smoothness constant.
Remark 3.4. Since we have shown the equivalence between â„“-smoothness and (r, â„“)-smoothness,
Lemma 3.3 also applies to â„“-smooth functions, for which we have L = â„“(2G) and r(G) = G/L if
choosing a = G in Proposition 3.2."
PROPERTIES,0.052127659574468084,"Lemma 3.3 states that, if the gradient at x is bounded by some constant G, then within its
neighborhood with a constant radius, we can obtain (2), the same inequalities that were derived in the
textbook analysis [Nesterov, 2003] under the standard Lipschitz smoothness condition. With (2), the
analysis for generalized smoothness is not much harder than that for standard smoothness. Since we"
PROPERTIES,0.05319148936170213,"Table 2: Examples of univariate (Ï, L0, LÏ) smooth functions for different Ïs. The parameters a, b, p
are real numbers (not necessarily integers) satisfying a, b > 1 and p < 1 or p â‰¥2. We use 1+ to
denote any real number slightly larger than 1."
PROPERTIES,0.05425531914893617,"Ï
0
1
1
1+
1.5
2
pâˆ’2
pâˆ’1
Example Functions
Quadratic
Polynomial
ax
a(bx)
Rational
Logarithmic
xp"
PROPERTIES,0.05531914893617021,"mostly choose x = x2 = xt and x1 = xt+1 in the analysis, in order to apply Lemma 3.3, we need
two conditions: âˆ¥âˆ‡f(xt)âˆ¥â‰¤G and âˆ¥xt+1 âˆ’xtâˆ¥â‰¤r(G) for some constant G. The latter is usually
directly implied by the former for most deterministic methods with a small enough stepsize, and the
former can be obtained with our new approach that bounds the gradients along the trajectory."
PROPERTIES,0.05638297872340425,"With Lemma 3.3, we can derive the following useful lemma which is the reverse direction of a
generalized Polyak-Lojasiewicz (PL) inequality, whose proof is deferred to Appendix A.3."
PROPERTIES,0.0574468085106383,"Lemma 3.5. If f is â„“-smooth, then âˆ¥âˆ‡f(x)âˆ¥2 â‰¤2â„“(2 âˆ¥âˆ‡f(x)âˆ¥) Â· (f(x) âˆ’f âˆ—) for any x âˆˆX."
PROPERTIES,0.05851063829787234,"Lemma 3.5 provides an inequality involving the gradient norm and the sub-optimality gap.
For example, when â„“(u) = uÏ for some 0 â‰¤Ï < 2, this lemma suggests âˆ¥âˆ‡f(x)âˆ¥â‰¤
O
 
(f(x) âˆ’f âˆ—)1/(2âˆ’Ï)
, which means the gradient norm is bounded whenever the function value is
bounded. The following corollary provides a more formal statement for general sub-quadratic â„“(i.e.,
limuâ†’âˆâ„“(u)/u2 = 0), and we defer its proof to Appendix A.3."
PROPERTIES,0.059574468085106386,"Corollary 3.6. Suppose f is â„“-smooth where â„“is sub-quadratic. If f(x) âˆ’f âˆ—â‰¤F for some x âˆˆX
and F â‰¥0, denoting G := sup{u â‰¥0 | u2 â‰¤2â„“(2u) Â· F}, then they satisfy G2 = 2â„“(2G) Â· F and
we have âˆ¥âˆ‡f(x)âˆ¥â‰¤G < âˆ."
PROPERTIES,0.06063829787234042,"Therefore, in order to bound the gradients along the trajectory as we discussed below Lemma 3.3, it
suffices to bound the function values, which is usually easier."
EXAMPLES,0.06170212765957447,"3.1.3
Examples"
EXAMPLES,0.0627659574468085,"The most important subset of â„“-smooth (or (r, â„“)-smooth) functions are those with a polynomial â„“,
and can be characterized by the (Ï, L0, LÏ)-smooth function class defined below."
EXAMPLES,0.06382978723404255,"Definition 3 ((Ï, L0, LÏ)-smoothness). A real-valued differentiable function f is (Ï, L0, LÏ)-smooth
for constants Ï, L0, LÏ â‰¥0 if it is â„“-smooth with â„“(u) = L0 + LÏuÏ."
EXAMPLES,0.06489361702127659,"Definition 3 reduces to the standard Lipschitz smoothness condition when Ï = 0 or LÏ = 0
and to the (L0, L1)-smoothness proposed in [Zhang et al., 2019] when Ï = 1. We list several
univariate examples of (Ï, L0, LÏ)-smooth functions for different Ïs in Table 2 with their rigorous
justifications in Appendix A.1. Note that when x goes to infinity, polynomial and exponential
functions corresponding to Ï = 1 grow much faster than quadratic functions corresponding to Ï = 0 .
Rational and logarithmic functions for Ï > 1 grow even faster as they can blow up to infinity near
finite points. Note that the domains of such functions are not Rd, which is why we consider the more
general Assumption 1 instead of simply assuming X = Rd."
EXAMPLES,0.06595744680851064,"Aside from logarithmic functions, the (2, L0, L2)-smooth function class also includes other univariate
self-concordant functions. This is an important function class in the analysis of Interior Point Methods
and coordinate-free analysis of the Newton method [Nesterov, 2003]. More specifically, a convex
function h : R â†’R is self-concordant if |hâ€²â€²â€²(x)| â‰¤2hâ€²â€²(x)3/2 for all x âˆˆR. Formally, we have the
following proposition whose proof is deferred to Appendix A.1."
EXAMPLES,0.06702127659574468,"Proposition 3.7. If h : R â†’R is a self-concordant function satisfying hâ€²â€²(x) > 0 over the interval
(a, b), then h restricted on (a, b) is (2, L0, 2)-smooth for some L0 > 0."
CONVEX SETTING,0.06808510638297872,"4
Convex setting"
CONVEX SETTING,0.06914893617021277,"In this section, we present the convergence results of gradient descent (GD) and Nesterovâ€™s accelerated
gradient method (NAG) in the convex setting. Formally, we define convexity as follows."
CONVEX SETTING,0.07021276595744681,"Definition 4. A real-valued differentiable function f : X â†’R is Âµ-strongly-convex for Âµ â‰¥0 if X
is a convex set and f(y) âˆ’f(x) â‰¥

âˆ‡f(x), y âˆ’x

+ Âµ"
CONVEX SETTING,0.07127659574468086,"2 âˆ¥y âˆ’xâˆ¥2 for any x, y âˆˆX. A function is
convex if it is Âµ-strongly-convex with Âµ = 0."
CONVEX SETTING,0.07234042553191489,"We assume the existence of a global optimal point xâˆ—throughout this section, as in the following
assumption. However, we want to note that, for gradient descent, this assumption is just for simplicity
rather than necessary.
Assumption 3. There exists a point xâˆ—âˆˆX such that f(xâˆ—) = f âˆ—= infxâˆˆX f(x)."
GRADIENT DESCENT,0.07340425531914893,"4.1
Gradient descent"
GRADIENT DESCENT,0.07446808510638298,The gradient descent method with a constant stepsize Î· is defined via the following update rule
GRADIENT DESCENT,0.07553191489361702,"xt+1 = xt âˆ’Î·âˆ‡f(xt).
(3)"
GRADIENT DESCENT,0.07659574468085106,"As discussed below Lemma 3.3, the key in the convergence analysis is to show âˆ¥âˆ‡f(xt)âˆ¥â‰¤G for
all t â‰¥0 and some constant G. We will prove it by induction relying on the following lemma whose
proof is deferred to Appendix B.
Lemma 4.1. For any x âˆˆX satisfying âˆ¥âˆ‡f(x)âˆ¥â‰¤G, define x+ := x âˆ’Î·âˆ‡f(x). If f is convex"
GRADIENT DESCENT,0.07765957446808511,"and (r, â„“)-smooth, and Î· â‰¤min
n
2
â„“(G), r(G)"
"G
O",0.07872340425531915,"2G
o
, we have x+ âˆˆX and âˆ¥âˆ‡f(x+)âˆ¥â‰¤âˆ¥âˆ‡f(x)âˆ¥â‰¤G."
"G
O",0.0797872340425532,"Lemma 4.1 suggests that for gradient descent (3) with a small enough stepsize, if the gradient norm
at xt is bounded by G, then we have âˆ¥âˆ‡f(xt+1)âˆ¥â‰¤âˆ¥âˆ‡f(xt)âˆ¥â‰¤G, i.e., the gradient norm is also
bounded by G at t+1. In other words, the gradient norm is indeed a non-increasing potential function
for gradient descent in the convex setting. With a standard induction argument, we can show that
âˆ¥âˆ‡f(xt)âˆ¥â‰¤âˆ¥âˆ‡f(x0)âˆ¥for all t â‰¥0. As discussed below Lemma 3.3, then we can basically apply
the classical analysis to obtain the convergence guarantee in the convex setting as in the following
theorem, whose proof is deferred to Appendix B."
"G
O",0.08085106382978724,"Theorem 4.2. Suppose f is convex and (r, â„“)-smooth. Denote G := âˆ¥âˆ‡f(x0)âˆ¥and L := â„“(G), then"
"G
O",0.08191489361702127,"the iterates generated by (3) with Î· â‰¤min
n
1
L, r(G)"
"G
O",0.08297872340425531,"2G
o
satisfy âˆ¥âˆ‡f(xt)âˆ¥â‰¤G for all t â‰¥0 and"
"G
O",0.08404255319148936,"f(xT ) âˆ’f âˆ—â‰¤âˆ¥x0 âˆ’xâˆ—âˆ¥2 2Î·T
."
"G
O",0.0851063829787234,"Since Î· is a constant independent of Ïµ or T, Theorem 4.2 achieves the classical O(1/T) rate, or
O(1/Ïµ) gradient complexity to achieve an Ïµ-sub-optimal point, under the generalized smoothness
condition. Since strongly convex functions are a subset of convex functions, Lemma 4.1 still holds
for them. Then we immediately obtain the following result in the strongly convex setting, whose
proof is deferred to Appendix B.
Theorem 4.3. Suppose f is Âµ-strongly-convex and (r, â„“)-smooth. Denote G := âˆ¥âˆ‡f(x0)âˆ¥and"
"G
O",0.08617021276595745,"L := â„“(G), then the iterates generated by (3) with Î· â‰¤min
n
1
L, r(G)"
"G
O",0.08723404255319149,"2G
o
satisfy âˆ¥âˆ‡f(xt)âˆ¥â‰¤G for
all t â‰¥0 and"
"G
O",0.08829787234042553,"f(xT ) âˆ’f âˆ—â‰¤
Âµ(1 âˆ’Î·Âµ)T"
"G
O",0.08936170212765958,2(1 âˆ’(1 âˆ’Î·Âµ)T ) âˆ¥x0 âˆ’xâˆ—âˆ¥2 .
"G
O",0.09042553191489362,"Theorem 4.3 gives a linear convergence rate and the O((Î·Âµ)âˆ’1 log(1/Ïµ)) gradient complexity to
achieve an Ïµ-sub-optimal point. Note that for â„“-smooth functions, we have r(G) G
= 1"
"G
O",0.09148936170212765,"L (see Remark 3.4),
which means we can choose Î· =
1
2L. Then we obtain the O(Îº log(1/Ïµ)) rate, where Îº := L/Âµ is
the local condition number around the initial point x0. For standard Lipschitz smooth functions, it
reduces to the classical rate of gradient descent."
"G
O",0.0925531914893617,"4.2
Nesterovâ€™s accelerated gradient method"
"G
O",0.09361702127659574,"In the case of convex and standard Lipschitz smooth functions, it is well known that Nesterovâ€™s
accelerated gradient method (NAG) achieves the optimal O(1/T 2) rate. In this section, we show that"
"G
O",0.09468085106382979,Algorithm 1: Nesterovâ€™s Accelerated Gradient Method (NAG)
"G
O",0.09574468085106383,"input A convex and â„“-smooth function f, stepsize Î·, initial point x0"
"G
O",0.09680851063829787,"1: Initialize z0 = x0, B0 = 0, and A0 = 1/Î·.
2: for t = 0, ... do
3:
Bt+1 = Bt + 1"
"G
O",0.09787234042553192,"2
 
1 + âˆš4Bt + 1
"
"G
O",0.09893617021276596,"4:
At+1 = Bt+1 + 1/Î·
5:
yt = xt + (1 âˆ’At/At+1)(zt âˆ’xt)
6:
xt+1 = yt âˆ’Î·âˆ‡f(yt)
7:
zt+1 = zt âˆ’Î·(At+1 âˆ’At)âˆ‡f(yt)
8: end for"
"G
O",0.1,"under the â„“-smoothness condition with a sub-quadratic â„“, the optimal O(1/T 2) rate can be achieved
by a slightly modified version of NAG shown in Algorithm 1, the only difference between which
and the classical NAG is that the latter directly sets At+1 = Bt+1 in Line 4. Formally, we have the
following theorem, whose proof is deferred to Appendix C."
"G
O",0.10106382978723404,Theorem 4.4. Suppose f is convex and â„“-smooth where â„“is sub-quadratic. Then there always exists
"G
O",0.10212765957446808,"a constant G satisfying G â‰¥max

8
q"
"G
O",0.10319148936170212,"â„“(2G)((f(x0) âˆ’f âˆ—) + âˆ¥x0 âˆ’xâˆ—âˆ¥2), âˆ¥âˆ‡f(x0)âˆ¥

. Denote"
"G
O",0.10425531914893617,"L := â„“(2G) and choose Î· â‰¤min

1
16L2 ,
1
2L
	
. The iterates generated by Algorithm 1 satisfy"
"G
O",0.10531914893617021,f(xT ) âˆ’f âˆ—â‰¤4(f(x0) âˆ’f âˆ—) + 4 âˆ¥x0 âˆ’xâˆ—âˆ¥2
"G
O",0.10638297872340426,"Î·T 2 + 4
."
"G
O",0.1074468085106383,"It is easy to note that Theorem 4.4 achieves the accelerated O(1/T 2) convergence rate, or
equivalently the O(1/âˆšÏµ) gradient complexity to find an Ïµ-sub-optimal point, which is optimal
among gradient-based methods [Nesterov, 2003]."
"G
O",0.10851063829787234,"In order to prove Theorem 4.4, we also use induction to show the gradients along the trajectory of
Algorithm 1 are bounded by G. However, unlike gradient descent, the gradient norm is no longer
a potential function or monotonically non-increasing, which makes the induction analysis more
challenging. Suppose that we have shown âˆ¥âˆ‡f(ys)âˆ¥â‰¤G for s < t. To complete the induction,
it suffices to prove âˆ¥âˆ‡f(yt)âˆ¥â‰¤G. Since xt = ytâˆ’1 âˆ’Î·âˆ‡f(ytâˆ’1) is a gradient descent step by
Line 6 of Algorithm 1, Lemma 4.1 directly shows âˆ¥âˆ‡f(xt)âˆ¥â‰¤G. In order to also bound âˆ¥âˆ‡f(yt)âˆ¥,
we try to control âˆ¥yt âˆ’xtâˆ¥, which is the most challenging part of our proof. Since yt âˆ’xt can be
expressed as a linear combination of past gradients {âˆ‡f(ys)}s<t, it might grow linearly with t if we
simply apply âˆ¥âˆ‡f(ys)âˆ¥â‰¤G for s < t. Fortunately, Lemma 3.5 allows us to control the gradient
norm with the function value. Thus if the function value is decreasing sufficiently fast, which can be
shown by following the standard Lyapunov analysis of NAG, we are able to obtain a good enough
bound on âˆ¥âˆ‡f(ys)âˆ¥for s < t, which allows us to control âˆ¥yt âˆ’xtâˆ¥. We defer the detailed proof to
Appendix C."
"G
O",0.10957446808510639,"Note that Theorem 4.4 requires a smaller stepsize Î· = O(1/L2), compared to the classical O(1/L)
stepsize for standard Lipschitz smooth functions. The reason is we require a small enough stepsize to
get a good enough bound on âˆ¥yt âˆ’xtâˆ¥. However, if the function is further assumed to be â„“-smooth
with a sub-linear â„“, the requirement of stepsize can be relaxed to Î· = O(1/L), similar to the classical
requirement. See Appendix C for the details."
"G
O",0.11063829787234042,"In the strongly convex setting, we can also prove convergence of NAG with different {At}tâ‰¥0
parameters when f is â„“-smooth with a sub-quadratic â„“, or (Ï, L0, LÏ)-smooth with Ï < 2. The rate
can be further improved when Ï becomes smaller. However, since the constants G and L are different
for GD and NAG, it is not clear whether the rate of NAG is faster than that of GD in the strongly
convex setting. We will present the detailed result and analysis in Appendix D."
NON-CONVEX SETTING,0.11170212765957446,"5
Non-convex setting"
NON-CONVEX SETTING,0.1127659574468085,"In this section, we present convergence results of gradient descent (GD) and stochastic gradient
descent (SGD) in the non-convex setting."
GRADIENT DESCENT,0.11382978723404255,"5.1
Gradient descent"
GRADIENT DESCENT,0.1148936170212766,"Similar to the convex setting, we still want to bound the gradients along the trajectory. However,
in the non-convex setting, the gradient norm is not necessarily non-increasing. Fortunately, similar
to the classical analyses, the function value is still non-increasing and thus a potential function, as
formally shown in the following lemma, whose proof is deferred to Appendix E."
GRADIENT DESCENT,0.11595744680851064,"Lemma 5.1. Suppose f is â„“-smooth where â„“is sub-quadratic. For any given F â‰¥0, let G :=
sup

u â‰¥0 | u2 â‰¤2â„“(2u) Â· F
	
and L := â„“(2G). For any x âˆˆX satisfying f(x) âˆ’f âˆ—â‰¤F, define
x+ := x âˆ’Î·âˆ‡f(x) where Î· â‰¤2/L, we have x+ âˆˆX and f(x+) â‰¤f(x)."
GRADIENT DESCENT,0.11702127659574468,"Then using a standard induction argument, we can show f(xt) â‰¤f(x0) for all t â‰¥0. According to
Corollary 3.6, it implies bounded gradients along the trajectory. Therefore, we can show convergence
of gradient descent as in the following theorem, whose proof is deferred to Appendix E."
GRADIENT DESCENT,0.11808510638297873,"Theorem
5.2.
Suppose
f
is
â„“-smooth
where
â„“
is
sub-quadratic.
Let
G
:=
sup

u â‰¥0 | u2 â‰¤2â„“(2u) Â· (f(x0) âˆ’f âˆ—)
	
and L := â„“(2G).
If Î· â‰¤1/L, the iterates gener-
ated by (3) satisfy âˆ¥âˆ‡f(xt)âˆ¥â‰¤G for all t â‰¥0 and"
T,0.11914893617021277,"1
T X"
T,0.1202127659574468,"t<T
âˆ¥âˆ‡f(xt)âˆ¥2 â‰¤2(f(x0) âˆ’f âˆ—) Î·T
."
T,0.12127659574468085,"It is clear that Theorem 5.2 gives the classical O(1/Ïµ2) gradient complexity to achieve an Ïµ-stationary
point, which is optimal as it matches the lower bound in [Carmon et al., 2017]."
STOCHASTIC GRADIENT DESCENT,0.12234042553191489,"5.2
Stochastic gradient descent"
STOCHASTIC GRADIENT DESCENT,0.12340425531914893,"In this part, we present the convergence result for stochastic gradient descent defined as follows."
STOCHASTIC GRADIENT DESCENT,0.12446808510638298,"xt+1 = xt âˆ’Î·gt,
(4)"
STOCHASTIC GRADIENT DESCENT,0.125531914893617,"where gt is an estimate of the gradient âˆ‡f(xt). We consider the following standard assumption on
the gradient noise Ïµt := gt âˆ’âˆ‡f(xt)."
STOCHASTIC GRADIENT DESCENT,0.12659574468085105,"Assumption 4. Etâˆ’1[Ïµt] = 0 and Etâˆ’1
h
âˆ¥Ïµtâˆ¥2i
â‰¤Ïƒ2 for some Ïƒ â‰¥0, where Etâˆ’1 denotes the"
STOCHASTIC GRADIENT DESCENT,0.1276595744680851,expectation conditioned on {gs}s<t.
STOCHASTIC GRADIENT DESCENT,0.12872340425531914,"Under Assumption 4, we can obtain the following theorem."
STOCHASTIC GRADIENT DESCENT,0.12978723404255318,"Theorem 5.3. Suppose f is â„“-smooth where â„“is sub-quadratic. For any 0 < Î´ < 1, we denote
F := 8(f(x0) âˆ’f âˆ—+ Ïƒ)/Î´ and G := sup{u â‰¥0 | u2 â‰¤2â„“(2u) Â· F} < âˆ. Denote L := â„“(2G)"
STOCHASTIC GRADIENT DESCENT,0.13085106382978723,"and choose Î· â‰¤min
n
1
2L,
1
4G
âˆš T"
STOCHASTIC GRADIENT DESCENT,0.13191489361702127,"o
and T â‰¥
F
Î·Ïµ2 for any Ïµ > 0. Then with probability at least 1 âˆ’Î´,"
STOCHASTIC GRADIENT DESCENT,0.13297872340425532,the iterates generated by (4) satisfy âˆ¥âˆ‡f(xt)âˆ¥â‰¤G for all t < T and
T,0.13404255319148936,"1
T X"
T,0.1351063829787234,"t<T
âˆ¥âˆ‡f(xt)âˆ¥2 â‰¤Ïµ2."
T,0.13617021276595745,"As we choose Î· = O(1/
âˆš"
T,0.1372340425531915,"T), Theorem 5.3 gives the classical O(1/Ïµ4) gradient complexity, where
we ignore non-leading terms. This rate is optimal as it matches the lower bound in [Arjevani et al.,
2019]. The key to its proof is again to bound the gradients along the trajectory. However, bounding
gradients in the stochastic setting is much more challenging than in the deterministic setting, especially
with the heavy-tailed noise in Assumption 4. We briefly discuss some of the challenges as well as our
approach below and defer the detailed proof of Theorem 5.3 to Appendix F."
T,0.13829787234042554,"First, due to the existence of heavy-tailed gradient noise as considered in Assumption 4, neither
the gradient nor the function values is non-increasing. The induction analyses we have used in the
deterministic setting hardly work. In addition, to apply Lemma 3.3, we need to control the update at
each step and make sure âˆ¥xt+1 âˆ’xtâˆ¥= Î· âˆ¥gtâˆ¥â‰¤G/L. However, gt might be unbounded due to the
potentially unbounded gradient noise."
T,0.13936170212765958,"To overcome these challenges, we define the following random variable Ï„."
T,0.14042553191489363,"Ï„1 := min{t | f(xt+1) âˆ’f âˆ—> F} âˆ§T,"
T,0.14148936170212767,"Ï„2 := min

t
âˆ¥Ïµtâˆ¥>
G
5Î·L"
T,0.1425531914893617,"
âˆ§T,
(5)"
T,0.14361702127659576,"Ï„ := min{Ï„1, Ï„2},"
T,0.14468085106382977,"where we use a âˆ§b to denote min{a, b} for any a, b âˆˆR. Then at least before time Ï„, we know that
the function value and gradient noise are bounded, where the former also implies bounded gradients
according to Corollary 3.6. Therefore, it suffices to show the probability of Ï„ < T is small, which
means with a high probability, Ï„ = T and thus gradients are always bounded before T."
T,0.14574468085106382,"Since both the gradient and noise are bounded for t < Ï„, it is straightforward to bound the update
âˆ¥xt+1 âˆ’xtâˆ¥, which allows us to use Lemma 3.3 and other useful properties. However, it is still
non-trivial to upper bound E[f(xÏ„) âˆ’f âˆ—] as Ï„ is a random variable instead of a fixed time step.
Fortunately, Ï„ is a stopping time with nice properties. That is because both f(xt+1) and Ïµt =
gt âˆ’âˆ‡f(xt) only depend on {gs}sâ‰¤t, i.e., the stochastic gradients up to t. Therefore, for any fixed t,
the events {Ï„ > t} only depend on {gs}sâ‰¤t, which show Ï„ is a stopping time. Then with a careful
analysis, we are still able to obtain an upper bound on E[f(xÏ„) âˆ’f âˆ—] = O(1)."
T,0.14680851063829786,"On the other hand, Ï„ < T means either Ï„ = Ï„1 < T or Ï„ = Ï„2 < T. If Ï„ = Ï„1 < T, by its definition,
we know f(xÏ„+1) âˆ’f âˆ—> F. Roughly speaking, it also suggests f(xÏ„) âˆ’f âˆ—> F/2. If we choose
F such that it is much larger than the upper bound on E[f(xÏ„) âˆ’f âˆ—] we just obtained, by Markovâ€™s
inequality, we can show the probability of Ï„ = Ï„1 < T is small. In addition, by union bound and
Chebyshevâ€™s inequality, the probability of Ï„2 < T can also be bounded by a small constant. Therefore,
we have shown Ï„ < T. Then the rest of the analysis is not too hard following the classical analysis."
RECONCILIATION WITH EXISTING LOWER BOUNDS,0.1478723404255319,"5.3
Reconciliation with existing lower bounds"
RECONCILIATION WITH EXISTING LOWER BOUNDS,0.14893617021276595,"In this section, we reconcile our convergence results for constant-stepsize GD/SGD in the non-convex
setting with existing lower bounds in [Zhang et al., 2019] and [Wang et al., 2022], based on which
the authors claim that adaptive methods such as GD/SGD with clipping and Adam are provably faster
than non-adaptive GD/SGD. This may seem to contradict our convergence results. In fact, we show
that any gain in adaptive methods is at most by constant factors, as GD and SGD already achieve the
optimal rates in the non-convex setting."
RECONCILIATION WITH EXISTING LOWER BOUNDS,0.15,"[Zhang et al., 2019] provides both upper and lower complexity bounds for constant-stepsize GD for
(L0, L1)-smooth functions, and shows that its complexity is O(MÏµâˆ’2), where"
RECONCILIATION WITH EXISTING LOWER BOUNDS,0.15106382978723404,M := sup{âˆ¥âˆ‡f(x)âˆ¥| f(x) â‰¤f(x0)}
RECONCILIATION WITH EXISTING LOWER BOUNDS,0.15212765957446808,"is the supremum gradient norm below the level set of the initial function value. If M is very large, then
the O(MÏµâˆ’2) complexity can be viewed as a negative result, and as evidence that constant-stepsize
GD can be slower than GD with gradient clipping, since in the latter case, they obtain the O(Ïµâˆ’2)
complexity without M. However, based on our Corollary 3.6, their M can be actually bounded by
our G, which is a constant. Therefore, the gain in adaptive methods is at most by constant factors."
RECONCILIATION WITH EXISTING LOWER BOUNDS,0.15319148936170213,"[Wang et al., 2022] further provides a lower bound which shows non-adaptive GD may diverge for
some examples. However, their counter-example does not allow the stepsize to depend on the initial
sub-optimality gap. In contrast, our stepsize Î· depends on the effective smoothness constant L, which
depends on the initial sub-optimality gap through G. Therefore, there is no contradiction here either.
We should point out that in the practice of training neural networks, the stepsize is usually tuned after
fixing the loss function and initialization, so it does depend on the problem instance and initialization."
LOWER BOUND,0.15425531914893617,"5.4
Lower bound"
LOWER BOUND,0.15531914893617021,"For (Ï, L0, LÏ)-smooth functions with Ï < 2, it is easy to verify that the constant G in both
Theorem 5.2 and Theorem 5.3 is a polynomial function of problem-dependent parameters like
L0, LÏ, f(x0) âˆ’f âˆ—, Ïƒ, etc. In other words, GD and SGD are provably efficient methods in the
non-convex setting for Ï < 2. In this section, we show that the requirement of Ï < 2 is necessary in
the non-convex setting with the lower bound for GD in the following Theorem 5.4, whose proof is
deferred in Appendix G. Since SGD reduces to GD when there is no gradient noise, it is also a lower
bound for SGD."
LOWER BOUND,0.15638297872340426,"Theorem 5.4. Given L0, L2, G0, âˆ†0 > 0 satisfying L2âˆ†0 â‰¥10, for any Î· â‰¥0, there exists a
(2, L0, L2)-smooth function f that satisfies Assumptions 1 and 2, and initial point x0 that satisfies
âˆ¥âˆ‡f(x0)âˆ¥â‰¤G0 and f(x0) âˆ’f âˆ—â‰¤âˆ†0, such that gradient descent with stepsize Î· (3) either cannot
reach a 1-stationary point or takes at least exp(L2âˆ†0/8)/6 steps to reach a 1-stationary point."
CONCLUSION,0.1574468085106383,"6
Conclusion"
CONCLUSION,0.15851063829787235,"In
this
paper,
we
generalize
the
standard
Lipschitz
smoothness
as
well
as
the
(L0, L1)-smoothness [Zhang et al., 2020] conditions to the â„“-smoothness condition, and
develop a new approach for analyzing the convergence under this condition. The approach uses
different techniques for several methods and settings to bound the gradient along the optimization
trajectory, which allows us to obtain stronger results for both convex and non-convex problems. We
obtain the classical rates for GD/SGD/NAG methods in the convex and/or non-convex setting. Our
results challenge the folklore belief on the necessity of adaptive methods for generalized smooth
functions."
CONCLUSION,0.1595744680851064,"There are several interesting future directions following this work. First, the â„“-smoothness can perhaps
be further generalized by allowing â„“to also depend on potential functions in each setting, besides the
gradient norm. In addition, it would also be interesting to see if the techniques of bounding gradients
along the trajectory that we have developed in this and the concurrent work [Li et al., 2023] can be
further generalized to other methods and problems and to see whether more efficient algorithms can
be obtained. Finally, although we justified the necessity of the requirement of â„“-smoothness with a
sub-quadratic â„“in the non-convex setting, it is not clear whether it is also necessary for NAG in the
convex setting, another interesting open problem."
CONCLUSION,0.16063829787234044,Acknowledgments
CONCLUSION,0.16170212765957448,"This work was supported, in part, by the MIT-IBM Watson AI Lab and ONR Grants
N00014-20-1-2394 and N00014-23-1-2299. We also acknowledge support from DOE under grant
DE-SC0022199, and NSF through awards DMS-2031883, DMS-1953181, and DMS-2022448
(TRIPODS program)."
REFERENCES,0.16276595744680852,References
REFERENCES,0.16382978723404254,"Yossi Arjevani, Yair Carmon, John C. Duchi, Dylan J. Foster, Nathan Srebro, and Blake E. Woodworth.
Lower bounds for non-convex stochastic optimization. Mathematical Programming, 199:165 â€“
214, 2019."
REFERENCES,0.16489361702127658,"Stephen P Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004."
REFERENCES,0.16595744680851063,"Yair Carmon, John C. Duchi, Oliver Hinder, and Aaron Sidford. Lower bounds for finding stationary
points i. Mathematical Programming, pages 1â€“50, 2017."
REFERENCES,0.16702127659574467,"Ziyi Chen, Yi Zhou, Yingbin Liang, and Zhaosong Lu. Generalized-smooth nonconvex optimization
is as efficient as smooth nonconvex optimization. arXiv preprint arXiv:2303.02854, 2023."
REFERENCES,0.16808510638297872,"Michael Crawshaw, Mingrui Liu, Francesco Orabona, Wei Zhang, and Zhenxun Zhuang. Robustness
to unbounded smoothness of generalized signsgd. Advances in Neural Information Processing
Systems, 35:9955â€“9968, 2022."
REFERENCES,0.16914893617021276,"Alexandre dâ€™Aspremont, Damien Scieur, and Adrien Taylor. Acceleration methods. Foundations and
TrendsÂ® in Optimization, 5(1-2):1â€“245, 2021. ISSN 2167-3888. doi: 10.1561/2400000036. URL
http://dx.doi.org/10.1561/2400000036."
REFERENCES,0.1702127659574468,"Matthew Faw, Litu Rout, Constantine Caramanis, and Sanjay Shakkottai.
Beyond uniform
smoothness: A stopped analysis of adaptive sgd. ArXiv, abs/2302.06570, 2023."
REFERENCES,0.17127659574468085,"Saeed Ghadimi and Guanghui Lan. Stochastic first-and zeroth-order methods for nonconvex stochastic
programming. SIAM Journal on Optimization, 23(4):2341â€“2368, 2013."
REFERENCES,0.1723404255319149,"Diederik P. Kingma and Jimmy Ba.
Adam: A method for stochastic optimization.
CoRR,
abs/1412.6980, 2014."
REFERENCES,0.17340425531914894,"Haochuan Li, Ali Jadbabaie, and Alexander Rakhlin. Convergence of adam under relaxed assumptions.
arXiv preprint arXiv:2304.13972, 2023."
REFERENCES,0.17446808510638298,"Arkadij SemenoviË‡c Nemirovskij and David Borisovich Yudin. Problem complexity and method
efficiency in optimization. Wiley-Interscience, 1983."
REFERENCES,0.17553191489361702,"Yurii Nesterov. Introductory lectures on convex optimization: A basic course, volume 87. Springer
Science & Business Media, 2003."
REFERENCES,0.17659574468085107,"Jiang Qian, Yuren Wu, Bojin Zhuang, Shaojun Wang, and Jing Xiao. Understanding gradient
clipping in incremental gradient methods. In International Conference on Artificial Intelligence
and Statistics, 2021."
REFERENCES,0.1776595744680851,"Amirhossein Reisizadeh, Haochuan Li, Subhro Das, and Ali Jadbabaie. Variance-reduced clipping
for non-convex optimization. ArXiv, abs/2303.00883, 2023."
REFERENCES,0.17872340425531916,"Bohan Wang, Yushun Zhang, Huishuai Zhang, Qi Meng, Zhi-Ming Ma, Tie-Yan Liu, and Wei Chen.
Provable adaptivity in adam. arXiv preprint arXiv:2208.09900, 2022."
REFERENCES,0.1797872340425532,"Bohang Zhang, Jikai Jin, Cong Fang, and Liwei Wang. Improved analysis of clipping algorithms for
non-convex optimization. ArXiv, abs/2010.02519, 2020."
REFERENCES,0.18085106382978725,"Jingzhao Zhang, Tianxing He, Suvrit Sra, and Ali Jadbabaie. Why gradient clipping accelerates
training: A theoretical justification for adaptivity. arXiv preprint arXiv:1905.11881, 2019."
REFERENCES,0.1819148936170213,"Shen-Yi Zhao, Yin-Peng Xie, and Wu-Jun Li. On the convergence and improvement of stochastic
normalized gradient descent. Science China Information Sciences, 64, 2021."
REFERENCES,0.1829787234042553,"A
Proofs related to generalized smoothness"
REFERENCES,0.18404255319148935,"In this section, we provide the proofs of propositions and lemmas related to the generalized
smoothness condition in Definition 1 or 2. First, in Appendix A.1, we justify the examples we
discussed in Section 3. Next, we provide the detailed proof of Proposition 3.2 in Appendix A.2.
Finally, we provide the proofs of the useful properties of generalized smoothness in Appendix A.3,
including Lemma 3.3, Lemma 3.5, and Corollary 3.6 stated in Section 3.1.2."
REFERENCES,0.1851063829787234,"A.1
Justification of examples in Section 3"
REFERENCES,0.18617021276595744,"In this section, we justify the univariate examples of (Ï, L0, LÏ)-smooth functions listed in Table 2
and also provide the proof of Propositions 3.7."
REFERENCES,0.18723404255319148,"First, it is well-known that all quadratic functions have bounded Hessian and are Lipschitz smooth,
corresponding to Ï = 0. Next, [Zhang et al., 2019, Lemma 2] shows that any univariate polynomial
is (L0, L1)-smooth, corresponding to Ï = 1. Then, regarding the exponential function f(x) = ax
where a > 1, we have f â€²(x) = log(a)ax and f â€²â€²(x) = log(a)2ax = log(a)f â€²(x), which implies
f is (1, 0, log(a))-smooth. Similarly, by standard calculations, it is straight forward to verify that
logarithmic functions and xp, p Ì¸= 1 are also (Ï, L0, LÏ)-smooth with Ï = 2 and Ï = pâˆ’2"
REFERENCES,0.18829787234042553,"pâˆ’1 respectively.
So far we have justified all the examples in Table 2 except double exponential functions a(bx) and
rational functions, which will be justified rigorously by the two propositions below."
REFERENCES,0.18936170212765957,"First, for double exponential functions in the form of f(x) = a(bx) where a, b > 1, we have the
following proposition, which shows f is (Ï, L0, LÏ)-smooth for any Ï > 1."
REFERENCES,0.19042553191489361,"Proposition A.1. For any Ï > 1, the double exponential function f(x) = a(bx), where a, b > 1, is
(Ï, L0, LÏ)-smooth for some L0, LÏ â‰¥0. However, it is not necessarily (L0, L1)-smooth for any
L0, L1 â‰¥0."
REFERENCES,0.19148936170212766,"Proof of Proposition A.1. By standard calculations, we can obtain"
REFERENCES,0.1925531914893617,"f â€²(x) = log(a) log(b) bxa(bx),
f â€²â€²(x) = log(b)(log(a)bx + 1) Â· f â€²(x).
(6)"
REFERENCES,0.19361702127659575,"Note that if Ï > 1,"
REFERENCES,0.1946808510638298,"lim
xâ†’+âˆ
|f â€²(x)|Ï"
REFERENCES,0.19574468085106383,"|f â€²â€²(x)| =
lim
xâ†’+âˆ
|f â€²(x)|Ïâˆ’1"
REFERENCES,0.19680851063829788,"log(b)(log(a)bx + 1) =
lim
yâ†’+âˆ
(log(a) log(b)y)Ïâˆ’1 a(Ïâˆ’1)y"
REFERENCES,0.19787234042553192,"log(b)(log(a)y + 1)
= âˆ,"
REFERENCES,0.19893617021276597,"where the first equality is a direct calculation based on (6); the second equality uses change of
variable y = bx; and the last equality is because exponential functions grow faster than affine
functions. Therefore, for any LÏ > 0, there exists x0 âˆˆR such that |f â€²â€²(x)| â‰¤LÏ |f â€²(x)|Ï if
x > x0. Next, note that limxâ†’âˆ’âˆf â€²â€²(x) = 0. Then for any Î»1 > 0, there exists x1 âˆˆR such
that |f â€²â€²(x)| â‰¤Î»1 if x < x1. Also, since f â€²â€² is continuous, by Weierstrassâ€™s Theorem, we have
|f â€²â€²(x)| â‰¤Î»2 if x1 â‰¤x â‰¤x0 for some Î»2 > 0. Then denoting L0 = max{Î»1, Î»2}, we know f is
(Ï, L0, LÏ)-smooth."
REFERENCES,0.2,"Next, to show f is not necessarily (L0, L1)-smooth, consider the specific double exponential function
f(x) = e(ex). Then we have"
REFERENCES,0.20106382978723406,"f â€²(x) = exe(ex),
f â€²â€²(x) = (ex + 1) Â· f â€²(x)."
REFERENCES,0.20212765957446807,"For any x â‰¥max {log(L0 + 1), log(L1 + 1)}, we can show that"
REFERENCES,0.20319148936170212,"|f â€²â€²(x)| > (L1 + 1)f â€²(x) > L0 + L1 |f â€²(x)| ,"
REFERENCES,0.20425531914893616,"which shows f is not (L0, L1) smooth for any L0, L1 â‰¥0."
REFERENCES,0.2053191489361702,"In the next proposition, we show that any univariate rational function f(x) = P(x)/Q(x), where P
and Q are two polynomials, is (Ï, L0, LÏ)-smooth with Ï = 1.5.
Proposition A.2. The rational function f(x) = P(x)/Q(x), where P and Q are two polynomials,
is (1.5, L0, L1.5)-smooth for some L0, L1.5 â‰¥0. However, it is not necessarily (Ï, L0, LÏ)-smooth
for any Ï < 1.5 and L0, LÏ â‰¥0."
REFERENCES,0.20638297872340425,"Proof of Proposition A.2. Let f(x) = P(x)/Q(x) where P and Q are two polynomials. Then the
partial fractional decomposition of f(x) is given by"
REFERENCES,0.2074468085106383,"f(x) = w(x) + m
X i=1 ji
X r=1"
REFERENCES,0.20851063829787234,"Air
(x âˆ’ai)r + n
X i=1 ki
X r=1"
REFERENCES,0.20957446808510638,"Birx + Cir
(x2 + bix + ci)r ,"
REFERENCES,0.21063829787234042,"where w(x) is a polynomial, Air, Bir, Cir, ai, bi, ci are all real constants satisfying b2
i âˆ’4ci < 0 for
each 1 â‰¤i â‰¤n which implies x2 + bix + ci > 0 for all x âˆˆR. Assume ji â‰¥1 and Aiji Ì¸= 0 without
loss of generality. Then we know f has only finite singular points {ai}1â‰¤iâ‰¤m and has continuous
first and second order derivatives at all other points. To simplify notation, denote"
REFERENCES,0.21170212765957447,"pir(x) :=
Air
(x âˆ’ai)r ,
qir(x) :=
Birx + Cir
(x2 + bix + ci)r ."
REFERENCES,0.2127659574468085,"Then we have f(x) = w(x) + Pm
i=1
Pji
r=1 pir(x) + Pn
i=1
Pki
r=1 qir(x). We know that r+2"
REFERENCES,0.21382978723404256,"r+1 â‰¤1.5
for any r â‰¥1. Then we can show that"
REFERENCES,0.2148936170212766,"lim
xâ†’ai
|f â€²(x)|1.5"
REFERENCES,0.21595744680851064,"|f â€²â€²(x)|
= lim
xâ†’ai"
REFERENCES,0.2170212765957447,"pâ€²
iji(x)
1.5
pâ€²â€²
iji(x)

â‰¥
1
ji + 1,
(7)"
REFERENCES,0.21808510638297873,"where the first equality is because one can easily verify that the first and second order derivatives
of piji dominate those of all other terms when x goes to ai, and the second equality is by standard
calculations noting that ji+2"
REFERENCES,0.21914893617021278,"ji+1 â‰¤1.5. Note that (7) implies that, for any LÏ > ji + 1, there exists
Î´i > 0 such that"
REFERENCES,0.22021276595744682,"|f â€²â€²(x)| â‰¤LÏ |f â€²(x)|1.5 ,
if |x âˆ’ai| < Î´i.
(8)"
REFERENCES,0.22127659574468084,"Similarly, one can show limxâ†’âˆ|f â€²(x)|
1.5"
REFERENCES,0.22234042553191488,"|f â€²â€²(x)|
= âˆ, which implies there exists x0 > 0 such that"
REFERENCES,0.22340425531914893,"|f â€²â€²(x)| â‰¤LÏ |f â€²(x)|1.5 ,
if |x| > x0.
(9)
Define
B := {x âˆˆR | |x| â‰¤x0 and |x âˆ’ai| â‰¥Î´i, âˆ€i} .
We know B is a compact set and therefore the continuous function f â€²â€² is bounded within B, i.e., there
exists some constant L0 > 0 such that
|f â€²â€²(x)| â‰¤L0,
if x âˆˆB.
(10)
Combining (8), (9), and (10), we have shown"
REFERENCES,0.22446808510638297,"|f â€²â€²(x)| â‰¤L0 + LÏ |f â€²(x)|1.5 ,
âˆ€x âˆˆdom(f),
which completes the proof of the first part."
REFERENCES,0.225531914893617,"For the second part, consider the ration function f(x) = 1/x. Then we know that f â€²(x) = âˆ’1/x2"
REFERENCES,0.22659574468085106,"and f â€²â€²(x) = 2/x3. Note that for any Ï < 1.5 and 0 < x â‰¤min{(L0 + 1)âˆ’1/3, (LÏ + 1)âˆ’1/(3âˆ’2Ï)},
we have"
REFERENCES,0.2276595744680851,|f â€²â€²(x)| = 1
REFERENCES,0.22872340425531915,"x3 +
1
x3âˆ’2Ï Â· |f â€²(x)|Ï > L0 + LÏ |f â€²(x)|Ï ,"
REFERENCES,0.2297872340425532,"which shows f is not (Ï, L0, LÏ) smooth for any Ï < 1.5 and L0, LÏ â‰¥0."
REFERENCES,0.23085106382978723,"Finally, we complete this section with the proof of Proposition 3.7, which shows self-concordant
functions are (2, L0, L2)-smooth for some L0, LÏ â‰¥0."
REFERENCES,0.23191489361702128,"Proof of Proposition 3.7. Let h : R â†’R be a self-concordant function. We have hâ€²â€²â€²(x) â‰¤
2hâ€²â€²(x)3/2. Then, for x âˆˆ(a, b), we can obtain
1
2hâ€²â€²(x)âˆ’1/2hâ€²â€²â€²(x) â‰¤hâ€²â€²(x)."
REFERENCES,0.23297872340425532,"Integrating both sides from x0 to y for x0, y âˆˆ(a, b), we have"
REFERENCES,0.23404255319148937,"hâ€²â€²(y)1/2 âˆ’hâ€²â€²(x0)1/2 â‰¤hâ€²(y) âˆ’hâ€²(x0).
Therefore,
hâ€²â€²(y) â‰¤(hâ€²â€²(x0)1/2 âˆ’hâ€²(x0) + hâ€²(y))2 â‰¤2(hâ€²â€²(x0)1/2 âˆ’hâ€²(x0))2 + 2hâ€²(y)2.
Since hâ€²â€²(y) > 0, we have |hâ€²â€²(y)| = hâ€²â€²(y). Therefore, the above inequality shows that h is
(2, L0, L2)-smooth with L0 = 2(hâ€²â€²(x0)1/2 âˆ’hâ€²(x0))2 and L2 = 2."
REFERENCES,0.2351063829787234,"A.2
Proof of Proposition 3.2"
REFERENCES,0.23617021276595745,"In order to prove Proposition 3.2, we need the following several lemmas. First, the lemma below
partially generalizes GrÃ¶nwallâ€™s inequality."
REFERENCES,0.2372340425531915,"Lemma A.3. Let Î± : [a, b] â†’[0, âˆ) and Î² : [0, âˆ) â†’(0, âˆ) be two continuous functions. Suppose
Î±â€²(t) â‰¤Î²(Î±(t)) almost everywhere over (a, b). Denote function Ï•(u) :=
R
1
Î²(u) du. We have for all
t âˆˆ[a, b],"
REFERENCES,0.23829787234042554,Ï•(Î±(t)) â‰¤Ï•(Î±(a)) âˆ’a + t.
REFERENCES,0.2393617021276596,"Proof of Lemma A.3. First, by definition, we know that Ï• is increasing since Ï•â€² =
1
Î² > 0. Let
function Î³ : [a, b] â†’R be the solution of the following differential equation"
REFERENCES,0.2404255319148936,"Î³â€²(t) = Î²(Î³(t)) âˆ€t âˆˆ(a, b),
Î³(a) = Î±(a).
(11)"
REFERENCES,0.24148936170212765,Then we have
REFERENCES,0.2425531914893617,"dÏ•(Î³(t)) =
dÎ³(t)
Î²(Î³(t)) = dt."
REFERENCES,0.24361702127659574,"Integrating both sides, noting that Î³(a) = Î±(a) by (11), we obtain"
REFERENCES,0.24468085106382978,Ï•(Î³(t)) âˆ’Ï•(Î±(a)) = t âˆ’a.
REFERENCES,0.24574468085106382,"Then it suffices to show Ï•(Î±(t)) â‰¤Ï•(Î³(t)), âˆ€t âˆˆ[a, b]. Note that the following inequality holds
almost everywhere."
REFERENCES,0.24680851063829787,"(Ï•(Î±(t)) âˆ’Ï•(Î³(t)))â€² = Ï•â€²(Î±(t))Î±â€²(t) âˆ’Ï•â€²(Î³(t))Î³â€²(t) =
Î±â€²(t)
Î²(Î±(t)) âˆ’
Î³â€²(t)
Î²(Î³(t)) â‰¤0,"
REFERENCES,0.2478723404255319,"where the inequality is because Î±â€²(t) â‰¤Î²(Î±(t)) by the assumption of this lemma and Î³â€²(t) = Î²(Î³(t))
by (11). Since Ï•(Î±(a)) âˆ’Ï•(Î³(a)) = 0, we know for all t âˆˆ[a, b], Ï•(Î±(t)) â‰¤Ï•(Î³(t)), which
completes the proof."
REFERENCES,0.24893617021276596,"With Lemma A.3, one can bound the gradient norm within a small enough neighborhood of a given
point as in the following lemma."
REFERENCES,0.25,"Lemma A.4. If the objective function f is â„“-smooth, for any two points x, y âˆˆRd such that the
closed line segment between x and y is contained in X, if âˆ¥y âˆ’xâˆ¥â‰¤
a
â„“(âˆ¥âˆ‡f(x)âˆ¥+a) for any a > 0,
we have
âˆ¥âˆ‡f(y)âˆ¥â‰¤âˆ¥âˆ‡f(x)âˆ¥+ a."
REFERENCES,0.251063829787234,"Proof of Lemma A.4. Denote z(t) := (1 âˆ’t)x + ty for 0 â‰¤t â‰¤1. Then we know z(t) âˆˆX for all
0 â‰¤t â‰¤1 by the assumption made in this lemma. Then we can also define Î±(t) := âˆ¥âˆ‡f(z(t))âˆ¥for
0 â‰¤t â‰¤1. Note that for any 0 â‰¤t â‰¤s â‰¤1, by triangle inequality,"
REFERENCES,0.2521276595744681,"Î±(s) âˆ’Î±(t) â‰¤âˆ¥âˆ‡f(z(s)) âˆ’âˆ‡f(z(t))âˆ¥.
(12)"
REFERENCES,0.2531914893617021,"We know that Î±(t) = âˆ¥âˆ‡f(z(t))âˆ¥is differentiable almost everywhere since f is second order
differentiable almost everywhere (Here we assume Î±(t) Ì¸= 0 for 0 < t < 1 without loss of generality.
Otherwise, one can define tm = sup{0 < t < 1 | Î±(t) = 0} and consider the interval [tm, 1] instead).
Then the following equality holds almost everywhere"
REFERENCES,0.2542553191489362,"Î±â€²(t) = lim
sâ†“t
Î±(s) âˆ’Î±(t)"
REFERENCES,0.2553191489361702,"s âˆ’t
â‰¤lim
sâ†“t
âˆ¥âˆ‡f(z(s)) âˆ’âˆ‡f(z(t))âˆ¥"
REFERENCES,0.25638297872340426,"s âˆ’t
=
lim
sâ†“t
âˆ‡f(z(s)) âˆ’âˆ‡f(z(t)) s âˆ’t "
REFERENCES,0.2574468085106383,"=
âˆ‡2f(z(t))(y âˆ’x)
 â‰¤
âˆ‡2f(z(t))
 âˆ¥y âˆ’xâˆ¥â‰¤â„“(Î±(t)) âˆ¥y âˆ’xâˆ¥,"
REFERENCES,0.25851063829787235,"where the first inequality is due to (12) and the last inequality is by Definition 1. Let Î²(u) :=
â„“(u) Â· âˆ¥y âˆ’xâˆ¥and Ï•(u) :=
R u
0
1
Î²(v)dv. By Lemma A.3, we know that"
REFERENCES,0.25957446808510637,Ï• (âˆ¥âˆ‡f(y)âˆ¥) = Ï•(u(1)) â‰¤Ï•(u(0)) + 1 = Ï• (âˆ¥âˆ‡f(x)âˆ¥) + 1.
REFERENCES,0.26063829787234044,"Denote Ïˆ(u) :=
R u
0
1
â„“(v)dv = Ï•(u) Â· âˆ¥y âˆ’xâˆ¥. We have"
REFERENCES,0.26170212765957446,Ïˆ (âˆ¥âˆ‡f(y)âˆ¥) â‰¤Ïˆ (âˆ¥âˆ‡f(x)âˆ¥) + âˆ¥y âˆ’xâˆ¥
REFERENCES,0.26276595744680853,"â‰¤Ïˆ (âˆ¥âˆ‡f(x)âˆ¥) +
a
â„“(âˆ¥âˆ‡f(x)âˆ¥+ a)"
REFERENCES,0.26382978723404255,"â‰¤
Z âˆ¥âˆ‡f(x)âˆ¥ 0"
REFERENCES,0.2648936170212766,"1
â„“(v) dv +
Z âˆ¥âˆ‡f(x)âˆ¥+a"
REFERENCES,0.26595744680851063,âˆ¥âˆ‡f(x)âˆ¥
REFERENCES,0.2670212765957447,"1
â„“(v) dv"
REFERENCES,0.2680851063829787,=Ïˆ(âˆ¥âˆ‡f(x)âˆ¥+ a).
REFERENCES,0.2691489361702128,"Since Ïˆ is increasing, we have âˆ¥âˆ‡f(y)âˆ¥â‰¤âˆ¥âˆ‡f(x)âˆ¥+ a."
REFERENCES,0.2702127659574468,"With Lemma A.4, we are ready to prove Proposition 3.2."
REFERENCES,0.2712765957446808,Proof of Proposition 3.2. We prove the two directions in this proposition separately.
REFERENCES,0.2723404255319149,"1. An (r, â„“)-smooth function is â„“-smooth."
REFERENCES,0.2734042553191489,"For each fixed x âˆˆX where âˆ‡2f(x) exists and any unit-norm vector w, by Definition 2, we know
that for any t â‰¤r(âˆ¥âˆ‡f(x)âˆ¥),"
REFERENCES,0.274468085106383,âˆ¥âˆ‡f(x + tw) âˆ’âˆ‡f(x)âˆ¥â‰¤t Â· â„“(âˆ¥âˆ‡f(x)âˆ¥).
REFERENCES,0.275531914893617,"Then we know that
âˆ‡2f(x)w
 =
lim
tâ†“0
1"
REFERENCES,0.2765957446808511,t (âˆ‡f(x + tw) âˆ’âˆ‡f(x))
REFERENCES,0.2776595744680851,"= lim
tâ†“0
1"
REFERENCES,0.27872340425531916,"t âˆ¥(âˆ‡f(x + tw) âˆ’âˆ‡f(x))âˆ¥â‰¤â„“(âˆ¥âˆ‡f(x)âˆ¥),"
REFERENCES,0.2797872340425532,"which implies
âˆ‡2f(x)
 â‰¤â„“(âˆ¥âˆ‡f(x)âˆ¥) for any point x if âˆ‡2f(x) exists."
REFERENCES,0.28085106382978725,"Then it suffices to show that âˆ‡2f(x) exists almost everywhere. Note that for each x âˆˆX, Definition 2
states that the gradient function is â„“(âˆ¥âˆ‡f(x)âˆ¥) Lipschitz within the ball B(x, r(âˆ¥âˆ‡f(x)âˆ¥)). Then
by Rademacherâ€™s Theorem, f is twice differentiable almost everywhere within this ball. Then we
can show it is also twice differentiable almost everywhere within the entire domain X as long as we
can cover X with countably many such balls. Define Sn := {x âˆˆX | n â‰¤âˆ¥âˆ‡f(x)âˆ¥â‰¤n + 1} for
integer n â‰¥0. We have X = âˆªnâ‰¥0Sn. One can easily find an internal covering of Sn with balls
of size r(n + 1)3, i.e., there exist {xn,i}iâ‰¥0, where xn,i âˆˆSn, such that Sn âŠ†âˆªiâ‰¥0B(xn,i, r(n +
1)) âŠ†âˆªiâ‰¥0B(xn,i, r(âˆ¥âˆ‡f(xn,i)âˆ¥)). Therefore we have X âŠ†âˆªn,iâ‰¥0B(xn,i, r(âˆ¥âˆ‡f(xn,i)âˆ¥)) which
completes the proof."
REFERENCES,0.28191489361702127,"2. An â„“-smooth function satisfying Assumption 1 is (r, m)-smooth where m(u) := â„“(u + a) and
r(u) := a/m(u) for any a > 0."
REFERENCES,0.28297872340425534,"For any y âˆˆRd satisfying âˆ¥y âˆ’xâˆ¥â‰¤r(âˆ¥âˆ‡f(x)âˆ¥) =
a
â„“(âˆ¥âˆ‡f(x)âˆ¥+a), denote z(t) := (1 âˆ’t)x + ty
for 0 â‰¤t â‰¤1. We first show y âˆˆX by contradiction. Suppose y /âˆˆX, let us define tb := inf{0 â‰¤
t â‰¤1 | z(t) /âˆˆX} and zb := z(tb). Then we know zb is a boundary point of X. Since f is a closed
function with an open domain, we have"
REFERENCES,0.28404255319148936,"lim
tâ†‘tb f(z(t)) = âˆ.
(13)"
REFERENCES,0.2851063829787234,"On the other hand, by the definition of tb, we know z(t) âˆˆX for every 0 â‰¤t < tb. Then by
Lemma A.4, for all 0 â‰¤t < tb, we have âˆ¥âˆ‡f(z(t))âˆ¥â‰¤âˆ¥âˆ‡f(x)âˆ¥+ a. Therefore for all 0 â‰¤t < tb,"
REFERENCES,0.28617021276595744,"f(z(t)) â‰¤f(x) +
Z t 0"
REFERENCES,0.2872340425531915,"âˆ‡f(z(s)), y âˆ’x

ds"
REFERENCES,0.28829787234042553,"â‰¤f(x) + (âˆ¥âˆ‡f(x)âˆ¥+ a) Â· âˆ¥y âˆ’xâˆ¥
<âˆ,"
REFERENCES,0.28936170212765955,"3We can find an internal covering in the following way. We first cover Sn with countably many hyper-cubes
of length r(n + 1)/
âˆš"
REFERENCES,0.2904255319148936,"d, which is obviously doable. Then for each hyper-cube that intersects with Sn, we pick
one point from the intersection. Then the ball centered at the picked point with radius r(n + 1) covers this
hyper-cube. Therefore, the union of all such balls can cover Sn."
REFERENCES,0.29148936170212764,"which contradicts (13). Therefore we have shown y âˆˆX. Since y is chosen arbitrarily with the ball
B(x, r(âˆ¥âˆ‡f(x)âˆ¥)), we have B(x, r(âˆ¥âˆ‡f(x)âˆ¥)) âŠ†X. Then for any x1, x2 âˆˆB(x, r(âˆ¥âˆ‡f(x)âˆ¥)), we
denote w(t) := tx1 + (1 âˆ’t)x2. Then we know w(t) âˆˆB(x, r(âˆ¥âˆ‡f(x)âˆ¥)) for all 0 â‰¤t â‰¤1 and
can obtain"
REFERENCES,0.2925531914893617,âˆ¥âˆ‡f(x1) âˆ’âˆ‡f(x2)âˆ¥= Z 1
REFERENCES,0.2936170212765957,"0
âˆ‡2f(w(t)) Â· (x1 âˆ’x2) dt"
REFERENCES,0.2946808510638298,"â‰¤âˆ¥x1 âˆ’x2âˆ¥Â·
Z 1"
REFERENCES,0.2957446808510638,"0
â„“(âˆ¥âˆ‡f(x)âˆ¥+ a) dt"
REFERENCES,0.2968085106382979,"=m(âˆ¥âˆ‡f(x)âˆ¥) Â· âˆ¥x1 âˆ’x2âˆ¥,"
REFERENCES,0.2978723404255319,where the last inequality is due to Lemma A.4.
REFERENCES,0.298936170212766,"A.3
Proofs of lemmas implied by generalized smoothness"
REFERENCES,0.3,"In this part, we provide the proofs of the useful properties stated in Section 3.1.2, including Lemma 3.3,
Lemma 3.5, and Corollary 3.6."
REFERENCES,0.30106382978723406,"Proof of Lemma 3.3. First, note that since â„“is non-decreasing and r is non-increasing, we have
â„“(âˆ¥âˆ‡f(x)âˆ¥) â‰¤â„“(G) = L and r(G) â‰¤r(âˆ¥âˆ‡f(x)âˆ¥). Then by Definition 2, we directly have that
B(x, r(G)) âŠ†B(x, r(âˆ¥âˆ‡f(x)âˆ¥)) âŠ†X, and that for any x1, x2 âˆˆB(x, r(G)), we have"
REFERENCES,0.3021276595744681,âˆ¥âˆ‡f(x1) âˆ’âˆ‡f(x2)âˆ¥â‰¤â„“(âˆ¥âˆ‡f(x)âˆ¥) âˆ¥x1 âˆ’x2âˆ¥â‰¤L âˆ¥x1 âˆ’x2âˆ¥.
REFERENCES,0.30319148936170215,"Next, for the second inequality in (2), define z(t) := (1 âˆ’t)x2 + tx1 for 0 â‰¤t â‰¤1. We know
z(t) âˆˆB(x, r(G)). Note that we have shown"
REFERENCES,0.30425531914893617,"âˆ¥âˆ‡f(z(t)) âˆ’âˆ‡f(x2)âˆ¥â‰¤L âˆ¥z(t) âˆ’x2âˆ¥= tL âˆ¥x1 âˆ’x2âˆ¥.
(14)"
REFERENCES,0.30531914893617024,Then we have
REFERENCES,0.30638297872340425,"f(x1) âˆ’f(x2) =
Z 1 0"
REFERENCES,0.3074468085106383,"âˆ‡f(z(t), x1 âˆ’x2

dt =
Z 1 0"
REFERENCES,0.30851063829787234,"âˆ‡f(x2), x1 âˆ’x2

+

âˆ‡f(z(t)) âˆ’âˆ‡f(x2), x1 âˆ’x2

dt"
REFERENCES,0.30957446808510636,"â‰¤

âˆ‡f(x2), x1 âˆ’x2

+ L âˆ¥x1 âˆ’x2âˆ¥2
Z 1"
T DT,0.31063829787234043,"0
t dt"
T DT,0.31170212765957445,"=

âˆ‡f(x2), x1 âˆ’x2

+ L"
T DT,0.3127659574468085,"2 âˆ¥x1 âˆ’x2âˆ¥2 ,"
T DT,0.31382978723404253,where the inequality is due to (14).
T DT,0.3148936170212766,"Proof of Lemma 3.5. If f is â„“-smooth, by Proposition 3.2, f is also (r, m)-smooth where m(u) =
â„“(2u) and r(u) = u/â„“(2u). Then by Lemma 3.3 where we choose G = âˆ¥âˆ‡f(x)âˆ¥, we have that"
T DT,0.3159574468085106,"B

x,
âˆ¥âˆ‡f(x)âˆ¥
â„“(2âˆ¥âˆ‡f(x)âˆ¥)

âŠ†X, and that for any x1, x2 âˆˆB

x,
âˆ¥âˆ‡f(x)âˆ¥
â„“(2âˆ¥âˆ‡f(x)âˆ¥)

, we have"
T DT,0.3170212765957447,"f(x1) â‰¤f(x2) +

âˆ‡f(x2), x1 âˆ’x2

+ â„“(2 âˆ¥âˆ‡f(x)âˆ¥)"
T DT,0.3180851063829787,"2
âˆ¥x1 âˆ’x2âˆ¥."
T DT,0.3191489361702128,"Choosing x2 = x and x1 = x âˆ’
âˆ‡f(x)
â„“(2âˆ¥âˆ‡f(x)âˆ¥), it is easy to verify that x1, x2 âˆˆB

x,
âˆ¥âˆ‡f(x)âˆ¥
â„“(2âˆ¥âˆ‡f(x)âˆ¥)

.
Therefore, we have"
T DT,0.3202127659574468,"f âˆ—â‰¤f

x âˆ’
âˆ‡f(x)
â„“(2 âˆ¥âˆ‡f(x)âˆ¥)"
T DT,0.32127659574468087,"
â‰¤f(x) âˆ’
âˆ¥âˆ‡f(x)âˆ¥2"
T DT,0.3223404255319149,"2â„“(2 âˆ¥âˆ‡f(x)âˆ¥),"
T DT,0.32340425531914896,which completes the proof.
T DT,0.324468085106383,"Proof of Corollary 3.6. We first show G < âˆ.
Note that since â„“is sub-quadratic, we know
limuâ†’âˆ2â„“(2u)/u2 = 0.
Therefore, for any F > 0, there exists some M > 0 such that
2â„“(2u)/u2 < 1/F for every u > M. In other words, for any u satisfying u2 â‰¤2â„“(2u) Â· F,
we must have u â‰¤M. Therefore, by definition of G, we have G â‰¤M < âˆif F > 0. If F = 0, we
trivially get G = 0 < âˆ. Also, since the set {u â‰¥0 | u2 â‰¤2â„“(2u) Â· F} is closed and bounded, we
know its supremum G is in this set and it is also straightforward to show G2 = 2â„“(2G) Â· F."
T DT,0.32553191489361705,"Next, by Lemma 3.5, we know"
T DT,0.32659574468085106,âˆ¥âˆ‡f(x)âˆ¥2 â‰¤2â„“(2 âˆ¥âˆ‡f(x)âˆ¥) Â· (f(x) âˆ’f âˆ—) â‰¤2â„“(2 âˆ¥âˆ‡f(x)âˆ¥) Â· F.
T DT,0.3276595744680851,"Then based on the definition of G, we have âˆ¥âˆ‡f(x)âˆ¥â‰¤G."
T DT,0.32872340425531915,"B
Analysis of GD for convex functions"
T DT,0.32978723404255317,"In this section, we provide the detailed convergence analysis of gradient descent in the convex setting,
including the proofs of Lemma 4.1 and Theorem 4.2, for which the following lemma will be helpful.
Lemma B.1 (Co-coercivity). If f is convex and (r, â„“)-smooth, for any x âˆˆX and y âˆˆ
B(x, r(âˆ¥âˆ‡f(x)âˆ¥)/2), we have y âˆˆX and"
T DT,0.33085106382978724,"âŸ¨âˆ‡f(x) âˆ’âˆ‡f(y), x âˆ’yâŸ©â‰¥1"
T DT,0.33191489361702126,"L âˆ¥âˆ‡f(x) âˆ’âˆ‡f(y)âˆ¥2 ,"
T DT,0.33297872340425533,where L = â„“(âˆ¥âˆ‡f(x)âˆ¥).
T DT,0.33404255319148934,"Proof of Lemma B.1. Define the Bregman divergences Ï•x(w) := f(w) âˆ’âŸ¨âˆ‡f(x), wâŸ©and Ï•y(w) :=
f(w) âˆ’âŸ¨âˆ‡f(y), wâŸ©, which are both convex functions. Since âˆ‡Ï•x(w) = âˆ‡f(w) âˆ’âˆ‡f(x), we
have âˆ‡Ï•x(x) = 0 which implies minw Ï•x(w) = Ï•x(x) as Ï•x is convex. Similarly we have
minw Ï•y(w) = Ï•y(y)."
T DT,0.3351063829787234,"Denote rx := r(âˆ¥âˆ‡f(x)âˆ¥). Since f is (r, â„“)-smooth, we know its gradient âˆ‡f is L-Lipschitz locally
in B(x, rx). Since âˆ‡Ï•x(w) âˆ’âˆ‡f(w) = âˆ‡f(x) is a constant, we know âˆ‡Ï•x is also L-Lipschitz
locally in B(x, rx). Then similar to the proof of Lemma 3.3, one can easily show that for any
x1, x2 âˆˆB(x, rx), we have"
T DT,0.33617021276595743,"Ï•x(x1) â‰¤Ï•x(x2) +

âˆ‡Ï•x(x2), x1 âˆ’x2

+ L"
T DT,0.3372340425531915,"2 âˆ¥x1 âˆ’x2âˆ¥2 .
(15)"
T DT,0.3382978723404255,"Note that for any y âˆˆB(x, r(âˆ¥âˆ‡f(x)âˆ¥)/2) as in the lemma statement,
y âˆ’1"
T DT,0.3393617021276596,"Lâˆ‡Ï•x(y) âˆ’x
 â‰¤âˆ¥y âˆ’xâˆ¥+ 1"
T DT,0.3404255319148936,"L âˆ¥âˆ‡f(y) âˆ’âˆ‡f(x)âˆ¥â‰¤2 âˆ¥y âˆ’xâˆ¥â‰¤rx,"
T DT,0.3414893617021277,"where the first inequality uses triangle inequality and âˆ‡Ï•x(y) = âˆ‡f(y) âˆ’âˆ‡f(x); and the second
inequality uses Definition 2. It implies that y âˆ’1"
T DT,0.3425531914893617,"Lâˆ‡Ï•x(y) âˆˆB(x, rx). Then we can obtain"
T DT,0.34361702127659577,"Ï•x(x) = min
w Ï•x(w) â‰¤Ï•x"
T DT,0.3446808510638298,"
y âˆ’1"
T DT,0.34574468085106386,"Lâˆ‡Ï•x(y)

â‰¤Ï•x(y) âˆ’1"
T DT,0.3468085106382979,"2L âˆ¥âˆ‡Ï•x(y)âˆ¥2 ,"
T DT,0.3478723404255319,where the last inequality uses (15) where we choose x1 = y âˆ’1
T DT,0.34893617021276596,"Lâˆ‡Ï•x(y) and x2 = y. By the
definition of Ï•x, the above inequality is equivalent to"
T DT,0.35,"1
2L âˆ¥âˆ‡f(y) âˆ’âˆ‡f(x)âˆ¥2 â‰¤f(y) âˆ’f(x) âˆ’âŸ¨âˆ‡f(x), x âˆ’yâŸ©."
T DT,0.35106382978723405,Similar argument can be made for Ï•y(Â·) to obtain
T DT,0.35212765957446807,"1
2L âˆ¥âˆ‡f(y) âˆ’âˆ‡f(x)âˆ¥2 â‰¤f(x) âˆ’f(y) âˆ’âŸ¨âˆ‡f(y), y âˆ’xâŸ©."
T DT,0.35319148936170214,"Summing up the two inequalities, we can obtain the desired result."
T DT,0.35425531914893615,"With Lemma B.1, we prove Lemma 4.1 as follows."
T DT,0.3553191489361702,"Proof of Lemma 4.1. Let L = â„“(G). We first verify that x+ âˆˆB(x, r(G)/2). Note that
x+ âˆ’x
 = âˆ¥Î·âˆ‡f(x)âˆ¥â‰¤Î·G â‰¤r(G)/2,"
T DT,0.35638297872340424,"where we choose Î· â‰¤r(G)/(2G). Thus by Lemma B.1, we have
âˆ‡f(x+)
2 = âˆ¥âˆ‡f(x)âˆ¥2 + 2âŸ¨âˆ‡f(x+) âˆ’âˆ‡f(x), âˆ‡f(x)âŸ©+
âˆ‡f(x+) âˆ’âˆ‡f(x)
2"
T DT,0.3574468085106383,= âˆ¥âˆ‡f(x)âˆ¥2 âˆ’2
T DT,0.35851063829787233,"Î· âŸ¨âˆ‡f(x+) âˆ’âˆ‡f(x), x+ âˆ’xâŸ©+
âˆ‡f(x+) âˆ’âˆ‡f(x)
2"
T DT,0.3595744680851064,"â‰¤âˆ¥âˆ‡f(x)âˆ¥2 +

1 âˆ’2 Î·L"
T DT,0.3606382978723404," âˆ‡f(x+) âˆ’âˆ‡f(x)
2"
T DT,0.3617021276595745,"â‰¤âˆ¥âˆ‡f(x)âˆ¥2 ,"
T DT,0.3627659574468085,where the first inequality uses Lemma B.1 and the last inequality chooses Î· â‰¤2/L.
T DT,0.3638297872340426,"With Lemma 4.1, we are ready to prove both Theorem 4.2 and Theorem 4.3."
T DT,0.3648936170212766,"Proof of Theorem 4.2. Denote G := âˆ¥âˆ‡f(x0)âˆ¥. Then we trivially have âˆ¥âˆ‡f(x0)âˆ¥â‰¤G. Lemma 4.1
states that if âˆ¥âˆ‡f(xt)âˆ¥â‰¤G for any t â‰¥0, then we also have âˆ¥âˆ‡f(xt+1)âˆ¥â‰¤âˆ¥âˆ‡f(xt)âˆ¥â‰¤G. By
induction, we can show that âˆ¥âˆ‡f(xt)âˆ¥â‰¤G for all t â‰¥0. Then the rest of the proof basically follows
the standard textbook analysis. We still provide the detailed proof below for completeness."
T DT,0.3659574468085106,"Note that âˆ¥xt+1 âˆ’xtâˆ¥= Î· âˆ¥âˆ‡f(xt)âˆ¥â‰¤Î·G â‰¤r(G), where we choose Î· â‰¤r(G)/(2G). Thus we
can apply Lemma 3.3 to obtain"
T DT,0.3670212765957447,"0 â‰¥f(xt+1) âˆ’f(xt) âˆ’âŸ¨âˆ‡f(xt), xt+1 âˆ’xtâŸ©âˆ’L"
T DT,0.3680851063829787,2 âˆ¥xt+1 âˆ’xtâˆ¥2
T DT,0.36914893617021277,"â‰¥f(xt+1) âˆ’f(xt) âˆ’âŸ¨âˆ‡f(xt), xt+1 âˆ’xtâŸ©âˆ’1"
T DT,0.3702127659574468,"2Î· âˆ¥xt+1 âˆ’xtâˆ¥2 ,
(16)"
T DT,0.37127659574468086,"where the last inequality chooses Î· â‰¤1/L. Meanwhile, by convexity between xt and xâˆ—, we have"
T DT,0.3723404255319149,"0 â‰¥f(xt) âˆ’f âˆ—+ âŸ¨âˆ‡f(xt), xâˆ—âˆ’xtâŸ©.
(17)"
T DT,0.37340425531914895,Note that (t + 1)Ã—(16)+(17) gives
T DT,0.37446808510638296,"0 â‰¥f(xt) âˆ’f âˆ—+ âŸ¨âˆ‡f(xt), xâˆ—âˆ’xtâŸ©"
T DT,0.37553191489361704,"+ (1 + t)

f(xt+1) âˆ’f(xt) âˆ’âŸ¨âˆ‡f(xt), xt+1 âˆ’xtâŸ©âˆ’1"
T DT,0.37659574468085105,"2Î· âˆ¥xt+1 âˆ’xtâˆ¥2

."
T DT,0.3776595744680851,"Then reorganizing the terms of the above inequality, noting that"
T DT,0.37872340425531914,"âˆ¥xt+1 âˆ’xâˆ—âˆ¥2 âˆ’âˆ¥xt âˆ’xâˆ—âˆ¥2 = âˆ¥xt+1 âˆ’xtâˆ¥2 + 2âŸ¨xt+1 âˆ’xt, xt âˆ’xâˆ—âŸ©"
T DT,0.3797872340425532,"= âˆ¥xt+1 âˆ’xtâˆ¥2 + 2Î·âŸ¨âˆ‡f(xt), xâˆ—âˆ’xtâŸ©,"
T DT,0.38085106382978723,we can obtain
T DT,0.3819148936170213,(t + 1)(f(xt+1) âˆ’f âˆ—) + 1
T DT,0.3829787234042553,2Î· âˆ¥xt+1 âˆ’xâˆ—âˆ¥2 â‰¤t(f(xt) âˆ’f âˆ—) + 1
T DT,0.3840425531914894,2Î· âˆ¥xt âˆ’xâˆ—âˆ¥2 .
T DT,0.3851063829787234,"The above inequality implies t(f(xt) âˆ’f âˆ—) +
1
2Î· âˆ¥xt âˆ’xâˆ—âˆ¥2 is a non-increasing potential function,
which directly implies the desired result."
T DT,0.3861702127659574,"Proof of Theorem 4.3. Since strongly convex functions are also convex, by the same argument as in
the proof of Theorem 4.2, we have âˆ¥âˆ‡f(xt)âˆ¥â‰¤G := âˆ¥âˆ‡f(x0)âˆ¥for all t â‰¥0. Moreover, (16) still
holds. For Âµ-strongly-convex function, we can obtain a tighter version of (17) as follows."
T DT,0.3872340425531915,"0 â‰¥f(xt) âˆ’f âˆ—+ âŸ¨âˆ‡f(xt), xâˆ—âˆ’xtâŸ©+ Âµ"
T DT,0.3882978723404255,"2 âˆ¥xâˆ—âˆ’xtâˆ¥2 .
(18)"
T DT,0.3893617021276596,"Let A0 = 0 and At+1 = (1 + At)/(1 âˆ’Î·Âµ) for all t â‰¥0. Combining (16) and (18), we have"
T DT,0.3904255319148936,"0 â‰¥(At+1 âˆ’At)(f(xt) âˆ’f âˆ—+ âŸ¨âˆ‡f(xt), xâˆ—âˆ’xtâŸ©)"
T DT,0.39148936170212767,+ At+1
T DT,0.3925531914893617,"
f(xt+1) âˆ’f(xt) âˆ’âŸ¨âˆ‡f(xt), xt+1 âˆ’xtâŸ©âˆ’1"
T DT,0.39361702127659576,"2Î· âˆ¥xt+1 âˆ’xtâˆ¥2

."
T DT,0.3946808510638298,"Then reorganizing the terms of the above inequality, noting that"
T DT,0.39574468085106385,"âˆ¥xt+1 âˆ’xâˆ—âˆ¥2 âˆ’âˆ¥xt âˆ’xâˆ—âˆ¥2 = âˆ¥xt+1 âˆ’xtâˆ¥2 + 2âŸ¨xt+1 âˆ’xt, xt âˆ’xâˆ—âŸ©"
T DT,0.39680851063829786,"= âˆ¥xt+1 âˆ’xtâˆ¥2 + 2Î·âŸ¨âˆ‡f(xt), xâˆ—âˆ’xtâŸ©,"
T DT,0.39787234042553193,we can obtain
T DT,0.39893617021276595,At+1(f(xt+1) âˆ’f âˆ—) + 1 + Î·ÂµAt+1
T DT,0.4,"2Î·
âˆ¥xt+1 âˆ’xâˆ—âˆ¥2 â‰¤At(f(xt) âˆ’f âˆ—) + 1 + Î·ÂµAt"
T DT,0.40106382978723404,"2Î·
âˆ¥xt âˆ’xâˆ—âˆ¥2 ."
T DT,0.4021276595744681,The above inequality means At(f(xt) âˆ’f âˆ—) + 1+Î·ÂµAt
T DT,0.4031914893617021,"2Î·
âˆ¥xt âˆ’xâˆ—âˆ¥2 is a non-increasing potential
function. Thus by telescoping we have"
T DT,0.40425531914893614,"f(xT ) âˆ’f âˆ—â‰¤
Âµ(1 âˆ’Î·Âµ)T"
T DT,0.4053191489361702,2(1 âˆ’(1 âˆ’Î·Âµ)T ) âˆ¥x0 âˆ’xâˆ—âˆ¥2 .
T DT,0.40638297872340423,"C
Analysis of NAG for convex functions"
T DT,0.4074468085106383,"In this section, we provide the detailed analysis of Nesterovâ€™s accelerated gradient method in the
convex setting. As we discussed in Section 4.2, the stepsize size choice in Theorem 4.4 is smaller
than the classical one. Therefore, we provide a more fine-grained version of the theorem, which
allows the stepsize to depend on the degree of â„“.
Theorem C.1. Suppose f is convex and â„“-smooth.
For Î± âˆˆ(0, 2], if â„“(u) = o(uÎ±), i.e.,
limuâ†’âˆâ„“(u)/uÎ± = 0, then there must exist a constant G such that for L := â„“(2G), we have"
T DT,0.4085106382978723,"G â‰¥max

8 max{L1/Î±âˆ’1/2, 1}
q"
T DT,0.4095744680851064,"L((f(x0) âˆ’f âˆ—) + âˆ¥x0 âˆ’xâˆ—âˆ¥2), âˆ¥âˆ‡f(x0)âˆ¥

.
(19)"
T DT,0.4106382978723404,"Choose Î· â‰¤min

1
16L3âˆ’2/Î± ,
1
2L
	
. Then the iterates of Algorithm 1 satisfy"
T DT,0.4117021276595745,f(xT ) âˆ’f âˆ—â‰¤4(f(x0 âˆ’f âˆ—) + 4 âˆ¥x0 âˆ’xâˆ—âˆ¥2
T DT,0.4127659574468085,"Î·T 2 + 4
."
T DT,0.41382978723404257,"Note that when Î± = 2, i.e., â„“is sub-quadratic, Theorem C.1 reduces to Theorem 4.4 which chooses
Î· â‰¤min{
1
16L2 ,
1
2L}. When Î± = 1, i.e., â„“is sub-linear, the above theorem chooses Î· â‰¤
1
16L as in the
classical textbook analysis up to a numerical constant factor."
T DT,0.4148936170212766,"Throughout this section, we will assume f is convex and â„“-smooth, and consider the parameter choices
in Theorem C.1, unless explicitly stated. Note that since f is â„“-smooth, it is also (r, m)-smooth
with m(u) = â„“(u + G) and r(u) =
G
â„“(u+G) by Proposition 3.2. Note that m(G) = â„“(2G) = L and"
T DT,0.41595744680851066,"r(G) = G/L. Then the stepsize satisfies Î· â‰¤1/(2L) â‰¤min{
2
m(G), r(G) 2G }."
T DT,0.41702127659574467,"Before proving Theorem C.1, we first present several additional useful lemmas. To start with, we
provide two lemmas regarding the weights {At}tâ‰¥0 and {Bt}tâ‰¥0 used in Algorithm 1. The lemma
below states that Bt = Î˜(t2).
Lemma C.2. The weights {Bt}tâ‰¥0 in Algorithm 1 satisfy 1"
T DT,0.41808510638297874,4t2 â‰¤Bt â‰¤t2 for all t â‰¥0.
T DT,0.41914893617021276,"Proof of Lemma C.2. We prove this lemma by induction. First note that the inequality obviously
holds for B0 = 0. Suppose its holds up to t. Then we have"
T DT,0.42021276595744683,Bt+1 = Bt + 1
T DT,0.42127659574468085,"2(1 +
p"
T DT,0.4223404255319149,4Bt + 1) â‰¥1
T DT,0.42340425531914894,4t2 + 1
T DT,0.42446808510638295,"2(1 +
p"
T DT,0.425531914893617,t2 + 1) â‰¥1
T DT,0.42659574468085104,4(t + 1)2.
T DT,0.4276595744680851,"Similarly, we have"
T DT,0.42872340425531913,Bt+1 = Bt + 1
T DT,0.4297872340425532,"2(1 +
p"
T DT,0.4308510638297872,4Bt + 1) â‰¤t2 + 1
T DT,0.4319148936170213,"2(1 +
p"
T DT,0.4329787234042553,4t2 + 1) â‰¤(t + 1)2.
T DT,0.4340425531914894,Lemma C.2 implies the following useful lemma.
T DT,0.4351063829787234,Lemma C.3. The weights {At}tâ‰¥0 in Algorithm 1 satisfy that
T DT,0.43617021276595747,"(1 âˆ’
At
At+1
) 1 At tâˆ’1
X s=0 p"
T DT,0.4372340425531915,As+1(As+1 âˆ’As âˆ’1) â‰¤4.
T DT,0.43829787234042555,"Proof of Lemma C.3. First, note that it is easy to verify that As+1 âˆ’As âˆ’1 = Bs+1 âˆ’Bs âˆ’1 â‰¥0,
which implies each term in the LHS of the above inequality is non-negative. Then we have"
T DT,0.43936170212765957,"(1 âˆ’
At
At+1
) 1 At tâˆ’1
X s=0 p"
T DT,0.44042553191489364,As+1(As+1 âˆ’As âˆ’1)
T DT,0.44148936170212766,"â‰¤
1
At+1
âˆšAt
(At+1 âˆ’At) tâˆ’1
X"
T DT,0.4425531914893617,"s=0
(As+1 âˆ’As âˆ’1)
(At â‰¥As+1)"
T DT,0.44361702127659575,"=
1
At+1
âˆšAt
(Bt+1 âˆ’Bt) tâˆ’1
X"
T DT,0.44468085106382976,"s=0
(Bs+1 âˆ’Bs âˆ’1)
(As = Bs + 1/Î·)"
T DT,0.44574468085106383,"=
1
At+1
âˆšAt
Â· 1"
T DT,0.44680851063829785,"2(1 +
p"
T DT,0.4478723404255319,"4Bt + 1) tâˆ’1
X s=0"
T DT,0.44893617021276594,"
âˆ’1 + 1"
T DT,0.45,"2(1 +
p"
T DT,0.451063829787234,"4Bs + 1)

(by definition of Bs)"
T DT,0.4521276595744681,"â‰¤8
1
(t + 1)2t Â· (t + 1)t2"
T DT,0.4531914893617021,"2
(by At â‰¥Bt and Lemma C.2) â‰¤4."
T DT,0.4542553191489362,"The following lemma summarizes the results in the classical potential function analysis of NAG
in [dâ€™Aspremont et al., 2021]. In order to not deal with the generalized smoothness condition for
now, we directly assume the inequality (20) holds in the lemma, which will be proved later under the
generalized smoothness condition."
T DT,0.4553191489361702,"Lemma C.4. For any t â‰¥0, if the following inequality holds,"
T DT,0.4563829787234043,"f(yt) + âŸ¨âˆ‡f(yt), xt+1 âˆ’ytâŸ©+ 1"
T DT,0.4574468085106383,"2Î· âˆ¥xt+1 âˆ’ytâˆ¥2 â‰¥f(xt+1),
(20)"
T DT,0.45851063829787236,then we can obtain
T DT,0.4595744680851064,At+1(f(xt+1) âˆ’f âˆ—) + 1
T DT,0.46063829787234045,2Î· âˆ¥zt+1 âˆ’xâˆ—âˆ¥2 â‰¤At(f(xt) âˆ’f âˆ—) + 1
T DT,0.46170212765957447,"2Î· âˆ¥zt âˆ’xâˆ—âˆ¥2 .
(21)"
T DT,0.4627659574468085,"Proof of Lemma C.4. These derivations below can be found in [dâ€™Aspremont et al., 2021]. We
present them here for completeness."
T DT,0.46382978723404256,"First, since f is convex, the convexity between xâˆ—and yt gives"
T DT,0.4648936170212766,"f âˆ—â‰¥f(yt) + âŸ¨âˆ‡f(yt), xâˆ—âˆ’ytâŸ©."
T DT,0.46595744680851064,Similarly the convexity between xt and yt gives
T DT,0.46702127659574466,"f(xt) â‰¥f(yt) + âŸ¨âˆ‡f(yt), xt âˆ’ytâŸ©."
T DT,0.46808510638297873,"Combining the above two inequalities as well as (20) assumed in this lemma, we have"
T DT,0.46914893617021275,"0 â‰¥(At+1 âˆ’At)(f(yt) âˆ’f âˆ—+ âŸ¨âˆ‡f(yt), xâˆ—âˆ’ytâŸ©)
+ At(f(yt) âˆ’f(xt) + âŸ¨âˆ‡f(yt), xt âˆ’ytâŸ©)"
T DT,0.4702127659574468,+ At+1
T DT,0.47127659574468084,"
f(xt+1) âˆ’f(yt) âˆ’âŸ¨âˆ‡f(yt), xt+1 âˆ’ytâŸ©âˆ’1"
T DT,0.4723404255319149,"2Î· âˆ¥xt+1 âˆ’ytâˆ¥2

.
(22)"
T DT,0.4734042553191489,"Furthermore, note that
1
2Î·"
T DT,0.474468085106383,"
âˆ¥zt+1 âˆ’xâˆ—âˆ¥2 âˆ’âˆ¥zt âˆ’xâˆ—âˆ¥2 = 1 2Î·"
T DT,0.475531914893617,"
âˆ¥zt+1 âˆ’ztâˆ¥2 + 2âŸ¨zt+1 âˆ’zt, zt âˆ’xâˆ—âŸ©
 = 1 2Î·"
T DT,0.4765957446808511,"
Î·2(At+1 âˆ’At)2 âˆ¥âˆ‡f(yt)âˆ¥2 âˆ’2Î·(At+1 âˆ’At)âŸ¨âˆ‡f(yt), zt âˆ’xâˆ—âŸ©
 = Î·"
T DT,0.4776595744680851,"2(At+1 âˆ’At)2 âˆ¥âˆ‡f(yt)âˆ¥2 âˆ’(At+1 âˆ’At)âŸ¨âˆ‡f(yt), zt âˆ’xâˆ—âŸ©.
(23)"
T DT,0.4787234042553192,"Meanwhile, we have"
T DT,0.4797872340425532,At+1xt+1 = At+1yt âˆ’Î·At+1âˆ‡f(yt) = At+1xt + (At+1 âˆ’At)(zt âˆ’xt) âˆ’Î·At+1âˆ‡f(yt).
T DT,0.4808510638297872,Thus we have
T DT,0.4819148936170213,(At+1 âˆ’At)zt = At+1xt+1 âˆ’Atxt + Î·At+1âˆ‡f(yt).
T DT,0.4829787234042553,"Plugging back in (23), we obtain 1
2Î·"
T DT,0.48404255319148937,"
âˆ¥zt+1 âˆ’xâˆ—âˆ¥2 âˆ’âˆ¥zt âˆ’xâˆ—âˆ¥2 = Î·"
T DT,0.4851063829787234,"2(At+1 âˆ’At)2 âˆ¥âˆ‡f(yt)âˆ¥2 + (At+1 âˆ’At)âŸ¨âˆ‡f(yt), xâˆ—âŸ©"
T DT,0.48617021276595745,"+ âŸ¨âˆ’At+1xt+1 + Atxt âˆ’Î·At+1âˆ‡f(yt), âˆ‡f(yt)âŸ©. Thus"
T DT,0.48723404255319147,"(At+1 âˆ’At)âŸ¨âˆ‡f(yt), xâˆ—âŸ©+ âŸ¨Atxt âˆ’At+1xt+1, âˆ‡f(yt)âŸ© = 1 2Î·"
T DT,0.48829787234042554,"
âˆ¥zt+1 âˆ’xâˆ—âˆ¥2 âˆ’âˆ¥zt âˆ’xâˆ—âˆ¥2
+ Î·(At+1 âˆ’1"
T DT,0.48936170212765956,2(At+1 âˆ’At)2) âˆ¥âˆ‡f(yt)âˆ¥2 .
T DT,0.49042553191489363,So we can reorganize (22) to obtain
T DT,0.49148936170212765,"0 â‰¥At+1(f(xt+1) âˆ’f âˆ—) âˆ’At(f(xt) âˆ’f âˆ—)
+ (At+1 âˆ’At)âŸ¨âˆ‡f(yt), xâˆ—âŸ©+ âŸ¨Atxt âˆ’At+1xt+1, âˆ‡f(yt)âŸ© âˆ’1"
T DT,0.4925531914893617,2Î· At+1 âˆ¥xt+1 âˆ’ytâˆ¥2
T DT,0.49361702127659574,= At+1(f(xt+1) âˆ’f âˆ—) âˆ’At(f(xt) âˆ’f âˆ—) + 1 2Î·
T DT,0.4946808510638298,"
âˆ¥zt+1 âˆ’xâˆ—âˆ¥2 âˆ’âˆ¥zt âˆ’xâˆ—âˆ¥2
+ Î·"
T DT,0.4957446808510638,2(At+1 âˆ’(At+1 âˆ’At)2) âˆ¥âˆ‡f(yt)âˆ¥2 .
T DT,0.4968085106382979,Then we complete the proof noting that it is easy to verify
T DT,0.4978723404255319,At+1 âˆ’(At+1 âˆ’At)2 = Bt+1 + 1
T DT,0.498936170212766,Î· âˆ’(Bt+1 âˆ’Bt)2 = 1 Î· â‰¥0.
T DT,0.5,"In the next lemma, we show that if âˆ¥âˆ‡f(yt)âˆ¥â‰¤G, then the condition (20) assumed in Lemma C.4
is satisfied at time t.
Lemma C.5. For any t â‰¥0, if âˆ¥âˆ‡f(yt)âˆ¥â‰¤G, then we have âˆ¥âˆ‡f(xt+1)âˆ¥â‰¤G, and furthermore,"
T DT,0.5010638297872341,"f(yt) + âŸ¨âˆ‡f(yt), xt+1 âˆ’ytâŸ©+ 1"
T DT,0.502127659574468,2Î· âˆ¥xt+1 âˆ’ytâˆ¥2 â‰¥f(xt+1).
T DT,0.5031914893617021,"Proof of Lemma C.5. As disccued below Theorem C.1, the stepsize satisfies Î· â‰¤1/(2L) â‰¤
min{
2
m(G), r(G)"
T DT,0.5042553191489362,"2G }. Therefore we can apply Lemma 4.1 to show âˆ¥âˆ‡f(xt+1)âˆ¥â‰¤âˆ¥âˆ‡f(yt)âˆ¥â‰¤G. For
the second part, note that âˆ¥xt+1 âˆ’ytâˆ¥= Î· âˆ¥âˆ‡f(yt)âˆ¥â‰¤
G
2L â‰¤r(G), we can apply Lemma 3.3 to
show"
T DT,0.5053191489361702,"f(xt+1) â‰¤f(yt) + âŸ¨âˆ‡f(yt), xt+1 âˆ’ytâŸ©+ L"
T DT,0.5063829787234042,2 âˆ¥xt+1 âˆ’ytâˆ¥2
T DT,0.5074468085106383,"â‰¤f(yt) + âŸ¨âˆ‡f(yt), xt+1 âˆ’ytâŸ©+ 1"
T DT,0.5085106382978724,2Î· âˆ¥xt+1 âˆ’ytâˆ¥2 .
T DT,0.5095744680851064,"With Lemma C.4 and Lemma C.5, we can show that âˆ¥âˆ‡f(yt)âˆ¥â‰¤G for all t â‰¥0, as in the lemma
below.
Lemma C.6. For all t â‰¥0, âˆ¥âˆ‡f(yt)âˆ¥â‰¤G."
T DT,0.5106382978723404,"Proof of Lemma C.6. We will prove this lemma by induction. First, by Lemma 3.5 and the choice of
G, it is easy to verify that âˆ¥âˆ‡f(x0)âˆ¥â‰¤G. Then for any fixed t â‰¥0, suppose that âˆ¥âˆ‡f(xs)âˆ¥â‰¤G
for all s < t. Then by Lemma C.4 and Lemma C.5, we know that âˆ¥âˆ‡f(xs)âˆ¥â‰¤G for all 0 â‰¤s â‰¤t,
and that for all s < t,"
T DT,0.5117021276595745,As+1(f(xs+1) âˆ’f âˆ—) + 1
T DT,0.5127659574468085,2Î· âˆ¥zs+1 âˆ’xâˆ—âˆ¥2 â‰¤As(f(xs) âˆ’f âˆ—) + 1
T DT,0.5138297872340426,"2Î· âˆ¥zs âˆ’xâˆ—âˆ¥2 .
(24)"
T DT,0.5148936170212766,"By telescoping (24), we have for all 0 â‰¤s < t,"
T DT,0.5159574468085106,"f(xs+1) âˆ’f âˆ—â‰¤
1
Î·As+1
((f(x0) âˆ’f âˆ—) + âˆ¥z0 âˆ’xâˆ—âˆ¥2).
(25)"
T DT,0.5170212765957447,"For 0 â‰¤s â‰¤t, since âˆ¥âˆ‡f(xs)âˆ¥â‰¤G, then Lemma 3.5 implies"
T DT,0.5180851063829788,"âˆ¥âˆ‡f(xs)âˆ¥2 â‰¤2L(f(xs) âˆ’f âˆ—).
(26)"
T DT,0.5191489361702127,"Note that by Algorithm 1, we have"
T DT,0.5202127659574468,zt âˆ’xt = Atâˆ’1
T DT,0.5212765957446809,"At
(ztâˆ’1 âˆ’xtâˆ’1) âˆ’Î·(At âˆ’Atâˆ’1)âˆ‡f(ytâˆ’1) + Î·âˆ‡f(ytâˆ’1)."
T DT,0.5223404255319148,Thus we can obtain
T DT,0.5234042553191489,"zt âˆ’xt = âˆ’1 At tâˆ’1
X"
T DT,0.524468085106383,"s=1
Î·As+1(As+1 âˆ’As âˆ’1)âˆ‡f(ys)."
T DT,0.5255319148936171,Therefore
T DT,0.526595744680851,"yt âˆ’xt = âˆ’(1 âˆ’
At
At+1
) 1 At tâˆ’1
X"
T DT,0.5276595744680851,"s=1
Î·As+1(As+1 âˆ’As âˆ’1)âˆ‡f(ys)."
T DT,0.5287234042553192,Thus we have
T DT,0.5297872340425532,"âˆ¥yt âˆ’xtâˆ¥â‰¤(1 âˆ’
At
At+1
) 1 At tâˆ’1
X"
T DT,0.5308510638297872,"s=1
Î·As+1(As+1 âˆ’As âˆ’1) âˆ¥âˆ‡f(ys)âˆ¥=: I."
T DT,0.5319148936170213,"Since âˆ¥âˆ‡f(ys)âˆ¥â‰¤G and âˆ¥xs+1 âˆ’ysâˆ¥= âˆ¥Î·âˆ‡f(ys)âˆ¥â‰¤r(G) for s < t, by Lemma 3.3, we have"
T DT,0.5329787234042553,"I â‰¤(1 âˆ’
At
At+1
) 1 At tâˆ’1
X"
T DT,0.5340425531914894,"s=1
Î·As+1(As+1 âˆ’As âˆ’1)(âˆ¥âˆ‡f(xs+1)âˆ¥+ Î·L âˆ¥âˆ‡f(ys)âˆ¥)"
T DT,0.5351063829787234,"â‰¤Î·LI + (1 âˆ’
At
At+1
) 1 At tâˆ’1
X"
T DT,0.5361702127659574,"s=1
Î·As+1(As+1 âˆ’As âˆ’1) âˆ¥âˆ‡f(xs+1)âˆ¥."
T DT,0.5372340425531915,"Thus
âˆ¥yt âˆ’xtâˆ¥"
T DT,0.5382978723404256,"â‰¤I â‰¤
1
1 âˆ’Î·L(1 âˆ’
At
At+1
) 1 At tâˆ’1
X"
T DT,0.5393617021276595,"s=1
Î·As+1(As+1 âˆ’As âˆ’1) âˆ¥âˆ‡f(xs+1)âˆ¥"
T DT,0.5404255319148936,"â‰¤
1
1 âˆ’Î·L(1 âˆ’
At
At+1
) 1 At tâˆ’1
X"
T DT,0.5414893617021277,"s=1
Î·As+1(As+1 âˆ’As âˆ’1)
p"
T DT,0.5425531914893617,"2L(f(xs+1) âˆ’f âˆ—)
(by (26))"
T DT,0.5436170212765957,"â‰¤
1
1 âˆ’Î·L(1 âˆ’
At
At+1
) 1 At tâˆ’1
X"
T DT,0.5446808510638298,"s=1
Î·As+1(As+1 âˆ’As âˆ’1) s"
L,0.5457446808510639,"2L
As+1
Â· 1"
L,0.5468085106382978,Î· ((f(x0) âˆ’f âˆ—) + âˆ¥z0 âˆ’xâˆ—âˆ¥2)
L,0.5478723404255319,(by (25))
L,0.548936170212766,= 2âˆšÎ·L
L,0.55,"1 âˆ’Î·L(1 âˆ’
At
At+1
) 1 At tâˆ’1
X s=1 p"
L,0.551063829787234,"As+1(As+1 âˆ’As âˆ’1)
q"
L,0.5521276595744681,(f(x0) âˆ’f âˆ—) + âˆ¥z0 âˆ’xâˆ—âˆ¥2 â‰¤8âˆšÎ· 1 âˆ’Î·L q
L,0.5531914893617021,"L((f(x0) âˆ’f âˆ—) + âˆ¥z0 âˆ’xâˆ—âˆ¥2)
(by Lemma C.3)"
L,0.5542553191489362,"â‰¤
1
2L3/2âˆ’1/Î± Â· L1/2âˆ’1/Î±G = G"
L,0.5553191489361702,"2L â‰¤r(G).
(by the choices of Î· and G)"
L,0.5563829787234043,"Since âˆ¥âˆ‡f(xt)âˆ¥â‰¤G and we just showed âˆ¥xt âˆ’ytâˆ¥â‰¤r(G), by Lemma 3.3, we have
âˆ¥âˆ‡f(yt)âˆ¥â‰¤âˆ¥âˆ‡f(xt)âˆ¥+ L âˆ¥yt âˆ’xtâˆ¥ â‰¤ s"
L,0.5574468085106383,"2L
Î·At
((f(x0) âˆ’f âˆ—) + âˆ¥z0 âˆ’xâˆ—âˆ¥2) + L Â· G"
L,0.5585106382978723,"2L
(by (26) and (25)) â‰¤G
1 4 + 1 2"
L,0.5595744680851064,"
â‰¤G.
(by At â‰¥1/Î· and choice of G)"
L,0.5606382978723404,Then we complete the induction as well as the proof.
L,0.5617021276595745,"With the three lemmas above, it is straight forward to prove Theorem C.1."
L,0.5627659574468085,"Proof of Theorem C.1. Combining Lemmas C.4, C.5, and C.6, we know the following inequality
holds for all t â‰¥0."
L,0.5638297872340425,At+1(f(xt+1) âˆ’f âˆ—) + 1
L,0.5648936170212766,2Î· âˆ¥zt+1 âˆ’xâˆ—âˆ¥2 â‰¤At(f(xt) âˆ’f âˆ—) + 1
L,0.5659574468085107,"2Î· âˆ¥zt âˆ’xâˆ—âˆ¥2 ,"
L,0.5670212765957446,"Then by telescoping, we directly complete the proof."
L,0.5680851063829787,"D
Analysis of NAG for strongly convex functions"
L,0.5691489361702128,"In this section, we provide the convergence analysis of the modified version of Nesterovâ€™s accelerated
gradient method for Âµ-strongly-convex functions defined in Algorithm 2."
L,0.5702127659574469,"The convergence results is formally presented in the following theorem.
Theorem D.1. Suppose f is Âµ-strongly-convex and â„“-smooth. For Î± âˆˆ(0, 2], if â„“(u) = o(uÎ±), i.e.,
limuâ†’âˆâ„“(u)/uÎ± = 0, then there must exist a constant G such that for L := â„“(2G), we have"
L,0.5712765957446808,"G â‰¥8 max{L1/Î±âˆ’1/2, 1}
q"
L,0.5723404255319149,"L((f(x0) âˆ’f âˆ—) + Âµ âˆ¥z0 âˆ’xâˆ—âˆ¥2)/ min{Âµ, 1}.
(27)"
L,0.573404255319149,If we choose
L,0.574468085106383,"Î· â‰¤min ï£±
ï£² ï£³
1"
L,0.575531914893617,"144L3âˆ’2/Î± log4
e + 144L3âˆ’2/Î±"
L,0.5765957446808511,"Âµ
, 1"
L,0.5776595744680851,"2L ï£¼
ï£½"
L,0.5787234042553191,"ï£¾.
(28)"
L,0.5797872340425532,Algorithm 2: NAG for Âµ-strongly-convex functions
L,0.5808510638297872,"input A Âµ-strongly-convex and â„“-smooth function f, stepsize Î·, initial point x0"
L,0.5819148936170213,"1: Initialize z0 = x0, B0 = 0, and A0 = 1/(Î·Âµ).
2: for t = 0, ... do"
L,0.5829787234042553,"3:
Bt+1 =
2Bt+1+âˆš"
L,0.5840425531914893,"4Bt+4Î·ÂµB2
t +1
2(1âˆ’Î·Âµ)
4:
At+1 = Bt+1 +
1
Î·Âµ
5:
Ï„t =
(At+1âˆ’At)(1+Î·ÂµAt)
At+1+2Î·ÂµAtAt+1âˆ’Î·ÂµA2
t and Î´t =
At+1âˆ’At
1+Î·ÂµAt+1
6:
yt = xt + Ï„t(zt âˆ’xt)
7:
xt+1 = yt âˆ’Î·âˆ‡f(yt)
8:
zt+1 = (1 âˆ’Î·ÂµÎ´t)zt + Î·ÂµÎ´tyt âˆ’Î·Î´tâˆ‡f(yt)
9: end for"
L,0.5851063829787234,The iterates generated by Algorithm 2 satisfy
L,0.5861702127659575,f(xT ) âˆ’f âˆ—â‰¤(1 âˆ’âˆšÎ·Âµ)T âˆ’1(f(x0 âˆ’f âˆ—) + Âµ âˆ¥z0 âˆ’xâˆ—âˆ¥2)
L,0.5872340425531914,"Î·Âµ + (1 âˆ’âˆšÎ·Âµ)T âˆ’1
."
L,0.5882978723404255,"The above theorem gives a gradient complexity of O

1
âˆšÎ·Âµ log(1/Ïµ)

. Note that Theorem 4.2 shows"
L,0.5893617021276596,"the complexity of GD is O

1
Î·Âµ log(1/Ïµ)

. It seems NAG gives a better rate at first glance. However,
note that the choices of G, L, Î· in these two theorems are different, it is less clear whether NAG
accelerates the optimization in this setting. Below, we informally show that, if â„“(u) = o(âˆšu), the
rate we obtain for NAG is faster than that for GD."
L,0.5904255319148937,"For simplicity, we informally assume â„“(u) â‰xÏ with Ï âˆˆ(0, 1). Let G0 = âˆ¥âˆ‡f(x0)âˆ¥. Then for
GD, by Theorem 4.2, we have Î·gdÂµ â‰Âµ/â„“(G0) â‰Âµ/GÏ
0. For NAG, since â„“is sub-linear we can
choose Î± = 1 in the theorem statement. Since f is Âµ-strongly-convex, by standard results, we
can show that f(x0) âˆ’f âˆ—â‰¤1"
L,0.5914893617021276,"ÂµG2
0 and âˆ¥z0 âˆ’xâˆ—âˆ¥â‰¤1"
L,0.5925531914893617,"ÂµG0. Thus the requirement of G in (27) can
be simplified as G â‰³â„“(G) Â· G0/Âµ, which is satisfied if choosing G â‰(G0/Âµ)1/(1âˆ’Ï). Then we
also have Î·nag â‰
1
â„“(G) â‰(Âµ/G0)Ï/(1âˆ’Ï). Thus âˆšÎ·nagÂµ â‰(Âµ/GÏ
0)1/(2âˆ’2Ï). This means whenever
1/(2 âˆ’2Ï) < 1, i.e., 0 â‰¤Ï < 1/2, we have âˆšÎ·nagÂµ â‰³Î·gdÂµ, which implies the rate we obtain for
NAG is faster than that for GD."
L,0.5936170212765958,"In what follows, we will provide the proof of Theorem D.1. We will always use the parameter choices
in the theorem throughout this section."
L,0.5946808510638298,"D.1
Useful lemmas"
L,0.5957446808510638,"In this part, we provide several useful lemmas for proving Theorem D.1. To start with, the following
two lemmas provide two useful inequalities."
L,0.5968085106382979,"Lemma D.2. For any 0 â‰¤u â‰¤1, we have log(1 + u) â‰¥1 2u."
L,0.597872340425532,"Lemma D.3. For all 0 < p â‰¤1 and t â‰¥0, we have"
L,0.5989361702127659,"t â‰¤
2
âˆšp log(e + 1"
L,0.6,p)(p(1 + âˆšp)t + 1).
L,0.601063829787234,Proof of Lemma D.3. Let
L,0.6021276595744681,"f(t) =
2
âˆšp log(e + 1"
L,0.6031914893617021,p)(p(1 + âˆšp)t + 1) âˆ’t.
L,0.6042553191489362,"It is obvious that f(t) â‰¥0 for t â‰¤
2
âˆšp log(e + 1"
L,0.6053191489361702,"p). For t >
2
âˆšp log(e + 1"
L,0.6063829787234043,"p), we have"
L,0.6074468085106383,f â€²(t) = 2âˆšp log(e + 1
L,0.6085106382978723,p) log(1 + âˆšp)(1 + âˆšp)t âˆ’1
L,0.6095744680851064,"â‰¥p(1 + âˆšp)t âˆ’1
(by Lemma D.2)
= p exp(t log(1 + âˆšp)) âˆ’1
â‰¥p exp(tâˆšp/2) âˆ’1
(by Lemma D.2)"
L,0.6106382978723405,"â‰¥p(e + 1/p) âˆ’1 â‰¥0.
(since t >
2
âˆšp log(e + 1 p))"
L,0.6117021276595744,Thus f is non-decreasing and
L,0.6127659574468085,"f(t) â‰¥f
 2
âˆšp log(e + 1"
L,0.6138297872340426,"p)

â‰¥0."
L,0.6148936170212767,"In the next four lemmas, we provide several useful inequalities regarding the weights {At}tâ‰¥0 and
{Bt}tâ‰¥0 used in Algorithm 2.
Lemma D.4. For all s â‰¤t, we have
Bt+1 âˆ’Bt"
L,0.6159574468085106,"Bt+1
Â· Bs+1 âˆ’Bs"
L,0.6170212765957447,"1 + Î·ÂµBs+1
â‰¤1,"
L,0.6180851063829788,which implies Ï„t Â· Î´s â‰¤1.
L,0.6191489361702127,"Proof of Lemma D.4. By Algorithm 2, it is easy to verify"
L,0.6202127659574468,(Bs+1 âˆ’Bs)2 = Bs+1(1 + Î·ÂµBs+1).
L,0.6212765957446809,This implies
L,0.6223404255319149,"Bs = Bs+1 âˆ’
p"
L,0.6234042553191489,Bs+1(1 + Î·ÂµBs+1). Thus
L,0.624468085106383,"Bt
Bt+1
= 1 âˆ’ s"
L,0.625531914893617,"Î·Âµ +
1
Bt+1
â‰¥1 âˆ’ s"
L,0.6265957446808511,"Î·Âµ +
1
Bs+1
=
Bs
Bs+1
,"
L,0.6276595744680851,"where in the inequality, we use the fact that Bs is non-decreasing with s. Therefore
Bt+1 âˆ’Bt"
L,0.6287234042553191,"Bt+1
Â· Bs+1 âˆ’Bs"
L,0.6297872340425532,"1 + Î·ÂµBs+1
â‰¤Bs+1 âˆ’Bs"
L,0.6308510638297873,"Bs+1
Â· Bs+1 âˆ’Bs"
L,0.6319148936170212,"1 + Î·ÂµBs+1
= 1."
L,0.6329787234042553,Thus we have
L,0.6340425531914894,"Ï„t Â· Î´s =
(At+1 âˆ’At)(1 + Î·ÂµAt)
At+1 + 2Î·ÂµAtAt+1 âˆ’Î·ÂµA2
t
Â· As+1 âˆ’As"
L,0.6351063829787233,1 + Î·ÂµAs+1
L,0.6361702127659574,â‰¤At+1 âˆ’At
L,0.6372340425531915,"At+1
Â· As+1 âˆ’As"
L,0.6382978723404256,"1 + Î·ÂµAs+1
(by At+1 â‰¥At)"
L,0.6393617021276595,= Bt+1 âˆ’Bt
L,0.6404255319148936,"At+1
Â· Bs+1 âˆ’Bs"
L,0.6414893617021277,"1 + Î·ÂµAs+1
(by As+1 âˆ’As = Bs+1 âˆ’Bs)"
L,0.6425531914893617,â‰¤Bt+1 âˆ’Bt
L,0.6436170212765957,"Bt+1
Â· Bs+1 âˆ’Bs"
L,0.6446808510638298,"1 + Î·ÂµBs+1
â‰¤1.
(by As+1 â‰¥Bs+1)"
L,0.6457446808510638,"Lemma D.5. If 0 < Î·Âµ < 1, then for any t â‰¥1, we have
Bt
1 âˆ’âˆšÎ·Âµ â‰¤Bt+1 â‰¤
3Bt
1 âˆ’Î·Âµ. Thus"
L,0.6468085106382979,"Bt â‰¥
1
(1 âˆ’âˆšÎ·Âµ)tâˆ’1 â‰¥(1 + âˆšÎ·Âµ)tâˆ’1."
L,0.6478723404255319,"Proof of Lemma D.5. For t â‰¥1, we have Bt â‰¥1 thus"
L,0.648936170212766,"Bt+1 = 2Bt + 1 +
p"
L,0.65,"4Bt + 4Î·ÂµB2
t + 1
2(1 âˆ’Î·Âµ)
â‰¤2Bt + 1"
L,0.6510638297872341,"1 âˆ’Î·Âµ â‰¤
3Bt
1 âˆ’ÂµÎ· ."
L,0.652127659574468,"On the other hand, we have"
L,0.6531914893617021,"Bt+1 = 2Bt + 1 +
p"
L,0.6542553191489362,"4Bt + 4Î·ÂµB2
t + 1
2(1 âˆ’Î·Âµ)"
L,0.6553191489361702,"â‰¥2Bt +
p"
L,0.6563829787234042,(2BtâˆšÎ·Âµ)2
L,0.6574468085106383,2(1 âˆ’Î·Âµ)
L,0.6585106382978724,"=
Bt
1 âˆ’âˆšÎ·Âµ. Thus"
L,0.6595744680851063,"Bt â‰¥

1
1 âˆ’âˆšÎ·Âµ"
L,0.6606382978723404,"tâˆ’1
B1 â‰¥

1
1 âˆ’âˆšÎ·Âµ"
L,0.6617021276595745,"tâˆ’1
â‰¥(1 + âˆšÎ·Âµ)tâˆ’1."
L,0.6627659574468086,"Lemma D.6. For 0 < Î·Âµ < 1 and t â‰¥1, we have t
X s=0 p"
L,0.6638297872340425,Bs â‰¤(1 âˆ’Î·Âµ)Bt+1 â‰¤3Bt.
L,0.6648936170212766,Proof of Lemma D.6.
L,0.6659574468085107,"Bt+1 = 2Bt + 1 +
p"
L,0.6670212765957447,"4Bt + 4Î·ÂµB2
t + 1
2(1 âˆ’Î·Âµ)"
L,0.6680851063829787,"â‰¥Bt +
âˆšBt
1 âˆ’Î·Âµ
â‰¥Â· Â· Â· â‰¥ t
X s=0"
L,0.6691489361702128,"âˆšBs
1 âˆ’Î·Âµ."
L,0.6702127659574468,"Combined with Lemma D.5, we have the desired result."
L,0.6712765957446809,"Lemma D.7. For t â‰¥1, we have tâˆ’1
X s=0 p"
L,0.6723404255319149,"As+1
At
â‰¤3 + 4 log(e + 1 Î·Âµ)."
L,0.6734042553191489,"Proof of Lemma D.7. By Lemma D.5, we have"
L,0.674468085106383,At = Bt + 1
L,0.675531914893617,Î·Âµ â‰¥(1 + âˆšÎ·Âµ)tâˆ’1 + 1
L,0.676595744680851,"Î·Âµ.
(29)"
L,0.6776595744680851,"Thus, we have tâˆ’1
X s=0 p"
L,0.6787234042553192,"As+1
At
= tâˆ’1
X s=0 p"
L,0.6797872340425531,"Bs+1 + 1/(Î·Âµ) At â‰¤ tâˆ’1
X s=0 p"
L,0.6808510638297872,"Bs+1
At
+
t
âˆšÎ·ÂµAt"
L,0.6819148936170213,"â‰¤3 +
1
âˆšÎ·ÂµAt
Â·
2
âˆšÎ·Âµ log(e + 1"
L,0.6829787234042554,Î·Âµ)(Î·Âµ(1 + âˆšÎ·Âµ)t + 1)
L,0.6840425531914893,(by Lemma D.6 and Lemma D.3)
L,0.6851063829787234,â‰¤3 + 4 log(e + 1
L,0.6861702127659575,"Î·Âµ).
(by Inequality (29))"
L,0.6872340425531915,"D.2
Proof of Theorem D.1"
L,0.6882978723404255,"With all the useful lemmas in the previous section, we proceed to prove Theorem D.1, for which
we need several additional lemmas. First, similar to Lemma C.4, the following lemma summarizes
the results in the classical potential function analysis of NAG for strongly convex functions in
[dâ€™Aspremont et al., 2021].
Lemma D.8. For any t â‰¥0, if the following inequality holds"
L,0.6893617021276596,"f(yt) + âŸ¨âˆ‡f(yt), xt+1 âˆ’ytâŸ©+ 1"
L,0.6904255319148936,"2Î· âˆ¥xt+1 âˆ’ytâˆ¥2 â‰¥f(xt+1),"
L,0.6914893617021277,then we can obtain
L,0.6925531914893617,At+1(f(xt+1) âˆ’f âˆ—) + 1 + Î·ÂµAt+1
L,0.6936170212765957,"2Î·
âˆ¥zt+1 âˆ’xâˆ—âˆ¥2 â‰¤At(f(xt) âˆ’f âˆ—) + 1 + Î·ÂµAt"
L,0.6946808510638298,"2Î·
âˆ¥zt âˆ’xâˆ—âˆ¥2 ."
L,0.6957446808510638,"Proof of Lemma D.8. These derivations can be found in dâ€™Aspremont et al. [2021]. We present it
here for completeness."
L,0.6968085106382979,The strong convexity between xâˆ—and yt gives
L,0.6978723404255319,"f âˆ—â‰¥f(yt) + âŸ¨âˆ‡f(yt), xâˆ—âˆ’ytâŸ©+ Âµ"
L,0.698936170212766,2 âˆ¥xâˆ—âˆ’ytâˆ¥2 .
L,0.7,The convexity between xt and yt gives
L,0.701063829787234,"f(xt) â‰¥f(yt) + âŸ¨âˆ‡f(yt), xt âˆ’ytâŸ©."
L,0.7021276595744681,"Combining the above two inequalities and the one assumed in this lemma, we have"
L,0.7031914893617022,"0 â‰¥(At+1 âˆ’At)(f âˆ—âˆ’f(yt) âˆ’âŸ¨âˆ‡f(yt), xâˆ—âˆ’ytâŸ©âˆ’Âµ"
L,0.7042553191489361,2 âˆ¥xâˆ—âˆ’ytâˆ¥2)
L,0.7053191489361702,"+ At(f(yt) âˆ’f(xt) âˆ’âŸ¨âˆ‡f(yt), xt âˆ’ytâŸ©)"
L,0.7063829787234043,"+ At+1(f(xt+1) âˆ’f(yt) âˆ’âŸ¨âˆ‡f(yt), xt+1 âˆ’ytâŸ©âˆ’1"
L,0.7074468085106383,2Î· âˆ¥xt+1 âˆ’ytâˆ¥2).
L,0.7085106382978723,Reorganizing we can obtain
L,0.7095744680851064,At+1(f(xt+1) âˆ’f âˆ—) + 1 + Î·ÂµAt+1
L,0.7106382978723405,"2Î·
âˆ¥zt+1 âˆ’xâˆ—âˆ¥2"
L,0.7117021276595744,â‰¤At(f(xt) âˆ’f âˆ—) + 1 + Î·ÂµAt
L,0.7127659574468085,"2Î·
âˆ¥zt âˆ’xâˆ—âˆ¥2"
L,0.7138297872340426,"+ (At âˆ’At+1)2 âˆ’At+1 âˆ’Î·ÂµA2
t+1
1 + Î·ÂµAt+1"
L,0.7148936170212766,"Î·
2 âˆ¥âˆ‡f(yt)âˆ¥2"
L,0.7159574468085106,"âˆ’A2
t
(At+1 âˆ’At)(1 + Î·ÂµAt)(1 + Î·ÂµAt+1)"
L,0.7170212765957447,"(At+1 + 2Î·ÂµAtAt+1 âˆ’Î·ÂµA2
t)2
Âµ"
L,0.7180851063829787,2 âˆ¥xt âˆ’ztâˆ¥2 .
L,0.7191489361702128,Then we complete the proof noting that
L,0.7202127659574468,"(At âˆ’At+1)2 âˆ’At+1 âˆ’Î·ÂµA2
t+1"
L,0.7212765957446808,= (Bt âˆ’Bt+1)2 âˆ’Bt+1 + 1
L,0.7223404255319149,Î·Âµ âˆ’Î·Âµ(Bt+1 + 1/(Î·Âµ))2
L,0.723404255319149,"= Î·ÂµB2
t+1 + 1"
L,0.7244680851063829,"Î·Âµ âˆ’Î·ÂµB2
t+1 âˆ’2Bt+1 âˆ’1"
L,0.725531914893617,"Î·Âµ
= âˆ’2Bt+1 â‰¤0."
L,0.7265957446808511,"Next, note that Lemma C.5 still holds in the strongly convex setting. We repeat it below for
completeness.
Lemma D.9. For any t â‰¥0, if âˆ¥âˆ‡f(yt)âˆ¥â‰¤G, then we have âˆ¥âˆ‡f(xt+1)âˆ¥â‰¤G, and furthermore,"
L,0.7276595744680852,"f(yt) + âŸ¨âˆ‡f(yt), xt+1 âˆ’ytâŸ©+ 1"
L,0.7287234042553191,2Î· âˆ¥xt+1 âˆ’ytâˆ¥2 â‰¥f(xt+1).
L,0.7297872340425532,"With Lemma D.8 and Lemma D.9, we will show that âˆ¥âˆ‡f(yt)âˆ¥â‰¤G for all t â‰¥0 by induction in
the following lemma."
L,0.7308510638297873,"Lemma D.10. For all t â‰¥0, we have âˆ¥âˆ‡f(yt)âˆ¥â‰¤G."
L,0.7319148936170212,"Proof of Lemma D.10. We will prove this lemma by induction. First, by Lemma 3.5 and the choice
of G, it is easy to verify that âˆ¥âˆ‡f(x0)âˆ¥â‰¤G. Then for any fixed t â‰¥0, suppose that âˆ¥âˆ‡f(xs)âˆ¥â‰¤G
for all s < t. Then by Lemma D.8 and Lemma D.9, we know that âˆ¥âˆ‡f(xs)âˆ¥â‰¤G for all 0 â‰¤s â‰¤t,
and that for all s < t,"
L,0.7329787234042553,As+1(f(xs+1) âˆ’f âˆ—) + 1 + Î·ÂµAs+1
L,0.7340425531914894,"2Î·
âˆ¥zs+1 âˆ’xâˆ—âˆ¥2 â‰¤As(f(xs) âˆ’f âˆ—) + 1 + Î·ÂµAs"
L,0.7351063829787234,"2Î·
âˆ¥zs âˆ’xâˆ—âˆ¥2 . (30)"
L,0.7361702127659574,"By telescoping (30), we have for all 0 â‰¤s < t,"
L,0.7372340425531915,"f(xs+1) âˆ’f âˆ—â‰¤
1
As+1Î·Âµ(f(x0) âˆ’f âˆ—+ Âµ âˆ¥z0 âˆ’xâˆ—âˆ¥2).
(31)"
L,0.7382978723404255,"For 0 â‰¤s â‰¤t, since âˆ¥âˆ‡f(xs)âˆ¥â‰¤G, then Lemma 3.5 implies"
L,0.7393617021276596,"âˆ¥âˆ‡f(xs)âˆ¥2 â‰¤2L(f(xs) âˆ’f âˆ—).
(32)"
L,0.7404255319148936,"Note that by Algorithm 2, we have"
L,0.7414893617021276,zt âˆ’xt = (1 âˆ’Î·ÂµÎ´tâˆ’1)(1 âˆ’Ï„tâˆ’1)(ztâˆ’1 âˆ’xtâˆ’1) + Î·(1 âˆ’Î´tâˆ’1)âˆ‡f(ytâˆ’1). Thus
L,0.7425531914893617,"zt âˆ’xt = Î· tâˆ’1
X"
L,0.7436170212765958,"s=0
(1 âˆ’Î´s)âˆ‡f(ys) tâˆ’1
Y"
L,0.7446808510638298,"i=s+1
(1 âˆ’Î·ÂµÎ´i)(1 âˆ’Ï„i)."
L,0.7457446808510638,Therefore
L,0.7468085106382979,"yt âˆ’xt = Î·Ï„t tâˆ’1
X"
L,0.747872340425532,"s=0
(1 âˆ’Î´s)âˆ‡f(ys) tâˆ’1
Y"
L,0.7489361702127659,"i=s+1
(1 âˆ’Î·ÂµÎ´i)(1 âˆ’Ï„i)."
L,0.75,Moreover
L,0.7510638297872341,1 âˆ’Î·ÂµÎ´i = 1 âˆ’Î·Âµ(Ai+1 âˆ’Ai)
L,0.752127659574468,"1 + Î·ÂµAi+1
=
1 + Î·ÂµAi
1 + Î·ÂµAi+1 and"
L,0.7531914893617021,"1 âˆ’Ï„i = 1 âˆ’
(Ai+1 âˆ’Ai)(1 + Î·ÂµAi)
Ai+1 + 2Î·ÂµAiAi+1 âˆ’Î·ÂµA2
i
=
Ai(1 + Î·ÂµAi+1)
Ai+1 + 2Î·ÂµAiAi+1 âˆ’Î·ÂµA2
i
â‰¤Ai(1 + Î·ÂµAi+1)"
L,0.7542553191489362,Ai+1(1 + Î·ÂµAi).
L,0.7553191489361702,Thus we have
L,0.7563829787234042,"âˆ¥yt âˆ’xtâˆ¥â‰¤Î·Ï„t tâˆ’1
X"
L,0.7574468085106383,"s=0
(Î´s âˆ’1)As+1"
L,0.7585106382978724,"At
âˆ¥âˆ‡f(ys)âˆ¥â‰¤Î· tâˆ’1
X s=0 As+1"
L,0.7595744680851064,"At
âˆ¥âˆ‡f(ys)âˆ¥=: I,"
L,0.7606382978723404,"where the second inequality follows from Lemma D.4. We further control term I by I â‰¤Î· tâˆ’1
X s=0 As+1"
L,0.7617021276595745,"At
(âˆ¥âˆ‡f(xs+1)âˆ¥+ Î·L âˆ¥âˆ‡f(ys)âˆ¥)"
L,0.7627659574468085,"â‰¤Î·LI + Î· tâˆ’1
X s=0 As+1"
L,0.7638297872340426,"At
âˆ¥âˆ‡f(xs+1)âˆ¥."
L,0.7648936170212766,Thus we have
L,0.7659574468085106,"âˆ¥yt âˆ’xtâˆ¥â‰¤
Î·
1 âˆ’Î·L tâˆ’1
X s=0 As+1"
L,0.7670212765957447,"At
âˆ¥âˆ‡f(xs+1)âˆ¥"
L,0.7680851063829788,"â‰¤
Î·
1 âˆ’Î·L tâˆ’1
X s=0 As+1 At p"
L,0.7691489361702127,"2L(f(xs+1) âˆ’f âˆ—)
(by (32))"
L,0.7702127659574468,"â‰¤
Î·
1 âˆ’Î·L tâˆ’1
X s=0 As+1 At s"
L,0.7712765957446809,"2L Â·
1
As+1Î·Âµ(f(x0) âˆ’f âˆ—+ Âµ âˆ¥z0 âˆ’xâˆ—âˆ¥2)
(by (31)) = q"
L,0.7723404255319148,2Î·L(f(x0) âˆ’f âˆ—+ Âµ âˆ¥z0 âˆ’xâˆ—âˆ¥2)
L,0.7734042553191489,"(1 âˆ’Î·L)âˆšÂµ tâˆ’1
X s=0 p"
L,0.774468085106383,"As+1
At â‰¤ q"
L,0.7755319148936171,2Î·L(f(x0) âˆ’f âˆ—+ Âµ âˆ¥z0 âˆ’xâˆ—âˆ¥2)
L,0.776595744680851,(1 âˆ’Î·L)âˆšÂµ
L,0.7776595744680851,"
3 + 4 log(e + 1"
L,0.7787234042553192,"Î·Âµ)

.
(by Lemma D.7)"
L,0.7797872340425532,"â‰¤
âˆšÎ·
1 âˆ’Î·L"
L,0.7808510638297872,"
3 + 4 log(e + 1"
L,0.7819148936170213,"Î·Âµ)

Â· G Â· L1/2âˆ’1/Î±"
L,0.7829787234042553,"4
(by (27))"
L,0.7840425531914894,"â‰¤
3 + 4 log(e +
1
Î·Âµ)"
L,0.7851063829787234,"log2
e + 144L3âˆ’2/Î±"
L,0.7861702127659574,"Âµ
 Â· G"
L,0.7872340425531915,"24L
(by (28)) â‰¤G"
L,0.7882978723404256,2L â‰¤r(G).
L,0.7893617021276595,"Since âˆ¥âˆ‡f(xt)âˆ¥â‰¤G and we just showed âˆ¥xt âˆ’ytâˆ¥â‰¤r(G), by Lemma 3.3, we have"
L,0.7904255319148936,âˆ¥âˆ‡f(yt)âˆ¥â‰¤âˆ¥âˆ‡f(xt)âˆ¥+ L âˆ¥yt âˆ’xtâˆ¥ â‰¤ s
L,0.7914893617021277,"2L
Î·ÂµAt
((f(x0) âˆ’f âˆ—) + Âµ âˆ¥z0 âˆ’xâˆ—âˆ¥2) + L Â· G"
L,0.7925531914893617,"2L
(by (31)) â‰¤G
1 4 + 1 2"
L,0.7936170212765957,"
â‰¤G.
(by At â‰¥1/(Î·Âµ) and (27))"
L,0.7946808510638298,Then we complete the induction as well as the proof.
L,0.7957446808510639,"Proof of Theorem D.1. Combining Lemmas D.8, D.9, and D.10, we know the following inequality
holds for all t â‰¥0."
L,0.7968085106382978,At+1(f(xt+1) âˆ’f âˆ—)+ 1 + Î·ÂµAt+1
L,0.7978723404255319,"2Î·
âˆ¥zt+1 âˆ’xâˆ—âˆ¥2 â‰¤At(f(xt) âˆ’f âˆ—)+ 1 + Î·ÂµAt"
L,0.798936170212766,"2Î·
âˆ¥zt âˆ’xâˆ—âˆ¥2 ."
L,0.8,"Then by telescoping, we get"
L,0.801063829787234,At(f(xt) âˆ’f âˆ—)+ 1 + Î·ÂµAt
L,0.8021276595744681,"2Î·
âˆ¥zt âˆ’xâˆ—âˆ¥2 â‰¤A0(f(x0) âˆ’f âˆ—)+ 1 + Î·ÂµA0"
L,0.8031914893617021,"2Î·
âˆ¥z0 âˆ’xâˆ—âˆ¥2 ."
L,0.8042553191489362,"Finally, applying Lemma D.5, we have At = Bt + 1/(Î·Âµ) â‰¥1/(1 âˆ’âˆšÎ·Âµ)tâˆ’1 + 1/(Î·Âµ). Thus
completes the proof."
L,0.8053191489361702,"E
Analysis of GD for non-convex functions"
L,0.8063829787234043,"In this section, we provide the proofs related to analysis of gradient descent for non-convex function,
including those of Lemma 5.1 and Theorem 5.2."
L,0.8074468085106383,"Proof of Lemma 5.1. First, based on Corollary 3.6, we know âˆ¥âˆ‡f(x)âˆ¥â‰¤G < âˆ. Also note that
x+ âˆ’x
 = âˆ¥Î·âˆ‡f(x)âˆ¥â‰¤Î·G â‰¤G/L."
L,0.8085106382978723,"Then by Lemma 3.3 and Remark 3.4, we have x+ âˆˆX and"
L,0.8095744680851064,"f(x+) â‰¤f(x) +

âˆ‡f(xt), x+ âˆ’x

+ L 2"
L,0.8106382978723404,"x+ âˆ’x
2"
L,0.8117021276595745,=f(x) âˆ’Î·(1 âˆ’Î·L/2) âˆ¥âˆ‡f(x)âˆ¥2
L,0.8127659574468085,â‰¤f(x).
L,0.8138297872340425,"Proof of Theorem 5.2. By Lemma 5.1, using induction, we directly obtain f(xt) â‰¤f(x0) for all
t â‰¥0. Then by Corollary 3.6, we have âˆ¥âˆ‡f(xt)âˆ¥â‰¤G for all t â‰¥0. Following the proof of
Lemma 5.1, we can similarly show"
L,0.8148936170212766,f(xt+1) âˆ’f(xt) â‰¤Î·(1 âˆ’Î·L/2) âˆ’Î·
L,0.8159574468085107,2 âˆ¥âˆ‡f(xt)âˆ¥2 â‰¤âˆ’Î·
L,0.8170212765957446,2 âˆ¥âˆ‡f(xt)âˆ¥2 .
L,0.8180851063829787,"Taking a summation over t < T and rearanging terms, we have"
T,0.8191489361702128,"1
T X"
T,0.8202127659574469,"t<T
âˆ¥âˆ‡f(xt)âˆ¥2 â‰¤2(f(x0) âˆ’f(xT ))"
T,0.8212765957446808,"Î·T
â‰¤2(f(x0) âˆ’f âˆ—) Î·T
."
T,0.8223404255319149,"F
Analysis of SGD for non-convex functions"
T,0.823404255319149,"In this section, we provide the detailed convergence analysis of stochastic gradient descent for
â„“-smooth and non-convex functions where â„“is sub-quadratic."
T,0.824468085106383,We first present some useful inequalities related to the parameter choices in Theorem 5.3.
T,0.825531914893617,"Lemma F.1. Under the parameters choices in Theorem 5.3, the following inequalities hold. Î·G
âˆš"
T,0.8265957446808511,"2T â‰¤1/2,
Î·2ÏƒLT â‰¤1/2,
100Î·2TÏƒ2L2 â‰¤Î´G2."
T,0.8276595744680851,"Proof of Lemma F.1. First note that by Corollary 3.6, we know"
T,0.8287234042553191,"G2 = 2LF = 16L(f(x0) âˆ’f âˆ—+ Ïƒ)/Î´ â‰¥16LÏƒ/Î´,"
T,0.8297872340425532,"i.e., ÏƒL â‰¤G2Î´/16. Then since we choose Î· â‰¤
1
4G
âˆš"
T,0.8308510638297872,"T , we have Î·G
âˆš"
T,0.8319148936170213,"2T â‰¤
âˆš"
T,0.8329787234042553,"2/4 â‰¤1/2,"
T,0.8340425531914893,"Î·2ÏƒLT â‰¤Î·2TG2Î´/16 â‰¤Î´/256 â‰¤1/2,"
T,0.8351063829787234,100Î·2TÏƒ2L2 â‰¤100Î·2TG4Î´2/256 â‰¤Î´G2.
T,0.8361702127659575,"Next, we show the useful lemma which bounds E[f(xÏ„) âˆ’f âˆ—] and E
hP"
T,0.8372340425531914,t<Ï„ âˆ¥âˆ‡f(xt)âˆ¥2i
T,0.8382978723404255,simultaneously.
T,0.8393617021276596,"Lemma F.2. Under the parameters choices in Theorem 5.3, the following inequality holds E """
T,0.8404255319148937,f(xÏ„) âˆ’f âˆ—+ Î· 2 X
T,0.8414893617021276,"t<Ï„
âˆ¥âˆ‡f(xt)âˆ¥2
#"
T,0.8425531914893617,â‰¤f(x0) âˆ’f âˆ—+ Ïƒ.
T,0.8436170212765958,"Proof of Lemma F.2. If t < Ï„, by the definition of Ï„, we know f(xt) âˆ’f âˆ—â‰¤F and âˆ¥Ïµtâˆ¥â‰¤
G
5Î·L,
and the former also implies âˆ¥âˆ‡f(xt)âˆ¥â‰¤G by Corollary 3.6. Then we can bound"
T,0.8446808510638298,"âˆ¥xt+1 âˆ’xtâˆ¥= Î· âˆ¥gtâˆ¥â‰¤Î·(âˆ¥âˆ‡f(xt)âˆ¥+ âˆ¥Ïµtâˆ¥) â‰¤Î·G + G 5L â‰¤G L ,"
T,0.8457446808510638,"where we use the choice of Î· â‰¤
1
2L. Then based on Lemma 3.3 and Remark 3.4, for any t < Ï„, we
have"
T,0.8468085106382979,"f(xt+1) âˆ’f(xt) â‰¤

âˆ‡f(xt), xt+1 âˆ’xt

+ L"
T,0.847872340425532,2 âˆ¥xt+1 âˆ’xtâˆ¥2
T,0.8489361702127659,"= âˆ’Î·

âˆ‡f(xt), gt

+ Î·2L"
T,0.85,"2
âˆ¥gtâˆ¥2"
T,0.851063829787234,"â‰¤âˆ’Î· âˆ¥âˆ‡f(xt)âˆ¥2 âˆ’Î·

âˆ‡f(xt), Ïµt

+ Î·2L âˆ¥âˆ‡f(xt)âˆ¥2 + Î·2L âˆ¥Ïµtâˆ¥2 â‰¤âˆ’Î·"
T,0.8521276595744681,"2 âˆ¥âˆ‡f(xt)âˆ¥2 âˆ’Î·

âˆ‡f(xt), Ïµt

+ Î·2L âˆ¥Ïµtâˆ¥2 ,
(33)"
T,0.8531914893617021,"where the equality is due to (4); the second inequality uses gt = Ïµt + âˆ‡f(xt) and Youngâ€™s inequality
âˆ¥y + zâˆ¥2 â‰¤2 âˆ¥yâˆ¥2 +2 âˆ¥zâˆ¥2 for any vectors y, z; and the last inequality chooses Î· â‰¤1/(2L). Taking
a summation over t < Ï„ and rearanging terms, we have"
T,0.8542553191489362,f(xÏ„) âˆ’f âˆ—+ Î· 2 X
T,0.8553191489361702,"t<Ï„
âˆ¥âˆ‡f(xt)âˆ¥2 â‰¤f(x0) âˆ’f âˆ—âˆ’Î·
X t<Ï„"
T,0.8563829787234043,"âˆ‡f(xt), Ïµt

+ Î·2L
X"
T,0.8574468085106383,"t<Ï„
âˆ¥Ïµtâˆ¥2 ."
T,0.8585106382978723,"Now we bound the last two terms on th RHS. First, for the last term, we have E ""X"
T,0.8595744680851064,"t<Ï„
âˆ¥Ïµtâˆ¥2
# â‰¤E ""X"
T,0.8606382978723405,"t<T
âˆ¥Ïµtâˆ¥2
# â‰¤Ïƒ2T,"
T,0.8617021276595744,where the first inequality uses Ï„ â‰¤T by its defnition; and in the last inequality we use Assumption 4.
T,0.8627659574468085,"For the cross term, note that Etâˆ’1

âˆ‡f(xt), Ïµt

= 0 by Assumption 4. So this term is a sum of
a martingale difference sequence. Since Ï„ is a stopping time, we can apply the optional stopping
theorem to obtain E ï£® ï£°X tâ‰¤Ï„"
T,0.8638297872340426,"âˆ‡f(xt), Ïµt

ï£¹"
T,0.8648936170212767,"ï£»= 0.
(34)"
T,0.8659574468085106,"Then we have E "" âˆ’
X t<Ï„"
T,0.8670212765957447,"âˆ‡f(xt), Ïµt

#"
T,0.8680851063829788,"=E

âˆ‡f(xÏ„), ÏµÏ„

â‰¤G E[âˆ¥ÏµÏ„âˆ¥] â‰¤G
q"
T,0.8691489361702127,E[âˆ¥ÏµÏ„âˆ¥2] â‰¤G
T,0.8702127659574468,"v
u
u
u
tE ï£® ï£°X"
T,0.8712765957446809,"tâ‰¤T
âˆ¥Ïµtâˆ¥2 ï£¹"
T,0.8723404255319149,"ï£»â‰¤ÏƒG
âˆš"
T,0.8734042553191489,"T + 1 â‰¤ÏƒG
âˆš 2T,"
T,0.874468085106383,"where the equality is due to (34); the first inequality uses âˆ¥âˆ‡f(xÏ„)âˆ¥â‰¤G by the definition of Ï„ in (5)
and Corollary 3.6; the fourth inequality uses E[X]2 â‰¤E[X2] for any random variable X; and the
last inequality uses Assumption 4."
T,0.875531914893617,"Combining all the bounds above, we get E """
T,0.8765957446808511,f(xÏ„) âˆ’f âˆ—+ Î· 2 X
T,0.8776595744680851,"t<Ï„
âˆ¥âˆ‡f(xt)âˆ¥2
#"
T,0.8787234042553191,"â‰¤f(x0) âˆ’f âˆ—+ Î·ÏƒG
âˆš"
T,0.8797872340425532,2T + Î·2Ïƒ2LT
T,0.8808510638297873,"â‰¤f(x0) âˆ’f âˆ—+ Ïƒ,"
T,0.8819148936170212,where the last inequality is due to Lemma F.1.
T,0.8829787234042553,"With Lemma F.2, we are ready to prove Theorem 5.3."
T,0.8840425531914894,"Proof of Theorem 5.3. We want to show the probability of {Ï„ < T} is small, as its complement
{Ï„ = T} means f(xt) âˆ’f âˆ—â‰¤F for all t â‰¤T which implies âˆ¥âˆ‡f(xt)âˆ¥â‰¤G for all t â‰¤T. Note
that"
T,0.8851063829787233,"{Ï„ < T} = {Ï„2 < T} âˆª{Ï„1 < T, Ï„2 = T}."
T,0.8861702127659574,Therefore we only need to bound the probability of each of these two events on the RHS.
T,0.8872340425531915,We first bound P(Ï„2 < T). Note that
T,0.8882978723404256,P(Ï„2 < T) =P [ t<T
T,0.8893617021276595,"
âˆ¥Ïµtâˆ¥>
G
5Î·L ! â‰¤
X"
T,0.8904255319148936,"t<T
P

âˆ¥Ïµtâˆ¥>
G
5Î·L "
T,0.8914893617021277,â‰¤25Î·2TÏƒ2L2
T,0.8925531914893617,"G2
â‰¤Î´/4,"
T,0.8936170212765957,"where the first inequality uses union bound; the second inequality applies Chebyshevâ€™s inequality
and E[âˆ¥Ïµtâˆ¥2] = E[Etâˆ’1[âˆ¥Ïµtâˆ¥2]] â‰¤Ïƒ2 for each fixed t by Assumption 4; the last inequality uses
Lemma F.1."
T,0.8946808510638298,"Next, we will bound P(Ï„1 < T, Ï„2 = T). Note that under the event {Ï„1 < T, Ï„2 = T}, we know that
1) Ï„ = Ï„1 < T which implies f(xÏ„+1) âˆ’f âˆ—> F; and 2) Ï„ < T = Ï„2 which implies âˆ¥ÏµÏ„âˆ¥â‰¤
G
5Î·L by
the definition in (5). Also note that we always have f(xÏ„) âˆ’f âˆ—â‰¤F which implies âˆ¥âˆ‡f(xÏ„)âˆ¥â‰¤G
by Corollary 3.6. Then we can show"
T,0.8957446808510638,"âˆ¥xÏ„+1 âˆ’xÏ„âˆ¥= Î· âˆ¥gÏ„âˆ¥â‰¤Î·(âˆ¥âˆ‡f(xÏ„)âˆ¥+ âˆ¥ÏµÏ„âˆ¥) â‰¤Î·G + G 5L â‰¤G L ,"
T,0.8968085106382979,"where we choose Î· â‰¤
1
2L. Then based on Lemma 3.3 and Remark 3.4, we have"
T,0.8978723404255319,f(xÏ„+1) âˆ’f(xÏ„) â‰¤âˆ’Î·
T,0.898936170212766,"2 âˆ¥âˆ‡f(xÏ„)âˆ¥2 âˆ’Î·

âˆ‡f(xÏ„), ÏµÏ„

+ Î·2L âˆ¥ÏµÏ„âˆ¥2"
T,0.9,â‰¤Î· âˆ¥âˆ‡f(xÏ„)âˆ¥Â· âˆ¥ÏµÏ„âˆ¥+ Î·2L âˆ¥ÏµÏ„âˆ¥2 â‰¤G2
L,0.9010638297872341,"4L =F 2 ,"
L,0.902127659574468,"where the first inequality is obtained following the same derivation as in (33); the last equality is due
to Corollary 3.6. Therefore we can show that under the event {Ï„1 < T, Ï„2 = T},"
L,0.9031914893617021,f(xÏ„) âˆ’f âˆ—= f(xÏ„) âˆ’f(xÏ„+1) + f(xÏ„+1) âˆ’f âˆ—> F/2.
L,0.9042553191489362,"Hence,"
L,0.9053191489361702,"P(Ï„1 < T, Ï„2 = T) â‰¤P (f(xÏ„) âˆ’f âˆ—> F/2) â‰¤E[f(xÏ„) âˆ’f âˆ—]"
L,0.9063829787234042,"F/2
â‰¤2(f(x0) âˆ’f âˆ—+ Ïƒ)"
L,0.9074468085106383,"F
= Î´/4,"
L,0.9085106382978724,"where the second inequality uses Markovâ€™s inequality; the third inequality uses Lemma F.2; and in
the last inequality we choose F = 8(f(x0) âˆ’f âˆ—+ Ïƒ)/Î´."
L,0.9095744680851063,Therefore we can show
L,0.9106382978723404,"P(Ï„ < T) â‰¤P(Ï„2 < T) + P(Ï„1 < T, Ï„2 = T) â‰¤Î´/2."
L,0.9117021276595745,"Then we also know P(Ï„ = T) â‰¥1 âˆ’Î´/2 â‰¥1/2. Therefore, by Lemma F.2,"
L,0.9127659574468086,"2(f(x0) âˆ’f âˆ—+ Ïƒ) Î·
â‰¥E ""X"
L,0.9138297872340425,"t<Ï„
âˆ¥âˆ‡f(xt)âˆ¥2
#"
L,0.9148936170212766,"â‰¥P(Ï„ = T)E "" X"
L,0.9159574468085107,"t<T
âˆ¥âˆ‡f(xt)âˆ¥2
 Ï„ = T # â‰¥1"
E,0.9170212765957447,"2E "" X"
E,0.9180851063829787,"t<T
âˆ¥âˆ‡f(xt)âˆ¥2
 Ï„ = T # ."
E,0.9191489361702128,"Then we have E ""
1
T X"
E,0.9202127659574468,"t<T
âˆ¥âˆ‡f(xt)âˆ¥2
 Ï„ = T #"
E,0.9212765957446809,â‰¤4(f(x0) âˆ’f âˆ—+ Ïƒ)
E,0.9223404255319149,"Î·T
= Î´F"
E,0.9234042553191489,2Î·T â‰¤Î´
E,0.924468085106383,"2 Â· Ïµ2,"
E,0.925531914893617,"where the last inequality uses the choice of T. Let E := { 1 T
P"
E,0.926595744680851,"t<T âˆ¥âˆ‡f(xt)âˆ¥2 > Ïµ2} denote the
event of not converging to an Ïµ-stationary point. By Markovâ€™s inequality, we have P(E) â‰¤Î´/2.
Therefore we have P({Ï„ < T} âˆªE) â‰¤Î´, which completes the proof."
E,0.9276595744680851,"G
Lower bound"
E,0.9287234042553192,"In this section, we provide the proof of Theorem 5.4."
E,0.9297872340425531,"Proof of Theorem 5.4. Let c, Î·0 > 0 satisfy Î·0 â‰¤c2/2. Consider"
E,0.9308510638297872,"f(x) = ï£±
ï£² ï£³"
E,0.9319148936170213,"log(|x| âˆ’c),
|x| â‰¥y
2 log(y âˆ’c) âˆ’log(2y âˆ’|x| âˆ’c),
c/2 â‰¤|x| < y
kx2 + b,
|x| < c/2,"
E,0.9329787234042554,"where c > 0 is a constant and y = (c +
p"
E,0.9340425531914893,c2 + 2Î·0)/2 > 0 is the fixed point of the iteration
E,0.9351063829787234,"xt+1 =
xt âˆ’
Î·0
xt âˆ’c ,"
E,0.9361702127659575,"and k, b are chosen in such a way that f(x) and f â€²(x) are continuous. Specifically, choose k =
câˆ’1f â€²(c/2) and b = f(c/2) âˆ’cf â€²(c/2)/4. Since f(âˆ’x) = f(x), f(x) is symmetric about the line
x = 0. In a small neighborhood, f(x) is symmetric about (y, f(y)), so f â€²(x) is continuous at y."
E,0.9372340425531915,"Let us first consider the smoothness of f. By symmetry, it suffices to consider x > 0. Then,"
E,0.9382978723404255,"f â€²(x) = ï£±
ï£² ï£³"
E,0.9393617021276596,"(x âˆ’c)âˆ’1,
x â‰¥y
(2y âˆ’x âˆ’c)âˆ’1,
c/2 â‰¤x < y
2kx,
0 < x < c/2."
E,0.9404255319148936,Its Hessian is given by
E,0.9414893617021277,"f â€²â€²(x) = ï£±
ï£² ï£³"
E,0.9425531914893617,"âˆ’(x âˆ’c)âˆ’2,
x > y
(2y âˆ’x âˆ’c)âˆ’2,
c/2 < x < y
2k,
0 < x < c/2."
E,0.9436170212765957,"Hence, f(x) is (2, 2k, 1)-smooth."
E,0.9446808510638298,"Note that f(x) has a stationary point 0. For stepsize Î·f satisfying Î·0 â‰¤Î·f â‰¤c2/4, there exists
z = (c+
p"
E,0.9457446808510638,"c2 + 2Î·f) â‰¥y such that âˆ’z = z âˆ’Î·f(yâˆ’c)âˆ’1 and by symmetry, once xÏ„ = z, xt = Â±z
for all t â‰¥Ï„, making the GD iterations stuck. Now we choose a proper x0 such that f â€²(x0) and
f(x0) âˆ’f(0) are bounded."
E,0.9468085106382979,"We consider arriving at y from above. That is, x0 â‰¥x1 â‰¥. . . xÏ„ = z > c > 0. Since in each update
where xt+1 = xt âˆ’Î·f(xt âˆ’c)âˆ’1 > c,"
E,0.9478723404255319,xt âˆ’xt+1 = xt âˆ’(xt âˆ’Î·f(xt âˆ’c)âˆ’1) = Î·f(xt âˆ’c)âˆ’1 â‰¤âˆšÎ·f.
E,0.948936170212766,"Hence, we can choose Ï„ in such a way that 3c/2 â‰¤x0 < 3c/2 + âˆšÎ·f. Then,"
E,0.95,"log(c/2) â‰¤f(x0) â‰¤log(c/2 + âˆšÎ·f),
2/(c + 2âˆšÎ·f) â‰¤f â€²(x0) â‰¤2/c."
E,0.951063829787234,"By definition, y âˆ’c = Î·0(c +
p"
E,0.9521276595744681,"c2 + 2Î·0)âˆ’1. Hence,"
E,0.9531914893617022,f(c/2) = 2 log(y âˆ’c) âˆ’log(2y âˆ’c/2 âˆ’c)
E,0.9542553191489361,"= 2 log(Î·0) âˆ’2 log(c +
p"
E,0.9553191489361702,"c2 + 2Î·0) âˆ’log(
p"
E,0.9563829787234043,"c2 + 2Î·0 âˆ’c/2),"
E,0.9574468085106383,"f â€²(c/2) =
1
p"
E,0.9585106382978723,"c2 + 2Î·0 âˆ’c/2 Then,"
E,0.9595744680851064,f(x0) âˆ’f(0) = f(x0) âˆ’f(c/2) + cf â€²(c/2)/4
E,0.9606382978723405,"â‰¤log(c/2 + âˆšÎ·f) + 2 log(Î·âˆ’1
0 ) + 2 log(c +
p"
E,0.9617021276595744,c2 + 2Î·0)
E,0.9627659574468085,"+ log(
p"
E,0.9638297872340426,"c2 + 2Î·0 âˆ’c/2) + c 4
1
p"
E,0.9648936170212766,c2 + 2Î·0 âˆ’c/2
E,0.9659574468085106,"â‰¤log(c) + 2 log(Î·âˆ’1
0 ) + 2 log(2
âˆš"
E,0.9670212765957447,"2c2) + log(
âˆš"
E,0.9680851063829787,2c2) + 1 2
E,0.9691489361702128,"= 4 log(c) + 2 log(Î·âˆ’1
0 ) + 7"
E,0.9702127659574468,2 log(2) + 1 2.
E,0.9712765957446808,"For stepsize Î·f < Î·0, reaching below 4c/3 takes at least"
E,0.9723404255319149,"(x0 âˆ’4c/3)/âˆšÎ·f â‰¥c/(6âˆšÎ·f) > cÎ·âˆ’1/2
0
/6"
E,0.973404255319149,"steps to reach 4c/3, where f â€²(4c/3) = log(c/3)."
E,0.9744680851063829,"Now we set c and Î·0 and scale function f(x) to satisfy the parameter specifications L0, L2, G0, âˆ†0.
Define g(x) = Lâˆ’1
2 f(x). Then, g(x) is (2, 2kLâˆ’1
2 , L2)-smooth. Since the gradient of g(x) is Lâˆ’1
2
times f(x), the above analysis for f(x) applies to g(x) by replacing Î·0 with Î·1 = L2Î·0 and Î·f with
Î· = L2Î·f. To ensure that"
E,0.975531914893617,"2kLâˆ’1
2
= 2(cL2)âˆ’1f â€²(c/2) =
2
cL2"
P,0.9765957446808511,"1
p"
P,0.9776595744680852,"c2 + 2Î·1 âˆ’c/2
â‰¤
4
c2L2
â‰¤L0,"
P,0.9787234042553191,it suffices to take c â‰¥2/âˆšL0L2. To ensure that
P,0.9797872340425532,"gâ€²(x0) â‰¤
2
L2c â‰¤G0,"
P,0.9808510638297873,it suffices to take c â‰¥2/(L2G0). To ensure that
P,0.9819148936170212,"g(x0) âˆ’g(0) â‰¤(4 log(c) + 2 log(Î·âˆ’1
1 ) + 3.5 log 2 + 0.5)Lâˆ’1
2
â‰¤âˆ†0,"
P,0.9829787234042553,it suffices to take
P,0.9840425531914894,"log(Î·âˆ’1
1 ) = L2âˆ†0 âˆ’3.5 log 2 âˆ’0.5"
P,0.9851063829787234,"2
âˆ’2 log(c)."
P,0.9861702127659574,"Since we require Î·1 â‰¤c2/2, parameters L2 and âˆ†0 need to satisfy"
P,0.9872340425531915,log 2 âˆ’2 log(c) â‰¤L2âˆ†0 âˆ’3.5 log 2 âˆ’0.5
P,0.9882978723404255,"2
âˆ’2 log(c),"
P,0.9893617021276596,"that is, L2âˆ†0
â‰¥
5.5 log 2 + 0.5, which holds because L2âˆ†0
â‰¥
10.
Take c
=
max{2/âˆšL0L2, 2/(L2G0),
p"
P,0.9904255319148936,"8/L0}. Then, as long as Î· â‰¤2/L0, the requirement that Î· â‰¤c2/4 is
satisfied. Therefore, on g(x) with initial point x0, gradient descent with a constant stepsize either
gets stuck, or takes at least"
P,0.9914893617021276,"cÎ·âˆ’1/2
1
/6 = c"
EXP,0.9925531914893617,"6 exp
L2âˆ†0 âˆ’3.5 log 2 âˆ’0.5"
EXP,0.9936170212765958,"4
âˆ’log(c)
 = 1"
EXP,0.9946808510638298,"6 exp(L2âˆ†0 âˆ’3.5 log 2 âˆ’0.5 4
) â‰¥1"
EXP,0.9957446808510638,"6 exp(L2âˆ†0 8
)"
EXP,0.9968085106382979,steps to reach a 1-stationary point.
EXP,0.997872340425532,"On the other hand, if Î· > 2/L0, consider the function f(x) = L0"
EXP,0.9989361702127659,"2 x2. For any xt Ì¸= 0, we always
have |xt+1| / |xt| = |1 âˆ’Î·L0| > 1, which means the iterates diverge to infinity."
