Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,Abstract
ABSTRACT,0.0040650406504065045,"We study offline model-based optimization to maximize a black-box objective
function with a static dataset of designs and scores. These designs encompass a
variety of domains, including materials, robots and DNA sequences. A common
approach trains a proxy on the static dataset to approximate the black-box objective
function and performs gradient ascent to obtain new designs. However, this often
results in poor designs due to the proxy inaccuracies for out-of-distribution designs.
Recent studies indicate that: (a) gradient ascent with a mean ensemble of proxies
generally outperforms simple gradient ascent, and (b) a trained proxy provides
weak ranking supervision signals for design selection. Motivated by (a) and (b),
we propose parallel-mentoring as an effective and novel method that facilitates
mentoring among parallel proxies, creating a more robust ensemble to mitigate the
out-of-distribution issue. We focus on the three-proxy case and our method consists
of two modules. The first module, voting-based pairwise supervision, operates on
three parallel proxies and captures their ranking supervision signals as pairwise
comparison labels. These labels are combined through majority voting to generate
consensus labels, which incorporate ranking supervision signals from all proxies
and enable mutual mentoring. However, label noise arises due to possible incorrect
consensus. To alleviate this, we introduce an adaptive soft-labeling module with
soft-labels initialized as consensus labels. Based on bi-level optimization, this
module fine-tunes proxies in the inner level and learns more accurate labels in
the outer level to adaptively mentor proxies, resulting in a more robust ensemble.
Experiments validate the effectiveness of our method. Our code is available here."
INTRODUCTION,0.008130081300813009,"1
Introduction"
INTRODUCTION,0.012195121951219513,"Designing new objects or entities to optimize specific properties is a widespread challenge, encom-
passing various domains such as materials, robots, and DNA sequences [1]. Traditional approaches
often involve interacting with a black-box function to propose new designs, but this can be expensive
or even dangerous in some cases [2–6]. In response, recent work [1] has focused on a more realistic
setting known as offline model-based optimization (MBO). In this setting, the objective is to maximize
a black-box function using only a static (offline) dataset of designs and scores."
INTRODUCTION,0.016260162601626018,"A prevalent approach to addressing the problem is to train a deep neural network (DNN) model
parameterized as fθ(·), on the static dataset, with the trained DNN serving as a proxy. The proxy
allows for gradient ascent on existing designs, generating improved designs by leveraging the gradient
information provided by the DNN model. However, this method encounters an issue with the trained
proxy being susceptible to out-of-distribution problems. Specifically, the proxy produces inaccurate
predictions when applied to data points that deviate significantly from the training distribution."
INTRODUCTION,0.02032520325203252,∗Correspondence to can.chen@mila.quebec.
INTRODUCTION,0.024390243902439025,"Recent studies have observed that (a) employing a mean ensemble of trained proxies for gradient
ascent in offline MBO generally leads to superior designs compared to using a single proxy [7]."
INTRODUCTION,0.028455284552845527,Figure 1: Motivation illustration.
INTRODUCTION,0.032520325203252036,"This improvement stems from the ability of the ensemble
to provide more robust predictions compared to a sin-
gle proxy [8–11]. Recent work has also found that (b)
a trained proxy offers weak (valuable, albeit potentially
unreliable) ranking supervision signals for design selec-
tion in various offline MBO contexts, such as evolutionary
algorithms [12], reinforcement learning [13], and genera-
tive modeling [14]. These signals, focusing on the relative
order of designs over absolute scores, are more resilient
to noise and inaccuracies. By exchanging these signals
among proxies in the ensemble, we can potentially en-
hance its robustness. As shown in Figure 1, we have three
parallel proxies f A
θ (·), f B
θ (·) and f C
θ (·). For two designs
xn
1 and xn
2 within the neighborhood of the current optimization point, proxies f A
θ (·) and f B
θ (·) agree
that the score of xn
1 is larger than that of xn
2, while proxy f C
θ (·) disagrees. Based on the majority
voting principle, proxies f A
θ (·) and f B
θ (·) provide a more reliable ranking, and their voted ranking
signal f V (xn
1) > f V (xn
2) could mentor the proxy f C
θ (·), thus enhancing its performance."
INTRODUCTION,0.036585365853658534,"To this end, we propose an effective and novel method called parallel-mentoring that facilitates
mentoring among parallel proxies to train a more robust ensemble against the out-of-distribution issue.
This paper primarily focuses on the three-proxy case, referred to as tri-mentoring, but we also examine
the situation with more proxies in Appendix A.1. As depicted in Figure 2, tri-mentoring consists of
two modules. Module 1, voting-based pairwise supervision (shown in Figure 2(a)), operates on three
parallel proxies f A
θ (·), f B
θ (·), and f C
θ (·) and utilizes their mean for the final prediction. To ensure
consistency with the ranking information employed in design selection, this module adopts a pairwise
approach to represent the ranking signals of each proxy. Specifically, as illustrated in Figure 2(a),
this module generates samples (e.g. xn
1, xn
2 and xn
3) in the neighborhood of the current point x
and computes pairwise comparison labels ˆyA for all sample pairs, serving as ranking supervision
signals for the proxy f A
θ (·). The label ˆyA
ij is defined as 1 if f A
θ (xi) > f A
θ (xj) and 0 otherwise, and
similar signals are derived for proxies f B
θ (·) and f C
θ (·). These labels ˆyA, ˆyB and ˆyC are combined
via majority voting to create consensus labels ˆyV which are more reliable and thus can be used for
mentoring proxies. The voted ranking signal f V (xn
1) > f V (xn
2) in Figure 1 corresponds to the
pairwise consensus label ˆyV
12 = 1 in Figure 2(a), and both can mentor the proxy f C
θ (·)."
INTRODUCTION,0.04065040650406504,Figure 2: Illustration of tri-mentoring.
INTRODUCTION,0.044715447154471545,"Module 2, adaptive soft-labeling (shown in Figure 2(b)), mitigates the issue of label noise that may
arise, since the voting consensus may not always be correct. To this end, this module initializes the
consensus labels ˆyV from the first module as soft-labels ˆyS. It then aims to learn more accurate
soft-labels to better represent the ranking supervision signals by leveraging the knowledge from the
static dataset. Specifically, assuming accurate soft-labels, one of the proxies, either f A
θ (·), f B
θ (·) or
f C
θ (·), fine-tuned using them, is expected to perform well on the static dataset, as both soft-labels"
INTRODUCTION,0.04878048780487805,"(pairwise perspective) and the static dataset (pointwise perspective) describe the same ground-truth
and share underlying similarities. This formulation leads to a bi-level optimization framework with
an inner fine-tuning level and an outer soft-labeling level as shown in Figure 2(b). The inner level
fine-tunes the proxy with soft-labels, which establishes the connection between them. The outer
level optimizes soft-labels to be more accurate by minimizing the loss of the static dataset via the
inner-level connection. The optimized labels are further fed back to the first module to adaptively
mentor the proxy, ultimately yielding a more robust ensemble. Experiments on design-bench validate
the effectiveness of our method."
INTRODUCTION,0.052845528455284556,"To summarize, our contributions are three-fold:"
INTRODUCTION,0.056910569105691054,"• We propose parallel-mentoring for offline MBO, effectively utilizing weak ranking supervision
signals among proxies, with a particular focus on the three-proxy case as tri-mentoring.
• Our method consists of two modules: voting-based pairwise supervision and adaptive soft-labeling.
The first module generates pairwise consensus labels via majority voting to mentor the proxies.
• To mitigate label noise in consensus labels, the second module proposes a bi-level optimization
framework to adaptively fine-tune proxies and soft-labels, resulting in a more robust ensemble."
INTRODUCTION,0.06097560975609756,"2
Preliminaries: Gradient Ascent on Offline Model-based Optimization"
INTRODUCTION,0.06504065040650407,"Offline model-based optimization (MBO) aims to find the optimal design x∗that maximizes the
black-box objective function f(·):"
INTRODUCTION,0.06910569105691057,"x∗= arg max
x
f(x) ,
(1)"
INTRODUCTION,0.07317073170731707,"To achieve this, a static dataset D = {(xi, yi)}N
i=1 with N points is available, where xi represents a
design and yi is its corresponding score."
INTRODUCTION,0.07723577235772358,"A common approach for solving this optimization problem is to fit a deep neural network (DNN)
model fθ(·) with parameters θ to the static dataset in a supervised manner. The optimal parameters
θ∗can be obtained by minimizing the mean squared error between the predictions and the true scores:"
INTRODUCTION,0.08130081300813008,"θ∗= arg min
θ
1
N N
X"
INTRODUCTION,0.08536585365853659,"i=1
(fθ(xi) −yi)2 .
(2)"
INTRODUCTION,0.08943089430894309,The trained DNN model fθ∗(·) acts as a proxy to optimize the design using gradient ascent steps:
INTRODUCTION,0.09349593495934959,"xt+1 = xt + η∇xfθ(x)|x=xt ,
for t ∈[0, T −1] ,
(3)"
INTRODUCTION,0.0975609756097561,"where T is the number of steps and η represents the learning rate. xT serves as the final design
candidate. However, this method faces a challenge with the proxy being vulnerable to out-of-
distribution designs. When handling designs that substantially differ from the training distribution,
the proxy yields inaccurate predictions."
METHOD,0.1016260162601626,"3
Method"
METHOD,0.10569105691056911,"In this section, we introduce parallel-mentoring, focusing on the three-proxy scenario, also known
as tri-mentoring. The method can be easily extended to incorporate more proxies, as discussed in
Appendix A.1. Tri-mentoring consists of two modules. The first module, voting-based pairwise
supervision in Section 3.1, manages three proxies parallelly and generates consensus labels via
majority voting to mentor proxies. To mitigate label noise, we introduce a second module, adaptive
soft-labeling in Section 3.2. This module adaptively fine-tunes proxies and soft-labels using bi-level
optimization, improving ensemble robustness. The overall algorithm is shown in Algorithm 1."
VOTING-BASED PAIRWISE SUPERVISION,0.10975609756097561,"3.1
Voting-based Pairwise Supervision"
VOTING-BASED PAIRWISE SUPERVISION,0.11382113821138211,"We train three parallel proxies f A
θ (·), f B
θ (·) and f C
θ (·) on the static dataset with different initializations
and utilize their mean as the final prediction as suggested in [1, 15]:"
VOTING-BASED PAIRWISE SUPERVISION,0.11788617886178862,fθ(·) = 1
VOTING-BASED PAIRWISE SUPERVISION,0.12195121951219512,"3(f A
θ (·) + f B
θ (·) + f C
θ (·)).
(4)"
VOTING-BASED PAIRWISE SUPERVISION,0.12601626016260162,"We then apply gradient ascent with fθ(·) on existing designs to generate improved designs as per
Eq.(3). Although the mean ensemble generally results in superior designs compared to a single proxy"
VOTING-BASED PAIRWISE SUPERVISION,0.13008130081300814,Algorithm 1 Tri-mentoring for Offline Model-based Optimization
VOTING-BASED PAIRWISE SUPERVISION,0.13414634146341464,"Input: The static dataset D, the number of iterations T, the optimizer OPT(·).
Output: The high-scoring design x∗
h.
1 Initialize x0 as the design with the highest score in D.
2 Train proxies f A
θ (·), f B
θ (·) and f C
θ (·) on D with different initializations.
3 for t ←0 to T −1 do"
VOTING-BASED PAIRWISE SUPERVISION,0.13821138211382114,"▷Voting-based pairwise supervision.
4
Sample K neighborhood points at xt as S(xt).
5
Compute pairwise comparison labels ˆyA, ˆyB and ˆyC for three proxies on S(xt).
6
Derive consensus labels: ˆyV = majority_voting(ˆyA, ˆyB, ˆyC)."
VOTING-BASED PAIRWISE SUPERVISION,0.14227642276422764,"▷Adaptive soft-labeling.
7
for proxy in [f A
θ (·), f B
θ (·), f C
θ (·)] do
8
Initialize soft-labels as consensus labels: ˆyS = ˆyV .
9
Inner level: fine-tune the proxy with Eq.(8).
10
Outer level: learn more accurate soft-labels ˆyS with Eq.(9).
11
Mentor proxy using the optimized soft-labels ˆyS with Eq.(8).
▷Gradient ascent with a mean ensemble.
12
Form a more robust ensemble as fθ(x) = 1"
VOTING-BASED PAIRWISE SUPERVISION,0.14634146341463414,"3(f A
θ (x) + f B
θ (x) + f C
θ (x))
13
Gradient ascent: xt+1 = xt + ηOPT(∇xfθ(xt))
14 Return x∗
h = xT"
VOTING-BASED PAIRWISE SUPERVISION,0.15040650406504066,"[7] due to the ensemble robustness [8, 9], this approach does not fully exploit the potential of weak
(valuable, albeit potentially unreliable) ranking supervision signals within every proxy. Emphasizing
the relative order of designs rather than their absolute scores, these signals are more resilient to
noise and inaccuracies. These ranking signals are commonly used in evolutionary algorithms [12],
reinforcement learning [13], and generative modeling [14] to select designs and could further improve
the ensemble robustness. We extract the ranking supervision signals from individual proxies in the
form of pairwise comparison labels, and then combine these labels via majority voting to generate
consensus labels to mentor proxies. We provide a detailed explanation of this module below, with its
implementation shown in Algorithm 1 from Line 4 to Line 6."
VOTING-BASED PAIRWISE SUPERVISION,0.15447154471544716,"Pairwise comparison label. We adopt a pairwise approach to represent the ranking supervision
signals for every proxy, focusing on relative order to align with the ranking information used in
design selection. We sample K points at the neighborhood of the optimization point xt as S(xt)
= {xn
1, . . . , xn
K} ∼N(xt, δ2) where N(xt, δ2) represents a Gaussian distribution centered at xt
with variance δ2. For each sample pair (xn
i , xn
j ) and a proxy (e.g., f A
θ (·)), we define the pairwise
comparison label yA
ij = 1(f A
θ (xn
i ) > f A
θ (xn
j )), where 1 is the indicator function. The labels ˆyA"
VOTING-BASED PAIRWISE SUPERVISION,0.15853658536585366,"from all sample pairs serves as the ranking supervision signals for the proxy f A
θ (·). We repeat this
process for all proxies, generating signals ˆyB and ˆyC for proxies f B
θ (·) and f C
θ (·) respectively."
VOTING-BASED PAIRWISE SUPERVISION,0.16260162601626016,"Majority voting. Given these pairwise comparison labels ˆyA, ˆyB and ˆyC, we derive the pairwise
consensus labels ˆyV via an element-wise majority voting:"
VOTING-BASED PAIRWISE SUPERVISION,0.16666666666666666,"ˆyV
ij = majority_voting(ˆyA
ij, ˆyB
ij, ˆyC
ij) ,
(5)"
VOTING-BASED PAIRWISE SUPERVISION,0.17073170731707318,"where i and j are the indexes of the neighborhood samples. As consensus labels are generally
more reliable, they can be employed for mentoring the proxies to promote the exchange of ranking
supervision signals. Specifically, we can fine-tune the proxy f A
θ (·) using the binary cross-entropy
loss, where σ(f A
θ (xn
i ) −f A
θ (xn
j )) represents the predicted probability that f A
θ (xn
i ) > f A
θ (xn
j ), as
also used in the ChatGPT reward model training [16–18]. The loss function can be computed as:"
VOTING-BASED PAIRWISE SUPERVISION,0.17479674796747968,"LA(θ) = −1 C2
K X"
VOTING-BASED PAIRWISE SUPERVISION,0.17886178861788618,"1≤i<j≤K
ˆyV
ij log[σ(f A
θ (xn
i ) −f A
θ (xn
j ))] + (1 −ˆyV
ij) log[σ(f A
θ (xn
j ) −f A
θ (xn
i ))],
(6)"
VOTING-BASED PAIRWISE SUPERVISION,0.18292682926829268,"where C2
K = K(K−1)"
VOTING-BASED PAIRWISE SUPERVISION,0.18699186991869918,"2
denotes the number of the sample pairs. This procedure is also applied to
proxies f B
θ (·) and f C
θ (·). While our approach encourages alignment with the consensus, it does not
aim to make proxies identical. Each proxy maintains its unique learning trajectory, thereby preserving
the diversity among the proxies."
ADAPTIVE SOFT-LABELING,0.1910569105691057,"3.2
Adaptive Soft-labeling"
ADAPTIVE SOFT-LABELING,0.1951219512195122,"The consensus labels ˆyV may contain noise since the majority voting consensus can be incorrect. To
mitigate this issue, we propose an adaptive soft-labeling module. This module initializes soft-labels
as consensus labels, and employs a bi-level optimization framework for adaptive mentoring, where
the inner level fine-tunes the proxies and the outer level refines the soft-labels. We provide a detailed
description of this module below; its implementation is outlined in Algorithm 1, Line 7- Line 11."
ADAPTIVE SOFT-LABELING,0.1991869918699187,"Fine-tuning. We initialize the soft-labels as the consensus labels: ˆyS = ˆyV , serving as an effective
starting point. Utilizing the soft-labels ˆyS, we can perform fine-tuning on the proxy f A
θ (·) against
the binary cross-entropy loss following Eq.(6),"
ADAPTIVE SOFT-LABELING,0.2032520325203252,"LA(θ, yS) = −1 C2
K X"
ADAPTIVE SOFT-LABELING,0.2073170731707317,"1≤i<j≤K
ˆyS
ij log[σ(f A
θ (xi) −f A
θ (xj))] + (1 −ˆyS
ij) log[σ(f A
θ (xj) −f A
θ (xi))] . (7)"
ADAPTIVE SOFT-LABELING,0.21138211382113822,"In contrast to Eq.(6), we express the loss LA(θ, ˆyS) as a function of both the proxy parameters θ
and the soft-labels ˆyS as the accurate soft-labels ˆyS have yet to be determined. One-step gradient
descent enables fine-tuning, resulting in the following relationship:"
ADAPTIVE SOFT-LABELING,0.21544715447154472,"θ(ˆyS) = θ −γ ∂LA(θ, ˆyS)"
ADAPTIVE SOFT-LABELING,0.21951219512195122,"∂θ⊤
,
(8)"
ADAPTIVE SOFT-LABELING,0.22357723577235772,where γ denotes the fine-tuning learning rate.
ADAPTIVE SOFT-LABELING,0.22764227642276422,"Soft-labeling. Assuming the soft-labels are accurate, the fine-tuned proxy f A
θ(ˆyS)(·) is expected
to perform well on the static dataset. This is due to the fact that, despite having different data
distributions, the soft-labels and the static dataset share underlying similarities, as they both represent
the same ground-truth from pairwise and pointwise perspectives, respectively. This leads to a bi-level
optimization framework with the fine-tuning mentioned above as the inner level and the soft-labeling
here as the outer level. In particular, we enhance the accuracy of soft-labels ˆyS by minimizing the
mean squared error on the static dataset D = {(xi, yi)}N
i=1,"
ADAPTIVE SOFT-LABELING,0.23170731707317074,ˆyS′ = ˆyS −λ N
ADAPTIVE SOFT-LABELING,0.23577235772357724,"∂PN
i=1(f A
θ(ˆy)S(xi) −yi)2"
ADAPTIVE SOFT-LABELING,0.23983739837398374,"∂(ˆyS)⊤
,
(9)"
ADAPTIVE SOFT-LABELING,0.24390243902439024,"where λ represents the soft-labeling learning rate. The nested optimization problem can be easily
solved by higher, a library for higher-order optimization [19]. Once optimized, the labels are fed back
to the first module, adaptively mentoring the proxy f A
θ (·) according to Eq.(8). The same procedure
can be employed for proxies f B
θ (·) and f C
θ (·), ultimately resulting in a more robust ensemble. We
further clarify the novelty of this module in Appendix A.2."
EXPERIMENTS,0.24796747967479674,"4
Experiments"
EXPERIMENTS,0.25203252032520324,"We conduct extensive experiments on design-bench to investigate the effectiveness and robustness of
the proposed method. In Section 4.4, we benchmark our approach against several well-established
baselines. In Section 4.5, we verify the effectiveness of two modules: voting-based pairwise
supervision and adaptive soft-labeling, as well as other contributing factors. In Section 4.6, we
investigate the sensitivity of our method to hyperparameter changes. While our primary focus is
the tri-mentoring with 3 proxies, we additionally explore other parallel-mentoring implementations
utilizing 5, 7, 9, and 11 proxies in Appendix A.1."
TASK OVERVIEW,0.25609756097560976,"4.1
Task Overview"
TASK OVERVIEW,0.2601626016260163,"We adopt the design-bench which comprises both continuous and discrete tasks. Below, we outline
the dataset details and evaluation protocols."
TASK OVERVIEW,0.26422764227642276,"Dataset. We conduct experiments on four continuous tasks: (1) Superconductor (SuperC) [2]:
discover an 86-D superconductor to maximize critical temperature with 17010 designs. (2) Ant
Morphology (Ant) [20]: identify a 60-D ant morphology to crawl quickly with 10004 designs. (3)
D’Kitty Morphology (D’Kitty) [21]: determine a 56-D D’Kitty morphology to crawl quickly with
10004 designs. (4) Hopper Controller (Hopper) [1]: find a neural network policy with 5126 weights
to maximize return with 3200 designs. Besides, we perform experiments on four discrete tasks: (1)
TF Bind 8 (TFB8) [5]: design a length 8 DNA sequence to maximize binding activity score with
32896 designs. (2) TF Bind 10 (TFB10) [5]: find a length 10 DNA sequence to maximize binding"
TASK OVERVIEW,0.2682926829268293,"activity score with 50000 designs. (3) NAS [1]: find a 64-D NN with 5 categories per dimension to
maximize the performance on CIFAR10 with 1771 designs."
TASK OVERVIEW,0.27235772357723576,"Evaluation. We use the oracle evaluation of design-bench to evaluate a certain design and the
details of the oracle functions are reported in Design-Bench Benchmark Tasks in [1]. Following [7],
we select the top N = 128 candidates for each method and report the 100th percentile (maximum)
normalized ground truth score. The score, denoted as yn is computed as
y−ymin
ymax−ymin where y is
the design score, and ymin and ymax are the lowest and highest scores in the complete unobserved
dataset, respectively. In addition, we provide the 50th percentile (median) normalized ground truth
scores used in the prior work in Appendix A.3. We also provide the mean and median ranks of all
comparison methods to better assess the overall performance."
COMPARISONS WITH OTHER METHODS,0.2764227642276423,"4.2
Comparisons with Other Methods"
COMPARISONS WITH OTHER METHODS,0.2804878048780488,"In this paper, we benchmark our method against both gradient-based and non-gradient-based ap-
proaches. The gradient-based methods include: (1) Grad: optimizes the design against the learned
proxy via simple gradient ascent; (2) DE (Deep Ensemble)[7]: optimizes the design against the mean
ensemble of three proxies via gradient ascent; (3) GB (Gradient Boosting) [22]: sequentially trains
new proxies to obtain a robust proxy, followed by gradient ascent using the proxy; (4) COMs [7]:
lower bounds the proxy’s prediction on out-of-distribution designs and subsequently carries out
gradient ascent; (5) ROMA [23]: incorporates the smoothness prior into the proxy and optimizes the
design against the proxy; (6) NEMO [24]: leverages normalized maximum likelihood to constrain
the distance between the proxy and the ground-truth, and acquires new designs by gradient ascent;
(7) BDI [25]: proposes to distill the information from the static dataset into the high-scoring design;
(8) IOM [26]: enforces the invariance between the representations of the static dataset and generated
designs to achieve a natural trade-off. Since our tri-mentoring adopts three proxies, methods using
one proxy including COMs, ROMA and IOM are equipped with three proxies for a fair comparison.
We also explore combining our method with ROMA and COMs and please refer to Appendix A.4 for
an in-depth discussion and corresponding empirical results."
COMPARISONS WITH OTHER METHODS,0.2845528455284553,"The non-gradient-based methods include: (1) BO-qEI [27]: fits a Gaussian Process, proposes
candidate designs utilizing the quasi-Expected Improvement acquisition function, and assigns labels
to the candidates with the proxy; (2) CMA-ES [28]: labels the sampled designs and gradually adapts
the covariance matrix distribution towards the high-scoring part among the sampled designs; (3)
REINFORCE [29]: parameterizes a design distribution and optimizes the distribution towards the
optimal design by policy gradient; (4) CbAS [30]: trains a VAE model and progressively adapts the
model to focus on the high-scoring designs; (5) Auto.CbAS [31]: retrains the proxy adopted in CbAS
by leveraging importance sampling; (6) MIN [32]: learns an inverse map from a score to a design
and then samples from the map conditioned an optimal score value."
TRAINING DETAILS,0.2886178861788618,"4.3
Training Details"
TRAINING DETAILS,0.2926829268292683,"We follow the settings in [7, 25] if not specified. We adopt a three-layer MLP network with the ReLU
function as the activation. We train the MLP model on the static dataset with a 1 × 10−3 learning
rate and an Adam optimizer. The fine-tuning learning rate γ is set as 1 × 10−3 and the soft-labeling
learning rate λ is set as 1 × 10−1. The standard deviation δ is set as 1 × 10−1 and the number of
the samples K is set as 10. All experiments are performed on a single V100 GPU. To ensure the
robustness of our results, we perform 16 trials for each setting and report the mean and standard error.
We’ve detailed the training time and computational overhead of our approach in Appendix A.5 to
provide a comprehensive view of its practicality."
RESULTS AND ANALYSIS,0.2967479674796748,"4.4
Results and Analysis"
RESULTS AND ANALYSIS,0.3008130081300813,"In Table 1 and Table 2, we present the results of our experiments for continuous and discrete tasks,
respectively. A delineating line is drawn to separate the gradient-based methods from the non-
gradient-based methods. Results for non-gradient-ascent methods are taken from [1]. The highest
score of the static dataset for each task is denoted by D(best). For each task, we highlight the
algorithms that fall within one standard deviation of the highest performance by bolding their results."
RESULTS AND ANALYSIS,0.3048780487804878,"Continuous tasks. (1) Table 1 demonstrates tri-mentoring attains the best results across the board,
highlighting its effectiveness. Its consistent gains over Grad confirm its ability to tackle the out-
of-distribution issue. We further test our tri-mentoring for out-of-distribution issues as detailed in
Appendix A.6. (2) Compared to DE and GB, which also use multiple proxies, tri-mentoring achieves"
RESULTS AND ANALYSIS,0.3089430894308943,"Table 1: Results (maximum normalized score) on continuous tasks.
Method
Superconductor
Ant Morphology
D’Kitty Morphology
Hopper Controller
D(best)
0.399
0.565
0.884
1.000
BO-qEI
0.402 ± 0.034
0.819 ± 0.000
0.896 ± 0.000
0.550 ± 0.018
CMA-ES
0.465 ± 0.024
1.214 ± 0.732
0.724 ± 0.001
0.604 ± 0.215
REINFORCE
0.481 ± 0.013
0.266 ± 0.032
0.562 ± 0.196
−0.020 ± 0.067
CbAS
0.503 ± 0.069
0.876 ± 0.031
0.892 ± 0.008
0.141 ± 0.012
Auto.CbAS
0.421 ± 0.045
0.882 ± 0.045
0.906 ± 0.006
0.137 ± 0.005
MIN
0.499 ± 0.017
0.445 ± 0.080
0.892 ± 0.011
0.424 ± 0.166
Grad
0.495 ± 0.011
0.934 ± 0.011
0.944 ± 0.017
1.797 ± 0.116
DE
0.514 ± 0.015
0.937 ± 0.016
0.956 ± 0.014
1.805 ± 0.105
GB
0.496 ± 0.012
0.926 ± 0.029
0.948 ± 0.012
1.793 ± 0.429
COMs
0.491 ± 0.028
0.856 ± 0.040
0.938 ± 0.015
0.642 ± 0.167
ROMA
0.508 ± 0.014
0.914 ± 0.029
0.930 ± 0.012
1.728 ± 0.266
NEMO
0.502 ± 0.002
0.958 ± 0.011
0.954 ± 0.007
0.481 ± 0.003
IOM
0.522 ± 0.018
0.926 ± 0.030
0.943 ± 0.012
1.015 ± 0.380
BDI
0.513 ± 0.000
0.906 ± 0.000
0.919 ± 0.000
1.993 ± 0.000
Tri-mentoring
0.514 ± 0.018
0.948 ± 0.014
0.966 ± 0.010
1.983 ± 0.110"
RESULTS AND ANALYSIS,0.3130081300813008,"Table 2: Results (maximum normalized score) on discrete tasks & ranking on all tasks.
Method
TF Bind 8
TF Bind 10
NAS
Rank Mean
Rank Median
D(best)
0.439
0.467
0.436
BO-qEI
0.798 ± 0.083
0.652 ± 0.038
1.079 ± 0.059
10.1/15
11/15
CMA-ES
0.953 ± 0.022
0.670 ± 0.023
0.985 ± 0.079
6.4/15
4/15
REINFORCE
0.948 ± 0.028
0.663 ± 0.034
−1.895 ± 0.000
11.4/15
15/15
CbAS
0.927 ± 0.051
0.651 ± 0.060
0.683 ± 0.079
9.1/15
9/15
Auto.CbAS
0.910 ± 0.044
0.630 ± 0.045
0.506 ± 0.074
11.6/15
11/15
MIN
0.905 ± 0.052
0.616 ± 0.021
0.717 ± 0.046
11.0/15
12/15
Grad
0.886 ± 0.035
0.647 ± 0.021
0.624 ± 0.102
7.9/15
9/15
DE
0.900 ± 0.056
0.659 ± 0.033
0.655 ± 0.059
5.3/15
4/15
GB
0.922 ± 0.050
0.630 ± 0.041
0.716 ± 0.088
7.6/15
6/15
COMs
0.496 ± 0.065
0.622 ± 0.003
0.783 ± 0.029
10.0/15
11/15
ROMA
0.917 ± 0.039
0.672 ± 0.035
0.927 ± 0.071
5.7/15
6/15
NEMO
0.943 ± 0.005
0.711 ± 0.021
0.737 ± 0.010
5.0/15
4/15
IOM
0.861 ± 0.079
0.647 ± 0.027
0.559 ± 0.081
7.9/15
7/15
BDI
0.870 ± 0.000
0.605 ± 0.000
0.722 ± 0.000
8.1/15
9/15
Tri-mentoring
0.970 ± 0.001
0.722 ± 0.017
0.759 ± 0.102
2.1/15
2/15"
RESULTS AND ANALYSIS,0.3170731707317073,"better results in all four tasks, indicating its improved robustness by sharing ranking supervision
signals among proxies. (3) DE typically outperforms simple gradient ascent due to ensemble
prediction robustness, consistent with findings in [1]. (4) Other gradient-based methods, such as
COMs, fail to achieve the performance as tri-mentoring, further highlighting its superior effectiveness.
(5) In low-dimensional TF Bind 8 tasks, gradient-based methods (average rank 8.8) underperform
compared to non-gradient-based methods (average rank 6.8); however, in high-dimensional TF Bind
10 tasks, gradient-based methods (average rank 7.7) surpass non-gradient-based methods (average
rank 8.2). This suggests non-gradient-based methods, like REINFORCE and generative modeling,
are more suited for low-dimensional design due to their global search ability, while gradient-based
methods provide more direct guidance in high-dimensional designs."
RESULTS AND ANALYSIS,0.32113821138211385,"Discrete tasks. (1) Table 2 shows that tri-mentoring achieves the best results in two out of the three
tasks, with a marginal difference in the third. This indicates that tri-mentoring is a potent method for
discrete tasks as well. (2) However, in complex tasks such as NAS, where each design is represented
as a 64-length sequence of 5-category one-hot vectors, the performance of tri-mentoring is slightly
compromised. This could be attributed to the encoding in design-bench not fully accounting for the
sequential and hierarchical nature of network architectures, leading to less effective gradient updates.
Our proposed method, also demonstrates its effectiveness on high-dimensional biological sequence
design, achieving maximum normalized scores of 0.865 and 0.699 on GFP and UTR respectively."
RESULTS AND ANALYSIS,0.3252032520325203,"In summary, tri-mentoring achieves the highest ranking as shown in Table 2 and Figure 3, and
delivers the best performance in six out of the seven tasks."
RESULTS AND ANALYSIS,0.32926829268292684,"Table 3: Ablation studies on tri-mentoring.
Task
tri-mentoring
w/o voting-based ps
w/o ada soft-labeling
w/o neighbor
post selection
SuperC
0.514 ± 0.018
0.505 ± 0.014
0.504 ± 0.014
0.516 ± 0.017
0.512 ± 0.011
Ant
0.948 ± 0.014
0.938 ± 0.021
0.945 ± 0.018
0.945 ± 0.012
0.945 ± 0.009
D’Kitty
0.966 ± 0.010
0.956 ± 0.010
0.947 ± 0.008
0.958 ± 0.008
0.970 ± 0.013
Hopper
1.983 ± 0.110
1.902 ± 0.138
1.916 ± 0.108
1.839 ± 0.112
1.901 ± 0.148
TF Bind 8
0.970 ± 0.001
0.971 ± 0.003
0.944 ± 0.026
0.950 ± 0.018
0.949 ± 0.006
TF Bind 10
0.722 ± 0.017
0.694 ± 0.030
0.710 ± 0.025
0.643 ± 0.009
0.635 ± 0.027
NAS
0.759 ± 0.102
0.509 ± 0.074
0.538 ± 0.082
0.666 ± 0.089
0.519 ± 0.076"
ABLATION STUDIES,0.3333333333333333,"4.5
Ablation Studies"
ABLATION STUDIES,0.33739837398373984,"In this subsection, the proposed method serves as the baseline, and we systematically remove
each module including voting-based pairwise supervision and adaptive soft-labeling to verify its
contribution. The results are presented in Table 3. Besides the performance results here, we also
provide an evaluation of the accuracy of generated pairwise labels to further verify the effectiveness
of the two modules in Appendix A.7."
ABLATION STUDIES,0.34146341463414637,"Voting-based pairwise supervision. Instead of using the proposed module, we compute the mean
prediction of the ensemble and use this prediction to create pairwise consensus labels. We denote
this as w/o voting-based ps. Our results in Table 3 show a decline in performance when adopting this
alternative. A plausible explanation for this performance decline is that the alternative module fails to
effectively exploit weak ranking supervision signals from individual proxies, resulting in reduced
information exchange and collaboration among the proxies compared to the proposed module."
ABLATION STUDIES,0.34552845528455284,"Adaptive soft-labeling. We remove this module and resort to using one-hot consensus labels. The
performance across all tasks generally deteriorates compared to the full tri-mentoring. A possible
explanation for this is that this module ensures that fine-tuned proxies are optimized to perform
well on the static dataset by introducing soft-labels, reducing the risk of overfitting to consensus
labels derived from individual proxy predictions. This demonstrates the significance of the adaptive
soft-labeling module in mitigating the effects of label noise and enhancing the ensemble performance."
ABLATION STUDIES,0.34959349593495936,"Furthermore, we assess the impact of neighborhood sampling in our method and a post selection
strategy related to our method, with results outlined in Table 3."
ABLATION STUDIES,0.35365853658536583,"Neighborhood sampling. Typically, we sample K neighborhood points at the optimization point
xt for pairwise labels. When neighborhood sampling is excluded (w/o neighbor), labels are directly
generated near the static dataset. The performance generally deteriorates for w/o neighbor in Table 3,
due to the lack of local ranking information around the optimization point."
ABLATION STUDIES,0.35772357723577236,"Post selection. We investigate a variant, post selection, where the mean of two proxies is used to
select the third proxy’s candidates. From Table 3, we find that this variant generally yields worse
results compared to the full tri-mentoring. This finding suggests that using the ranking supervision
signals directly for design selection is less effective than allowing proxies to exchange ranking
supervision signals within the ensemble to produce a more robust ensemble."
HYPERPARAMETER SENSITIVITY,0.3617886178861789,"4.6
Hyperparameter Sensitivity"
HYPERPARAMETER SENSITIVITY,0.36585365853658536,"In this section, we study the sensitivity of our method to hyperparameters, specifically the number of
neighborhood samples K and the number of optimization steps T, on two tasks, the continuous Ant
and the discrete TFB8. We also discuss the standard deviation hyperparameter δ in Appendix A.8."
HYPERPARAMETER SENSITIVITY,0.3699186991869919,"Number of neighborhood samples (K). We evaluate the performance of our method for different
values of K, i.e., the number of neighborhood samples around the optimization point. We test K
values of 5, 10, 15, 20, and 25, with K = 10 being the default value used in this paper. The results
are normalized by dividing them by the result obtained for K = 10. As shown in Figure 4, the
performance of the tri-mentoring method is quite robust to changes in K for both tasks."
HYPERPARAMETER SENSITIVITY,0.37398373983739835,"Number of optimization steps (T). We also investigate the impact of the number of optimization
steps on the performance of our method. As indicated in Figure 5, the method is robust to changes in
the number of optimization steps for both Ant and TFB8 tasks."
HYPERPARAMETER SENSITIVITY,0.3780487804878049,"In summary, our sensitivity analysis demonstrates that the tri-mentoring method is robust to variations
in key hyperparameters, ensuring stable performance across a range of settings."
HYPERPARAMETER SENSITIVITY,0.3821138211382114,"1
2
3
4
5
6
7
8
9 10 11 12 13 14 15
Rank"
HYPERPARAMETER SENSITIVITY,0.3861788617886179,"BO-qEI
CMA-ES
REINFORCE"
HYPERPARAMETER SENSITIVITY,0.3902439024390244,"CbAS
Auto.CbAS"
HYPERPARAMETER SENSITIVITY,0.3943089430894309,"MIN
Grad"
HYPERPARAMETER SENSITIVITY,0.3983739837398374,"DE
GB
COMs
ROMA
NEMO IOM"
HYPERPARAMETER SENSITIVITY,0.4024390243902439,"BDI
Tri-mentoring"
HYPERPARAMETER SENSITIVITY,0.4065040650406504,"Figure 3: Whiskers signify rank
min/max; medians and means are
shown as vertical lines and black
triangles, respectively."
HYPERPARAMETER SENSITIVITY,0.4105691056910569,"5
10
15
20
25
Num of samples K 0.995 1.000 1.005"
HYPERPARAMETER SENSITIVITY,0.4146341463414634,"1.010
1.012"
HYPERPARAMETER SENSITIVITY,0.4186991869918699,Score ratio
HYPERPARAMETER SENSITIVITY,0.42276422764227645,"TFB8
Ant"
HYPERPARAMETER SENSITIVITY,0.4268292682926829,"Figure 4: The ratio of the per-
formance of our tri-mentoring
method with K to the perfor-
mance with K = 10."
HYPERPARAMETER SENSITIVITY,0.43089430894308944,"0
100
200
300
400
Step T 0.6 0.8 1.0 Score"
HYPERPARAMETER SENSITIVITY,0.4349593495934959,"TFB8
Ant"
HYPERPARAMETER SENSITIVITY,0.43902439024390244,"Figure 5: The performance
score as a function of the
optimization step T for both
TFB8 and Ant tasks."
RELATED WORK,0.44308943089430897,"5
Related Work"
RELATED WORK,0.44715447154471544,"Offline model-based optimization. Recently two broad groups of methods have emerged for offline
model-based optimization. One group is based on generative modeling, where methods aim to
gradually adapt a generative model towards the high-scoring design [31–33]. Another group is
based on using gradient ascent to optimize existing designs via gradient information. These methods
generally try to incorporate prior information into the proxy before using it for gradient ascent.
Examples of this approach include COMs [7], ROMA [23], NEMO [24], BDI [25, 34] and IOM [26].
Our proposed method called parallel-mentoring (tri-mentoring) belongs to this category. We maintain
an ensemble of proxies and aim to incorporate weak ranking signals from any pair of proxies into the
third. This symmetric learning process, which cycles through all proxies, enhances the robustness
and resilience of our ensemble. Our proposed ensemble training process, with its focus on parallel-
mentoring, has the potential to improve the proxy and reward training [35, 33], thereby contributing
to advancements in biological sequence design. Notably, the contemporaneous ICT method [36]
exchanges direct proxy scores, which may be less robust than our pairwise comparison approach."
RELATED WORK,0.45121951219512196,"Tri-training. Our work is related to tri-training [37] which trains three classifiers and refines them
using unlabeled samples. In each round, an unlabeled sample is labeled for one classifier if the other
two agree on the label, under specific conditions. While tri-mentoring is inspired by tri-training, there
are fundamental differences between them: (1) Tri-training aims to enhance classification tasks by
mitigating label noise, while tri-mentoring focuses on producing a more robust regression ensemble;
(2) Tri-training leverages unlabeled data, while tri-mentoring operates on samples near the current
optimization point; (3) Tri-mentoring incorporates an adaptive soft-labeling module to mitigate label
noise, which is not present in tri-training. In addition to tri-training and tri-mentoring, there are other
research works [38] [39] [40] involving multiple proxies cooperating to improve learning. Unlike
tri-training and tri-mentoring with three proxies, these methods focus on two proxies."
RELATED WORK,0.45528455284552843,"Bi-level optimization for hyperparameter optimization. Bi-level optimization has become increas-
ingly popular for hyperparameter optimization [41–46] due to the hierarchical problem structure [47].
In the inner level, the relationship between model parameters and hyperparameters is established
by minimizing the training loss. Meanwhile, the outer level optimizes hyperparameters through
the connection built at the inner level by minimizing the validation loss. A specific category of
hyperparameters is soft-label [48, 49], which is updated under the guidance of noise-free data to
reduce noise. In this paper, we propose adaptive soft-labeling to reduce noise in the consensus labels."
RELATED WORK,0.45934959349593496,"Ensemble learning. Ensemble learning techniques train multiple base learners and aggregate
their predictions to achieve better performance and generalization than individual base learners
alone [8, 9, 50, 10, 11, 51, 52]. These methods can be broadly classified into boosting [53, 54],
bagging [55], and stacking [56]. In contrast to our proposed tri-mentoring, where multiple proxies
collaborate to enhance the learning process, ensemble learning mainly involves interaction during the
aggregation phase, without influencing each other’s training."
RELATED WORK,0.4634146341463415,"Pairwise learning to rank. Learning to rank [16, 57] has been extensively employed by commercial
search engines for ranking search results [58, 59]. Unlike pointwise methods that score inputs, pair-
wise methods focus on relative order, aligning more with ranking concepts [57]. Recent research [60]
applies pairwise binary cross-entropy loss for training reward models in reinforcement learning, a
technique used in ChatGPT [18]. Our work expresses a proxy’s ranking ability through pairwise
comparison labels, generating consensus labels via majority voting to enable mutual mentoring."
CONCLUSION,0.46747967479674796,"6
Conclusion"
CONCLUSION,0.4715447154471545,"In this work, we introduce parallel-mentoring to enhance ensemble robustness against out-of-
distribution issues through mutual mentoring among proxies. Focusing on a three-proxy case,
we instantiate this as tri-mentoring, with two modules: voting-based pairwise supervision for gen-
erating consensus labels, and adaptive soft-labeling which mitigates label noise through bi-level
optimization. Experimental results validate our approach’s effectivenss. We discuss potential negative
impacts in Appendix A.9 and limitations in Appendix A.10."
ACKNOWLEDGEMENT,0.47560975609756095,"7
Acknowledgement"
ACKNOWLEDGEMENT,0.4796747967479675,"We thank CIFAR for support under the AI Chairs program. This research was empowered in part by
the computational support provided by Compute Canada (www.computecanada.ca)."
REFERENCES,0.483739837398374,References
REFERENCES,0.4878048780487805,"[1] Brandon Trabucco, Xinyang Geng, Aviral Kumar, and Sergey Levine. Design-bench: Bench-
marks for data-driven offline model-based optimization. arXiv preprint arXiv:2202.08450,
2022."
REFERENCES,0.491869918699187,"[2] Kam Hamidieh. A data-driven statistical model for predicting the critical temperature of a
superconductor. Computational Materials Science, 2018."
REFERENCES,0.4959349593495935,"[3] Karen S Sarkisyan et al. Local fitness landscape of the green fluorescent protein. Nature, 2016."
REFERENCES,0.5,"[4] Christof Angermueller, David Dohan, David Belanger, Ramya Deshpande, Kevin Murphy, and
Lucy Colwell. Model-based reinforcement learning for biological sequence design. In Proc. Int.
Conf. Learning Rep. (ICLR), 2019."
REFERENCES,0.5040650406504065,"[5] Luis A Barrera et al. Survey of variation in human transcription factors reveals prevalent dna
binding changes. Science, 2016."
REFERENCES,0.508130081300813,"[6] Paul J Sample, Ban Wang, David W Reid, Vlad Presnyak, Iain J McFadyen, David R Morris,
and Georg Seelig. Human 5 UTR design and variant effect prediction from a massively parallel
translation assay. Nature Biotechnology, 2019."
REFERENCES,0.5121951219512195,"[7] Brandon Trabucco, Aviral Kumar, Xinyang Geng, and Sergey Levine. Conservative objective
models for effective offline model-based optimization. In Proc. Int. Conf. Learning Rep. (ICLR),
2021."
REFERENCES,0.516260162601626,"[8] Lars Kai Hansen and Peter Salamon. Neural network ensembles. IEEE transactions on pattern
analysis and machine intelligence, 1990."
REFERENCES,0.5203252032520326,"[9] Thomas G Dietterich. Ensemble methods in machine learning. In Multiple Classifier Systems:
First International Workshop, 2000."
REFERENCES,0.524390243902439,"[10] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable
predictive uncertainty estimation using deep ensembles. In Proc. Adv. Neur. Inf. Proc. Syst
(NeurIPS), 2017."
REFERENCES,0.5284552845528455,"[11] Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian Nowozin,
Joshua Dillon, Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model’s
uncertainty? evaluating predictive uncertainty under dataset shift. In Proc. Adv. Neur. Inf. Proc.
Syst (NeurIPS), 2019."
REFERENCES,0.532520325203252,"[12] Kevin K Yang, Zachary Wu, and Frances H Arnold. Machine-learning-guided directed evolution
for protein engineering. Nature methods, 2019."
REFERENCES,0.5365853658536586,"[13] Christof Angermueller, David Dohan, David Belanger, Ramya Deshpande, Kevin Murphy, and
Lucy Colwell. Model-based reinforcement learning for biological sequence design. In Proc. Int.
Conf. Learning Rep. (ICLR), 2020."
REFERENCES,0.540650406504065,"[14] Alvin Chan, Ali Madani, Ben Krause, and Nikhil Naik. Deep extrapolation for attribute-
enhanced generation. In Proc. Adv. Neur. Inf. Proc. Syst (NeurIPS), 2021."
REFERENCES,0.5447154471544715,"[15] Stanislav Fort, Huiyi Hu, and Balaji Lakshminarayanan. Deep ensembles: A loss landscape
perspective. arXiv preprint arXiv:1912.02757, 2019."
REFERENCES,0.5487804878048781,"[16] Ralph Allan Bradley and Milton E Terry. Rank analysis of incomplete block designs: I. the
method of paired comparisons. Biometrika, 1952."
REFERENCES,0.5528455284552846,"[17] Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep
reinforcement learning from human preferences. In Proc. Adv. Neur. Inf. Proc. Syst (NeurIPS),
2017."
REFERENCES,0.556910569105691,"[18] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin,
Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to
follow instructions with human feedback. arXiv preprint arXiv:2203.02155, 2022."
REFERENCES,0.5609756097560976,"[19] Edward Grefenstette, Brandon Amos, Denis Yarats, Phu Mon Htut, Artem Molchanov, Franziska
Meier, Douwe Kiela, Kyunghyun Cho, and Soumith Chintala. Generalized inner loop meta-
learning. arXiv preprint arXiv:1910.01727, 2019."
REFERENCES,0.5650406504065041,"[20] Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang,
and Wojciech Zaremba. Openai gym. arXiv preprint arXiv:1606.01540, 2016."
REFERENCES,0.5691056910569106,"[21] Michael Ahn, Henry Zhu, Kristian Hartikainen, Hugo Ponte, Abhishek Gupta, Sergey Levine,
and Vikash Kumar. Robel: Robotics benchmarks for learning with low-cost robots. In Conf. on
Robot Lea. (CoRL), 2020."
REFERENCES,0.573170731707317,"[22] Jerome H Friedman. Greedy function approximation: a gradient boosting machine. Annals of
statistics, 2001."
REFERENCES,0.5772357723577236,"[23] Sihyun Yu, Sungsoo Ahn, Le Song, and Jinwoo Shin. Roma: Robust model adaptation for
offline model-based optimization. In Proc. Adv. Neur. Inf. Proc. Syst (NeurIPS), 2021."
REFERENCES,0.5813008130081301,"[24] Justin Fu and Sergey Levine. Offline model-based optimization via normalized maximum
likelihood estimation. In Proc. Int. Conf. Learning Rep. (ICLR), 2021."
REFERENCES,0.5853658536585366,"[25] Can Chen, Yingxue Zhang, Jie Fu, Xue Liu, and Mark Coates. Bidirectional learning for offline
infinite-width model-based optimization. In Proc. Adv. Neur. Inf. Proc. Syst (NeurIPS), 2022."
REFERENCES,0.5894308943089431,"[26] Han Qi, Yi Su, Aviral Kumar, and Sergey Levine. Data-driven model-based optimization via
invariant representation learning. In Proc. Adv. Neur. Inf. Proc. Syst (NeurIPS), 2022."
REFERENCES,0.5934959349593496,"[27] James T Wilson, Riccardo Moriconi, Frank Hutter, and Marc Peter Deisenroth. The reparame-
terization trick for acquisition functions. arXiv preprint arXiv:1712.00424, 2017."
REFERENCES,0.5975609756097561,"[28] Nikolaus Hansen. The cma evolution strategy: a comparing review. Towards a new evolutionary
computation: Advances in the estimation of distribution algorithms, 2006."
REFERENCES,0.6016260162601627,"[29] Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforce-
ment learning. Machine Learning, 1992."
REFERENCES,0.6056910569105691,"[30] David Brookes, Hahnbeom Park, and Jennifer Listgarten. Conditioning by adaptive sampling
for robust design. In Proc. Int. Conf. Machine Lea. (ICML), 2019."
REFERENCES,0.6097560975609756,"[31] Clara Fannjiang and Jennifer Listgarten. Autofocused oracles for model-based design. In Proc.
Adv. Neur. Inf. Proc. Syst (NeurIPS), 2020."
REFERENCES,0.6138211382113821,"[32] Aviral Kumar and Sergey Levine. Model inversion networks for model-based optimization. In
Proc. Adv. Neur. Inf. Proc. Syst (NeurIPS), 2020."
REFERENCES,0.6178861788617886,"[33] Minsu Kim, Federico Berto, Sungsoo Ahn, and Jinkyoo Park.
Bootstrapped training of
score-conditioned generator for offline design of biological sequences.
arXiv preprint
arXiv:2306.03111, 2023."
REFERENCES,0.6219512195121951,"[34] Can Chen, Yingxue Zhang, Xue Liu, and Mark Coates. Bidirectional learning for offline
model-based biological sequence design. In Proc. Int. Conf. Machine Lea. (ICML), 2023."
REFERENCES,0.6260162601626016,"[35] Moksh Jain, Emmanuel Bengio, Alex Hernandez-Garcia, Jarrid Rector-Brooks, Bonaventure FP
Dossou, Chanakya Ajit Ekbote, Jie Fu, Tianyu Zhang, Michael Kilgour, Dinghuai Zhang, et al.
Biological sequence design with gflownets. In Proc. Int. Conf. Machine Lea. (ICML). PMLR,
2022."
REFERENCES,0.6300813008130082,"[36] Ye Yuan, Can Chen, Zixuan Liu, Willie Neiswanger, and Xue Liu. Importance-aware co-
teaching for offline model-based optimization. In Proc. Adv. Neur. Inf. Proc. Syst (NeurIPS),
2023."
REFERENCES,0.6341463414634146,"[37] Zhi-Hua Zhou and Ming Li. Tri-training: Exploiting unlabeled data using three classifiers.
IEEE Transactions on knowledge and Data Engineering, 2005."
REFERENCES,0.6382113821138211,"[38] Eran Malach and Shai Shalev-Shwartz. Decoupling ""when to update"" from ""how to update"". In
Proc. Adv. Neur. Inf. Proc. Syst (NeurIPS), 2017."
REFERENCES,0.6422764227642277,"[39] Avrim Blum and Tom Mitchell. Combining labeled and unlabeled data with co-training. In
Proceedings of the eleventh annual conference on Computational learning theory, 1998."
REFERENCES,0.6463414634146342,"[40] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi
Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels.
In Proc. Adv. Neur. Inf. Proc. Syst (NeurIPS), volume 31, 2018."
REFERENCES,0.6504065040650406,"[41] Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimiliano Pontil.
Bilevel programming for hyperparameter optimization and meta-learning. In Proc. Int. Conf.
Machine Lea. (ICML), 2018."
REFERENCES,0.6544715447154471,"[42] Can Chen, Shuhao Zheng, Xi Chen, Erqun Dong, Xue Steve Liu, Hao Liu, and Dejing Dou.
Generalized data weighting via class-level gradient manipulation. Proc. Adv. Neur. Inf. Proc.
Syst (NeurIPS), 2021."
REFERENCES,0.6585365853658537,"[43] Can Chen, Xi Chen, Chen Ma, Zixuan Liu, and Xue Liu. Gradient-based bi-level optimization
for deep learning: A survey. arXiv preprint arXiv:2207.11719, 2022."
REFERENCES,0.6626016260162602,"[44] Can Chen, Chen Ma, Xi Chen, Sirui Song, Hao Liu, and Xue Liu. Unbiased implicit feedback
via bi-level optimization. arXiv preprint arXiv:2206.00147, 2022."
REFERENCES,0.6666666666666666,"[45] Can Chen, Jingbo Zhou, Fan Wang, Xue Liu, and Dejing Dou. Structure-aware protein self-
supervised learning. Bioinformatics, 2023."
REFERENCES,0.6707317073170732,"[46] Zhixiang Chi, Li Gu, Huan Liu, Yang Wang, Yuanhao Yu, and Jin Tang. Metafscil: A meta-
learning approach for few-shot class incremental learning. In Proc. IEEE/CVF Conf. Comput.
Vis. Pattern Recogn. (CVPR), 2022."
REFERENCES,0.6747967479674797,"[47] Tommaso Giovannelli, Griffin Kent, and Luis Nunes Vicente. Bilevel optimization with a
multi-objective lower-level problem: Risk-neutral and risk-averse formulations. arXiv preprint
arXiv:2302.05540, 2023."
REFERENCES,0.6788617886178862,"[48] Yichen Wu, Jun Shu, Qi Xie, Qian Zhao, and Deyu Meng. Learning to purify noisy labels via
meta soft label corrector. In Proceedings of the AAAI Conference on Artificial Intelligence,
2021."
REFERENCES,0.6829268292682927,"[49] Görkem Algan and Ilkay Ulusoy. Meta soft label generation for noisy labels. In 2020 25th
International Conference on Pattern Recognition (ICPR), 2021."
REFERENCES,0.6869918699186992,"[50] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network.
arXiv preprint arXiv:1503.02531, 2015."
REFERENCES,0.6910569105691057,"[51] Zeyuan Allen-Zhu and Yuanzhi Li. Towards understanding ensemble, knowledge distillation
and self-distillation in deep learning. In Proc. Int. Conf. Learning Rep. (ICLR), 2023."
REFERENCES,0.6951219512195121,"[52] Olivier Laurent, Adrien Lafage, Enzo Tartaglione, Geoffrey Daniel, Jean marc Martinez, Andrei
Bursuc, and Gianni Franchi. Packed ensembles for efficient uncertainty estimation. In Proc. Int.
Conf. Learning Rep. (ICLR), 2023."
REFERENCES,0.6991869918699187,"[53] Yoav Freund, Robert Schapire, and Naoki Abe. A short introduction to boosting. Journal-
Japanese Society For Artificial Intelligence, 1999."
REFERENCES,0.7032520325203252,"[54] Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of
the 22nd acm sigkdd international conference on knowledge discovery and data mining, 2016."
REFERENCES,0.7073170731707317,"[55] Leo Breiman. Bagging predictors. Machine learning, 1996."
REFERENCES,0.7113821138211383,"[56] David H Wolpert. Stacked generalization. Neural networks, 1992."
REFERENCES,0.7154471544715447,"[57] Tie-Yan Liu et al. Learning to rank for information retrieval. Foundations and Trends® in
Information Retrieval, 2009."
REFERENCES,0.7195121951219512,"[58] Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Greg
Hullender. Learning to rank using gradient descent. In Proc. Int. Conf. Learning Rep. (ICLR),
2005."
REFERENCES,0.7235772357723578,"[59] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. Bpr:
Bayesian personalized ranking from implicit feedback. arXiv preprint arXiv:1205.2618, 2012."
REFERENCES,0.7276422764227642,"[60] Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec
Radford, Dario Amodei, and Paul F Christiano. Learning to summarize with human feedback.
In Proc. Adv. Neur. Inf. Proc. Syst (NeurIPS), 2020."
REFERENCES,0.7317073170731707,"A
Appendix"
REFERENCES,0.7357723577235772,"A.1
Scenarios for Parallel Mentoring with Multiple Proxies"
REFERENCES,0.7398373983739838,"A.1.1
Method"
REFERENCES,0.7439024390243902,"In the primary paper, we mainly focus on a scenario with three proxies. Here, we extend our method
to incorporate M proxies. We revisit the two essential modules."
REFERENCES,0.7479674796747967,"Voting-based pairwise supervision. We train M (M ≥3) parallel proxies, f 1
θ(·), f 2
θ(·), · · · , f M
θ (·),
each initialized differently, on the static dataset. Their mean is utilized as the final prediction:"
REFERENCES,0.7520325203252033,fθ(·) = 1
REFERENCES,0.7560975609756098,"M (f 1
θ(·) + f 2
θ(·) + · · · f M
θ (·)).
(10)"
REFERENCES,0.7601626016260162,"We generate the pairwise comparison labels ˆy1, ˆy2, · · · , and ˆyM for each proxy in the same way.
We extend the subsequent majority voting part and derive the pairwise consensus labels ˆyV via an
element-wise majority voting:"
REFERENCES,0.7642276422764228,"ˆyV
ij = majority_voting(ˆy1
ij, ˆy2
ij, · · · , ˆyM
ij ).
(11)"
REFERENCES,0.7682926829268293,"Here, i and j are the indexes of the neighborhood samples."
REFERENCES,0.7723577235772358,"Adaptive soft-labeling. This module remains the same as it is designed for an individual proxy. We
carry out fine-tuning and soft-labeling via bi-level optimization to adaptively mentor the proxy."
REFERENCES,0.7764227642276422,"Setting on M. In Eq.(11), M can be any positive number greater than 2 as a decision may not be
reached with just two proxies. In this study, we consider M as an odd number to ensure a decisive
outcome in the voting process. Cases with an even number of proxies can be handled by adopting
strategies like maintaining the original labels and skipping the fine-tuning step when the proxies
are evenly split in their labels. However, we do not delve into these cases for brevity. We examine
scenarios with M equal to 3, 5, 7, 9, and 11."
REFERENCES,0.7804878048780488,"A.1.2
Experiments"
REFERENCES,0.7845528455284553,"We conduct experiments on the Ant task and the TFB8 task. The performance ratio comparing the
performance of parallel mentoring to that of tri-mentoring, is computed as a function of M (the
number of proxies). The results are displayed in Figure 6."
REFERENCES,0.7886178861788617,"(1) Our observations indicate that as the number of proxies (M) increases, the performance ratios for
both tasks initially improve, eventually reaching a plateau. This behavior suggests that an increased
number of proxies enhances the robustness of the ensemble due to the increased diversity. However,
this impact lessens as the number of proxies increases further, with the ensemble’s robustness
plateauing after a certain point. (2) Somewhat unexpectedly, the performance with M = 7 shows a
slight dip on the Ant task. A possible explanation for this could be the dynamics of the voting system.
When we have M = 3, some voting happens when two proxies agree but conflict with the third.
However, when M increases to 7, voting may occur when four proxies align with one another but
dissent with the remaining three. Such a scenario can make consensus labels less reliable, potentially
explaining the poor performance of the M = 7 case on the Ant task. (3) Finally, it’s important to
note that adding more proxies also amplifies computational complexity. This increase could become
a restricting factor when trying to scale the method to include a larger number of proxies."
REFERENCES,0.7926829268292683,"A.2
Novelty of Adaptive Soft-labeling"
REFERENCES,0.7967479674796748,"Our adaptive soft-labeling approach, while bearing some superficial resemblance to existing bi-level
optimization methods applied to soft-labels, possesses unique characteristics that underscore its
innovation. In this appendix, we detail these distinctive facets."
REFERENCES,0.8008130081300813,"Initialization: Contrary to previous works that aim to address label noise in a collected dataset, our
method handles label noise created by a unique voting mechanism along the optimization path."
REFERENCES,0.8048780487804879,"Optimization: Previous work typically leverages the classification loss of a clean validation set
to update the soft-label. However, our method proposes an innovative strategy of employing the
regression loss of the static dataset for soft-label updates. This unique strategy is due to our novel"
REFERENCES,0.8089430894308943,"3
5
7
9
11
Num of proxies M 0.995 1.000 1.005"
REFERENCES,0.8130081300813008,"1.010
1.012"
REFERENCES,0.8170731707317073,Performance ratio
REFERENCES,0.8211382113821138,"TFB8
Ant"
REFERENCES,0.8252032520325203,"Figure 6: Ratio of performance with M prox-
ies to performance with M = 3 proxies."
REFERENCES,0.8292682926829268,"0.05
0.1
0.15
0.2
0.25
Standard deviation 0.975 0.985 0.995 1.005 1.015"
REFERENCES,0.8333333333333334,Performance ratio
REFERENCES,0.8373983739837398,"TFB8
Ant"
REFERENCES,0.8414634146341463,"Figure 7: Ratio of performance with standard
deviation δ to performance with δ = 0.10."
REFERENCES,0.8455284552845529,"Table 4: Results (median normalized score) on continuous tasks.
Method
Superconductor
Ant Morphology
D’Kitty Morphology
Hopper Controller
D(best)
0.399
0.565
0.884
1.000
BO-qEI
0.300 ± 0.015
0.567 ± 0.000
0.883 ± 0.000
0.343 ± 0.010
CMA-ES
0.379 ± 0.003
−0.045 ± 0.004
0.684 ± 0.016
−0.033 ± 0.005
REINFORCE
0.463 ± 0.016
0.138 ± 0.032
0.356 ± 0.131
−0.064 ± 0.003
CbAS
0.111 ± 0.017
0.384 ± 0.016
0.753 ± 0.008
0.015 ± 0.002
Auto.CbAS
0.131 ± 0.010
0.364 ± 0.014
0.736 ± 0.025
0.019 ± 0.008
MIN
0.336 ± 0.016
0.618 ± 0.040
0.887 ± 0.004
0.352 ± 0.058
Grad
0.339 ± 0.015
0.564 ± 0.014
0.877 ± 0.005
0.384 ± 0.004
DE
0.333 ± 0.004
0.570 ± 0.011
0.875 ± 0.004
0.385 ± 0.007
GB
0.373 ± 0.013
0.550 ± 0.021
0.869 ± 0.009
0.374 ± 0.008
COMs
0.316 ± 0.022
0.568 ± 0.002
0.883 ± 0.002
0.346 ± 0.009
ROMA
0.368 ± 0.019
0.475 ± 0.036
0.856 ± 0.008
0.388 ± 0.007
NEMO
0.322 ± 0.008
0.593 ± 0.000
0.885 ± 0.000
0.361 ± 0.001
IOM
0.348 ± 0.022
0.516 ± 0.037
0.876 ± 0.007
0.368 ± 0.008
BDI
0.412 ± 0.000
0.474 ± 0.000
0.855 ± 0.000
0.408 ± 0.000
tri-mentoring
0.355 ± 0.003
0.606 ± 0.007
0.886 ± 0.001
0.391 ± 0.004"
REFERENCES,0.8495934959349594,"recognition that, despite their differing data distributions, the soft-labels and the static dataset share
significant underlying similarities. They both represent the same ground-truth from pairwise and
pointwise perspectives, respectively."
REFERENCES,0.8536585365853658,"Objective: Whereas previous works primarily focus on mitigating label noise to enhance the
performance of a classification model, our work takes a distinctive route by addressing label noise to
improve the performance of a regression model for offline MBO. This adaptation to a new context
further underscores the innovative aspects of our approach."
REFERENCES,0.8577235772357723,"A.3
Additional Results on 50th Percentile Scores"
REFERENCES,0.8617886178861789,"In the main paper, we presented the 100th percentile scores. Here, we offer supplementary results
on the 50th percentile scores, which have been previously utilized in the design-bench work [1], to
further validate the efficacy of tri-mentoring. Continuous task results can be found in Table 4 while
discrete task results and ranking statistics are shown in Table 5. A review of Table 5 reveals that
tri-mentoring achieves the highest ranking, demonstrating its effectiveness in this context."
REFERENCES,0.8658536585365854,"A.4
Integration of COMs and ROMA with Tri-mentoring"
REFERENCES,0.8699186991869918,"We explore the integration of ROMA and COMs with our tri-mentoring approach. The results in
Table 6 offer insights into the outcomes when combining these methods on the Ant and TFB8 tasks."
REFERENCES,0.8739837398373984,"When COMs are combined with tri-mentoring, a slight drop in performance is observed. This
decrease might originate from COMs’ propensity to score lower for out-of-distribution designs,
potentially conflicting with tri-mentoring’s majority voting mechanism for such designs."
REFERENCES,0.8780487804878049,"Table 5: Results (median normalized score) on discrete tasks & ranking on all tasks.
Method
TF Bind 8
TF Bind 10
NAS
Rank Mean
Rank Median
D(best)
0.439
0.467
0.436
BO-qEI
0.439 ± 0.000
0.467 ± 0.000
0.544 ± 0.099
8.0/15
8/15
CMA-ES
0.537 ± 0.014
0.484 ± 0.014
0.591 ± 0.102
8.0/15
5/15
REINFORCE
0.462 ± 0.021
0.475 ± 0.008
−1.895 ± 0.000
10.6/15
14/15
CbAS
0.428 ± 0.010
0.463 ± 0.007
0.292 ± 0.027
12.7/15
12/15
Auto.CbAS
0.419 ± 0.007
0.461 ± 0.007
0.217 ± 0.005
13.3/15
13/15
MIN
0.421 ± 0.015
0.468 ± 0.006
0.433 ± 0.000
7.7/15
9/15
Grad
0.532 ± 0.017
0.529 ± 0.027
0.443 ± 0.126
6.1/15
6/15
DE
0.581 ± 0.034
0.534 ± 0.014
0.474 ± 0.085
5.4/15
4/15
GB
0.503 ± 0.054
0.455 ± 0.020
0.559 ± 0.090
7.3/15
6/15
COMs
0.439 ± 0.000
0.466 ± 0.002
0.529 ± 0.003
7.9/15
8/15
ROMA
0.548 ± 0.017
0.516 ± 0.020
0.529 ± 0.008
5.7/15
5/15
NEMO
0.439 ± 0.018
0.456 ± 0.015
0.568 ± 0.021
7.0/15
8/15
IOM
0.437 ± 0.010
0.475 ± 0.010
−0.083 ± 0.012
9.0/15
7/15
BDI
0.439 ± 0.000
0.476 ± 0.000
0.517 ± 0.000
6.6/15
7/15
tri-mentoring
0.609 ± 0.021
0.527 ± 0.008
0.516 ± 0.028
3.4/15
2/15"
REFERENCES,0.8821138211382114,Table 6: Integration results for tri-mentoring with COMs and ROMA.
REFERENCES,0.8861788617886179,"Method
Ant
TFB8
COMs
0.856
0.496
Tri-mentoring
0.948
0.970
COMs + Tri-mentoring
0.941
0.960
ROMA
0.914
0.917
ROMA + Tri-mentoring
0.945
0.971"
REFERENCES,0.8902439024390244,"Conversely, ROMA inherently promotes smoother proxy models, a characteristic theoretically or-
thogonal to our tri-mentoring method. The presented results hint that our current benchmarks might
not be adequately challenging to fully exploit the combined strengths of ROMA and tri-mentoring."
REFERENCES,0.8943089430894309,"A.5
Training Time Analysis"
REFERENCES,0.8983739837398373,"Understanding the time complexity and computational overhead of a method is crucial for practical
implementations. Hence, we provide detailed estimates for the training time of our approach."
REFERENCES,0.9024390243902439,"For a single proxy training on the static dataset, the training time required is 101.1 s for TFB8 and
33.5 s for Ant. This training duration remains consistent across all methods employing a proxy. The
added time overhead in tri-mentoring arises mainly from the proxy fine-tuning step. Specifically, the
fine-tuning step takes 0.21 s for TFB8 and 0.08 s for Ant."
REFERENCES,0.9065040650406504,"Given the minimal overhead of our method, especially when considering its benefits, we believe it
presents a feasible and efficient choice for researchers and practitioners aiming for effective results
without compromising on speed."
REFERENCES,0.9105691056910569,"A.6
Validation of Tri-mentoring against Out-of-distribution Issues"
REFERENCES,0.9146341463414634,"To substantiate our tri-mentoring approach’s competence in addressing out-of-distribution (OOD)
challenges, we have performed additional experiments on TFBind8 and TFBind10. We choose the
two tasks as we could easily identify high-scoring designs and thereby create an out-of-distribution
test set. From each dataset, we sample 1000 high-scoring designs to form our OOD test sets. For
these, our tri-mentoring ensemble have been tested over 5 runs against a mean ensemble and a single
proxy, and the mean squared error (MSE) is used as the metric. These results in Table 7 illustrate that
the tri-mentoring ensemble consistently outperforms the other models in handling OOD designs."
REFERENCES,0.9186991869918699,"A.7
Accuracy of Pairwise Consensus Labels"
REFERENCES,0.9227642276422764,"In addition to the performance results presented in the main paper, we also examine the accuracy
of the optimized consensus labels ˆyS′. This analysis further substantiates the effectiveness of our"
REFERENCES,0.926829268292683,Table 7: MSE Results for OOD Validation using TFBind8 and TFBind10 Datasets
REFERENCES,0.9308943089430894,"Model
TFBind8 (MSE)
TFBind10 (MSE)
Tri-mentoring ensemble
0.0537 ± 0.0008
0.2271 ± 0.0075
Mean ensemble
0.0549 ± 0.0006
0.2669 ± 0.0084
Single proxy
0.0660 ± 0.0012
0.2776 ± 0.0185"
REFERENCES,0.9349593495934959,"method. For the D’Kitty and TFB8 tasks, we utilize the ground-truth function to determine the
ground-truth pairwise labels. This enables us to assess the accuracy of ˆyS′. For easier accuracy
computation, these labels are converted into one-hot labels."
REFERENCES,0.9390243902439024,"(1) Recall that the pairwise comparison labels of a single proxy serve as its ranking supervision
signals. In our analysis, we found that for a single proxy, 13.45% of pairwise comparison labels for
the D’Kitty task and 8.38% for the TFB8 task differ from the optimized consensus labels ˆyS′. This
reveals the extent to which our method modifies the original labels. (2) Further analysis shows that, of
the conflicting optimized labels, 62.91% are accurate for D’Kitty and 63.16% are accurate for TFB8.
These results reinforce the overall efficacy of our method. (3) When we remove the voting-based
pairwise supervision module, we note a decrease in accuracy from 62.91% to 52.21% for D’Kitty
and from 63.16% to 55.63% for TFB8. Similarly, omitting the adaptive soft-labeling module leads
to a drop in accuracy from 62.91% to 57.16% for D’Kitty and from 63.16% to 60.86% for TFB8.
These experiments underscore the crucial role of both modules in preserving the label accuracy."
REFERENCES,0.943089430894309,"A.8
Additional Analysis on Sensitivity to the Standard Deviation Hyperparameter"
REFERENCES,0.9471544715447154,"We further delve into how the standard deviation hyperparameter δ in neighborhood sampling, impacts
the performance of our method. We experiment with δ values of 0.05, 0.10, 0.15, 0.20, and 0.25,
with 0.10 being the default value employed in this paper. The results are normalized by dividing them
by the result obtained for δ = 0.10. As demonstrated in Figure 7, tri-mentoring exhibits remarkable
robustness to variations in δ for both the continuous Ant and the discrete TFB8 tasks."
REFERENCES,0.9512195121951219,"We further explore γ and λ. We conduct additional experiments over varied ranges on TFB8 and Ant,
evaluating across the following values:"
REFERENCES,0.9552845528455285,"• γ: [2.5e −4, 5e −4, 1e −3, 2e −3, 4e −3]"
REFERENCES,0.959349593495935,"• λ: [0.025, 0.05, 0.1, 0.2, 0.4]"
REFERENCES,0.9634146341463414,"These results in Table 8 confirm the method’s resilience against hyperparameter variations on γ and
λ, emphasizing its potential for real-world scenarios despite its perceived complexity."
REFERENCES,0.967479674796748,Table 8: Sensitivity Analysis Results on TFB8 and Ant.
REFERENCES,0.9715447154471545,"TFB8
Ant
Parameter
2.5e-4
5e-4
1e-3
2e-3
4e-3
2.5e-4
5e-4
1e-3
2e-3
4e-3
γ
0.903
0.995
1.000
0.996
1.006
0.953
1.008
1.000
1.021
1.022
λ
0.945
0.983
1.000
1.000
0.995
1.011
0.989
1.000
0.992
0.997"
REFERENCES,0.975609756097561,"Last but not least, we explore the number of the fine-tuning step. We select a single step primarily
for efficiency and our comprehensive experiments indicate that increasing the number of fine-tuning
steps does not significantly impact the model’s performance, confirming the method’s robustness in
this regard. For the TFB8 dataset, the normalized results for 1, 2, 3, and 4 fine-tuning steps are 1.000,
0.986, 1.006, and 0.992 respectively. Similarly, for the Ant dataset, they are 1.000, 0.994, 1.000, and
0.985. As seen, the performance remains consistent across different numbers of steps."
REFERENCES,0.9796747967479674,"A.9
Broader Impacts"
REFERENCES,0.983739837398374,"Our work could potentially expedite the development of new materials, biomedical innovations,
or robotics technologies, leading to significant advancements in these areas. However, as with all
powerful tools, there are potential risks if misused. One potential negative impact could be the misuse
of this technology in designing objects or entities for harmful purposes. For instance, in the wrong
hands, the ability to optimize designs could be used to create more efficient weapons or harmful"
REFERENCES,0.9878048780487805,"biological agents. Therefore, it is crucial to implement appropriate safeguards and regulations on the
use of such technology, particularly in sensitive areas."
REFERENCES,0.991869918699187,"A.10
Limitations"
REFERENCES,0.9959349593495935,"Despite the promising results demonstrated by our method, its performance is largely dependent on
the accuracy of the design encoding. For tasks of high complexity, such as Neural Architecture Search
(NAS) - which represents each design as a 64-length sequence of 5-category one-hot vectors - the
performance of tri-mentoring is somewhat limited. This shortfall could be due to the default encoding
technique of design-bench [1], which may fail to adequately capture the sequential and hierarchical
nature of neural architectures, leading to ineffective gradient updates. This challenge suggests that,
while our method provides a general framework for offline model-based optimization, task-specific
techniques might be necessary for effective design encoding, especially in the context of complex
tasks. Potential future research could explore ways of integrating problem-specific knowledge into
the design encoding process to address these complexities more effectively."
