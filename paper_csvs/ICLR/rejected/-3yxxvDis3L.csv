Section,Section Appearance Order,Paragraph
ABSTRACT,0.0,ABSTRACT
ABSTRACT,0.0013477088948787063,"Conventional machine learning applications typically assume that data samples
are independently and identically distributed (i.i.d.). However, practical scenar-
ios often involve a data-generating process that produces highly dependent data
samples, which are known to heavily bias the stochastic optimization process and
slow down the convergence of learning. In this paper, we conduct a fundamental
study on how different structures of stochastic update schemes affect the sam-
ple complexity of stochastic gradient descent (SGD) over highly dependent data.
Speciﬁcally, with a φ-mixing model of data dependence, we show that SGD with
proper periodic data-subsampling achieves an improved sample complexity over
the standard SGD in the full spectrum of the data dependence level. Interest-
ingly, even subsampling a subset of data samples can accelerate the convergence
of SGD over highly dependent data. Moreover, we show that mini-batch SGD
can further substantially improve the sample complexity over SGD with periodic
data-subsampling over highly dependent data. We also conduct some numerical
experiments to validate our theoretical results."
INTRODUCTION,0.0026954177897574125,"1
INTRODUCTION"
INTRODUCTION,0.004043126684636119,"Stochastic optimization algorithms have attracted great attention in the past decade due to its suc-
cessful applications to a broad research areas, including deep learning (Goodfellow et al., 2016), re-
inforcement learning (Sutton & Barto, 2018), online learning (Bottou, 2010; Hazan, 2017), control
(Marti, 2017), etc. In the conventional analysis of stochastic optimization algorithms, it is usually
assumed that all data samples are independently and identically distributed (i.i.d.) and queried. For
example, data samples in the traditional empirical risk minimization framework are assumed to be
queried independently from the underlying data distribution, while data samples in reinforcement
learning are assumed to be queried from the stationary distribution of the underlying Markov chain."
INTRODUCTION,0.005390835579514825,"Although the i.i.d. data assumption leads to a comprehensive understanding of the statistical limit
and computation complexity of SGD, it violates the nature of many practical data-generating
stochastic processes, which generate highly correlated samples that depend on the history. In fact,
dependent data can be found almost everywhere, e.g., daily stock price, weather/climate data, state
transitions in Markov chains, etc. To understand the impact of data dependence on the convergence
and complexity of stochastic algorithms, there is a growing number of recent works that introduce
various deﬁnitions to quantify data dependence. Speciﬁcally, to analyze the ﬁnite-time convergence
of various stochastic reinforcement learning algorithms, recent studies assume that the dependent
samples queried from the Markov decision process satisfy a geometric mixing property (Dalal et al.,
2018; Zou et al., 2019; Xu & Gu, 2020; Qu & Wierman, 2020), which requires the underlying
Markov chain to be uniformly ergodic or has a ﬁnite mixing time (Even-Dar et al., 2003). On the
other hand, to analyze the convergence of stochastic optimization algorithms over dependent data,
Karimi et al. (2019) assumed the existence of a solution to the Poisson equation associated with the
underlying Markov chain, which is a weaker condition than the uniform ergodic condition (Glynn
& Meyn, 1996). Moreover, Agarwal & Duchi (2012) introduced a φ-mixing property of the data-
generating process that quantiﬁes how fast the distribution of future data samples (conditioned on a
ﬁxed ﬁltration) converges to the underlying stationary data distribution. In particular, the φ-mixing
property is more general than the previous two notions of data dependence (Douc et al., 2018)."
INTRODUCTION,0.006738544474393531,Under review as a conference paper at ICLR 2022
INTRODUCTION,0.008086253369272238,"While the aforementioned works leveraged the above notions of data dependence to characterize the
sample complexity of various standard stochastic algorithms over dependent data, there still lacks
theoretical understanding of how algorithm structure affects the sample complexity of stochastic
algorithms under different levels of data dependence. In particular, a key algorithm structure is the
stochastic update scheme, which critically affects the bias and variance of the stochastic optimiza-
tion process. In fact, under i.i.d. data and convex geometry, it is well known that SGD achieves
the sample complexity lower bound under various stochastic update schemes (Bottou, 2010), e.g.,
single-sample update and mini-batch update. However, these stochastic update schemes may lead
to substantially different convergence behaviors over highly dependent data, as they are no longer
unbiased. Therefore, it is of vital importance to understand the interplay among data dependence,
structure of stochastic update and convergence rate of stochastic algorithms, and we want to ask the
following fundamental question."
INTRODUCTION,0.009433962264150943,• Q: How does the structure of stochastic updates affect the convergence rate and sample
INTRODUCTION,0.01078167115902965,complexity of stochastic algorithms over dependent data?
INTRODUCTION,0.012129380053908356,"In this paper, we provide comprehensive answers to the above fundamental question. Speciﬁcally,
we conduct a comprehensive study of the convergence rate and sample complexity of the SGD
algorithm over a wide spectrum of data dependence levels under various types of stochastic updates,
including periodic subsampling and mini-batch sampling. Our results show that SGD with both
stochastic updates achieves a substantially improved sample complexity over the standard SGD
under highly dependent data. We summarize our contributions as follows."
OUR CONTRIBUTIONS,0.013477088948787063,"1.1
OUR CONTRIBUTIONS"
OUR CONTRIBUTIONS,0.014824797843665768,We consider the following standard stochastic optimization problem.
OUR CONTRIBUTIONS,0.016172506738544475,"min
w∈W f(w) := Eξ∼µ

F(w; ξ)

,
(P)"
OUR CONTRIBUTIONS,0.01752021563342318,"where the objective function f is convex and Lipschitz continuous, and the expectation is taken over
the stationary distribution µ of the underlying data-generating process P. To perform stochastic
optimization, we query a stream of dependent data samples from the underlying data-generating
process. Speciﬁcally, we adopt the φ-mixing model to quantify the data dependence via a decaying
mixing coefﬁcient function φξ(k) (see Deﬁnition 2.2) (Agarwal & Duchi, 2012). We study the con-
vergence of the stochastic gradient descent (SGD) algorithm over φ-mixing dependent data samples
under various stochastic update schemes, including data subsampling and mini-batch sampling."
OUR CONTRIBUTIONS,0.018867924528301886,"We ﬁrst study the convergence of SGD over φ-mixing dependent data samples under the data sub-
sampling update scheme. In particular, the data subsampling update scheme utilizes only one data
sample per r consecutive data samples by periodically skipping r −1 samples. With this data sub-
sampling scheme, the subsampled data samples are less dependent for a larger subsampling period
r. Consequently, we show that SGD with a proper data subsampling period achieves an improved
sample complexity over that of the standard SGD in the full spectrum of the convergence rate of the
φ-mixing coefﬁcient. In particular, the improvement is substantial when the data is highly dependent
with an algebraic decaying φ-mixing coefﬁcient."
OUR CONTRIBUTIONS,0.02021563342318059,"Moreover, we study the sample complexity of SGD over φ-mixing dependent data samples under
the mini-batch update scheme. Compare to the data subsampling update, mini-batch update can
substantially reduce the mini-batch data dependence without skipping data samples. Consequently,
mini-batch update leverages the sample average over a mini batch of data samples to reduce both the
bias (caused by the data dependence) and the optimization variance. Speciﬁcally, we show that SGD
with mini-batch update achieves an orderwise lower sample complexity than both the standard SGD
and the SGD with data subsampling in the full spectrum of the convergence rate of the φ-mixing
coefﬁcient. We summarize and compare the sample complexities of these stochastic algorithms
under different φ-mixing data dependence models in Table 1."
RELATED WORK,0.0215633423180593,"1.2
RELATED WORK"
RELATED WORK,0.022911051212938006,"Stochastic Algorithms over Dependent Data
Steinwart & Christmann (2009) and Modha &
Masry (1996) established the convergence analysis of online stochastic algorithms for streaming"
RELATED WORK,0.02425876010781671,Under review as a conference paper at ICLR 2022
RELATED WORK,0.025606469002695417,"Table 1: Comparison of sample complexities of SGD, SGD with data subsampling and Mini-batch
SGD under different levels of data dependence for achieving f(w) −f(w∗) ≤ϵ. Note that θ is a
parameter of the convergence rate of the φ-mixing coefﬁcient."
RELATED WORK,0.026954177897574125,"Data dependence level
φξ(k)
SGD
SGD w/ subsampling
Mini-batch SGD"
RELATED WORK,0.02830188679245283,"Geometric φ-mixing
exp(−kθ),
O(ϵ−2(log ϵ−1)
2
θ )
O(ϵ−2(log ϵ−1)
1
θ )
O(ϵ−2)
(Weakly dependent)
θ > 0"
RELATED WORK,0.029649595687331536,"Fast algebraic φ-mixing
k−θ,
O(ϵ−2−2"
RELATED WORK,0.03099730458221024,"θ )
O(ϵ−2−1"
RELATED WORK,0.03234501347708895,"θ )
e
O(ϵ−2)
(Medium dependent)
θ ≥1"
RELATED WORK,0.03369272237196765,"Slow algebraic φ-mixing
k−θ,
O(ϵ−2−2"
RELATED WORK,0.03504043126684636,"θ )
O(ϵ−2−1"
RELATED WORK,0.03638814016172507,"θ )
O(ϵ−1−1"
RELATED WORK,0.03773584905660377,"θ )
(Highly dependent)
0 < θ < 1"
RELATED WORK,0.03908355795148248,"data with geometric ergodicity. Duchi et al. (2011) proved that the stochastic subgradient method
has strong convergence guarantee if the mixing time is uniformly bounded. Agarwal & Duchi (2012)
studied the convex/strongly convex stochastic optimization problem and proved high-probability
convergence bounds for general stochastic algorithms under general stationary mixing processes.
Godichon-Baggioni et al. (2021) provided the non-asymptotic analysis of stochastic algorithms with
strongly convex objective function over streaming mini-batch data. In a more general setting, the
stochastic approximation (SA) problem was studied in (Karimi et al., 2019) by assuming the exis-
tence of solution to a Poisson equation. Recently, Debavelaere et al. (2021) developed the asymptotic
convergence analysis of SA problem for sub-geometric Markov dynamic noises."
RELATED WORK,0.04043126684636118,"Finite-time convergence of reinforcement learning
Recently, a series of work studied the ﬁnite-
time convergence of many stochastic reinforcement learning algorithms over Markovian dependent
samples, including TD learning (Dalal et al., 2018; Xu et al., 2019; Kaledin et al., 2020), Q-learning
(Qu & Wierman, 2020; Li et al., 2021; Melo et al., 2008; Chen et al., 2019; Xu & Gu, 2020), ﬁtted Q-
iteration (Mnih et al., 2013; 2015; Agarwal et al., 2021), actor-critic algorithms (Wang et al., 2019;
Yang et al., 2019; Kumar et al., 2019; Qiu et al., 2019; Wu et al., 2020; Xu et al., 2020), etc. In these
studies, the dependent Markovian samples are assumed to satisfy the geometric φ-mixing property,
which is satisﬁed when the underlying Markov chain is uniformly ergodic or time-homogeneous
with ﬁnite-states."
RELATED WORK,0.04177897574123989,"Regret of Stochastic Convex Optimization
There have been many known regret bounds for on-
line convex optimization problem. Hazan (2017) has built the standard O(
√"
RELATED WORK,0.0431266846361186,"T) regret bound for on-
line SGD algorithm with assuming the bounded gradient. Xiao (2009) introduces the regret bound
of online dual averaging method. To our best knowledge, there is no high-probability guaranteed
regret bound for mini-batch SGD algorithm with considering the data dependence."
PROBLEM FORMULATION AND ASSUMPTIONS,0.0444743935309973,"2
PROBLEM FORMULATION AND ASSUMPTIONS"
PROBLEM FORMULATION AND ASSUMPTIONS,0.04582210242587601,"In this section, we introduce the problem formulation and some basic assumptions. Consider a
model with parameters w. For any data sample ξ, denote F(w; ξ) ∈R as the sample loss of this data
sample under the model w. In this paper, we consider the following standard stochastic optimization
problem that has broad applications in machine learning."
PROBLEM FORMULATION AND ASSUMPTIONS,0.04716981132075472,"min
w∈W f(w) := Eξ∼µ

F(w; ξ)

.
(P)"
PROBLEM FORMULATION AND ASSUMPTIONS,0.04851752021563342,"Here, the expectation is taken over the randomness of the data sample ξ, which is drawn from an
underlying distribution µ. In particular, we make the following standard assumptions regarding the
problem (P) (Agarwal & Duchi, 2012).
Assumption 2.1. The stochastic optimization problem (P) satisﬁes"
PROBLEM FORMULATION AND ASSUMPTIONS,0.04986522911051213,"1. For every ξ, function F(·; ξ) is G-Lipschitz continuous over W, i.e., for all w, v ∈W,"
PROBLEM FORMULATION AND ASSUMPTIONS,0.05121293800539083,|F(w; ξ) −F(v; ξ)| ≤G∥w −v∥.
PROBLEM FORMULATION AND ASSUMPTIONS,0.05256064690026954,"2. Function f(·) is convex and bounded below, i.e., f(w∗) := infw∈W f(w) > −∞."
PROBLEM FORMULATION AND ASSUMPTIONS,0.05390835579514825,Under review as a conference paper at ICLR 2022
PROBLEM FORMULATION AND ASSUMPTIONS,0.05525606469002695,"3. W is a convex and compact set with bounded diameter R, i.e., supw,v∈W ∥w −v∥≤R."
PROBLEM FORMULATION AND ASSUMPTIONS,0.05660377358490566,"To solve this stochastic optimization problem, one often needs to query a set of data samples from
the distribution µ to perform optimization. Unlike traditional stochastic optimization that usually
assumes that the data samples are i.i.d. we consider a more general and practical dependent data-
generating process as we elaborate below."
PROBLEM FORMULATION AND ASSUMPTIONS,0.057951482479784364,"Dependent data-generating process: We consider a stochastic process P that generates a stream
of data samples {ξ1, ξ2, ..., }, which are not necessarily independent. In particular, the stochastic
process P has an underlying stationary distribution µ. To quantify the dependence of the data
generation process, we introduce the following standard φ-mixing model (Agarwal & Duchi, 2012),
where we denote {Ft}t as the canonical ﬁltration generated by {ξt}t.
Deﬁnition 2.2 (φ-mixing process). Consider a stochastic process {ξt}t with a stationary distribution
µ. Let P(ξt+k ∈·|Ft) be the distribution of the (t+k)-th sample conditioned on Ft, and denote dTV
as the total variation distance. Then, the process {ξt}t is called φ-mixing if the following mixing
coefﬁcient φξ(·) converges to 0 as k tends to inﬁnity."
PROBLEM FORMULATION AND ASSUMPTIONS,0.05929919137466307,"φξ(k) :=
sup
t∈N,A∈Ft
2dTV
 
P(ξt+k ∈·|A), µ

."
PROBLEM FORMULATION AND ASSUMPTIONS,0.06064690026954178,"Intuitively, the φ-mixing coefﬁcient describes how fast the distribution of sample ξt+k converges to
the stationary distribution µ when conditioned on the ﬁltration Ft, as the time gap k →∞. The φ-
mixing process can be found in many applications, which involve mixing coefﬁcients that converge
to zero at different convergence rates. Below we mention some popular examples."
PROBLEM FORMULATION AND ASSUMPTIONS,0.06199460916442048,"• Geometric φ-mixing process. Such a type of process has a geometrically diminishing
mixing coefﬁcient, i.e., φξ(k) ≤φ0 exp(−ckθ) for some φ0, c, θ > 0. Examples include
ﬁnite-state ergodic Markov chains and some aperiodic Harris-recurrent Markov processes
(Modha & Masry, 1996; Agarwal & Duchi, 2012; Meyn & Tweedie, 2012);
• Algebraic φ-mixing process. Such a type of process has a polynomially diminishing mix-
ing coefﬁcient, i.e., φξ(k) ≤φ0k−θ for some φ0, θ > 0. Examples include a large class of
Metropolis-Hastings samplers (Jarner & Roberts, 2002) and some queuing systems (Agar-
wal & Duchi, 2012)."
CONVERGENCE OF SGD WITH SUBSAMPLING OVER DEPENDENT DATA,0.06334231805929919,"3
CONVERGENCE OF SGD WITH SUBSAMPLING OVER DEPENDENT DATA"
CONVERGENCE OF SGD WITH SUBSAMPLING OVER DEPENDENT DATA,0.0646900269541779,"In this section, we study the convergence rate and sample complexity of SGD with data subsampling
update over φ-mixing dependent data. In Section 3.1, we recap the convergence results of the stan-
dard SGD over dependent data established in (Agarwal & Duchi, 2012). In Section 3.2, we establish
convergence results of SGD with the data subsampling update."
CONVERGENCE OF SGD WITH SUBSAMPLING OVER DEPENDENT DATA,0.0660377358490566,"Throughout, we deﬁne the sample complexity as the total number of samples required for the algo-
rithm to output a model w that achieves an ϵ convergence error, i.e., f(w) −f(w∗) ≤ϵ. Also, the
standard regret of a stochastic algorithm is deﬁned as"
CONVERGENCE OF SGD WITH SUBSAMPLING OVER DEPENDENT DATA,0.0673854447439353,"(Regret):
Rn := n
X"
CONVERGENCE OF SGD WITH SUBSAMPLING OVER DEPENDENT DATA,0.06873315363881402,"t=1
F(w(t); ξt) −F(w∗; ξt),"
CONVERGENCE OF SGD WITH SUBSAMPLING OVER DEPENDENT DATA,0.07008086253369272,"where the models {w1, w2, ..., wn} are generated using the data samples {ξ1, ξ2, ..., ξn}, respec-
tively, and w∗is the minimizer of f(w). For this sequence of models {w1, w2, ..., wn}, we make the
following mild assumption, which is satisﬁed by many SGD-type algorithms.
Assumption 3.1. There is a non-increasing sequence {κ(t)}t such that ∥w(t + 1) −w(t)∥≤κ(t)."
STOCHASTIC GRADIENT DESCENT,0.07142857142857142,"3.1
STOCHASTIC GRADIENT DESCENT"
STOCHASTIC GRADIENT DESCENT,0.07277628032345014,"Stochastic gradient descent (SGD) is a popular and classical algorithm for stochastic optimization.
In every iteration t, SGD queries a sample ξt from the data-generating process and performs the
following update."
STOCHASTIC GRADIENT DESCENT,0.07412398921832884,"(SGD):
w(t + 1) = w(t) −ηt∇F(w(t); ξt),
(1)"
STOCHASTIC GRADIENT DESCENT,0.07547169811320754,Under review as a conference paper at ICLR 2022
STOCHASTIC GRADIENT DESCENT,0.07681940700808626,"where ηt is the learning rate. In Theorem 2 of (Agarwal & Duchi, 2012), the authors established a
high probability convergence error bound for a generic class of stochastic algorithms. Speciﬁcally,
under the Assumptions 2.1 and 3.1, they showed that for any τ ∈N with probability at least 1 −δ,
the averaged predictor bwn := 1"
STOCHASTIC GRADIENT DESCENT,0.07816711590296496,"n
Pn
t=1 w(t) satisﬁes"
STOCHASTIC GRADIENT DESCENT,0.07951482479784366,f( bwn) −f(w∗) ≤Rn
STOCHASTIC GRADIENT DESCENT,0.08086253369272237,"n + (τ −1)G n n
X"
STOCHASTIC GRADIENT DESCENT,0.08221024258760108,"t=1
κ(t) + 2(τ −1)GR"
STOCHASTIC GRADIENT DESCENT,0.08355795148247978,"n
+ 2GR r 2τ"
STOCHASTIC GRADIENT DESCENT,0.08490566037735849,n log τ
STOCHASTIC GRADIENT DESCENT,0.0862533692722372,δ + φξ(τ)GR. (2)
STOCHASTIC GRADIENT DESCENT,0.0876010781671159,"Here, Rn is the regret of the algorithm of interest, and τ ∈N is an auxiliary parameter that is in-
troduced to decouple the dependence of the data samples. From the above bound, one can see that
the optimal choice of τ depends on the convergence rate of the mixing coefﬁcient φξ(τ). Speciﬁ-
cally, consider the SGD algorithm in (1). It can be shown that it achieves the regret Rn = O(√n)
and satisﬁes κ(t) = O(1/
√"
STOCHASTIC GRADIENT DESCENT,0.0889487870619946,"t) with a proper diminishing learning rate. Consequently, the above
high-probability convergence bound for SGD reduces to"
STOCHASTIC GRADIENT DESCENT,0.09029649595687332,"f( bwn) −f(w∗) ≤O
 1
√n + inf
τ∈N"
STOCHASTIC GRADIENT DESCENT,0.09164420485175202,"nτ −1
√n +
rτ"
STOCHASTIC GRADIENT DESCENT,0.09299191374663072,n log τ
STOCHASTIC GRADIENT DESCENT,0.09433962264150944,"δ + φξ(τ)
o
.
(3)"
STOCHASTIC GRADIENT DESCENT,0.09568733153638814,"Such a bound further implies the following sample complexity results of SGD under different con-
vergence rates of the mixing coefﬁcient φξ.
Corollary 3.2. The sample complexity of SGD in (1) for achieving an ϵ convergence error over
φ-mixing dependent data is given as follows."
STOCHASTIC GRADIENT DESCENT,0.09703504043126684,"• If the data is geometric φ-mixing with parameter θ > 0, then we choose τ = O
 
(log 1"
STOCHASTIC GRADIENT DESCENT,0.09838274932614555,"ϵ )
1
θ 
.
The resulting sample complexity is in the order of n = O
 
ϵ−2(log 1"
STOCHASTIC GRADIENT DESCENT,0.09973045822102426,"ϵ )
2
θ 
."
STOCHASTIC GRADIENT DESCENT,0.10107816711590296,"• If the data is algebraic φ-mixing with parameter θ > 0, then we choose τ = O(ϵ−1"
STOCHASTIC GRADIENT DESCENT,0.10242587601078167,"θ ). The
resulting sample complexity is in the order of n = O(ϵ−2−2 θ )."
STOCHASTIC GRADIENT DESCENT,0.10377358490566038,"It can be seen that if the data-generating process has a fast geometrically diminishing mixing co-
efﬁcient, i.e., the data samples are close to being independent from each other, then the resulting
sample complexity is almost the same as that of SGD with i.i.d. samples. On the other hand, if the
data-generating process mixes slowly with an algebraically diminishing mixing coefﬁcient, i.e., the
data samples are highly dependent, then the data dependence increases the sample complexity by
a non-negligible factor of ϵ−2"
STOCHASTIC GRADIENT DESCENT,0.10512129380053908,"θ . In particular, such a factor is substantially large if the mixing rate
parameter θ is close to zero."
SGD WITH SUBSAMPLING,0.10646900269541779,"3.2
SGD WITH SUBSAMPLING"
SGD WITH SUBSAMPLING,0.1078167115902965,"When apply SGD to solve stochastic optimization problems over dependent data, the key chal-
lenge is that the data dependence introduces non-negligible bias that slows down the convergence
of the algorithm. Hence, a straightforward solution is to reduce data dependence before performing
stochastic optimization. In the existing literature, a simple and useful approach is data subsam-
pling (Nagaraj et al., 2020; Kotsalis et al., 2020). Next, we show that such an approach leads to an
improved convergence bound and sample complexity of SGD over highly dependent data."
SGD WITH SUBSAMPLING,0.1091644204851752,"Speciﬁcally, consider a stream of φ-mixing data samples {ξ1, ξ2, ξ3, . . . }. Instead of utilizing the
entire stream of data, we subsample a subset of this data stream with period r ∈N and obtain the
following subsampled data stream"
SGD WITH SUBSAMPLING,0.1105121293800539,"{ξ1, ξr+1, ξ2r+1, . . . }."
SGD WITH SUBSAMPLING,0.11185983827493262,"In particular, let {Ft}t be the canonical ﬁltration generated by {ξtr+1}t. Since the consecutive
subsampled samples are r time steps away from each other, it is easy to verify that the subsampled
data stream {ξtr+1}t is also a φ-mixing process with mixing coefﬁcient given by φr
ξ(t) = φξ(rt),
where φr
ξ denotes the mixing coefﬁcient of the subsampled data stream {ξtr+1}t. Therefore, by
periodically subsampling the data stream, the resulting subsampled process has a faster-converging
mixing coefﬁcient. Then, we apply SGD over such subsampled data, i.e.,"
SGD WITH SUBSAMPLING,0.11320754716981132,"(SGD with subsampling):
w(t + 1) = w(t) −ηt∇F(w(t); ξtr+1).
(4)"
SGD WITH SUBSAMPLING,0.11455525606469003,Under review as a conference paper at ICLR 2022
SGD WITH SUBSAMPLING,0.11590296495956873,"In particular, the convergence error bound in eq. (2) still holds by replacing φξ(τ) with φξ(rτ), and
we obtain the following bound for SGD with subsampling."
SGD WITH SUBSAMPLING,0.11725067385444744,"f( bwn) −f(w∗) ≤O
 1
√n + inf
τ∈N"
SGD WITH SUBSAMPLING,0.11859838274932614,"n(τ −1)
√n
+
rτ"
SGD WITH SUBSAMPLING,0.11994609164420485,n log τ
SGD WITH SUBSAMPLING,0.12129380053908356,"δ + φξ(rτ)
o
.
(5)"
SGD WITH SUBSAMPLING,0.12264150943396226,"Such a bound further implies the following sample complexity results of SGD with subsampling
under different convergence rates of the mixing coefﬁcient φξ.
Corollary 3.3. The sample complexity of SGD with subsampling in (4) for achieving an ϵ conver-
gence error over φ-mixing dependent data is given as follows."
SGD WITH SUBSAMPLING,0.12398921832884097,"• If the data is geometric φ-mixing with parameter θ > 0, then we choose r = O
 
(log 1"
SGD WITH SUBSAMPLING,0.12533692722371967,"ϵ )
1
θ "
SGD WITH SUBSAMPLING,0.12668463611859837,"and τ = O(1). The resulting sample complexity is in the order of rn = O
 
ϵ−2(log 1"
SGD WITH SUBSAMPLING,0.1280323450134771,"ϵ )
1
θ 
."
SGD WITH SUBSAMPLING,0.1293800539083558,"• If the data is algebraic φ-mixing with parameter θ > 0, then we choose r = O
 
ϵ−1"
SGD WITH SUBSAMPLING,0.1307277628032345,"θ 
and
τ = O(1). The resulting sample complexity is in the order of rn = O
 
ϵ−2−1 θ 
."
SGD WITH SUBSAMPLING,0.1320754716981132,"Compare the above sample complexity results with those of the standard SGD in Corollary 3.2,
we conclude that data-subsampling can improve the sample complexity by a factor of (log 1"
SGD WITH SUBSAMPLING,0.1334231805929919,"ϵ )
1
θ and
ϵ−1"
SGD WITH SUBSAMPLING,0.1347708894878706,"θ for geometric φ-mixing and algebraic φ-mixing data, respectively. Intuitively, this is because
with data subsampling, we can choose a sufﬁciently large subsampling period r to decouple the data
dependence in the term φξ(rτ), as opposed to choosing a large τ in Corollary 3.2. In this way, the
order of the dominant term p τ"
SGD WITH SUBSAMPLING,0.13611859838274934,n log τ
SGD WITH SUBSAMPLING,0.13746630727762804,"δ is reduced. Therefore, when the data is highly dependent, it is
beneﬁcial to subsample the dependent data before performing SGD. We also note another advantage
of using data-subsampling, i.e., it only requires computing the stochastic gradients of the subsampled
data, and therefore can substantially reduce the computation load."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.13881401617250674,"4
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.14016172506738545,"Although the data-subsampling update scheme studied in the previous section helps improve the
sample complexity of SGD, it does not leverage the full information of all the queried data. In
particular, when the data is highly dependent, we need to choose a large period r to reduce data
dependence, and this will throw away a huge amount of valuable samples. In this section, we study
SGD with another popular update scheme that leverages the full information of all the sampled
data, i.e., the mini-batch update scheme. We show that this simple and popular scheme can effec-
tively reduce data dependence without skipping data samples, and can achieve an improved sample
complexity over SGD with subsampling."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.14150943396226415,"Speciﬁcally, we consider a data stream {ξt}t with φ-mixing dependent samples. We rearrange the
data samples into a stream of mini-batches {xt}t, where each mini-batch xt contains B samples,
i.e., xt = {ξ(t−1)B+1, ξ(t−1)B+2, . . . , ξtB}. Then, we perform mini-batch SGD update as follows."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.14285714285714285,"(Mini-batch SGD):
w(t + 1) = w(t) −ηt B X"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.14420485175202155,"ξ∈xt
∇F(w(t); ξ).
(6)"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.14555256064690028,"Performing SGD updates with mini-batch data has several advantages. First, it substantially reduce
the optimization variance and allows to use a large learning rate to facilitate the convergence of the
algorithm. As a comparison, SGD with subsampling still suffers from a large optimization variance.
Second, unlike SGD with subsampling, mini-batch SGD utilizes the information of all the data
samples to improve the performance of the model. Moreover, as we show in the following lemma,
mini-batch update substantially reduces the stochastic bias caused by the data dependence. In the
sequel, we denote F(w; x) :=
1
B
P"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.14690026954177898,"ξ∈x F(w; ξ) as the average loss on a mini-batch of samples.
With a bit abuse of notation, we also deﬁne {Ft}t as the canonical ﬁltration generated by the mini-
batch samples {xt}t.
Lemma 4.1. Let Assumption 2.1 hold and consider the mini-batch data stream {xt}t. Then, for any
w, v ∈W measureable with regard to Ft and any τ ∈N, it holds that"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.14824797843665768,"E

F(w; xt+τ) −F(v; xt+τ)|Ft

−
 
f(w) −f(v)

≤GR B B
X"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1495956873315364,"i=1
φξ(τB + i).
(7)"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1509433962264151,Under review as a conference paper at ICLR 2022
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1522911051212938,"With dependent data, the above lemma shows that we can approximate the population risk f(w)
by the conditional expectation E[F(w; xt+τ)|Ft], which involves the sample xt+τ that is τ steps
ahead of the ﬁltration Ft. Intuitively, by the φ-mixing principle, as τ gets larger, the distribution of
xt+τ conditional on Ft gets closer to the stationary distribution µ. In general, the estimation bias
GR"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.15363881401617252,"B
PB
i=1 φξ(τB + i) depends on both the batch size and the accumulated mixing coefﬁcient over
the corresponding batch of samples. To provide a concrete understanding, below we calculate the
estimation bias for several different mixing models."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.15498652291105122,"• Geometric φ-mixing: In this case, PB
i=1 φξ(τB + i) ≤P∞
i=1 φξ(i) = O(1). Hence, the
estimation bias is in the order of O( GR B )."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.15633423180592992,"• Fast algebraic φ-mixing (θ ≥1): In this case, PB
i=1 φξ(τB + i) ≤P∞
i=1 φξ(i) = e
O(1).
Hence, the estimation bias is in the order of e
O( GR"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.15768194070080863,"B ), where e
O hides all logarithm factors."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.15902964959568733,"• Slow algebraic φ-mixing (0 < θ < 1): In this case, PB
i=1 φξ(τB + i) ≤O((τB)1−θ).
Hence, the estimation bias is in the order of O( GRτ 1−θ Bθ
)."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.16037735849056603,"It can be seen that if the mixing coefﬁcient converges fast, i.e., either geometrically or fast alge-
braically, then the data dependence has a negligible impact on the estimation error. Consequently,
choosing a large batch size can substantially reduce the estimation bias. On the other hand, when
the mixing coefﬁcient converges slow algebraically, it substantially increases the estimation bias,
but it is still beneﬁcial to use a large batch size. This result shows that mini-batch update can effec-
tively reduce the statistical bias of stochastic approximation for a wide spectrum of dependent data
generating processes."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.16172506738544473,"We obtain prove the following convergence error bound for mini-batch SGD over dependent data.
Theorem 4.2. Let Assumption 2.1 and 3.1 hold. Apply mini-batch SGD to solve the stochastic
optimization problem (P) over φ-mixing dependent data and assume that it achieves regret Rn.
Then, for any τ ∈N and any minimizer w∗with probability at least 1 −δ, the averaged predictor
bwn := 1"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.16307277628032346,"n
Pn
t=1 w(t) satisﬁes"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.16442048517520216,f( bwn) −f(w∗) ≤Rn
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.16576819407008087,n + G(τ −1) n
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.16711590296495957,"n−τ+1
X"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.16846361185983827,"t=1
κ(t) + GR(τ −1) n"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.16981132075471697,"+ O
 1 nB B
X"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1711590296495957,"i=1
φ(τB + i) +
r τ"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1725067385444744,nB log τ
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1738544474393531,"δ log n δ 
B−1"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1752021563342318,"4 +
h
B
X"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1765498652291105,"i=1
φ(i)
i 1"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1778975741239892,"4 
. (8)"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1792452830188679,"To further understand the order of the above bound, a standard regret analysis shows that mini-batch"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.18059299191374664,SGD achieves a regret in the order of Rn
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.18194070080862534,"n = e
O(
q Pn
j=1 φ(j)"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.18328840970350405,"nB
) and κ(t) ≡O(
q B"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.18463611859838275,"n ) (see Theorem C.3
for the proof). Consequently, the above convergence error bound reduces to the following bound,
where we hide all logarithm factors for simplicity of presentation."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.18598382749326145,"f( bwn) −f(w∗) ≤e
O
sPn
j=1 φ(j)"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.18733153638814015,"nB
+ GR(τ −1) n
(9) + 1 nB B
X"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.18867924528301888,"i=1
φ(τB + i) +
r τ nB 
B−1"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.19002695417789758,"4 +
h
B
X"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.19137466307277629,"i=1
φ(i)
i 1"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.192722371967655,"4 
.
(10)"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1940700808625337,"Such a bound further implies the following sample complexity results of mini-batch SGD under
different convergence rates of the mixing coefﬁcient φξ.
Corollary 4.3. The sample complexity of mini-batch SGD in (6) for achieving an ϵ convergence
error over φ-mixing dependent data is given as follows."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1954177897574124,"• If the data is geometric φ-mixing with parameter θ > 0, then we choose τ = 1, B =
O(ϵ−1), n = O(ϵ−1). The overall sample complexity is nB = O(ϵ−2)."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.1967654986522911,"• If the data is fast algebraic φ-mixing with parameter θ ≥1, then we choose τ = 1, B =
O(ϵ−1), n = O(ϵ−1). The overall sample complexity is nB = e
O(ϵ−2)."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.19811320754716982,Under review as a conference paper at ICLR 2022
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.19946091644204852,"• If the data is slow algebraic φ-mixing with parameter 0 < θ < 1, then we choose τ =
1, B = O(ϵ−1"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.20080862533692723,"θ ), n = O(ϵ−1). The overall sample complexity is nB = O(ϵ−1−1 θ )."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.20215633423180593,"It can be seen that mini-batch SGD can achieve an order-wise lower sample complexity than the SGD
with subsampling in the full spectrum of φ-mixing convergence rate. Speciﬁcally, mini-batch SGD
improves the sample complexity over that of SGD with subsampling by a factor of O((log 1"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.20350404312668463,"ϵ )
1
θ ),
e
O(ϵ−1"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.20485175202156333,"θ ) and O(ϵ−1) for geometric φ-mixing, fast algebraic φ-mixing and slow algebraic φ-mixing
data samples, respectively. This shows that mini-batch update can effectively reduce the bias caused
by data dependence and leverage the full information of all the data samples to improve the learning
performance."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.20619946091644206,"To intuitively explain, this is because with mini-batch updates, we can choose a sufﬁciently large
batch size B to reduce the bias caused by the data dependence and choose a small auxiliary parame-
ter τ = 1. As a comparison, to control the bias caused by data dependence, the standard SGD needs
to choose a very large τ and the SGD with subsampling needs to choose a large subsampling period
r that skips a huge amount of valuable data samples, especially when the mixing coefﬁcient con-
verges slowly. Therefore, our result proves that it is beneﬁcial to use mini-batch stochastic gradient
updates when the data samples are highly dependent."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.20754716981132076,"We note that our proof of the tight high-probability bound in Theorem 4.2 for mini-batch SGD
involves substantial new developments compared with the proof of (Agarwal & Duchi, 2012). Next,
we elaborate on our technical novelty."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.20889487870619947,"• In (Agarwal & Duchi, 2012), they deﬁned the following random variable"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.21024258760107817,"Xi
t := f
 
w((t −1)τ + i)

−f(w∗) + F
 
w((t −1)τ + i); ξt+τ−1

−F
 
w∗; ξt+τ−1

."
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.21159029649595687,"As this random variable involves only one sample ξt+τ−1, they bound the bias term
Xi
t −E[Xi
t|Fi
t−1] as a universal constant. As a comparison, the random variable Xi
t would
involve a mini-batch of samples xt+τ−1 in our analysis. With the mini-batch structure, the
bias Xi
t −E[Xi
t|Fi
t−1] can be written as an average of B zero-mean dependent random vari-
ables, which is close to zero with high probability due to the concentration phenomenon.
Consequently, we are able to apply a Bernstein-type inequality developed in (Delyon et al.,
2009) for dependent stochastic process to obtain an improved bias bound from O(1) to
e
O(1/
√"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.21293800539083557,"B). This is critical for obtaining the improved bound.
• Second, with the improved high-probability bias bound mentioned above, the remaining
proof of (Agarwal & Duchi, 2012) no longer holds. Speciﬁcally, we can no longer apply
the Azuma’s inequality to bound the accumulated bias P"
CONVERGENCE OF MINI-BATCH SGD OVER DEPENDENT DATA,0.21428571428571427,"t(Xi
t −E[Xi
t|Fi
t−1]), as each bias
term is no longer bounded with probability one. To address this issue, we developed a gen-
eralized Azuma’s inequality for martingale differences in Lemma B.3 based on Proposition
34 of (Tao et al., 2015) for independent zero-mean random variables.
• Third, we develop a high-probability regret bound for mini-batch SGD over dependent data
so that it can be integrated with the high-probability convergence bound in Theorem 4.2.
To our best knowledge, the regret of SGD over dependent data has not been studied before."
NUMERICAL EXAMPLE,0.215633423180593,"5
NUMERICAL EXAMPLE"
NUMERICAL EXAMPLE,0.2169811320754717,"We examine our theory via a basic convex quadratic optimization problem, which is written as"
NUMERICAL EXAMPLE,0.2183288409703504,"min
w∈Rd f(w) := Eξ∼µ

(w −ξ)⊤A(w −ξ)

,"
NUMERICAL EXAMPLE,0.2196765498652291,"where A ⪰0 is a ﬁxed positive semi-deﬁnite matrix and µ is the uniform distribution on [0, 1]d.
Then, following the construction in (Jarner & Roberts, 2002), we generate an algebraic φ-mixing
Markov chain that has the stationary distribution µ. In particular, its mixing coefﬁcient φξ(k) con-
verges at a sublinear convergence rate k−1"
NUMERICAL EXAMPLE,0.2210242587601078,"r , where r > 0 is a parameter that controls the speed of
convergence. Please refer to Appendix D for more details of the experiment setup."
NUMERICAL EXAMPLE,0.2223719676549865,We ﬁrst estimate the following stochastic bias at the ﬁxed origin point w = 0d.
NUMERICAL EXAMPLE,0.22371967654986524,"(Bias):
E

F(w; xτ)|x0 = 0d

−f(w)
,"
NUMERICAL EXAMPLE,0.22506738544474394,Under review as a conference paper at ICLR 2022
NUMERICAL EXAMPLE,0.22641509433962265,"where the expectation is taken over the randomness of the mini-batch of samples queried at time
τ ∈N. Such a bias is affected by several factors, including the time gap τ, the batch size B and the
convergence rate parameter r of the mixing coefﬁcient."
NUMERICAL EXAMPLE,0.22776280323450135,"In Figure 1, we investigate the impact of these factors on the stochastic bias, and we use 10k Monte
Carlo samples to estimate the stochastic bias. The left two ﬁgures ﬁx the batch size, and it can be
seen that the bias decreases as τ increases, which matches the deﬁnition of the φ-mixing property.
Also, a faster-mixing Markov chain (i.e., smaller r) leads to a smaller bias. In particular, with batch
size B = 1 and a slow-mixing chain r = 2, it takes an unacceptably large τ to achieve a relatively
small bias. This provides an empirical justiﬁcation to Corollary 3.2 and explains why the standard
SGD suffers from a high sample complexity over highly dependent data. Moreover, as the batch
size gets larger, one can achieve a numerically smaller bias, which matches our Lemma 4.1. The
right two ﬁgures ﬁx the convergence rate parameter of the mixing coefﬁcient, and it can be seen
that increasing the batch size signiﬁcantly reduces the bias. Consequently, instead of choosing a
large τ to reduce the bias, one can simply choose a large batch size B = 100 and set τ = 1. This
observation matches and justiﬁes our theoretical results in Corollary 4.3."
NUMERICAL EXAMPLE,0.22911051212938005,"Figure 1: Impact of τ, batch size B and convergence rate of mixing coefﬁcient on the bias."
NUMERICAL EXAMPLE,0.23045822102425875,"Figure 2: Comparison of sam-
ple complexity of different
SGD algorithms."
NUMERICAL EXAMPLE,0.23180592991913745,"We further compare the convergence of SGD, SGD with sub-
sampling and mini-batch SGD. Here, we set r = 2 to generate
highly dependent data samples. We set learning rate η = 0.01
for both SGD and SGD with subsampling, and set learning rate
η = 0.01×
q"
NUMERICAL EXAMPLE,0.23315363881401618,"B
PB
j=1 φξ(j) = 0.01×1001/4 for mini-batch SGD with"
NUMERICAL EXAMPLE,0.23450134770889489,"batch size B = 100, as suggested by Theorem C.3 in the appendix.
The results are plotted in Figure 2, where each curve corresponds
to the mean of 100 independent trails. It can be seen that SGD with
subsampling achieves a lower loss than the standard SGD asymptot-
ically, due to the use of less dependent data. Moreover, mini-batch
SGD achieves the smallest asymptotic loss. All these observations
are consistent with our theoretical results."
CONCLUSION,0.2358490566037736,"6
CONCLUSION"
CONCLUSION,0.2371967654986523,"In this study, we investigate the convergence property of SGD under various popular stochastic
update schemes over highly dependent data. Unlike the conventional i.i.d. data setting in which the
stochastic update schemes do not affect the sample complexity of SGD, the convergence of SGD
in the data-dependent setting critically depends on the structure of the stochastic update scheme. In
particular, we show that both data subsampling and mini-batch sampling can substantially improve
the sample complexity of SGD over highly dependent data. Our study takes one step forward toward
understanding the theoretical limits of stochastic optimization over dependent data, and it opens
many directions for future study. For example, it is interesting to further explore the impact of
algorithm structure on the sample complexity of stochastic reinforcement learning algorithms. Also,
it is important to develop advanced algorithm update schemes that can facilitate the convergence of
learning over highly dependent data."
REFERENCES,0.238544474393531,REFERENCES
REFERENCES,0.2398921832884097,"Alekh Agarwal and John C Duchi. The generalization ability of online algorithms for dependent
data. IEEE Transactions on Information Theory, 59(1):573–587, 2012."
REFERENCES,0.24123989218328842,"Alekh Agarwal, Nan Jiang, Kakade Sham M, and Wen Sun. Reinforcement learning: Theory and
algorithms. https://rltheorybook.github.io/, 2021."
REFERENCES,0.24258760107816713,Under review as a conference paper at ICLR 2022
REFERENCES,0.24393530997304583,"L´eon Bottou. Large-scale machine learning with stochastic gradient descent. In Yves Lechevallier
and Gilbert Saporta (eds.), Proc. COMPSTAT, pp. 177–186, 2010."
REFERENCES,0.24528301886792453,"Zaiwei Chen, Sheng Zhang, Thinh T Doan, John-Paul Clarke, and Siva Theja Maguluri. Finite-
sample analysis of nonlinear stochastic approximation with applications in reinforcement learn-
ing. arXiv:1905.11425, 2019."
REFERENCES,0.24663072776280323,"Gal Dalal, Bal´azs Sz¨or´enyi, Gugan Thoppe, and Shie Mannor. Finite sample analyses for td (0) with
function approximation. In Proc. AAAI conference on artiﬁcial intelligence, 2018."
REFERENCES,0.24797843665768193,"Vianney Debavelaere, Stanley Durrleman, and St´ephanie Allassonni`ere. On the convergence of
stochastic approximations under a subgeometric ergodic Markov dynamic. Electronic Journal of
Statistics, 15(1):1583 – 1609, 2021."
REFERENCES,0.24932614555256064,Bernard Delyon et al. Exponential inequalities for sums of weakly dependent variables. Electronic
REFERENCES,0.25067385444743934,"Journal of Probability, 14:752–779, 2009."
REFERENCES,0.25202156334231807,"Randal Douc, Eric Moulines, Pierre Priouret, and Philippe Soulier. Markov chains. Springer, 2018."
REFERENCES,0.25336927223719674,"John Duchi, Alekh Agarwal, Mikael Johansson, and Michael Jordan. Ergodic subgradient descent.
In Allerton Conference, 2011."
REFERENCES,0.25471698113207547,"Eyal Even-Dar, Yishay Mansour, and Peter Bartlett.
Learning rates for q-learning.
Journal of
machine learning Research, 5(1), 2003."
REFERENCES,0.2560646900269542,Peter W. Glynn and Sean P. Meyn. A Lyapunov bound for solutions of the Poisson equation. The
REFERENCES,0.2574123989218329,"Annals of Probability, 24(2):916 – 931, 1996."
REFERENCES,0.2587601078167116,"Antoine Godichon-Baggioni, Nicklas Werge, and Olivier Wintenberger. Non-asymptotic analysis of
stochastic approximation algorithms for streaming data. arXiv:2109.07117, 2021."
REFERENCES,0.2601078167115903,"Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016."
REFERENCES,0.261455525606469,"Elad Hazan. Introduction to Online Convex Optimization. Elad Hazan, Erscheinungsort nicht er-
mittelbar, 2017. ISBN 1521133301."
REFERENCES,0.2628032345013477,Søren F Jarner and Gareth O Roberts. Polynomial convergence rates of markov chains. The Annals
REFERENCES,0.2641509433962264,"of Applied Probability, 12(1):224–247, 2002."
REFERENCES,0.26549865229110514,"Maxim Kaledin, Eric Moulines, Alexey Naumov, Vladislav Tadic, and Hoi-To Wai. Finite time
analysis of linear two-timescale stochastic approximation with markovian noise. In Conference
on Learning Theory, pp. 2144–2203. PMLR, 2020."
REFERENCES,0.2668463611859838,"Belhal Karimi, Blazej Miasojedow, Eric Moulines, and Hoi-To Wai. Non-asymptotic analysis of
biased stochastic approximation scheme. In Proc. Conference on Learning Theory, pp. 1944–
1974, 2019."
REFERENCES,0.26819407008086255,"Georgios Kotsalis, Guanghui Lan, and Tianjiao Li.
Simple and optimal methods for stochastic
variational inequalities, ii: Markovian noise and policy evaluation in reinforcement learning.
arXiv:2011.02987, 11 2020."
REFERENCES,0.2695417789757412,"Harshat Kumar, Alec Koppel, and Alejandro Ribeiro. On the sample complexity of actor-critic
method for reinforcement learning with function approximation. ArXiv:1910.08412, 2019."
REFERENCES,0.27088948787061995,"Gen Li, Changxiao Cai, Yuxin Chen, Yuantao Gu, Yuting Wei, and Yuejie Chi. Tightening the depen-
dence on horizon in the sample complexity of q-learning. In ICML, volume 139 of Proceedings
of Machine Learning Research, pp. 6296–6306. PMLR, 2021."
REFERENCES,0.2722371967654987,"Kurt Marti. Stochastic optimization of regulators. Computers and Structures, 180:40–51, February
2017."
REFERENCES,0.27358490566037735,"Francisco S Melo, Sean P Meyn, and M Isabel Ribeiro. An analysis of reinforcement learning with
function approximation. In Proc. International Conference on Machine Learning, pp. 664–671,
2008."
REFERENCES,0.2749326145552561,Under review as a conference paper at ICLR 2022
REFERENCES,0.27628032345013476,"Sean P Meyn and Richard L Tweedie. Markov chains and stochastic stability. Springer Science &
Business Media, 2012."
REFERENCES,0.2776280323450135,"Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wier-
stra, and Martin Riedmiller. Playing atari with deep reinforcement learning. arXiv:1312.5602,
2013."
REFERENCES,0.27897574123989216,"Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Belle-
mare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. Human-level
control through deep reinforcement learning. nature, 518(7540):529–533, 2015."
REFERENCES,0.2803234501347709,"Dharmendra S Modha and Elias Masry. Minimum complexity regression estimation with weakly
dependent observations. IEEE Transactions on Information Theory, 42(6):2133–2145, 1996."
REFERENCES,0.2816711590296496,"Dheeraj Nagaraj, Xian Wu, Guy Bresler, Prateek Jain, and Praneeth Netrapalli. Least squares re-
gression with markovian data: Fundamental limits and algorithms. In Proc. Advances in Neural
Information Processing Systems, volume 33, 2020."
REFERENCES,0.2830188679245283,"Shuang Qiu, Zhuoran Yang, Jieping Ye, and Zhaoran Wang. On the ﬁnite-time convergence of actor-
critic algorithm. In NeurIPS Optimization Foundations for Reinforcement Learning Workshop,
2019."
REFERENCES,0.284366576819407,"Guannan Qu and Adam Wierman. Finite-time analysis of asynchronous stochastic approximation
and q-learning. In Proc. Conference on Learning Theory, pp. 3185–3205, 2020."
REFERENCES,0.2857142857142857,Ingo Steinwart and Andreas Christmann. Fast learning from non-iid observations. Advances in
REFERENCES,0.28706199460916443,"neural information processing systems, 22:1768–1776, 2009."
REFERENCES,0.2884097035040431,"Richard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction. Bradford, 2018."
REFERENCES,0.28975741239892183,"Terence Tao, Van Vu, et al.
Random matrices: universality of local spectral statistics of non-
hermitian matrices. Annals of probability, 43(2):782–874, 2015."
REFERENCES,0.29110512129380056,"Lingxiao Wang, Qi Cai, Zhuoran Yang, and Zhaoran Wang. Neural policy gradient methods: Global
optimality and rates of convergence. In International Conference on Learning Representations,
2019."
REFERENCES,0.29245283018867924,"Yue Frank Wu, Weitong ZHANG, Pan Xu, and Quanquan Gu.
A ﬁnite-time analysis of two
time-scale actor-critic methods. In Proc. Advances in Neural Information Processing Systems
(NeurIPS), volume 33, pp. 17617–17628, 2020."
REFERENCES,0.29380053908355797,Lin Xiao. Dual averaging method for regularized stochastic learning and online optimization. Proc.
REFERENCES,0.29514824797843664,"Advances in Neural Information Processing Systems, 22:2116–2124, 2009."
REFERENCES,0.29649595687331537,"Pan Xu and Quanquan Gu. A ﬁnite-time analysis of q-learning with neural network function ap-
proximation. In Proc. International Conference on Machine Learning, pp. 10555–10565, 2020."
REFERENCES,0.29784366576819404,"Tengyu Xu, Shaofeng Zou, and Yingbin Liang.
Two time-scale off-policy TD learning: Non-
asymptotic analysis over Markovian samples.
In Proc. Advances in Neural Information
Processing Systems (NeurIPS), 2019."
REFERENCES,0.2991913746630728,"Tengyu Xu, Zhe Wang, and Yingbin Liang. Improving sample complexity bounds for (natural)
actor-critic algorithms. In Proc. Advances in Neural Information Processing Systems (NeurIPS),
volume 33, 2020."
REFERENCES,0.3005390835579515,"Zhuoran Yang, Yongxin Chen, Mingyi Hong, and Zhaoran Wang. Provably global convergence of
actor-critic: A case for linear quadratic regulator with ergodic cost. In Proc. Advances in Neural
Information Processing Systems (NeurIPS), 2019."
REFERENCES,0.3018867924528302,"Shaofeng Zou, Tengyu Xu, and Yingbin Liang.
Finite-sample analysis for SARSA with linear
function approximation. In Proc. Advances in Neural Information Processing Systems, pp. 8665–
8675, 2019."
REFERENCES,0.3032345013477089,Under review as a conference paper at ICLR 2022
REFERENCES,0.3045822102425876,Appendix
REFERENCES,0.3059299191374663,Table of Contents
REFERENCES,0.30727762803234504,"A Proof of Corollary 3.3
12"
REFERENCES,0.3086253369272237,"B
Proof of Theorem 4.2
13
B.1
Key Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
B.2
Proof of the Main Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17"
REFERENCES,0.30997304582210244,"C Regret Analysis of Mini-Batch SGD
20"
REFERENCES,0.3113207547169811,"D Experiment Setup
24"
REFERENCES,0.31266846361185985,"Notation: To simplify the notation, throughout the appendix, we denote ξ(i)
t
:= ξ(t−1)B+i, which
corresponds to the i-th data sample of the t-th mini-batch data xt. With this notation, we have
xt = {ξ(1)
t
, ξ(2)
t
, ..., ξ(B)
t
}."
REFERENCES,0.3140161725067385,"A
PROOF OF COROLLARY 3.3"
REFERENCES,0.31536388140161725,"In this section, we analyze the convergence error bound of the SGD with data-subsampling in (4)."
REFERENCES,0.316711590296496,"Given a φξ-mixing data stream {ξ1, ξ2, ξ3, . . . }, we consider the following subsampled data stream
{ξ1, ξr+1, ξ2r+1, . . . }.
Let F be the canonical ﬁltration generated by {xt}. Then the subsampled data stream {ξtr+1}t is
φr
ξ-mixing with the mixing coefﬁcient given by"
REFERENCES,0.31805929919137466,"φr
ξ(t) = φξ(rt).
With this mixing coefﬁcient, we can apply Theorem 2 of (Agarwal & Duchi, 2012) and obtain the
following convergence error bound for any τ ∈N."
REFERENCES,0.3194070080862534,"f( bwn) −f(w∗) ≤O
Rn"
REFERENCES,0.32075471698113206,"n + (τ −1) n n
X"
REFERENCES,0.3221024258760108,"t=1
κ(t) + τ"
REFERENCES,0.32345013477088946,"n +
rτ"
REFERENCES,0.3247978436657682,n log τ
REFERENCES,0.3261455525606469,"δ + φξ(rτ)

."
REFERENCES,0.3274932614555256,"Consider the standard SGD with a diminishing learning rate, we have κ(t) = O( 1
√"
REFERENCES,0.3288409703504043,"t) and Rn =
O(√n). Then, the convergence error bound becomes"
REFERENCES,0.330188679245283,"f( bwn) −f(w∗) ≤O
 1
√n + inf
τ∈N"
REFERENCES,0.33153638814016173,"n(τ −1)
√n
+
rτ"
REFERENCES,0.3328840970350404,n log τ
REFERENCES,0.33423180592991913,"δ + φξ(rτ)
o
."
REFERENCES,0.33557951482479786,"The above result further implies the following sample complexity results for different convergence
rates of the mixing coefﬁcient."
REFERENCES,0.33692722371967654,"• Geometric φ-mixing: In this case, φξ(k) ≤O(exp(−kθ)) for some θ > 0. Set the last
term φξ(rτ) = O(ϵ). We obtain that rτ = O((log 1"
REFERENCES,0.33827493261455527,"ϵ )
1
θ ). Further set the second term
τ−1
√n
= O(ϵ). We obtain that nτ −2 = O(ϵ−2). By choosing τ = O(1), the sample
complexity is in the order of"
REFERENCES,0.33962264150943394,"ϵ-complexity = r · n = O

log 1 ϵ  1"
REFERENCES,0.34097035040431267,"θ τ 2ϵ−2
= O

ϵ−2
log ϵ−1 1 θ 
."
REFERENCES,0.3423180592991914,"• Algebraic φ-mixing: In this case, φξ(k) ≤O(k−θ) for some θ > 0. Set the last term
φξ(rτ) = O(ϵ). We obtain that τr = O(ϵ−1"
REFERENCES,0.3436657681940701,"θ ). Set the second term τ−1
√n = O(ϵ). We
obtain that nτ −2 = O(ϵ−2). By setting τ = O(1), the sample complexity is in the order of"
REFERENCES,0.3450134770889488,ϵ-complexity = r · n = O(ϵ−1
REFERENCES,0.3463611859838275,θ τ 2ϵ−2) = O(ϵ−2−1 θ ).
REFERENCES,0.3477088948787062,Under review as a conference paper at ICLR 2022
REFERENCES,0.3490566037735849,"B
PROOF OF THEOREM 4.2"
REFERENCES,0.3504043126684636,"B.1
KEY LEMMAS"
REFERENCES,0.35175202156334234,"In this subsection, we present several useful preliminary results for proving Theorem 4.2. Deﬁne
N := {1, 2, 3, . . . }. Throughout this subsection, we assume that Assumption 2.1 holds. The follow-
ing lemma is a generalization of the Lemma 1 in (Agarwal & Duchi, 2012)."
REFERENCES,0.353099730458221,"Lemma B.1. Let w, v be measurable with respect to Ft. Then for any τ ∈N,"
REFERENCES,0.35444743935309975,"E

F(w; xt+τ) −F(v; xt+τ)|Ft

≤GR B B
X"
REFERENCES,0.3557951482479784,"i=1
φξ(τB + i) + f(w) −f(v)."
REFERENCES,0.35714285714285715,"Proof. For any τ ∈N, we consider the following decomposition."
REFERENCES,0.3584905660377358,"E[F(w; xt+τ) −F(v; xt+τ)|Ft]
=E[F(w; xt+τ) −f(w) + f(v) −F(v; xt+τ)|Ft] + f(w) −f(v) =
h 1 B B
X i=1"
REFERENCES,0.35983827493261455,"Z
F(w; ξ(i)
t+τ)dP(ξ(i)
t+τ ∈·|Ft) −
Z
F(w; ξ)dµ
i
−
h 1 B B
X i=1"
REFERENCES,0.3611859838274933,"Z
F(v; ξ(i)
t+τ)dP(ξ(i)
t+τ ∈·|Ft) −
Z
F(v; x)dµ
i"
REFERENCES,0.36253369272237196,"|
{z
}
(A)
+ f(w) −f(v)."
REFERENCES,0.3638814016172507,We can further bound the term (A) using the mixing property of the dependent data stream.
REFERENCES,0.36522911051212936,"(A) =
h 1 B B
X i=1"
REFERENCES,0.3665768194070081,"Z
F(w; ξ(i)
t+τ)dP(ξ(i)
t+τ ∈·|Ft) −
Z
F(w; ξ)dµ
i
−
h 1 B B
X i=1"
REFERENCES,0.36792452830188677,"Z
F(v; ξ(i)
t+τ)dP(ξ(i)
t+τ ∈·|Ft) −
Z
F(v; x)dµ
i = 1 B B
X i=1"
REFERENCES,0.3692722371967655,"Z
(F(w; ξ) −F(v; ξ))d
 
P(ξ(i)
t+τ ∈dξ|Ft) −µ(dξ)
 ≤1 B B
X i=1"
REFERENCES,0.3706199460916442,"Z
GRd
P(ξ(i)
t+τ ∈dξ|Ft) −µ(dξ) ≤GR B B
X"
REFERENCES,0.3719676549865229,"i=1
φξ(τB + i),"
REFERENCES,0.37331536388140163,"where in the ﬁrst inequality we use the facts that F(·; ξ) is G-Lipschitz and the domain is bounded
by R, and the second inequality is implied by the φ-mixing property. Substituting the above upper
bound of (A) into the previous equation yields that"
REFERENCES,0.3746630727762803,"E[F(w; xt+τ) −F(v; xt+τ)|Ft] ≤GR B B
X"
REFERENCES,0.37601078167115903,"i=1
φξ(τB + i) + f(w) −f(v)."
REFERENCES,0.37735849056603776,This completes the proof.
REFERENCES,0.37870619946091644,"Proposition B.2. Let {w(t)}t∈N be the model parameter sequence generated by (6). Also suppose
that Assumption 3.1 holds. Then for any τ ∈N, we have n
X"
REFERENCES,0.38005390835579517,"t=1
[f(w(t)) −f(w∗)] ≤ n
X"
REFERENCES,0.38140161725067384,"t=1
[f(w(t)) −F(w(t); xt+τ−1) + F(w∗; xt+τ−1) −f(w∗)] + Rn + G(τ −1)"
REFERENCES,0.38274932614555257,"n−τ+1
X"
REFERENCES,0.38409703504043125,"t=1
κ(t) + GR(τ −1)."
REFERENCES,0.38544474393531,Under review as a conference paper at ICLR 2022
REFERENCES,0.3867924528301887,"Proof. For any τ ∈N, we consider the following decomposition, n
X"
REFERENCES,0.3881401617250674,"t=1
[f(w(t)) −f(w∗)] = n
X"
REFERENCES,0.3894878706199461,"t=1
[f(w(t)) −F(w(t); xt+τ−1) + F(w∗; xt+τ−1) −f(w∗) + F(w(t); xt+τ−1) −F(w∗; xt+τ−1)] = n
X"
REFERENCES,0.3908355795148248,"t=1
[f(w(t)) −F(w(t); xt+τ−1) + F(w∗; xt+τ−1) −f(w∗)]
(11) + n
X t=1"
REFERENCES,0.3921832884097035,"
F(w(t); xt+τ−1) −F(w∗; xt+τ−1)
"
REFERENCES,0.3935309973045822,"|
{z
}
(B) ."
REFERENCES,0.3948787061994609,"We will keep the ﬁrst term and bound the term (B). (B) = n
X"
REFERENCES,0.39622641509433965,"t=1
F(w(t); xt+τ−1) −F(w∗; xt+τ−1) = n
X"
REFERENCES,0.3975741239892183,"t=1
[F(w(t); xt) −F(w∗; xt)]"
REFERENCES,0.39892183288409705,"|
{z
}
(B1) +"
REFERENCES,0.4002695417789757,"n−τ+1
X"
REFERENCES,0.40161725067385445,"t=1
[F(w(t); xt+τ−1) −F(w(t + τ −1); xt+τ−1)]"
REFERENCES,0.4029649595687331,"|
{z
}
(B2) + n
X"
REFERENCES,0.40431266846361186,"t=n−τ+2
F(w(t); xt+τ−1) − τ−1
X"
REFERENCES,0.4056603773584906,"t=1
F(w(t); xt) + τ−1
X"
REFERENCES,0.40700808625336926,"t=1
F(w∗; xt) −"
REFERENCES,0.408355795148248,"n+τ−1
X"
REFERENCES,0.40970350404312667,"t=n+1
F(w∗; xt)"
REFERENCES,0.4110512129380054,"|
{z
}
(B3) ."
REFERENCES,0.4123989218328841,Recall that the term (B1) is the regret Rn. We can bound the term (B2) by noting that
REFERENCES,0.4137466307277628,"F(w(t); xt+τ−1) −F(w(t + τ −1); xt+τ−1) ≤G∥w(t + τ −1) −w(t)∥ ≤G τ−2
X"
REFERENCES,0.41509433962264153,"i=0
∥w(t + i + 1) −w(t + i)∥ ≤G τ−2
X"
REFERENCES,0.4164420485175202,"i=0
κ(t + i)"
REFERENCES,0.41778975741239893,≤G(τ −1)κ(t).
REFERENCES,0.4191374663072776,"For the term (B3), we can bound it using the G-Lipschitzness of F(·; ξ) and the R-bounded domain. n
X"
REFERENCES,0.42048517520215634,"t=n−τ+2
F(w(t); xt+τ−1) − τ−1
X"
REFERENCES,0.42183288409703507,"t=1
F(w(t); xt) + τ−1
X"
REFERENCES,0.42318059299191374,"t=1
F(w∗; xt) −"
REFERENCES,0.42452830188679247,"n+τ−1
X"
REFERENCES,0.42587601078167114,"t=n+1
F(w∗; xt+τ−1)"
REFERENCES,0.4272237196765499,"=
h
n
X"
REFERENCES,0.42857142857142855,"t=n−τ+2
F(w(t); xt+τ−1) −"
REFERENCES,0.4299191374663073,"n+τ−1
X"
REFERENCES,0.431266846361186,"t=n+1
F(w∗; xt+τ−1)
i
−
h τ−1
X"
REFERENCES,0.4326145552560647,"t=1
F(w(t); xt) − τ−1
X"
REFERENCES,0.4339622641509434,"t=1
F(w∗; xt)
i"
REFERENCES,0.4353099730458221,"≤G
h
n
X"
REFERENCES,0.4366576819407008,"t=n−τ+2
∥w(t) −w∗∥
i
+ G
h τ−1
X"
REFERENCES,0.4380053908355795,"t=1
∥w(t) −w∗∥
i"
REFERENCES,0.4393530997304582,≤GR(τ −1).
REFERENCES,0.44070080862533695,Under review as a conference paper at ICLR 2022
REFERENCES,0.4420485175202156,"Combining the above bounds of (B1), (B2), and (B3), we obtain the upper bound of (B) as follows. n
X"
REFERENCES,0.44339622641509435,"t=1
F(w(t); xt+τ−1) −F(w∗; xt+τ−1) = n
X"
REFERENCES,0.444743935309973,"t=1
[F(w(t); xt) −F(w∗; xt)]"
REFERENCES,0.44609164420485176,"|
{z
}
(B1) +"
REFERENCES,0.4474393530997305,"n−τ+1
X"
REFERENCES,0.44878706199460916,"t=1
[F(w(t); xt+τ−1) −F(w(t + τ −1); xt+τ−1)]"
REFERENCES,0.4501347708894879,"|
{z
}
(B2) + n
X"
REFERENCES,0.45148247978436656,"t=n−τ+2
F(w(t); xt+τ−1) − τ−1
X"
REFERENCES,0.4528301886792453,"t=1
F(w(t); xt) + τ
X"
REFERENCES,0.45417789757412397,"t=1
F(w∗; xt) −"
REFERENCES,0.4555256064690027,"n+τ−1
X"
REFERENCES,0.4568733153638814,"t=n+1
F(w∗; xt)"
REFERENCES,0.4582210242587601,"|
{z
}
(B3) ."
REFERENCES,0.45956873315363883,≤Rn + G(τ −1)
REFERENCES,0.4609164420485175,"n−τ+1
X"
REFERENCES,0.46226415094339623,"t=1
κ(t) + GR(τ −1)."
REFERENCES,0.4636118598382749,Then the proof is completed by substituting the upper bound of (B) into (11).
REFERENCES,0.46495956873315364,"The following generalized Azuma’s inequality generalizes the Proposition 34 of (Tao et al., 2015).
The inequality can be used to bound sum of martingale difference random variables."
REFERENCES,0.46630727762803237,"Lemma B.3 (Generalized Azuma’s Inequality). Let {Xt} be a martingale difference sequence with
respect to its canonical ﬁltration F. Deﬁne Y = PT
i=1 Xi and assume E|Y | < ∞. Then for any
{αt}t > 0, P "
REFERENCES,0.46765498652291104,|Y −EY | ≥λ
REFERENCES,0.46900269541778977,"v
u
u
t T
X"
REFERENCES,0.47035040431266845,"t=1
α2
t "
REFERENCES,0.4716981132075472,"≤2 exp

−λ2 2 
+ T
X"
REFERENCES,0.47304582210242585,"t=1
P(|Xt| ≥αt)."
REFERENCES,0.4743935309973046,Proof. Let T := min{t : |Xt| > αt}. Then the sets Bt := {ω : T (ω) = t} are disjoint. Construct
REFERENCES,0.4757412398921833,"Y ′(ω) := 
"
REFERENCES,0.477088948787062,"
Y (ω)
if ω ∈
 ST
t=1 Bt
C
,"
REFERENCES,0.4784366576819407,"E[Y |Bt]
if ω ∈Bt for all t ∈{1, 2, . . . , T}."
REFERENCES,0.4797843665768194,"By the above construction, the associated Doob martingale of Y ′ with respect to F is {Zt :=
Pt∧T
i=1 Xi}. It satisﬁes the conditions of Azuma’s inequality, i.e.,"
REFERENCES,0.4811320754716981,"• {Zt} forms a martingale with respect to F (because the stopped martingale is still a mar-
tingale)."
REFERENCES,0.48247978436657685,• |Zt −Zt−1| ≤αt.
REFERENCES,0.4838274932614555,Then we can apply Azuma’s inequality to Y ′. P 
REFERENCES,0.48517520215633425,|Y ′ −EY ′| ≥λ
REFERENCES,0.4865229110512129,"v
u
u
t T
X"
REFERENCES,0.48787061994609165,"t=1
α2
t "
REFERENCES,0.48921832884097033,"≤2 exp

−λ2 2 
."
REFERENCES,0.49056603773584906,Under review as a conference paper at ICLR 2022
REFERENCES,0.4919137466307278,"Now we can bound P

|Y −EY | ≥λ
qPT
t=1 α2
t"
REFERENCES,0.49326145552560646,"
as follows. P "
REFERENCES,0.4946091644204852,|Y −EY | ≥λ
REFERENCES,0.49595687331536387,"v
u
u
t T
X"
REFERENCES,0.4973045822102426,"t=1
α2
t   =P "
REFERENCES,0.49865229110512127,|Y −EY | ≥λ
REFERENCES,0.5,"v
u
u
t T
X"
REFERENCES,0.5013477088948787,"t=1
α2
t, Y = Y ′  + P "
REFERENCES,0.5026954177897575,|Y −EY | ≥λ
REFERENCES,0.5040431266846361,"v
u
u
t T
X"
REFERENCES,0.5053908355795148,"t=1
α2
t, Y ̸= Y ′   ≤P "
REFERENCES,0.5067385444743935,|Y ′ −EY ′| ≥λ
REFERENCES,0.5080862533692723,"v
u
u
t T
X"
REFERENCES,0.5094339622641509,"t=1
α2
t "
REFERENCES,0.5107816711590296,+ P (Y ̸= Y ′)
REFERENCES,0.5121293800539084,"≤2 exp

−λ2 2 
+ T
X"
REFERENCES,0.5134770889487871,"t=1
P(|Xt| ≥αt)."
REFERENCES,0.5148247978436657,Then the proof is completed. Here we notice the fact that EY ′ = EY by our construction.
REFERENCES,0.5161725067385444,"The following lemma is taken from (22), Theorem 4 of (Delyon et al., 2009)."
REFERENCES,0.5175202156334232,"Lemma B.4 (Bernstein’s Inequality for Dependent Process). Let {Zt} be a centered adaptive pro-
cess with respect to F. Deﬁne the following quantities. q = n
X k=1 k−1
X"
REFERENCES,0.5188679245283019,"i=1
∥Zi∥∞· ∥E[Zk|Fi]∥∞, v =
X"
REFERENCES,0.5202156334231806,"k
∥E[Z2
k|Zk−1, . . . , Z1]∥∞,"
REFERENCES,0.5215633423180593,"m = sup
1≤i≤n
∥Zi∥∞."
REFERENCES,0.522911051212938,"Then, it holds that"
REFERENCES,0.5242587601078167,"P

n
X"
REFERENCES,0.5256064690026954,"i=1
Zi ≥t

≤exp

−
t2"
REFERENCES,0.5269541778975741,"2(v + 2q) + 2tm/3 
."
REFERENCES,0.5283018867924528,"Application of Lemma B.4 to our proof. Here we make some comments about how to apply this
inequality in our main proof. We deﬁne the following random variable in our proof. Throughout, we
use the batch-level ﬁltration F and the intra-batch level ﬁltration bF. The formal deﬁnition is given
in Section B.2."
REFERENCES,0.5296495956873315,"Xi
t = f
 
w((t −1)τ + 1)

−f(w∗) + F(w∗; xtτ+i−1) −F
 
w((t −1)τ + 1); xtτ+i−1

."
REFERENCES,0.5309973045822103,"We also deﬁne the ﬁltration Fi
t := Ftτ+i−1 for simplicity. Then, we have"
REFERENCES,0.532345013477089,"E[Xi
t|Fi
t−1] = f
 
w((t −1)τ + 1)

−f(w∗) + E

F(w∗; xtτ+i−1) −F
 
w((t −1)τ + 1); xtτ+i−1

|Fi
t−1

."
REFERENCES,0.5336927223719676,"Then, the bias can be rewritten as"
REFERENCES,0.5350404312668463,"Xi
t −E[Xi
t|Fi
t−1]"
REFERENCES,0.5363881401617251,"=F(w∗; xtτ+i−1) −F(w((t −1)τ + 1); xtτ+i−1) −E

F(w∗; xtτ+i−1) −F
 
w((t −1)τ + 1); xtτ+i−1

|Fi
t−1
 = 1 B X"
REFERENCES,0.5377358490566038,"ξ∈xtτ+i−1
Y i
t (ξ),"
REFERENCES,0.5390835579514824,"where Y i
t is deﬁned as"
REFERENCES,0.5404312668463612,"Y i
t (ξ) = F(w∗; ξ) −F
 
w((t −1)τ + 1); ξ

−E

F(w∗; ξ) −F
 
w((t −1)τ + 1); ξ

|Fi
t−1

."
REFERENCES,0.5417789757412399,Under review as a conference paper at ICLR 2022
REFERENCES,0.5431266846361186,"More speciﬁcally, we have"
REFERENCES,0.5444743935309974,"Xi
t −E[Xi
t|Fi
t−1] = 1 B X"
REFERENCES,0.545822102425876,"ξ∈xtτ+i−1
Y i
t (ξ) = 1 B B
X"
REFERENCES,0.5471698113207547,"j=1
Y i
t (ξ(j)
tτ+i−1)."
REFERENCES,0.5485175202156334,"Recall that
bF is the canonical ﬁltration generated from the data stream (12).
Moreover,
{Y i
t (ξ(j)
tτ+i−1)}j=1,2,...,B is centered and adaptive with respect to this ﬁltration. Then we can evalu-
ate the quantities q, v, and m in Lemma B.4 as follows."
REFERENCES,0.5498652291105122,"• Bounding m is simple. By Assumption 2.1 we have ∥Y i
t (ξ(j)
tτ+i−1)∥≤2GR."
REFERENCES,0.5512129380053908,"• The above bound of m leads to a simple bound for v, i.e., v ≤2nG2R2."
REFERENCES,0.5525606469002695,"• The quantity q can be bounded as follows. q := n
X k=1 k−1
X"
REFERENCES,0.5539083557951483,"j=1
∥Y i
t (ξ(j)
tτ+i−1)∥∞∥E[Y i
t (ξ(k)
tτ+i−1)| bF(j)
tτ+i−1]∥∞ ≤2GR n
X k=1 k−1
X"
REFERENCES,0.555256064690027,"j=1
∥E[Y i
t (ξ(k)
tτ+i−1)| bF(j)
tτ+i−1]∥∞ = 2GR n
X k=1 k−1
X"
REFERENCES,0.5566037735849056,"j=1
∥E[Y i
t (ξ(k)
tτ+i−1)| bF(j)
tτ+i−1] −Eξ∼µY i
t (ξ(k)
tτ+i−1)∥∞"
REFERENCES,0.5579514824797843,"≤4G2R2
n
X k=1 k−1
X"
REFERENCES,0.5592991913746631,"i=1
φξ(k −i)"
REFERENCES,0.5606469002695418,"≤4G2R2n n
X"
REFERENCES,0.5619946091644205,"i=1
φξ(i)."
REFERENCES,0.5633423180592992,"Then, by applying Lemma B.4, we obtain the following high-probability bound."
REFERENCES,0.5646900269541779,"P
 
|Xi
t −E[Xi
t|Fi
t−1]| ≥t

≤2 exp

−
B2t2"
REFERENCES,0.5660377358490566,2(v + 2q) + 2Btm/3 
REFERENCES,0.5673854447439353,≤2 exp 
REFERENCES,0.568733153638814,"−
B2t2"
REFERENCES,0.5700808625336927,"2(2G2R2B + 8G2R2B PB
i=1 φξ(i)) + 4GRBt/3 !"
REFERENCES,0.5714285714285714,"= 2 exp  −
Bt2"
REFERENCES,0.5727762803234502,"2(2G2R2 + 8G2R2 PB
i=1 φξ(i)) + 4GRt/3 ! ."
REFERENCES,0.5741239892183289,Simplifying yields that
REFERENCES,0.5754716981132075,"P
 
|Xi
t −E[Xi
t|Fi
t−1]| ≥t

≤2 exp  −
Bt2 C + 4"
REFERENCES,0.5768194070080862,"3GRt + 16G2R2 PB
i=1 φξ(i) ! ,"
REFERENCES,0.578167115902965,where C := 4G2R2.
REFERENCES,0.5795148247978437,"B.2
PROOF OF THE MAIN RESULT"
REFERENCES,0.5808625336927223,"Recall that we are considering a data stream divided into small mini-batches. For convenience, we
re-label the data stream {ξ1, ξ2, ξ3, . . . } as follows to explicitly indicate its mini-batch index."
REFERENCES,0.5822102425876011,"{ξ(1)
1 , ξ(2)
1 , . . . , ξ(B)
1
, ξ(1)
2 , ξ(2)
2 , . . . , ξ(B)
2
, . . . }.
(12)"
REFERENCES,0.5835579514824798,"The canonical ﬁltration generated by the re-labeled data stream is denoted by bF. Also, when the
batch size is clear in the context, we denote the data in the speciﬁed mini-batch as x. For example,"
REFERENCES,0.5849056603773585,Under review as a conference paper at ICLR 2022
REFERENCES,0.5862533692722371,"we use xt to represent the t-th mini-batch {ξ(1)
t
, ξ(2)
t
, . . . , ξ(B)
t
}. Then we can re-writhe the above
data stream as"
REFERENCES,0.5876010781671159,"{x1, x2, x3. . . . }."
REFERENCES,0.5889487870619946,"We denote the canonical ﬁltration generated by the above sequence as F. Note that we have the
following relation:"
REFERENCES,0.5902964959568733,"Ft = bF(B)
t
."
REFERENCES,0.5916442048517521,"In summary, when we analyze the mini-batch SGD dynamics, we use the ﬁltration F, and when we
need to consider intra-batch samples, we use the ﬁltration bF."
REFERENCES,0.5929919137466307,"Theorem B.5. Let {w(t)}t∈N be the model parameter sequence generated by (6). Suppose Assump-
tions 2.1 and 3.1 hold. Then, for any τ ∈N, with probability at least 1 −δ, we have n
X"
REFERENCES,0.5943396226415094,"t=1
[f(w(t)) −f(w∗)] ≤GR n B B
X"
REFERENCES,0.5956873315363881,"i=1
φξ(τB + i) +"
REFERENCES,0.5970350404312669,"v
u
u
u
t2τn"
REFERENCES,0.5983827493261455,"B
·
2"
GR,0.5997304582210242,"3
GR"
GR,0.601078167115903,B log 4n δ +
GR,0.6024258760107817,"v
u
u
t4"
GR,0.6037735849056604,"9
G2R2"
GR,0.605121293800539,"B
(log 4n"
GR,0.6064690026954178,"δ )2 +
 
4G2R2 + 16G2R2
B
X"
GR,0.6078167115902965,"i=1
φξ(i)

log 4n δ"
GR,0.6091644204851752,"
· log 4τ"
GR,0.610512129380054,δ log 4n δ
GR,0.6118598382749326,+ Rn + G(τ −1)
GR,0.6132075471698113,"n−τ+1
X"
GR,0.6145552560646901,"t=1
κ(t) + GR(τ −1)."
GR,0.6159029649595688,"In particular, if τ = 1, then n
X"
GR,0.6172506738544474,"t=1
[f(w(t)) −f(w∗)]"
GR,0.6185983827493261,"≤Rn + GR n B B
X"
GR,0.6199460916442049,"i=1
φξ(B + i) +"
GR,0.6212938005390836,"v
u
u
u
t2n"
GR,0.6226415094339622,"B ·
2"
GR,0.623989218328841,"3
GR"
GR,0.6253369272237197,B log 4n δ +
GR,0.6266846361185984,"v
u
u
t4"
GR,0.628032345013477,"9
G2R2"
GR,0.6293800539083558,"B
(log 4n"
GR,0.6307277628032345,"δ )2 +
 
4G2R2 + 16G2R2
B
X"
GR,0.6320754716981132,"i=1
φξ(i)

log 4n δ"
GR,0.633423180592992,"
· log 4τ"
GR,0.6347708894878706,δ log 4n δ .
GR,0.6361185983827493,"Proof. From Proposition B.2, we obtain the following bound. n
X"
GR,0.637466307277628,"t=1
[f(w(t)) −f(w∗)] ≤ n
X"
GR,0.6388140161725068,"t=1
[f(w(t)) −F(w(t); xt+τ−1) + F(w∗; xt+τ−1) −f(w∗)] + Rn + G(τ −1)"
GR,0.6401617250673854,"n−τ+1
X"
GR,0.6415094339622641,"t=1
κ(t) + GR(τ −1)."
GR,0.6428571428571429,"To complete the proof, it sufﬁces to bound the ﬁrst term; we deﬁne this term as Zn := n
X"
GR,0.6442048517520216,"t=1
[f(w(t)) −F(w(t); xt+τ−1) + F(w∗; xt+τ−1) −f(w∗)]."
GR,0.6455525606469003,"We apply the same decomposition as the (13) of (Agarwal & Duchi, 2012). Deﬁne the index set
I(i) as {1, . . . , ⌊n"
GR,0.6469002695417789,τ ⌋+ 1} for i ≤n −τ⌊n
GR,0.6482479784366577,"τ ⌋and {1, . . . , ⌊n"
GR,0.6495956873315364,"τ ⌋} otherwise. Then we have Zn = τ
X i=1 X"
GR,0.6509433962264151,"t∈I(i)
[Xi
t −E[Xi
t|Fi
t−1]] + τ
X i=1 X"
GR,0.6522911051212938,"t∈I(i)
E[Xi
t|Fi
t−1],"
GR,0.6536388140161725,Under review as a conference paper at ICLR 2022 where
GR,0.6549865229110512,"Xi
t = f
 
w((t −1)τ + 1)

−f(w∗) + F(w∗; xtτ+i−1) −F
 
w((t −1)τ + 1); xtτ+i−1

."
GR,0.6563342318059299,"Note that by Lemma 4.1, we have that E[Xi
t|Fi
t−1] ≤GR"
GR,0.6576819407008087,"B
PB
i=1 φξ(τB + i). Then, we have"
GR,0.6590296495956873,"P

Zn > nGR B B
X"
GR,0.660377358490566,"i=1
φξ(τB + i) + γ

≤P( τ
X i=1 X"
GR,0.6617250673854448,"t∈I(i)
[Xi
t −E[Xi
t|Fi
t−1]] > γ)"
GR,0.6630727762803235,"≤P

τ[ i=1 n X"
GR,0.6644204851752021,"t∈I(i)
[Xi
t −E[Xi
t|Fi
t−1]] > γ τ o ≤ τ
X"
GR,0.6657681940700808,"i=1
P
 X"
GR,0.6671159029649596,"t∈I(i)
[Xi
t −E[Xi
t|Fi
t−1]] > γ τ 
."
GR,0.6684636118598383,Deﬁne Y := P
GR,0.6698113207547169,"t∈I(i)[Xi
t −E[Xi
t|Fi
t−1]] and α :=
λ
√"
GR,0.6711590296495957,"B . Notice that Xi
t −E[Xi
t|Fi
t−1] is a centered
random variable, that is, E[Xi
t −E[Xi
t|Fi
t−1]] = 0. Then by the generalized Azuma’s inequality
(Lemma B.3), we conclude that"
GR,0.6725067385444744,"P

Y ≥γ τ"
GR,0.6738544474393531,"
≤2 exp

−
γ2"
GR,0.6752021563342318,"2τ 2 n τ α2 
+ n
τ
X"
GR,0.6765498652291105,"t=1
P(|Xi
t −E[Xi
t|Fi
t−1]| ≥α)."
GR,0.6778975741239892,"The second term can be bounded by using the generalized Bernstein’s inequality. The detailed
calculation can be found in the discussion after Lemma B.4. We obtain that"
GR,0.6792452830188679,"P
 
|Xi
t −E[Xi
t|Fi
t−1]| ≥α

≤2 exp  −
λ2 C + 4"
GR,0.6805929919137467,"3GR λ
√"
GR,0.6819407008086253,"B + 16G2R2 PB
i=1 φξ(i) ! ,"
GR,0.683288409703504,"where C = 4G2R2. In summary, the concentration bound for Zn is"
GR,0.6846361185983828,"P

Zn > GR n B X"
GR,0.6859838274932615,"i
φξ(τB + i) + γ
"
GR,0.6873315363881402,"≤2τ exp

−
γ2"
GR,0.6886792452830188,"2τ 2 n τ α2 
+ τ n
τ
X"
GR,0.6900269541778976,"t=1
P(|Xi
t −E[Xi
t|Fi
t−1]| ≥α)"
GR,0.6913746630727763,"≤2τ exp  −
γ2"
GR,0.692722371967655,2τn λ2 B !
GR,0.6940700808625337,"+ 2n exp  −
λ2 C + 4"
GR,0.6954177897574124,"3GR λ
√"
GR,0.6967654986522911,"B + 16G2R2 PB
i=1 φξ(i) ! ."
GR,0.6981132075471698,"Then, let δ"
GR,0.6994609164420486,"2 = 2n exp
 
−
λ2 C+ 4"
GR,0.7008086253369272,"3 GR
λ
√"
GR,0.7021563342318059,"B +16G2R2 PB
i=1 φξ(i)

, and we obtain that"
GR,0.7035040431266847,"λ2 =

C + 4"
GR,0.7048517520215634,"3GR λ
√"
GR,0.706199460916442,"B
+ 16G2R2
B
X"
GR,0.7075471698113207,"i=1
φξ(i)

· log 4n δ ."
GR,0.7088948787061995,It is a quadratic function of λ. Solving it yields that λ = 2
GR,0.7102425876010782,"3
GR"
GR,0.7115902964959568,B log 4n δ +
GR,0.7129380053908356,"v
u
u
t4"
GR,0.7142857142857143,"9
G2R2 B"
GR,0.715633423180593,"
log 4n δ"
GR,0.7169811320754716,"2
+

C + 16G2R2
B
X"
GR,0.7183288409703504,"i=1
φξ(i)

log 4n"
GR,0.7196765498652291,"δ .
(13)"
GR,0.7210242587601078,"Also, let δ"
GR,0.7223719676549866,"2 = 2τ exp

−
γ2"
GR,0.7237196765498652,2τn λ2 B
GR,0.7250673854447439,"
, we have that"
GR,0.7264150943396226,γ2 = 2τnλ2
GR,0.7277628032345014,B · log 4τ δ .
GR,0.72911051212938,"Substituting (13) into the above equation, we obtain that γ ="
GR,0.7304582210242587,"v
u
u
u
t2τn"
GR,0.7318059299191375,"B
·
2"
GR,0.7331536388140162,"3
GR"
GR,0.7345013477088949,B log 4n δ +
GR,0.7358490566037735,"v
u
u
t4"
GR,0.7371967654986523,"9
G2R2 B"
GR,0.738544474393531,"
log 4n δ"
GR,0.7398921832884097,"2
+

C + 16G2R2
B
X"
GR,0.7412398921832885,"i=1
φξ(i)

log 4n δ"
GR,0.7425876010781671,"
· log 4τ"
GR,0.7439353099730458,δ log 4n δ .
GR,0.7452830188679245,Under review as a conference paper at ICLR 2022
GR,0.7466307277628033,"Then, we conclude that with probability at least 1 −δ, n
X"
GR,0.7479784366576819,"t=1
[f(w(t)) −f(w∗)] ≤GR n B B
X"
GR,0.7493261455525606,"i=1
φξ(τB + i) +"
GR,0.7506738544474394,"v
u
u
u
t2τn"
GR,0.7520215633423181,"B
·
2"
GR,0.7533692722371967,"3
GR"
GR,0.7547169811320755,B log 4n δ +
GR,0.7560646900269542,"v
u
u
t4"
GR,0.7574123989218329,"9
G2R2 B"
GR,0.7587601078167115,"
log 4n δ"
GR,0.7601078167115903,"2
+

4G2R2 + 16G2R2
B
X"
GR,0.761455525606469,"i=1
φξ(i)

log 4n δ"
GR,0.7628032345013477,"
· log 4τ"
GR,0.7641509433962265,δ log 4n δ
GR,0.7654986522911051,+ Rn + G(τ −1)
GR,0.7668463611859838,"n−τ+1
X"
GR,0.7681940700808625,"t=1
κ(t) + GR(τ −1).
(14)"
GR,0.7695417789757413,"The desired result follows by noting that Pn
t=1 f(w(t)) ≥nf( bwn)."
GR,0.77088948787062,"C
REGRET ANALYSIS OF MINI-BATCH SGD"
GR,0.7722371967654986,"In this section, we derive the regret bound of mini-batch SGD algorithm. Throughout, for each sam-
ple loss F(w; ξ), recall that its gradient ∥∇F(w; ξ)∥is uniformly bounded by G (see Assumption
2.1). In particular, we assume the k-th coordinate of ∇F(w; ξ) is uniformly bounded by Gk, and
we have G =
pP"
GR,0.7735849056603774,"k G2
k."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7749326145552561,1. Gradient Variance Bound under Dependent Data
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7762803234501348,"In the i.i.d. setting, the variance of stochastic gradient decreases as the batch size increases. Speciﬁ-
cally, we have E∥1 B B
X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7776280323450134,"i=1
∇F(w; ξi) −∇f(w)∥2 = 1 B2 B
X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7789757412398922,"i=1
E∥∇F(w; ξi) −∇f(w)∥2 ≤2G2 B ."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7803234501347709,"Therefore, E∥1"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7816711590296496,"B
PB
i=1 ∇F(w; ξi) −∇f(w)∥2 = O( 1"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7830188679245284,"B ). However, this bound no longer holds if
the data samples are dependent. In the following lemma, we develop a similar result when the data
is collected from a dependent stochastic process. Recall that ∇F(w(t); xt) denotes the averaged
gradient over the mini-batch xt, i.e.,"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.784366576819407,"∇F(w(t); xt) = 1 B B
X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7857142857142857,"i=1
F(w(t); ξ(i)
t )."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7870619946091644,"Lemma C.1. Let {w(t)}t∈N be the model parameter sequence generated by the mini-batch SGD in
(6). Let Assumptions 2.1 and 3.1 hold. Then, with probability at least 1 −δ,"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7884097035040432,"∥∇F(w(t); xt) −∇f(w(t))∥2 ≤
h268"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7897574123989218,"3 G2 + 256G2
B
X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7911051212938005,"j=1
φξ(j)
i
· log 2d"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7924528301886793,"δ
B
+ 2G2
 PB
i=1 φξ(i) B !2 ."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.793800539083558,"Proof. Let xt = {ξ(i)
t }B
i=1 be the t-th mini-batch samples. We consider the ﬁltration within xt and
denote it as { bF(i)
t }. Then, by the deﬁnition of canonical ﬁltration,"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7951482479784366,"Xi := ∇F(w(t); ξ(i)
t )"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7964959568733153,"is measurable with respect to bF(i)
t . Deﬁne"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7978436657681941,"Yi,k := (Xi −E[Xi|Ft−1])k"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.7991913746630728,"where (·)k denotes the k-th entry of the speciﬁed vector. And it is easy to see that {Yi,k}i is a
centered process for any k ∈{1, 2, . . . , d}. With these construction, we start from the following"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8005390835579514,Under review as a conference paper at ICLR 2022
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8018867924528302,decomposition.
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8032345013477089,∥∇F(w(t); xt) −∇f(w(t))∥2
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8045822102425876,=∥∇F(w(t); xt) −E[∇F(w(t); xt)|Ft−1] + E[∇F(w(t); xt)|Ft−1] −∇f(w(t))∥2
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8059299191374663,"≤2 ∥∇F(w(t); xt) −E[∇F(w(t); xt)|Ft−1]∥2
|
{z
}
(A)"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.807277628032345,"+2 ∥E[∇F(w(t); xt)|Ft−1] −∇f(w(t))∥2
|
{z
}
(B) ."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8086253369272237,"Then we will bound the term (A) and (B), respectively."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8099730458221024,• Bounding (A): Note that
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8113207547169812,"∥∇F(w(t); xt) −E[∇F(w(t); xt)|Ft−1]∥2 = 1 B2 ∥ B
X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8126684636118598,"i=1
[Xi −E[Xi|Ft−1]]∥2 = 1 B2 d
X k=1 h
B
X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8140161725067385,"i=1
(Xi −E[Xi|Ft−1])k
i2 = 1 B2 d
X k=1 h
B
X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8153638814016172,"i=1
Yi,k
i2
."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.816711590296496,"Then, we show that the process {Yi,k}i satisﬁes the conditions of Lemma B.4."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8180592991913747,"◦Since E[Yi,k|Ft−1] = 0, we conclude that {Yi,k}i is a centered process.
◦Denote the k-th entry of Xi as Xi,k. We know that |Xi,k| ≤Gk. Hence, we conclude
that 0 ≤|Yi,k| ≤2Gk. Then, we can set bi = 2Gk for all i.
◦Lastly, we can bound the quantity q deﬁned in Lemma B.4 as follows."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8194070080862533,"q ≤2Gk B
X j=1 j−1
X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8207547169811321,"i=1
∥E[Yj,k|F(i)
t ]∥+ 4"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8221024258760108,"3G2
kB"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8234501347708895,"≤4G2
k B
X j=1 j−1
X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8247978436657682,"i=1
φξ(j −i) + 4"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8261455525606469,"3G2
kB"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8274932614555256,"≤4G2
kB B
X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8288409703504043,"j=1
φξ(j) + 4"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8301886792452831,"3G2
kB."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8315363881401617,"Now, we can apply Lemma B.4 and obtain that P X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8328840970350404,"i
Yi,k > λ ! ≤exp  −
λ2 134"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8342318059299192,"3 G2
kB + 128G2
kB PB
j=1 φξ(j) ! ."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8355795148247979,"With a union bound, we obtain that P X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8369272237196765,"i
Yi,k
 > λ !"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8382749326145552,"≤2 exp  −
λ2 134"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.839622641509434,"3 G2
kB + 128G2
kB PB
j=1 φξ(j) ! ."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8409703504043127,"Further applying the union bound over k = 1, 2, . . . , d, we obtain that P d[ k=1 n X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8423180592991913,"i
Yi,k
2 > λ2
k
o! ≤2
X k
exp "
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8436657681940701,"−
λ2
k
134"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8450134770889488,"3 G2
kB + 128G2
kB PB
j=1 φξ(j) ! . Let δ"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8463611859838275,"d = 2 exp

−
λ2
k
134"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8477088948787062,"3 G2
kB+128G2
kB PB
j=1 φξ(j)"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8490566037735849,"
, we obtain that"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8504043126684636,"λ2
k =
h134"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8517520215633423,"3 G2
kB + 128G2
kB B
X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8530997304582211,"j=1
φξ(j)
i
· log 2d δ ."
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8544474393530997,Under review as a conference paper at ICLR 2022
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8557951482479784,"Then we conclude that, P  
d\ k=1 n X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8571428571428571,"i
Yi,k
2 ≤
h134"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8584905660377359,"3 G2
kB + 128G2
kB B
X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8598382749326146,"j=1
φξ(j)
i
· log 2d δ o
"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8611859838274932,≥1 −δ.
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.862533692722372,"It implies that with the probability at least 1 −δ, X k X"
GRADIENT VARIANCE BOUND UNDER DEPENDENT DATA,0.8638814016172507,"i
Yi,k
2 ≤
h134"
B,0.8652291105121294,"3 B
 X"
B,0.866576819407008,"k
G2
k

+ 128B

B
X"
B,0.8679245283018868,"j=1
φξ(j)
 X"
B,0.8692722371967655,"k
G2
k
i
· log 2d δ ."
B,0.8706199460916442,"By deﬁnition, G =
pP"
B,0.871967654986523,"k G2
k. Finally, we have the following bound for term (A): with
probability at least 1 −δ,"
B,0.8733153638814016,"∥∇F(w(t); xt) −E[∇F(w(t); xt)|Ft−1]∥2 ≤
h134"
B,0.8746630727762803,"3 G2 + 128G2
B
X"
B,0.876010781671159,"j=1
φξ(j)
i
· log 2d δ
B
."
B,0.8773584905660378,• Bounding (B): Note that
B,0.8787061994609164,"∥E[∇F(w(t); ξ(i)
t )|Ft−1] −∇f(w(t))∥=

Z
∇F(w(t); ξ(i)
t )dP(ξ(i)
t
∈·|Ft−1) −
Z
∇F(w(t); ξ)dµ(ξ)"
B,0.8800539083557951,"≤
Z
∥∇F(w(t); ξ(i)
t )∥|dP(ξ(i)
t
∈·|Ft−1) −dµ|"
B,0.8814016172506739,≤G · φξ(i).
B,0.8827493261455526,"Then we bound the norm by triangle inequality,"
B,0.8840970350404312,"∥E[∇F(w(t); xt)|Ft−1] −∇f(w(t))∥≤1 B B
X"
B,0.8854447439353099,"i=1
∥E[∇F(w(t); ξ(i)
t )|Ft−1] −∇f(w(t))∥ ≤G B B
X"
B,0.8867924528301887,"i=1
φξ(i)."
B,0.8881401617250674,"Finally, we obtain the bound for the term (B) as"
B,0.889487870619946,"∥E[∇F(w(t); xt)|Ft−1] −∇f(w(t))∥2 ≤G2
 PB
i=1 φξ(i) B !2 ."
B,0.8908355795148248,"Combing the bounds of (A) and (B) yields that with probability at least 1 −δ,"
B,0.8921832884097035,"∥∇F(w(t); xt) −∇f(w(t))∥2 ≤
h268"
B,0.8935309973045822,"3 G2 + 256G2
B
X"
B,0.894878706199461,"j=1
φξ(j)
i
· log 2d"
B,0.8962264150943396,"δ
B
+ 2G2
 PB
i=1 φξ(i) B !2 ."
HIGH-PROBABILITY REGRET BOUND,0.8975741239892183,2. High-Probability Regret Bound
HIGH-PROBABILITY REGRET BOUND,0.898921832884097,"To derive the regret bound for the mini-batch SGD algorithm, we make the following additional
mild assumption."
HIGH-PROBABILITY REGRET BOUND,0.9002695417789758,Assumption C.2. The stochastic optimization problem (P) satisﬁes
HIGH-PROBABILITY REGRET BOUND,0.9016172506738545,1. Each sample loss F(·; ξ) : W →R is convex.
HIGH-PROBABILITY REGRET BOUND,0.9029649595687331,2. The objective function f : W →R is L-smooth.
HIGH-PROBABILITY REGRET BOUND,0.9043126684636119,Under review as a conference paper at ICLR 2022
HIGH-PROBABILITY REGRET BOUND,0.9056603773584906,"Theorem C.3 (High-probability regret bound). Let {w(t)}t∈N be the model parameter sequence
generated by the mini-batch SGD in (6). Suppose Assumptions C.2, 3.1 and 2.1 hold. Then, with
probability at least 1 −δ,"
HIGH-PROBABILITY REGRET BOUND,0.9070080862533693,RT ≤∥w(1) −w∗∥2
HIGH-PROBABILITY REGRET BOUND,0.9083557951482479,"2η
+ ηT
h268"
HIGH-PROBABILITY REGRET BOUND,0.9097035040431267,"3 G2 + 256G2
B
X"
HIGH-PROBABILITY REGRET BOUND,0.9110512129380054,"j=1
φξ(j)
log 2dT"
HIGH-PROBABILITY REGRET BOUND,0.9123989218328841,"δ
B
+ 2G2PB
i=1 φξ(i) B 2i + 2ηL T
X t=1"
HIGH-PROBABILITY REGRET BOUND,0.9137466307277629," 
f(w(t)) −f(w∗)

."
HIGH-PROBABILITY REGRET BOUND,0.9150943396226415,"Moreover, let η = O(
q"
HIGH-PROBABILITY REGRET BOUND,0.9164420485175202,"B
T ·PB
j=1 φξ(j)), the optimized upper bound is in the order of"
HIGH-PROBABILITY REGRET BOUND,0.9177897574123989,"RT = e
O

s"
HIGH-PROBABILITY REGRET BOUND,0.9191374663072777,"T · PB
j=1 φξ(j) B"
HIGH-PROBABILITY REGRET BOUND,0.9204851752021563,"
+ 2ηL T
X t=1"
HIGH-PROBABILITY REGRET BOUND,0.921832884097035," 
f(w(t)) −f(w∗)

."
HIGH-PROBABILITY REGRET BOUND,0.9231805929919138,"Proof. For convenience, we deﬁne gt = 1"
HIGH-PROBABILITY REGRET BOUND,0.9245283018867925,"B
PB
i=1 ∇F(w(t); ξ(i)
t ). By the algorithm update (6), we
obtain that"
HIGH-PROBABILITY REGRET BOUND,0.9258760107816711,"2⟨gt, w(t) −w∗⟩≤∥w(t) −w∗∥2 −∥w(t + 1) −w∗∥2"
HIGH-PROBABILITY REGRET BOUND,0.9272237196765498,"η
+ η∥gt∥2"
HIGH-PROBABILITY REGRET BOUND,0.9285714285714286,≤∥w(t) −w∗∥2 −∥w(t + 1) −w∗∥2
HIGH-PROBABILITY REGRET BOUND,0.9299191374663073,"η
+ 2η∥gt −∇f(w(t))∥2 + 2η∥∇f(w(t))∥2."
HIGH-PROBABILITY REGRET BOUND,0.931266846361186,"Summing the above inequality over t yields that 2 T
X"
HIGH-PROBABILITY REGRET BOUND,0.9326145552560647,"t=1
⟨gt, w(t) −w∗⟩"
HIGH-PROBABILITY REGRET BOUND,0.9339622641509434,≤∥w(1) −w∗∥2 −∥w(T + 1) −w∗∥2
HIGH-PROBABILITY REGRET BOUND,0.9353099730458221,"η
+ 2η T
X"
HIGH-PROBABILITY REGRET BOUND,0.9366576819407008,"t=1
∥gt −∇f(w(t))∥2 + 4ηL T
X"
HIGH-PROBABILITY REGRET BOUND,0.9380053908355795,"t=1
(f(w(t)) −f(w∗))."
HIGH-PROBABILITY REGRET BOUND,0.9393530997304582,"By convexity of the function, we further obtain that 2 T
X"
HIGH-PROBABILITY REGRET BOUND,0.9407008086253369,"t=1
(F(w(t); xt) −F(w∗; xt)) ≤∥w(1) −w∗∥2"
HIGH-PROBABILITY REGRET BOUND,0.9420485175202157,"η
+ 2η T
X"
HIGH-PROBABILITY REGRET BOUND,0.9433962264150944,"t=1
∥gt −∇f(w(t))∥2 + 4ηL T
X"
HIGH-PROBABILITY REGRET BOUND,0.944743935309973,"t=1
(f(w(t)) −f(w∗))."
HIGH-PROBABILITY REGRET BOUND,0.9460916442048517,"Then, we apply Lemma C.1 to bound the second term PT
t=1 ∥gt −∇f(w(t))∥2 and then apply a
union bound on over t. We conclude that, with probability at least 1 −δ, T
X"
HIGH-PROBABILITY REGRET BOUND,0.9474393530997305,"t=1
(F(w(t); xt) −F(w∗; xt))"
HIGH-PROBABILITY REGRET BOUND,0.9487870619946092,≤∥w(1) −w∗∥2
HIGH-PROBABILITY REGRET BOUND,0.9501347708894878,"2η
+ ηT ·
h268"
HIGH-PROBABILITY REGRET BOUND,0.9514824797843666,"3 G2 + 256G2
B
X"
HIGH-PROBABILITY REGRET BOUND,0.9528301886792453,"j=1
φξ(j)
log 2dT"
HIGH-PROBABILITY REGRET BOUND,0.954177897574124,"δ
B
+ 2G2
 PB
i=1 φξ(i) B !2 i + 2ηL T
X"
HIGH-PROBABILITY REGRET BOUND,0.9555256064690026,"t=1
(f(w(t)) −f(w∗))."
HIGH-PROBABILITY REGRET BOUND,0.9568733153638814,"The proof is completed. Lastly, we set the learning rate η. To minimize the obtained upper bound, it
sufﬁces to minimize the ﬁrst two terms, as the last term can be combined with the left hand side of
(14) when we apply this regret bound. The optimized learning rate is achieved when"
HIGH-PROBABILITY REGRET BOUND,0.9582210242587601,∥w(1) −w∗∥2
HIGH-PROBABILITY REGRET BOUND,0.9595687331536388,"2η
= ηT ·
h268"
HIGH-PROBABILITY REGRET BOUND,0.9609164420485176,"3 G2 + 256G2
B
X"
HIGH-PROBABILITY REGRET BOUND,0.9622641509433962,"j=1
φξ(j)
log 2dT"
HIGH-PROBABILITY REGRET BOUND,0.9636118598382749,"δ
B
+ 2G2
 PB
i=1 φξ(i) B"
HIGH-PROBABILITY REGRET BOUND,0.9649595687331537,"!2 i
."
HIGH-PROBABILITY REGRET BOUND,0.9663072776280324,Under review as a conference paper at ICLR 2022
HIGH-PROBABILITY REGRET BOUND,0.967654986522911,"Then, η is chosen as η ="
HIGH-PROBABILITY REGRET BOUND,0.9690026954177897,"v
u
u
t"
HIGH-PROBABILITY REGRET BOUND,0.9703504043126685,∥w(1) −w∗∥2/2
HIGH-PROBABILITY REGRET BOUND,0.9716981132075472,"T ·
h
268"
HIGH-PROBABILITY REGRET BOUND,0.9730458221024259,"3 G2 + 256G2 PB
j=1 φξ(j)
 log 2dT"
HIGH-PROBABILITY REGRET BOUND,0.9743935309973046,"δ
B
+ 2G2
 PB
i=1 φξ(i)"
HIGH-PROBABILITY REGRET BOUND,0.9757412398921833,"B
2 i = O s B"
HIGH-PROBABILITY REGRET BOUND,0.977088948787062,"T · PB
j=1 φξ(j) ! ."
HIGH-PROBABILITY REGRET BOUND,0.9784366576819407,"D
EXPERIMENT SETUP"
HIGH-PROBABILITY REGRET BOUND,0.9797843665768194,Recall that we consider the following convex quadratic optimization problem:
HIGH-PROBABILITY REGRET BOUND,0.9811320754716981,"min
w∈Rd Eξ∼µ(w −ξ)T A(w −ξ),"
HIGH-PROBABILITY REGRET BOUND,0.9824797843665768,"where A is a ﬁxed positive semi-deﬁnite matrix and µ is the uniform distribution on [0, 1]d. The data
stream admitting such a stationary distribution µ can be generated by a certain Metropolis-Hastings
sampler provided in (Jarner & Roberts, 2002). Speciﬁcally, it is described as follows."
HIGH-PROBABILITY REGRET BOUND,0.9838274932614556,"Step 1: Let the “proposal” distribution q(x) have the density of Beta(r + 1, 1); that is,"
HIGH-PROBABILITY REGRET BOUND,0.9851752021563343,"q(x) =
(r + 1)xr
x ∈[0, 1]
0
x /∈[0, 1] ."
HIGH-PROBABILITY REGRET BOUND,0.9865229110512129,"Deﬁne the acceptance probability α(x, y) = min{ q(x)"
HIGH-PROBABILITY REGRET BOUND,0.9878706199460916,"q(y), 1}."
HIGH-PROBABILITY REGRET BOUND,0.9892183288409704,"Step 2: If the current state is ξt, then we sample ζ ∼q. Deﬁne the next state ξt+1:"
HIGH-PROBABILITY REGRET BOUND,0.9905660377358491,"ξt+1 =
ξt
w.p. 1 −α(ξt, ζ),
ζ
w.p. α(ξt, ζ)."
HIGH-PROBABILITY REGRET BOUND,0.9919137466307277,Step 3: Go back to Step 2 to generate the next state.
HIGH-PROBABILITY REGRET BOUND,0.9932614555256065,"We repeatedly generate d independent sequences starting from the same initial state s0 = 0 to obtain
a d-dimension Markov chain. It has been shown that the above generated Markov chain converges to
µ in distribution with an algebraic convergence rate φξ(k) ≤O(k−1/r) in Proposition 5.2, (Jarner
& Roberts, 2002)."
HIGH-PROBABILITY REGRET BOUND,0.9946091644204852,We consider the following bias term at the ﬁxed point w = 0d.
HIGH-PROBABILITY REGRET BOUND,0.9959568733153639,"(Bias):
E

F(w; xτ)|x0 = 0d

−f(w)
."
HIGH-PROBABILITY REGRET BOUND,0.9973045822102425,"It can be used to approximate the left-hand side of Lemma 4.1. Since E

F(w; xτ)|s0 = 0d

cannot
be explicitly obtained, we use Monte Carlo method to estimate this conditional expectation. That
is, we generate n = 10, 000 independent trajectories starting from x0 = 0d. At the step τ, we
estimate the expected value as 1"
HIGH-PROBABILITY REGRET BOUND,0.9986522911051213,"n
Pn
i=1 F(w; x(i)
τ ), where x(i)
τ
with the superscript (i) indicates that
it is sampled from the i-th trajectory. Then we investigate the relation between the step τ and the
mixing parameter r and the relation between the step τ and the batch size B. All the results are
presented in Section 5."
